{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from joblib import dump\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./datasets/fundamental_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = data['growth']\n",
    "data.drop(columns='growth')\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data, y_data, test_size=0.2, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise data\n",
    "normaliser = preprocessing.MinMaxScaler()\n",
    "X_train = normaliser.fit_transform(X_train)\n",
    "X_test = normaliser.transform(X_test)\n",
    "\n",
    "# Y normaliser\n",
    "y_normaliser = preprocessing.MinMaxScaler()\n",
    "Y_train = y_normaliser.fit_transform(Y_train.to_numpy().reshape(-1, 1))\n",
    "Y_test = y_normaliser.transform(Y_test.to_numpy().reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./normalisers/fundamental_y_normaliser.joblib']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save scalers for future use\n",
    "dump(normaliser, './normalisers/fundamental_x_normaliser.joblib')\n",
    "dump(y_normaliser, './normalisers/fundamental_y_normaliser.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dense(x, y, batch_size=512, epochs=24, **params):\n",
    "    \n",
    "    # List of parameters\n",
    "    if 'density' not in params: params['density'] = x.shape[1]\n",
    "    if 'activation' not in params: params['activation'] = 'relu'\n",
    "    if 'optimizer' not in params: params['optimizer'] = 'adam'\n",
    "    if 'shuffle' not in params: params['shuffle'] = False\n",
    "    \n",
    "    # Model definition\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(params['density'], activation=params['activation']))\n",
    "    \n",
    "    density = params['density']//2\n",
    "    while density >= 12:\n",
    "        if 'dropout' in params:\n",
    "            model.add(Dropout(params['dropout']))\n",
    "        model.add(Dense(density, activation=params['activation']))\n",
    "        density //= 2\n",
    "            \n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    \n",
    "    model.compile(loss='mse', optimizer=params['optimizer'])\n",
    "    \n",
    "    if 'callbacks' in params:\n",
    "        callback = model.fit(x=x, y=y, validation_split=0.1, batch_size=batch_size, epochs=epochs, shuffle=params['shuffle'],\n",
    "                            callbacks=params['callbacks'])\n",
    "    else:\n",
    "        callback = model.fit(x=x, y=y, validation_split=0.1, batch_size=batch_size, epochs=epochs, shuffle=params['shuffle'])\n",
    "    \n",
    "    return [model, callback, params]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evolutive algorith to search for the most optimal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_genes(x, y, population_size, population=[]):\n",
    "    if population_size-len(population) < 0:\n",
    "        print('population size must be greater or equal than actual population')\n",
    "        return\n",
    "    \n",
    "    if len(population) > 0:\n",
    "        if len(population) < 3:\n",
    "            print('population should be empty or 3 at least')\n",
    "            return\n",
    "        \n",
    "        population[2] = breed_genes(x, y, population[0][2].copy())\n",
    "        population[1] = breed_genes(x, y, combine=(population[0][2], population[1][2]))\n",
    "        population = population[:3]\n",
    "    \n",
    "    for _ in range(population_size-len(population)):\n",
    "        subject = breed_genes(x, y)\n",
    "        population.append(subject)\n",
    "        \n",
    "    return population\n",
    "\n",
    "def breed_genes(x, y, genes={}, combine=None):\n",
    "    genes['x'] = x\n",
    "    genes['y'] = y\n",
    "    \n",
    "    if type(combine) is list or type(combine) is tuple:\n",
    "        genes['density'] = combine[np.random.randint(0,2)]['density']\n",
    "        genes['activation'] = combine[np.random.randint(0,2)]['activation']\n",
    "        genes['optimizer'] = combine[np.random.randint(0,2)]['optimizer']\n",
    "        genes['shuffle'] = combine[np.random.randint(0,2)]['shuffle']\n",
    "        \n",
    "        genes['dropout'] = combine[np.random.randint(0,2)].get('dropout')\n",
    "        if genes['dropout'] is None: del genes['dropout']\n",
    "            \n",
    "    else:\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['density'] = int((np.random.randint(x.shape[1]//2,x.shape[1]*2.66)//2)*2)\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            activation = [\n",
    "                'relu',\n",
    "                'sigmoid',\n",
    "                'softplus',\n",
    "                'softsign',\n",
    "                'tanh',\n",
    "                'selu',\n",
    "                'elu',\n",
    "                'exponential'\n",
    "            ]\n",
    "            genes['activation'] = activation[np.random.randint(0,8)]\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            optimizer = [\n",
    "                'sgd',\n",
    "                'rmsprop',\n",
    "                'adam',\n",
    "                'adadelta',\n",
    "                'adagrad',\n",
    "                'adamax',\n",
    "                'nadam'\n",
    "            ]\n",
    "            genes['optimizer'] = optimizer[np.random.randint(0,7)]\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['shuffle'] = True\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['dropout'] = np.random.randint(1,4)/10\n",
    "            \n",
    "    new_model = build_dense(**genes)\n",
    "        \n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def breed_population(x, y, generations, population_size, population=[]):\n",
    "    \n",
    "    if generations > 1 and population_size < 3:\n",
    "        print('population size should be of a minimum of 3 for more than one generation')\n",
    "        return\n",
    "    \n",
    "    for g in range(generations):\n",
    "        print(f'\\nGENERATION {g}\\n')\n",
    "        population = set_genes(x, y, population_size, population)\n",
    "        population = sorted(population, key=lambda x: x[1].history['val_loss'][-1]+x[1].history['loss'][-1])\n",
    "        \n",
    "    return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GENERATION 0\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 36us/step - loss: 0.0107 - val_loss: 8.8871e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 0.0023 - val_loss: 2.9519e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0012 - val_loss: 9.2847e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 7.7633e-04 - val_loss: 8.4896e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 5.4246e-04 - val_loss: 1.1669e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 4.2114e-04 - val_loss: 5.5622e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 3.2186e-04 - val_loss: 4.1438e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 2.5486e-04 - val_loss: 3.6764e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 2.1472e-04 - val_loss: 3.0164e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 1.7951e-04 - val_loss: 4.0570e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 1.5662e-04 - val_loss: 2.8919e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 1.3878e-04 - val_loss: 3.0354e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 1.2066e-04 - val_loss: 2.6602e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 1.1122e-04 - val_loss: 2.9367e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 1.0207e-04 - val_loss: 3.1273e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 9.4457e-05 - val_loss: 2.4207e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 9.7067e-05 - val_loss: 2.8029e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 9.0474e-05 - val_loss: 2.3343e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 7.9055e-05 - val_loss: 2.1773e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 8.1612e-05 - val_loss: 2.5022e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 7.8752e-05 - val_loss: 1.9941e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 7.6051e-05 - val_loss: 1.8882e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 7.3515e-05 - val_loss: 1.8932e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 6.7895e-05 - val_loss: 1.8253e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0306 - val_loss: 1.3918e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 0.0107 - val_loss: 8.1018e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 0.0069 - val_loss: 5.2346e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 0.0049 - val_loss: 4.1799e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0038 - val_loss: 3.9177e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 0.0029 - val_loss: 3.8175e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 0.0024 - val_loss: 3.5993e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 0.0020 - val_loss: 3.6859e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 0.0017 - val_loss: 3.7627e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 0.0015 - val_loss: 5.3510e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 0.0013 - val_loss: 4.8903e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 0.0012 - val_loss: 4.5140e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 0.0010 - val_loss: 5.5287e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 9.3420e-04 - val_loss: 4.3017e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 8.3714e-04 - val_loss: 5.0158e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 7.6553e-04 - val_loss: 4.1951e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 7.1033e-04 - val_loss: 3.9469e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 6.6136e-04 - val_loss: 4.5088e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 6.0175e-04 - val_loss: 5.8398e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 5.6464e-04 - val_loss: 4.7128e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - ETA: 0s - loss: 5.3549e-0 - 0s 6us/step - loss: 5.3158e-04 - val_loss: 5.2827e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 5.0045e-04 - val_loss: 4.6447e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 4.6296e-04 - val_loss: 4.6163e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 4.3377e-04 - val_loss: 3.8822e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 498654566785555127567646720.0000 - val_loss: 5928.9827\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 985825299104.9912 - val_loss: 5808.7260\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 16999104825.9310 - val_loss: 5806.9698\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 7389095744.6930 - val_loss: 5805.7382\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 571714627829852.6250 - val_loss: 5805.5598\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 496966092245.8334 - val_loss: 5805.7223\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 80335028236.9186 - val_loss: 5804.4460\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 21677355776.9060 - val_loss: 5804.4732\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 164356207281.6893 - val_loss: 5802.9746\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 36589718157.0377 - val_loss: 5802.9366\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 20260652554.1644 - val_loss: 5802.9381\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 14448289465399726.0000 - val_loss: 5801.3874\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 398925652243.3504 - val_loss: 5801.3231\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 97009779793233.2656 - val_loss: 5801.0200\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 2772354913086.0513 - val_loss: 5802.2144\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 12959331429685.6953 - val_loss: 5802.3617\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 48979163071739.5547 - val_loss: 5802.3517\n",
      "Epoch 18/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 5us/step - loss: 31719061455.7653 - val_loss: 5802.2791\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 2515862864.4995 - val_loss: 5802.2388\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 31616295895.5957 - val_loss: 5802.2309\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 41379940663.5961 - val_loss: 5802.2283\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 127730688280551.5938 - val_loss: 5802.2162\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 1857303876614.8938 - val_loss: 5802.2136\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 16562235844995282.0000 - val_loss: 5802.3340\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: nan - val_loss: nan\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0905 - val_loss: 6.4170e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0115 - val_loss: 9.0146e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0062 - val_loss: 8.9901e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0041 - val_loss: 1.0656e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0030 - val_loss: 8.2265e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0022 - val_loss: 6.8307e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0017 - val_loss: 4.0030e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0014 - val_loss: 5.2767e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0012 - val_loss: 3.4436e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 9.9325e-04 - val_loss: 3.5653e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 8.5295e-04 - val_loss: 3.2286e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 7.2570e-04 - val_loss: 3.0987e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 6.4129e-04 - val_loss: 3.0778e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 5.6762e-04 - val_loss: 3.0058e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 5.1805e-04 - val_loss: 3.0022e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 4.6236e-04 - val_loss: 3.0064e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 4.1620e-04 - val_loss: 3.0776e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 3.8105e-04 - val_loss: 3.0471e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 3.5015e-04 - val_loss: 3.0637e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 3.2843e-04 - val_loss: 3.1344e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 2.9687e-04 - val_loss: 3.0579e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 2.8254e-04 - val_loss: 2.9792e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 2.6305e-04 - val_loss: 3.0557e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 2.4887e-04 - val_loss: 3.1870e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0493 - val_loss: 0.0014\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0093 - val_loss: 8.0075e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0046 - val_loss: 1.1442e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0028 - val_loss: 8.7171e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0019 - val_loss: 5.6709e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0013 - val_loss: 5.4095e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0010 - val_loss: 6.2213e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 7.7921e-04 - val_loss: 4.7236e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 6.3955e-04 - val_loss: 5.9585e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 5.0240e-04 - val_loss: 4.0830e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 4.3419e-04 - val_loss: 4.5557e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 3.7122e-04 - val_loss: 3.9256e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 3.3028e-04 - val_loss: 4.3013e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 2.8941e-04 - val_loss: 3.4917e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 2.5378e-04 - val_loss: 3.9930e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 2.2954e-04 - val_loss: 3.6401e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 2.0806e-04 - val_loss: 3.7158e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 1.8966e-04 - val_loss: 4.0895e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 1.7586e-04 - val_loss: 3.3822e-05\n",
      "Epoch 20/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 6us/step - loss: 1.5670e-04 - val_loss: 3.2889e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 1.5085e-04 - val_loss: 2.9829e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 1.4298e-04 - val_loss: 3.1339e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 1.3619e-04 - val_loss: 3.4512e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 1.2376e-04 - val_loss: 3.1188e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.1611 - val_loss: 0.0034\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0233 - val_loss: 2.3594e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0130 - val_loss: 1.6796e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0079 - val_loss: 9.5489e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0055 - val_loss: 7.5877e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0041 - val_loss: 6.7805e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0032 - val_loss: 8.2912e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0026 - val_loss: 7.3659e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0021 - val_loss: 6.0195e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0017 - val_loss: 5.4356e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0015 - val_loss: 5.8963e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0013 - val_loss: 5.2862e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0011 - val_loss: 4.9963e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 9.6928e-04 - val_loss: 5.0383e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 8.5859e-04 - val_loss: 4.6526e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 7.4759e-04 - val_loss: 4.7116e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 6.7929e-04 - val_loss: 4.4394e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 5.9279e-04 - val_loss: 4.5329e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 5.4625e-04 - val_loss: 3.9826e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 5.1733e-04 - val_loss: 4.2915e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 4.5086e-04 - val_loss: 4.2842e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 4.0591e-04 - val_loss: 3.8076e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 3.8215e-04 - val_loss: 3.9439e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 3.5842e-04 - val_loss: 3.5459e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.3015 - val_loss: 0.0190\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0176 - val_loss: 5.3696e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0140 - val_loss: 1.8633e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0130 - val_loss: 2.5142e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0115 - val_loss: 1.8007e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0105 - val_loss: 2.1504e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0095 - val_loss: 1.4935e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0084 - val_loss: 1.8360e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0077 - val_loss: 2.0310e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0069 - val_loss: 1.3806e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0062 - val_loss: 1.7244e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0056 - val_loss: 1.6594e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0051 - val_loss: 1.4805e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0045 - val_loss: 1.0607e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0041 - val_loss: 1.1633e-04\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0036 - val_loss: 8.5678e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0032 - val_loss: 8.0633e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0029 - val_loss: 1.0647e-04\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0026 - val_loss: 8.6981e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0022 - val_loss: 6.4945e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0021 - val_loss: 9.2254e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0019 - val_loss: 6.9272e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0016 - val_loss: 7.8666e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0015 - val_loss: 6.8124e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 0.1796 - val_loss: 0.0120\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0137 - val_loss: 1.2899e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0110 - val_loss: 1.8098e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0099 - val_loss: 1.2260e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0089 - val_loss: 1.4757e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0078 - val_loss: 1.0896e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0069 - val_loss: 8.8812e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0061 - val_loss: 9.5855e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0054 - val_loss: 8.7768e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0048 - val_loss: 1.1365e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0042 - val_loss: 9.2234e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0038 - val_loss: 8.9861e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0034 - val_loss: 8.0504e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0030 - val_loss: 8.6568e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0027 - val_loss: 5.5167e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0025 - val_loss: 8.1501e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0022 - val_loss: 5.9625e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0020 - val_loss: 5.3584e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0018 - val_loss: 6.9493e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0016 - val_loss: 5.5792e-05\n",
      "Epoch 21/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0015 - val_loss: 5.9170e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0014 - val_loss: 5.6442e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0012 - val_loss: 4.8366e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0011 - val_loss: 5.8181e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 26us/step - loss: 0.0420 - val_loss: 4.8011e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0134 - val_loss: 1.4486e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0096 - val_loss: 2.8343e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0069 - val_loss: 2.3938e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0052 - val_loss: 1.8673e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0041 - val_loss: 1.1331e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0031 - val_loss: 1.0386e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0025 - val_loss: 5.8616e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0021 - val_loss: 7.1001e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0017 - val_loss: 6.5017e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0014 - val_loss: 5.2590e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0012 - val_loss: 4.9648e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0011 - val_loss: 4.5294e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.4237e-04 - val_loss: 3.7847e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 8.1017e-04 - val_loss: 3.6474e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 7.3070e-04 - val_loss: 3.7329e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 6.7888e-04 - val_loss: 4.4401e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 6.2051e-04 - val_loss: 4.3050e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 5.7839e-04 - val_loss: 4.0088e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 5.2368e-04 - val_loss: 3.8065e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 4.9917e-04 - val_loss: 3.9827e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 4.7916e-04 - val_loss: 3.7253e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 4.4831e-04 - val_loss: 3.5209e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 4.2340e-04 - val_loss: 3.5323e-05\n",
      "\n",
      "GENERATION 1\n",
      "\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 30us/step - loss: 0.0138 - val_loss: 8.5160e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0030 - val_loss: 6.4030e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0016 - val_loss: 4.8943e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0011 - val_loss: 3.9800e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 7.9067e-04 - val_loss: 3.7021e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 6.0624e-04 - val_loss: 3.6201e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 4.9745e-04 - val_loss: 3.3448e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 4.1288e-04 - val_loss: 3.3671e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 3.5458e-04 - val_loss: 3.2113e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 3.1409e-04 - val_loss: 3.2513e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 2.9219e-04 - val_loss: 3.4922e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 2.5947e-04 - val_loss: 3.5453e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 2.4307e-04 - val_loss: 3.1949e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 2.2514e-04 - val_loss: 3.1887e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 2.1608e-04 - val_loss: 3.7532e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 2.0021e-04 - val_loss: 3.1873e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 1.9218e-04 - val_loss: 3.1392e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 1.8903e-04 - val_loss: 3.1460e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 1.8088e-04 - val_loss: 3.1926e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 1.7127e-04 - val_loss: 3.1467e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 1.6963e-04 - val_loss: 3.2021e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.6543e-04 - val_loss: 3.1736e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.5915e-04 - val_loss: 3.4064e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 1.5614e-04 - val_loss: 3.1652e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 25us/step - loss: 0.1121 - val_loss: 0.0065\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0193 - val_loss: 0.0010\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0092 - val_loss: 5.7402e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0056 - val_loss: 3.0890e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0037 - val_loss: 2.9872e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0026 - val_loss: 2.4583e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0020 - val_loss: 1.8030e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0016 - val_loss: 1.6485e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0013 - val_loss: 1.4996e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0011 - val_loss: 1.6980e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 9.2410e-04 - val_loss: 1.0356e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 8.0211e-04 - val_loss: 1.0478e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 6.9223e-04 - val_loss: 7.8941e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 6.2349e-04 - val_loss: 7.8403e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 5.4373e-04 - val_loss: 6.3085e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 4.8717e-04 - val_loss: 6.4246e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 4.4816e-04 - val_loss: 6.9317e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 4.0759e-04 - val_loss: 5.5315e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 3.7424e-04 - val_loss: 4.8857e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 3.4588e-04 - val_loss: 4.9691e-05\n",
      "Epoch 21/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 6us/step - loss: 3.1351e-04 - val_loss: 4.8472e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 2.7968e-04 - val_loss: 4.2204e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 2.6678e-04 - val_loss: 4.5531e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 2.6125e-04 - val_loss: 4.7397e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 29us/step - loss: 0.0900 - val_loss: 0.0060\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0160 - val_loss: 0.0012\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0088 - val_loss: 7.5131e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0059 - val_loss: 4.7162e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0043 - val_loss: 5.0712e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0034 - val_loss: 2.7000e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0027 - val_loss: 2.3668e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0022 - val_loss: 2.6114e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0018 - val_loss: 1.4378e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0016 - val_loss: 2.0819e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0014 - val_loss: 1.3589e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0012 - val_loss: 1.5497e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0011 - val_loss: 1.6156e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.5358e-04 - val_loss: 1.5460e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 8.5414e-04 - val_loss: 8.9312e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 7.7421e-04 - val_loss: 8.9696e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 7.1127e-04 - val_loss: 7.4199e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 6.5202e-04 - val_loss: 8.4707e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 5.8413e-04 - val_loss: 6.5834e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 5.3004e-04 - val_loss: 5.9882e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 5.0882e-04 - val_loss: 9.1199e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 4.6768e-04 - val_loss: 4.7084e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 4.2171e-04 - val_loss: 6.6266e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 3.9890e-04 - val_loss: 7.9621e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 28us/step - loss: 0.0502 - val_loss: 0.0017\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0091 - val_loss: 5.4357e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0054 - val_loss: 4.2885e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0038 - val_loss: 4.7110e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0028 - val_loss: 2.4258e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0022 - val_loss: 1.3121e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0018 - val_loss: 1.5086e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0014 - val_loss: 8.4967e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0011 - val_loss: 7.6373e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.9320e-04 - val_loss: 6.7004e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 8.1684e-04 - val_loss: 5.3990e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 6.8819e-04 - val_loss: 4.2757e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 5.9634e-04 - val_loss: 4.4638e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 5.2106e-04 - val_loss: 3.7319e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 4.6810e-04 - val_loss: 3.6576e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 4.2747e-04 - val_loss: 3.4438e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 3.6218e-04 - val_loss: 3.4466e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 3.4929e-04 - val_loss: 3.3993e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 3.1050e-04 - val_loss: 3.4346e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 2.8491e-04 - val_loss: 3.4097e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 2.7567e-04 - val_loss: 3.1396e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 2.7047e-04 - val_loss: 3.1611e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 2.6047e-04 - val_loss: 3.1243e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 2.3807e-04 - val_loss: 3.0741e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 29us/step - loss: 0.0627 - val_loss: 0.0026\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0180 - val_loss: 0.0025\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0114 - val_loss: 0.0016\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0081 - val_loss: 0.0010\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0063 - val_loss: 7.2044e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0050 - val_loss: 6.6389e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0041 - val_loss: 5.0090e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0034 - val_loss: 3.0078e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0029 - val_loss: 1.9608e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0025 - val_loss: 2.2639e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0022 - val_loss: 2.0175e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0019 - val_loss: 1.4704e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0016 - val_loss: 8.4781e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0014 - val_loss: 1.0592e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0013 - val_loss: 7.6007e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0011 - val_loss: 9.2676e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0010 - val_loss: 6.7737e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 8.9481e-04 - val_loss: 7.3302e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 7.9088e-04 - val_loss: 5.8399e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 7.2454e-04 - val_loss: 4.5744e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 6.4360e-04 - val_loss: 4.9884e-05\n",
      "Epoch 22/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 6us/step - loss: 5.8214e-04 - val_loss: 4.5437e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 5.1740e-04 - val_loss: 3.6417e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 4.8195e-04 - val_loss: 4.2986e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 30us/step - loss: 0.1195 - val_loss: 1.7231e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0363 - val_loss: 3.0949e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0243 - val_loss: 1.1870e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0179 - val_loss: 2.8847e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0141 - val_loss: 2.2693e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0113 - val_loss: 1.1067e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0094 - val_loss: 1.0287e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0084 - val_loss: 7.9678e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0072 - val_loss: 8.5081e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0064 - val_loss: 4.9229e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0057 - val_loss: 3.4995e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0050 - val_loss: 3.6874e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0042 - val_loss: 3.2286e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0040 - val_loss: 3.2161e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0037 - val_loss: 3.2651e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0035 - val_loss: 3.2556e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0033 - val_loss: 3.1873e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0030 - val_loss: 3.2110e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0028 - val_loss: 3.1641e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0025 - val_loss: 3.3426e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0024 - val_loss: 3.9737e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0021 - val_loss: 3.1477e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0021 - val_loss: 3.6217e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0020 - val_loss: 4.1093e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 31us/step - loss: 0.1482 - val_loss: 1.3822e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0380 - val_loss: 8.7113e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0291 - val_loss: 9.0163e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0231 - val_loss: 7.8706e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0202 - val_loss: 5.4496e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0170 - val_loss: 4.8442e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0148 - val_loss: 3.6868e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0132 - val_loss: 2.7495e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0119 - val_loss: 2.9783e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0106 - val_loss: 2.1973e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0096 - val_loss: 1.6305e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0086 - val_loss: 1.4517e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0080 - val_loss: 1.5589e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0071 - val_loss: 1.2884e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0067 - val_loss: 1.3438e-04\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0062 - val_loss: 1.0087e-04\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0056 - val_loss: 9.2701e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0053 - val_loss: 1.3787e-04\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0049 - val_loss: 8.3265e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0044 - val_loss: 8.7683e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0043 - val_loss: 1.0857e-04\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0038 - val_loss: 9.5717e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0036 - val_loss: 9.0384e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0034 - val_loss: 8.7287e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 35us/step - loss: 0.0357 - val_loss: 6.0239e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0089 - val_loss: 3.2213e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0072 - val_loss: 3.5756e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0060 - val_loss: 3.2193e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0051 - val_loss: 3.3718e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0045 - val_loss: 3.2494e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0038 - val_loss: 3.3089e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0034 - val_loss: 3.4763e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0029 - val_loss: 3.2711e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0026 - val_loss: 3.9813e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0024 - val_loss: 4.5517e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0021 - val_loss: 3.6037e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0019 - val_loss: 4.7782e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0018 - val_loss: 4.0890e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0016 - val_loss: 3.4483e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0015 - val_loss: 4.6296e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0013 - val_loss: 3.4033e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0012 - val_loss: 5.0488e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0011 - val_loss: 3.8369e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0011 - val_loss: 4.4174e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.8290e-04 - val_loss: 4.3928e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.2433e-04 - val_loss: 3.7440e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 8.4123e-04 - val_loss: 3.7934e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 8.0036e-04 - val_loss: 4.2621e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 34us/step - loss: 0.0334 - val_loss: 3.2319e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0086 - val_loss: 6.5418e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0064 - val_loss: 4.6291e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0052 - val_loss: 6.2172e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0044 - val_loss: 5.1022e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0037 - val_loss: 4.6829e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0033 - val_loss: 4.6765e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0029 - val_loss: 3.3675e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0026 - val_loss: 3.9807e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0024 - val_loss: 3.8175e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0022 - val_loss: 2.7738e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0020 - val_loss: 3.3365e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0018 - val_loss: 3.6893e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0016 - val_loss: 3.1083e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0015 - val_loss: 2.9057e-04\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0013 - val_loss: 2.0462e-04\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0012 - val_loss: 2.5885e-04\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0011 - val_loss: 2.1128e-04\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.4951e-04 - val_loss: 2.0849e-04\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 8.1849e-04 - val_loss: 1.4220e-04\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 7.2704e-04 - val_loss: 1.3780e-04\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 6.3228e-04 - val_loss: 1.1840e-04\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 5.6168e-04 - val_loss: 1.2478e-04\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 5.0387e-04 - val_loss: 1.1004e-04\n",
      "\n",
      "GENERATION 2\n",
      "\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 34us/step - loss: 0.0080 - val_loss: 3.4614e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0023 - val_loss: 4.9420e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.8548e-04 - val_loss: 4.3745e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 5.4601e-04 - val_loss: 3.1884e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 3.7589e-04 - val_loss: 4.0082e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 2.8163e-04 - val_loss: 3.4926e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 2.3276e-04 - val_loss: 4.8260e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 2.0048e-04 - val_loss: 3.1430e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.7796e-04 - val_loss: 4.4539e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.6205e-04 - val_loss: 3.3511e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.4752e-04 - val_loss: 4.3296e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 1.4074e-04 - val_loss: 3.4136e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.3009e-04 - val_loss: 3.6653e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.2549e-04 - val_loss: 3.1756e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.2122e-04 - val_loss: 3.1675e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.1737e-04 - val_loss: 3.6109e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.1238e-04 - val_loss: 3.2679e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.1022e-04 - val_loss: 3.8567e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.0761e-04 - val_loss: 3.5194e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.0481e-04 - val_loss: 3.5028e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.0364e-04 - val_loss: 3.2730e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.0275e-04 - val_loss: 3.1477e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.0074e-04 - val_loss: 3.3161e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.8528e-05 - val_loss: 3.3458e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 36us/step - loss: 0.0282 - val_loss: 5.0083e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0071 - val_loss: 1.3453e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0038 - val_loss: 5.8707e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0024 - val_loss: 4.9695e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0016 - val_loss: 4.6334e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0012 - val_loss: 6.1191e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 8.9775e-04 - val_loss: 5.0900e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 7.2538e-04 - val_loss: 6.2705e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 6.1039e-04 - val_loss: 7.3862e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 5.1746e-04 - val_loss: 5.4967e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 4.5577e-04 - val_loss: 4.6264e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 3.9858e-04 - val_loss: 3.9344e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 3.5618e-04 - val_loss: 3.6995e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 3.1904e-04 - val_loss: 4.0489e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 2.9057e-04 - val_loss: 3.3446e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 2.7650e-04 - val_loss: 3.2154e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 2.5254e-04 - val_loss: 3.8947e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 2.3090e-04 - val_loss: 3.1786e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 2.1120e-04 - val_loss: 3.2864e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.9968e-04 - val_loss: 3.1249e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.9782e-04 - val_loss: 3.2721e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.8307e-04 - val_loss: 3.2791e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.7876e-04 - val_loss: 3.2604e-05\n",
      "Epoch 24/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.7151e-04 - val_loss: 3.2822e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 33us/step - loss: 0.0404 - val_loss: 0.0013\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0330 - val_loss: 0.0011\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0272 - val_loss: 0.0011\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0234 - val_loss: 8.8141e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0204 - val_loss: 7.3454e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0183 - val_loss: 8.3125e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0161 - val_loss: 6.8192e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0145 - val_loss: 5.5096e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0130 - val_loss: 4.6971e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0119 - val_loss: 4.2585e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0112 - val_loss: 3.9227e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0100 - val_loss: 3.5739e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0096 - val_loss: 3.1881e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0089 - val_loss: 2.8605e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0082 - val_loss: 3.1649e-04\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0077 - val_loss: 2.4361e-04\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0073 - val_loss: 2.5634e-04\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0069 - val_loss: 2.4520e-04\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0065 - val_loss: 2.3459e-04\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0061 - val_loss: 1.9173e-04\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0059 - val_loss: 1.8259e-04\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0056 - val_loss: 2.0410e-04\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0053 - val_loss: 1.6271e-04\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0050 - val_loss: 1.5048e-04\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 37us/step - loss: 0.0284 - val_loss: 1.1879e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0085 - val_loss: 0.0010\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0039 - val_loss: 0.0015\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0023 - val_loss: 1.4842e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0012 - val_loss: 2.2040e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 8.4581e-04 - val_loss: 5.5227e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 5.6628e-04 - val_loss: 2.2832e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 3.7756e-04 - val_loss: 8.6601e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 3.2751e-04 - val_loss: 1.3064e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 2.3063e-04 - val_loss: 4.7201e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 2.6617e-04 - val_loss: 4.2709e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.8210e-04 - val_loss: 4.2508e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 2.0568e-04 - val_loss: 5.7514e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.5466e-04 - val_loss: 4.0595e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.7437e-04 - val_loss: 4.4968e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.5013e-04 - val_loss: 7.6968e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.6367e-04 - val_loss: 6.0460e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.4748e-04 - val_loss: 4.6103e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.3730e-04 - val_loss: 5.2553e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.3724e-04 - val_loss: 4.2515e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.4959e-04 - val_loss: 8.4173e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.3099e-04 - val_loss: 3.5947e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.2378e-04 - val_loss: 5.2487e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.2206e-04 - val_loss: 7.1292e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 44us/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 42us/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 44us/step - loss: 0.2152 - val_loss: 2.8226e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0248 - val_loss: 1.0834e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0136 - val_loss: 3.2269e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0092 - val_loss: 4.7932e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0063 - val_loss: 9.7303e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0044 - val_loss: 8.2135e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0033 - val_loss: 8.1996e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0025 - val_loss: 7.5806e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0019 - val_loss: 1.0647e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0015 - val_loss: 4.7036e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0012 - val_loss: 5.0174e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 9.4597e-04 - val_loss: 5.0633e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 7.5049e-04 - val_loss: 3.6043e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 6.2215e-04 - val_loss: 3.9923e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 5.4888e-04 - val_loss: 4.7196e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 4.5569e-04 - val_loss: 3.6180e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 4.0411e-04 - val_loss: 3.2794e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 3.9132e-04 - val_loss: 3.2850e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 3.3751e-04 - val_loss: 3.4125e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 2.9515e-04 - val_loss: 4.1058e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 2.9152e-04 - val_loss: 3.1811e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 2.6813e-04 - val_loss: 3.6560e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 2.3325e-04 - val_loss: 4.3034e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 2.3034e-04 - val_loss: 3.5571e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 46us/step - loss: 0.0054 - val_loss: 1.5561e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 5.1673e-04 - val_loss: 9.3033e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 2.3522e-04 - val_loss: 4.4326e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 1.5522e-04 - val_loss: 3.7269e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 1.3046e-04 - val_loss: 3.1640e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 1.1552e-04 - val_loss: 3.2182e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 1.0697e-04 - val_loss: 3.4452e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 1.0316e-04 - val_loss: 3.1985e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 9.7957e-05 - val_loss: 3.1500e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 9.5236e-05 - val_loss: 3.1560e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 9.3776e-05 - val_loss: 3.1484e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 9.3810e-05 - val_loss: 3.1916e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 9.2339e-05 - val_loss: 3.1555e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 9.3119e-05 - val_loss: 3.1660e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 9.0871e-05 - val_loss: 3.1526e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 9.1367e-05 - val_loss: 3.1463e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.9313e-05 - val_loss: 3.1463e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 9.1567e-05 - val_loss: 3.1468e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.9305e-05 - val_loss: 3.1651e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.9125e-05 - val_loss: 3.1509e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.9616e-05 - val_loss: 3.1459e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.8706e-05 - val_loss: 3.1454e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.9852e-05 - val_loss: 3.1820e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 9.1773e-05 - val_loss: 3.1516e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 42us/step - loss: 0.0199 - val_loss: 7.9452e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0125 - val_loss: 3.0674e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0090 - val_loss: 1.1746e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0071 - val_loss: 4.3826e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0058 - val_loss: 4.6199e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0049 - val_loss: 8.6896e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0041 - val_loss: 1.7106e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0036 - val_loss: 2.2837e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0031 - val_loss: 2.7857e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0028 - val_loss: 3.0796e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0025 - val_loss: 3.4147e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0023 - val_loss: 3.6560e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0020 - val_loss: 4.1325e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0019 - val_loss: 4.1359e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0017 - val_loss: 4.2953e-04\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0017 - val_loss: 4.4026e-04\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0016 - val_loss: 4.4977e-04\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0015 - val_loss: 4.6514e-04\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0014 - val_loss: 4.7098e-04\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0013 - val_loss: 4.8532e-04\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0012 - val_loss: 5.1961e-04\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0011 - val_loss: 5.2946e-04\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0011 - val_loss: 5.3745e-04\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0011 - val_loss: 5.5003e-04\n",
      "\n",
      "GENERATION 3\n",
      "\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 45us/step - loss: 0.0102 - val_loss: 7.0148e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0030 - val_loss: 4.6102e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0016 - val_loss: 5.6148e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.6667e-04 - val_loss: 3.1533e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 6.4537e-04 - val_loss: 3.0801e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 4.6005e-04 - val_loss: 3.0583e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 3.5864e-04 - val_loss: 3.0644e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 3.0607e-04 - val_loss: 3.4146e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 2.5628e-04 - val_loss: 3.0064e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 2.2956e-04 - val_loss: 2.8823e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 2.1669e-04 - val_loss: 2.8518e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.9644e-04 - val_loss: 3.2379e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.8162e-04 - val_loss: 2.8339e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.7159e-04 - val_loss: 2.7717e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.6108e-04 - val_loss: 2.8665e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.5343e-04 - val_loss: 2.7375e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.4521e-04 - val_loss: 2.7028e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.4077e-04 - val_loss: 2.6840e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.3737e-04 - val_loss: 2.6887e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.3114e-04 - val_loss: 2.5566e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.2375e-04 - val_loss: 2.5498e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.2056e-04 - val_loss: 2.6656e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.1298e-04 - val_loss: 2.6267e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.0857e-04 - val_loss: 2.4149e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 49us/step - loss: 0.0335 - val_loss: 6.5211e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0070 - val_loss: 1.6778e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0031 - val_loss: 1.3266e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0018 - val_loss: 6.3644e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0011 - val_loss: 4.5112e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 7.5917e-04 - val_loss: 6.6725e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 5.2230e-04 - val_loss: 3.7945e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 3.8793e-04 - val_loss: 4.0157e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 2.8805e-04 - val_loss: 3.5179e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 2.2585e-04 - val_loss: 3.2859e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 1.8620e-04 - val_loss: 3.2344e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 1.5887e-04 - val_loss: 3.2047e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 1.3694e-04 - val_loss: 3.1972e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 1.2803e-04 - val_loss: 3.1184e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 1.1755e-04 - val_loss: 3.0919e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 1.1137e-04 - val_loss: 3.0380e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 1.0810e-04 - val_loss: 3.0193e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 1.0524e-04 - val_loss: 2.9976e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 9.9332e-05 - val_loss: 2.9711e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 9.8139e-05 - val_loss: 2.9436e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 9.4567e-05 - val_loss: 2.8111e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.8283e-05 - val_loss: 2.8277e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.7744e-05 - val_loss: 2.6785e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.7169e-05 - val_loss: 2.7269e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 50us/step - loss: 0.1909 - val_loss: 0.0052\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0137 - val_loss: 2.5270e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0088 - val_loss: 1.4123e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0068 - val_loss: 1.8489e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0053 - val_loss: 1.9964e-04\n",
      "Epoch 6/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0043 - val_loss: 1.2881e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0036 - val_loss: 1.0544e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0029 - val_loss: 7.8108e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0024 - val_loss: 9.3191e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0020 - val_loss: 4.8554e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0018 - val_loss: 3.8914e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0015 - val_loss: 6.1223e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0014 - val_loss: 5.3342e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0012 - val_loss: 4.3450e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0012 - val_loss: 4.9590e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0011 - val_loss: 3.1419e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0010 - val_loss: 4.5576e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 9.5732e-04 - val_loss: 3.4994e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 9.0605e-04 - val_loss: 3.2769e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.7733e-04 - val_loss: 4.6228e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 7.8788e-04 - val_loss: 3.5517e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 7.8874e-04 - val_loss: 5.6638e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 7.5975e-04 - val_loss: 3.9254e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 7.3781e-04 - val_loss: 4.6713e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 52us/step - loss: 0.1333 - val_loss: 3.4841e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0309 - val_loss: 3.2610e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0112 - val_loss: 2.1695e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0064 - val_loss: 1.2836e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0045 - val_loss: 1.3345e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0034 - val_loss: 9.3101e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0027 - val_loss: 7.0384e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0022 - val_loss: 1.0021e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0016 - val_loss: 7.1588e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0013 - val_loss: 7.2869e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0011 - val_loss: 6.4207e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 9.3432e-04 - val_loss: 4.1862e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 7.5807e-04 - val_loss: 3.6977e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 7.0628e-04 - val_loss: 3.5911e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 6.1895e-04 - val_loss: 3.5687e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 5.8530e-04 - val_loss: 3.3642e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 5.1744e-04 - val_loss: 3.1631e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 4.4093e-04 - val_loss: 3.2054e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 4.3719e-04 - val_loss: 3.1599e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 4.2353e-04 - val_loss: 3.1617e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 3.9237e-04 - val_loss: 3.1633e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 3.8400e-04 - val_loss: 3.1615e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 3.7904e-04 - val_loss: 3.1579e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 3.5805e-04 - val_loss: 3.1811e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 53us/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 55us/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 54us/step - loss: 0.0233 - val_loss: 4.1920e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0049 - val_loss: 3.9842e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0039 - val_loss: 3.5518e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0031 - val_loss: 3.5733e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0027 - val_loss: 3.2462e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0024 - val_loss: 3.2361e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0021 - val_loss: 3.1315e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0019 - val_loss: 3.3212e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0017 - val_loss: 3.0884e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0016 - val_loss: 3.0641e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0014 - val_loss: 3.0657e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0013 - val_loss: 3.0664e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0013 - val_loss: 3.1134e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0011 - val_loss: 3.5101e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0010 - val_loss: 3.5495e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 9.7290e-04 - val_loss: 3.2516e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 9.1394e-04 - val_loss: 3.1793e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.6325e-04 - val_loss: 3.1030e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 7.9005e-04 - val_loss: 3.1470e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 7.4158e-04 - val_loss: 3.2330e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 6.8909e-04 - val_loss: 3.1445e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 6.6140e-04 - val_loss: 3.3873e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 6.2096e-04 - val_loss: 2.9481e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 5.9215e-04 - val_loss: 3.0765e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 53us/step - loss: 0.0122 - val_loss: 3.2293e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0108 - val_loss: 2.4393e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0096 - val_loss: 1.9342e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0086 - val_loss: 1.6346e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0079 - val_loss: 1.3258e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0072 - val_loss: 1.1156e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0065 - val_loss: 9.9617e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0061 - val_loss: 9.0199e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0057 - val_loss: 7.7240e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0054 - val_loss: 7.1967e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0050 - val_loss: 7.8699e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0048 - val_loss: 6.1326e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0045 - val_loss: 7.5294e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0044 - val_loss: 6.0911e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0043 - val_loss: 5.4904e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0040 - val_loss: 5.1394e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0038 - val_loss: 5.7525e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0037 - val_loss: 5.2616e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0036 - val_loss: 4.9501e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0034 - val_loss: 5.6835e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0033 - val_loss: 5.0248e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0032 - val_loss: 4.9679e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0031 - val_loss: 5.1301e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0031 - val_loss: 4.8778e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 54us/step - loss: 0.0136 - val_loss: 8.5139e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0126 - val_loss: 5.4088e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0112 - val_loss: 3.6698e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0100 - val_loss: 2.6694e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0090 - val_loss: 1.7957e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0083 - val_loss: 1.6611e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0074 - val_loss: 1.3424e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0068 - val_loss: 1.1824e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0062 - val_loss: 1.1084e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0060 - val_loss: 9.9775e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0056 - val_loss: 1.0067e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0054 - val_loss: 9.3133e-05\n",
      "Epoch 13/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0050 - val_loss: 7.2106e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0047 - val_loss: 7.7856e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0046 - val_loss: 6.8070e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0044 - val_loss: 6.5842e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0042 - val_loss: 6.4274e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0040 - val_loss: 5.8995e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0040 - val_loss: 5.7136e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0038 - val_loss: 6.4411e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0036 - val_loss: 5.4263e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0035 - val_loss: 5.3758e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0035 - val_loss: 5.0713e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0033 - val_loss: 5.2135e-05\n",
      "\n",
      "GENERATION 4\n",
      "\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 53us/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 60us/step - loss: 0.0227 - val_loss: 8.1170e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0057 - val_loss: 3.4329e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0032 - val_loss: 3.3166e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0020 - val_loss: 3.2945e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0014 - val_loss: 3.2667e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0010 - val_loss: 3.3215e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.0759e-04 - val_loss: 3.2245e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 6.4876e-04 - val_loss: 3.1648e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 5.3709e-04 - val_loss: 3.0818e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 4.7349e-04 - val_loss: 3.0573e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 4.0074e-04 - val_loss: 3.0969e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 3.5490e-04 - val_loss: 3.1576e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 3.2235e-04 - val_loss: 3.6159e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 2.9163e-04 - val_loss: 3.2653e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 2.7422e-04 - val_loss: 3.0716e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 2.5018e-04 - val_loss: 3.0535e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 2.3699e-04 - val_loss: 3.1482e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 2.2086e-04 - val_loss: 3.0959e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 2.0876e-04 - val_loss: 3.1639e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.9790e-04 - val_loss: 3.1773e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.8798e-04 - val_loss: 3.1937e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.7878e-04 - val_loss: 3.1407e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.7255e-04 - val_loss: 3.0774e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.6264e-04 - val_loss: 3.1164e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 59us/step - loss: 0.0155 - val_loss: 1.1477e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0031 - val_loss: 4.8629e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0015 - val_loss: 4.8321e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 9.5934e-04 - val_loss: 3.9315e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 6.8122e-04 - val_loss: 3.2403e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 5.1392e-04 - val_loss: 3.0772e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 4.1651e-04 - val_loss: 3.0765e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 3.5146e-04 - val_loss: 3.5507e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 3.1071e-04 - val_loss: 2.8698e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 2.5819e-04 - val_loss: 2.8373e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 2.3940e-04 - val_loss: 2.9255e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 2.0867e-04 - val_loss: 2.7961e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 1.9337e-04 - val_loss: 2.7566e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.7693e-04 - val_loss: 2.6992e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 1.6233e-04 - val_loss: 2.7963e-05\n",
      "Epoch 16/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 8us/step - loss: 1.4598e-04 - val_loss: 2.6903e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 1.3398e-04 - val_loss: 2.7351e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 1.2214e-04 - val_loss: 2.5590e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 1.1175e-04 - val_loss: 2.5015e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 1.0492e-04 - val_loss: 2.5263e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 9.9906e-05 - val_loss: 2.4352e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 9.3697e-05 - val_loss: 2.3081e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.4061e-05 - val_loss: 2.4359e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.6099e-05 - val_loss: 2.1637e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 62us/step - loss: 0.7198 - val_loss: 0.0212\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0870 - val_loss: 0.0150\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0598 - val_loss: 0.0142\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0448 - val_loss: 0.0151\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0340 - val_loss: 0.0095\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0272 - val_loss: 0.0092\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0231 - val_loss: 0.0069\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0200 - val_loss: 0.0024\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0169 - val_loss: 0.0027\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0152 - val_loss: 0.0025\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0135 - val_loss: 0.0022\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0123 - val_loss: 0.0016\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0112 - val_loss: 0.0027\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0105 - val_loss: 0.0016\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0096 - val_loss: 0.0016\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0091 - val_loss: 9.1436e-04\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0084 - val_loss: 9.9265e-04\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0080 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0075 - val_loss: 0.0015\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0071 - val_loss: 0.0015\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0068 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0064 - val_loss: 8.0126e-04\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0063 - val_loss: 7.2640e-04\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0059 - val_loss: 7.8042e-04\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 62us/step - loss: 0.3358 - val_loss: 1.3971e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0347 - val_loss: 1.9096e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0232 - val_loss: 9.4890e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0166 - val_loss: 5.7373e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0132 - val_loss: 5.6694e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0105 - val_loss: 1.9216e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0085 - val_loss: 1.8583e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0074 - val_loss: 1.4362e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0064 - val_loss: 2.4316e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0057 - val_loss: 1.4409e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0050 - val_loss: 1.8153e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0045 - val_loss: 1.1234e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0041 - val_loss: 1.1890e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0036 - val_loss: 1.1203e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0033 - val_loss: 1.0044e-04\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0031 - val_loss: 9.4367e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0029 - val_loss: 1.0647e-04\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0028 - val_loss: 9.4415e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0025 - val_loss: 8.8029e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0024 - val_loss: 9.3766e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0022 - val_loss: 9.6981e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0021 - val_loss: 1.0522e-04\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0020 - val_loss: 8.7752e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0019 - val_loss: 9.2805e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 62us/step - loss: 0.9202 - val_loss: 0.0013\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.1108 - val_loss: 5.4704e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0719 - val_loss: 2.4630e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0529 - val_loss: 4.0901e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0431 - val_loss: 1.9232e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0366 - val_loss: 9.5092e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0314 - val_loss: 4.3936e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0265 - val_loss: 1.5450e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0231 - val_loss: 4.1532e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0201 - val_loss: 2.1421e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0181 - val_loss: 2.6940e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0163 - val_loss: 2.7659e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0147 - val_loss: 2.3783e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0139 - val_loss: 3.2389e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0123 - val_loss: 3.2371e-04\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0114 - val_loss: 2.3938e-04\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0106 - val_loss: 2.5457e-04\n",
      "Epoch 18/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0099 - val_loss: 2.7221e-04\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0089 - val_loss: 2.7016e-04\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0087 - val_loss: 3.7977e-04\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0081 - val_loss: 3.3639e-04\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0074 - val_loss: 3.2151e-04\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0070 - val_loss: 2.9660e-04\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0066 - val_loss: 3.0193e-04\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 65us/step - loss: 1.0023 - val_loss: 0.0121\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.1359 - val_loss: 0.0148\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0881 - val_loss: 0.0109\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0658 - val_loss: 0.0047\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0513 - val_loss: 0.0018\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0419 - val_loss: 9.7724e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0353 - val_loss: 0.0016\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0303 - val_loss: 9.0315e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0256 - val_loss: 3.0547e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0236 - val_loss: 4.3838e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0209 - val_loss: 1.9542e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0192 - val_loss: 1.2133e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0175 - val_loss: 1.3493e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0163 - val_loss: 1.8743e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0153 - val_loss: 1.0524e-04\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0142 - val_loss: 1.2327e-04\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0133 - val_loss: 9.8792e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 9.8737e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0117 - val_loss: 1.4627e-04\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0109 - val_loss: 8.0918e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0104 - val_loss: 8.4344e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0101 - val_loss: 6.9869e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0093 - val_loss: 7.5667e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0090 - val_loss: 9.9757e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 65us/step - loss: 0.0092 - val_loss: 4.0954e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 1.8303e-04 - val_loss: 3.8050e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.4206e-04 - val_loss: 3.5193e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.2243e-04 - val_loss: 3.4441e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.1356e-04 - val_loss: 3.4701e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.0759e-04 - val_loss: 3.4013e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.0800e-04 - val_loss: 3.3384e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.0196e-04 - val_loss: 3.4411e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 9.9328e-05 - val_loss: 3.3812e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 9.8729e-05 - val_loss: 3.2907e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 9.5654e-05 - val_loss: 3.2764e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 9.6491e-05 - val_loss: 3.2515e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 9.5307e-05 - val_loss: 3.2526e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 9.4745e-05 - val_loss: 3.2166e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 9.3754e-05 - val_loss: 3.1929e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 9.3214e-05 - val_loss: 3.1929e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 9.2714e-05 - val_loss: 3.1772e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 9.2461e-05 - val_loss: 3.1653e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 9.2499e-05 - val_loss: 3.1597e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 9.0603e-05 - val_loss: 3.1534e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 9.1231e-05 - val_loss: 3.1512e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 9.0904e-05 - val_loss: 3.1511e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.9968e-05 - val_loss: 3.1478e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 9.1619e-05 - val_loss: 3.1483e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 66us/step - loss: 0.0074 - val_loss: 4.8281e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 2.6118e-04 - val_loss: 3.5199e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.5395e-04 - val_loss: 3.2456e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.2811e-04 - val_loss: 3.1769e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.1396e-04 - val_loss: 3.1663e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.1169e-04 - val_loss: 3.1431e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.0635e-04 - val_loss: 3.1444e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.0190e-04 - val_loss: 3.1482e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.0051e-04 - val_loss: 3.1439e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 9.9057e-05 - val_loss: 3.1440e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 9.7836e-05 - val_loss: 3.1445e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 9.8149e-05 - val_loss: 3.1452e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 9.6822e-05 - val_loss: 3.1451e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 9.8414e-05 - val_loss: 3.1468e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 9.5652e-05 - val_loss: 3.1454e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 9.5243e-05 - val_loss: 3.1459e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 9.5692e-05 - val_loss: 3.1475e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 9.4370e-05 - val_loss: 3.1496e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 9.4159e-05 - val_loss: 3.1458e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 9.3783e-05 - val_loss: 3.1469e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 9.4285e-05 - val_loss: 3.1489e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 9.3389e-05 - val_loss: 3.1452e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 9.3251e-05 - val_loss: 3.1486e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 9.2148e-05 - val_loss: 3.1472e-05\n",
      "\n",
      "GENERATION 5\n",
      "\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 68us/step - loss: 0.1070 - val_loss: 0.0011\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0194 - val_loss: 2.2437e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0076 - val_loss: 2.0606e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0041 - val_loss: 1.2038e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0026 - val_loss: 1.0952e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0018 - val_loss: 9.2267e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0013 - val_loss: 7.7323e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0010 - val_loss: 7.1211e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 9.0365e-04 - val_loss: 6.1464e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 7.5875e-04 - val_loss: 6.2969e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 6.8817e-04 - val_loss: 5.2970e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 6.4189e-04 - val_loss: 4.9397e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 5.3852e-04 - val_loss: 4.1312e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 4.9480e-04 - val_loss: 3.5819e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 4.5623e-04 - val_loss: 3.0844e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 4.0419e-04 - val_loss: 2.8345e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 3.7209e-04 - val_loss: 2.9744e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 3.5031e-04 - val_loss: 2.8681e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 3.5419e-04 - val_loss: 2.4531e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 3.1827e-04 - val_loss: 2.1027e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 3.1341e-04 - val_loss: 1.8848e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 3.0038e-04 - val_loss: 1.7570e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 2.7520e-04 - val_loss: 1.8035e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 2.4979e-04 - val_loss: 1.5222e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 2s 72us/step - loss: 0.0133 - val_loss: 2.1758e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0028 - val_loss: 3.3767e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0014 - val_loss: 3.4461e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.1272e-04 - val_loss: 3.1803e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 5.5121e-04 - val_loss: 3.4947e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 3.9610e-04 - val_loss: 3.0823e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 3.2377e-04 - val_loss: 3.1764e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 2.7305e-04 - val_loss: 3.5280e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 2.3117e-04 - val_loss: 3.2098e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - ETA: 0s - loss: 2.1192e-0 - 0s 9us/step - loss: 2.0388e-04 - val_loss: 3.0925e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.8268e-04 - val_loss: 3.1435e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.7214e-04 - val_loss: 3.5545e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.5678e-04 - val_loss: 3.0911e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.4898e-04 - val_loss: 3.2393e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 1.3293e-04 - val_loss: 3.0922e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.2846e-04 - val_loss: 3.1039e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 1.2172e-04 - val_loss: 3.0954e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 1.1017e-04 - val_loss: 3.0427e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.1250e-04 - val_loss: 3.0252e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.0573e-04 - val_loss: 2.9786e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 9.6041e-05 - val_loss: 2.9501e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 9.7770e-05 - val_loss: 3.0335e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 9.4788e-05 - val_loss: 3.0299e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.5810e-05 - val_loss: 2.7059e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 69us/step - loss: 0.0249 - val_loss: 1.8218e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0203 - val_loss: 2.7057e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0174 - val_loss: 3.1904e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0156 - val_loss: 2.5848e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0138 - val_loss: 2.9189e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 2.3394e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0110 - val_loss: 2.4985e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0099 - val_loss: 2.3364e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0090 - val_loss: 1.9414e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0084 - val_loss: 2.3253e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0076 - val_loss: 1.9109e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0069 - val_loss: 2.2719e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0065 - val_loss: 2.0921e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0061 - val_loss: 1.6978e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0057 - val_loss: 1.7726e-04\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0055 - val_loss: 1.3555e-04\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0051 - val_loss: 1.6356e-04\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0048 - val_loss: 1.2024e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0045 - val_loss: 1.2442e-04\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0042 - val_loss: 1.2165e-04\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0040 - val_loss: 1.2184e-04\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0039 - val_loss: 1.0380e-04\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0037 - val_loss: 1.1147e-04\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0035 - val_loss: 1.0111e-04\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 2s 75us/step - loss: 0.0167 - val_loss: 2.0845e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0046 - val_loss: 5.2052e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0025 - val_loss: 4.0287e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0016 - val_loss: 3.3634e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0011 - val_loss: 3.4203e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.0454e-04 - val_loss: 3.1645e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 6.3692e-04 - val_loss: 3.0849e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 5.0956e-04 - val_loss: 3.2454e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 4.2302e-04 - val_loss: 3.0277e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 3.5844e-04 - val_loss: 3.0574e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 3.0714e-04 - val_loss: 2.9785e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 2.6998e-04 - val_loss: 2.9753e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 2.3202e-04 - val_loss: 3.5472e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 2.0761e-04 - val_loss: 2.9294e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 1.8143e-04 - val_loss: 2.9148e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 1.5888e-04 - val_loss: 2.8775e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.5905e-04 - val_loss: 2.8409e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 1.4257e-04 - val_loss: 2.7901e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.3194e-04 - val_loss: 2.7899e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 1.1971e-04 - val_loss: 2.7035e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 1.0565e-04 - val_loss: 2.6265e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 1.0216e-04 - val_loss: 2.6043e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 9.6998e-05 - val_loss: 2.5229e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 9.0731e-05 - val_loss: 2.5182e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 2s 82us/step - loss: 0.0211 - val_loss: 3.7262e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0057 - val_loss: 5.5447e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0030 - val_loss: 2.5838e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0020 - val_loss: 2.3298e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0014 - val_loss: 1.8206e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0010 - val_loss: 1.3504e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 7.7394e-04 - val_loss: 1.0923e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 6.0634e-04 - val_loss: 9.5813e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 5.0068e-04 - val_loss: 6.5572e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 4.1374e-04 - val_loss: 5.2559e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 3.4606e-04 - val_loss: 4.0075e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 3.0434e-04 - val_loss: 3.5008e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 2.7347e-04 - val_loss: 3.3070e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 2.4552e-04 - val_loss: 3.2977e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 2.2491e-04 - val_loss: 3.1517e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 2.0805e-04 - val_loss: 3.1734e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 1.9620e-04 - val_loss: 3.4168e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 1.9258e-04 - val_loss: 3.3228e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 1.8063e-04 - val_loss: 3.2928e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 1.7969e-04 - val_loss: 3.4050e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 1.7285e-04 - val_loss: 3.3688e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 1.7001e-04 - val_loss: 3.4799e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 1.6559e-04 - val_loss: 3.3750e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 1.6447e-04 - val_loss: 3.2391e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 2s 78us/step - loss: 0.0313 - val_loss: 0.0010\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0054 - val_loss: 6.2736e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0038 - val_loss: 1.2425e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0029 - val_loss: 1.0777e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0023 - val_loss: 5.8585e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0018 - val_loss: 5.0003e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0015 - val_loss: 3.3006e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0013 - val_loss: 8.5338e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0011 - val_loss: 4.0864e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 9.2092e-04 - val_loss: 3.4687e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.0536e-04 - val_loss: 3.2883e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 7.0360e-04 - val_loss: 3.4224e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 6.3646e-04 - val_loss: 3.2722e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 5.5544e-04 - val_loss: 3.0856e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 5.1096e-04 - val_loss: 3.1199e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 4.5858e-04 - val_loss: 3.5255e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 4.1671e-04 - val_loss: 3.0710e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 3.7804e-04 - val_loss: 3.2704e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 3.4085e-04 - val_loss: 3.1889e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 3.0746e-04 - val_loss: 3.0191e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 2.8434e-04 - val_loss: 2.9555e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 2.6725e-04 - val_loss: 2.9601e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 2.4881e-04 - val_loss: 2.9142e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 2.2492e-04 - val_loss: 2.8502e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 2s 86us/step - loss: 0.0033 - val_loss: 3.8938e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 7.5603e-04 - val_loss: 3.1546e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 3.2341e-04 - val_loss: 4.3013e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 3.0058e-04 - val_loss: 3.3352e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.6935e-04 - val_loss: 1.3681e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 2.0243e-04 - val_loss: 3.2379e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.6448e-04 - val_loss: 5.7873e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.6789e-04 - val_loss: 3.8271e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.4543e-04 - val_loss: 6.2919e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.3863e-04 - val_loss: 9.3870e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.2420e-04 - val_loss: 4.8744e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.4669e-04 - val_loss: 1.0239e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.1106e-04 - val_loss: 4.5877e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.0967e-04 - val_loss: 4.6234e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.6456e-04 - val_loss: 4.3172e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 9.7476e-05 - val_loss: 3.1460e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.2847e-04 - val_loss: 9.8565e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.0917e-04 - val_loss: 7.5896e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.0368e-04 - val_loss: 3.1583e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.1760e-04 - val_loss: 4.0718e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.1005e-04 - val_loss: 6.7316e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.0806e-04 - val_loss: 3.1470e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.0420e-04 - val_loss: 4.4365e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.2159e-04 - val_loss: 5.3759e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 2s 88us/step - loss: 0.1848 - val_loss: 8.4090e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0165 - val_loss: 4.6620e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0089 - val_loss: 5.6172e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0057 - val_loss: 5.1086e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0041 - val_loss: 3.1503e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0031 - val_loss: 3.5448e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0024 - val_loss: 3.1377e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0019 - val_loss: 3.1803e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0015 - val_loss: 3.1703e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0013 - val_loss: 3.2964e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0011 - val_loss: 3.1475e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.9805e-04 - val_loss: 3.5814e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 7.9070e-04 - val_loss: 3.4141e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 7.5070e-04 - val_loss: 3.5549e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 7.0079e-04 - val_loss: 3.4350e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 6.3064e-04 - val_loss: 3.1714e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 5.8419e-04 - val_loss: 3.3980e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 5.4621e-04 - val_loss: 3.3682e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 5.0284e-04 - val_loss: 3.2023e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 4.7216e-04 - val_loss: 3.3241e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 4.4238e-04 - val_loss: 4.6991e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 4.3818e-04 - val_loss: 3.7749e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 4.1177e-04 - val_loss: 3.3147e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 3.9543e-04 - val_loss: 3.7315e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 2s 82us/step - loss: 0.0743 - val_loss: 5.3901e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0431 - val_loss: 1.2121e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0290 - val_loss: 9.1011e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0229 - val_loss: 1.0695e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0189 - val_loss: 1.5316e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0162 - val_loss: 1.3078e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0143 - val_loss: 1.4566e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0131 - val_loss: 1.9024e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0116 - val_loss: 1.4923e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0108 - val_loss: 1.2918e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0098 - val_loss: 1.4382e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0093 - val_loss: 2.4496e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0087 - val_loss: 1.2386e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0082 - val_loss: 1.0481e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0076 - val_loss: 1.4535e-04\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0072 - val_loss: 1.3720e-04\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0069 - val_loss: 1.7016e-04\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0066 - val_loss: 1.5817e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0063 - val_loss: 8.8980e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0061 - val_loss: 1.2831e-04\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0057 - val_loss: 1.1486e-04\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0054 - val_loss: 8.6150e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0053 - val_loss: 1.2415e-04\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0052 - val_loss: 1.7133e-04\n",
      "\n",
      "GENERATION 6\n",
      "\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 2s 83us/step - loss: 0.0199 - val_loss: 1.0939e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0033 - val_loss: 1.0997e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0015 - val_loss: 9.0077e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.3936e-04 - val_loss: 5.4747e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 4.7394e-04 - val_loss: 3.4483e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 3.1429e-04 - val_loss: 4.0766e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 2.4468e-04 - val_loss: 3.2491e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 2.0642e-04 - val_loss: 3.1826e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 1.8124e-04 - val_loss: 3.0544e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 1.6831e-04 - val_loss: 2.9361e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 1.5064e-04 - val_loss: 3.0022e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 1.3206e-04 - val_loss: 2.8936e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 1.2866e-04 - val_loss: 2.8800e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 1.1815e-04 - val_loss: 2.7736e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 1.1599e-04 - val_loss: 2.7511e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 1.1173e-04 - val_loss: 2.7311e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 1.0273e-04 - val_loss: 2.6977e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 1.0139e-04 - val_loss: 2.6105e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 9.7936e-05 - val_loss: 2.6210e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 9.3260e-05 - val_loss: 2.5488e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 9.1272e-05 - val_loss: 2.5190e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 9.2733e-05 - val_loss: 2.5409e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.9461e-05 - val_loss: 2.4533e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 9.3654e-05 - val_loss: 2.3954e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 2s 87us/step - loss: 0.0292 - val_loss: 9.6788e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0080 - val_loss: 8.0324e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0040 - val_loss: 5.4355e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0024 - val_loss: 8.8410e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0016 - val_loss: 4.7523e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0011 - val_loss: 5.5660e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.6851e-04 - val_loss: 3.7963e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 6.5964e-04 - val_loss: 3.1798e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 5.1374e-04 - val_loss: 2.9858e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 3.9853e-04 - val_loss: 2.8846e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 3.2268e-04 - val_loss: 2.8151e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 2.6765e-04 - val_loss: 2.8873e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 2.1594e-04 - val_loss: 2.6902e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 1.8851e-04 - val_loss: 2.7456e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 1.5341e-04 - val_loss: 2.4788e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 1.3551e-04 - val_loss: 2.4603e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 1.2068e-04 - val_loss: 2.3235e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.1606e-04 - val_loss: 2.1438e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.0300e-04 - val_loss: 2.0116e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 1.0097e-04 - val_loss: 1.9731e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 9.1766e-05 - val_loss: 1.8286e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.7010e-05 - val_loss: 1.6761e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.5785e-05 - val_loss: 1.6184e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.1453e-05 - val_loss: 1.5297e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 2s 85us/step - loss: 0.0396 - val_loss: 1.2976e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0306 - val_loss: 2.4315e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0250 - val_loss: 2.4339e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0201 - val_loss: 3.4022e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0177 - val_loss: 3.1359e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0157 - val_loss: 3.5003e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0136 - val_loss: 4.5147e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0125 - val_loss: 3.7297e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0112 - val_loss: 3.5233e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0104 - val_loss: 4.2076e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0096 - val_loss: 4.6641e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0088 - val_loss: 4.7943e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0084 - val_loss: 5.2489e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0080 - val_loss: 5.3910e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0074 - val_loss: 4.5308e-04\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0070 - val_loss: 4.7394e-04\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0068 - val_loss: 4.6513e-04\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0063 - val_loss: 4.8819e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0061 - val_loss: 4.4020e-04\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0059 - val_loss: 4.3073e-04\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0057 - val_loss: 4.6750e-04\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0055 - val_loss: 4.2962e-04\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0053 - val_loss: 3.6839e-04\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0052 - val_loss: 3.7698e-04\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 2s 88us/step - loss: 0.0618 - val_loss: 4.2345e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0322 - val_loss: 3.5266e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0205 - val_loss: 3.2047e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0151 - val_loss: 3.1129e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 3.4165e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0099 - val_loss: 3.4603e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0086 - val_loss: 2.5475e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0075 - val_loss: 2.8992e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0067 - val_loss: 2.7708e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0059 - val_loss: 2.6073e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0055 - val_loss: 2.1998e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0050 - val_loss: 2.1913e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0045 - val_loss: 2.0544e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0042 - val_loss: 1.7375e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0040 - val_loss: 1.3865e-04\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0037 - val_loss: 1.5601e-04\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0035 - val_loss: 1.5894e-04\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0033 - val_loss: 1.4736e-04\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0031 - val_loss: 1.0514e-04\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0029 - val_loss: 1.2508e-04\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0028 - val_loss: 1.3516e-04\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0027 - val_loss: 1.2096e-04\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0026 - val_loss: 1.0034e-04\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0024 - val_loss: 9.4243e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 2s 87us/step - loss: 0.0481 - val_loss: 5.4233e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0329 - val_loss: 3.2671e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0241 - val_loss: 2.2553e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0186 - val_loss: 2.6961e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0148 - val_loss: 1.4448e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0128 - val_loss: 2.0734e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0112 - val_loss: 1.0708e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0099 - val_loss: 1.0781e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0092 - val_loss: 8.8781e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0085 - val_loss: 9.4020e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0077 - val_loss: 7.8089e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0072 - val_loss: 7.4885e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0068 - val_loss: 8.7544e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0064 - val_loss: 8.3146e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0060 - val_loss: 7.3927e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0057 - val_loss: 7.4769e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0053 - val_loss: 6.3589e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0051 - val_loss: 7.2184e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0050 - val_loss: 7.4184e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0046 - val_loss: 6.2605e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0045 - val_loss: 6.8974e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0043 - val_loss: 7.2139e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0042 - val_loss: 6.3275e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0040 - val_loss: 7.3218e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 2s 89us/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 2s 91us/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: nan - val_loss: nan\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 2s 95us/step - loss: 0.0070 - val_loss: 2.6142e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0018 - val_loss: 8.2120e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 6.9333e-04 - val_loss: 2.2908e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 3.7243e-04 - val_loss: 1.2830e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 2.5058e-04 - val_loss: 1.0545e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.9306e-04 - val_loss: 1.0610e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 1.6891e-04 - val_loss: 7.9224e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 1.5345e-04 - val_loss: 9.8918e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 1.4105e-04 - val_loss: 7.0308e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.3300e-04 - val_loss: 6.8711e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 1.2401e-04 - val_loss: 4.3544e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.2179e-04 - val_loss: 5.3819e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 1.1359e-04 - val_loss: 8.9296e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.1048e-04 - val_loss: 4.7878e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.1154e-04 - val_loss: 5.9900e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 1.0992e-04 - val_loss: 4.3421e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 1.0514e-04 - val_loss: 1.2654e-04\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.0744e-04 - val_loss: 3.3276e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 1.0959e-04 - val_loss: 3.4783e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 1.0794e-04 - val_loss: 6.7006e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.0366e-04 - val_loss: 3.4268e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.0979e-04 - val_loss: 3.3778e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 1.0697e-04 - val_loss: 4.9034e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.0650e-04 - val_loss: 3.4004e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 2s 96us/step - loss: 0.0103 - val_loss: 0.0010\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0030 - val_loss: 2.7419e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0016 - val_loss: 5.1487e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0011 - val_loss: 1.0512e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 7.4508e-04 - val_loss: 1.4525e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 5.8569e-04 - val_loss: 3.2939e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 5.0017e-04 - val_loss: 5.3200e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 4.4377e-04 - val_loss: 4.0306e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 3.8409e-04 - val_loss: 3.3633e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 3.4719e-04 - val_loss: 3.5248e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 3.2482e-04 - val_loss: 2.4339e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 3.0789e-04 - val_loss: 1.9343e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 2.8838e-04 - val_loss: 2.1904e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 2.7307e-04 - val_loss: 1.4814e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 2.5311e-04 - val_loss: 1.7238e-04\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 2.4479e-04 - val_loss: 2.0557e-04\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 2.3342e-04 - val_loss: 1.2015e-04\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 2.2501e-04 - val_loss: 1.4942e-04\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 2.1159e-04 - val_loss: 1.1751e-04\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 2.0490e-04 - val_loss: 1.6132e-04\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 1.9704e-04 - val_loss: 6.5290e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 1.8849e-04 - val_loss: 1.3962e-04\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 1.7759e-04 - val_loss: 1.4826e-04\n",
      "Epoch 24/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 11us/step - loss: 1.7069e-04 - val_loss: 1.5132e-04\n",
      "\n",
      "GENERATION 7\n",
      "\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 2s 95us/step - loss: 0.0209 - val_loss: 9.0014e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0042 - val_loss: 2.5581e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0024 - val_loss: 1.0301e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0016 - val_loss: 6.1916e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0011 - val_loss: 4.9562e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.4904e-04 - val_loss: 3.6236e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 6.6560e-04 - val_loss: 3.7849e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 5.4041e-04 - val_loss: 3.8069e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 4.4990e-04 - val_loss: 3.3268e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 3.7177e-04 - val_loss: 3.1203e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 3.2910e-04 - val_loss: 3.8102e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 2.9320e-04 - val_loss: 3.1157e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 2.5791e-04 - val_loss: 3.0142e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 2.3088e-04 - val_loss: 3.1799e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 2.0398e-04 - val_loss: 2.7753e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 1.9345e-04 - val_loss: 2.6439e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 1.7116e-04 - val_loss: 3.1045e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.5651e-04 - val_loss: 2.7969e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 1.4325e-04 - val_loss: 2.4533e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 1.3441e-04 - val_loss: 2.5982e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 1.3229e-04 - val_loss: 2.3722e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 1.1865e-04 - val_loss: 2.2768e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 1.1077e-04 - val_loss: 2.1854e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 1.0874e-04 - val_loss: 2.0412e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 2s 105us/step - loss: 0.0211 - val_loss: 1.8991e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0038 - val_loss: 6.6940e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0020 - val_loss: 4.2806e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0012 - val_loss: 3.7723e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.4862e-04 - val_loss: 3.3951e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 6.5319e-04 - val_loss: 3.3586e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 5.1336e-04 - val_loss: 3.4619e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 4.1958e-04 - val_loss: 3.1616e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 3.5213e-04 - val_loss: 3.2331e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 3.0449e-04 - val_loss: 3.1452e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 2.6064e-04 - val_loss: 3.0308e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 2.3534e-04 - val_loss: 3.2749e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 2.0608e-04 - val_loss: 2.9980e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 1.8952e-04 - val_loss: 3.0600e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 1.7524e-04 - val_loss: 3.0940e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 1.6415e-04 - val_loss: 3.0389e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 1.4957e-04 - val_loss: 3.0446e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 1.3533e-04 - val_loss: 2.9891e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 1.3114e-04 - val_loss: 2.9684e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 1.2614e-04 - val_loss: 2.9530e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 1.2060e-04 - val_loss: 2.9479e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 1.1326e-04 - val_loss: 2.9499e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 1.1164e-04 - val_loss: 2.9957e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 1.0875e-04 - val_loss: 2.9785e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 2s 100us/step - loss: 0.0380 - val_loss: 1.3493e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0064 - val_loss: 7.8183e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0033 - val_loss: 5.4446e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0023 - val_loss: 4.7484e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0016 - val_loss: 4.0711e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0012 - val_loss: 3.6280e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 9.3753e-04 - val_loss: 3.5553e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 7.2362e-04 - val_loss: 3.2471e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 5.9409e-04 - val_loss: 3.4894e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 4.7672e-04 - val_loss: 3.1590e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 3.9756e-04 - val_loss: 3.1384e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 3.3119e-04 - val_loss: 3.0482e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 2.9851e-04 - val_loss: 3.0706e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 2.5901e-04 - val_loss: 3.1330e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 2.3010e-04 - val_loss: 3.0243e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 2.0733e-04 - val_loss: 3.0410e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 1.8323e-04 - val_loss: 3.0553e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 1.7026e-04 - val_loss: 3.0716e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 1.5993e-04 - val_loss: 2.9926e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 1.4876e-04 - val_loss: 3.0661e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 1.3821e-04 - val_loss: 2.9364e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 1.3134e-04 - val_loss: 2.9276e-05\n",
      "Epoch 23/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 11us/step - loss: 1.2500e-04 - val_loss: 2.9304e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 1.1799e-04 - val_loss: 2.9312e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 2s 99us/step - loss: 0.0683 - val_loss: 9.8000e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0128 - val_loss: 6.2445e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0064 - val_loss: 5.0866e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0039 - val_loss: 5.6020e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0028 - val_loss: 7.4094e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0022 - val_loss: 5.3888e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0017 - val_loss: 4.9054e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0014 - val_loss: 4.6525e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0012 - val_loss: 9.3380e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0011 - val_loss: 4.7088e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 9.1232e-04 - val_loss: 6.5946e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.0668e-04 - val_loss: 5.4356e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 7.3291e-04 - val_loss: 5.8466e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 6.8081e-04 - val_loss: 5.0690e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 5.9658e-04 - val_loss: 4.1118e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 5.4608e-04 - val_loss: 4.4392e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 4.8925e-04 - val_loss: 4.6016e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 4.4807e-04 - val_loss: 4.4295e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 4.0886e-04 - val_loss: 4.3488e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 3.7177e-04 - val_loss: 3.7686e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 3.4232e-04 - val_loss: 3.9050e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 3.1444e-04 - val_loss: 4.2127e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 2.9130e-04 - val_loss: 4.1770e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 2.6372e-04 - val_loss: 3.3790e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 2s 104us/step - loss: 0.1072 - val_loss: 6.7046e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0217 - val_loss: 2.7620e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0135 - val_loss: 1.3842e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0095 - val_loss: 1.4800e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0069 - val_loss: 4.8191e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0053 - val_loss: 3.4648e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0043 - val_loss: 4.1466e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0034 - val_loss: 4.4368e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0027 - val_loss: 4.9541e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0023 - val_loss: 3.2188e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0019 - val_loss: 4.2406e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0016 - val_loss: 3.4161e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0014 - val_loss: 3.1051e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0011 - val_loss: 4.1029e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 9.5122e-04 - val_loss: 3.8651e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.1987e-04 - val_loss: 3.1617e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 7.1560e-04 - val_loss: 3.5656e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 6.2578e-04 - val_loss: 2.9903e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 5.4107e-04 - val_loss: 2.8221e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 4.7724e-04 - val_loss: 2.8404e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 4.1472e-04 - val_loss: 2.8874e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 3.7714e-04 - val_loss: 2.6951e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 3.4102e-04 - val_loss: 2.9103e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 3.1788e-04 - val_loss: 3.0367e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 2s 109us/step - loss: 0.1250 - val_loss: 0.0016\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0237 - val_loss: 3.1954e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0136 - val_loss: 1.9495e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0087 - val_loss: 1.6162e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0061 - val_loss: 1.9404e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0045 - val_loss: 7.4299e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0034 - val_loss: 8.2998e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0027 - val_loss: 7.6415e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0021 - val_loss: 6.5145e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0019 - val_loss: 4.0588e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0016 - val_loss: 5.4011e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0013 - val_loss: 3.2219e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0012 - val_loss: 3.5387e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0011 - val_loss: 4.2756e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 9.9359e-04 - val_loss: 4.0500e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.9779e-04 - val_loss: 3.9006e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.1435e-04 - val_loss: 3.1915e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 7.7740e-04 - val_loss: 3.2008e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 7.1257e-04 - val_loss: 3.4980e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 6.6160e-04 - val_loss: 3.1773e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 6.0595e-04 - val_loss: 3.2153e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 5.6498e-04 - val_loss: 3.1808e-05\n",
      "Epoch 23/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 12us/step - loss: 5.4957e-04 - val_loss: 3.1815e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 5.2757e-04 - val_loss: 3.2191e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 2s 110us/step - loss: 0.1622 - val_loss: 2.0174e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0326 - val_loss: 7.5245e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0164 - val_loss: 3.0996e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0087 - val_loss: 0.0010\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0048 - val_loss: 1.3516e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0028 - val_loss: 8.7654e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0018 - val_loss: 1.6210e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0012 - val_loss: 2.6421e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0012 - val_loss: 6.7288e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 9.6853e-04 - val_loss: 7.2138e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0012 - val_loss: 7.4125e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0030 - val_loss: 0.0025\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 2s 113us/step - loss: 0.0724 - val_loss: 2.5216e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0141 - val_loss: 2.0391e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0112 - val_loss: 6.2915e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0094 - val_loss: 4.7265e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0079 - val_loss: 5.2042e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0070 - val_loss: 5.4029e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0061 - val_loss: 4.5092e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0057 - val_loss: 4.3956e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0051 - val_loss: 4.3051e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0047 - val_loss: 5.8436e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0044 - val_loss: 6.2458e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0040 - val_loss: 4.1001e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0037 - val_loss: 4.7597e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0034 - val_loss: 7.0759e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0032 - val_loss: 4.4192e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0030 - val_loss: 3.7513e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0028 - val_loss: 3.8665e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0026 - val_loss: 4.8174e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0025 - val_loss: 3.2986e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0024 - val_loss: 3.5526e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0022 - val_loss: 4.2240e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0021 - val_loss: 3.1301e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0020 - val_loss: 4.0824e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0019 - val_loss: 3.1222e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 3s 117us/step - loss: 0.0965 - val_loss: 4.1305e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0106 - val_loss: 4.2810e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0076 - val_loss: 6.6406e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0063 - val_loss: 7.9755e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0055 - val_loss: 1.6643e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0048 - val_loss: 1.4128e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0044 - val_loss: 1.2374e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0039 - val_loss: 1.3323e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0036 - val_loss: 9.5081e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0032 - val_loss: 1.1547e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0030 - val_loss: 1.3439e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0028 - val_loss: 8.6366e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0025 - val_loss: 1.4974e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0024 - val_loss: 8.6152e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0022 - val_loss: 9.1474e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0020 - val_loss: 8.7938e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0019 - val_loss: 1.1635e-04\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0018 - val_loss: 8.0810e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0017 - val_loss: 7.0721e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0016 - val_loss: 6.7218e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0014 - val_loss: 6.8885e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0014 - val_loss: 7.5859e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0013 - val_loss: 6.1432e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0013 - val_loss: 5.8010e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GENERATION 8\n",
      "\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 2s 116us/step - loss: 0.0136 - val_loss: 1.1976e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0030 - val_loss: 5.3636e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0019 - val_loss: 3.1770e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0013 - val_loss: 3.7259e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 9.0338e-04 - val_loss: 3.5398e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 6.5580e-04 - val_loss: 3.0849e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 4.9613e-04 - val_loss: 3.0896e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 3.9727e-04 - val_loss: 3.8066e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 3.2200e-04 - val_loss: 3.5570e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 2.7733e-04 - val_loss: 3.2308e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 2.3872e-04 - val_loss: 7.0200e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 2.1965e-04 - val_loss: 3.2071e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.9836e-04 - val_loss: 3.9289e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.7966e-04 - val_loss: 3.9476e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.7313e-04 - val_loss: 4.0762e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.6253e-04 - val_loss: 5.0118e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.5760e-04 - val_loss: 3.6610e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.5021e-04 - val_loss: 4.2723e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.4484e-04 - val_loss: 4.1072e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.4051e-04 - val_loss: 5.2048e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.3897e-04 - val_loss: 4.3104e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.3476e-04 - val_loss: 3.8493e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.2928e-04 - val_loss: 3.9358e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.2918e-04 - val_loss: 4.3688e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 2s 113us/step - loss: 0.0156 - val_loss: 1.4579e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0031 - val_loss: 5.3243e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0015 - val_loss: 4.0123e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8874e-04 - val_loss: 3.5020e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 5.6681e-04 - val_loss: 3.3301e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 4.0772e-04 - val_loss: 3.5111e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 3.1839e-04 - val_loss: 3.3602e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 2.4790e-04 - val_loss: 2.7667e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.9653e-04 - val_loss: 2.8691e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.7133e-04 - val_loss: 2.5272e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.4655e-04 - val_loss: 4.0283e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.4604e-04 - val_loss: 2.5433e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 1.2091e-04 - val_loss: 2.1910e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.1769e-04 - val_loss: 2.0608e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.0853e-04 - val_loss: 2.0138e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.0104e-04 - val_loss: 1.9526e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 9.4202e-05 - val_loss: 1.9017e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 9.5090e-05 - val_loss: 1.8020e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.2739e-05 - val_loss: 1.7642e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 9.2742e-05 - val_loss: 1.6627e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.0079e-05 - val_loss: 1.8475e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 7.7627e-05 - val_loss: 1.5494e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 7.2808e-05 - val_loss: 1.4336e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 7.0678e-05 - val_loss: 1.4401e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 2s 114us/step - loss: 0.0211 - val_loss: 4.3520e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0049 - val_loss: 4.6395e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0023 - val_loss: 4.4058e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0013 - val_loss: 3.7233e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 9.2543e-04 - val_loss: 3.2062e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 6.9788e-04 - val_loss: 3.2003e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 5.7088e-04 - val_loss: 3.3539e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 4.6865e-04 - val_loss: 3.2162e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 3.9989e-04 - val_loss: 3.1497e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 3.4488e-04 - val_loss: 3.2036e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 2.9883e-04 - val_loss: 3.0834e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 2.6874e-04 - val_loss: 3.0084e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 2.3894e-04 - val_loss: 3.0159e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 2.1145e-04 - val_loss: 3.0203e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.8633e-04 - val_loss: 2.9508e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.7168e-04 - val_loss: 2.9541e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.5730e-04 - val_loss: 2.9455e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.4383e-04 - val_loss: 2.8908e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.2353e-04 - val_loss: 2.9432e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.2064e-04 - val_loss: 2.8952e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.1269e-04 - val_loss: 2.8043e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 9.8915e-05 - val_loss: 2.7435e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 9.5695e-05 - val_loss: 2.6695e-05\n",
      "Epoch 24/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 12us/step - loss: 9.3685e-05 - val_loss: 2.6367e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 3s 119us/step - loss: 0.0917 - val_loss: 8.6451e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0132 - val_loss: 1.2947e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0069 - val_loss: 1.4137e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0045 - val_loss: 9.3711e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0032 - val_loss: 6.4408e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0025 - val_loss: 6.1110e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0020 - val_loss: 5.6494e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0016 - val_loss: 6.7112e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0014 - val_loss: 4.8345e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0012 - val_loss: 4.7310e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0010 - val_loss: 4.3527e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.9985e-04 - val_loss: 4.3597e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 7.7243e-04 - val_loss: 3.8671e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 6.9446e-04 - val_loss: 3.9749e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 6.0358e-04 - val_loss: 3.8056e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 5.3576e-04 - val_loss: 3.3813e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 4.8642e-04 - val_loss: 3.2273e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 4.3528e-04 - val_loss: 3.2301e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 3.9246e-04 - val_loss: 3.3705e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 3.5573e-04 - val_loss: 3.3532e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 3.1962e-04 - val_loss: 2.8876e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 2.9808e-04 - val_loss: 2.7648e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 2.7566e-04 - val_loss: 2.6923e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 2.5922e-04 - val_loss: 2.8937e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 3s 118us/step - loss: 0.2275 - val_loss: 1.5545e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0196 - val_loss: 1.5675e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0130 - val_loss: 1.2131e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0096 - val_loss: 8.8887e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0076 - val_loss: 9.2541e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0062 - val_loss: 6.2660e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0052 - val_loss: 5.3415e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0044 - val_loss: 5.3484e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0038 - val_loss: 5.2527e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0033 - val_loss: 5.1635e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0030 - val_loss: 5.4125e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0028 - val_loss: 4.8838e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0024 - val_loss: 4.7855e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0022 - val_loss: 5.2297e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0020 - val_loss: 5.6037e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0018 - val_loss: 4.7443e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0017 - val_loss: 4.9499e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0016 - val_loss: 4.8358e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0014 - val_loss: 4.5252e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0014 - val_loss: 4.6031e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0013 - val_loss: 4.4633e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0012 - val_loss: 4.6877e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0011 - val_loss: 4.3705e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0011 - val_loss: 4.3050e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 3s 125us/step - loss: 0.7496 - val_loss: 0.0045\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.1156 - val_loss: 0.0077\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0750 - val_loss: 0.0025\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0525 - val_loss: 5.0173e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0385 - val_loss: 1.5727e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0292 - val_loss: 3.9982e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0240 - val_loss: 8.8777e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0198 - val_loss: 9.6052e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0168 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0147 - val_loss: 9.4897e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0127 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0115 - val_loss: 9.3523e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0101 - val_loss: 8.9744e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0094 - val_loss: 8.7273e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0086 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0078 - val_loss: 8.8814e-04\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0070 - val_loss: 6.4456e-04\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0067 - val_loss: 7.1304e-04\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0061 - val_loss: 6.7787e-04\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0057 - val_loss: 7.0035e-04\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0053 - val_loss: 6.0081e-04\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0052 - val_loss: 5.9822e-04\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0047 - val_loss: 5.8149e-04\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0044 - val_loss: 5.6427e-04\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 3s 121us/step - loss: 1.4095 - val_loss: 0.0068\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.1427 - val_loss: 0.0032\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.1024 - val_loss: 0.0015\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0801 - val_loss: 0.0019\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0640 - val_loss: 0.0012\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0544 - val_loss: 0.0010\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0462 - val_loss: 3.0962e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0402 - val_loss: 4.8853e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0357 - val_loss: 8.6159e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0317 - val_loss: 8.0747e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0283 - val_loss: 0.0015\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0260 - val_loss: 0.0015\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0238 - val_loss: 0.0015\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0219 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0200 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0189 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0172 - val_loss: 0.0014\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0162 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0152 - val_loss: 8.0406e-04\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0141 - val_loss: 0.0010\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0133 - val_loss: 8.8135e-04\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0126 - val_loss: 7.8160e-04\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0120 - val_loss: 8.4424e-04\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0115 - val_loss: 8.0191e-04\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 3s 121us/step - loss: 0.8759 - val_loss: 2.4668e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0938 - val_loss: 0.0020\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0593 - val_loss: 3.7695e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0451 - val_loss: 0.0029\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0353 - val_loss: 6.2618e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0287 - val_loss: 7.0078e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0251 - val_loss: 0.0013\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0218 - val_loss: 9.9194e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0199 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0179 - val_loss: 0.0026\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0163 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0152 - val_loss: 0.0024\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0141 - val_loss: 0.0027\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0130 - val_loss: 0.0049\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0123 - val_loss: 0.0027\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0114 - val_loss: 0.0028\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0110 - val_loss: 0.0032\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0103 - val_loss: 0.0022\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0100 - val_loss: 0.0026\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0091 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0088 - val_loss: 0.0023\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0084 - val_loss: 0.0020\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0081 - val_loss: 0.0024\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0078 - val_loss: 0.0022\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 3s 127us/step - loss: 0.6896 - val_loss: 0.0032\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0768 - val_loss: 6.9334e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0462 - val_loss: 0.0014\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0298 - val_loss: 7.3626e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0218 - val_loss: 4.1566e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0164 - val_loss: 4.0920e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0131 - val_loss: 2.4507e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0105 - val_loss: 5.5111e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0088 - val_loss: 2.4139e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0074 - val_loss: 2.7397e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0063 - val_loss: 1.9394e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0057 - val_loss: 1.8691e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0050 - val_loss: 1.6236e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0045 - val_loss: 1.5973e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0039 - val_loss: 1.5045e-04\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0037 - val_loss: 1.4388e-04\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0034 - val_loss: 1.5403e-04\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0031 - val_loss: 1.8327e-04\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0030 - val_loss: 1.4627e-04\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0027 - val_loss: 1.7479e-04\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0026 - val_loss: 1.1980e-04\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0025 - val_loss: 1.5586e-04\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0023 - val_loss: 1.5682e-04\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0022 - val_loss: 1.4116e-04\n",
      "\n",
      "GENERATION 9\n",
      "\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 3s 130us/step - loss: 0.3051 - val_loss: 0.0119\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0464 - val_loss: 0.0045\n",
      "Epoch 3/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0205 - val_loss: 0.0015\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0127 - val_loss: 6.1240e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0088 - val_loss: 9.1769e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0063 - val_loss: 4.5084e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0048 - val_loss: 1.4085e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0037 - val_loss: 1.3522e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0030 - val_loss: 7.1978e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0024 - val_loss: 7.5727e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0020 - val_loss: 7.6219e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0017 - val_loss: 1.3653e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0015 - val_loss: 1.4109e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0012 - val_loss: 2.1174e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0011 - val_loss: 1.7393e-04\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 9.5468e-04 - val_loss: 2.0168e-04\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.6850e-04 - val_loss: 1.9370e-04\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 7.5481e-04 - val_loss: 1.9099e-04\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 6.9909e-04 - val_loss: 1.8671e-04\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 6.4709e-04 - val_loss: 1.3310e-04\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 5.7506e-04 - val_loss: 1.2565e-04\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 5.3529e-04 - val_loss: 1.2239e-04\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 4.8813e-04 - val_loss: 1.0226e-04\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 4.5447e-04 - val_loss: 1.0671e-04\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 3s 130us/step - loss: 0.0274 - val_loss: 1.7013e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0065 - val_loss: 5.4232e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0031 - val_loss: 6.0502e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0019 - val_loss: 3.8822e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0013 - val_loss: 3.7564e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 9.5995e-04 - val_loss: 5.0118e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 7.1352e-04 - val_loss: 4.8357e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 5.7963e-04 - val_loss: 3.2444e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 4.8092e-04 - val_loss: 3.0540e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 4.0376e-04 - val_loss: 2.9418e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 3.5517e-04 - val_loss: 2.9518e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 3.1013e-04 - val_loss: 2.8845e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 2.7697e-04 - val_loss: 2.8677e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 2.4145e-04 - val_loss: 2.8865e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 2.2009e-04 - val_loss: 2.9309e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 2.0675e-04 - val_loss: 2.9265e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.9617e-04 - val_loss: 2.6883e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.7667e-04 - val_loss: 2.6722e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.6259e-04 - val_loss: 2.7950e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.5061e-04 - val_loss: 2.6489e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.4436e-04 - val_loss: 2.6095e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.3488e-04 - val_loss: 2.5872e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.3060e-04 - val_loss: 2.6092e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.2582e-04 - val_loss: 2.5733e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 3s 128us/step - loss: 0.0164 - val_loss: 3.8737e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 6.4672e-04 - val_loss: 2.8383e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 2.7003e-04 - val_loss: 1.7872e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.8527e-04 - val_loss: 1.2419e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.4980e-04 - val_loss: 9.7801e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.2679e-04 - val_loss: 7.6324e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.1258e-04 - val_loss: 6.2171e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.0578e-04 - val_loss: 4.4832e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.0203e-04 - val_loss: 3.7283e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 9.8417e-05 - val_loss: 3.3313e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 9.4510e-05 - val_loss: 3.2257e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 9.4464e-05 - val_loss: 3.2280e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 9.3138e-05 - val_loss: 3.2174e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 9.1986e-05 - val_loss: 3.1931e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 9.1820e-05 - val_loss: 3.2300e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 9.3883e-05 - val_loss: 3.1844e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 9.0251e-05 - val_loss: 3.1729e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 9.0762e-05 - val_loss: 3.1872e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.9812e-05 - val_loss: 3.1861e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 9.0274e-05 - val_loss: 3.1933e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.9470e-05 - val_loss: 3.1909e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.9069e-05 - val_loss: 3.1648e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8811e-05 - val_loss: 3.1542e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.9174e-05 - val_loss: 3.1702e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 3s 129us/step - loss: 0.0078 - val_loss: 4.1186e-05\n",
      "Epoch 2/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 12us/step - loss: 3.0145e-04 - val_loss: 3.7957e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.1335e-04 - val_loss: 3.2373e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 9.2595e-05 - val_loss: 3.6870e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.9497e-05 - val_loss: 3.1849e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.9439e-05 - val_loss: 3.1937e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8608e-05 - val_loss: 3.1888e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8563e-05 - val_loss: 3.1555e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8639e-05 - val_loss: 3.2173e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.9037e-05 - val_loss: 3.1567e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8624e-05 - val_loss: 3.1510e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8303e-05 - val_loss: 3.1508e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8473e-05 - val_loss: 3.1458e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8475e-05 - val_loss: 3.1485e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8454e-05 - val_loss: 3.1811e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8431e-05 - val_loss: 3.1546e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8448e-05 - val_loss: 3.3060e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8597e-05 - val_loss: 3.1470e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8419e-05 - val_loss: 3.1615e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8391e-05 - val_loss: 3.1493e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8489e-05 - val_loss: 3.2306e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8505e-05 - val_loss: 3.1573e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8625e-05 - val_loss: 3.1560e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8430e-05 - val_loss: 3.2859e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 3s 131us/step - loss: 0.0046 - val_loss: 1.2597e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.5263e-04 - val_loss: 3.2516e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 9.2132e-05 - val_loss: 3.1539e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.9065e-05 - val_loss: 3.1599e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.9063e-05 - val_loss: 3.1381e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8433e-05 - val_loss: 3.2127e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8393e-05 - val_loss: 3.1497e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8477e-05 - val_loss: 3.2002e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8114e-05 - val_loss: 3.1646e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.9065e-05 - val_loss: 3.1430e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8353e-05 - val_loss: 3.1434e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8258e-05 - val_loss: 3.8101e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8309e-05 - val_loss: 3.1634e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8217e-05 - val_loss: 3.1413e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8230e-05 - val_loss: 3.1618e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8135e-05 - val_loss: 3.1433e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8221e-05 - val_loss: 3.1450e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8140e-05 - val_loss: 3.1474e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8118e-05 - val_loss: 3.1489e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8149e-05 - val_loss: 3.1461e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8185e-05 - val_loss: 3.1452e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8085e-05 - val_loss: 3.1651e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8185e-05 - val_loss: 3.2242e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8271e-05 - val_loss: 3.1462e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 3s 131us/step - loss: 0.1816 - val_loss: 2.9018e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0146 - val_loss: 3.0524e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0033 - val_loss: 4.5151e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0013 - val_loss: 6.2512e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 7.1006e-04 - val_loss: 2.7937e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 4.1507e-04 - val_loss: 2.4536e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 2.7308e-04 - val_loss: 1.9231e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 2.0283e-04 - val_loss: 1.3235e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.7244e-04 - val_loss: 8.8934e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.5547e-04 - val_loss: 1.1483e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.5419e-04 - val_loss: 8.5689e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.5080e-04 - val_loss: 1.0283e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.5427e-04 - val_loss: 1.0713e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.4552e-04 - val_loss: 1.4771e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.5643e-04 - val_loss: 9.5826e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.5258e-04 - val_loss: 1.1423e-04\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.4874e-04 - val_loss: 1.0271e-04\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.5205e-04 - val_loss: 7.5329e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.5383e-04 - val_loss: 9.7919e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.5224e-04 - val_loss: 1.0803e-04\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.5207e-04 - val_loss: 5.1767e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.4985e-04 - val_loss: 8.0451e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.5282e-04 - val_loss: 7.7354e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.5192e-04 - val_loss: 6.7114e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 3s 134us/step - loss: 0.2140 - val_loss: 2.7108e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0215 - val_loss: 3.2155e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0050 - val_loss: 1.4913e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0020 - val_loss: 1.0832e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0010 - val_loss: 3.9110e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 6.5937e-04 - val_loss: 5.5906e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 4.7480e-04 - val_loss: 1.9236e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 3.5543e-04 - val_loss: 2.8019e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 2.9962e-04 - val_loss: 2.0061e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 2.5252e-04 - val_loss: 1.4939e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 2.2755e-04 - val_loss: 1.5184e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 2.0092e-04 - val_loss: 1.3067e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.7922e-04 - val_loss: 9.2284e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.7335e-04 - val_loss: 7.2830e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.5883e-04 - val_loss: 8.4131e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.5307e-04 - val_loss: 8.6306e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.5087e-04 - val_loss: 6.1047e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.4719e-04 - val_loss: 8.5570e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.4715e-04 - val_loss: 9.3224e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.4896e-04 - val_loss: 7.5093e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.4684e-04 - val_loss: 9.3038e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.4748e-04 - val_loss: 6.1967e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.4558e-04 - val_loss: 7.2995e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.4639e-04 - val_loss: 8.6214e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 3s 138us/step - loss: 0.0125 - val_loss: 1.3428e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0024 - val_loss: 1.1177e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 7.4751e-04 - val_loss: 4.6894e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 4.1944e-04 - val_loss: 6.8090e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 3.0995e-04 - val_loss: 1.9991e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 2.5693e-04 - val_loss: 1.2794e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 2.2923e-04 - val_loss: 1.1776e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 2.1362e-04 - val_loss: 8.2410e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.9691e-04 - val_loss: 8.5488e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.7845e-04 - val_loss: 1.2042e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.7640e-04 - val_loss: 1.2707e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.6304e-04 - val_loss: 1.2976e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.5577e-04 - val_loss: 9.2593e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.4857e-04 - val_loss: 8.8935e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.4673e-04 - val_loss: 8.3052e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.3437e-04 - val_loss: 8.9032e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.3149e-04 - val_loss: 8.5563e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.2268e-04 - val_loss: 6.7931e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.2004e-04 - val_loss: 8.3617e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.1835e-04 - val_loss: 4.0551e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.1529e-04 - val_loss: 3.6018e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.1152e-04 - val_loss: 6.2684e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.1548e-04 - val_loss: 4.5281e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.1171e-04 - val_loss: 7.5311e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 3s 137us/step - loss: 0.0218 - val_loss: 3.1474e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0087 - val_loss: 3.2328e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0085 - val_loss: 3.1549e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0082 - val_loss: 3.1721e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0079 - val_loss: 3.1671e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0077 - val_loss: 3.2803e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0076 - val_loss: 3.6335e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0073 - val_loss: 3.3306e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0071 - val_loss: 3.1952e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0070 - val_loss: 3.2241e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0066 - val_loss: 3.1685e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0065 - val_loss: 3.1810e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0064 - val_loss: 3.2716e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0063 - val_loss: 3.4736e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0061 - val_loss: 3.1938e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0059 - val_loss: 3.3230e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0057 - val_loss: 3.1483e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0056 - val_loss: 3.1657e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0055 - val_loss: 3.1657e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0053 - val_loss: 3.1569e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0052 - val_loss: 3.5606e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0051 - val_loss: 3.1806e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0051 - val_loss: 3.3034e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0049 - val_loss: 3.1485e-05\n",
      "\n",
      "GENERATION 10\n",
      "\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 3s 138us/step - loss: 0.0055 - val_loss: 1.5765e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 5.3253e-04 - val_loss: 6.1325e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 2.9074e-04 - val_loss: 3.4831e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 2.1199e-04 - val_loss: 3.3709e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.6322e-04 - val_loss: 3.1699e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.3237e-04 - val_loss: 3.1098e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.1617e-04 - val_loss: 3.1985e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.0636e-04 - val_loss: 3.2158e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.0387e-04 - val_loss: 3.1519e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.0018e-04 - val_loss: 3.1725e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 9.8184e-05 - val_loss: 3.1634e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 9.7043e-05 - val_loss: 3.1556e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 9.7114e-05 - val_loss: 3.1629e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 9.5251e-05 - val_loss: 3.1606e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 9.5049e-05 - val_loss: 3.1536e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 9.2536e-05 - val_loss: 3.1394e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 9.3768e-05 - val_loss: 3.1353e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 9.3045e-05 - val_loss: 3.1376e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 9.2882e-05 - val_loss: 3.1368e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 9.0242e-05 - val_loss: 3.1453e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 9.1794e-05 - val_loss: 3.1390e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 9.1453e-05 - val_loss: 3.1396e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - ETA: 0s - loss: 1.0243e-0 - 0s 13us/step - loss: 9.1652e-05 - val_loss: 3.1474e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 9.0593e-05 - val_loss: 3.1430e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 3s 140us/step - loss: 0.0132 - val_loss: 9.1183e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 4.8515e-04 - val_loss: 3.1590e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.0933e-04 - val_loss: 3.1640e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 9.1685e-05 - val_loss: 3.1693e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.9203e-05 - val_loss: 3.1517e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 9.1305e-05 - val_loss: 3.1782e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.9026e-05 - val_loss: 3.2407e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.9108e-05 - val_loss: 3.1790e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.9025e-05 - val_loss: 3.2069e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.9207e-05 - val_loss: 3.2315e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8746e-05 - val_loss: 3.1512e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8738e-05 - val_loss: 3.5983e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8805e-05 - val_loss: 3.2286e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8981e-05 - val_loss: 3.2734e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8874e-05 - val_loss: 3.1740e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.8932e-05 - val_loss: 3.1457e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.8632e-05 - val_loss: 3.7450e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8617e-05 - val_loss: 3.2594e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.8641e-05 - val_loss: 3.1544e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.8813e-05 - val_loss: 3.2770e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.8688e-05 - val_loss: 3.1915e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.8805e-05 - val_loss: 4.0563e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.8602e-05 - val_loss: 3.2493e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.8961e-05 - val_loss: 3.1465e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 3s 140us/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: nan - val_loss: nan\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 3s 154us/step - loss: 0.3620 - val_loss: 0.0027\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0781 - val_loss: 1.7990e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0435 - val_loss: 3.8887e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0277 - val_loss: 4.8188e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0204 - val_loss: 4.5207e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0156 - val_loss: 4.7968e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0121 - val_loss: 3.8421e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0098 - val_loss: 3.6407e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0079 - val_loss: 3.1916e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0066 - val_loss: 4.4041e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0056 - val_loss: 3.9528e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0050 - val_loss: 4.1359e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0041 - val_loss: 4.2619e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0037 - val_loss: 5.3979e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0031 - val_loss: 5.0857e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0028 - val_loss: 6.9078e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0024 - val_loss: 7.7775e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0022 - val_loss: 7.5874e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0020 - val_loss: 1.0748e-04\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0019 - val_loss: 9.3120e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0017 - val_loss: 1.1646e-04\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0015 - val_loss: 9.2513e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0014 - val_loss: 8.5608e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0013 - val_loss: 9.6347e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 3s 148us/step - loss: 1.0405 - val_loss: 0.0434\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0654 - val_loss: 6.6786e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0443 - val_loss: 4.6838e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0343 - val_loss: 4.1395e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0269 - val_loss: 5.6825e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0216 - val_loss: 4.6364e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0177 - val_loss: 6.5488e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0141 - val_loss: 3.5794e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0119 - val_loss: 7.7990e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0097 - val_loss: 3.4116e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0082 - val_loss: 3.3999e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0071 - val_loss: 3.3935e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0059 - val_loss: 4.0786e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0053 - val_loss: 4.1526e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0046 - val_loss: 4.2212e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0042 - val_loss: 4.1970e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0039 - val_loss: 4.4264e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0035 - val_loss: 3.3607e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0033 - val_loss: 3.8866e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0030 - val_loss: 4.1288e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0029 - val_loss: 3.5653e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0026 - val_loss: 4.2912e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0025 - val_loss: 4.3151e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0023 - val_loss: 3.5690e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 3s 149us/step - loss: 0.2239 - val_loss: 7.7859e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0227 - val_loss: 7.1002e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0128 - val_loss: 3.9756e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0087 - val_loss: 3.5505e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0062 - val_loss: 2.8016e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0047 - val_loss: 2.7131e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0036 - val_loss: 1.9832e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0029 - val_loss: 1.8410e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0023 - val_loss: 1.3638e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0019 - val_loss: 1.5950e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0016 - val_loss: 1.0518e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0013 - val_loss: 8.9878e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0012 - val_loss: 5.7158e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 9.8390e-04 - val_loss: 4.8510e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.5966e-04 - val_loss: 5.6659e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 7.7456e-04 - val_loss: 4.6302e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 6.9043e-04 - val_loss: 5.2577e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 6.1048e-04 - val_loss: 4.5897e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 5.4038e-04 - val_loss: 3.6040e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 5.0787e-04 - val_loss: 3.7993e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 4.7382e-04 - val_loss: 3.9536e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 4.2777e-04 - val_loss: 3.4917e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 4.0562e-04 - val_loss: 3.3405e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 3.7269e-04 - val_loss: 3.1676e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 3s 156us/step - loss: 0.1150 - val_loss: 3.7321e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0199 - val_loss: 2.3377e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0084 - val_loss: 2.3637e-04\n",
      "Epoch 4/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0037 - val_loss: 1.7463e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0017 - val_loss: 1.1890e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0010 - val_loss: 7.6062e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 5.6262e-04 - val_loss: 1.8790e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 5.7610e-04 - val_loss: 9.2253e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 4.5861e-04 - val_loss: 1.3677e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 4.8813e-04 - val_loss: 2.7278e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 5.4541e-04 - val_loss: 2.6170e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 3.6773e-04 - val_loss: 2.6003e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 4.6532e-04 - val_loss: 3.8585e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 5.2577e-04 - val_loss: 5.1293e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 7.3175e-04 - val_loss: 5.5948e-04\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 7.5716e-04 - val_loss: 4.1481e-04\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 7.9917e-04 - val_loss: 8.5773e-04\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 9.6723e-04 - val_loss: 7.9970e-04\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 9.5461e-04 - val_loss: 8.7327e-04\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.7753e-04 - val_loss: 7.9565e-04\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 9.8807e-04 - val_loss: 9.4464e-04\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 3s 157us/step - loss: 0.2752 - val_loss: 3.1548e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0559 - val_loss: 3.5260e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0230 - val_loss: 3.9825e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0097 - val_loss: 5.5728e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0042 - val_loss: 9.7721e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0019 - val_loss: 3.3995e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0011 - val_loss: 2.3849e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 7.2926e-04 - val_loss: 2.6148e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 6.7297e-04 - val_loss: 1.7268e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 3.5681e-04 - val_loss: 8.6816e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 4.1029e-04 - val_loss: 5.9812e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 5.5081e-04 - val_loss: 4.4092e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 4.0551e-04 - val_loss: 2.2400e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 4.4022e-04 - val_loss: 2.9783e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 5.1404e-04 - val_loss: 4.5631e-04\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 6.1677e-04 - val_loss: 5.7785e-04\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 5.6336e-04 - val_loss: 4.4184e-04\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 6.9760e-04 - val_loss: 4.9224e-04\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 6.0974e-04 - val_loss: 4.4723e-04\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 6.8291e-04 - val_loss: 7.6904e-04\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.5196e-04 - val_loss: 7.9731e-04\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 7.6288e-04 - val_loss: 4.9808e-04\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 7.7884e-04 - val_loss: 8.1262e-04\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 7.6875e-04 - val_loss: 8.4451e-04\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 3s 158us/step - loss: 0.1253 - val_loss: 5.1069e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0220 - val_loss: 4.4781e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0088 - val_loss: 2.5476e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0036 - val_loss: 1.9842e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0018 - val_loss: 8.9666e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 9.4017e-04 - val_loss: 9.1787e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0010 - val_loss: 4.3847e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 6.4386e-04 - val_loss: 5.7968e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 4.7531e-04 - val_loss: 4.1846e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.9916e-04 - val_loss: 7.5180e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 5.8619e-04 - val_loss: 3.0131e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 7.4343e-04 - val_loss: 4.3684e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 7.1031e-04 - val_loss: 5.0022e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 9.1710e-04 - val_loss: 8.6119e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 9.5425e-04 - val_loss: 7.7373e-04\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0010 - val_loss: 9.3893e-04\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0012 - val_loss: 9.8948e-04\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "\n",
      "GENERATION 11\n",
      "\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 3s 156us/step - loss: 0.0186 - val_loss: 0.0017\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0040 - val_loss: 6.7569e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0019 - val_loss: 1.9235e-04\n",
      "Epoch 4/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 14us/step - loss: 7.9600e-04 - val_loss: 2.6989e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 9.4101e-04 - val_loss: 3.1604e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 4.5314e-04 - val_loss: 3.9040e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 3.8900e-04 - val_loss: 6.3023e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 5.8739e-04 - val_loss: 4.9422e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 3.9678e-04 - val_loss: 6.6012e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 4.9629e-04 - val_loss: 3.1497e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 3.0825e-04 - val_loss: 2.2875e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 3.0279e-04 - val_loss: 0.0010\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 4.9065e-04 - val_loss: 4.3962e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 2.3735e-04 - val_loss: 5.3131e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 2.3608e-04 - val_loss: 1.4216e-04\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 2.5131e-04 - val_loss: 3.1793e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 2.5420e-04 - val_loss: 3.1820e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 2.0621e-04 - val_loss: 3.9276e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 2.1763e-04 - val_loss: 4.1612e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 2.3927e-04 - val_loss: 4.6220e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 2.5533e-04 - val_loss: 3.8939e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 2.1800e-04 - val_loss: 3.3961e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.7810e-04 - val_loss: 3.2938e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.9922e-04 - val_loss: 3.1767e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 3s 154us/step - loss: 0.0237 - val_loss: 0.0046\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0054 - val_loss: 5.7622e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0016 - val_loss: 2.4597e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 7.3729e-04 - val_loss: 3.7042e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.8372e-04 - val_loss: 3.4376e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 4.5094e-04 - val_loss: 1.7946e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 2.2183e-04 - val_loss: 3.3424e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 3.3545e-04 - val_loss: 3.2585e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.4814e-04 - val_loss: 1.9880e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 2.9284e-04 - val_loss: 3.5809e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 2.1583e-04 - val_loss: 3.2982e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.9735e-04 - val_loss: 3.2045e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 2.1807e-04 - val_loss: 3.1996e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.8989e-04 - val_loss: 3.2952e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 2.0452e-04 - val_loss: 3.3877e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.6617e-04 - val_loss: 1.5871e-04\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.7521e-04 - val_loss: 3.2202e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 2.1629e-04 - val_loss: 3.2250e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.6707e-04 - val_loss: 3.5670e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.2364e-04 - val_loss: 3.1606e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.6482e-04 - val_loss: 4.7238e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.8252e-04 - val_loss: 0.0013\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.6634e-04 - val_loss: 3.1540e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.5686e-04 - val_loss: 3.1529e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 3s 157us/step - loss: 0.0157 - val_loss: 6.0668e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0028 - val_loss: 1.0799e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 7.5976e-04 - val_loss: 2.3245e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 3.3144e-04 - val_loss: 4.1256e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.6990e-04 - val_loss: 3.6588e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.6013e-04 - val_loss: 4.7939e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 2.1373e-04 - val_loss: 9.3838e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 2.1192e-04 - val_loss: 3.1669e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.0682e-04 - val_loss: 1.7887e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.2330e-04 - val_loss: 3.2868e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.5504e-04 - val_loss: 3.6387e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.5427e-04 - val_loss: 7.6141e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.4461e-04 - val_loss: 3.2541e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.2377e-04 - val_loss: 3.3120e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.2178e-04 - val_loss: 3.0926e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.2602e-04 - val_loss: 3.3844e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.1993e-04 - val_loss: 6.5025e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.0081e-04 - val_loss: 3.0481e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.1215e-04 - val_loss: 4.4470e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.2017e-04 - val_loss: 4.0772e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.2312e-04 - val_loss: 7.9803e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.0976e-04 - val_loss: 3.0202e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.0221e-04 - val_loss: 5.1530e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.1366e-04 - val_loss: 3.1489e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 3s 157us/step - loss: 0.0196 - val_loss: 2.0235e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0032 - val_loss: 9.6196e-04\n",
      "Epoch 3/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0011 - val_loss: 3.0755e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 3.5738e-04 - val_loss: 3.3440e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 2.9187e-04 - val_loss: 2.3504e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 3.0379e-04 - val_loss: 0.0026\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 2.2351e-04 - val_loss: 2.2941e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 2.0115e-04 - val_loss: 3.6193e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 2.2835e-04 - val_loss: 6.3789e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.6763e-04 - val_loss: 3.2115e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 2.4754e-04 - val_loss: 3.0870e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.7944e-04 - val_loss: 3.1687e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.5648e-04 - val_loss: 3.1437e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.8117e-04 - val_loss: 0.0010\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.6661e-04 - val_loss: 2.1907e-04\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.7729e-04 - val_loss: 4.5671e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.7480e-04 - val_loss: 3.3196e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.5229e-04 - val_loss: 3.1576e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.7566e-04 - val_loss: 3.2278e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.3945e-04 - val_loss: 3.0876e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.6707e-04 - val_loss: 3.0488e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.3805e-04 - val_loss: 2.9942e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.4415e-04 - val_loss: 3.5342e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.4542e-04 - val_loss: 4.3943e-04\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 3s 159us/step - loss: 0.0193 - val_loss: 7.9125e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0044 - val_loss: 5.1277e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0015 - val_loss: 1.9726e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 5.9439e-04 - val_loss: 9.2309e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 6.6258e-04 - val_loss: 2.2926e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 3.2190e-04 - val_loss: 3.7868e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 2.9214e-04 - val_loss: 3.3720e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 2.9896e-04 - val_loss: 3.2612e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 2.1663e-04 - val_loss: 3.1651e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 2.5466e-04 - val_loss: 3.1550e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 2.1358e-04 - val_loss: 3.1429e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 2.1127e-04 - val_loss: 3.2196e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 2.2016e-04 - val_loss: 3.1582e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.8112e-04 - val_loss: 1.8796e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.9916e-04 - val_loss: 1.3027e-04\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.9835e-04 - val_loss: 6.0854e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.9373e-04 - val_loss: 2.1844e-04\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.6303e-04 - val_loss: 3.0958e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.7265e-04 - val_loss: 3.1548e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.3244e-04 - val_loss: 3.8318e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 2.2152e-04 - val_loss: 3.8233e-04\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.4396e-04 - val_loss: 3.0978e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.3860e-04 - val_loss: 3.8455e-04\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.2745e-04 - val_loss: 1.6220e-04\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 3s 160us/step - loss: 0.0204 - val_loss: 0.0027\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0042 - val_loss: 5.2876e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0016 - val_loss: 4.6704e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 5.1272e-04 - val_loss: 0.0031\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 5.8934e-04 - val_loss: 3.3251e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 3.8484e-04 - val_loss: 3.2448e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 3.8166e-04 - val_loss: 3.1741e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 3.2448e-04 - val_loss: 3.2192e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.9374e-04 - val_loss: 3.1616e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 2.9684e-04 - val_loss: 3.1557e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 2.1447e-04 - val_loss: 4.5108e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 2.3669e-04 - val_loss: 3.3422e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 2.3425e-04 - val_loss: 3.0346e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.8017e-04 - val_loss: 3.2074e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 2.6459e-04 - val_loss: 3.3308e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 2.1215e-04 - val_loss: 4.0458e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.7515e-04 - val_loss: 3.0843e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.4004e-04 - val_loss: 4.0268e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 2.0457e-04 - val_loss: 3.0323e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 2.0134e-04 - val_loss: 3.3015e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.6071e-04 - val_loss: 3.7909e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.2830e-04 - val_loss: 3.9118e-04\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 2.0009e-04 - val_loss: 3.5088e-04\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.8100e-04 - val_loss: 3.0641e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 4s 164us/step - loss: 0.0115 - val_loss: 0.0013\n",
      "Epoch 2/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0032 - val_loss: 6.4491e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0018 - val_loss: 2.4099e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0012 - val_loss: 4.0801e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.2183e-04 - val_loss: 3.2228e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 5.4442e-04 - val_loss: 9.9946e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 5.2535e-04 - val_loss: 1.0460e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 3.8869e-04 - val_loss: 7.2392e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 3.5104e-04 - val_loss: 0.0020\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 3.6598e-04 - val_loss: 7.4969e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 2.7745e-04 - val_loss: 5.4237e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 2.4223e-04 - val_loss: 1.3026e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 2.4584e-04 - val_loss: 3.4080e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 2.0611e-04 - val_loss: 1.5007e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 2.8930e-04 - val_loss: 3.2263e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.7840e-04 - val_loss: 3.3321e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 3.6942e-04 - val_loss: 3.1625e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.7933e-04 - val_loss: 3.1591e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.7516e-04 - val_loss: 4.1732e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.9479e-04 - val_loss: 4.5684e-04\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.7763e-04 - val_loss: 3.9731e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.8030e-04 - val_loss: 3.1742e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.9505e-04 - val_loss: 7.5702e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.4735e-04 - val_loss: 3.1995e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 4s 165us/step - loss: 0.0338 - val_loss: 6.1310e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0043 - val_loss: 1.4629e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0021 - val_loss: 4.9360e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0014 - val_loss: 1.8739e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 9.8801e-04 - val_loss: 2.3264e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 7.5171e-04 - val_loss: 7.1934e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 6.1506e-04 - val_loss: 1.1593e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 5.3072e-04 - val_loss: 1.4701e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 4.7676e-04 - val_loss: 1.7381e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 4.0594e-04 - val_loss: 7.2538e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 3.8579e-04 - val_loss: 8.0223e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 3.4613e-04 - val_loss: 1.5147e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 3.1857e-04 - val_loss: 1.4603e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 3.0789e-04 - val_loss: 1.2896e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 2.8809e-04 - val_loss: 8.1162e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 2.7326e-04 - val_loss: 8.9990e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 2.6650e-04 - val_loss: 9.4430e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - ETA: 0s - loss: 2.5806e-0 - 0s 14us/step - loss: 2.5019e-04 - val_loss: 1.2717e-04\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 2.4094e-04 - val_loss: 1.3002e-04\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 2.4291e-04 - val_loss: 9.7399e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 2.2202e-04 - val_loss: 8.0736e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 2.2294e-04 - val_loss: 2.0166e-04\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 2.1792e-04 - val_loss: 1.4392e-04\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 2.1013e-04 - val_loss: 6.2479e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 4s 168us/step - loss: 0.0908 - val_loss: 1.5797e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0089 - val_loss: 0.0019\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0030 - val_loss: 9.5406e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0011 - val_loss: 8.5894e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 4.6834e-04 - val_loss: 1.1928e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 2.5949e-04 - val_loss: 4.9186e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.6462e-04 - val_loss: 7.7240e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.4215e-04 - val_loss: 7.3924e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.4029e-04 - val_loss: 5.7545e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.3743e-04 - val_loss: 4.9343e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.3958e-04 - val_loss: 9.1892e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.3537e-04 - val_loss: 6.2801e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.4007e-04 - val_loss: 1.1723e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.3233e-04 - val_loss: 1.8117e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.3677e-04 - val_loss: 4.3517e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.3813e-04 - val_loss: 5.8385e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.4210e-04 - val_loss: 6.0651e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.4017e-04 - val_loss: 4.5641e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.3441e-04 - val_loss: 9.7347e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.3716e-04 - val_loss: 1.0154e-04\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.3667e-04 - val_loss: 8.0399e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.3734e-04 - val_loss: 1.0785e-04\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.3976e-04 - val_loss: 1.4790e-04\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.3650e-04 - val_loss: 1.1197e-04\n",
      "\n",
      "GENERATION 12\n",
      "\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 4s 173us/step - loss: 0.0674 - val_loss: 0.0085\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0125 - val_loss: 8.5017e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0034 - val_loss: 2.8337e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0013 - val_loss: 4.1331e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 6.8478e-04 - val_loss: 3.6101e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 2.5746e-04 - val_loss: 1.6587e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 2.7027e-04 - val_loss: 3.1298e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.6204e-04 - val_loss: 1.2533e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 2.7097e-04 - val_loss: 3.4521e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.2460e-04 - val_loss: 3.0996e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.3055e-04 - val_loss: 3.6980e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.4751e-04 - val_loss: 5.6942e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.7458e-04 - val_loss: 3.1053e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.4716e-04 - val_loss: 3.2887e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.3903e-04 - val_loss: 3.2699e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.1826e-04 - val_loss: 3.2099e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.1553e-04 - val_loss: 3.2165e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.2954e-04 - val_loss: 3.2380e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.3498e-04 - val_loss: 3.2751e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.1561e-04 - val_loss: 3.2637e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 9.8636e-05 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.3345e-04 - val_loss: 3.1319e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.7139e-04 - val_loss: 3.2050e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.0325e-04 - val_loss: 4.3506e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 4s 168us/step - loss: 0.0148 - val_loss: 5.8502e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0022 - val_loss: 4.1507e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.1666e-04 - val_loss: 2.7813e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 4.5485e-04 - val_loss: 3.1856e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 2.5230e-04 - val_loss: 7.9453e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 3.4003e-04 - val_loss: 3.4139e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 3.7983e-04 - val_loss: 3.2947e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.7228e-04 - val_loss: 3.2268e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 2.1948e-04 - val_loss: 3.5847e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 2.3402e-04 - val_loss: 3.1258e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 2.2636e-04 - val_loss: 4.3571e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.9179e-04 - val_loss: 3.8898e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.9263e-04 - val_loss: 5.6306e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.8754e-04 - val_loss: 3.3017e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.6044e-04 - val_loss: 4.7610e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.8670e-04 - val_loss: 4.5657e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.8403e-04 - val_loss: 4.6960e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.6099e-04 - val_loss: 4.7274e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.7362e-04 - val_loss: 2.1719e-04\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.9629e-04 - val_loss: 3.0961e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.4757e-04 - val_loss: 2.4985e-04\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.1962e-04 - val_loss: 6.2640e-04\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.9621e-04 - val_loss: 3.8394e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.6292e-04 - val_loss: 3.0837e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 4s 173us/step - loss: 0.3626 - val_loss: 0.0121\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0548 - val_loss: 0.0061\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0133 - val_loss: 0.0048\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0045 - val_loss: 6.3231e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0035 - val_loss: 7.9395e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0017 - val_loss: 4.7784e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 5.9630e-04 - val_loss: 1.9659e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 6.5491e-04 - val_loss: 0.0013\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.1809e-04 - val_loss: 1.5245e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 6.4495e-04 - val_loss: 8.8870e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 4.4508e-04 - val_loss: 1.1907e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 4.8558e-04 - val_loss: 3.4117e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 4.5087e-04 - val_loss: 8.5893e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 3.7008e-04 - val_loss: 3.4825e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 3.8110e-04 - val_loss: 1.8989e-04\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 3.7473e-04 - val_loss: 3.4410e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 3.1270e-04 - val_loss: 3.2384e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 2.4717e-04 - val_loss: 3.8561e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 2.7140e-04 - val_loss: 5.1595e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 2.7726e-04 - val_loss: 4.6358e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 2.1555e-04 - val_loss: 3.5975e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 2.0463e-04 - val_loss: 1.1362e-04\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 2.9295e-04 - val_loss: 3.5792e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.9372e-04 - val_loss: 5.7247e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 4s 180us/step - loss: 0.6785 - val_loss: 0.0027\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.2255 - val_loss: 0.0137\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.1064 - val_loss: 4.4531e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0500 - val_loss: 0.0024\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0212 - val_loss: 3.5129e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0098 - val_loss: 1.9710e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0123 - val_loss: 1.0480e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0024 - val_loss: 6.8935e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0015 - val_loss: 6.1694e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0010 - val_loss: 1.7205e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.3641e-04 - val_loss: 2.3529e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0087 - val_loss: 6.3240e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 5.0446e-04 - val_loss: 5.8979e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 3.4996e-04 - val_loss: 7.3173e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0024 - val_loss: 0.0148\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0019 - val_loss: 2.0488e-04\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 4.3801e-04 - val_loss: 1.2127e-04\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 3.8996e-04 - val_loss: 4.6133e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 3.5402e-04 - val_loss: 1.6027e-04\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0014 - val_loss: 5.2431e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.8374e-04 - val_loss: 4.4909e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 2.7210e-04 - val_loss: 4.7781e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 2.9764e-04 - val_loss: 5.1560e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 4s 181us/step - loss: 0.3678 - val_loss: 0.0012\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0931 - val_loss: 9.5389e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0455 - val_loss: 0.0012\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0243 - val_loss: 2.4888e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0140 - val_loss: 4.4023e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0079 - val_loss: 4.2379e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0044 - val_loss: 1.2245e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0031 - val_loss: 7.1731e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0023 - val_loss: 4.0091e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0018 - val_loss: 7.2620e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0014 - val_loss: 6.8476e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0021 - val_loss: 1.0169e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 7.3781e-04 - val_loss: 9.2782e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0017 - val_loss: 0.0117\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0011 - val_loss: 4.4120e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 4.1479e-04 - val_loss: 4.4925e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0011 - val_loss: 0.0120\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0017 - val_loss: 3.8331e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 2.9686e-04 - val_loss: 3.8305e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 4.2394e-04 - val_loss: 9.9104e-04\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0152 - val_loss: 3.7889e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 4.2613e-04 - val_loss: 3.6530e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 3.1832e-04 - val_loss: 3.7201e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.6103e-04 - val_loss: 4.0287e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 4s 178us/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: nan - val_loss: nan\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 4s 178us/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 14us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: nan - val_loss: nan\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 4s 181us/step - loss: 0.3745 - val_loss: 6.9268e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0433 - val_loss: 5.3546e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0284 - val_loss: 5.8353e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0209 - val_loss: 7.4509e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0166 - val_loss: 1.2872e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0137 - val_loss: 5.9508e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0118 - val_loss: 9.8191e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0102 - val_loss: 1.0569e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0093 - val_loss: 9.5770e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0084 - val_loss: 6.2357e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0076 - val_loss: 4.7816e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0070 - val_loss: 1.6198e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0066 - val_loss: 1.1555e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0061 - val_loss: 8.5834e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0057 - val_loss: 9.3183e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0053 - val_loss: 9.0861e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0052 - val_loss: 8.3670e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0048 - val_loss: 6.7094e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0045 - val_loss: 1.0014e-04\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0044 - val_loss: 1.0247e-04\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0042 - val_loss: 1.0515e-04\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0040 - val_loss: 8.1810e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0038 - val_loss: 7.8892e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0037 - val_loss: 7.3575e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 4s 181us/step - loss: 0.1418 - val_loss: 4.8859e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0618 - val_loss: 3.0390e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0383 - val_loss: 1.7022e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0270 - val_loss: 1.3848e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0213 - val_loss: 2.0756e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0170 - val_loss: 8.8097e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0143 - val_loss: 9.4869e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0122 - val_loss: 6.4703e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0105 - val_loss: 9.0757e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0094 - val_loss: 5.8949e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0086 - val_loss: 8.1725e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0077 - val_loss: 7.3433e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0070 - val_loss: 7.1350e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0065 - val_loss: 8.4702e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0060 - val_loss: 6.9522e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0057 - val_loss: 4.1442e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0051 - val_loss: 4.9293e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0050 - val_loss: 7.5405e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0047 - val_loss: 4.2227e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0044 - val_loss: 5.6650e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0042 - val_loss: 5.3890e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0040 - val_loss: 4.5573e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0039 - val_loss: 4.6243e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0036 - val_loss: 4.2797e-05\n",
      "\n",
      "GENERATION 13\n",
      "\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 4s 186us/step - loss: 0.0166 - val_loss: 1.8571e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0055 - val_loss: 0.0012\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0033 - val_loss: 4.3896e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0018 - val_loss: 8.6891e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0010 - val_loss: 1.8989e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 6.6969e-04 - val_loss: 3.7199e-04\n",
      "Epoch 7/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 15us/step - loss: 5.4445e-04 - val_loss: 8.2567e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 3.9611e-04 - val_loss: 1.4555e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 4.0400e-04 - val_loss: 3.7336e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.5850e-04 - val_loss: 6.3211e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 3.2173e-04 - val_loss: 7.4258e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 2.5363e-04 - val_loss: 1.2305e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 2.5440e-04 - val_loss: 7.8333e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 3.0353e-04 - val_loss: 8.4707e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 2.2963e-04 - val_loss: 1.3288e-04\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 2.8524e-04 - val_loss: 1.4762e-04\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 3.0583e-04 - val_loss: 1.2171e-04\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 2.1062e-04 - val_loss: 1.5754e-04\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 2.2031e-04 - val_loss: 4.7364e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 2.0555e-04 - val_loss: 8.7389e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 2.4710e-04 - val_loss: 1.0307e-04\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 2.1013e-04 - val_loss: 7.2863e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.9480e-04 - val_loss: 1.2082e-04\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 2.1317e-04 - val_loss: 1.0321e-04\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 4s 187us/step - loss: 0.0299 - val_loss: 1.3553e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0044 - val_loss: 4.4212e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0019 - val_loss: 4.3038e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0010 - val_loss: 3.8620e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 6.5760e-04 - val_loss: 3.5440e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 4.6446e-04 - val_loss: 3.5147e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 3.4540e-04 - val_loss: 2.9822e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 2.8534e-04 - val_loss: 2.9797e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 2.2096e-04 - val_loss: 3.1520e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.9954e-04 - val_loss: 2.7549e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.7054e-04 - val_loss: 2.5755e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.5250e-04 - val_loss: 2.5227e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.4562e-04 - val_loss: 2.5665e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.2542e-04 - val_loss: 2.3929e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.1981e-04 - val_loss: 2.3496e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.0458e-04 - val_loss: 2.2708e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.1022e-04 - val_loss: 2.1814e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.0417e-04 - val_loss: 2.1747e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 9.8286e-05 - val_loss: 2.1334e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 9.0111e-05 - val_loss: 2.0570e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.2679e-05 - val_loss: 1.9272e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 7.5413e-05 - val_loss: 1.8602e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 9.0967e-05 - val_loss: 1.8929e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 7.5700e-05 - val_loss: 1.7324e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 4s 201us/step - loss: 0.1286 - val_loss: 6.2763e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0182 - val_loss: 4.4176e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0090 - val_loss: 2.6694e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0055 - val_loss: 6.9667e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0038 - val_loss: 2.6300e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0029 - val_loss: 1.2297e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0021 - val_loss: 1.0196e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0016 - val_loss: 1.1167e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0013 - val_loss: 4.2334e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0011 - val_loss: 4.2013e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.7037e-04 - val_loss: 4.0480e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.3507e-04 - val_loss: 3.9184e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 7.3418e-04 - val_loss: 4.7464e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 6.8802e-04 - val_loss: 3.7046e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 6.0845e-04 - val_loss: 3.2914e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 5.4862e-04 - val_loss: 3.3360e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 5.2279e-04 - val_loss: 3.7616e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 4.3375e-04 - val_loss: 4.1033e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 4.4325e-04 - val_loss: 3.1436e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 3.8205e-04 - val_loss: 3.5823e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 3.6125e-04 - val_loss: 3.5905e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 3.6191e-04 - val_loss: 3.5070e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 3.2038e-04 - val_loss: 3.1428e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 3.2373e-04 - val_loss: 3.1523e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 4s 202us/step - loss: 0.0859 - val_loss: 5.1494e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0139 - val_loss: 6.4472e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0079 - val_loss: 3.0263e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0052 - val_loss: 1.6619e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 1.5561e-04\n",
      "Epoch 6/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0025 - val_loss: 5.7406e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0019 - val_loss: 7.0231e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0015 - val_loss: 5.1734e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0012 - val_loss: 3.2217e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 9.4401e-04 - val_loss: 3.9626e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.0119e-04 - val_loss: 3.1562e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 7.2719e-04 - val_loss: 3.1925e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 6.4224e-04 - val_loss: 3.2875e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 5.4464e-04 - val_loss: 3.1746e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 4.8952e-04 - val_loss: 3.3052e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 4.3589e-04 - val_loss: 3.2251e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 4.0411e-04 - val_loss: 3.1905e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 3.8845e-04 - val_loss: 3.2691e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 3.5756e-04 - val_loss: 3.2171e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 3.2623e-04 - val_loss: 3.2448e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 3.0881e-04 - val_loss: 3.1473e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 2.9765e-04 - val_loss: 3.2584e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 2.8183e-04 - val_loss: 3.1629e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 2.5272e-04 - val_loss: 3.1795e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 4s 201us/step - loss: 0.0382 - val_loss: 0.0011\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0052 - val_loss: 1.2968e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0026 - val_loss: 5.9518e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0016 - val_loss: 4.5808e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0011 - val_loss: 3.6718e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.1352e-04 - val_loss: 4.4258e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 6.1249e-04 - val_loss: 3.8827e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 5.1024e-04 - val_loss: 3.2676e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 4.1357e-04 - val_loss: 3.1410e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 3.6510e-04 - val_loss: 3.3305e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 3.2154e-04 - val_loss: 3.1842e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 3.0076e-04 - val_loss: 3.1426e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 2.7105e-04 - val_loss: 3.1446e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 2.5337e-04 - val_loss: 3.4666e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 2.3143e-04 - val_loss: 3.1438e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 2.0710e-04 - val_loss: 3.2047e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 2.0354e-04 - val_loss: 3.2698e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.8699e-04 - val_loss: 3.3879e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.8327e-04 - val_loss: 3.1700e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.6344e-04 - val_loss: 3.8256e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.5894e-04 - val_loss: 3.1552e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 1.5675e-04 - val_loss: 3.1813e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 1.5407e-04 - val_loss: 3.1614e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.4448e-04 - val_loss: 3.1618e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 4s 201us/step - loss: 0.1748 - val_loss: 0.0101\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0549 - val_loss: 0.0062\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0384 - val_loss: 0.0023\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0305 - val_loss: 6.9600e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0255 - val_loss: 3.3088e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0223 - val_loss: 1.6022e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0201 - val_loss: 7.0055e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0178 - val_loss: 4.1198e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0163 - val_loss: 6.2967e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0151 - val_loss: 4.6497e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0137 - val_loss: 4.9841e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0131 - val_loss: 8.5846e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0120 - val_loss: 1.1282e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0111 - val_loss: 1.4642e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0106 - val_loss: 1.0203e-04\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0096 - val_loss: 1.4305e-04\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0093 - val_loss: 1.3398e-04\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0089 - val_loss: 1.8193e-04\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0085 - val_loss: 1.8115e-04\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0080 - val_loss: 1.2257e-04\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0077 - val_loss: 1.9623e-04\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0072 - val_loss: 2.6085e-04\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0069 - val_loss: 1.8634e-04\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0066 - val_loss: 2.4004e-04\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 5s 213us/step - loss: 0.0423 - val_loss: 5.0472e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0163 - val_loss: 3.3938e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0119 - val_loss: 4.6060e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0094 - val_loss: 4.8659e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0076 - val_loss: 2.2594e-04\n",
      "Epoch 6/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0066 - val_loss: 1.5762e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0056 - val_loss: 9.7228e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0048 - val_loss: 5.8590e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0041 - val_loss: 5.6984e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0037 - val_loss: 4.2283e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0032 - val_loss: 4.4626e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0028 - val_loss: 4.6170e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0025 - val_loss: 3.1572e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0023 - val_loss: 3.1650e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0021 - val_loss: 3.3350e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0019 - val_loss: 3.8511e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0017 - val_loss: 3.2770e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0015 - val_loss: 3.2987e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0014 - val_loss: 3.2385e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0013 - val_loss: 3.1619e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0012 - val_loss: 3.2189e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0011 - val_loss: 3.1659e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0011 - val_loss: 3.4492e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 9.6567e-04 - val_loss: 3.1731e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 5s 211us/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: nan - val_loss: nan\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 5s 216us/step - loss: 0.2493 - val_loss: 6.5503e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0526 - val_loss: 9.3650e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0324 - val_loss: 5.7888e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0255 - val_loss: 6.9017e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0201 - val_loss: 5.8635e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0169 - val_loss: 3.6988e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0141 - val_loss: 4.9029e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0130 - val_loss: 3.1590e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0113 - val_loss: 3.9825e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0103 - val_loss: 2.1369e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0093 - val_loss: 3.0308e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0089 - val_loss: 1.8412e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0080 - val_loss: 2.4732e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0076 - val_loss: 1.9373e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0072 - val_loss: 1.9799e-04\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0068 - val_loss: 2.5302e-04\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0065 - val_loss: 3.0416e-04\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0060 - val_loss: 2.9500e-04\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0058 - val_loss: 2.4604e-04\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0054 - val_loss: 1.6111e-04\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0053 - val_loss: 1.8378e-04\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0049 - val_loss: 2.0377e-04\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0047 - val_loss: 1.1412e-04\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0046 - val_loss: 3.2420e-04\n",
      "\n",
      "GENERATION 14\n",
      "\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 5s 213us/step - loss: 0.0669 - val_loss: 0.0011\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0132 - val_loss: 4.1571e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0068 - val_loss: 1.3136e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0043 - val_loss: 5.0681e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0029 - val_loss: 6.5341e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0021 - val_loss: 4.3682e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0015 - val_loss: 3.9086e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0011 - val_loss: 4.1183e-05\n",
      "Epoch 9/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.4875e-04 - val_loss: 3.8866e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 6.6802e-04 - val_loss: 3.9073e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 5.2357e-04 - val_loss: 4.2241e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 4.3575e-04 - val_loss: 3.7658e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 3.7255e-04 - val_loss: 3.6410e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 3.1909e-04 - val_loss: 3.6025e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 2.8495e-04 - val_loss: 3.3846e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 2.5460e-04 - val_loss: 3.2027e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 2.3077e-04 - val_loss: 2.9948e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 2.1532e-04 - val_loss: 2.8825e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 2.0060e-04 - val_loss: 2.8780e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.9135e-04 - val_loss: 2.7693e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.8540e-04 - val_loss: 2.6395e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.7230e-04 - val_loss: 2.5198e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.5399e-04 - val_loss: 2.3699e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.5965e-04 - val_loss: 2.2684e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 5s 219us/step - loss: 0.0172 - val_loss: 2.1941e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0038 - val_loss: 4.9598e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0018 - val_loss: 3.9615e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0011 - val_loss: 4.9322e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.1093e-04 - val_loss: 4.2443e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 6.1786e-04 - val_loss: 3.7714e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 5.0673e-04 - val_loss: 3.1312e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 4.2659e-04 - val_loss: 3.9654e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 3.6001e-04 - val_loss: 3.0308e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 3.0649e-04 - val_loss: 3.0708e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.7491e-04 - val_loss: 3.0577e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 2.4288e-04 - val_loss: 2.9162e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.0726e-04 - val_loss: 3.2250e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.9007e-04 - val_loss: 2.8182e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.7796e-04 - val_loss: 2.7962e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.5916e-04 - val_loss: 2.9525e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.4348e-04 - val_loss: 2.7584e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.3390e-04 - val_loss: 2.7579e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.2118e-04 - val_loss: 2.6312e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.1485e-04 - val_loss: 2.5659e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.0809e-04 - val_loss: 2.5474e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.0512e-04 - val_loss: 2.5167e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 9.9978e-05 - val_loss: 2.5754e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 9.5843e-05 - val_loss: 2.3310e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 5s 214us/step - loss: 0.0076 - val_loss: 6.2706e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0018 - val_loss: 3.9761e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 9.2900e-04 - val_loss: 4.3002e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 6.1046e-04 - val_loss: 3.3137e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 4.3934e-04 - val_loss: 3.1768e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 3.4455e-04 - val_loss: 3.3582e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.8771e-04 - val_loss: 3.7076e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.4575e-04 - val_loss: 3.0615e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 2.1346e-04 - val_loss: 4.0452e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.8804e-04 - val_loss: 3.8099e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.6777e-04 - val_loss: 3.4581e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.5569e-04 - val_loss: 3.5867e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.3990e-04 - val_loss: 3.4982e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.2632e-04 - val_loss: 3.2316e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.1659e-04 - val_loss: 3.0859e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.0926e-04 - val_loss: 3.1139e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.0326e-04 - val_loss: 3.0140e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 9.0231e-05 - val_loss: 2.7861e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 9.1934e-05 - val_loss: 2.7221e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.6928e-05 - val_loss: 2.7027e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 7.8079e-05 - val_loss: 2.5785e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 7.6346e-05 - val_loss: 2.5649e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 7.3514e-05 - val_loss: 2.3286e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 7.4323e-05 - val_loss: 2.4393e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 5s 217us/step - loss: 0.0223 - val_loss: 1.4330e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0054 - val_loss: 1.5013e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0028 - val_loss: 5.8191e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0017 - val_loss: 3.5203e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0011 - val_loss: 3.8862e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.2177e-04 - val_loss: 3.2499e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 6.6313e-04 - val_loss: 3.4510e-05\n",
      "Epoch 8/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 16us/step - loss: 5.5353e-04 - val_loss: 3.6849e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 4.6676e-04 - val_loss: 3.3139e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 4.0532e-04 - val_loss: 3.3057e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 3.4832e-04 - val_loss: 3.4412e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 3.2392e-04 - val_loss: 3.9908e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.8799e-04 - val_loss: 3.2953e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.5319e-04 - val_loss: 3.2431e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 2.3308e-04 - val_loss: 3.1299e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.1333e-04 - val_loss: 3.1625e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.9568e-04 - val_loss: 3.0832e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.8018e-04 - val_loss: 3.0749e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.7324e-04 - val_loss: 3.0009e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.6003e-04 - val_loss: 3.1967e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.4788e-04 - val_loss: 3.0729e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.4854e-04 - val_loss: 2.9047e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.3350e-04 - val_loss: 2.8882e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.2926e-04 - val_loss: 2.8803e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 5s 218us/step - loss: 0.0220 - val_loss: 2.2181e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0042 - val_loss: 4.2597e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0018 - val_loss: 3.4243e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0011 - val_loss: 3.2067e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.1943e-04 - val_loss: 3.4472e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 6.6138e-04 - val_loss: 3.7544e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 5.1041e-04 - val_loss: 3.6127e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 4.1029e-04 - val_loss: 3.0207e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 3.3345e-04 - val_loss: 3.1845e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 2.7660e-04 - val_loss: 2.8786e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.3500e-04 - val_loss: 2.8054e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.9322e-04 - val_loss: 2.7168e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.6918e-04 - val_loss: 2.6441e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.5827e-04 - val_loss: 2.5872e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.3472e-04 - val_loss: 2.5116e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.2249e-04 - val_loss: 2.3888e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.2058e-04 - val_loss: 2.3095e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.1054e-04 - val_loss: 2.2413e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.0513e-04 - val_loss: 2.2049e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 9.3380e-05 - val_loss: 2.1376e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 9.3759e-05 - val_loss: 2.0699e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.9919e-05 - val_loss: 2.0394e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.0180e-05 - val_loss: 1.8952e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 7.7825e-05 - val_loss: 1.8099e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 5s 218us/step - loss: 0.0072 - val_loss: 1.2068e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0014 - val_loss: 6.5369e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 7.7202e-04 - val_loss: 5.8313e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 5.2438e-04 - val_loss: 4.8189e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 3.9585e-04 - val_loss: 4.2121e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 3.2774e-04 - val_loss: 3.7813e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.7931e-04 - val_loss: 3.7279e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.3671e-04 - val_loss: 3.6584e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.1544e-04 - val_loss: 3.7715e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.9335e-04 - val_loss: 3.3005e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.7371e-04 - val_loss: 4.1535e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.6479e-04 - val_loss: 3.5151e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.4898e-04 - val_loss: 3.7019e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.4221e-04 - val_loss: 3.9808e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.3122e-04 - val_loss: 3.2916e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.2678e-04 - val_loss: 3.5438e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.1874e-04 - val_loss: 3.3602e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.1221e-04 - val_loss: 3.2613e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.0882e-04 - val_loss: 3.4948e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.0540e-04 - val_loss: 3.8399e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.0310e-04 - val_loss: 3.1956e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 9.9812e-05 - val_loss: 3.0719e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 9.7395e-05 - val_loss: 3.0061e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 9.2740e-05 - val_loss: 3.0398e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 5s 219us/step - loss: 0.0316 - val_loss: 2.8330e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0059 - val_loss: 9.8872e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0041 - val_loss: 6.1956e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0031 - val_loss: 4.0928e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0023 - val_loss: 3.8218e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0018 - val_loss: 4.0437e-05\n",
      "Epoch 7/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0014 - val_loss: 3.7985e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0012 - val_loss: 5.3383e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 9.8133e-04 - val_loss: 5.1884e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.2514e-04 - val_loss: 3.9218e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 6.9925e-04 - val_loss: 4.1686e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 5.8650e-04 - val_loss: 5.0914e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 5.2648e-04 - val_loss: 4.9280e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 4.6950e-04 - val_loss: 5.1084e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 4.2040e-04 - val_loss: 4.0148e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 3.7483e-04 - val_loss: 3.5582e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 3.4442e-04 - val_loss: 3.7774e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 3.1132e-04 - val_loss: 3.4568e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.9233e-04 - val_loss: 3.5085e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.7566e-04 - val_loss: 3.1643e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.5816e-04 - val_loss: 3.2027e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.4379e-04 - val_loss: 3.0336e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.2422e-04 - val_loss: 3.0742e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.1806e-04 - val_loss: 3.2754e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 5s 225us/step - loss: 0.0190 - val_loss: 2.8354e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0048 - val_loss: 1.1328e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0031 - val_loss: 5.4839e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0022 - val_loss: 4.3658e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0016 - val_loss: 4.6359e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0013 - val_loss: 4.2803e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 9.6236e-04 - val_loss: 3.6973e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 7.5687e-04 - val_loss: 3.6394e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 6.1749e-04 - val_loss: 5.4679e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 4.9580e-04 - val_loss: 4.4733e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 4.3334e-04 - val_loss: 3.8191e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 3.6148e-04 - val_loss: 3.5748e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 3.0728e-04 - val_loss: 2.9151e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.7580e-04 - val_loss: 3.0282e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.4486e-04 - val_loss: 3.0955e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.1924e-04 - val_loss: 3.2561e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.9723e-04 - val_loss: 3.1668e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.8207e-04 - val_loss: 2.9485e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.7360e-04 - val_loss: 3.2136e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.5636e-04 - val_loss: 2.9719e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.5210e-04 - val_loss: 2.9541e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.5425e-04 - val_loss: 3.0001e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.3814e-04 - val_loss: 2.9718e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.3595e-04 - val_loss: 3.0600e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 5s 227us/step - loss: 0.0108 - val_loss: 2.3395e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0028 - val_loss: 5.5777e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0016 - val_loss: 4.1845e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0011 - val_loss: 4.4916e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 7.8537e-04 - val_loss: 3.8163e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 5.9452e-04 - val_loss: 3.5852e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 4.6987e-04 - val_loss: 3.3282e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 3.9538e-04 - val_loss: 3.2824e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 3.3306e-04 - val_loss: 3.1318e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.9191e-04 - val_loss: 3.3643e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.6130e-04 - val_loss: 2.9593e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.4389e-04 - val_loss: 2.9980e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.2067e-04 - val_loss: 2.9932e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.0914e-04 - val_loss: 2.8190e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.9768e-04 - val_loss: 2.9204e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.8404e-04 - val_loss: 2.7527e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.7451e-04 - val_loss: 3.1976e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.6797e-04 - val_loss: 2.9907e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.6294e-04 - val_loss: 2.6737e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.4886e-04 - val_loss: 2.6413e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.4859e-04 - val_loss: 2.6580e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.4927e-04 - val_loss: 2.6349e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.3947e-04 - val_loss: 2.5843e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.3323e-04 - val_loss: 2.7506e-05\n",
      "\n",
      "GENERATION 15\n",
      "\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 5s 234us/step - loss: 0.0259 - val_loss: 4.9871e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0061 - val_loss: 4.5421e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0031 - val_loss: 2.3649e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0018 - val_loss: 1.8460e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0012 - val_loss: 1.0360e-04\n",
      "Epoch 6/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7099e-04 - val_loss: 6.0022e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 6.4986e-04 - val_loss: 5.4221e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 4.8544e-04 - val_loss: 5.8940e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 3.8914e-04 - val_loss: 4.3450e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 3.0872e-04 - val_loss: 3.9313e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 2.5018e-04 - val_loss: 3.6305e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 2.0384e-04 - val_loss: 3.4862e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.8347e-04 - val_loss: 3.2806e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.6326e-04 - val_loss: 3.2548e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.4017e-04 - val_loss: 3.0594e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.2981e-04 - val_loss: 2.9912e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.2228e-04 - val_loss: 3.0221e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.1680e-04 - val_loss: 2.9527e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.0929e-04 - val_loss: 2.9395e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.0994e-04 - val_loss: 2.8899e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 1.0609e-04 - val_loss: 2.8424e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 1.0023e-04 - val_loss: 2.9036e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.0358e-04 - val_loss: 2.8413e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.9055e-05 - val_loss: 2.7944e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 5s 232us/step - loss: 0.0214 - val_loss: 4.0592e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0046 - val_loss: 3.0628e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0026 - val_loss: 2.0914e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0017 - val_loss: 1.2085e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0012 - val_loss: 8.7167e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.9308e-04 - val_loss: 1.5645e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 7.1353e-04 - val_loss: 7.4837e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 5.7389e-04 - val_loss: 7.8022e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 4.8622e-04 - val_loss: 8.8491e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 4.1770e-04 - val_loss: 9.0721e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 3.6690e-04 - val_loss: 7.9394e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 3.1460e-04 - val_loss: 5.0941e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.8327e-04 - val_loss: 4.9736e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.5242e-04 - val_loss: 5.0222e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.2950e-04 - val_loss: 4.3159e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.1206e-04 - val_loss: 3.3575e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.9119e-04 - val_loss: 3.8595e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.7921e-04 - val_loss: 3.3311e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.6693e-04 - val_loss: 3.3752e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.6092e-04 - val_loss: 3.1234e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.4655e-04 - val_loss: 3.5114e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.3234e-04 - val_loss: 3.4800e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.2223e-04 - val_loss: 3.4982e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.1247e-04 - val_loss: 3.2588e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 5s 235us/step - loss: 0.0160 - val_loss: 7.1347e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0045 - val_loss: 4.3991e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0026 - val_loss: 9.0395e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0018 - val_loss: 4.8803e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0012 - val_loss: 6.2755e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 9.2220e-04 - val_loss: 6.2568e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 7.1507e-04 - val_loss: 5.5799e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 5.9134e-04 - val_loss: 4.0664e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 4.9946e-04 - val_loss: 3.0653e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 4.3170e-04 - val_loss: 3.4454e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 3.7818e-04 - val_loss: 2.7445e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 3.3498e-04 - val_loss: 3.3433e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.9205e-04 - val_loss: 3.7168e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.6976e-04 - val_loss: 2.5262e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.4476e-04 - val_loss: 2.4480e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.2192e-04 - val_loss: 2.4001e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.0362e-04 - val_loss: 2.4451e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.0124e-04 - val_loss: 2.2975e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.8615e-04 - val_loss: 2.2333e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.7137e-04 - val_loss: 2.2422e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.6099e-04 - val_loss: 2.1607e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.5820e-04 - val_loss: 2.0844e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.4587e-04 - val_loss: 2.0392e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.3753e-04 - val_loss: 2.1840e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 5s 237us/step - loss: 0.0202 - val_loss: 5.1749e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0040 - val_loss: 6.9366e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0019 - val_loss: 4.7640e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0011 - val_loss: 4.3260e-05\n",
      "Epoch 5/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 16us/step - loss: 7.9420e-04 - val_loss: 4.7403e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 6.0923e-04 - val_loss: 4.1308e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 5.1081e-04 - val_loss: 3.6663e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 4.3553e-04 - val_loss: 3.5192e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 3.7672e-04 - val_loss: 3.2552e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 3.3233e-04 - val_loss: 3.2894e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 3.0268e-04 - val_loss: 3.2890e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.7844e-04 - val_loss: 3.2408e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 2.5078e-04 - val_loss: 3.2799e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 2.4228e-04 - val_loss: 3.1924e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 2.2109e-04 - val_loss: 3.2159e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 2.0948e-04 - val_loss: 3.2121e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.9363e-04 - val_loss: 3.1822e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.8471e-04 - val_loss: 3.1337e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.7458e-04 - val_loss: 3.0893e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.6734e-04 - val_loss: 3.0794e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.6053e-04 - val_loss: 3.0610e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.4897e-04 - val_loss: 3.0696e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.4187e-04 - val_loss: 3.0570e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.3438e-04 - val_loss: 3.1635e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 5s 238us/step - loss: 0.0173 - val_loss: 7.8072e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0042 - val_loss: 5.4666e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0021 - val_loss: 3.9136e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0013 - val_loss: 6.4939e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.8073e-04 - val_loss: 4.2788e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 6.7914e-04 - val_loss: 4.2426e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 5.3682e-04 - val_loss: 3.4729e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 4.4113e-04 - val_loss: 3.1038e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 3.7139e-04 - val_loss: 2.9320e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 3.1047e-04 - val_loss: 3.0955e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.7002e-04 - val_loss: 3.2808e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.3671e-04 - val_loss: 3.2794e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.0155e-04 - val_loss: 3.0852e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.7971e-04 - val_loss: 2.8864e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - ETA: 0s - loss: 1.2954e-0 - 0s 16us/step - loss: 1.6029e-04 - val_loss: 2.5786e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.4875e-04 - val_loss: 2.4299e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.3343e-04 - val_loss: 2.3677e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.1801e-04 - val_loss: 2.5690e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.0701e-04 - val_loss: 2.3363e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.0948e-04 - val_loss: 2.1495e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 9.0230e-05 - val_loss: 2.1020e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 9.0284e-05 - val_loss: 2.0301e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.0653e-05 - val_loss: 1.9472e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.0802e-05 - val_loss: 1.8832e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 5s 238us/step - loss: 0.0172 - val_loss: 8.4776e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0032 - val_loss: 2.1467e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0013 - val_loss: 6.1388e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 5.2679e-04 - val_loss: 6.4161e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 4.4242e-04 - val_loss: 3.4720e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 2.4425e-04 - val_loss: 6.5688e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 3.5611e-04 - val_loss: 3.6885e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.8006e-04 - val_loss: 5.3610e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 2.2426e-04 - val_loss: 3.3560e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.8423e-04 - val_loss: 3.2023e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.8659e-04 - val_loss: 9.3208e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 2.3654e-04 - val_loss: 3.9344e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.0852e-04 - val_loss: 7.8807e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.4392e-04 - val_loss: 4.8644e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.9059e-04 - val_loss: 9.4725e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.4702e-04 - val_loss: 3.2317e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.3637e-04 - val_loss: 3.3550e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.9773e-04 - val_loss: 3.0646e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.4042e-04 - val_loss: 5.0644e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.6610e-04 - val_loss: 1.4562e-04\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.9130e-04 - val_loss: 7.9835e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.8393e-04 - val_loss: 4.5160e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.1976e-04 - val_loss: 3.1634e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.3601e-04 - val_loss: 4.6959e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 5s 246us/step - loss: 0.0077 - val_loss: 6.0411e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 9.7763e-04 - val_loss: 2.3173e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 9.6226e-04 - val_loss: 4.4505e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 5.4089e-04 - val_loss: 1.4419e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 4.2113e-04 - val_loss: 2.8328e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 4.6974e-04 - val_loss: 1.0870e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.2447e-04 - val_loss: 1.3293e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 3.1525e-04 - val_loss: 2.1176e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.7730e-04 - val_loss: 6.2758e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.2982e-04 - val_loss: 5.1490e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.3447e-04 - val_loss: 3.1194e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.5147e-04 - val_loss: 3.7047e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.4017e-04 - val_loss: 7.0073e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.0875e-04 - val_loss: 2.5875e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.2735e-04 - val_loss: 3.9253e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.1466e-04 - val_loss: 2.7210e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.1652e-04 - val_loss: 5.0465e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.6597e-04 - val_loss: 2.5049e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.0311e-04 - val_loss: 3.5992e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.4518e-05 - val_loss: 2.4916e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.1876e-04 - val_loss: 2.4661e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 9.1214e-05 - val_loss: 6.2436e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 9.4486e-05 - val_loss: 2.7386e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 5s 244us/step - loss: 0.0107 - val_loss: 4.2357e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0020 - val_loss: 1.4527e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0012 - val_loss: 7.2403e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 5.7811e-04 - val_loss: 3.6695e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 7.1123e-04 - val_loss: 3.0551e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 3.1286e-04 - val_loss: 2.8202e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 4.4992e-04 - val_loss: 2.9062e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.3453e-04 - val_loss: 1.6385e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.2774e-04 - val_loss: 2.3601e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.6847e-04 - val_loss: 1.2821e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.6571e-04 - val_loss: 4.3449e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.2157e-04 - val_loss: 5.7837e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.5342e-04 - val_loss: 5.3194e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.6508e-04 - val_loss: 4.9082e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.3238e-04 - val_loss: 2.9246e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.6928e-04 - val_loss: 2.6542e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.1759e-04 - val_loss: 2.5480e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.1425e-04 - val_loss: 1.1699e-04\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.2622e-04 - val_loss: 8.9235e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.1551e-04 - val_loss: 5.6851e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.0232e-04 - val_loss: 4.5278e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 9.7138e-05 - val_loss: 2.1604e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.0107e-04 - val_loss: 3.1565e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.0675e-05 - val_loss: 5.1741e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 5s 248us/step - loss: 0.0107 - val_loss: 6.9701e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0025 - val_loss: 1.0391e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0016 - val_loss: 3.3087e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 7.3357e-04 - val_loss: 1.0970e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 7.4420e-04 - val_loss: 5.0601e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 3.9871e-04 - val_loss: 3.6811e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 3.8357e-04 - val_loss: 3.0306e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 3.2136e-04 - val_loss: 1.9531e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.7171e-04 - val_loss: 1.3397e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.6811e-04 - val_loss: 4.9599e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.9038e-04 - val_loss: 6.5872e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.2247e-04 - val_loss: 2.1200e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.9677e-04 - val_loss: 4.7827e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.8258e-04 - val_loss: 1.3852e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.7525e-04 - val_loss: 2.9196e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.5188e-04 - val_loss: 9.3744e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.3918e-04 - val_loss: 3.8911e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.4642e-04 - val_loss: 1.1803e-04\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.4132e-04 - val_loss: 3.0772e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.2444e-04 - val_loss: 9.6512e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.3385e-04 - val_loss: 3.6979e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.2461e-04 - val_loss: 5.3639e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.1635e-04 - val_loss: 3.9670e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.1547e-04 - val_loss: 2.9541e-05\n",
      "\n",
      "GENERATION 16\n",
      "\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 5s 246us/step - loss: 0.1003 - val_loss: 0.0028\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0557 - val_loss: 0.0015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0369 - val_loss: 0.0012\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0278 - val_loss: 7.9264e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0219 - val_loss: 6.0928e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0187 - val_loss: 6.3477e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0161 - val_loss: 4.5465e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0139 - val_loss: 5.2924e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0125 - val_loss: 3.2996e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0114 - val_loss: 4.0207e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0102 - val_loss: 2.6623e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0096 - val_loss: 2.8777e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0089 - val_loss: 2.9967e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0084 - val_loss: 2.3837e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0078 - val_loss: 2.5405e-04\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0075 - val_loss: 2.3302e-04\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0070 - val_loss: 2.2026e-04\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0066 - val_loss: 2.4382e-04\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0063 - val_loss: 1.6790e-04\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0060 - val_loss: 2.1313e-04\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0057 - val_loss: 1.7176e-04\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0056 - val_loss: 1.7007e-04\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0054 - val_loss: 1.7922e-04\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0051 - val_loss: 1.7908e-04\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 5s 249us/step - loss: 0.0316 - val_loss: 7.3368e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0078 - val_loss: 8.7336e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0040 - val_loss: 5.4874e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0025 - val_loss: 6.2009e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0017 - val_loss: 3.6835e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0012 - val_loss: 2.8097e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 9.6805e-04 - val_loss: 2.0832e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 7.9725e-04 - val_loss: 2.7179e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 6.7294e-04 - val_loss: 2.0381e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 5.5804e-04 - val_loss: 1.8921e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 4.7932e-04 - val_loss: 1.5303e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 4.3272e-04 - val_loss: 1.0014e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 3.7395e-04 - val_loss: 9.2832e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 3.3269e-04 - val_loss: 7.9135e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 3.0342e-04 - val_loss: 1.1116e-04\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.7100e-04 - val_loss: 7.4394e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.5063e-04 - val_loss: 6.3872e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.2676e-04 - val_loss: 8.2466e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.1063e-04 - val_loss: 5.8258e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.9695e-04 - val_loss: 5.1398e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.7833e-04 - val_loss: 5.0754e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.6819e-04 - val_loss: 4.4115e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.5166e-04 - val_loss: 3.3847e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.3493e-04 - val_loss: 3.7660e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 5s 253us/step - loss: 0.1862 - val_loss: 8.4764e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0268 - val_loss: 0.0016\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0108 - val_loss: 3.1214e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0054 - val_loss: 1.7983e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0030 - val_loss: 2.0804e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0019 - val_loss: 9.4176e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0014 - val_loss: 7.6825e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0011 - val_loss: 9.2782e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0010 - val_loss: 4.9136e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 9.0516e-04 - val_loss: 5.1228e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 7.6566e-04 - val_loss: 4.7321e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 7.0340e-04 - val_loss: 4.3218e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 6.4324e-04 - val_loss: 3.5031e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 6.1803e-04 - val_loss: 3.8715e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 5.3181e-04 - val_loss: 3.1384e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 5.0895e-04 - val_loss: 3.4894e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - ETA: 0s - loss: 4.7699e-0 - 0s 16us/step - loss: 4.7967e-04 - val_loss: 2.7615e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 4.3216e-04 - val_loss: 3.0333e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 3.8802e-04 - val_loss: 2.5755e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 3.7931e-04 - val_loss: 2.4752e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 3.4475e-04 - val_loss: 2.2925e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 3.5139e-04 - val_loss: 2.5965e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 3.2638e-04 - val_loss: 2.6642e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.9299e-04 - val_loss: 2.4352e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 5s 254us/step - loss: 0.0442 - val_loss: 0.0027\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0080 - val_loss: 1.4158e-04\n",
      "Epoch 3/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0038 - val_loss: 9.2427e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0022 - val_loss: 5.2716e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0015 - val_loss: 3.9864e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0011 - val_loss: 4.1181e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 7.6010e-04 - val_loss: 3.8629e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 5.9044e-04 - val_loss: 3.5652e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 4.7060e-04 - val_loss: 3.3317e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 4.0819e-04 - val_loss: 3.2935e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 3.3871e-04 - val_loss: 3.7381e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.9706e-04 - val_loss: 3.1473e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.6216e-04 - val_loss: 3.0375e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.3215e-04 - val_loss: 2.9949e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.9565e-04 - val_loss: 2.9003e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.8402e-04 - val_loss: 2.8927e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.7244e-04 - val_loss: 2.7200e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.6981e-04 - val_loss: 2.6648e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.5084e-04 - val_loss: 2.6754e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.5060e-04 - val_loss: 2.5717e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.3145e-04 - val_loss: 2.4758e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.4318e-04 - val_loss: 2.4214e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.3356e-04 - val_loss: 2.4416e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.3733e-04 - val_loss: 2.4030e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 5s 256us/step - loss: 0.0874 - val_loss: 0.0028\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0138 - val_loss: 4.3057e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0060 - val_loss: 3.9322e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0033 - val_loss: 1.0688e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0020 - val_loss: 1.2515e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0014 - val_loss: 8.1141e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 9.6909e-04 - val_loss: 7.6100e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 7.1238e-04 - val_loss: 6.9827e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 5.8037e-04 - val_loss: 5.4343e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 4.7320e-04 - val_loss: 4.6364e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 4.4224e-04 - val_loss: 4.5157e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 3.8598e-04 - val_loss: 4.3944e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 3.3344e-04 - val_loss: 3.7347e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 3.2175e-04 - val_loss: 3.3455e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.9363e-04 - val_loss: 3.2196e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.7362e-04 - val_loss: 3.2129e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.7171e-04 - val_loss: 2.8891e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.4252e-04 - val_loss: 2.7622e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 2.3125e-04 - val_loss: 2.7559e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 2.0711e-04 - val_loss: 2.9154e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.0080e-04 - val_loss: 2.4429e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.0152e-04 - val_loss: 2.3475e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.8556e-04 - val_loss: 2.4928e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.8555e-04 - val_loss: 2.1567e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 6s 266us/step - loss: 0.0711 - val_loss: 1.7015e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0093 - val_loss: 1.3422e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0038 - val_loss: 7.4570e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0022 - val_loss: 4.6906e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0015 - val_loss: 6.8729e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0010 - val_loss: 4.3339e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 7.7706e-04 - val_loss: 3.4929e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 5.8827e-04 - val_loss: 3.3066e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 4.7139e-04 - val_loss: 3.5324e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 4.1100e-04 - val_loss: 3.1595e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 3.3958e-04 - val_loss: 2.8279e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 2.9343e-04 - val_loss: 2.7830e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 2.5159e-04 - val_loss: 2.6072e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.2661e-04 - val_loss: 2.4410e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.9670e-04 - val_loss: 2.3247e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.8189e-04 - val_loss: 2.1708e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.6378e-04 - val_loss: 2.1997e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.5885e-04 - val_loss: 1.9626e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.4326e-04 - val_loss: 1.8714e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.3927e-04 - val_loss: 1.7793e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.3191e-04 - val_loss: 1.6896e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.2518e-04 - val_loss: 1.5909e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.2208e-04 - val_loss: 1.5843e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.3067e-04 - val_loss: 1.4860e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 6s 257us/step - loss: 0.8480 - val_loss: 0.0059\n",
      "Epoch 2/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0366 - val_loss: 0.0011\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0316 - val_loss: 6.2214e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0296 - val_loss: 7.0856e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0270 - val_loss: 7.1689e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0241 - val_loss: 6.2747e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0229 - val_loss: 5.3939e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0214 - val_loss: 4.6316e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0199 - val_loss: 4.0568e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0187 - val_loss: 4.1222e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0171 - val_loss: 4.4620e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0161 - val_loss: 4.0400e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0144 - val_loss: 4.9791e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0130 - val_loss: 3.8887e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0122 - val_loss: 3.4923e-04\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0114 - val_loss: 3.3754e-04\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0102 - val_loss: 1.9991e-04\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0093 - val_loss: 2.0389e-04\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0086 - val_loss: 2.0776e-04\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0080 - val_loss: 1.6269e-04\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0073 - val_loss: 1.2465e-04\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0064 - val_loss: 9.6044e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0062 - val_loss: 9.9885e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0058 - val_loss: 1.0559e-04\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 6s 274us/step - loss: 0.2259 - val_loss: 2.4513e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0417 - val_loss: 4.6829e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0286 - val_loss: 4.1743e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0224 - val_loss: 2.3558e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0182 - val_loss: 7.2173e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0151 - val_loss: 4.2049e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0129 - val_loss: 1.2489e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0112 - val_loss: 1.3632e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0102 - val_loss: 4.3417e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0086 - val_loss: 3.9396e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0077 - val_loss: 1.6711e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0072 - val_loss: 2.6701e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0065 - val_loss: 1.7929e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0059 - val_loss: 1.2474e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0054 - val_loss: 1.3569e-04\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0051 - val_loss: 1.4379e-04\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0048 - val_loss: 1.0176e-04\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0044 - val_loss: 2.6661e-04\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0043 - val_loss: 1.6709e-04\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0039 - val_loss: 1.3628e-04\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0038 - val_loss: 1.4009e-04\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0035 - val_loss: 2.1967e-04\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0033 - val_loss: 9.4673e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0031 - val_loss: 8.6932e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 6s 264us/step - loss: 0.0257 - val_loss: 1.9435e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0016 - val_loss: 5.7759e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0012 - val_loss: 4.1679e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 9.5913e-04 - val_loss: 3.3102e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.0598e-04 - val_loss: 3.6757e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 7.0899e-04 - val_loss: 3.7269e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 6.0704e-04 - val_loss: 3.1182e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 5.7510e-04 - val_loss: 2.8981e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 4.9755e-04 - val_loss: 6.1843e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 4.6331e-04 - val_loss: 2.9632e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 4.3088e-04 - val_loss: 4.8740e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 4.0562e-04 - val_loss: 2.5881e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 3.7468e-04 - val_loss: 2.6695e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 3.4980e-04 - val_loss: 2.5064e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 3.3607e-04 - val_loss: 3.3328e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 3.2404e-04 - val_loss: 2.4485e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 3.1711e-04 - val_loss: 3.7971e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.9945e-04 - val_loss: 3.2564e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.9009e-04 - val_loss: 2.9280e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.7875e-04 - val_loss: 3.8287e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.7017e-04 - val_loss: 3.0010e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.6490e-04 - val_loss: 3.0052e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.5679e-04 - val_loss: 2.7618e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.5307e-04 - val_loss: 2.6045e-05\n",
      "\n",
      "GENERATION 17\n",
      "\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 6s 270us/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 16us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: nan - val_loss: nan\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 6s 268us/step - loss: 0.0112 - val_loss: 3.1395e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0030 - val_loss: 5.1806e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0016 - val_loss: 6.6465e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 9.3253e-04 - val_loss: 4.2568e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 6.1201e-04 - val_loss: 4.0360e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 4.2486e-04 - val_loss: 3.8032e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 3.2379e-04 - val_loss: 3.7740e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 2.6951e-04 - val_loss: 3.7824e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.2724e-04 - val_loss: 3.6386e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.9302e-04 - val_loss: 3.3582e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.6557e-04 - val_loss: 3.3004e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.5077e-04 - val_loss: 3.2557e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.3761e-04 - val_loss: 3.1523e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.2233e-04 - val_loss: 3.2531e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.1610e-04 - val_loss: 3.1196e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.0885e-04 - val_loss: 2.9671e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.0277e-04 - val_loss: 2.9605e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 9.7903e-05 - val_loss: 2.8984e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 9.6203e-05 - val_loss: 2.8468e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 9.2197e-05 - val_loss: 2.7750e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.9129e-05 - val_loss: 2.7580e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.5234e-05 - val_loss: 2.6861e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.4762e-05 - val_loss: 2.5365e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.4085e-05 - val_loss: 2.4733e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 6s 274us/step - loss: 0.0276 - val_loss: 1.2481e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0051 - val_loss: 6.5161e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0026 - val_loss: 3.7166e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0017 - val_loss: 7.8257e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0012 - val_loss: 1.0173e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 9.2658e-04 - val_loss: 6.1673e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 7.4247e-04 - val_loss: 3.9026e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 6.2200e-04 - val_loss: 3.6247e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 5.0492e-04 - val_loss: 4.4045e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 4.4243e-04 - val_loss: 5.7552e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 3.8652e-04 - val_loss: 4.0105e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 3.3890e-04 - val_loss: 3.9520e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 3.0296e-04 - val_loss: 4.1067e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 2.6425e-04 - val_loss: 3.9622e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 2.3477e-04 - val_loss: 4.2585e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 2.2337e-04 - val_loss: 4.0221e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 2.0132e-04 - val_loss: 4.3621e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.8874e-04 - val_loss: 4.2021e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.8083e-04 - val_loss: 3.5951e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.7136e-04 - val_loss: 3.8141e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.6185e-04 - val_loss: 4.2687e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.5459e-04 - val_loss: 3.9735e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.4576e-04 - val_loss: 3.7233e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.4520e-04 - val_loss: 3.9443e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 6s 274us/step - loss: 0.0134 - val_loss: 5.8996e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0035 - val_loss: 2.0039e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0018 - val_loss: 9.7480e-05\n",
      "Epoch 4/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0011 - val_loss: 9.1476e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 7.1293e-04 - val_loss: 6.3927e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 5.1184e-04 - val_loss: 7.9760e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 3.8992e-04 - val_loss: 4.0765e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.0975e-04 - val_loss: 3.7175e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 2.4893e-04 - val_loss: 2.9771e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 2.0681e-04 - val_loss: 3.4175e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.7729e-04 - val_loss: 2.7316e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.5075e-04 - val_loss: 2.7570e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.3439e-04 - val_loss: 2.6769e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.2406e-04 - val_loss: 2.4755e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.1361e-04 - val_loss: 2.4162e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.0299e-04 - val_loss: 2.1664e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 9.3939e-05 - val_loss: 2.0369e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.6035e-05 - val_loss: 1.9662e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.6306e-05 - val_loss: 1.9624e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.0785e-05 - val_loss: 1.7689e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 7.5399e-05 - val_loss: 1.6601e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 7.5266e-05 - val_loss: 1.6419e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 7.9664e-05 - val_loss: 1.6239e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 6.8228e-05 - val_loss: 1.4499e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 6s 281us/step - loss: 0.0050 - val_loss: 3.6534e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0012 - val_loss: 9.7808e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 5.8356e-04 - val_loss: 5.3129e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 3.5777e-04 - val_loss: 4.6502e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 2.6563e-04 - val_loss: 3.7188e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 2.1840e-04 - val_loss: 3.4613e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.7846e-04 - val_loss: 3.8135e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.5840e-04 - val_loss: 3.2965e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.4299e-04 - val_loss: 3.3079e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.3083e-04 - val_loss: 3.4696e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.2320e-04 - val_loss: 3.5428e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.1607e-04 - val_loss: 3.5573e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.1081e-04 - val_loss: 3.2277e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.0527e-04 - val_loss: 3.4031e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.0323e-04 - val_loss: 3.1806e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.0114e-04 - val_loss: 2.9500e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 9.6854e-05 - val_loss: 3.5612e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 9.2862e-05 - val_loss: 3.0714e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.9935e-05 - val_loss: 2.9247e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7261e-05 - val_loss: 2.8748e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.5261e-05 - val_loss: 2.6657e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.3781e-05 - val_loss: 2.5286e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 7.5558e-05 - val_loss: 2.5151e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.1297e-05 - val_loss: 2.6031e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 6s 282us/step - loss: 0.0117 - val_loss: 1.6114e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0027 - val_loss: 1.1235e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0016 - val_loss: 8.6302e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0011 - val_loss: 1.0941e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.2936e-04 - val_loss: 7.5133e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 6.4466e-04 - val_loss: 8.0642e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 5.3044e-04 - val_loss: 6.5732e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 4.4380e-04 - val_loss: 5.4507e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 3.7994e-04 - val_loss: 6.3851e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 3.3446e-04 - val_loss: 5.0391e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 2.9101e-04 - val_loss: 3.3411e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 2.6957e-04 - val_loss: 4.0019e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 2.3940e-04 - val_loss: 4.0509e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 2.2124e-04 - val_loss: 3.8739e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.9697e-04 - val_loss: 3.8848e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.8326e-04 - val_loss: 3.7804e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.6878e-04 - val_loss: 3.1169e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.6038e-04 - val_loss: 3.2391e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.4772e-04 - val_loss: 3.3078e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.4200e-04 - val_loss: 3.1477e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.3169e-04 - val_loss: 3.1858e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.2633e-04 - val_loss: 3.1602e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.2066e-04 - val_loss: 3.1099e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.1444e-04 - val_loss: 3.1396e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 6s 287us/step - loss: 0.0250 - val_loss: 5.2791e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0062 - val_loss: 3.4219e-05\n",
      "Epoch 3/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0034 - val_loss: 3.7179e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0022 - val_loss: 3.3234e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0016 - val_loss: 5.0975e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0012 - val_loss: 5.9992e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.6638e-04 - val_loss: 4.0290e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.0054e-04 - val_loss: 4.1611e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 6.9419e-04 - val_loss: 3.6853e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 6.0443e-04 - val_loss: 3.6537e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 5.2970e-04 - val_loss: 3.2836e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 4.8002e-04 - val_loss: 3.4862e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 4.2131e-04 - val_loss: 3.8772e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 3.8842e-04 - val_loss: 3.2940e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.4393e-04 - val_loss: 3.0277e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.1662e-04 - val_loss: 3.1298e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 2.8856e-04 - val_loss: 3.1662e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 2.7253e-04 - val_loss: 3.2535e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 2.5512e-04 - val_loss: 3.0171e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 2.2892e-04 - val_loss: 3.6251e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 2.1933e-04 - val_loss: 3.2796e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 2.0714e-04 - val_loss: 3.0210e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.9255e-04 - val_loss: 3.0191e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.8909e-04 - val_loss: 3.0287e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 6s 292us/step - loss: 0.0150 - val_loss: 9.9040e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0030 - val_loss: 1.2026e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0017 - val_loss: 1.3498e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0011 - val_loss: 3.8517e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.1027e-04 - val_loss: 5.7206e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 6.1480e-04 - val_loss: 3.8040e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 5.1118e-04 - val_loss: 3.4582e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 4.2150e-04 - val_loss: 3.1561e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 3.5612e-04 - val_loss: 3.4788e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 3.1366e-04 - val_loss: 3.3774e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 2.7897e-04 - val_loss: 3.1868e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 2.5106e-04 - val_loss: 3.3058e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 2.3064e-04 - val_loss: 3.1485e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 2.2011e-04 - val_loss: 3.1802e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 2.0391e-04 - val_loss: 3.2217e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.9463e-04 - val_loss: 3.1697e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.8491e-04 - val_loss: 3.1594e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.8208e-04 - val_loss: 3.2127e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.6898e-04 - val_loss: 3.7522e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.6312e-04 - val_loss: 3.3769e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.5709e-04 - val_loss: 3.2582e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.5306e-04 - val_loss: 3.1723e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.4792e-04 - val_loss: 3.2315e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.4029e-04 - val_loss: 3.7448e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 6s 297us/step - loss: 0.0215 - val_loss: 4.9797e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0041 - val_loss: 4.3565e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0023 - val_loss: 4.1152e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0015 - val_loss: 4.1125e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0011 - val_loss: 3.1796e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.1429e-04 - val_loss: 4.2962e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 6.4946e-04 - val_loss: 3.1070e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 5.3220e-04 - val_loss: 3.6076e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 4.4657e-04 - val_loss: 3.2185e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 3.8426e-04 - val_loss: 4.0316e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 3.4113e-04 - val_loss: 3.5018e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 2.9824e-04 - val_loss: 3.0633e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 2.7171e-04 - val_loss: 3.0491e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 2.4375e-04 - val_loss: 3.3565e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 2.2081e-04 - val_loss: 3.0939e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 2.0601e-04 - val_loss: 3.0199e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.9306e-04 - val_loss: 3.0490e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.7901e-04 - val_loss: 3.0016e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.6622e-04 - val_loss: 3.0001e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.5931e-04 - val_loss: 3.0957e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.4543e-04 - val_loss: 2.9900e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.3818e-04 - val_loss: 3.0078e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.3175e-04 - val_loss: 2.9543e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.2188e-04 - val_loss: 2.8521e-05\n",
      "\n",
      "GENERATION 18\n",
      "\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 6s 299us/step - loss: 0.0167 - val_loss: 5.9691e-04\n",
      "Epoch 2/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0039 - val_loss: 2.5720e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0020 - val_loss: 8.5396e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0013 - val_loss: 1.1032e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 9.2638e-04 - val_loss: 1.0850e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 7.1730e-04 - val_loss: 4.0109e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 5.8241e-04 - val_loss: 4.9701e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 4.8873e-04 - val_loss: 3.4577e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 4.1028e-04 - val_loss: 3.7148e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 3.5313e-04 - val_loss: 3.1867e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 2.9897e-04 - val_loss: 3.1515e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 2.6901e-04 - val_loss: 3.5017e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 2.2633e-04 - val_loss: 2.9894e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 2.0003e-04 - val_loss: 3.5209e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.7740e-04 - val_loss: 2.8144e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.6143e-04 - val_loss: 2.9361e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.4822e-04 - val_loss: 2.8465e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.4246e-04 - val_loss: 2.8122e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.2804e-04 - val_loss: 2.7298e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.1738e-04 - val_loss: 2.6484e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.1277e-04 - val_loss: 2.6545e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.0321e-04 - val_loss: 2.5156e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.0069e-04 - val_loss: 2.5243e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 9.4342e-05 - val_loss: 2.3961e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 6s 299us/step - loss: 0.0169 - val_loss: 1.6082e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0034 - val_loss: 8.3686e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0017 - val_loss: 3.4506e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.9255e-04 - val_loss: 4.6986e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 6.9053e-04 - val_loss: 6.0334e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 5.2300e-04 - val_loss: 4.2213e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 4.1124e-04 - val_loss: 3.6814e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 3.3627e-04 - val_loss: 3.8693e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 2.7926e-04 - val_loss: 3.0944e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 2.4034e-04 - val_loss: 3.3243e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 2.1829e-04 - val_loss: 3.1033e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.8754e-04 - val_loss: 2.8652e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.6805e-04 - val_loss: 3.0547e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.5284e-04 - val_loss: 3.1593e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.3922e-04 - val_loss: 3.0096e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.2749e-04 - val_loss: 2.7583e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.2367e-04 - val_loss: 2.5572e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.1637e-04 - val_loss: 2.8667e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.0254e-04 - val_loss: 2.4913e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.3253e-05 - val_loss: 2.5220e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 9.5849e-05 - val_loss: 2.5099e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.9265e-05 - val_loss: 2.3222e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.0970e-05 - val_loss: 2.2302e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 7.8394e-05 - val_loss: 2.2048e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 7s 310us/step - loss: 0.0101 - val_loss: 2.2212e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0018 - val_loss: 3.5026e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.5427e-04 - val_loss: 4.2305e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 5.3910e-04 - val_loss: 3.7188e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 3.9643e-04 - val_loss: 3.6510e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 3.1774e-04 - val_loss: 3.7348e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 2.6762e-04 - val_loss: 3.2738e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 2.3133e-04 - val_loss: 3.0827e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 2.0578e-04 - val_loss: 2.9904e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.9046e-04 - val_loss: 3.5667e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.6883e-04 - val_loss: 3.2335e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.5582e-04 - val_loss: 2.8848e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.4585e-04 - val_loss: 3.3046e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.3571e-04 - val_loss: 3.0222e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.3128e-04 - val_loss: 2.8111e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.2123e-04 - val_loss: 2.8002e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.1224e-04 - val_loss: 2.8999e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.0789e-04 - val_loss: 2.7308e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.7012e-05 - val_loss: 2.7910e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.2333e-05 - val_loss: 2.6503e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.8219e-05 - val_loss: 2.6354e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.3585e-05 - val_loss: 2.5010e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.5560e-05 - val_loss: 2.4403e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 7.9536e-05 - val_loss: 2.3458e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 7s 314us/step - loss: 0.0149 - val_loss: 8.6595e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 1.7390e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0021 - val_loss: 1.3610e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0013 - val_loss: 5.2684e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.4021e-04 - val_loss: 4.5090e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 6.9732e-04 - val_loss: 3.1924e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 5.5608e-04 - val_loss: 4.0853e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 4.5101e-04 - val_loss: 3.5556e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 3.8727e-04 - val_loss: 3.1877e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 3.3764e-04 - val_loss: 3.1426e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 3.0253e-04 - val_loss: 3.3131e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 2.7575e-04 - val_loss: 3.4400e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 2.4575e-04 - val_loss: 3.2860e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 2.3422e-04 - val_loss: 3.5486e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 2.2669e-04 - val_loss: 3.3371e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 2.1128e-04 - val_loss: 3.5723e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.0782e-04 - val_loss: 3.3922e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 1.9522e-04 - val_loss: 3.5234e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.8956e-04 - val_loss: 3.3357e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.8011e-04 - val_loss: 3.7625e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.7304e-04 - val_loss: 3.2177e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.7367e-04 - val_loss: 3.3416e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.6338e-04 - val_loss: 3.3835e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.6064e-04 - val_loss: 3.1508e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 7s 313us/step - loss: 0.0108 - val_loss: 4.1730e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0024 - val_loss: 3.2438e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0013 - val_loss: 1.6447e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 9.3806e-04 - val_loss: 1.3777e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 6.7920e-04 - val_loss: 1.0037e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 5.3909e-04 - val_loss: 6.2350e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 4.2769e-04 - val_loss: 5.0496e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 3.5807e-04 - val_loss: 3.8654e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 3.1799e-04 - val_loss: 3.5896e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 2.7941e-04 - val_loss: 3.4421e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 2.5629e-04 - val_loss: 3.5864e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 2.3209e-04 - val_loss: 3.2298e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 2.1547e-04 - val_loss: 3.1576e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 2.0196e-04 - val_loss: 3.1261e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.9374e-04 - val_loss: 3.1538e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 1.8342e-04 - val_loss: 3.1347e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.7130e-04 - val_loss: 3.1530e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.6779e-04 - val_loss: 3.3737e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.6195e-04 - val_loss: 3.1318e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 1.5539e-04 - val_loss: 3.1159e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 1.5154e-04 - val_loss: 3.1333e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.4398e-04 - val_loss: 3.2410e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.4072e-04 - val_loss: 3.1717e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.3841e-04 - val_loss: 3.2058e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 7s 311us/step - loss: 0.0233 - val_loss: 1.8491e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0178 - val_loss: 1.4790e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0153 - val_loss: 1.5277e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0134 - val_loss: 7.8493e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0119 - val_loss: 9.1821e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0108 - val_loss: 6.2540e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0098 - val_loss: 8.0490e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 0.0090 - val_loss: 7.9242e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 0.0082 - val_loss: 7.1129e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0077 - val_loss: 7.1800e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0073 - val_loss: 5.3976e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0068 - val_loss: 8.2411e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0063 - val_loss: 5.4233e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0059 - val_loss: 5.5466e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0057 - val_loss: 5.5795e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0053 - val_loss: 5.7896e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0051 - val_loss: 4.4180e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0048 - val_loss: 4.8986e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0047 - val_loss: 4.7736e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0045 - val_loss: 5.2982e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0042 - val_loss: 4.3627e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0041 - val_loss: 4.7617e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0040 - val_loss: 4.9620e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0038 - val_loss: 5.3270e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 7s 348us/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 23us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: nan - val_loss: nan\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 7s 327us/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: nan - val_loss: nan\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 7s 331us/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: nan - val_loss: nan\n",
      "\n",
      "GENERATION 19\n",
      "\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 7s 331us/step - loss: 0.0217 - val_loss: 0.0028\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0049 - val_loss: 0.0012\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0026 - val_loss: 7.7538e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0017 - val_loss: 4.2313e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0012 - val_loss: 3.8807e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.7237e-04 - val_loss: 1.5688e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 6.9686e-04 - val_loss: 9.0527e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 5.6524e-04 - val_loss: 9.7636e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.8075e-04 - val_loss: 5.1397e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.1921e-04 - val_loss: 4.7056e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.6986e-04 - val_loss: 3.8159e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - ETA: 0s - loss: 3.3669e-0 - 0s 20us/step - loss: 3.3340e-04 - val_loss: 3.7095e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.0529e-04 - val_loss: 3.1505e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.7844e-04 - val_loss: 3.9520e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.6078e-04 - val_loss: 3.1184e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.4425e-04 - val_loss: 3.1286e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.3006e-04 - val_loss: 3.3141e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.1808e-04 - val_loss: 3.3319e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.1231e-04 - val_loss: 4.3085e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.0022e-04 - val_loss: 3.2769e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.9274e-04 - val_loss: 3.1579e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.8697e-04 - val_loss: 3.2309e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.7790e-04 - val_loss: 3.5044e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.7289e-04 - val_loss: 3.3760e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 7s 330us/step - loss: 0.0239 - val_loss: 1.8310e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0050 - val_loss: 5.8548e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0023 - val_loss: 4.8527e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0014 - val_loss: 5.6623e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.8415e-04 - val_loss: 3.9650e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 7.2368e-04 - val_loss: 3.8404e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 5.8763e-04 - val_loss: 3.7417e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.8462e-04 - val_loss: 3.6076e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.9280e-04 - val_loss: 3.1171e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.4114e-04 - val_loss: 3.0213e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 2.9709e-04 - val_loss: 3.1404e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.6964e-04 - val_loss: 2.8169e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 2.3375e-04 - val_loss: 2.8548e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.1203e-04 - val_loss: 2.5582e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 2.0135e-04 - val_loss: 2.5063e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 1.7083e-04 - val_loss: 2.4162e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 1.5987e-04 - val_loss: 2.3346e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 1.4954e-04 - val_loss: 2.3256e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.3328e-04 - val_loss: 2.2261e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.2408e-04 - val_loss: 2.0689e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.1691e-04 - val_loss: 1.9530e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 1.0271e-04 - val_loss: 1.8991e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.4821e-05 - val_loss: 2.3956e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.0150e-04 - val_loss: 1.9173e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 7s 333us/step - loss: 0.0433 - val_loss: 5.7280e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0341 - val_loss: 4.3977e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0281 - val_loss: 2.9334e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0230 - val_loss: 2.3364e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0198 - val_loss: 1.9967e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0170 - val_loss: 1.7223e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0152 - val_loss: 1.4727e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0136 - val_loss: 1.8301e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0122 - val_loss: 1.3801e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0112 - val_loss: 1.2820e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0103 - val_loss: 1.3420e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0093 - val_loss: 1.4354e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0085 - val_loss: 1.3184e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0080 - val_loss: 1.3035e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0077 - val_loss: 1.3132e-04\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0071 - val_loss: 1.0813e-04\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0066 - val_loss: 1.4586e-04\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0063 - val_loss: 1.3407e-04\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0059 - val_loss: 1.1992e-04\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0057 - val_loss: 1.1992e-04\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0054 - val_loss: 1.2446e-04\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0051 - val_loss: 1.1515e-04\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0050 - val_loss: 1.2530e-04\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0048 - val_loss: 1.0977e-04\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 7s 332us/step - loss: 0.0155 - val_loss: 6.3702e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0049 - val_loss: 3.9026e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0032 - val_loss: 4.4632e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0025 - val_loss: 3.3061e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0020 - val_loss: 2.4879e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 0.0016 - val_loss: 2.0957e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0014 - val_loss: 2.1963e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0011 - val_loss: 1.3525e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0010 - val_loss: 9.0804e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8266e-04 - val_loss: 7.6343e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 7.8371e-04 - val_loss: 7.4253e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 7.0408e-04 - val_loss: 5.4207e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 6.1824e-04 - val_loss: 4.8643e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 5.7375e-04 - val_loss: 5.2206e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 5.1888e-04 - val_loss: 4.8722e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 4.7108e-04 - val_loss: 4.5571e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 4.2957e-04 - val_loss: 4.4236e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.9804e-04 - val_loss: 4.4068e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 3.6842e-04 - val_loss: 4.6847e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 3.4053e-04 - val_loss: 4.2839e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 3.2083e-04 - val_loss: 4.1237e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.9018e-04 - val_loss: 3.8190e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 2.8021e-04 - val_loss: 3.6520e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 2.5450e-04 - val_loss: 3.9621e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 7s 335us/step - loss: 0.0135 - val_loss: 5.4148e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0042 - val_loss: 1.0523e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0030 - val_loss: 1.6010e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0022 - val_loss: 1.5998e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0018 - val_loss: 2.0421e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0015 - val_loss: 1.6017e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0012 - val_loss: 9.8756e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0011 - val_loss: 9.5892e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 9.2857e-04 - val_loss: 8.1128e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.3052e-04 - val_loss: 9.6520e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 7.3373e-04 - val_loss: 7.3297e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 6.6034e-04 - val_loss: 9.2822e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 6.1875e-04 - val_loss: 7.4547e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 5.6086e-04 - val_loss: 6.3332e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 5.2193e-04 - val_loss: 4.2046e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.7390e-04 - val_loss: 5.1659e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 4.4269e-04 - val_loss: 4.8107e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 4.1178e-04 - val_loss: 3.7962e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 3.9452e-04 - val_loss: 3.2788e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 3.6696e-04 - val_loss: 3.1716e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 3.4489e-04 - val_loss: 3.1093e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 3.3334e-04 - val_loss: 3.0580e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 3.1514e-04 - val_loss: 3.0075e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.9520e-04 - val_loss: 2.9955e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 7s 341us/step - loss: 0.0270 - val_loss: 9.0639e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0078 - val_loss: 1.0447e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0051 - val_loss: 7.1217e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0039 - val_loss: 6.0165e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0031 - val_loss: 7.3978e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0025 - val_loss: 6.8147e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0022 - val_loss: 5.6769e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0019 - val_loss: 5.3992e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0017 - val_loss: 5.7404e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0015 - val_loss: 7.3069e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0014 - val_loss: 6.0679e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0012 - val_loss: 5.3849e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0011 - val_loss: 5.1688e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0010 - val_loss: 4.7499e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 9.3520e-04 - val_loss: 4.2912e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.7556e-04 - val_loss: 4.2644e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.3261e-04 - val_loss: 4.6898e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 7.5514e-04 - val_loss: 4.1307e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 7.1211e-04 - val_loss: 4.7106e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 6.7267e-04 - val_loss: 4.3435e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 6.4917e-04 - val_loss: 3.7933e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 5.9315e-04 - val_loss: 3.6479e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 5.6063e-04 - val_loss: 3.6696e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 5.3388e-04 - val_loss: 3.4656e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 7s 345us/step - loss: 0.0090 - val_loss: 1.2871e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0031 - val_loss: 1.1648e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0021 - val_loss: 7.3968e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0015 - val_loss: 1.1380e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0012 - val_loss: 1.0395e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 9.7555e-04 - val_loss: 1.1087e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.2505e-04 - val_loss: 8.7129e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 6.9701e-04 - val_loss: 8.1160e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 6.0789e-04 - val_loss: 9.9793e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 5.4911e-04 - val_loss: 8.6194e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 4.7701e-04 - val_loss: 8.2780e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 4.3564e-04 - val_loss: 9.7710e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 3.9361e-04 - val_loss: 7.4224e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.5943e-04 - val_loss: 8.0051e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 3.2913e-04 - val_loss: 8.1034e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 3.0819e-04 - val_loss: 8.2839e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.8356e-04 - val_loss: 6.5460e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.6742e-04 - val_loss: 7.1279e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 2.5076e-04 - val_loss: 5.8298e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 2.3875e-04 - val_loss: 4.9196e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 2.2176e-04 - val_loss: 4.9418e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 2.1203e-04 - val_loss: 5.4187e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 1.9617e-04 - val_loss: 5.1603e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 1.9024e-04 - val_loss: 4.0512e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 7s 342us/step - loss: 0.0303 - val_loss: 8.3373e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0084 - val_loss: 7.5276e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0066 - val_loss: 8.0704e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0052 - val_loss: 5.4723e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0045 - val_loss: 7.6275e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0038 - val_loss: 8.5671e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0033 - val_loss: 5.9584e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 0.0028 - val_loss: 4.8088e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 0.0025 - val_loss: 7.2857e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0022 - val_loss: 5.3055e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0019 - val_loss: 4.9868e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0018 - val_loss: 5.1506e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0016 - val_loss: 6.9366e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0014 - val_loss: 5.8084e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0013 - val_loss: 8.2183e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0012 - val_loss: 8.5006e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0011 - val_loss: 6.5619e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0010 - val_loss: 6.2054e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.4315e-04 - val_loss: 4.4204e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.6492e-04 - val_loss: 4.3465e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.1980e-04 - val_loss: 4.8352e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 7.5313e-04 - val_loss: 4.2334e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 7.0086e-04 - val_loss: 4.7905e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 6.5103e-04 - val_loss: 4.4159e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 7s 349us/step - loss: 0.3509 - val_loss: 0.0033\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0870 - val_loss: 4.4794e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0567 - val_loss: 0.0022\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0422 - val_loss: 0.0023\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0333 - val_loss: 0.0010\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0270 - val_loss: 0.0014\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0221 - val_loss: 9.9676e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0189 - val_loss: 0.0013\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0168 - val_loss: 9.9066e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0148 - val_loss: 8.3475e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0131 - val_loss: 6.2270e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0118 - val_loss: 5.2780e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0107 - val_loss: 5.2533e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0097 - val_loss: 6.2355e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0089 - val_loss: 6.2737e-04\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 0.0081 - val_loss: 3.9614e-04\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 0.0075 - val_loss: 2.3344e-04\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 0.0069 - val_loss: 2.0648e-04\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0063 - val_loss: 2.4991e-04\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0059 - val_loss: 2.2671e-04\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0055 - val_loss: 1.3749e-04\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0050 - val_loss: 8.9992e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0046 - val_loss: 1.4287e-04\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0044 - val_loss: 9.1453e-05\n"
     ]
    }
   ],
   "source": [
    "best_models = breed_population(X_train, Y_train, generations=20, population_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.00014578905102220337,\n",
       " 5.324250623964949e-05,\n",
       " 4.012273837487687e-05,\n",
       " 3.502018207944752e-05,\n",
       " 3.330115027713889e-05,\n",
       " 3.511103870187986e-05,\n",
       " 3.3601509853392936e-05,\n",
       " 2.7667172159514137e-05,\n",
       " 2.8690636981069248e-05,\n",
       " 2.5271549512266405e-05,\n",
       " 4.0283382234985905e-05,\n",
       " 2.5433455736536672e-05,\n",
       " 2.1910266929349953e-05,\n",
       " 2.060753085101556e-05,\n",
       " 2.013804340335699e-05,\n",
       " 1.9526027911167032e-05,\n",
       " 1.901653664551944e-05,\n",
       " 1.8019791273405066e-05,\n",
       " 1.7642038334318516e-05,\n",
       " 1.6626616602857138e-05,\n",
       " 1.8475294844359375e-05,\n",
       " 1.5493819311466513e-05,\n",
       " 1.4336143881158039e-05,\n",
       " 1.4400636469889324e-05]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models[0][1].history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal parameters\n",
      "_______________________\n",
      "density: 72\n",
      "activation: softsign\n",
      "shuffle: True\n",
      "dropout: 0.2\n",
      "optimizer: adam\n"
     ]
    }
   ],
   "source": [
    "print('optimal parameters')\n",
    "print('_______________________')\n",
    "for key,val in best_models[0][2].items():\n",
    "    if key != 'x' and key != 'y': print(f'{key}: {val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_75\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_355 (Dense)            (None, 72)                7272      \n",
      "_________________________________________________________________\n",
      "dropout_207 (Dropout)        (None, 72)                0         \n",
      "_________________________________________________________________\n",
      "dense_356 (Dense)            (None, 36)                2628      \n",
      "_________________________________________________________________\n",
      "dropout_208 (Dropout)        (None, 36)                0         \n",
      "_________________________________________________________________\n",
      "dense_357 (Dense)            (None, 18)                666       \n",
      "_________________________________________________________________\n",
      "dense_358 (Dense)            (None, 1)                 19        \n",
      "=================================================================\n",
      "Total params: 10,585\n",
      "Trainable params: 10,585\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_models[0][0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\n",
    "    filepath='./checkpoints/fundamental.{epoch}-{val_loss}.hdf5',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = best_models[0][2]\n",
    "params['x'] = X_train\n",
    "params['y'] = Y_train\n",
    "params['epochs'] = 2000\n",
    "params['callbacks'] = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/2000\n",
      "21471/21471 [==============================] - 7s 349us/step - loss: 0.0201 - val_loss: 1.9579e-04\n",
      "Epoch 2/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0043 - val_loss: 2.0349e-04\n",
      "Epoch 3/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0024 - val_loss: 1.2635e-04\n",
      "Epoch 4/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0015 - val_loss: 1.0517e-04\n",
      "Epoch 5/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0011 - val_loss: 6.7393e-05\n",
      "Epoch 6/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.5102e-04 - val_loss: 4.7601e-05\n",
      "Epoch 7/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 6.7104e-04 - val_loss: 4.0687e-05\n",
      "Epoch 8/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 5.3943e-04 - val_loss: 3.9438e-05\n",
      "Epoch 9/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 4.4265e-04 - val_loss: 4.6126e-05\n",
      "Epoch 10/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.8261e-04 - val_loss: 3.5820e-05\n",
      "Epoch 11/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.3466e-04 - val_loss: 4.2242e-05\n",
      "Epoch 12/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.9442e-04 - val_loss: 3.0741e-05\n",
      "Epoch 13/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.7005e-04 - val_loss: 2.9164e-05\n",
      "Epoch 14/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.4194e-04 - val_loss: 2.9905e-05\n",
      "Epoch 15/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.1644e-04 - val_loss: 3.8398e-05\n",
      "Epoch 16/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.9725e-04 - val_loss: 3.1011e-05\n",
      "Epoch 17/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.8079e-04 - val_loss: 3.7827e-05\n",
      "Epoch 18/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.7433e-04 - val_loss: 2.9024e-05\n",
      "Epoch 19/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.6184e-04 - val_loss: 2.9400e-05\n",
      "Epoch 20/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.4339e-04 - val_loss: 2.8671e-05\n",
      "Epoch 21/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.4646e-04 - val_loss: 2.8467e-05\n",
      "Epoch 22/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.2983e-04 - val_loss: 2.8766e-05\n",
      "Epoch 23/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.2760e-04 - val_loss: 2.6999e-05\n",
      "Epoch 24/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.0734e-04 - val_loss: 2.7934e-05\n",
      "Epoch 25/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.0825e-04 - val_loss: 2.8525e-05\n",
      "Epoch 26/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.0549e-04 - val_loss: 2.6143e-05\n",
      "Epoch 27/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.2027e-05 - val_loss: 2.6880e-05\n",
      "Epoch 28/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.1026e-05 - val_loss: 2.6118e-05\n",
      "Epoch 29/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0831e-05 - val_loss: 2.5243e-05\n",
      "Epoch 30/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.4348e-05 - val_loss: 2.2928e-05\n",
      "Epoch 31/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.3180e-05 - val_loss: 2.2522e-05\n",
      "Epoch 32/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 7.0255e-05 - val_loss: 2.1345e-05\n",
      "Epoch 33/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 6.5184e-05 - val_loss: 1.9802e-05\n",
      "Epoch 34/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 5.9879e-05 - val_loss: 1.9156e-05\n",
      "Epoch 35/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 5.9917e-05 - val_loss: 1.8139e-05\n",
      "Epoch 36/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 5.2144e-05 - val_loss: 1.6057e-05\n",
      "Epoch 37/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 6.0171e-05 - val_loss: 1.5504e-05\n",
      "Epoch 38/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 6.2816e-05 - val_loss: 1.6520e-05\n",
      "Epoch 39/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.7406e-05 - val_loss: 1.6424e-05\n",
      "Epoch 40/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 5.1353e-05 - val_loss: 1.3538e-05\n",
      "Epoch 41/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.2521e-05 - val_loss: 1.2504e-05\n",
      "Epoch 42/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.2517e-05 - val_loss: 1.1184e-05\n",
      "Epoch 43/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.3537e-05 - val_loss: 1.3708e-05\n",
      "Epoch 44/2000\n",
      "21471/21471 [==============================] - 1s 23us/step - loss: 4.3166e-05 - val_loss: 9.9611e-06\n",
      "Epoch 45/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.2436e-05 - val_loss: 9.7372e-06\n",
      "Epoch 46/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.1523e-05 - val_loss: 1.0270e-05\n",
      "Epoch 47/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 4.3358e-05 - val_loss: 9.4934e-06\n",
      "Epoch 48/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 3.6860e-05 - val_loss: 7.6455e-06\n",
      "Epoch 49/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 3.1778e-05 - val_loss: 1.0000e-05\n",
      "Epoch 50/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.3992e-05 - val_loss: 7.6797e-06\n",
      "Epoch 51/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 3.3314e-05 - val_loss: 9.4037e-06\n",
      "Epoch 52/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 3.6579e-05 - val_loss: 7.4810e-06\n",
      "Epoch 53/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 2.8917e-05 - val_loss: 6.8667e-06\n",
      "Epoch 54/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.1560e-05 - val_loss: 6.7382e-06\n",
      "Epoch 55/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.4644e-05 - val_loss: 8.4138e-06\n",
      "Epoch 56/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 2.5216e-05 - val_loss: 6.5808e-06\n",
      "Epoch 57/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 3.9517e-05 - val_loss: 7.3936e-06\n",
      "Epoch 58/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.9004e-05 - val_loss: 5.6997e-06\n",
      "Epoch 59/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.7127e-05 - val_loss: 6.1477e-06\n",
      "Epoch 60/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 2.1816e-05 - val_loss: 5.9275e-06\n",
      "Epoch 61/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 2.6148e-05 - val_loss: 5.9663e-06\n",
      "Epoch 62/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.0439e-05 - val_loss: 6.5473e-06\n",
      "Epoch 63/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.9837e-05 - val_loss: 6.5164e-06\n",
      "Epoch 64/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.7716e-05 - val_loss: 5.9571e-06\n",
      "Epoch 65/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.3804e-05 - val_loss: 6.8622e-06\n",
      "Epoch 66/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.0868e-05 - val_loss: 5.7962e-06\n",
      "Epoch 67/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.9246e-05 - val_loss: 6.1894e-06\n",
      "Epoch 68/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.8482e-05 - val_loss: 6.6112e-06\n",
      "Epoch 69/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.2607e-05 - val_loss: 6.2032e-06\n",
      "Epoch 70/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.4530e-05 - val_loss: 5.6582e-06\n",
      "Epoch 71/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.9430e-05 - val_loss: 5.9507e-06\n",
      "Epoch 72/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.2248e-05 - val_loss: 6.6931e-06\n",
      "Epoch 73/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.6722e-05 - val_loss: 5.9565e-06\n",
      "Epoch 74/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.0112e-05 - val_loss: 5.9132e-06\n",
      "Epoch 75/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.8780e-05 - val_loss: 5.8688e-06\n",
      "Epoch 76/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.1776e-05 - val_loss: 5.8686e-06\n",
      "Epoch 77/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.4328e-05 - val_loss: 5.9164e-06\n",
      "Epoch 78/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 2.5380e-05 - val_loss: 6.0477e-06\n",
      "Epoch 79/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 3.4094e-05 - val_loss: 8.4382e-06\n",
      "Epoch 80/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.2583e-05 - val_loss: 5.9855e-06\n",
      "Epoch 81/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.0720e-05 - val_loss: 6.8140e-06\n",
      "Epoch 82/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 1.6956e-05 - val_loss: 5.7856e-06\n",
      "Epoch 83/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.6235e-05 - val_loss: 6.1853e-06\n",
      "Epoch 84/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.8437e-05 - val_loss: 6.3819e-06\n",
      "Epoch 85/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.7543e-05 - val_loss: 6.3237e-06\n",
      "Epoch 86/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.6433e-05 - val_loss: 6.0652e-06\n",
      "Epoch 87/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.9544e-05 - val_loss: 5.8221e-06\n",
      "Epoch 88/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.5664e-05 - val_loss: 5.4891e-06\n",
      "Epoch 89/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.3889e-05 - val_loss: 5.5978e-06\n",
      "Epoch 90/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.3705e-05 - val_loss: 7.5907e-06\n",
      "Epoch 91/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.2316e-05 - val_loss: 4.8021e-06\n",
      "Epoch 92/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.3700e-05 - val_loss: 5.5704e-06\n",
      "Epoch 93/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.6479e-05 - val_loss: 5.1537e-06\n",
      "Epoch 94/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.7978e-05 - val_loss: 6.1786e-06\n",
      "Epoch 95/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 1.3960e-05 - val_loss: 5.9143e-06\n",
      "Epoch 96/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 2.6856e-05 - val_loss: 5.9897e-06\n",
      "Epoch 97/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 2.3706e-05 - val_loss: 5.4708e-06\n",
      "Epoch 98/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.3647e-05 - val_loss: 5.5254e-06\n",
      "Epoch 99/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.4878e-05 - val_loss: 5.7176e-06\n",
      "Epoch 100/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.3342e-05 - val_loss: 6.8224e-06\n",
      "Epoch 101/2000\n",
      "21471/21471 [==============================] - 0s 23us/step - loss: 2.0123e-05 - val_loss: 5.4496e-06\n",
      "Epoch 102/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.1284e-05 - val_loss: 5.0332e-06\n",
      "Epoch 103/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.6947e-05 - val_loss: 5.9742e-06\n",
      "Epoch 104/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.6296e-05 - val_loss: 5.6875e-06\n",
      "Epoch 105/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.3766e-05 - val_loss: 5.9805e-06\n",
      "Epoch 106/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.7751e-05 - val_loss: 4.8978e-06\n",
      "Epoch 107/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.2760e-05 - val_loss: 4.9379e-06\n",
      "Epoch 108/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.4161e-05 - val_loss: 4.5485e-06\n",
      "Epoch 109/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.8743e-05 - val_loss: 6.0376e-06\n",
      "Epoch 110/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.2717e-05 - val_loss: 5.4795e-06\n",
      "Epoch 111/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.6197e-05 - val_loss: 6.3667e-06\n",
      "Epoch 112/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.6211e-05 - val_loss: 5.4115e-06\n",
      "Epoch 113/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.6315e-05 - val_loss: 5.8655e-06\n",
      "Epoch 114/2000\n",
      "21471/21471 [==============================] - 0s 23us/step - loss: 1.6950e-05 - val_loss: 8.1617e-06\n",
      "Epoch 115/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 1.6644e-05 - val_loss: 1.1166e-05\n",
      "Epoch 116/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.3337e-05 - val_loss: 4.8800e-06\n",
      "Epoch 117/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 1.3198e-05 - val_loss: 5.6378e-06\n",
      "Epoch 118/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.2664e-05 - val_loss: 7.5424e-06\n",
      "Epoch 119/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.8036e-05 - val_loss: 6.2974e-06\n",
      "Epoch 120/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.1519e-05 - val_loss: 7.1753e-06\n",
      "Epoch 121/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.3506e-05 - val_loss: 4.6624e-06\n",
      "Epoch 122/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.3820e-06 - val_loss: 5.0450e-06\n",
      "Epoch 123/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.4081e-05 - val_loss: 7.1281e-06\n",
      "Epoch 124/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.2597e-05 - val_loss: 6.1383e-06\n",
      "Epoch 125/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.7152e-05 - val_loss: 7.0777e-06\n",
      "Epoch 126/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.4424e-05 - val_loss: 6.9433e-06\n",
      "Epoch 127/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.2793e-05 - val_loss: 6.6250e-06\n",
      "Epoch 128/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.6019e-05 - val_loss: 8.7488e-06\n",
      "Epoch 129/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.0892e-05 - val_loss: 9.3504e-06\n",
      "Epoch 130/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.2554e-05 - val_loss: 6.1978e-06\n",
      "Epoch 131/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.5736e-05 - val_loss: 5.8846e-06\n",
      "Epoch 132/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.0200e-05 - val_loss: 6.2067e-06\n",
      "Epoch 133/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.9486e-05 - val_loss: 7.2374e-06\n",
      "Epoch 134/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 1.3178e-05 - val_loss: 5.3970e-06\n",
      "Epoch 135/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.3867e-05 - val_loss: 5.3725e-06\n",
      "Epoch 136/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.5356e-05 - val_loss: 5.7530e-06\n",
      "Epoch 137/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.3818e-05 - val_loss: 6.2842e-06\n",
      "Epoch 138/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.8686e-05 - val_loss: 6.2282e-06\n",
      "Epoch 139/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.5412e-05 - val_loss: 5.1704e-06\n",
      "Epoch 140/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.7981e-05 - val_loss: 7.3034e-06\n",
      "Epoch 141/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.0393e-05 - val_loss: 5.9448e-06\n",
      "Epoch 142/2000\n",
      "21471/21471 [==============================] - ETA: 0s - loss: 2.0592e-0 - 0s 20us/step - loss: 1.9147e-05 - val_loss: 6.3311e-06\n",
      "Epoch 143/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.4681e-05 - val_loss: 5.0482e-06\n",
      "Epoch 144/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.1403e-05 - val_loss: 4.6080e-06\n",
      "Epoch 145/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.2006e-05 - val_loss: 6.3057e-06\n",
      "Epoch 146/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.9227e-05 - val_loss: 5.6504e-06\n",
      "Epoch 147/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.8090e-05 - val_loss: 4.4126e-06\n",
      "Epoch 148/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.3190e-05 - val_loss: 7.6917e-06\n",
      "Epoch 149/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 1.5377e-05 - val_loss: 6.1545e-06\n",
      "Epoch 150/2000\n",
      "21471/21471 [==============================] - 1s 24us/step - loss: 1.0699e-05 - val_loss: 5.4267e-06\n",
      "Epoch 151/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.0362e-05 - val_loss: 5.9306e-06\n",
      "Epoch 152/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 7.3547e-06 - val_loss: 5.3778e-06\n",
      "Epoch 153/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.4926e-04 - val_loss: 4.9930e-05\n",
      "Epoch 154/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 3.8409e-05 - val_loss: 5.3616e-06\n",
      "Epoch 155/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.5778e-05 - val_loss: 4.8268e-06\n",
      "Epoch 156/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.1318e-05 - val_loss: 5.9810e-06\n",
      "Epoch 157/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.1988e-05 - val_loss: 5.8688e-06\n",
      "Epoch 158/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.5365e-05 - val_loss: 4.6966e-06\n",
      "Epoch 159/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.5713e-06 - val_loss: 3.9975e-06\n",
      "Epoch 160/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.0270e-05 - val_loss: 4.3054e-06\n",
      "Epoch 161/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 7.9536e-06 - val_loss: 4.1608e-06\n",
      "Epoch 162/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 2.0447e-05 - val_loss: 4.3731e-06\n",
      "Epoch 163/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.1442e-05 - val_loss: 4.1627e-06\n",
      "Epoch 164/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 7.1479e-06 - val_loss: 4.5764e-06\n",
      "Epoch 165/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.0666e-05 - val_loss: 4.8890e-06\n",
      "Epoch 166/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 9.1988e-06 - val_loss: 7.0089e-06\n",
      "Epoch 167/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.3989e-05 - val_loss: 5.5948e-06\n",
      "Epoch 168/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.4769e-06 - val_loss: 6.1866e-06\n",
      "Epoch 169/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.0800e-05 - val_loss: 5.7590e-06\n",
      "Epoch 170/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.4968e-05 - val_loss: 4.7975e-06\n",
      "Epoch 171/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.1805e-05 - val_loss: 5.9091e-06\n",
      "Epoch 172/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.3449e-05 - val_loss: 6.2789e-06\n",
      "Epoch 173/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 9.9963e-06 - val_loss: 4.4442e-06\n",
      "Epoch 174/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.0858e-06 - val_loss: 3.9534e-06\n",
      "Epoch 175/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.2827e-05 - val_loss: 4.5255e-06\n",
      "Epoch 176/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.6297e-06 - val_loss: 4.6294e-06\n",
      "Epoch 177/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.1051e-06 - val_loss: 5.2569e-06\n",
      "Epoch 178/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.0485e-05 - val_loss: 5.2263e-06\n",
      "Epoch 179/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.6721e-06 - val_loss: 4.7592e-06\n",
      "Epoch 180/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9112e-06 - val_loss: 6.0220e-06\n",
      "Epoch 181/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9456e-06 - val_loss: 3.9068e-06\n",
      "Epoch 182/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 7.7149e-06 - val_loss: 3.9043e-06\n",
      "Epoch 183/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 7.9668e-06 - val_loss: 4.1839e-06\n",
      "Epoch 184/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.2678e-05 - val_loss: 5.4419e-06\n",
      "Epoch 185/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 6.5194e-06 - val_loss: 4.0448e-06\n",
      "Epoch 186/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.2099e-05 - val_loss: 4.3224e-06\n",
      "Epoch 187/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.5331e-05 - val_loss: 6.8779e-06\n",
      "Epoch 188/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.0369e-05 - val_loss: 4.9510e-06\n",
      "Epoch 189/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.0118e-05 - val_loss: 5.7915e-06\n",
      "Epoch 190/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.1494e-05 - val_loss: 5.0477e-06\n",
      "Epoch 191/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.3758e-05 - val_loss: 4.4423e-06\n",
      "Epoch 192/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.1565e-05 - val_loss: 5.2279e-06\n",
      "Epoch 193/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.5181e-04 - val_loss: 2.9848e-05\n",
      "Epoch 194/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.3388e-04 - val_loss: 3.8644e-05\n",
      "Epoch 195/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.9765e-04 - val_loss: 3.5277e-05\n",
      "Epoch 196/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.8148e-04 - val_loss: 3.4155e-05\n",
      "Epoch 197/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.6172e-04 - val_loss: 3.1464e-05\n",
      "Epoch 198/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.5953e-04 - val_loss: 3.2142e-05\n",
      "Epoch 199/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.4777e-04 - val_loss: 3.5828e-05\n",
      "Epoch 200/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.4668e-04 - val_loss: 3.2273e-05\n",
      "Epoch 201/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.3214e-04 - val_loss: 3.0375e-05\n",
      "Epoch 202/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.3299e-04 - val_loss: 3.0399e-05\n",
      "Epoch 203/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.2384e-04 - val_loss: 3.2356e-05\n",
      "Epoch 204/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.1531e-04 - val_loss: 3.2377e-05\n",
      "Epoch 205/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.0883e-04 - val_loss: 3.2619e-05\n",
      "Epoch 206/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.0258e-04 - val_loss: 3.6915e-05\n",
      "Epoch 207/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.0624e-04 - val_loss: 3.1813e-05\n",
      "Epoch 208/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.0097e-04 - val_loss: 2.8962e-05\n",
      "Epoch 209/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 9.7874e-05 - val_loss: 2.7422e-05\n",
      "Epoch 210/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.5254e-05 - val_loss: 2.6529e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 211/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.5568e-05 - val_loss: 2.5310e-05\n",
      "Epoch 212/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 7.8061e-05 - val_loss: 2.3819e-05\n",
      "Epoch 213/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 7.5537e-05 - val_loss: 2.2236e-05\n",
      "Epoch 214/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8072e-05 - val_loss: 2.5118e-05\n",
      "Epoch 215/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 6.9488e-05 - val_loss: 2.0613e-05\n",
      "Epoch 216/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 6.3723e-05 - val_loss: 1.7277e-05\n",
      "Epoch 217/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 6.0129e-05 - val_loss: 1.6297e-05\n",
      "Epoch 218/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 5.9820e-05 - val_loss: 1.4884e-05\n",
      "Epoch 219/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.5939e-05 - val_loss: 1.4860e-05\n",
      "Epoch 220/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 6.1571e-05 - val_loss: 1.0589e-05\n",
      "Epoch 221/2000\n",
      "21471/21471 [==============================] - 1s 24us/step - loss: 3.9906e-05 - val_loss: 7.8075e-06\n",
      "Epoch 222/2000\n",
      "21471/21471 [==============================] - 0s 23us/step - loss: 3.8747e-05 - val_loss: 7.9581e-06\n",
      "Epoch 223/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.7470e-05 - val_loss: 4.9501e-06\n",
      "Epoch 224/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.9371e-05 - val_loss: 5.8842e-06\n",
      "Epoch 225/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 3.4569e-05 - val_loss: 4.3409e-06\n",
      "Epoch 226/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.8281e-05 - val_loss: 3.6360e-06\n",
      "Epoch 227/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.5827e-05 - val_loss: 3.5041e-06\n",
      "Epoch 228/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 2.4013e-05 - val_loss: 4.3060e-06\n",
      "Epoch 229/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.5186e-05 - val_loss: 3.8815e-06\n",
      "Epoch 230/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.9963e-05 - val_loss: 2.6958e-06\n",
      "Epoch 231/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.5205e-05 - val_loss: 2.8521e-06\n",
      "Epoch 232/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.6820e-05 - val_loss: 3.0236e-06\n",
      "Epoch 233/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.0038e-05 - val_loss: 3.1271e-06\n",
      "Epoch 234/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 1.9314e-05 - val_loss: 2.8234e-06\n",
      "Epoch 235/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.7548e-05 - val_loss: 3.0726e-06\n",
      "Epoch 236/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.2309e-05 - val_loss: 3.5957e-06\n",
      "Epoch 237/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.3444e-05 - val_loss: 2.8273e-06\n",
      "Epoch 238/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.1023e-05 - val_loss: 3.4136e-06\n",
      "Epoch 239/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.9404e-05 - val_loss: 2.8222e-06\n",
      "Epoch 240/2000\n",
      "21471/21471 [==============================] - 1s 24us/step - loss: 1.3940e-05 - val_loss: 3.1913e-06\n",
      "Epoch 241/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.2501e-05 - val_loss: 2.8609e-06\n",
      "Epoch 242/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.1892e-05 - val_loss: 2.2279e-06\n",
      "Epoch 243/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.5538e-05 - val_loss: 5.0678e-06\n",
      "Epoch 244/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.3497e-05 - val_loss: 2.6432e-06\n",
      "Epoch 245/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.2765e-05 - val_loss: 3.1849e-06\n",
      "Epoch 246/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.5260e-05 - val_loss: 1.7143e-06\n",
      "Epoch 247/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.4237e-05 - val_loss: 2.5173e-06\n",
      "Epoch 248/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.1540e-05 - val_loss: 2.1253e-06\n",
      "Epoch 249/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.3499e-05 - val_loss: 2.7458e-06\n",
      "Epoch 250/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.5084e-05 - val_loss: 2.9005e-06\n",
      "Epoch 251/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.6491e-05 - val_loss: 2.3373e-06\n",
      "Epoch 252/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 1.1158e-05 - val_loss: 2.3051e-06\n",
      "Epoch 253/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.1480e-05 - val_loss: 3.7205e-06\n",
      "Epoch 254/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.6346e-05 - val_loss: 2.1233e-06\n",
      "Epoch 255/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 9.6765e-06 - val_loss: 3.1462e-06\n",
      "Epoch 256/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 1.0572e-05 - val_loss: 2.4159e-06\n",
      "Epoch 257/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 1.2479e-05 - val_loss: 1.9532e-06\n",
      "Epoch 258/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.5432e-05 - val_loss: 3.5440e-06\n",
      "Epoch 259/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.4542e-05 - val_loss: 2.1058e-06\n",
      "Epoch 260/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.2895e-05 - val_loss: 3.5534e-06\n",
      "Epoch 261/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.0469e-05 - val_loss: 2.4543e-06\n",
      "Epoch 262/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.9003e-05 - val_loss: 3.0086e-06\n",
      "Epoch 263/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.0575e-05 - val_loss: 2.1717e-06\n",
      "Epoch 264/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.0192e-05 - val_loss: 1.5429e-06\n",
      "Epoch 265/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8905e-06 - val_loss: 2.7562e-06\n",
      "Epoch 266/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.7967e-05 - val_loss: 3.4877e-06\n",
      "Epoch 267/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.0668e-05 - val_loss: 1.6480e-06\n",
      "Epoch 268/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.4885e-05 - val_loss: 3.1263e-06\n",
      "Epoch 269/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.5212e-05 - val_loss: 2.8659e-06\n",
      "Epoch 270/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.2307e-05 - val_loss: 2.6937e-06\n",
      "Epoch 271/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.1507e-05 - val_loss: 4.3426e-06\n",
      "Epoch 272/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.3069e-05 - val_loss: 1.8956e-06\n",
      "Epoch 273/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.2274e-06 - val_loss: 1.3976e-06\n",
      "Epoch 274/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.2594e-05 - val_loss: 3.2835e-06\n",
      "Epoch 275/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.3161e-05 - val_loss: 4.5969e-06\n",
      "Epoch 276/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.9440e-06 - val_loss: 1.7720e-06\n",
      "Epoch 277/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 7.0026e-06 - val_loss: 1.8496e-06\n",
      "Epoch 278/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.1335e-05 - val_loss: 3.0562e-06\n",
      "Epoch 279/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.9614e-05 - val_loss: 2.9955e-06\n",
      "Epoch 280/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 9.5396e-06 - val_loss: 4.0230e-06\n",
      "Epoch 281/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 20us/step - loss: 6.9750e-06 - val_loss: 1.9152e-06\n",
      "Epoch 282/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 6.5520e-06 - val_loss: 2.3086e-06\n",
      "Epoch 283/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.8952e-05 - val_loss: 3.5061e-06\n",
      "Epoch 284/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.2000e-05 - val_loss: 3.0891e-06\n",
      "Epoch 285/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.2001e-05 - val_loss: 2.1717e-06\n",
      "Epoch 286/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.2318e-06 - val_loss: 1.7234e-06\n",
      "Epoch 287/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.1076e-05 - val_loss: 2.9199e-06\n",
      "Epoch 288/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.2224e-05 - val_loss: 1.4060e-06\n",
      "Epoch 289/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.5420e-05 - val_loss: 6.1901e-06\n",
      "Epoch 290/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 7.5603e-06 - val_loss: 1.4272e-06\n",
      "Epoch 291/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.0126e-05 - val_loss: 3.2313e-06\n",
      "Epoch 292/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 2.2024e-05 - val_loss: 5.9018e-06\n",
      "Epoch 293/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 1.1590e-05 - val_loss: 4.6264e-06\n",
      "Epoch 294/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.7021e-06 - val_loss: 1.9005e-06\n",
      "Epoch 295/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9479e-06 - val_loss: 3.0852e-06\n",
      "Epoch 296/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 6.6952e-06 - val_loss: 1.9014e-06\n",
      "Epoch 297/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.2036e-06 - val_loss: 2.1210e-06\n",
      "Epoch 298/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 7.7010e-06 - val_loss: 3.1372e-06\n",
      "Epoch 299/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.1904e-05 - val_loss: 6.8666e-06\n",
      "Epoch 300/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.0708e-05 - val_loss: 2.5829e-06\n",
      "Epoch 301/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.1391e-05 - val_loss: 8.6639e-06\n",
      "Epoch 302/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.1373e-05 - val_loss: 3.8813e-06\n",
      "Epoch 303/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.6410e-06 - val_loss: 2.7592e-06\n",
      "Epoch 304/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 9.6810e-06 - val_loss: 2.9546e-06\n",
      "Epoch 305/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.1185e-05 - val_loss: 2.8276e-06\n",
      "Epoch 306/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 6.9994e-06 - val_loss: 1.8237e-06\n",
      "Epoch 307/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.3974e-06 - val_loss: 4.4538e-06\n",
      "Epoch 308/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.0751e-05 - val_loss: 4.4429e-06\n",
      "Epoch 309/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.2340e-05 - val_loss: 4.2377e-06\n",
      "Epoch 310/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.9249e-05 - val_loss: 3.8562e-06\n",
      "Epoch 311/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.5311e-05 - val_loss: 5.2117e-06\n",
      "Epoch 312/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.0103e-05 - val_loss: 8.9727e-06\n",
      "Epoch 313/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.2872e-05 - val_loss: 4.2455e-06\n",
      "Epoch 314/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.3266e-05 - val_loss: 2.3850e-06\n",
      "Epoch 315/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.4692e-05 - val_loss: 6.5005e-06\n",
      "Epoch 316/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 7.5997e-06 - val_loss: 2.8593e-06\n",
      "Epoch 317/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 7.2790e-06 - val_loss: 2.0231e-06\n",
      "Epoch 318/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.1663e-06 - val_loss: 2.1924e-06\n",
      "Epoch 319/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.1674e-05 - val_loss: 6.9769e-06\n",
      "Epoch 320/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 9.3027e-06 - val_loss: 4.2941e-06\n",
      "Epoch 321/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.6303e-05 - val_loss: 5.7323e-06\n",
      "Epoch 322/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.8224e-05 - val_loss: 3.0483e-06\n",
      "Epoch 323/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 6.2225e-06 - val_loss: 2.7191e-06\n",
      "Epoch 324/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.1423e-05 - val_loss: 3.8808e-06\n",
      "Epoch 325/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.0420e-04 - val_loss: 7.9285e-05\n",
      "Epoch 326/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.2171e-04 - val_loss: 4.4853e-05\n",
      "Epoch 327/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.0795e-04 - val_loss: 3.7180e-05\n",
      "Epoch 328/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 1.0469e-04 - val_loss: 3.0865e-05\n",
      "Epoch 329/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 9.6347e-05 - val_loss: 2.9675e-05\n",
      "Epoch 330/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.3449e-05 - val_loss: 3.1161e-05\n",
      "Epoch 331/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.6771e-05 - val_loss: 4.7287e-05\n",
      "Epoch 332/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.1973e-05 - val_loss: 2.8049e-05\n",
      "Epoch 333/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 7.3004e-05 - val_loss: 3.2217e-05\n",
      "Epoch 334/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 7.7092e-05 - val_loss: 2.7702e-05\n",
      "Epoch 335/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.2128e-05 - val_loss: 2.8643e-05\n",
      "Epoch 336/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 5.4129e-05 - val_loss: 2.5799e-05\n",
      "Epoch 337/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 5.3162e-05 - val_loss: 2.1016e-05\n",
      "Epoch 338/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 5.2327e-05 - val_loss: 2.1429e-05\n",
      "Epoch 339/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 5.1899e-05 - val_loss: 1.7895e-05\n",
      "Epoch 340/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.9457e-05 - val_loss: 1.4939e-05\n",
      "Epoch 341/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.0510e-05 - val_loss: 1.1635e-05\n",
      "Epoch 342/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.8074e-05 - val_loss: 9.3349e-06\n",
      "Epoch 343/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.9330e-05 - val_loss: 1.2511e-05\n",
      "Epoch 344/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.1800e-05 - val_loss: 7.7744e-06\n",
      "Epoch 345/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.5794e-05 - val_loss: 7.7662e-06\n",
      "Epoch 346/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.9902e-05 - val_loss: 8.6151e-06\n",
      "Epoch 347/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.6095e-05 - val_loss: 7.3421e-06\n",
      "Epoch 348/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.1767e-05 - val_loss: 5.6296e-06\n",
      "Epoch 349/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.2446e-05 - val_loss: 2.9687e-06\n",
      "Epoch 350/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.1839e-05 - val_loss: 8.4710e-06\n",
      "Epoch 351/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.3819e-05 - val_loss: 8.2204e-06\n",
      "Epoch 352/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.4390e-05 - val_loss: 6.4447e-06\n",
      "Epoch 353/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.5107e-05 - val_loss: 5.9585e-06\n",
      "Epoch 354/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.4174e-05 - val_loss: 7.7222e-06\n",
      "Epoch 355/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.0909e-05 - val_loss: 7.7467e-06\n",
      "Epoch 356/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.2745e-05 - val_loss: 6.3369e-06\n",
      "Epoch 357/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.8599e-05 - val_loss: 3.3415e-06\n",
      "Epoch 358/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.5208e-05 - val_loss: 1.4128e-05\n",
      "Epoch 359/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.1124e-05 - val_loss: 8.7793e-06\n",
      "Epoch 360/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.4305e-05 - val_loss: 3.4379e-06\n",
      "Epoch 361/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.0763e-05 - val_loss: 1.1418e-05\n",
      "Epoch 362/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.6847e-05 - val_loss: 5.6430e-06\n",
      "Epoch 363/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.8694e-05 - val_loss: 5.1675e-06\n",
      "Epoch 364/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.4892e-05 - val_loss: 4.0858e-06\n",
      "Epoch 365/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 1.6174e-05 - val_loss: 3.9842e-06\n",
      "Epoch 366/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.6584e-05 - val_loss: 4.7153e-06\n",
      "Epoch 367/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.4481e-05 - val_loss: 4.1648e-06\n",
      "Epoch 368/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.6128e-05 - val_loss: 5.5654e-06\n",
      "Epoch 369/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.4937e-05 - val_loss: 5.1502e-06\n",
      "Epoch 370/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.6411e-05 - val_loss: 5.0704e-06\n",
      "Epoch 371/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.5312e-05 - val_loss: 7.6159e-06\n",
      "Epoch 372/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.2864e-05 - val_loss: 4.1370e-06\n",
      "Epoch 373/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.0752e-05 - val_loss: 4.7216e-06\n",
      "Epoch 374/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.3067e-05 - val_loss: 2.5375e-06\n",
      "Epoch 375/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.8894e-05 - val_loss: 3.4947e-06\n",
      "Epoch 376/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.4201e-05 - val_loss: 2.8880e-06\n",
      "Epoch 377/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.8702e-05 - val_loss: 3.1355e-06\n",
      "Epoch 378/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.1681e-06 - val_loss: 3.5014e-06\n",
      "Epoch 379/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.2245e-05 - val_loss: 4.6081e-06\n",
      "Epoch 380/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.5855e-05 - val_loss: 9.2446e-06\n",
      "Epoch 381/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.2636e-05 - val_loss: 3.5771e-06\n",
      "Epoch 382/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.6125e-05 - val_loss: 2.6177e-06\n",
      "Epoch 383/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0013 - val_loss: 0.00140308e\n",
      "Epoch 384/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.2996e-04 - val_loss: 3.0417e-05\n",
      "Epoch 385/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.0988e-04 - val_loss: 3.0485e-05\n",
      "Epoch 386/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.0439e-04 - val_loss: 3.1008e-05\n",
      "Epoch 387/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.9296e-05 - val_loss: 3.0709e-05\n",
      "Epoch 388/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 9.8079e-05 - val_loss: 3.0936e-05\n",
      "Epoch 389/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.5329e-05 - val_loss: 3.0582e-05\n",
      "Epoch 390/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.5699e-05 - val_loss: 3.0529e-05\n",
      "Epoch 391/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.5960e-05 - val_loss: 3.0581e-05\n",
      "Epoch 392/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.6651e-05 - val_loss: 3.0963e-05\n",
      "Epoch 393/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.3079e-05 - val_loss: 3.0459e-05\n",
      "Epoch 394/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.4278e-05 - val_loss: 3.0942e-05\n",
      "Epoch 395/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.1263e-05 - val_loss: 3.0316e-05\n",
      "Epoch 396/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0222e-05 - val_loss: 3.0209e-05\n",
      "Epoch 397/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8907e-05 - val_loss: 3.0970e-05\n",
      "Epoch 398/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.2877e-05 - val_loss: 3.0994e-05\n",
      "Epoch 399/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0248e-05 - val_loss: 3.0028e-05\n",
      "Epoch 400/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0725e-05 - val_loss: 3.0457e-05\n",
      "Epoch 401/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 8.7638e-05 - val_loss: 3.0722e-05\n",
      "Epoch 402/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 8.9785e-05 - val_loss: 2.9662e-05\n",
      "Epoch 403/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.6930e-05 - val_loss: 2.9540e-05\n",
      "Epoch 404/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.7828e-05 - val_loss: 2.9675e-05\n",
      "Epoch 405/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.5737e-05 - val_loss: 2.9361e-05\n",
      "Epoch 406/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.5640e-05 - val_loss: 2.9230e-05\n",
      "Epoch 407/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.1193e-05 - val_loss: 3.0209e-05\n",
      "Epoch 408/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.0600e-05 - val_loss: 2.9945e-05\n",
      "Epoch 409/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 6.8812e-05 - val_loss: 2.7248e-05\n",
      "Epoch 410/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 6.6678e-05 - val_loss: 2.6310e-05\n",
      "Epoch 411/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.7205e-05 - val_loss: 2.5436e-05\n",
      "Epoch 412/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 5.1357e-05 - val_loss: 2.3924e-05\n",
      "Epoch 413/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.6340e-05 - val_loss: 2.5740e-05\n",
      "Epoch 414/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.0820e-05 - val_loss: 2.2803e-05\n",
      "Epoch 415/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.4106e-05 - val_loss: 2.2724e-05\n",
      "Epoch 416/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.5428e-05 - val_loss: 2.1274e-05\n",
      "Epoch 417/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.6236e-05 - val_loss: 1.7656e-05\n",
      "Epoch 418/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.9024e-05 - val_loss: 1.7905e-05\n",
      "Epoch 419/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.0534e-05 - val_loss: 1.5530e-05\n",
      "Epoch 420/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.1001e-05 - val_loss: 1.9162e-05\n",
      "Epoch 421/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.8861e-05 - val_loss: 1.4854e-05\n",
      "Epoch 422/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.4482e-05 - val_loss: 1.7795e-05\n",
      "Epoch 423/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.7597e-05 - val_loss: 1.3510e-05\n",
      "Epoch 424/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.6756e-05 - val_loss: 1.2934e-05\n",
      "Epoch 425/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.7852e-05 - val_loss: 1.2474e-05\n",
      "Epoch 426/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.6319e-05 - val_loss: 1.2550e-05\n",
      "Epoch 427/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.8714e-05 - val_loss: 9.3901e-06\n",
      "Epoch 428/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.4441e-05 - val_loss: 1.0094e-05\n",
      "Epoch 429/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.3172e-05 - val_loss: 1.4341e-05\n",
      "Epoch 430/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.6625e-05 - val_loss: 1.1502e-05\n",
      "Epoch 431/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.2420e-05 - val_loss: 1.0020e-05\n",
      "Epoch 432/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.9051e-05 - val_loss: 9.2822e-06\n",
      "Epoch 433/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.1469e-05 - val_loss: 1.0597e-05\n",
      "Epoch 434/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.9891e-05 - val_loss: 8.6794e-06\n",
      "Epoch 435/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.9681e-05 - val_loss: 9.6344e-06\n",
      "Epoch 436/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.6585e-05 - val_loss: 6.6975e-06\n",
      "Epoch 437/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.8206e-05 - val_loss: 8.3704e-06\n",
      "Epoch 438/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 2.1187e-05 - val_loss: 8.1831e-06\n",
      "Epoch 439/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.4317e-05 - val_loss: 6.2799e-06\n",
      "Epoch 440/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.7183e-05 - val_loss: 6.0574e-06\n",
      "Epoch 441/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.1942e-05 - val_loss: 5.9772e-06\n",
      "Epoch 442/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.9482e-05 - val_loss: 7.2754e-06\n",
      "Epoch 443/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.5564e-05 - val_loss: 5.7945e-06\n",
      "Epoch 444/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.4642e-05 - val_loss: 5.0092e-06\n",
      "Epoch 445/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.5315e-05 - val_loss: 4.8126e-06\n",
      "Epoch 446/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.2859e-05 - val_loss: 8.5194e-06\n",
      "Epoch 447/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.5068e-05 - val_loss: 1.1654e-05\n",
      "Epoch 448/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.9119e-05 - val_loss: 7.3621e-06\n",
      "Epoch 449/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.4113e-05 - val_loss: 4.4978e-06\n",
      "Epoch 450/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.0998e-05 - val_loss: 3.4742e-06\n",
      "Epoch 451/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.3981e-05 - val_loss: 3.1691e-06\n",
      "Epoch 452/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.2392e-05 - val_loss: 6.3930e-06\n",
      "Epoch 453/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.4073e-05 - val_loss: 4.6611e-06\n",
      "Epoch 454/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.1079e-05 - val_loss: 3.3120e-06\n",
      "Epoch 455/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.2468e-05 - val_loss: 3.7592e-06\n",
      "Epoch 456/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.4840e-05 - val_loss: 4.6624e-06\n",
      "Epoch 457/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.6911e-05 - val_loss: 3.6431e-06\n",
      "Epoch 458/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.8819e-05 - val_loss: 6.9216e-06\n",
      "Epoch 459/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.5042e-05 - val_loss: 5.4050e-06\n",
      "Epoch 460/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.4079e-05 - val_loss: 3.3772e-06\n",
      "Epoch 461/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.2101e-05 - val_loss: 3.5646e-06\n",
      "Epoch 462/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.0012e-05 - val_loss: 9.2592e-06\n",
      "Epoch 463/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.3127e-05 - val_loss: 3.8803e-06\n",
      "Epoch 464/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.0180e-05 - val_loss: 4.0298e-06\n",
      "Epoch 465/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.1287e-05 - val_loss: 3.3380e-06\n",
      "Epoch 466/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.2241e-05 - val_loss: 4.0555e-06\n",
      "Epoch 467/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.6548e-05 - val_loss: 4.5915e-06\n",
      "Epoch 468/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.2889e-05 - val_loss: 2.8647e-06\n",
      "Epoch 469/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.5031e-05 - val_loss: 3.5606e-06\n",
      "Epoch 470/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.9093e-06 - val_loss: 2.6725e-06\n",
      "Epoch 471/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.3133e-05 - val_loss: 2.7345e-06\n",
      "Epoch 472/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.0594e-05 - val_loss: 3.0631e-06\n",
      "Epoch 473/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 9.7100e-06 - val_loss: 2.9526e-06\n",
      "Epoch 474/2000\n",
      "21471/21471 [==============================] - 0s 23us/step - loss: 8.1655e-06 - val_loss: 3.1231e-06\n",
      "Epoch 475/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.1306e-05 - val_loss: 4.8161e-06\n",
      "Epoch 476/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.2831e-06 - val_loss: 3.3459e-06\n",
      "Epoch 477/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.3929e-05 - val_loss: 2.5639e-06\n",
      "Epoch 478/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.6516e-06 - val_loss: 1.2252e-06\n",
      "Epoch 479/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 6.1886e-06 - val_loss: 2.0158e-06\n",
      "Epoch 480/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.0558e-05 - val_loss: 1.4029e-06\n",
      "Epoch 481/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.3430e-05 - val_loss: 3.4328e-06\n",
      "Epoch 482/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.8377e-05 - val_loss: 8.5755e-06\n",
      "Epoch 483/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.0723e-05 - val_loss: 1.5323e-06\n",
      "Epoch 484/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.3284e-05 - val_loss: 5.2075e-06\n",
      "Epoch 485/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.1053e-05 - val_loss: 2.5006e-06\n",
      "Epoch 486/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.1993e-05 - val_loss: 1.9969e-06\n",
      "Epoch 487/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.3239e-05 - val_loss: 3.5111e-06\n",
      "Epoch 488/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.3089e-06 - val_loss: 2.8524e-06\n",
      "Epoch 489/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 6.9915e-06 - val_loss: 2.1132e-06\n",
      "Epoch 490/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 7.5720e-06 - val_loss: 2.2339e-06\n",
      "Epoch 491/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 20us/step - loss: 7.7667e-06 - val_loss: 4.4153e-06\n",
      "Epoch 492/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 7.5627e-06 - val_loss: 1.2794e-06\n",
      "Epoch 493/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.0533e-05 - val_loss: 1.1074e-06\n",
      "Epoch 494/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 7.1366e-06 - val_loss: 1.7485e-06\n",
      "Epoch 495/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 6.7184e-06 - val_loss: 1.6763e-06\n",
      "Epoch 496/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 7.7217e-06 - val_loss: 6.5850e-06\n",
      "Epoch 497/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 9.0563e-06 - val_loss: 2.9366e-06\n",
      "Epoch 498/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 6.7322e-06 - val_loss: 2.6564e-06\n",
      "Epoch 499/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 7.4700e-06 - val_loss: 2.4681e-06\n",
      "Epoch 500/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.0694e-05 - val_loss: 3.2249e-06\n",
      "Epoch 501/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.4388e-05 - val_loss: 2.3272e-06\n",
      "Epoch 502/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.3089e-05 - val_loss: 3.7590e-06\n",
      "Epoch 503/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 7.1851e-06 - val_loss: 1.4225e-06\n",
      "Epoch 504/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.1329e-05 - val_loss: 1.6692e-06\n",
      "Epoch 505/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 5.9184e-06 - val_loss: 1.4216e-06\n",
      "Epoch 506/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.0154e-05 - val_loss: 4.3221e-06\n",
      "Epoch 507/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 5.7822e-06 - val_loss: 1.7760e-06\n",
      "Epoch 508/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.2625e-06 - val_loss: 3.0914e-06\n",
      "Epoch 509/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 6.2500e-06 - val_loss: 1.5089e-06\n",
      "Epoch 510/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 7.5575e-06 - val_loss: 1.4072e-06\n",
      "Epoch 511/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 9.5186e-06 - val_loss: 1.1988e-06\n",
      "Epoch 512/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 6.9082e-06 - val_loss: 1.5622e-06\n",
      "Epoch 513/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.4099e-05 - val_loss: 1.4693e-06\n",
      "Epoch 514/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.0331e-05 - val_loss: 3.0603e-06\n",
      "Epoch 515/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 6.9782e-06 - val_loss: 2.9365e-06\n",
      "Epoch 516/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 7.4968e-06 - val_loss: 4.6708e-06\n",
      "Epoch 517/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.3895e-06 - val_loss: 1.5802e-06\n",
      "Epoch 518/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 7.4656e-06 - val_loss: 4.4536e-06\n",
      "Epoch 519/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.6003e-05 - val_loss: 3.8463e-06\n",
      "Epoch 520/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.6500e-05 - val_loss: 4.1246e-06\n",
      "Epoch 521/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.1219e-05 - val_loss: 4.9453e-06\n",
      "Epoch 522/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 6.8268e-06 - val_loss: 4.2974e-06\n",
      "Epoch 523/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 5.8767e-06 - val_loss: 1.8891e-06\n",
      "Epoch 524/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.2695e-05 - val_loss: 4.2495e-06\n",
      "Epoch 525/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 5.3907e-06 - val_loss: 1.1692e-06\n",
      "Epoch 526/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.2752e-05 - val_loss: 4.5488e-06\n",
      "Epoch 527/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.8825e-05 - val_loss: 2.6922e-06\n",
      "Epoch 528/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.8859e-06 - val_loss: 3.3666e-06\n",
      "Epoch 529/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 7.4220e-06 - val_loss: 2.3101e-06\n",
      "Epoch 530/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.2343e-06 - val_loss: 5.0075e-06\n",
      "Epoch 531/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.1802e-06 - val_loss: 5.6748e-06\n",
      "Epoch 532/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 7.2444e-06 - val_loss: 1.3327e-06\n",
      "Epoch 533/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.3799e-06 - val_loss: 1.5709e-06\n",
      "Epoch 534/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.3456e-06 - val_loss: 1.5403e-06\n",
      "Epoch 535/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.2234e-06 - val_loss: 6.6221e-06\n",
      "Epoch 536/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.0967e-06 - val_loss: 2.8330e-06\n",
      "Epoch 537/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.0922e-05 - val_loss: 7.4913e-06\n",
      "Epoch 538/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 7.5433e-06 - val_loss: 1.8433e-06\n",
      "Epoch 539/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 6.4904e-06 - val_loss: 1.7707e-06\n",
      "Epoch 540/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 6.8954e-06 - val_loss: 2.3955e-06\n",
      "Epoch 541/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 7.3263e-06 - val_loss: 1.4426e-06\n",
      "Epoch 542/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.7780e-05 - val_loss: 1.8585e-06\n",
      "Epoch 543/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 7.0987e-06 - val_loss: 2.4711e-06\n",
      "Epoch 544/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 9.7802e-06 - val_loss: 9.0908e-07\n",
      "Epoch 545/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.1194e-06 - val_loss: 2.8502e-06\n",
      "Epoch 546/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 9.2803e-06 - val_loss: 6.5540e-06\n",
      "Epoch 547/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 7.6524e-06 - val_loss: 1.7703e-06\n",
      "Epoch 548/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 6.4253e-06 - val_loss: 2.6306e-06\n",
      "Epoch 549/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 5.2884e-06 - val_loss: 1.3293e-06\n",
      "Epoch 550/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.9959e-06 - val_loss: 1.0856e-06\n",
      "Epoch 551/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 6.2304e-06 - val_loss: 1.1190e-06\n",
      "Epoch 552/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.5299e-06 - val_loss: 1.4606e-06\n",
      "Epoch 553/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 7.3520e-06 - val_loss: 1.2112e-06\n",
      "Epoch 554/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 5.2097e-06 - val_loss: 2.5628e-06\n",
      "Epoch 555/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.7134e-06 - val_loss: 1.5521e-06\n",
      "Epoch 556/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 5.3247e-06 - val_loss: 9.7646e-07\n",
      "Epoch 557/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 5.5235e-06 - val_loss: 1.0542e-06\n",
      "Epoch 558/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 4.9187e-06 - val_loss: 1.5325e-06\n",
      "Epoch 559/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 3.7408e-06 - val_loss: 3.1801e-06\n",
      "Epoch 560/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 5.4503e-06 - val_loss: 1.5928e-06\n",
      "Epoch 561/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 22us/step - loss: 5.2933e-06 - val_loss: 2.8289e-06\n",
      "Epoch 562/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.2715e-06 - val_loss: 1.2624e-06\n",
      "Epoch 563/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 5.0123e-06 - val_loss: 1.4425e-06\n",
      "Epoch 564/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 4.3121e-06 - val_loss: 2.5993e-06\n",
      "Epoch 565/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.5624e-06 - val_loss: 1.1623e-06\n",
      "Epoch 566/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.4139e-06 - val_loss: 1.3630e-06\n",
      "Epoch 567/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 1.0469e-05 - val_loss: 1.5405e-05\n",
      "Epoch 568/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 7.0656e-06 - val_loss: 1.9572e-06\n",
      "Epoch 569/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 6.3217e-06 - val_loss: 4.0299e-06\n",
      "Epoch 570/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 7.6471e-06 - val_loss: 1.0604e-06\n",
      "Epoch 571/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 6.5387e-06 - val_loss: 2.0867e-06\n",
      "Epoch 572/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.7742e-06 - val_loss: 1.8626e-06\n",
      "Epoch 573/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 6.4071e-06 - val_loss: 2.7819e-06\n",
      "Epoch 574/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 7.0918e-06 - val_loss: 2.2395e-06\n",
      "Epoch 575/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 9.6970e-06 - val_loss: 9.9665e-07\n",
      "Epoch 576/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.1169e-06 - val_loss: 1.0729e-06\n",
      "Epoch 577/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.9750e-06 - val_loss: 1.4276e-06\n",
      "Epoch 578/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.8439e-06 - val_loss: 2.3300e-06\n",
      "Epoch 579/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 5.2824e-06 - val_loss: 1.1902e-06\n",
      "Epoch 580/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.6868e-06 - val_loss: 1.0980e-06\n",
      "Epoch 581/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 4.3378e-06 - val_loss: 9.6104e-07\n",
      "Epoch 582/2000\n",
      "21471/21471 [==============================] - 0s 23us/step - loss: 5.2076e-06 - val_loss: 4.7967e-06\n",
      "Epoch 583/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.0868e-06 - val_loss: 1.7278e-06\n",
      "Epoch 584/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 5.4059e-06 - val_loss: 1.0617e-06\n",
      "Epoch 585/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 7.6486e-06 - val_loss: 3.9245e-06\n",
      "Epoch 586/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.8365e-05 - val_loss: 1.7336e-05\n",
      "Epoch 587/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 9.8634e-06 - val_loss: 1.6649e-06\n",
      "Epoch 588/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.5622e-06 - val_loss: 1.1452e-06\n",
      "Epoch 589/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.5993e-06 - val_loss: 1.1833e-06\n",
      "Epoch 590/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.3279e-06 - val_loss: 1.5448e-06\n",
      "Epoch 591/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.9915e-06 - val_loss: 9.8538e-07\n",
      "Epoch 592/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.5425e-06 - val_loss: 1.5472e-06\n",
      "Epoch 593/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 6.5035e-06 - val_loss: 5.9931e-06\n",
      "Epoch 594/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 7.6903e-06 - val_loss: 1.0533e-06\n",
      "Epoch 595/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.7366e-06 - val_loss: 8.7668e-07\n",
      "Epoch 596/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.3271e-06 - val_loss: 1.1974e-06\n",
      "Epoch 597/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 3.5244e-06 - val_loss: 1.3871e-06\n",
      "Epoch 598/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.6988e-06 - val_loss: 1.1775e-06\n",
      "Epoch 599/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.3665e-06 - val_loss: 1.2827e-06\n",
      "Epoch 600/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 5.5116e-06 - val_loss: 1.2596e-06\n",
      "Epoch 601/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.9522e-06 - val_loss: 2.6698e-06\n",
      "Epoch 602/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 5.1472e-06 - val_loss: 1.2129e-06\n",
      "Epoch 603/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.6859e-06 - val_loss: 2.3646e-06\n",
      "Epoch 604/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 5.5705e-06 - val_loss: 1.4776e-06\n",
      "Epoch 605/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.7840e-06 - val_loss: 1.4854e-06\n",
      "Epoch 606/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.5818e-06 - val_loss: 8.7925e-07\n",
      "Epoch 607/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.6727e-06 - val_loss: 9.2614e-07\n",
      "Epoch 608/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 7.3843e-06 - val_loss: 9.4424e-07\n",
      "Epoch 609/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.3457e-06 - val_loss: 8.2239e-07\n",
      "Epoch 610/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 5.2423e-06 - val_loss: 1.2776e-06\n",
      "Epoch 611/2000\n",
      "21471/21471 [==============================] - 0s 23us/step - loss: 4.0278e-06 - val_loss: 1.5089e-06\n",
      "Epoch 612/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 3.7451e-06 - val_loss: 3.1774e-06\n",
      "Epoch 613/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 5.0693e-06 - val_loss: 1.0225e-06\n",
      "Epoch 614/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 3.4506e-06 - val_loss: 8.9399e-07\n",
      "Epoch 615/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.3264e-06 - val_loss: 1.6286e-06\n",
      "Epoch 616/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 7.4540e-06 - val_loss: 1.2500e-06\n",
      "Epoch 617/2000\n",
      "21471/21471 [==============================] - 0s 23us/step - loss: 5.7887e-06 - val_loss: 1.5651e-06\n",
      "Epoch 618/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.6230e-06 - val_loss: 1.0474e-06\n",
      "Epoch 619/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.6980e-06 - val_loss: 1.4755e-06\n",
      "Epoch 620/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 6.5672e-06 - val_loss: 9.0772e-07\n",
      "Epoch 621/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.6216e-06 - val_loss: 8.0226e-07\n",
      "Epoch 622/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 5.4352e-06 - val_loss: 1.0190e-06\n",
      "Epoch 623/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 6.0842e-06 - val_loss: 1.3136e-06\n",
      "Epoch 624/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.2284e-06 - val_loss: 1.7286e-06\n",
      "Epoch 625/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 6.1976e-06 - val_loss: 4.6981e-06\n",
      "Epoch 626/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 0.0017 - val_loss: 1.1664e-04\n",
      "Epoch 627/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 2.7440e-04 - val_loss: 3.0104e-05\n",
      "Epoch 628/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 1.7236e-04 - val_loss: 3.0434e-05\n",
      "Epoch 629/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 1.3394e-04 - val_loss: 3.1407e-05\n",
      "Epoch 630/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 1.1737e-04 - val_loss: 3.0424e-05\n",
      "Epoch 631/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 22us/step - loss: 1.0598e-04 - val_loss: 3.2419e-05\n",
      "Epoch 632/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.0009e-04 - val_loss: 3.3441e-05\n",
      "Epoch 633/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 9.8861e-05 - val_loss: 3.2753e-05\n",
      "Epoch 634/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 9.6072e-05 - val_loss: 3.2393e-05\n",
      "Epoch 635/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 9.5464e-05 - val_loss: 3.1461e-05\n",
      "Epoch 636/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 9.4217e-05 - val_loss: 3.7500e-05\n",
      "Epoch 637/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 9.3651e-05 - val_loss: 3.2653e-05\n",
      "Epoch 638/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 9.3473e-05 - val_loss: 3.1554e-05\n",
      "Epoch 639/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 9.2608e-05 - val_loss: 3.2535e-05\n",
      "Epoch 640/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 9.2742e-05 - val_loss: 3.1460e-05\n",
      "Epoch 641/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 9.2598e-05 - val_loss: 3.3950e-05\n",
      "Epoch 642/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 9.2175e-05 - val_loss: 3.2193e-05\n",
      "Epoch 643/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 9.1770e-05 - val_loss: 3.1088e-05\n",
      "Epoch 644/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 9.1353e-05 - val_loss: 3.5551e-05\n",
      "Epoch 645/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 9.1146e-05 - val_loss: 3.1740e-05\n",
      "Epoch 646/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 9.1670e-05 - val_loss: 3.1204e-05\n",
      "Epoch 647/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 9.1116e-05 - val_loss: 3.2100e-05\n",
      "Epoch 648/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 9.0651e-05 - val_loss: 3.4701e-05\n",
      "Epoch 649/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 9.1294e-05 - val_loss: 3.1507e-05\n",
      "Epoch 650/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 9.1301e-05 - val_loss: 3.1693e-05\n",
      "Epoch 651/2000\n",
      "21471/21471 [==============================] - 0s 23us/step - loss: 9.1336e-05 - val_loss: 3.2301e-05\n",
      "Epoch 652/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 9.0939e-05 - val_loss: 3.2515e-05\n",
      "Epoch 653/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 9.0639e-05 - val_loss: 3.1220e-05\n",
      "Epoch 654/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 9.0938e-05 - val_loss: 3.1425e-05\n",
      "Epoch 655/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 9.0409e-05 - val_loss: 3.1673e-05\n",
      "Epoch 656/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 9.1037e-05 - val_loss: 3.3489e-05\n",
      "Epoch 657/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 9.1783e-05 - val_loss: 3.2149e-05\n",
      "Epoch 658/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 9.0423e-05 - val_loss: 3.1232e-05\n",
      "Epoch 659/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 9.0542e-05 - val_loss: 3.1554e-05\n",
      "Epoch 660/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 9.0427e-05 - val_loss: 3.3456e-05\n",
      "Epoch 661/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 9.0305e-05 - val_loss: 3.3515e-05\n",
      "Epoch 662/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 9.0971e-05 - val_loss: 3.1349e-05\n",
      "Epoch 663/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 9.0839e-05 - val_loss: 3.1122e-05\n",
      "Epoch 664/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.9438e-05 - val_loss: 3.3152e-05\n",
      "Epoch 665/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 9.0415e-05 - val_loss: 3.1462e-05\n",
      "Epoch 666/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 9.0193e-05 - val_loss: 3.4105e-05\n",
      "Epoch 667/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 8.9418e-05 - val_loss: 3.2935e-05\n",
      "Epoch 668/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 8.9594e-05 - val_loss: 3.1797e-05\n",
      "Epoch 669/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 8.8908e-05 - val_loss: 3.1918e-05\n",
      "Epoch 670/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 8.9371e-05 - val_loss: 3.2032e-05\n",
      "Epoch 671/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.9032e-05 - val_loss: 3.1217e-05\n",
      "Epoch 672/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.9579e-05 - val_loss: 3.4313e-05\n",
      "Epoch 673/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 8.6685e-05 - val_loss: 3.3906e-05\n",
      "Epoch 674/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 8.9613e-05 - val_loss: 3.4077e-05\n",
      "Epoch 675/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.6716e-05 - val_loss: 3.1968e-05\n",
      "Epoch 676/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 8.6509e-05 - val_loss: 3.1822e-05\n",
      "Epoch 677/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 8.0709e-05 - val_loss: 3.3297e-05\n",
      "Epoch 678/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 7.8189e-05 - val_loss: 3.2191e-05\n",
      "Epoch 679/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 8.2025e-05 - val_loss: 3.0362e-05\n",
      "Epoch 680/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 7.7929e-05 - val_loss: 3.2994e-05\n",
      "Epoch 681/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 7.1898e-05 - val_loss: 3.7737e-05\n",
      "Epoch 682/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 5.9446e-05 - val_loss: 3.2536e-05\n",
      "Epoch 683/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 5.4463e-05 - val_loss: 3.3872e-05\n",
      "Epoch 684/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 5.7712e-05 - val_loss: 3.0263e-05\n",
      "Epoch 685/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 4.7248e-05 - val_loss: 2.2163e-05\n",
      "Epoch 686/2000\n",
      "21471/21471 [==============================] - 1s 23us/step - loss: 4.2815e-05 - val_loss: 2.4786e-05\n",
      "Epoch 687/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 3.7836e-05 - val_loss: 3.3619e-05\n",
      "Epoch 688/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 5.6462e-05 - val_loss: 2.7880e-05\n",
      "Epoch 689/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 3.8027e-05 - val_loss: 1.3691e-05\n",
      "Epoch 690/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 3.2951e-05 - val_loss: 1.3308e-05\n",
      "Epoch 691/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.6049e-05 - val_loss: 2.1467e-05\n",
      "Epoch 692/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 2.5177e-05 - val_loss: 2.4573e-05\n",
      "Epoch 693/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 3.4299e-05 - val_loss: 2.4062e-05\n",
      "Epoch 694/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 2.6949e-05 - val_loss: 1.1361e-05\n",
      "Epoch 695/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.0498e-05 - val_loss: 1.9509e-05\n",
      "Epoch 696/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 2.1787e-05 - val_loss: 1.0993e-05\n",
      "Epoch 697/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 2.0909e-05 - val_loss: 2.5331e-05\n",
      "Epoch 698/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 4.4465e-05 - val_loss: 2.7010e-05\n",
      "Epoch 699/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.1872e-05 - val_loss: 8.2020e-06\n",
      "Epoch 700/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.3666e-05 - val_loss: 2.6116e-05\n",
      "Epoch 701/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.2424e-05 - val_loss: 2.7691e-05\n",
      "Epoch 702/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.9525e-05 - val_loss: 1.7615e-05\n",
      "Epoch 703/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.3037e-05 - val_loss: 1.5323e-05\n",
      "Epoch 704/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.7059e-05 - val_loss: 2.0992e-05\n",
      "Epoch 705/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.9667e-05 - val_loss: 1.0096e-05\n",
      "Epoch 706/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.6234e-05 - val_loss: 1.7927e-05\n",
      "Epoch 707/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.9643e-05 - val_loss: 9.2937e-06\n",
      "Epoch 708/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.6159e-05 - val_loss: 8.1517e-06\n",
      "Epoch 709/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.2886e-05 - val_loss: 7.5308e-06\n",
      "Epoch 710/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 1.3317e-05 - val_loss: 5.8821e-06\n",
      "Epoch 711/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.4512e-05 - val_loss: 5.1612e-06\n",
      "Epoch 712/2000\n",
      "21471/21471 [==============================] - 0s 23us/step - loss: 1.8467e-05 - val_loss: 5.0826e-06\n",
      "Epoch 713/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.4513e-05 - val_loss: 1.2780e-05\n",
      "Epoch 714/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.8863e-05 - val_loss: 6.2301e-06\n",
      "Epoch 715/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.0418e-05 - val_loss: 4.7624e-06\n",
      "Epoch 716/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.6921e-05 - val_loss: 4.5766e-06\n",
      "Epoch 717/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.1706e-05 - val_loss: 4.5950e-06\n",
      "Epoch 718/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 2.1034e-05 - val_loss: 1.3721e-05\n",
      "Epoch 719/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.3130e-05 - val_loss: 6.8620e-06\n",
      "Epoch 720/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 1.1116e-05 - val_loss: 5.0972e-06\n",
      "Epoch 721/2000\n",
      "21471/21471 [==============================] - 0s 23us/step - loss: 9.1642e-06 - val_loss: 2.6111e-06\n",
      "Epoch 722/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 7.1881e-06 - val_loss: 3.5728e-06\n",
      "Epoch 723/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.4050e-05 - val_loss: 3.5344e-06\n",
      "Epoch 724/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.6316e-05 - val_loss: 9.8968e-06\n",
      "Epoch 725/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.7319e-05 - val_loss: 7.1566e-06\n",
      "Epoch 726/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.5854e-05 - val_loss: 2.7379e-06\n",
      "Epoch 727/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 8.0567e-06 - val_loss: 4.1427e-06\n",
      "Epoch 728/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 9.2089e-06 - val_loss: 6.8213e-06\n",
      "Epoch 729/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.0768e-06 - val_loss: 3.9818e-06\n",
      "Epoch 730/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.2611e-05 - val_loss: 4.2425e-06\n",
      "Epoch 731/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 6.3951e-06 - val_loss: 1.8847e-06\n",
      "Epoch 732/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.5981e-06 - val_loss: 2.6818e-06\n",
      "Epoch 733/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 6.7935e-06 - val_loss: 8.6218e-07\n",
      "Epoch 734/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.9814e-06 - val_loss: 1.1046e-06\n",
      "Epoch 735/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 5.5055e-06 - val_loss: 1.2205e-06\n",
      "Epoch 736/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 7.2336e-06 - val_loss: 2.0407e-06\n",
      "Epoch 737/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.3201e-05 - val_loss: 1.6184e-06\n",
      "Epoch 738/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 7.1275e-06 - val_loss: 9.1385e-07\n",
      "Epoch 739/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.2002e-05 - val_loss: 4.7559e-06\n",
      "Epoch 740/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 6.1284e-06 - val_loss: 1.2672e-06\n",
      "Epoch 741/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.6724e-06 - val_loss: 9.2720e-07\n",
      "Epoch 742/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 7.3287e-06 - val_loss: 1.2004e-06\n",
      "Epoch 743/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 7.4109e-06 - val_loss: 8.3476e-07\n",
      "Epoch 744/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 5.5614e-06 - val_loss: 3.2188e-06\n",
      "Epoch 745/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 5.6095e-06 - val_loss: 2.1302e-06\n",
      "Epoch 746/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.6833e-06 - val_loss: 1.2720e-06\n",
      "Epoch 747/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 5.7853e-06 - val_loss: 1.8295e-06\n",
      "Epoch 748/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 5.1573e-06 - val_loss: 1.1561e-06\n",
      "Epoch 749/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.8676e-06 - val_loss: 9.6852e-07\n",
      "Epoch 750/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.2256e-06 - val_loss: 7.1087e-07\n",
      "Epoch 751/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.9924e-06 - val_loss: 2.9664e-06\n",
      "Epoch 752/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.9924e-06 - val_loss: 1.6555e-06\n",
      "Epoch 753/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.4133e-05 - val_loss: 6.8147e-06\n",
      "Epoch 754/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.0266e-05 - val_loss: 1.1720e-06\n",
      "Epoch 755/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.2696e-05 - val_loss: 6.6183e-06\n",
      "Epoch 756/2000\n",
      "21471/21471 [==============================] - 1s 23us/step - loss: 1.7246e-05 - val_loss: 3.1804e-06\n",
      "Epoch 757/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 6.8085e-06 - val_loss: 1.3806e-06\n",
      "Epoch 758/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 6.4828e-06 - val_loss: 6.2592e-06\n",
      "Epoch 759/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 5.1768e-06 - val_loss: 2.3154e-06\n",
      "Epoch 760/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.5012e-06 - val_loss: 1.4345e-06\n",
      "Epoch 761/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.3487e-06 - val_loss: 4.7715e-07\n",
      "Epoch 762/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 5.8202e-06 - val_loss: 2.1246e-06\n",
      "Epoch 763/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 5.4824e-06 - val_loss: 4.7828e-06\n",
      "Epoch 764/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 5.4689e-06 - val_loss: 2.9240e-06\n",
      "Epoch 765/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 6.6058e-06 - val_loss: 6.1469e-07\n",
      "Epoch 766/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.7098e-06 - val_loss: 6.8181e-07\n",
      "Epoch 767/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 7.3228e-06 - val_loss: 1.1230e-06\n",
      "Epoch 768/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 5.3371e-06 - val_loss: 2.0621e-06\n",
      "Epoch 769/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.1230e-06 - val_loss: 4.9004e-07\n",
      "Epoch 770/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.0541e-05 - val_loss: 5.6351e-06\n",
      "Epoch 771/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.4589e-06 - val_loss: 5.5545e-07\n",
      "Epoch 772/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.5562e-06 - val_loss: 1.1298e-06\n",
      "Epoch 773/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 6.9433e-06 - val_loss: 2.1702e-06\n",
      "Epoch 774/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.9415e-06 - val_loss: 2.6338e-06\n",
      "Epoch 775/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.0672e-06 - val_loss: 1.3738e-06\n",
      "Epoch 776/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.0568e-05 - val_loss: 1.7647e-06\n",
      "Epoch 777/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.6686e-05 - val_loss: 1.0975e-06\n",
      "Epoch 778/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.6512e-06 - val_loss: 4.6017e-07\n",
      "Epoch 779/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.1613e-05 - val_loss: 4.5669e-06\n",
      "Epoch 780/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 6.7661e-06 - val_loss: 2.4546e-06\n",
      "Epoch 781/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.6533e-06 - val_loss: 1.0053e-06\n",
      "Epoch 782/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.6440e-06 - val_loss: 8.2253e-07\n",
      "Epoch 783/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.8556e-06 - val_loss: 7.6365e-07\n",
      "Epoch 784/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.1440e-06 - val_loss: 1.7521e-06\n",
      "Epoch 785/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 5.3005e-06 - val_loss: 3.0605e-06\n",
      "Epoch 786/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.7891e-06 - val_loss: 8.7888e-07\n",
      "Epoch 787/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.8496e-06 - val_loss: 8.9124e-07\n",
      "Epoch 788/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.6665e-06 - val_loss: 1.4634e-06\n",
      "Epoch 789/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 7.3238e-06 - val_loss: 1.8803e-06\n",
      "Epoch 790/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 5.3786e-06 - val_loss: 1.4519e-06\n",
      "Epoch 791/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 3.8651e-06 - val_loss: 4.0391e-07\n",
      "Epoch 792/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 3.8053e-06 - val_loss: 4.9080e-07\n",
      "Epoch 793/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.8047e-06 - val_loss: 1.7231e-06\n",
      "Epoch 794/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.0961e-06 - val_loss: 8.2867e-07\n",
      "Epoch 795/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.4284e-06 - val_loss: 1.0351e-06\n",
      "Epoch 796/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.0991e-06 - val_loss: 7.1094e-07\n",
      "Epoch 797/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.2670e-06 - val_loss: 1.0091e-06\n",
      "Epoch 798/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 6.4970e-06 - val_loss: 5.2395e-06\n",
      "Epoch 799/2000\n",
      "21471/21471 [==============================] - ETA: 0s - loss: 6.3548e-0 - 0s 22us/step - loss: 5.9714e-06 - val_loss: 1.0421e-06\n",
      "Epoch 800/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.9771e-06 - val_loss: 8.0902e-07\n",
      "Epoch 801/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 4.3664e-06 - val_loss: 1.7854e-06\n",
      "Epoch 802/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.5131e-06 - val_loss: 4.3638e-07\n",
      "Epoch 803/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.5936e-06 - val_loss: 1.0738e-06\n",
      "Epoch 804/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.9546e-06 - val_loss: 2.6048e-06\n",
      "Epoch 805/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 6.8425e-06 - val_loss: 1.5985e-06\n",
      "Epoch 806/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 7.2542e-06 - val_loss: 3.2168e-06\n",
      "Epoch 807/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 5.7778e-06 - val_loss: 2.4516e-06\n",
      "Epoch 808/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.2073e-06 - val_loss: 1.2058e-06\n",
      "Epoch 809/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.4366e-06 - val_loss: 9.9918e-07\n",
      "Epoch 810/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.5747e-06 - val_loss: 7.5079e-07\n",
      "Epoch 811/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.5281e-06 - val_loss: 1.4503e-06\n",
      "Epoch 812/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.6693e-06 - val_loss: 1.5016e-06\n",
      "Epoch 813/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.9025e-06 - val_loss: 5.8746e-07\n",
      "Epoch 814/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.0651e-06 - val_loss: 1.1325e-06\n",
      "Epoch 815/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.0340e-06 - val_loss: 8.1122e-07\n",
      "Epoch 816/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 6.2578e-06 - val_loss: 5.1637e-06\n",
      "Epoch 817/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 7.5778e-06 - val_loss: 5.3134e-06\n",
      "Epoch 818/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 6.0094e-06 - val_loss: 8.9642e-07\n",
      "Epoch 819/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.9814e-06 - val_loss: 5.6093e-07\n",
      "Epoch 820/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.6550e-06 - val_loss: 7.3717e-07\n",
      "Epoch 821/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.5057e-06 - val_loss: 5.0584e-06\n",
      "Epoch 822/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 6.5954e-06 - val_loss: 1.6025e-06\n",
      "Epoch 823/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.1477e-06 - val_loss: 7.0905e-07\n",
      "Epoch 824/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.8507e-06 - val_loss: 8.5616e-07\n",
      "Epoch 825/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.5460e-06 - val_loss: 5.8687e-07\n",
      "Epoch 826/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.2964e-06 - val_loss: 1.7351e-06\n",
      "Epoch 827/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.5818e-06 - val_loss: 4.5118e-06\n",
      "Epoch 828/2000\n",
      "21471/21471 [==============================] - 0s 23us/step - loss: 4.2408e-06 - val_loss: 1.3524e-06\n",
      "Epoch 829/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.6124e-06 - val_loss: 1.4730e-06\n",
      "Epoch 830/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.3346e-06 - val_loss: 8.5905e-07\n",
      "Epoch 831/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.1337e-06 - val_loss: 9.9163e-07\n",
      "Epoch 832/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.5113e-06 - val_loss: 1.7191e-06\n",
      "Epoch 833/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.1719e-06 - val_loss: 9.5120e-07\n",
      "Epoch 834/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.1243e-06 - val_loss: 1.2236e-06\n",
      "Epoch 835/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.7548e-06 - val_loss: 1.9743e-06\n",
      "Epoch 836/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 5.4857e-06 - val_loss: 1.0524e-06\n",
      "Epoch 837/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.5714e-06 - val_loss: 1.2227e-06\n",
      "Epoch 838/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.0059e-06 - val_loss: 8.2782e-07\n",
      "Epoch 839/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.5875e-06 - val_loss: 5.7411e-07\n",
      "Epoch 840/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 5.9774e-06 - val_loss: 1.0989e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 841/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.6898e-06 - val_loss: 9.9325e-07\n",
      "Epoch 842/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 5.7924e-06 - val_loss: 2.2397e-06\n",
      "Epoch 843/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.0894e-06 - val_loss: 1.0220e-06\n",
      "Epoch 844/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.5558e-06 - val_loss: 7.4006e-07\n",
      "Epoch 845/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.7589e-06 - val_loss: 1.2108e-06\n",
      "Epoch 846/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.1507e-06 - val_loss: 7.6582e-07\n",
      "Epoch 847/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.9260e-06 - val_loss: 7.1904e-07\n",
      "Epoch 848/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.6586e-06 - val_loss: 7.4078e-07\n",
      "Epoch 849/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.3651e-06 - val_loss: 3.4012e-06\n",
      "Epoch 850/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.8635e-06 - val_loss: 2.6982e-06\n",
      "Epoch 851/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 6.3993e-06 - val_loss: 1.5138e-06\n",
      "Epoch 852/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.8809e-06 - val_loss: 6.9167e-07\n",
      "Epoch 853/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.6611e-06 - val_loss: 8.9647e-07\n",
      "Epoch 854/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.1708e-06 - val_loss: 1.4153e-06\n",
      "Epoch 855/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.5964e-06 - val_loss: 1.3916e-06\n",
      "Epoch 856/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 5.9979e-06 - val_loss: 1.9143e-06\n",
      "Epoch 857/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.5500e-06 - val_loss: 2.7781e-06\n",
      "Epoch 858/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.5808e-06 - val_loss: 8.7132e-07\n",
      "Epoch 859/2000\n",
      "21471/21471 [==============================] - ETA: 0s - loss: 3.1411e-0 - 0s 20us/step - loss: 3.1713e-06 - val_loss: 1.4118e-06\n",
      "Epoch 860/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 5.1359e-06 - val_loss: 1.7072e-06\n",
      "Epoch 861/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 5.2452e-06 - val_loss: 3.7073e-06\n",
      "Epoch 862/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.2857e-06 - val_loss: 1.4463e-06\n",
      "Epoch 863/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.8812e-06 - val_loss: 8.6924e-07\n",
      "Epoch 864/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 2.8286e-06 - val_loss: 7.9801e-07\n",
      "Epoch 865/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.4970e-06 - val_loss: 7.6380e-07\n",
      "Epoch 866/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.8273e-06 - val_loss: 1.5513e-06\n",
      "Epoch 867/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.5960e-06 - val_loss: 1.7267e-06\n",
      "Epoch 868/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 5.5590e-06 - val_loss: 2.6010e-06\n",
      "Epoch 869/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.6635e-06 - val_loss: 1.3557e-06\n",
      "Epoch 870/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.0842e-06 - val_loss: 1.2328e-06\n",
      "Epoch 871/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.1919e-06 - val_loss: 1.4769e-06\n",
      "Epoch 872/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.0808e-06 - val_loss: 1.3006e-06\n",
      "Epoch 873/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.4803e-06 - val_loss: 9.2162e-07\n",
      "Epoch 874/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.5337e-06 - val_loss: 7.2413e-07\n",
      "Epoch 875/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.7835e-06 - val_loss: 2.1742e-06\n",
      "Epoch 876/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.5840e-06 - val_loss: 1.9654e-06\n",
      "Epoch 877/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.4590e-06 - val_loss: 1.0290e-05\n",
      "Epoch 878/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.5342e-05 - val_loss: 6.5411e-06\n",
      "Epoch 879/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 5.9617e-06 - val_loss: 8.1473e-07\n",
      "Epoch 880/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 7.1256e-06 - val_loss: 2.4061e-06\n",
      "Epoch 881/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.2385e-06 - val_loss: 9.7163e-07\n",
      "Epoch 882/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.8210e-06 - val_loss: 2.2179e-06\n",
      "Epoch 883/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.8729e-06 - val_loss: 6.0370e-07\n",
      "Epoch 884/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.0272e-06 - val_loss: 1.4831e-06\n",
      "Epoch 885/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.6825e-06 - val_loss: 1.3750e-06\n",
      "Epoch 886/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.6614e-06 - val_loss: 1.9549e-06\n",
      "Epoch 887/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 5.5484e-06 - val_loss: 9.6520e-07\n",
      "Epoch 888/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 5.5533e-06 - val_loss: 1.8885e-06\n",
      "Epoch 889/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 5.3556e-06 - val_loss: 3.6814e-06\n",
      "Epoch 890/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.2486e-06 - val_loss: 1.1600e-06\n",
      "Epoch 891/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.8471e-06 - val_loss: 4.0668e-06\n",
      "Epoch 892/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.3317e-06 - val_loss: 6.5940e-07\n",
      "Epoch 893/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.7488e-06 - val_loss: 1.1815e-06\n",
      "Epoch 894/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.2395e-06 - val_loss: 7.9105e-07\n",
      "Epoch 895/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.5509e-06 - val_loss: 1.9301e-06\n",
      "Epoch 896/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.6146e-06 - val_loss: 1.0452e-06\n",
      "Epoch 897/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 5.2212e-06 - val_loss: 8.0051e-07\n",
      "Epoch 898/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 5.6289e-06 - val_loss: 4.7875e-06\n",
      "Epoch 899/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.1402e-06 - val_loss: 1.3078e-06\n",
      "Epoch 900/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 3.5615e-06 - val_loss: 8.4924e-07\n",
      "Epoch 901/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 1.0684e-04 - val_loss: 1.8541e-04\n",
      "Epoch 902/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 5.9191e-05 - val_loss: 1.3537e-05\n",
      "Epoch 903/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.3988e-05 - val_loss: 3.2542e-06\n",
      "Epoch 904/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 5.4373e-06 - val_loss: 3.1596e-06\n",
      "Epoch 905/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 5.3334e-06 - val_loss: 1.3875e-06\n",
      "Epoch 906/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 6.1734e-06 - val_loss: 1.1876e-06\n",
      "Epoch 907/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.1551e-06 - val_loss: 1.0360e-06\n",
      "Epoch 908/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 5.9137e-06 - val_loss: 7.4473e-07\n",
      "Epoch 909/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.5725e-06 - val_loss: 2.5198e-06\n",
      "Epoch 910/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.7643e-06 - val_loss: 7.8534e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 911/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 6.1237e-06 - val_loss: 1.1142e-06\n",
      "Epoch 912/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.2862e-06 - val_loss: 5.4299e-07\n",
      "Epoch 913/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.4710e-06 - val_loss: 4.5045e-07\n",
      "Epoch 914/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.2515e-06 - val_loss: 5.6119e-07\n",
      "Epoch 915/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.5896e-06 - val_loss: 5.3805e-07\n",
      "Epoch 916/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.9507e-06 - val_loss: 4.7018e-07\n",
      "Epoch 917/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.6762e-06 - val_loss: 6.5266e-07\n",
      "Epoch 918/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.4853e-06 - val_loss: 4.7825e-07\n",
      "Epoch 919/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.9949e-06 - val_loss: 4.7793e-07\n",
      "Epoch 920/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.9016e-06 - val_loss: 2.6465e-06\n",
      "Epoch 921/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.1843e-06 - val_loss: 5.8434e-07\n",
      "Epoch 922/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.4551e-06 - val_loss: 4.0496e-07\n",
      "Epoch 923/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.9126e-06 - val_loss: 5.4862e-07\n",
      "Epoch 924/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.1751e-06 - val_loss: 6.1780e-07\n",
      "Epoch 925/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.6028e-06 - val_loss: 9.2993e-07\n",
      "Epoch 926/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.6551e-06 - val_loss: 8.0390e-07\n",
      "Epoch 927/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.2880e-06 - val_loss: 6.1153e-07\n",
      "Epoch 928/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.3728e-06 - val_loss: 8.3383e-07\n",
      "Epoch 929/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.6920e-05 - val_loss: 6.1801e-07\n",
      "Epoch 930/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 6.1427e-06 - val_loss: 2.6634e-06\n",
      "Epoch 931/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 7.7642e-06 - val_loss: 2.0772e-06\n",
      "Epoch 932/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.2861e-06 - val_loss: 1.0370e-06\n",
      "Epoch 933/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.9096e-06 - val_loss: 4.6457e-07\n",
      "Epoch 934/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.3257e-06 - val_loss: 9.1887e-07\n",
      "Epoch 935/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.6254e-06 - val_loss: 7.0631e-07\n",
      "Epoch 936/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.0171e-06 - val_loss: 1.0177e-06\n",
      "Epoch 937/2000\n",
      "21471/21471 [==============================] - 0s 23us/step - loss: 9.4454e-06 - val_loss: 3.4691e-06\n",
      "Epoch 938/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.6900e-06 - val_loss: 8.3523e-07\n",
      "Epoch 939/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.3850e-06 - val_loss: 6.1134e-07\n",
      "Epoch 940/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.1669e-06 - val_loss: 2.6652e-06\n",
      "Epoch 941/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 6.5320e-06 - val_loss: 1.7592e-06\n",
      "Epoch 942/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.2835e-06 - val_loss: 7.9842e-07\n",
      "Epoch 943/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.6790e-06 - val_loss: 1.1638e-06\n",
      "Epoch 944/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.4531e-06 - val_loss: 5.4826e-07\n",
      "Epoch 945/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.2349e-06 - val_loss: 6.8456e-07\n",
      "Epoch 946/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.2406e-06 - val_loss: 5.0705e-07\n",
      "Epoch 947/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.3642e-06 - val_loss: 8.3139e-07\n",
      "Epoch 948/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.6474e-06 - val_loss: 2.0810e-06\n",
      "Epoch 949/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.1884e-06 - val_loss: 3.8025e-06\n",
      "Epoch 950/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.3429e-06 - val_loss: 9.3279e-07\n",
      "Epoch 951/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.7433e-06 - val_loss: 8.3882e-07\n",
      "Epoch 952/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 5.2436e-06 - val_loss: 7.4248e-07\n",
      "Epoch 953/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.4529e-06 - val_loss: 1.1706e-06\n",
      "Epoch 954/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 5.9001e-06 - val_loss: 4.2730e-06\n",
      "Epoch 955/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 5.8311e-06 - val_loss: 2.4844e-06\n",
      "Epoch 956/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.8744e-06 - val_loss: 1.0553e-06\n",
      "Epoch 957/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.7553e-06 - val_loss: 1.7770e-06\n",
      "Epoch 958/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.0609e-06 - val_loss: 8.9612e-07\n",
      "Epoch 959/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.2636e-06 - val_loss: 1.8789e-06\n",
      "Epoch 960/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.2597e-06 - val_loss: 5.5993e-07\n",
      "Epoch 961/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.4959e-06 - val_loss: 3.0199e-06\n",
      "Epoch 962/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.4241e-06 - val_loss: 1.8716e-06\n",
      "Epoch 963/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.4471e-06 - val_loss: 1.1760e-06\n",
      "Epoch 964/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.7198e-06 - val_loss: 1.3014e-06\n",
      "Epoch 965/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.0637e-06 - val_loss: 5.0647e-07\n",
      "Epoch 966/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.4162e-06 - val_loss: 5.9522e-07\n",
      "Epoch 967/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.4728e-06 - val_loss: 1.7243e-06\n",
      "Epoch 968/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.4920e-06 - val_loss: 5.6140e-07\n",
      "Epoch 969/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.8745e-06 - val_loss: 2.1584e-06\n",
      "Epoch 970/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.1771e-06 - val_loss: 6.0529e-07\n",
      "Epoch 971/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 5.6965e-06 - val_loss: 9.0796e-07\n",
      "Epoch 972/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.1400e-05 - val_loss: 1.1006e-06\n",
      "Epoch 973/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 3.0803e-06 - val_loss: 6.7104e-07\n",
      "Epoch 974/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.5498e-06 - val_loss: 9.5602e-07\n",
      "Epoch 975/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.7357e-06 - val_loss: 2.7305e-06\n",
      "Epoch 976/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.8163e-06 - val_loss: 5.5345e-07\n",
      "Epoch 977/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.6230e-06 - val_loss: 5.7354e-07\n",
      "Epoch 978/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.5741e-06 - val_loss: 6.7090e-07\n",
      "Epoch 979/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.6033e-06 - val_loss: 8.1430e-07\n",
      "Epoch 980/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.8256e-06 - val_loss: 8.1728e-07\n",
      "Epoch 981/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.2427e-06 - val_loss: 1.6569e-06\n",
      "Epoch 982/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.4491e-06 - val_loss: 7.9956e-07\n",
      "Epoch 983/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.3603e-06 - val_loss: 9.8937e-07\n",
      "Epoch 984/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.5782e-06 - val_loss: 1.4964e-06\n",
      "Epoch 985/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.3237e-06 - val_loss: 1.4923e-06\n",
      "Epoch 986/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.8616e-06 - val_loss: 6.1559e-07\n",
      "Epoch 987/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.6928e-06 - val_loss: 2.1703e-06\n",
      "Epoch 988/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 6.6049e-06 - val_loss: 2.2171e-06\n",
      "Epoch 989/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 5.3707e-06 - val_loss: 3.5467e-06\n",
      "Epoch 990/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.9800e-06 - val_loss: 1.0711e-06\n",
      "Epoch 991/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.4409e-06 - val_loss: 6.1339e-07\n",
      "Epoch 992/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.5619e-06 - val_loss: 6.2446e-07\n",
      "Epoch 993/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 5.4670e-06 - val_loss: 3.4449e-06\n",
      "Epoch 994/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.7732e-06 - val_loss: 1.5134e-06\n",
      "Epoch 995/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.4699e-06 - val_loss: 8.4905e-07\n",
      "Epoch 996/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.9469e-06 - val_loss: 1.4854e-06\n",
      "Epoch 997/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.8877e-06 - val_loss: 1.6946e-06\n",
      "Epoch 998/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.1414e-06 - val_loss: 8.5515e-07\n",
      "Epoch 999/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.1711e-06 - val_loss: 5.8586e-07\n",
      "Epoch 1000/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.9408e-06 - val_loss: 5.5036e-07\n",
      "Epoch 1001/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.9037e-06 - val_loss: 5.5085e-07\n",
      "Epoch 1002/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.4522e-06 - val_loss: 6.2471e-07\n",
      "Epoch 1003/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.0545e-06 - val_loss: 3.4101e-06\n",
      "Epoch 1004/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.6185e-06 - val_loss: 1.3542e-06\n",
      "Epoch 1005/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.2125e-06 - val_loss: 9.8799e-07\n",
      "Epoch 1006/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.4088e-06 - val_loss: 1.0688e-06\n",
      "Epoch 1007/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.8476e-06 - val_loss: 7.9648e-07\n",
      "Epoch 1008/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.4009e-06 - val_loss: 1.5630e-06\n",
      "Epoch 1009/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.2870e-05 - val_loss: 1.9545e-06\n",
      "Epoch 1010/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 6.1094e-06 - val_loss: 1.5654e-06\n",
      "Epoch 1011/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 5.9861e-06 - val_loss: 1.2160e-06\n",
      "Epoch 1012/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 6.8150e-06 - val_loss: 9.9233e-07\n",
      "Epoch 1013/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.5743e-06 - val_loss: 6.3160e-07\n",
      "Epoch 1014/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.9571e-06 - val_loss: 1.6140e-06\n",
      "Epoch 1015/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.1223e-06 - val_loss: 9.3470e-07\n",
      "Epoch 1016/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 5.1986e-06 - val_loss: 7.1307e-07\n",
      "Epoch 1017/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.5040e-06 - val_loss: 1.2050e-06\n",
      "Epoch 1018/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.0545e-06 - val_loss: 2.3164e-06\n",
      "Epoch 1019/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.6734e-06 - val_loss: 1.6076e-06\n",
      "Epoch 1020/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.6712e-06 - val_loss: 1.0587e-06\n",
      "Epoch 1021/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.5462e-06 - val_loss: 1.4962e-06\n",
      "Epoch 1022/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.8218e-06 - val_loss: 8.4288e-07\n",
      "Epoch 1023/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.1990e-06 - val_loss: 9.2278e-07\n",
      "Epoch 1024/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.5937e-06 - val_loss: 7.4260e-07\n",
      "Epoch 1025/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.7663e-06 - val_loss: 9.9144e-07\n",
      "Epoch 1026/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.9288e-06 - val_loss: 8.0366e-07\n",
      "Epoch 1027/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.3105e-06 - val_loss: 8.4653e-07\n",
      "Epoch 1028/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.6362e-06 - val_loss: 3.5738e-06\n",
      "Epoch 1029/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.6641e-06 - val_loss: 2.7864e-06\n",
      "Epoch 1030/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.4894e-06 - val_loss: 7.6599e-07\n",
      "Epoch 1031/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.9601e-06 - val_loss: 2.8270e-06\n",
      "Epoch 1032/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.2322e-06 - val_loss: 1.1785e-06\n",
      "Epoch 1033/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.3497e-06 - val_loss: 7.5662e-07\n",
      "Epoch 1034/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.0472e-06 - val_loss: 6.6607e-07\n",
      "Epoch 1035/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.8359e-06 - val_loss: 3.6118e-06\n",
      "Epoch 1036/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.3462e-06 - val_loss: 7.5834e-07\n",
      "Epoch 1037/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.8854e-06 - val_loss: 1.0515e-06\n",
      "Epoch 1038/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.8146e-06 - val_loss: 1.0744e-06\n",
      "Epoch 1039/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 7.3132e-06 - val_loss: 8.4977e-07\n",
      "Epoch 1040/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.8887e-05 - val_loss: 1.7091e-06\n",
      "Epoch 1041/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.3980e-06 - val_loss: 1.3004e-06\n",
      "Epoch 1042/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.8172e-06 - val_loss: 7.9773e-07\n",
      "Epoch 1043/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 6.0866e-06 - val_loss: 1.5608e-06\n",
      "Epoch 1044/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.8486e-06 - val_loss: 7.5935e-07\n",
      "Epoch 1045/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 2.3589e-06 - val_loss: 8.8351e-07\n",
      "Epoch 1046/2000\n",
      "21471/21471 [==============================] - 1s 24us/step - loss: 2.7712e-06 - val_loss: 6.3047e-07\n",
      "Epoch 1047/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.4597e-06 - val_loss: 9.2939e-07\n",
      "Epoch 1048/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.8605e-06 - val_loss: 1.6333e-06\n",
      "Epoch 1049/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.7933e-06 - val_loss: 7.1091e-07\n",
      "Epoch 1050/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.8638e-06 - val_loss: 6.1693e-07\n",
      "Epoch 1051/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.6651e-06 - val_loss: 7.2839e-07\n",
      "Epoch 1052/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.5409e-06 - val_loss: 6.2862e-07\n",
      "Epoch 1053/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.5547e-06 - val_loss: 3.0878e-06\n",
      "Epoch 1054/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.7338e-06 - val_loss: 8.8068e-07\n",
      "Epoch 1055/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.4033e-06 - val_loss: 9.6459e-07\n",
      "Epoch 1056/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.8279e-06 - val_loss: 1.4544e-06\n",
      "Epoch 1057/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 7.3060e-06 - val_loss: 1.0052e-05\n",
      "Epoch 1058/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.1564e-05 - val_loss: 3.3691e-06\n",
      "Epoch 1059/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.0328e-05 - val_loss: 1.0028e-06\n",
      "Epoch 1060/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.4312e-06 - val_loss: 7.0973e-07\n",
      "Epoch 1061/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.2609e-06 - val_loss: 7.3962e-07\n",
      "Epoch 1062/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.2826e-06 - val_loss: 5.3152e-06\n",
      "Epoch 1063/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.2472e-06 - val_loss: 1.1033e-06\n",
      "Epoch 1064/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.7901e-06 - val_loss: 1.4469e-06\n",
      "Epoch 1065/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.2187e-06 - val_loss: 6.7124e-07\n",
      "Epoch 1066/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.8364e-06 - val_loss: 8.2925e-07\n",
      "Epoch 1067/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.1521e-06 - val_loss: 1.1994e-06\n",
      "Epoch 1068/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.7720e-06 - val_loss: 6.3738e-07\n",
      "Epoch 1069/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 5.6919e-06 - val_loss: 1.3303e-06\n",
      "Epoch 1070/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.4300e-06 - val_loss: 8.4617e-07\n",
      "Epoch 1071/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 3.0013e-06 - val_loss: 9.7448e-07\n",
      "Epoch 1072/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.5895e-06 - val_loss: 8.6500e-07\n",
      "Epoch 1073/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.2326e-06 - val_loss: 2.6348e-06\n",
      "Epoch 1074/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.1112e-06 - val_loss: 2.2396e-06\n",
      "Epoch 1075/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.1466e-06 - val_loss: 1.4797e-06\n",
      "Epoch 1076/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.0257e-06 - val_loss: 1.2703e-06\n",
      "Epoch 1077/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.8967e-06 - val_loss: 1.9916e-06\n",
      "Epoch 1078/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.3007e-06 - val_loss: 9.4344e-07\n",
      "Epoch 1079/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.2169e-06 - val_loss: 9.2637e-07\n",
      "Epoch 1080/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.6294e-06 - val_loss: 1.2575e-06\n",
      "Epoch 1081/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.9313e-06 - val_loss: 1.9338e-06\n",
      "Epoch 1082/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 2.5829e-06 - val_loss: 5.3511e-07\n",
      "Epoch 1083/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.7211e-06 - val_loss: 8.6908e-07\n",
      "Epoch 1084/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.9020e-06 - val_loss: 8.4293e-07\n",
      "Epoch 1085/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.6013e-06 - val_loss: 1.0481e-06\n",
      "Epoch 1086/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.8503e-06 - val_loss: 1.3573e-06\n",
      "Epoch 1087/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.6265e-06 - val_loss: 3.9507e-06\n",
      "Epoch 1088/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.9939e-06 - val_loss: 6.9963e-07\n",
      "Epoch 1089/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.6440e-06 - val_loss: 5.3238e-07\n",
      "Epoch 1090/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.6999e-06 - val_loss: 7.6869e-07\n",
      "Epoch 1091/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 5.5858e-06 - val_loss: 2.2293e-06\n",
      "Epoch 1092/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.5395e-06 - val_loss: 2.1171e-06\n",
      "Epoch 1093/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 5.0790e-06 - val_loss: 3.6911e-06\n",
      "Epoch 1094/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.4150e-06 - val_loss: 5.7375e-07\n",
      "Epoch 1095/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.8504e-06 - val_loss: 1.0583e-06\n",
      "Epoch 1096/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.8008e-06 - val_loss: 1.1380e-06\n",
      "Epoch 1097/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.1033e-06 - val_loss: 1.1292e-06\n",
      "Epoch 1098/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.4525e-06 - val_loss: 5.4605e-07\n",
      "Epoch 1099/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.3820e-06 - val_loss: 2.0914e-06\n",
      "Epoch 1100/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.3542e-06 - val_loss: 6.7262e-07\n",
      "Epoch 1101/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.4774e-06 - val_loss: 2.0824e-06\n",
      "Epoch 1102/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.9583e-06 - val_loss: 8.3095e-07\n",
      "Epoch 1103/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.4052e-06 - val_loss: 9.8863e-07\n",
      "Epoch 1104/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.2851e-06 - val_loss: 3.2242e-06\n",
      "Epoch 1105/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.4509e-06 - val_loss: 1.0150e-06\n",
      "Epoch 1106/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.4807e-06 - val_loss: 1.6459e-06\n",
      "Epoch 1107/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.4312e-06 - val_loss: 1.6071e-06\n",
      "Epoch 1108/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.0591e-06 - val_loss: 3.2845e-06\n",
      "Epoch 1109/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 6.9023e-06 - val_loss: 8.9538e-07\n",
      "Epoch 1110/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.0805e-06 - val_loss: 1.1202e-06\n",
      "Epoch 1111/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 6.6525e-06 - val_loss: 5.9074e-06\n",
      "Epoch 1112/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.1825e-06 - val_loss: 6.5561e-07\n",
      "Epoch 1113/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.1098e-06 - val_loss: 5.9172e-07\n",
      "Epoch 1114/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.5994e-06 - val_loss: 1.9975e-06\n",
      "Epoch 1115/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.4004e-06 - val_loss: 1.4433e-06\n",
      "Epoch 1116/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.7334e-06 - val_loss: 5.2684e-07\n",
      "Epoch 1117/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.1011e-06 - val_loss: 1.1557e-06\n",
      "Epoch 1118/2000\n",
      "21471/21471 [==============================] - 0s 23us/step - loss: 3.3402e-06 - val_loss: 1.5906e-06\n",
      "Epoch 1119/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.0005e-06 - val_loss: 9.5414e-07\n",
      "Epoch 1120/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.1610e-06 - val_loss: 1.3144e-06\n",
      "Epoch 1121/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.2411e-06 - val_loss: 1.2766e-06\n",
      "Epoch 1122/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.4171e-06 - val_loss: 1.1392e-05\n",
      "Epoch 1123/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.5784e-06 - val_loss: 1.0941e-06\n",
      "Epoch 1124/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.0493e-06 - val_loss: 7.4644e-07\n",
      "Epoch 1125/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.5292e-06 - val_loss: 2.3068e-06\n",
      "Epoch 1126/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.8246e-06 - val_loss: 7.7334e-07\n",
      "Epoch 1127/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.2335e-06 - val_loss: 9.4785e-07\n",
      "Epoch 1128/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.1992e-06 - val_loss: 1.2985e-06\n",
      "Epoch 1129/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 6.6849e-06 - val_loss: 3.8500e-06\n",
      "Epoch 1130/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.1266e-06 - val_loss: 1.7935e-06\n",
      "Epoch 1131/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.9004e-06 - val_loss: 1.0104e-06\n",
      "Epoch 1132/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.1443e-06 - val_loss: 8.4026e-07\n",
      "Epoch 1133/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.9384e-06 - val_loss: 7.4657e-07\n",
      "Epoch 1134/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.2384e-06 - val_loss: 9.4331e-07\n",
      "Epoch 1135/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.5287e-06 - val_loss: 9.2238e-07\n",
      "Epoch 1136/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.0307e-06 - val_loss: 7.3817e-07\n",
      "Epoch 1137/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.9248e-06 - val_loss: 1.4811e-06\n",
      "Epoch 1138/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.8412e-06 - val_loss: 1.9401e-06\n",
      "Epoch 1139/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.7184e-06 - val_loss: 3.1033e-06\n",
      "Epoch 1140/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.3669e-06 - val_loss: 2.4078e-06\n",
      "Epoch 1141/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.4354e-06 - val_loss: 1.6284e-06\n",
      "Epoch 1142/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.7031e-06 - val_loss: 1.1505e-06\n",
      "Epoch 1143/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 5.5633e-06 - val_loss: 2.0612e-06\n",
      "Epoch 1144/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.1429e-06 - val_loss: 8.8612e-07\n",
      "Epoch 1145/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.4747e-06 - val_loss: 6.3825e-07\n",
      "Epoch 1146/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 7.0013e-06 - val_loss: 3.5202e-06\n",
      "Epoch 1147/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 6.6195e-06 - val_loss: 1.1371e-06\n",
      "Epoch 1148/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.0937e-06 - val_loss: 7.2726e-07\n",
      "Epoch 1149/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.1794e-06 - val_loss: 7.0997e-07\n",
      "Epoch 1150/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.3726e-06 - val_loss: 2.7118e-06\n",
      "Epoch 1151/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.9117e-06 - val_loss: 1.7135e-06\n",
      "Epoch 1152/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.8447e-06 - val_loss: 9.1136e-07\n",
      "Epoch 1153/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.8634e-06 - val_loss: 5.9053e-07\n",
      "Epoch 1154/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 1.8854e-06 - val_loss: 6.4003e-07\n",
      "Epoch 1155/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 5.7437e-06 - val_loss: 8.5060e-07\n",
      "Epoch 1156/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.1434e-06 - val_loss: 2.6672e-06\n",
      "Epoch 1157/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.2943e-06 - val_loss: 7.8781e-07\n",
      "Epoch 1158/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.4755e-05 - val_loss: 1.3567e-04\n",
      "Epoch 1159/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.4404e-04 - val_loss: 3.8940e-05\n",
      "Epoch 1160/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.3988e-05 - val_loss: 5.4655e-06\n",
      "Epoch 1161/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.2337e-05 - val_loss: 2.8068e-06\n",
      "Epoch 1162/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.5444e-06 - val_loss: 3.1542e-06\n",
      "Epoch 1163/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.6486e-06 - val_loss: 5.9702e-06\n",
      "Epoch 1164/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 7.8797e-06 - val_loss: 1.3358e-06\n",
      "Epoch 1165/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.1002e-06 - val_loss: 1.0504e-06\n",
      "Epoch 1166/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.8691e-06 - val_loss: 1.0774e-06\n",
      "Epoch 1167/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.4348e-06 - val_loss: 9.3460e-07\n",
      "Epoch 1168/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.7108e-06 - val_loss: 9.2774e-07\n",
      "Epoch 1169/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 5.3941e-06 - val_loss: 6.7619e-07\n",
      "Epoch 1170/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.4916e-06 - val_loss: 7.2645e-07\n",
      "Epoch 1171/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.3328e-06 - val_loss: 4.9488e-07\n",
      "Epoch 1172/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.9573e-06 - val_loss: 6.5081e-07\n",
      "Epoch 1173/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.7182e-06 - val_loss: 5.4293e-07\n",
      "Epoch 1174/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.7418e-06 - val_loss: 4.6953e-07\n",
      "Epoch 1175/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.1418e-06 - val_loss: 5.7999e-07\n",
      "Epoch 1176/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.5217e-06 - val_loss: 1.1604e-06\n",
      "Epoch 1177/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.8632e-06 - val_loss: 6.0900e-07\n",
      "Epoch 1178/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.3329e-06 - val_loss: 6.1412e-07\n",
      "Epoch 1179/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.9366e-06 - val_loss: 8.5213e-07\n",
      "Epoch 1180/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.1432e-06 - val_loss: 1.2279e-06\n",
      "Epoch 1181/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.0182e-06 - val_loss: 4.3784e-07\n",
      "Epoch 1182/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.8187e-06 - val_loss: 1.2778e-06\n",
      "Epoch 1183/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.6377e-06 - val_loss: 6.3348e-07\n",
      "Epoch 1184/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.8068e-06 - val_loss: 8.7365e-07\n",
      "Epoch 1185/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.4651e-06 - val_loss: 9.1034e-07\n",
      "Epoch 1186/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.1037e-06 - val_loss: 4.7041e-07\n",
      "Epoch 1187/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.3139e-06 - val_loss: 5.1291e-07\n",
      "Epoch 1188/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.2721e-06 - val_loss: 7.1514e-07\n",
      "Epoch 1189/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 2.2020e-06 - val_loss: 4.9989e-07\n",
      "Epoch 1190/2000\n",
      "21471/21471 [==============================] - 0s 23us/step - loss: 1.7211e-06 - val_loss: 5.2023e-07\n",
      "Epoch 1191/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.6715e-06 - val_loss: 7.9694e-07\n",
      "Epoch 1192/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.3350e-06 - val_loss: 4.4761e-07\n",
      "Epoch 1193/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.0356e-06 - val_loss: 1.1902e-06\n",
      "Epoch 1194/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.4476e-06 - val_loss: 4.5188e-07\n",
      "Epoch 1195/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.9607e-06 - val_loss: 1.0367e-06\n",
      "Epoch 1196/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 5.4374e-06 - val_loss: 4.4704e-07\n",
      "Epoch 1197/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.2574e-06 - val_loss: 7.9052e-07\n",
      "Epoch 1198/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.1377e-06 - val_loss: 4.8024e-07\n",
      "Epoch 1199/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.8332e-06 - val_loss: 7.1327e-07\n",
      "Epoch 1200/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.8145e-06 - val_loss: 4.2200e-07\n",
      "Epoch 1201/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.1565e-06 - val_loss: 6.0556e-07\n",
      "Epoch 1202/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.0104e-05 - val_loss: 3.8298e-06\n",
      "Epoch 1203/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 5.5781e-06 - val_loss: 6.1309e-07\n",
      "Epoch 1204/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.0128e-06 - val_loss: 5.9079e-07\n",
      "Epoch 1205/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.7817e-06 - val_loss: 5.1262e-07\n",
      "Epoch 1206/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.6982e-06 - val_loss: 8.2536e-07\n",
      "Epoch 1207/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.1367e-06 - val_loss: 3.6556e-07\n",
      "Epoch 1208/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.4658e-06 - val_loss: 3.7204e-07\n",
      "Epoch 1209/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.4054e-06 - val_loss: 4.0719e-07\n",
      "Epoch 1210/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.4916e-06 - val_loss: 3.5737e-07\n",
      "Epoch 1211/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.6392e-06 - val_loss: 5.0490e-07\n",
      "Epoch 1212/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.8729e-06 - val_loss: 6.4112e-07\n",
      "Epoch 1213/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.2080e-06 - val_loss: 5.9971e-07\n",
      "Epoch 1214/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.4942e-06 - val_loss: 6.2494e-07\n",
      "Epoch 1215/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.8638e-06 - val_loss: 5.7329e-07\n",
      "Epoch 1216/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.5077e-06 - val_loss: 9.0610e-07\n",
      "Epoch 1217/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.1282e-06 - val_loss: 7.7449e-07\n",
      "Epoch 1218/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.1731e-06 - val_loss: 8.6466e-07\n",
      "Epoch 1219/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.0318e-06 - val_loss: 1.0083e-06\n",
      "Epoch 1220/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.0171e-06 - val_loss: 4.4393e-06\n",
      "Epoch 1221/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 6.2909e-06 - val_loss: 1.5870e-06\n",
      "Epoch 1222/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.7893e-06 - val_loss: 6.4202e-07\n",
      "Epoch 1223/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.8081e-06 - val_loss: 1.2799e-06\n",
      "Epoch 1224/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.4253e-06 - val_loss: 4.0565e-07\n",
      "Epoch 1225/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 2.4526e-06 - val_loss: 5.8898e-07\n",
      "Epoch 1226/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 2.3660e-06 - val_loss: 4.5926e-07\n",
      "Epoch 1227/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.7989e-06 - val_loss: 3.7298e-07\n",
      "Epoch 1228/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.0629e-06 - val_loss: 6.5652e-07\n",
      "Epoch 1229/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.0547e-06 - val_loss: 7.4440e-07\n",
      "Epoch 1230/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.5399e-06 - val_loss: 1.2712e-06\n",
      "Epoch 1231/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.5703e-06 - val_loss: 1.1154e-06\n",
      "Epoch 1232/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.3709e-06 - val_loss: 5.7826e-07\n",
      "Epoch 1233/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.6219e-06 - val_loss: 5.0076e-07\n",
      "Epoch 1234/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.2112e-06 - val_loss: 4.6761e-07\n",
      "Epoch 1235/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.0297e-06 - val_loss: 5.5700e-07\n",
      "Epoch 1236/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.1598e-06 - val_loss: 6.4335e-07\n",
      "Epoch 1237/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.5577e-06 - val_loss: 1.0676e-06\n",
      "Epoch 1238/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.5150e-06 - val_loss: 6.2110e-07\n",
      "Epoch 1239/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.0225e-06 - val_loss: 5.1613e-07\n",
      "Epoch 1240/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 6.6976e-06 - val_loss: 6.9981e-07\n",
      "Epoch 1241/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.9659e-06 - val_loss: 5.5540e-07\n",
      "Epoch 1242/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.3466e-06 - val_loss: 2.5366e-06\n",
      "Epoch 1243/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.3912e-06 - val_loss: 5.8226e-07\n",
      "Epoch 1244/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.4657e-06 - val_loss: 4.5245e-07\n",
      "Epoch 1245/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.1728e-06 - val_loss: 7.0710e-07\n",
      "Epoch 1246/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.8858e-06 - val_loss: 8.4953e-07\n",
      "Epoch 1247/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.0067e-06 - val_loss: 7.8258e-07\n",
      "Epoch 1248/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.1233e-06 - val_loss: 9.9648e-07\n",
      "Epoch 1249/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.7306e-06 - val_loss: 4.8075e-07\n",
      "Epoch 1250/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.7276e-06 - val_loss: 6.4684e-07\n",
      "Epoch 1251/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.4020e-06 - val_loss: 6.3631e-07\n",
      "Epoch 1252/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.6433e-06 - val_loss: 4.7799e-07\n",
      "Epoch 1253/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.6951e-06 - val_loss: 8.4290e-07\n",
      "Epoch 1254/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 7.6039e-06 - val_loss: 2.0221e-06\n",
      "Epoch 1255/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.0249e-06 - val_loss: 5.5695e-07\n",
      "Epoch 1256/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.0547e-06 - val_loss: 6.7944e-07\n",
      "Epoch 1257/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.8522e-06 - val_loss: 7.8675e-07\n",
      "Epoch 1258/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.8345e-06 - val_loss: 1.8789e-06\n",
      "Epoch 1259/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.3323e-06 - val_loss: 5.0433e-07\n",
      "Epoch 1260/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.2153e-05 - val_loss: 8.9751e-06\n",
      "Epoch 1261/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.1313e-06 - val_loss: 6.5743e-07\n",
      "Epoch 1262/2000\n",
      "21471/21471 [==============================] - 0s 23us/step - loss: 2.5938e-06 - val_loss: 6.9813e-07\n",
      "Epoch 1263/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.5468e-06 - val_loss: 5.1602e-07\n",
      "Epoch 1264/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.3536e-06 - val_loss: 6.7898e-07\n",
      "Epoch 1265/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.8488e-06 - val_loss: 7.4269e-07\n",
      "Epoch 1266/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.4461e-06 - val_loss: 1.7565e-06\n",
      "Epoch 1267/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.8298e-06 - val_loss: 1.2909e-06\n",
      "Epoch 1268/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.6187e-06 - val_loss: 4.5298e-06\n",
      "Epoch 1269/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.1916e-06 - val_loss: 6.1006e-07\n",
      "Epoch 1270/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.4320e-06 - val_loss: 7.2185e-07\n",
      "Epoch 1271/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.0078e-06 - val_loss: 6.0759e-07\n",
      "Epoch 1272/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.0541e-06 - val_loss: 1.0971e-06\n",
      "Epoch 1273/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.3461e-06 - val_loss: 6.6958e-07\n",
      "Epoch 1274/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.8361e-06 - val_loss: 8.5251e-07\n",
      "Epoch 1275/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.4766e-06 - val_loss: 1.0866e-06\n",
      "Epoch 1276/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.5433e-06 - val_loss: 6.1469e-07\n",
      "Epoch 1277/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.1552e-06 - val_loss: 6.9956e-07\n",
      "Epoch 1278/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.3607e-06 - val_loss: 1.0198e-06\n",
      "Epoch 1279/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.7016e-06 - val_loss: 5.7427e-07\n",
      "Epoch 1280/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.1538e-06 - val_loss: 1.4171e-06\n",
      "Epoch 1281/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.1877e-06 - val_loss: 9.0686e-07\n",
      "Epoch 1282/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.5056e-05 - val_loss: 4.0352e-06\n",
      "Epoch 1283/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.8344e-06 - val_loss: 6.1441e-07\n",
      "Epoch 1284/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.9696e-06 - val_loss: 1.9478e-06\n",
      "Epoch 1285/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 5.1839e-06 - val_loss: 8.0120e-07\n",
      "Epoch 1286/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.7407e-06 - val_loss: 2.1064e-06\n",
      "Epoch 1287/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.8065e-06 - val_loss: 6.2726e-07\n",
      "Epoch 1288/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.6612e-06 - val_loss: 1.3005e-06\n",
      "Epoch 1289/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.7442e-06 - val_loss: 4.6329e-07\n",
      "Epoch 1290/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.4665e-06 - val_loss: 9.9000e-07\n",
      "Epoch 1291/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.7448e-06 - val_loss: 1.9014e-06\n",
      "Epoch 1292/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.5622e-06 - val_loss: 1.1150e-06\n",
      "Epoch 1293/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 5.3662e-06 - val_loss: 2.0471e-06\n",
      "Epoch 1294/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.3340e-06 - val_loss: 8.9981e-07\n",
      "Epoch 1295/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.0994e-06 - val_loss: 5.8217e-07\n",
      "Epoch 1296/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.2160e-06 - val_loss: 1.2361e-06\n",
      "Epoch 1297/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.4674e-06 - val_loss: 5.2363e-07\n",
      "Epoch 1298/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 3.2837e-06 - val_loss: 6.2792e-07\n",
      "Epoch 1299/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 3.6114e-06 - val_loss: 2.8445e-06\n",
      "Epoch 1300/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.1568e-06 - val_loss: 1.9563e-06\n",
      "Epoch 1301/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.8327e-06 - val_loss: 1.0435e-06\n",
      "Epoch 1302/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.2096e-06 - val_loss: 7.7896e-07\n",
      "Epoch 1303/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.4288e-06 - val_loss: 5.5871e-07\n",
      "Epoch 1304/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.5440e-06 - val_loss: 7.3195e-07\n",
      "Epoch 1305/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.5354e-06 - val_loss: 1.5725e-06\n",
      "Epoch 1306/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.8238e-06 - val_loss: 1.1518e-06\n",
      "Epoch 1307/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.8881e-06 - val_loss: 6.8595e-07\n",
      "Epoch 1308/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.5953e-06 - val_loss: 1.3106e-06\n",
      "Epoch 1309/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.1942e-06 - val_loss: 1.2214e-06\n",
      "Epoch 1310/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.2652e-06 - val_loss: 5.8585e-07\n",
      "Epoch 1311/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.6404e-06 - val_loss: 1.2702e-06\n",
      "Epoch 1312/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.6465e-06 - val_loss: 5.2407e-07\n",
      "Epoch 1313/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 7.1534e-06 - val_loss: 6.9964e-07\n",
      "Epoch 1314/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.3958e-06 - val_loss: 1.0903e-06\n",
      "Epoch 1315/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.2806e-06 - val_loss: 6.9744e-07\n",
      "Epoch 1316/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.0792e-06 - val_loss: 6.9284e-07\n",
      "Epoch 1317/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 5.0163e-06 - val_loss: 8.0120e-07\n",
      "Epoch 1318/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.2870e-06 - val_loss: 2.1053e-06\n",
      "Epoch 1319/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.1887e-06 - val_loss: 5.5165e-07\n",
      "Epoch 1320/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.0619e-06 - val_loss: 4.6936e-07\n",
      "Epoch 1321/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.7392e-06 - val_loss: 7.2266e-07\n",
      "Epoch 1322/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.7261e-06 - val_loss: 3.4850e-06\n",
      "Epoch 1323/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 5.6200e-06 - val_loss: 4.5747e-07\n",
      "Epoch 1324/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.9572e-06 - val_loss: 9.1414e-07\n",
      "Epoch 1325/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.7345e-06 - val_loss: 1.0960e-06\n",
      "Epoch 1326/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.9524e-06 - val_loss: 3.6711e-06\n",
      "Epoch 1327/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 5.3500e-06 - val_loss: 6.4398e-07\n",
      "Epoch 1328/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.0875e-06 - val_loss: 8.4027e-07\n",
      "Epoch 1329/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.6996e-06 - val_loss: 6.7680e-07\n",
      "Epoch 1330/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.4751e-06 - val_loss: 4.9946e-07\n",
      "Epoch 1331/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.4949e-06 - val_loss: 7.2814e-07\n",
      "Epoch 1332/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.6429e-06 - val_loss: 3.0254e-06\n",
      "Epoch 1333/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.4907e-06 - val_loss: 1.9189e-06\n",
      "Epoch 1334/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 3.2905e-06 - val_loss: 6.8842e-07\n",
      "Epoch 1335/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 2.0878e-06 - val_loss: 9.0054e-07\n",
      "Epoch 1336/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.7893e-06 - val_loss: 1.0993e-06\n",
      "Epoch 1337/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.8857e-06 - val_loss: 7.1418e-07\n",
      "Epoch 1338/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.3612e-05 - val_loss: 1.1952e-06\n",
      "Epoch 1339/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.9429e-06 - val_loss: 8.7936e-07\n",
      "Epoch 1340/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.0291e-06 - val_loss: 1.0423e-06\n",
      "Epoch 1341/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.5928e-06 - val_loss: 7.1945e-07\n",
      "Epoch 1342/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.5540e-06 - val_loss: 8.4727e-07\n",
      "Epoch 1343/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.8484e-06 - val_loss: 6.8869e-07\n",
      "Epoch 1344/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.8660e-06 - val_loss: 4.5652e-07\n",
      "Epoch 1345/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.2178e-06 - val_loss: 3.8189e-07\n",
      "Epoch 1346/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.2067e-06 - val_loss: 4.3782e-07\n",
      "Epoch 1347/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.1769e-06 - val_loss: 1.0056e-06\n",
      "Epoch 1348/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.5052e-06 - val_loss: 1.5122e-06\n",
      "Epoch 1349/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.5581e-06 - val_loss: 5.1238e-07\n",
      "Epoch 1350/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.3108e-06 - val_loss: 5.4958e-07\n",
      "Epoch 1351/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.1049e-06 - val_loss: 5.4868e-07\n",
      "Epoch 1352/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.7069e-06 - val_loss: 4.5361e-07\n",
      "Epoch 1353/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.6515e-06 - val_loss: 1.1430e-06\n",
      "Epoch 1354/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.8772e-06 - val_loss: 7.0555e-07\n",
      "Epoch 1355/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.5921e-06 - val_loss: 6.3251e-07\n",
      "Epoch 1356/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.9599e-06 - val_loss: 2.8718e-06\n",
      "Epoch 1357/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.5392e-06 - val_loss: 1.2065e-06\n",
      "Epoch 1358/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.4939e-06 - val_loss: 1.7056e-06\n",
      "Epoch 1359/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.6466e-06 - val_loss: 1.1042e-06\n",
      "Epoch 1360/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.2293e-06 - val_loss: 8.5244e-07\n",
      "Epoch 1361/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.6966e-06 - val_loss: 1.4473e-06\n",
      "Epoch 1362/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.8400e-06 - val_loss: 2.1063e-06\n",
      "Epoch 1363/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.5691e-06 - val_loss: 5.5517e-07\n",
      "Epoch 1364/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.2392e-06 - val_loss: 4.6861e-07\n",
      "Epoch 1365/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.7305e-06 - val_loss: 6.8866e-07\n",
      "Epoch 1366/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.0361e-06 - val_loss: 4.3839e-07\n",
      "Epoch 1367/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.6939e-06 - val_loss: 1.3093e-06\n",
      "Epoch 1368/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.4916e-06 - val_loss: 9.3152e-07\n",
      "Epoch 1369/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.2836e-06 - val_loss: 1.1708e-06\n",
      "Epoch 1370/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.2913e-06 - val_loss: 9.1309e-07\n",
      "Epoch 1371/2000\n",
      "21471/21471 [==============================] - 1s 24us/step - loss: 3.4382e-06 - val_loss: 2.0200e-06\n",
      "Epoch 1372/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.7741e-06 - val_loss: 8.5168e-07\n",
      "Epoch 1373/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.1138e-06 - val_loss: 9.4152e-07\n",
      "Epoch 1374/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.6293e-06 - val_loss: 5.8615e-07\n",
      "Epoch 1375/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.4607e-06 - val_loss: 2.6602e-06\n",
      "Epoch 1376/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.0633e-06 - val_loss: 1.2438e-06\n",
      "Epoch 1377/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.2984e-06 - val_loss: 7.9839e-07\n",
      "Epoch 1378/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.4426e-06 - val_loss: 1.5631e-06\n",
      "Epoch 1379/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.3116e-06 - val_loss: 2.5654e-06\n",
      "Epoch 1380/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.6713e-06 - val_loss: 5.5519e-07\n",
      "Epoch 1381/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.2317e-06 - val_loss: 2.3243e-06\n",
      "Epoch 1382/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.0180e-06 - val_loss: 2.5349e-06\n",
      "Epoch 1383/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.3734e-06 - val_loss: 9.5252e-07\n",
      "Epoch 1384/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.5775e-06 - val_loss: 2.6097e-06\n",
      "Epoch 1385/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.1107e-06 - val_loss: 1.1876e-06\n",
      "Epoch 1386/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.5663e-06 - val_loss: 7.3696e-07\n",
      "Epoch 1387/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.8580e-06 - val_loss: 1.0795e-06\n",
      "Epoch 1388/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.0590e-06 - val_loss: 8.4278e-07\n",
      "Epoch 1389/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.4357e-06 - val_loss: 1.0402e-06\n",
      "Epoch 1390/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.2947e-06 - val_loss: 6.6109e-07\n",
      "Epoch 1391/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.2542e-06 - val_loss: 1.1464e-06\n",
      "Epoch 1392/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.4759e-06 - val_loss: 5.5114e-07\n",
      "Epoch 1393/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.0345e-06 - val_loss: 6.7230e-07\n",
      "Epoch 1394/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.3262e-06 - val_loss: 1.3195e-06\n",
      "Epoch 1395/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.5512e-06 - val_loss: 2.2228e-06\n",
      "Epoch 1396/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.2432e-06 - val_loss: 1.1335e-06\n",
      "Epoch 1397/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.2955e-06 - val_loss: 2.9494e-06\n",
      "Epoch 1398/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.8376e-06 - val_loss: 1.4188e-06\n",
      "Epoch 1399/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.0153e-06 - val_loss: 7.8799e-07\n",
      "Epoch 1400/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.2787e-06 - val_loss: 1.4269e-06\n",
      "Epoch 1401/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.4022e-06 - val_loss: 8.8737e-07\n",
      "Epoch 1402/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.2890e-06 - val_loss: 1.2334e-06\n",
      "Epoch 1403/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.1707e-06 - val_loss: 9.9171e-07\n",
      "Epoch 1404/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.0671e-06 - val_loss: 1.0914e-06\n",
      "Epoch 1405/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.2189e-06 - val_loss: 1.1877e-06\n",
      "Epoch 1406/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 6.5421e-06 - val_loss: 1.9340e-06\n",
      "Epoch 1407/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 1.9505e-04 - val_loss: 7.4767e-05\n",
      "Epoch 1408/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 5.6853e-05 - val_loss: 2.6593e-05\n",
      "Epoch 1409/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.0722e-05 - val_loss: 1.2486e-05\n",
      "Epoch 1410/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.4763e-05 - val_loss: 4.2647e-06\n",
      "Epoch 1411/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.1227e-05 - val_loss: 2.4865e-06\n",
      "Epoch 1412/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.7995e-06 - val_loss: 1.8319e-06\n",
      "Epoch 1413/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.3491e-05 - val_loss: 3.1802e-06\n",
      "Epoch 1414/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.1353e-05 - val_loss: 1.8656e-06\n",
      "Epoch 1415/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.4885e-06 - val_loss: 1.8295e-06\n",
      "Epoch 1416/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 5.8880e-06 - val_loss: 1.4291e-06\n",
      "Epoch 1417/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 5.1834e-06 - val_loss: 1.0792e-06\n",
      "Epoch 1418/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 6.3166e-06 - val_loss: 1.0036e-06\n",
      "Epoch 1419/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.6630e-06 - val_loss: 8.4157e-07\n",
      "Epoch 1420/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 5.6119e-06 - val_loss: 1.4906e-06\n",
      "Epoch 1421/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.0410e-06 - val_loss: 8.3557e-07\n",
      "Epoch 1422/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.0216e-06 - val_loss: 6.5745e-07\n",
      "Epoch 1423/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.9842e-06 - val_loss: 5.7308e-07\n",
      "Epoch 1424/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.7391e-06 - val_loss: 5.3495e-07\n",
      "Epoch 1425/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.0964e-06 - val_loss: 4.5636e-07\n",
      "Epoch 1426/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.3856e-06 - val_loss: 4.4103e-07\n",
      "Epoch 1427/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.2619e-06 - val_loss: 3.3259e-07\n",
      "Epoch 1428/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.1896e-06 - val_loss: 4.5744e-07\n",
      "Epoch 1429/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.9801e-06 - val_loss: 4.7430e-07\n",
      "Epoch 1430/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.3898e-06 - val_loss: 3.5697e-07\n",
      "Epoch 1431/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.9376e-06 - val_loss: 1.1673e-06\n",
      "Epoch 1432/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.6466e-06 - val_loss: 4.5364e-07\n",
      "Epoch 1433/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.7736e-06 - val_loss: 3.5798e-07\n",
      "Epoch 1434/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.2793e-06 - val_loss: 3.9172e-07\n",
      "Epoch 1435/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.8024e-06 - val_loss: 4.0747e-07\n",
      "Epoch 1436/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.5919e-06 - val_loss: 3.7373e-07\n",
      "Epoch 1437/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.9726e-06 - val_loss: 1.2500e-06\n",
      "Epoch 1438/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.3202e-06 - val_loss: 3.1207e-07\n",
      "Epoch 1439/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.7508e-06 - val_loss: 3.2629e-07\n",
      "Epoch 1440/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.8978e-06 - val_loss: 4.6884e-07\n",
      "Epoch 1441/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.5214e-06 - val_loss: 8.1188e-07\n",
      "Epoch 1442/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 2.1894e-06 - val_loss: 1.0049e-06\n",
      "Epoch 1443/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 2.8981e-06 - val_loss: 3.4311e-07\n",
      "Epoch 1444/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 5.2337e-06 - val_loss: 1.7009e-06\n",
      "Epoch 1445/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.7037e-06 - val_loss: 3.6206e-07\n",
      "Epoch 1446/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.1824e-06 - val_loss: 6.9109e-07\n",
      "Epoch 1447/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.6136e-06 - val_loss: 6.1223e-07\n",
      "Epoch 1448/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.6034e-06 - val_loss: 1.0884e-06\n",
      "Epoch 1449/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.5122e-06 - val_loss: 3.9561e-07\n",
      "Epoch 1450/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.6121e-06 - val_loss: 4.0844e-07\n",
      "Epoch 1451/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.2823e-06 - val_loss: 3.7470e-07\n",
      "Epoch 1452/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.3371e-06 - val_loss: 5.7444e-07\n",
      "Epoch 1453/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.8904e-06 - val_loss: 4.6044e-07\n",
      "Epoch 1454/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.2905e-06 - val_loss: 6.6675e-07\n",
      "Epoch 1455/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.9507e-06 - val_loss: 1.0067e-06\n",
      "Epoch 1456/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.1315e-06 - val_loss: 4.7889e-07\n",
      "Epoch 1457/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.9062e-06 - val_loss: 5.5378e-07\n",
      "Epoch 1458/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.4865e-06 - val_loss: 1.5941e-06\n",
      "Epoch 1459/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.2716e-06 - val_loss: 5.2129e-07\n",
      "Epoch 1460/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.4520e-06 - val_loss: 8.2980e-07\n",
      "Epoch 1461/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.3081e-06 - val_loss: 5.6377e-07\n",
      "Epoch 1462/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.1899e-06 - val_loss: 6.5976e-07\n",
      "Epoch 1463/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.1949e-06 - val_loss: 1.4595e-06\n",
      "Epoch 1464/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.9941e-06 - val_loss: 5.6288e-07\n",
      "Epoch 1465/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.0991e-06 - val_loss: 7.1629e-07\n",
      "Epoch 1466/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.2383e-06 - val_loss: 5.7364e-07\n",
      "Epoch 1467/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.8698e-06 - val_loss: 3.9608e-07\n",
      "Epoch 1468/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.0009e-06 - val_loss: 3.9166e-07\n",
      "Epoch 1469/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.8758e-06 - val_loss: 1.6728e-06\n",
      "Epoch 1470/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.5428e-06 - val_loss: 1.2256e-06\n",
      "Epoch 1471/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.0986e-06 - val_loss: 3.6858e-07\n",
      "Epoch 1472/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.7858e-06 - val_loss: 1.1023e-06\n",
      "Epoch 1473/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.9617e-06 - val_loss: 3.2841e-06\n",
      "Epoch 1474/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.2739e-06 - val_loss: 3.3634e-07\n",
      "Epoch 1475/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.2470e-06 - val_loss: 3.7399e-07\n",
      "Epoch 1476/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.8306e-06 - val_loss: 7.2001e-07\n",
      "Epoch 1477/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.4333e-06 - val_loss: 1.2941e-06\n",
      "Epoch 1478/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.8307e-06 - val_loss: 4.6386e-07\n",
      "Epoch 1479/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.2177e-06 - val_loss: 1.9047e-06\n",
      "Epoch 1480/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 1.7791e-06 - val_loss: 1.1940e-06\n",
      "Epoch 1481/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.3927e-06 - val_loss: 6.3658e-07\n",
      "Epoch 1482/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.4041e-06 - val_loss: 9.7098e-07\n",
      "Epoch 1483/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.6141e-06 - val_loss: 1.4189e-06\n",
      "Epoch 1484/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.7474e-06 - val_loss: 1.3453e-06\n",
      "Epoch 1485/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.3321e-06 - val_loss: 1.1589e-06\n",
      "Epoch 1486/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.6068e-06 - val_loss: 7.1646e-07\n",
      "Epoch 1487/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.3217e-06 - val_loss: 4.4868e-07\n",
      "Epoch 1488/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.3580e-06 - val_loss: 6.4291e-07\n",
      "Epoch 1489/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.6624e-06 - val_loss: 4.5797e-07\n",
      "Epoch 1490/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.6351e-06 - val_loss: 3.3870e-07\n",
      "Epoch 1491/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.4490e-06 - val_loss: 5.6980e-07\n",
      "Epoch 1492/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.0605e-06 - val_loss: 1.0235e-06\n",
      "Epoch 1493/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.3236e-06 - val_loss: 1.5795e-06\n",
      "Epoch 1494/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.9783e-06 - val_loss: 4.5080e-07\n",
      "Epoch 1495/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.0855e-06 - val_loss: 1.3938e-06\n",
      "Epoch 1496/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.7484e-06 - val_loss: 1.9209e-06\n",
      "Epoch 1497/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.6969e-06 - val_loss: 1.2363e-06\n",
      "Epoch 1498/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 5.1775e-06 - val_loss: 1.8306e-06\n",
      "Epoch 1499/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.0713e-06 - val_loss: 9.3548e-07\n",
      "Epoch 1500/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.4005e-06 - val_loss: 1.5841e-06\n",
      "Epoch 1501/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.4775e-06 - val_loss: 1.5318e-06\n",
      "Epoch 1502/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 6.1276e-06 - val_loss: 2.8673e-05\n",
      "Epoch 1503/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 6.0054e-06 - val_loss: 2.0206e-06\n",
      "Epoch 1504/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.4553e-06 - val_loss: 4.5314e-07\n",
      "Epoch 1505/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.8192e-06 - val_loss: 5.2629e-07\n",
      "Epoch 1506/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.6675e-06 - val_loss: 4.1030e-07\n",
      "Epoch 1507/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.0397e-06 - val_loss: 1.9990e-06\n",
      "Epoch 1508/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.3898e-06 - val_loss: 4.6549e-07\n",
      "Epoch 1509/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.6336e-06 - val_loss: 1.5445e-06\n",
      "Epoch 1510/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.6662e-06 - val_loss: 1.0237e-06\n",
      "Epoch 1511/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.3069e-06 - val_loss: 4.0167e-07\n",
      "Epoch 1512/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.3999e-06 - val_loss: 5.8532e-07\n",
      "Epoch 1513/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.6849e-06 - val_loss: 5.3038e-07\n",
      "Epoch 1514/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.9211e-06 - val_loss: 4.6221e-07\n",
      "Epoch 1515/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.3729e-06 - val_loss: 2.2231e-06\n",
      "Epoch 1516/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 4.1304e-06 - val_loss: 4.4606e-07\n",
      "Epoch 1517/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.5274e-06 - val_loss: 6.3310e-07\n",
      "Epoch 1518/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.1883e-06 - val_loss: 4.5736e-07\n",
      "Epoch 1519/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.6516e-06 - val_loss: 7.1391e-07\n",
      "Epoch 1520/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.0707e-06 - val_loss: 7.8507e-07\n",
      "Epoch 1521/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.0378e-06 - val_loss: 4.6312e-07\n",
      "Epoch 1522/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.0073e-06 - val_loss: 1.7977e-06\n",
      "Epoch 1523/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.2216e-06 - val_loss: 4.7833e-07\n",
      "Epoch 1524/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.3804e-06 - val_loss: 1.1661e-06\n",
      "Epoch 1525/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.4071e-06 - val_loss: 6.9021e-07\n",
      "Epoch 1526/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.4506e-06 - val_loss: 2.0602e-06\n",
      "Epoch 1527/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.9708e-06 - val_loss: 1.2656e-06\n",
      "Epoch 1528/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.9822e-06 - val_loss: 3.0909e-06\n",
      "Epoch 1529/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.3551e-06 - val_loss: 8.1882e-07\n",
      "Epoch 1530/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.5843e-06 - val_loss: 1.0709e-06\n",
      "Epoch 1531/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.1803e-06 - val_loss: 3.4154e-06\n",
      "Epoch 1532/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.2868e-06 - val_loss: 5.0322e-07\n",
      "Epoch 1533/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.6606e-06 - val_loss: 1.7480e-06\n",
      "Epoch 1534/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 5.6723e-06 - val_loss: 2.9141e-06\n",
      "Epoch 1535/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.3932e-06 - val_loss: 2.1296e-06\n",
      "Epoch 1536/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.7556e-06 - val_loss: 6.7960e-07\n",
      "Epoch 1537/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.5211e-06 - val_loss: 4.7134e-07\n",
      "Epoch 1538/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 6.6898e-06 - val_loss: 1.1831e-05\n",
      "Epoch 1539/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.4926e-06 - val_loss: 1.5299e-06\n",
      "Epoch 1540/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.4637e-06 - val_loss: 8.4366e-07\n",
      "Epoch 1541/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.2690e-06 - val_loss: 7.6363e-07\n",
      "Epoch 1542/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.5600e-06 - val_loss: 1.1044e-06\n",
      "Epoch 1543/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.5359e-06 - val_loss: 9.0027e-07\n",
      "Epoch 1544/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.9716e-06 - val_loss: 1.1258e-06\n",
      "Epoch 1545/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.8996e-06 - val_loss: 5.3841e-07\n",
      "Epoch 1546/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.6039e-06 - val_loss: 4.3322e-07\n",
      "Epoch 1547/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.6218e-06 - val_loss: 8.5239e-07\n",
      "Epoch 1548/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.4024e-06 - val_loss: 7.1450e-07\n",
      "Epoch 1549/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.6887e-05 - val_loss: 1.1583e-05\n",
      "Epoch 1550/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.4081e-05 - val_loss: 9.1796e-06\n",
      "Epoch 1551/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 5.6474e-06 - val_loss: 1.2799e-06\n",
      "Epoch 1552/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 2.3079e-06 - val_loss: 6.4504e-07\n",
      "Epoch 1553/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 3.6357e-06 - val_loss: 2.0153e-06\n",
      "Epoch 1554/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.2361e-06 - val_loss: 5.3689e-07\n",
      "Epoch 1555/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.0490e-06 - val_loss: 5.9628e-07\n",
      "Epoch 1556/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.8063e-06 - val_loss: 3.8117e-07\n",
      "Epoch 1557/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.7630e-06 - val_loss: 3.5454e-07\n",
      "Epoch 1558/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.6376e-06 - val_loss: 4.0012e-07\n",
      "Epoch 1559/2000\n",
      "21471/21471 [==============================] - ETA: 0s - loss: 1.4969e-0 - 0s 20us/step - loss: 1.6090e-06 - val_loss: 3.6728e-07\n",
      "Epoch 1560/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.6260e-06 - val_loss: 3.6000e-07\n",
      "Epoch 1561/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.3157e-06 - val_loss: 7.0914e-07\n",
      "Epoch 1562/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.3929e-06 - val_loss: 5.1718e-07\n",
      "Epoch 1563/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.3470e-06 - val_loss: 4.9931e-07\n",
      "Epoch 1564/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.0110e-06 - val_loss: 6.8155e-07\n",
      "Epoch 1565/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.7253e-06 - val_loss: 4.8484e-07\n",
      "Epoch 1566/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.0987e-06 - val_loss: 4.7960e-07\n",
      "Epoch 1567/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.5144e-06 - val_loss: 6.1088e-07\n",
      "Epoch 1568/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.9396e-06 - val_loss: 1.2306e-06\n",
      "Epoch 1569/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.1341e-06 - val_loss: 4.9399e-07\n",
      "Epoch 1570/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.1085e-06 - val_loss: 1.0239e-06\n",
      "Epoch 1571/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.1020e-06 - val_loss: 3.9094e-07\n",
      "Epoch 1572/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.8023e-06 - val_loss: 1.0091e-06\n",
      "Epoch 1573/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.1994e-06 - val_loss: 5.6683e-07\n",
      "Epoch 1574/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.4628e-06 - val_loss: 6.9866e-07\n",
      "Epoch 1575/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.0784e-06 - val_loss: 1.2815e-06\n",
      "Epoch 1576/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.7305e-06 - val_loss: 9.8784e-07\n",
      "Epoch 1577/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.4992e-06 - val_loss: 9.3956e-07\n",
      "Epoch 1578/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.3635e-06 - val_loss: 6.0790e-07\n",
      "Epoch 1579/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.4945e-06 - val_loss: 1.8027e-06\n",
      "Epoch 1580/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.6320e-06 - val_loss: 6.6041e-07\n",
      "Epoch 1581/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.7803e-06 - val_loss: 5.9965e-07\n",
      "Epoch 1582/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.6130e-06 - val_loss: 8.3013e-07\n",
      "Epoch 1583/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.0701e-06 - val_loss: 5.3693e-07\n",
      "Epoch 1584/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.4392e-06 - val_loss: 6.2912e-07\n",
      "Epoch 1585/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.9136e-06 - val_loss: 7.7886e-07\n",
      "Epoch 1586/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.1810e-06 - val_loss: 5.0234e-07\n",
      "Epoch 1587/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.5416e-06 - val_loss: 5.7835e-06\n",
      "Epoch 1588/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.0438e-06 - val_loss: 7.9350e-07\n",
      "Epoch 1589/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 2.2571e-06 - val_loss: 6.9124e-07\n",
      "Epoch 1590/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.3521e-06 - val_loss: 4.8536e-07\n",
      "Epoch 1591/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 6.6727e-06 - val_loss: 4.8368e-06\n",
      "Epoch 1592/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 5.0087e-06 - val_loss: 1.1640e-06\n",
      "Epoch 1593/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.2875e-06 - val_loss: 6.9860e-07\n",
      "Epoch 1594/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.1071e-06 - val_loss: 9.7464e-07\n",
      "Epoch 1595/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.6060e-06 - val_loss: 1.4059e-06\n",
      "Epoch 1596/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.4185e-06 - val_loss: 2.7201e-06\n",
      "Epoch 1597/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.3136e-06 - val_loss: 1.1761e-06\n",
      "Epoch 1598/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.8501e-06 - val_loss: 4.1313e-07\n",
      "Epoch 1599/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.0290e-06 - val_loss: 4.5696e-07\n",
      "Epoch 1600/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.5821e-06 - val_loss: 2.0121e-06\n",
      "Epoch 1601/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.4753e-06 - val_loss: 2.5211e-06\n",
      "Epoch 1602/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.1127e-06 - val_loss: 4.4893e-06\n",
      "Epoch 1603/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.2986e-06 - val_loss: 4.9832e-07\n",
      "Epoch 1604/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.9597e-06 - val_loss: 4.7740e-07\n",
      "Epoch 1605/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.8800e-06 - val_loss: 6.4412e-07\n",
      "Epoch 1606/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.7295e-06 - val_loss: 1.4773e-06\n",
      "Epoch 1607/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.5264e-06 - val_loss: 9.2621e-07\n",
      "Epoch 1608/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.3735e-06 - val_loss: 6.2075e-07\n",
      "Epoch 1609/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.7158e-06 - val_loss: 4.8090e-07\n",
      "Epoch 1610/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.7808e-06 - val_loss: 4.9975e-07\n",
      "Epoch 1611/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.0430e-06 - val_loss: 5.6435e-07\n",
      "Epoch 1612/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.9510e-06 - val_loss: 2.4984e-06\n",
      "Epoch 1613/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.3062e-06 - val_loss: 1.0957e-06\n",
      "Epoch 1614/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.7070e-06 - val_loss: 6.9953e-07\n",
      "Epoch 1615/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.0089e-06 - val_loss: 7.2675e-07\n",
      "Epoch 1616/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.8362e-06 - val_loss: 8.5995e-07\n",
      "Epoch 1617/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.6671e-06 - val_loss: 2.9909e-06\n",
      "Epoch 1618/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.7386e-06 - val_loss: 4.9156e-07\n",
      "Epoch 1619/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.8318e-06 - val_loss: 5.2640e-07\n",
      "Epoch 1620/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 5.1080e-06 - val_loss: 2.9192e-06\n",
      "Epoch 1621/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.1600e-06 - val_loss: 6.3504e-07\n",
      "Epoch 1622/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.4726e-06 - val_loss: 8.0624e-07\n",
      "Epoch 1623/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.0129e-06 - val_loss: 4.1846e-07\n",
      "Epoch 1624/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.1871e-06 - val_loss: 4.4343e-07\n",
      "Epoch 1625/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 2.4824e-06 - val_loss: 7.4123e-07\n",
      "Epoch 1626/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.0868e-06 - val_loss: 4.6107e-07\n",
      "Epoch 1627/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.8905e-06 - val_loss: 4.7834e-07\n",
      "Epoch 1628/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.2661e-06 - val_loss: 3.9140e-06\n",
      "Epoch 1629/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.5572e-06 - val_loss: 8.9611e-07\n",
      "Epoch 1630/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.6843e-06 - val_loss: 6.8049e-07\n",
      "Epoch 1631/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.2535e-06 - val_loss: 9.7747e-07\n",
      "Epoch 1632/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.9912e-06 - val_loss: 3.1022e-06\n",
      "Epoch 1633/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.1537e-06 - val_loss: 5.0456e-07\n",
      "Epoch 1634/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.9970e-06 - val_loss: 8.2566e-07\n",
      "Epoch 1635/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.9564e-06 - val_loss: 6.2734e-07\n",
      "Epoch 1636/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.5778e-06 - val_loss: 4.8686e-07\n",
      "Epoch 1637/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.2698e-06 - val_loss: 1.3658e-06\n",
      "Epoch 1638/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.8912e-06 - val_loss: 8.9475e-07\n",
      "Epoch 1639/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.1801e-06 - val_loss: 1.3522e-06\n",
      "Epoch 1640/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.9247e-06 - val_loss: 4.0675e-06\n",
      "Epoch 1641/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.7789e-06 - val_loss: 8.7786e-07\n",
      "Epoch 1642/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.6240e-06 - val_loss: 8.2006e-07\n",
      "Epoch 1643/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.8974e-06 - val_loss: 1.5957e-06\n",
      "Epoch 1644/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.1050e-06 - val_loss: 1.6905e-06\n",
      "Epoch 1645/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.7748e-06 - val_loss: 1.4522e-06\n",
      "Epoch 1646/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.9647e-06 - val_loss: 2.1088e-06\n",
      "Epoch 1647/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.7609e-06 - val_loss: 5.3947e-07\n",
      "Epoch 1648/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.0367e-04 - val_loss: 9.1330e-05\n",
      "Epoch 1649/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.9269e-05 - val_loss: 1.2088e-05\n",
      "Epoch 1650/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 7.8137e-06 - val_loss: 2.5528e-06\n",
      "Epoch 1651/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 5.5552e-06 - val_loss: 1.9509e-06\n",
      "Epoch 1652/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.6093e-06 - val_loss: 2.1027e-06\n",
      "Epoch 1653/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.4318e-06 - val_loss: 1.4701e-06\n",
      "Epoch 1654/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.0800e-06 - val_loss: 1.0681e-06\n",
      "Epoch 1655/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.9366e-06 - val_loss: 8.0886e-07\n",
      "Epoch 1656/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.7753e-06 - val_loss: 8.1291e-07\n",
      "Epoch 1657/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.8456e-06 - val_loss: 8.2612e-07\n",
      "Epoch 1658/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.3288e-06 - val_loss: 5.6793e-07\n",
      "Epoch 1659/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.7265e-06 - val_loss: 6.2004e-07\n",
      "Epoch 1660/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.8972e-06 - val_loss: 5.3333e-07\n",
      "Epoch 1661/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 5.8497e-06 - val_loss: 2.7971e-07\n",
      "Epoch 1662/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 2.2006e-06 - val_loss: 3.0713e-07\n",
      "Epoch 1663/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.3815e-06 - val_loss: 3.5174e-07\n",
      "Epoch 1664/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.1540e-06 - val_loss: 7.9831e-07\n",
      "Epoch 1665/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.8393e-06 - val_loss: 3.4191e-07\n",
      "Epoch 1666/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.2376e-06 - val_loss: 3.6835e-07\n",
      "Epoch 1667/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.5362e-06 - val_loss: 6.7022e-07\n",
      "Epoch 1668/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.2936e-06 - val_loss: 5.9874e-07\n",
      "Epoch 1669/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.3830e-06 - val_loss: 3.6824e-07\n",
      "Epoch 1670/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.2204e-06 - val_loss: 3.4905e-07\n",
      "Epoch 1671/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.5029e-06 - val_loss: 3.7590e-07\n",
      "Epoch 1672/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.4020e-06 - val_loss: 5.2177e-07\n",
      "Epoch 1673/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.9412e-06 - val_loss: 5.0313e-07\n",
      "Epoch 1674/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.1439e-06 - val_loss: 4.3068e-07\n",
      "Epoch 1675/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.4198e-06 - val_loss: 6.2511e-07\n",
      "Epoch 1676/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.4974e-06 - val_loss: 3.6616e-07\n",
      "Epoch 1677/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.9631e-06 - val_loss: 2.9404e-07\n",
      "Epoch 1678/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.2703e-06 - val_loss: 3.1418e-07\n",
      "Epoch 1679/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.8149e-06 - val_loss: 3.8576e-07\n",
      "Epoch 1680/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.5527e-06 - val_loss: 4.0795e-07\n",
      "Epoch 1681/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.7466e-06 - val_loss: 5.0716e-07\n",
      "Epoch 1682/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.7629e-06 - val_loss: 3.0865e-07\n",
      "Epoch 1683/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.8308e-06 - val_loss: 2.7280e-07\n",
      "Epoch 1684/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.9089e-06 - val_loss: 4.3451e-07\n",
      "Epoch 1685/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.4472e-06 - val_loss: 5.1490e-07\n",
      "Epoch 1686/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.1734e-06 - val_loss: 7.6903e-07\n",
      "Epoch 1687/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.9571e-06 - val_loss: 5.1030e-07\n",
      "Epoch 1688/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.7428e-06 - val_loss: 3.6445e-07\n",
      "Epoch 1689/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.6333e-06 - val_loss: 3.6038e-07\n",
      "Epoch 1690/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.0860e-06 - val_loss: 7.7561e-07\n",
      "Epoch 1691/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.8724e-06 - val_loss: 6.9675e-07\n",
      "Epoch 1692/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.7374e-06 - val_loss: 4.2901e-07\n",
      "Epoch 1693/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.1936e-06 - val_loss: 1.2759e-06\n",
      "Epoch 1694/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.4121e-06 - val_loss: 4.3461e-07\n",
      "Epoch 1695/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.7029e-06 - val_loss: 7.3067e-07\n",
      "Epoch 1696/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.8162e-06 - val_loss: 3.9635e-07\n",
      "Epoch 1697/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.7556e-06 - val_loss: 1.5210e-06\n",
      "Epoch 1698/2000\n",
      "21471/21471 [==============================] - 0s 23us/step - loss: 2.9871e-06 - val_loss: 3.0104e-07\n",
      "Epoch 1699/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.4921e-06 - val_loss: 1.0236e-06\n",
      "Epoch 1700/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.3582e-06 - val_loss: 9.4626e-07\n",
      "Epoch 1701/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.8664e-06 - val_loss: 4.0822e-07\n",
      "Epoch 1702/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.2719e-06 - val_loss: 2.8981e-07\n",
      "Epoch 1703/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.4560e-06 - val_loss: 3.6501e-07\n",
      "Epoch 1704/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.6761e-06 - val_loss: 4.2465e-07\n",
      "Epoch 1705/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.2148e-06 - val_loss: 7.0597e-07\n",
      "Epoch 1706/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.2780e-06 - val_loss: 1.0147e-06\n",
      "Epoch 1707/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 5.0701e-06 - val_loss: 2.1245e-06\n",
      "Epoch 1708/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 6.7906e-06 - val_loss: 6.7507e-07\n",
      "Epoch 1709/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.2358e-06 - val_loss: 4.5418e-07\n",
      "Epoch 1710/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.1407e-06 - val_loss: 4.1714e-07\n",
      "Epoch 1711/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.5536e-06 - val_loss: 5.2640e-07\n",
      "Epoch 1712/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.2255e-06 - val_loss: 5.2292e-07\n",
      "Epoch 1713/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.6069e-06 - val_loss: 8.5526e-07\n",
      "Epoch 1714/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.2440e-06 - val_loss: 1.0037e-06\n",
      "Epoch 1715/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.6649e-06 - val_loss: 1.3317e-06\n",
      "Epoch 1716/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.4267e-06 - val_loss: 4.3513e-07\n",
      "Epoch 1717/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.6776e-06 - val_loss: 7.9727e-07\n",
      "Epoch 1718/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.9714e-06 - val_loss: 5.7397e-07\n",
      "Epoch 1719/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.3919e-06 - val_loss: 3.8189e-07\n",
      "Epoch 1720/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.3372e-06 - val_loss: 3.4206e-07\n",
      "Epoch 1721/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.7855e-06 - val_loss: 5.7544e-07\n",
      "Epoch 1722/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.1940e-06 - val_loss: 1.9846e-06\n",
      "Epoch 1723/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.0965e-06 - val_loss: 6.6735e-07\n",
      "Epoch 1724/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.8816e-06 - val_loss: 1.2188e-06\n",
      "Epoch 1725/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.3780e-06 - val_loss: 4.0516e-07\n",
      "Epoch 1726/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.2808e-06 - val_loss: 3.6669e-06\n",
      "Epoch 1727/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.5115e-06 - val_loss: 1.2947e-06\n",
      "Epoch 1728/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.4927e-06 - val_loss: 1.4745e-06\n",
      "Epoch 1729/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.3401e-06 - val_loss: 4.7405e-07\n",
      "Epoch 1730/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.4647e-06 - val_loss: 3.4000e-06\n",
      "Epoch 1731/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.8600e-06 - val_loss: 2.9680e-06\n",
      "Epoch 1732/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 5.0638e-06 - val_loss: 4.5899e-07\n",
      "Epoch 1733/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.0293e-06 - val_loss: 9.9690e-07\n",
      "Epoch 1734/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 1.7365e-06 - val_loss: 5.3394e-07\n",
      "Epoch 1735/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 2.0352e-06 - val_loss: 1.3095e-06\n",
      "Epoch 1736/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 6.9867e-06 - val_loss: 1.7603e-06\n",
      "Epoch 1737/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.5305e-06 - val_loss: 1.1894e-06\n",
      "Epoch 1738/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.3926e-06 - val_loss: 6.7738e-07\n",
      "Epoch 1739/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.2720e-06 - val_loss: 6.2977e-07\n",
      "Epoch 1740/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.6286e-06 - val_loss: 3.7041e-07\n",
      "Epoch 1741/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.3131e-06 - val_loss: 1.1522e-06\n",
      "Epoch 1742/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.2589e-06 - val_loss: 8.2258e-07\n",
      "Epoch 1743/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.7513e-06 - val_loss: 1.0745e-06\n",
      "Epoch 1744/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.0904e-06 - val_loss: 6.9891e-07\n",
      "Epoch 1745/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.3209e-06 - val_loss: 6.7272e-07\n",
      "Epoch 1746/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.6512e-06 - val_loss: 9.5363e-07\n",
      "Epoch 1747/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.5103e-06 - val_loss: 8.7718e-07\n",
      "Epoch 1748/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.3668e-06 - val_loss: 1.2124e-06\n",
      "Epoch 1749/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.2085e-06 - val_loss: 4.4756e-07\n",
      "Epoch 1750/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.6068e-06 - val_loss: 5.6788e-07\n",
      "Epoch 1751/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.6100e-06 - val_loss: 6.1312e-06\n",
      "Epoch 1752/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.5010e-06 - val_loss: 7.3406e-07\n",
      "Epoch 1753/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.9883e-06 - val_loss: 4.9203e-07\n",
      "Epoch 1754/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.3665e-06 - val_loss: 5.1387e-07\n",
      "Epoch 1755/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.4836e-05 - val_loss: 3.4088e-06\n",
      "Epoch 1756/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 5.1598e-06 - val_loss: 3.9825e-06\n",
      "Epoch 1757/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.2469e-06 - val_loss: 8.0796e-07\n",
      "Epoch 1758/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.6004e-06 - val_loss: 1.0549e-06\n",
      "Epoch 1759/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.6850e-06 - val_loss: 9.7290e-07\n",
      "Epoch 1760/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.1720e-06 - val_loss: 6.5151e-07\n",
      "Epoch 1761/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.1032e-06 - val_loss: 5.5187e-07\n",
      "Epoch 1762/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.9308e-06 - val_loss: 2.8090e-06\n",
      "Epoch 1763/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.4960e-06 - val_loss: 6.2063e-07\n",
      "Epoch 1764/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.7467e-06 - val_loss: 4.3126e-07\n",
      "Epoch 1765/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.6715e-06 - val_loss: 6.1739e-07\n",
      "Epoch 1766/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.6439e-06 - val_loss: 1.0651e-06\n",
      "Epoch 1767/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.2097e-06 - val_loss: 7.6934e-07\n",
      "Epoch 1768/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.9293e-06 - val_loss: 4.8877e-07\n",
      "Epoch 1769/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.6409e-06 - val_loss: 9.1911e-07\n",
      "Epoch 1770/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 2.2168e-06 - val_loss: 8.7129e-07\n",
      "Epoch 1771/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.1260e-06 - val_loss: 2.5517e-06\n",
      "Epoch 1772/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.3784e-06 - val_loss: 2.4113e-06\n",
      "Epoch 1773/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.4735e-06 - val_loss: 1.0192e-06\n",
      "Epoch 1774/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.5473e-06 - val_loss: 1.0271e-06\n",
      "Epoch 1775/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.6315e-06 - val_loss: 1.5143e-06\n",
      "Epoch 1776/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.0540e-06 - val_loss: 1.2891e-06\n",
      "Epoch 1777/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.2767e-06 - val_loss: 8.5459e-07\n",
      "Epoch 1778/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.2576e-06 - val_loss: 1.5234e-06\n",
      "Epoch 1779/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.0870e-06 - val_loss: 1.8915e-06\n",
      "Epoch 1780/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.2289e-06 - val_loss: 2.0534e-06\n",
      "Epoch 1781/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.7359e-06 - val_loss: 9.8847e-07\n",
      "Epoch 1782/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.0777e-06 - val_loss: 7.4868e-07\n",
      "Epoch 1783/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.3650e-06 - val_loss: 6.2498e-07\n",
      "Epoch 1784/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.7860e-06 - val_loss: 7.7756e-07\n",
      "Epoch 1785/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 5.7263e-06 - val_loss: 3.6874e-06\n",
      "Epoch 1786/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 5.4591e-06 - val_loss: 1.2289e-06\n",
      "Epoch 1787/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.1543e-06 - val_loss: 2.3198e-06\n",
      "Epoch 1788/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.0021e-06 - val_loss: 1.6275e-06\n",
      "Epoch 1789/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.2650e-06 - val_loss: 1.8165e-06\n",
      "Epoch 1790/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.8997e-06 - val_loss: 1.1066e-06\n",
      "Epoch 1791/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.9302e-06 - val_loss: 6.6228e-07\n",
      "Epoch 1792/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.3638e-06 - val_loss: 7.9677e-07\n",
      "Epoch 1793/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 7.6264e-06 - val_loss: 3.9369e-06\n",
      "Epoch 1794/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.3828e-06 - val_loss: 5.1615e-07\n",
      "Epoch 1795/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.4021e-06 - val_loss: 5.8827e-07\n",
      "Epoch 1796/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.1057e-06 - val_loss: 1.4956e-06\n",
      "Epoch 1797/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.8026e-06 - val_loss: 4.7169e-07\n",
      "Epoch 1798/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.1633e-06 - val_loss: 1.1811e-06\n",
      "Epoch 1799/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.6912e-06 - val_loss: 1.3998e-06\n",
      "Epoch 1800/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.2349e-06 - val_loss: 1.0071e-06\n",
      "Epoch 1801/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.3974e-06 - val_loss: 5.9006e-07\n",
      "Epoch 1802/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.7711e-06 - val_loss: 1.3693e-06\n",
      "Epoch 1803/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.0402e-06 - val_loss: 8.4989e-07\n",
      "Epoch 1804/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.7244e-06 - val_loss: 1.0107e-06\n",
      "Epoch 1805/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.7270e-06 - val_loss: 4.2881e-07\n",
      "Epoch 1806/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 1.9458e-06 - val_loss: 4.9781e-07\n",
      "Epoch 1807/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 2.2199e-06 - val_loss: 4.7987e-07\n",
      "Epoch 1808/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.0243e-06 - val_loss: 1.3803e-06\n",
      "Epoch 1809/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.7866e-06 - val_loss: 1.5410e-06\n",
      "Epoch 1810/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.9066e-06 - val_loss: 1.9070e-06\n",
      "Epoch 1811/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.5838e-06 - val_loss: 1.2821e-06\n",
      "Epoch 1812/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.8799e-06 - val_loss: 1.0614e-06\n",
      "Epoch 1813/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.2606e-06 - val_loss: 7.6761e-07\n",
      "Epoch 1814/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.3414e-06 - val_loss: 7.4908e-07\n",
      "Epoch 1815/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.5938e-06 - val_loss: 8.3949e-07\n",
      "Epoch 1816/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 5.9122e-06 - val_loss: 1.0705e-06\n",
      "Epoch 1817/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.7580e-06 - val_loss: 1.2349e-06\n",
      "Epoch 1818/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.2717e-06 - val_loss: 5.9242e-07\n",
      "Epoch 1819/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 6.9109e-06 - val_loss: 8.9857e-07\n",
      "Epoch 1820/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.1018e-06 - val_loss: 7.6917e-07\n",
      "Epoch 1821/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.1376e-06 - val_loss: 8.8819e-07\n",
      "Epoch 1822/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.2939e-06 - val_loss: 2.2470e-06\n",
      "Epoch 1823/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.8683e-06 - val_loss: 2.4667e-06\n",
      "Epoch 1824/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.6153e-06 - val_loss: 2.5858e-06\n",
      "Epoch 1825/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 5.7401e-06 - val_loss: 8.4995e-07\n",
      "Epoch 1826/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.5432e-06 - val_loss: 2.7312e-06\n",
      "Epoch 1827/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.6110e-06 - val_loss: 5.5279e-07\n",
      "Epoch 1828/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.9543e-06 - val_loss: 5.7061e-07\n",
      "Epoch 1829/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.3391e-06 - val_loss: 8.0627e-07\n",
      "Epoch 1830/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.9188e-06 - val_loss: 4.6137e-07\n",
      "Epoch 1831/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.8774e-06 - val_loss: 7.1501e-07\n",
      "Epoch 1832/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.3090e-06 - val_loss: 8.9064e-07\n",
      "Epoch 1833/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.7561e-06 - val_loss: 4.4132e-06\n",
      "Epoch 1834/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.0057e-06 - val_loss: 1.2186e-06\n",
      "Epoch 1835/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.3023e-06 - val_loss: 7.1503e-07\n",
      "Epoch 1836/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.8508e-06 - val_loss: 8.5996e-07\n",
      "Epoch 1837/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.5669e-06 - val_loss: 1.3156e-06\n",
      "Epoch 1838/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.7676e-06 - val_loss: 4.2978e-06\n",
      "Epoch 1839/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.5356e-06 - val_loss: 1.1048e-06\n",
      "Epoch 1840/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.0275e-06 - val_loss: 7.5189e-07\n",
      "Epoch 1841/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.1286e-06 - val_loss: 2.0120e-06\n",
      "Epoch 1842/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.1698e-06 - val_loss: 2.1157e-06\n",
      "Epoch 1843/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 1.4914e-06 - val_loss: 6.4335e-07\n",
      "Epoch 1844/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.9324e-06 - val_loss: 1.6150e-06\n",
      "Epoch 1845/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.8617e-05 - val_loss: 1.2011e-06\n",
      "Epoch 1846/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.2377e-06 - val_loss: 8.7655e-07\n",
      "Epoch 1847/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.6330e-06 - val_loss: 1.1511e-06\n",
      "Epoch 1848/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.6143e-06 - val_loss: 1.1132e-06\n",
      "Epoch 1849/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.7396e-06 - val_loss: 1.9679e-06\n",
      "Epoch 1850/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.8048e-06 - val_loss: 5.5755e-07\n",
      "Epoch 1851/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.0427e-06 - val_loss: 5.1653e-07\n",
      "Epoch 1852/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.8067e-06 - val_loss: 1.0884e-06\n",
      "Epoch 1853/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.7548e-06 - val_loss: 2.8590e-06\n",
      "Epoch 1854/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.4838e-06 - val_loss: 9.7933e-07\n",
      "Epoch 1855/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.9546e-06 - val_loss: 9.1129e-07\n",
      "Epoch 1856/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.4678e-06 - val_loss: 5.7489e-07\n",
      "Epoch 1857/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.7682e-06 - val_loss: 1.3819e-06\n",
      "Epoch 1858/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.1586e-06 - val_loss: 1.8023e-06\n",
      "Epoch 1859/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.2591e-06 - val_loss: 1.7917e-06\n",
      "Epoch 1860/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.3485e-06 - val_loss: 9.8805e-07\n",
      "Epoch 1861/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.9887e-06 - val_loss: 2.0619e-06\n",
      "Epoch 1862/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 1.7683e-06 - val_loss: 1.1877e-06\n",
      "Epoch 1863/2000\n",
      "21471/21471 [==============================] - 0s 23us/step - loss: 3.2996e-06 - val_loss: 1.6948e-06\n",
      "Epoch 1864/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.5408e-06 - val_loss: 8.5510e-07\n",
      "Epoch 1865/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.5862e-06 - val_loss: 1.3409e-06\n",
      "Epoch 1866/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.0148e-06 - val_loss: 2.0775e-06\n",
      "Epoch 1867/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.2733e-06 - val_loss: 7.6497e-07\n",
      "Epoch 1868/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.8761e-06 - val_loss: 1.0242e-06\n",
      "Epoch 1869/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.7386e-06 - val_loss: 6.1565e-07\n",
      "Epoch 1870/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.5750e-06 - val_loss: 6.7813e-07\n",
      "Epoch 1871/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.7573e-06 - val_loss: 1.2602e-06\n",
      "Epoch 1872/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.4112e-06 - val_loss: 8.5534e-07\n",
      "Epoch 1873/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.9185e-06 - val_loss: 1.5866e-06\n",
      "Epoch 1874/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.6176e-06 - val_loss: 1.1242e-06\n",
      "Epoch 1875/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.0356e-06 - val_loss: 1.1313e-06\n",
      "Epoch 1876/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.8060e-06 - val_loss: 1.7546e-06\n",
      "Epoch 1877/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.6714e-06 - val_loss: 6.7281e-07\n",
      "Epoch 1878/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.5779e-06 - val_loss: 2.9626e-06\n",
      "Epoch 1879/2000\n",
      "21471/21471 [==============================] - 0s 23us/step - loss: 2.1060e-06 - val_loss: 1.0126e-06\n",
      "Epoch 1880/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.7709e-06 - val_loss: 7.2380e-06\n",
      "Epoch 1881/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.0493e-06 - val_loss: 6.7272e-07\n",
      "Epoch 1882/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.6775e-06 - val_loss: 7.6476e-07\n",
      "Epoch 1883/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.7002e-06 - val_loss: 1.2766e-06\n",
      "Epoch 1884/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.6973e-06 - val_loss: 8.2619e-07\n",
      "Epoch 1885/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.3133e-06 - val_loss: 5.2129e-07\n",
      "Epoch 1886/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.5454e-06 - val_loss: 6.4434e-07\n",
      "Epoch 1887/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.5600e-06 - val_loss: 1.5192e-06\n",
      "Epoch 1888/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.0065e-06 - val_loss: 1.6243e-06\n",
      "Epoch 1889/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.8062e-06 - val_loss: 5.5530e-07\n",
      "Epoch 1890/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.4221e-06 - val_loss: 8.3104e-07\n",
      "Epoch 1891/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.2662e-06 - val_loss: 9.9765e-07\n",
      "Epoch 1892/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.8198e-06 - val_loss: 7.8658e-07\n",
      "Epoch 1893/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.1785e-06 - val_loss: 5.1601e-06\n",
      "Epoch 1894/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.7080e-06 - val_loss: 9.5576e-07\n",
      "Epoch 1895/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.7643e-06 - val_loss: 7.3974e-07\n",
      "Epoch 1896/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.6139e-06 - val_loss: 1.4552e-06\n",
      "Epoch 1897/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.5292e-06 - val_loss: 6.8492e-07\n",
      "Epoch 1898/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.3142e-06 - val_loss: 1.0970e-06\n",
      "Epoch 1899/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.7957e-06 - val_loss: 1.4615e-06\n",
      "Epoch 1900/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.3817e-06 - val_loss: 7.5216e-07\n",
      "Epoch 1901/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.1015e-06 - val_loss: 5.7223e-07\n",
      "Epoch 1902/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.5146e-06 - val_loss: 1.9352e-06\n",
      "Epoch 1903/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.5422e-06 - val_loss: 7.5901e-07\n",
      "Epoch 1904/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.7751e-06 - val_loss: 1.2970e-06\n",
      "Epoch 1905/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.0227e-06 - val_loss: 6.7605e-07\n",
      "Epoch 1906/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.6312e-06 - val_loss: 6.3442e-07\n",
      "Epoch 1907/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.0888e-06 - val_loss: 1.2235e-06\n",
      "Epoch 1908/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.2687e-06 - val_loss: 9.2593e-07\n",
      "Epoch 1909/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.7634e-06 - val_loss: 7.3831e-07\n",
      "Epoch 1910/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.5904e-06 - val_loss: 9.7849e-07\n",
      "Epoch 1911/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.0066e-06 - val_loss: 1.2958e-06\n",
      "Epoch 1912/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.6880e-06 - val_loss: 5.0358e-07\n",
      "Epoch 1913/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.3191e-06 - val_loss: 8.3860e-07\n",
      "Epoch 1914/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.4517e-06 - val_loss: 2.8363e-06\n",
      "Epoch 1915/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 2.8846e-06 - val_loss: 1.6203e-06\n",
      "Epoch 1916/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 1.5532e-06 - val_loss: 7.6232e-07\n",
      "Epoch 1917/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.3252e-06 - val_loss: 5.0911e-07\n",
      "Epoch 1918/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.4458e-06 - val_loss: 1.6440e-06\n",
      "Epoch 1919/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.0861e-06 - val_loss: 1.0677e-06\n",
      "Epoch 1920/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.3464e-06 - val_loss: 9.3941e-07\n",
      "Epoch 1921/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.6006e-06 - val_loss: 1.1173e-06\n",
      "Epoch 1922/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.5042e-06 - val_loss: 1.4063e-06\n",
      "Epoch 1923/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.0817e-06 - val_loss: 2.8031e-06\n",
      "Epoch 1924/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.3072e-06 - val_loss: 7.1857e-07\n",
      "Epoch 1925/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.8534e-06 - val_loss: 4.5156e-07\n",
      "Epoch 1926/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.4829e-06 - val_loss: 5.2342e-07\n",
      "Epoch 1927/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 7.3585e-06 - val_loss: 5.5601e-06\n",
      "Epoch 1928/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.6620e-05 - val_loss: 1.0596e-05\n",
      "Epoch 1929/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 7.0548e-06 - val_loss: 1.7182e-06\n",
      "Epoch 1930/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.1869e-06 - val_loss: 1.0969e-06\n",
      "Epoch 1931/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.2274e-06 - val_loss: 8.0873e-07\n",
      "Epoch 1932/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.6888e-06 - val_loss: 1.2107e-06\n",
      "Epoch 1933/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.3290e-06 - val_loss: 9.8187e-07\n",
      "Epoch 1934/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.7880e-06 - val_loss: 6.3677e-07\n",
      "Epoch 1935/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.6770e-06 - val_loss: 5.4003e-07\n",
      "Epoch 1936/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.0120e-06 - val_loss: 4.1261e-07\n",
      "Epoch 1937/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.5523e-06 - val_loss: 4.0159e-07\n",
      "Epoch 1938/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.0801e-06 - val_loss: 7.9087e-07\n",
      "Epoch 1939/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.5318e-06 - val_loss: 4.3040e-07\n",
      "Epoch 1940/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.0698e-06 - val_loss: 6.7563e-07\n",
      "Epoch 1941/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.0229e-06 - val_loss: 1.2240e-06\n",
      "Epoch 1942/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.4697e-06 - val_loss: 4.8664e-07\n",
      "Epoch 1943/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.4819e-06 - val_loss: 3.4730e-07\n",
      "Epoch 1944/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.6960e-06 - val_loss: 8.7118e-07\n",
      "Epoch 1945/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.0357e-06 - val_loss: 1.1835e-06\n",
      "Epoch 1946/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.0000e-06 - val_loss: 6.1102e-07\n",
      "Epoch 1947/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.7760e-06 - val_loss: 7.2600e-07\n",
      "Epoch 1948/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.7407e-06 - val_loss: 5.6233e-07\n",
      "Epoch 1949/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.7802e-06 - val_loss: 4.8895e-07\n",
      "Epoch 1950/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.3003e-06 - val_loss: 4.6170e-07\n",
      "Epoch 1951/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 2.3881e-06 - val_loss: 5.7069e-07\n",
      "Epoch 1952/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 1.8703e-06 - val_loss: 5.4494e-07\n",
      "Epoch 1953/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.6732e-06 - val_loss: 4.0385e-06\n",
      "Epoch 1954/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.9235e-06 - val_loss: 1.0585e-06\n",
      "Epoch 1955/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.8019e-06 - val_loss: 4.9346e-07\n",
      "Epoch 1956/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.6834e-06 - val_loss: 5.7288e-07\n",
      "Epoch 1957/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.5170e-06 - val_loss: 9.7775e-07\n",
      "Epoch 1958/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.5499e-06 - val_loss: 8.9393e-07\n",
      "Epoch 1959/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.3127e-06 - val_loss: 6.7549e-07\n",
      "Epoch 1960/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.6067e-06 - val_loss: 5.2615e-07\n",
      "Epoch 1961/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.2474e-06 - val_loss: 9.6814e-07\n",
      "Epoch 1962/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.5595e-06 - val_loss: 2.8157e-06\n",
      "Epoch 1963/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.7467e-06 - val_loss: 1.1257e-06\n",
      "Epoch 1964/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.1491e-05 - val_loss: 4.3335e-06\n",
      "Epoch 1965/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.7134e-06 - val_loss: 9.7524e-07\n",
      "Epoch 1966/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.9805e-06 - val_loss: 5.2918e-07\n",
      "Epoch 1967/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.3504e-06 - val_loss: 4.9686e-07\n",
      "Epoch 1968/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.3920e-06 - val_loss: 5.7019e-07\n",
      "Epoch 1969/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.7484e-06 - val_loss: 7.9995e-07\n",
      "Epoch 1970/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.5027e-06 - val_loss: 6.2259e-07\n",
      "Epoch 1971/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.0113e-06 - val_loss: 5.4887e-07\n",
      "Epoch 1972/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.8377e-06 - val_loss: 5.5293e-07\n",
      "Epoch 1973/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.7130e-06 - val_loss: 9.1616e-07\n",
      "Epoch 1974/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.1516e-06 - val_loss: 6.0483e-07\n",
      "Epoch 1975/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.0235e-06 - val_loss: 5.9017e-07\n",
      "Epoch 1976/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.3638e-06 - val_loss: 5.6230e-07\n",
      "Epoch 1977/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.0878e-06 - val_loss: 6.2061e-07\n",
      "Epoch 1978/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.8133e-06 - val_loss: 6.6004e-07\n",
      "Epoch 1979/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.1029e-06 - val_loss: 4.8717e-07\n",
      "Epoch 1980/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.3945e-06 - val_loss: 1.4082e-06\n",
      "Epoch 1981/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.0922e-06 - val_loss: 7.9439e-07\n",
      "Epoch 1982/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.2327e-06 - val_loss: 7.6624e-07\n",
      "Epoch 1983/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.5048e-06 - val_loss: 9.1929e-07\n",
      "Epoch 1984/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.8464e-06 - val_loss: 3.5068e-06\n",
      "Epoch 1985/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.9446e-06 - val_loss: 5.4527e-07\n",
      "Epoch 1986/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.5602e-06 - val_loss: 6.9524e-07\n",
      "Epoch 1987/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 2.4966e-06 - val_loss: 8.8339e-07\n",
      "Epoch 1988/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 2.6615e-06 - val_loss: 2.1797e-06\n",
      "Epoch 1989/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.7623e-06 - val_loss: 1.3992e-06\n",
      "Epoch 1990/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.7101e-06 - val_loss: 1.7733e-06\n",
      "Epoch 1991/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.8032e-06 - val_loss: 3.9278e-06\n",
      "Epoch 1992/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.2307e-06 - val_loss: 1.0062e-06\n",
      "Epoch 1993/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.8707e-06 - val_loss: 6.4932e-07\n",
      "Epoch 1994/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.0833e-06 - val_loss: 7.6543e-07\n",
      "Epoch 1995/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 6.0485e-06 - val_loss: 1.3507e-06\n",
      "Epoch 1996/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.1707e-06 - val_loss: 5.6550e-07\n",
      "Epoch 1997/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.0009e-06 - val_loss: 6.4777e-07\n",
      "Epoch 1998/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.1953e-06 - val_loss: 4.9287e-07\n",
      "Epoch 1999/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.0535e-06 - val_loss: 5.1800e-07\n",
      "Epoch 2000/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.8055e-06 - val_loss: 1.2691e-06\n"
     ]
    }
   ],
   "source": [
    "final_model = build_dense(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'density': 72,\n",
       " 'activation': 'softsign',\n",
       " 'shuffle': True,\n",
       " 'dropout': 0.2,\n",
       " 'optimizer': 'adam',\n",
       " 'callbacks': [<keras.callbacks.callbacks.ModelCheckpoint at 0x203e5d342c8>]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_182\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_832 (Dense)            (None, 72)                7272      \n",
      "_________________________________________________________________\n",
      "dropout_470 (Dropout)        (None, 72)                0         \n",
      "_________________________________________________________________\n",
      "dense_833 (Dense)            (None, 36)                2628      \n",
      "_________________________________________________________________\n",
      "dropout_471 (Dropout)        (None, 36)                0         \n",
      "_________________________________________________________________\n",
      "dense_834 (Dense)            (None, 18)                666       \n",
      "_________________________________________________________________\n",
      "dense_835 (Dense)            (None, 1)                 19        \n",
      "=================================================================\n",
      "Total params: 10,585\n",
      "Trainable params: 10,585\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model[0].load_weights('./checkpoints/fundamental.(best).hdf5')\n",
    "y_predicted = final_model[0].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y_test = y_normaliser.inverse_transform(y_predicted)\n",
    "true_y_test = y_normaliser.inverse_transform(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE is 6429.10\n",
      "Medium error is 5.63\n"
     ]
    }
   ],
   "source": [
    "loss = np.mean((true_y_test - predicted_y_test)**2)\n",
    "medium_error = np.mean(abs(true_y_test - predicted_y_test))\n",
    "print(f'MSE is {loss:.2f}\\nMedium error is {medium_error:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trend accuracy is: 95.49%\n"
     ]
    }
   ],
   "source": [
    "print(f'Trend accuracy is: {(sum(1 for r,p in zip(predicted_y_test,true_y_test) if (r > 0 and p > 0) or (r < 0 and p < 0))/len(Y_test))*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test growth trends:        Predicted growth trends:\n",
      "3110                       2885\n",
      "Test decreasing trends:    Predicted decreasing trends:\n",
      "2855                       3080\n"
     ]
    }
   ],
   "source": [
    "print('Test growth trends:        Predicted growth trends:')\n",
    "print(sum(1 for v in true_y_test if v > 0),'                     ',sum(1 for v in predicted_y_test if v > 0))\n",
    "print('Test decreasing trends:    Predicted decreasing trends:')\n",
    "print(sum(1 for v in true_y_test if v < 0),'                     ',sum(1 for v in predicted_y_test if v < 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test mean: 13.814097446110715\n",
      "Predictions mean: 14.388855934143066\n"
     ]
    }
   ],
   "source": [
    "print(f'Test mean: {np.mean(true_y_test)}')\n",
    "print(f'Predictions mean: {np.mean(predicted_y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Results seem incredibly good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test values:    Predicted values:\n",
      "    6.71            4.72\n",
      "    15.98           12.71\n",
      "    -24.16          -21.00\n",
      "    -3.26           -3.81\n",
      "    -37.74          -32.02\n",
      "    19.17           13.64\n",
      "    -22.51          -19.86\n",
      "    3.10            1.58\n",
      "    -32.61          -27.95\n",
      "    -2.50           -3.28\n",
      "    -35.70          -30.71\n",
      "    5.68            0.93\n",
      "    5.03            3.37\n",
      "    42.44           35.66\n",
      "    4.46           -0.66\n",
      "    -29.52          -25.52\n",
      "    7.42            5.21\n",
      "    -4.15           -7.50\n",
      "    -16.67          -14.98\n",
      "    37.96           31.92\n",
      "    -21.83          -19.48\n",
      "    -5.49           -5.83\n",
      "    3.60            1.66\n",
      "    17.70           14.24\n",
      "    7.64            5.53\n",
      "    19.82           16.10\n",
      "    -11.20          -10.42\n",
      "    4.49            2.79\n",
      "    6.44            4.49\n",
      "    -1.85           -2.61\n",
      "    9.54            5.72\n",
      "    0.44           -2.28\n",
      "    17.55           14.06\n",
      "    -31.37          -27.16\n",
      "    10.42            8.26\n",
      "    -25.96          -22.85\n",
      "    5.77            3.78\n",
      "    26.91           22.00\n",
      "    -6.28           -6.40\n",
      "    139.19          122.41\n",
      "    -7.27           -7.20\n",
      "    1.71            0.41\n",
      "    -29.57          -25.70\n",
      "    4.49            2.78\n",
      "    -21.04          -18.17\n",
      "    0.24           -0.81\n",
      "    13.91           10.90\n",
      "    0.38           -0.72\n",
      "    21.39           17.52\n",
      "    -4.89           -5.02\n",
      "    5.54            1.91\n",
      "    -37.90          -32.46\n",
      "    -11.39          -10.79\n",
      "    10.34            7.58\n",
      "    19.00           15.40\n",
      "    167.94          148.40\n",
      "    -40.07          -33.99\n",
      "    13.27           10.31\n",
      "    -11.11          -10.44\n",
      "    7.57            5.32\n",
      "    -69.80          -57.72\n",
      "    10.82            8.11\n",
      "    14.15           11.85\n",
      "    12.16            2.48\n",
      "    -41.29          -34.97\n",
      "    -49.70          -41.82\n",
      "    52.54           44.90\n",
      "    8.35            6.21\n",
      "    9.72            7.29\n",
      "    19.63           15.84\n",
      "    -13.96          -12.80\n",
      "    -0.06           -1.10\n",
      "    74.25           63.95\n",
      "    -1.06           -1.95\n",
      "    4.84            3.07\n",
      "    9.15            7.07\n",
      "    7.57            5.43\n",
      "    14.52           11.42\n",
      "    11.17            8.42\n",
      "    -27.83          -23.90\n",
      "    -16.00          -14.54\n",
      "    -3.77           -1.91\n",
      "    -31.60          -27.19\n",
      "    -26.35          -23.05\n",
      "    75.28           65.03\n",
      "    27.41           22.19\n",
      "    20.57           16.69\n",
      "    -63.28          -52.42\n",
      "    1.35           -0.46\n",
      "    36.81           30.90\n",
      "    -29.84          -26.01\n",
      "    -48.32          -41.18\n",
      "    -37.31          -31.97\n",
      "    5.89            4.02\n",
      "    14.99           11.69\n",
      "    -13.61          -12.52\n",
      "    1.11           -1.15\n",
      "    21.34           17.48\n",
      "    -4.09           -5.45\n",
      "    3.37            1.39\n",
      "    3.37            5.29\n",
      "    -18.91          -16.42\n",
      "    40.97           34.56\n",
      "    -45.94          -38.92\n",
      "    42.91           36.31\n",
      "    1.71            0.19\n",
      "    14.80           15.27\n",
      "    -8.69           -8.25\n",
      "    -0.12           -1.34\n",
      "    18.27           14.66\n",
      "    6.12            4.17\n",
      "    29.41           24.31\n",
      "    -10.26           -9.73\n",
      "    44.68           37.86\n",
      "    14.46           11.66\n",
      "    6.38            4.47\n",
      "    15.62           12.36\n",
      "    3.55            2.15\n",
      "    39.83           33.60\n",
      "    530.45          492.34\n",
      "    2.00            0.65\n",
      "    -16.35          -14.61\n",
      "    -33.54          -28.27\n",
      "    2.76            1.30\n",
      "    7.41            5.27\n",
      "    -17.10          -15.23\n",
      "    16.41           13.07\n",
      "    -1.88           -3.05\n",
      "    0.87           -0.40\n",
      "    15.75           12.50\n",
      "    46.66           39.56\n",
      "    -13.27          -12.20\n",
      "    38.14           32.07\n",
      "    4.26            2.59\n",
      "    127.94          111.97\n",
      "    -3.42           -4.05\n",
      "    -7.27           -7.08\n",
      "    17.94           14.41\n",
      "    -2.00           -2.81\n",
      "    -11.96          -11.22\n",
      "    4.98            3.19\n",
      "    -0.45            7.95\n",
      "    25.83           21.29\n",
      "    -26.92          -23.40\n",
      "    21.04           17.06\n",
      "    0.73           -0.45\n",
      "    -2.00           -2.74\n",
      "    -25.66          -22.52\n",
      "    -4.68           -4.87\n",
      "    -2.59           -3.22\n",
      "    21.80           17.58\n",
      "    -22.50          -19.74\n",
      "    -39.94         1590.08\n",
      "    4.10            2.44\n",
      "    5.71            3.85\n",
      "    -13.11          -11.95\n",
      "    -13.96          -12.66\n",
      "    7.15            4.96\n",
      "    -84.00          -68.61\n",
      "    -8.96           -8.62\n",
      "    -17.92          -15.88\n",
      "    -20.00          -17.63\n",
      "    -36.97          -31.46\n",
      "    -8.36           -8.64\n",
      "    -2.29           -3.13\n",
      "    0.33           -2.40\n",
      "    7.65            5.58\n",
      "    11.02            8.75\n",
      "    22.33           18.19\n",
      "    -7.67           -7.61\n",
      "    13.08           10.20\n",
      "    50.00           42.50\n",
      "    -61.11          -50.96\n",
      "    -2.53           -3.08\n",
      "    138.33          121.86\n",
      "    -15.07          -13.71\n",
      "    -9.41           -8.97\n",
      "    16.00           12.62\n",
      "    7.41            5.32\n",
      "    302.33          272.02\n",
      "    249.52          222.87\n",
      "    0.60           -0.54\n",
      "    6.72            4.68\n",
      "    10.51            7.94\n",
      "    3.05            1.59\n",
      "    -16.71          -14.94\n",
      "    31.55           26.25\n",
      "    -42.43          -35.96\n",
      "    4.79            3.06\n",
      "    -8.76           -8.64\n",
      "    12.92           10.02\n",
      "    -4.36           -4.79\n",
      "    12.59            9.77\n",
      "    13.94           10.89\n",
      "    7.07           -0.63\n",
      "    -24.55          -21.60\n",
      "    21.58           17.64\n",
      "    -11.84          -10.99\n",
      "    -7.54           -7.41\n",
      "    -0.31           -1.31\n",
      "    -21.02          -19.66\n",
      "    -13.90          -12.63\n",
      "    -0.32           -1.19\n",
      "    -45.45          -38.62\n",
      "    1.89            0.64\n",
      "    16.94           13.52\n",
      "    -16.67          -15.13\n",
      "    42.86           36.18\n",
      "    21.29           17.25\n",
      "    5.38            3.85\n",
      "    -2.06           -2.83\n",
      "    12.79           10.08\n",
      "    -37.37          -32.01\n",
      "    11.21            8.49\n",
      "    29.03           24.71\n",
      "    3.88            1.10\n",
      "    23.16           18.97\n",
      "    -32.89          -28.20\n",
      "    2.06            0.73\n",
      "    2.70            1.28\n",
      "    10.48            7.55\n",
      "    78.67           67.94\n",
      "    14.08           11.06\n",
      "    -10.13           -9.39\n",
      "    -36.11          -31.06\n",
      "    -61.04          -50.76\n",
      "    16.29           12.62\n",
      "    32.50           26.70\n",
      "    24.85           20.39\n",
      "    8.84            6.85\n",
      "    -0.25           -0.33\n",
      "    -2.88           -3.57\n",
      "    90.53           78.50\n",
      "    1.97            0.61\n",
      "    63.06           53.88\n",
      "    7.48            5.41\n",
      "    -0.87           -1.73\n",
      "    24.32           19.98\n",
      "    120.66          105.68\n",
      "    15.72           -7.07\n",
      "    12.36            9.57\n",
      "    10.77            8.24\n",
      "    4.56            3.06\n",
      "    -1.04           -1.94\n",
      "    -17.12          -15.34\n",
      "    -2.20           -2.91\n",
      "    0.20            0.01\n",
      "    21.92           17.23\n",
      "    15.48           12.29\n",
      "    41.31           34.92\n",
      "    -14.44          -13.23\n",
      "    36.08           30.36\n",
      "    -31.49          -27.31\n",
      "    -11.02           -6.55\n",
      "    -6.95           -6.75\n",
      "    -12.70          -11.71\n",
      "    37.57           31.56\n",
      "    -2.82           -6.03\n",
      "    3.89            2.47\n",
      "    -56.20          -47.00\n",
      "    -71.25          -58.74\n",
      "    9.50            7.02\n",
      "    -13.27          -12.52\n",
      "    20.43           16.70\n",
      "    -28.42          -24.79\n",
      "    55.07           43.78\n",
      "    6.48            4.37\n",
      "    -34.78          -29.98\n",
      "    0.08          -11.35\n",
      "    10.31            7.65\n",
      "    -8.99           -8.51\n",
      "    -46.92          -39.70\n",
      "    20.48           16.57\n",
      "    10.43            7.91\n",
      "    -19.08          -17.13\n",
      "    -12.71          -13.16\n",
      "    -0.05           -1.08\n",
      "    -10.89          -10.26\n",
      "    -39.12          -33.53\n",
      "    -17.15          -15.42\n",
      "    -0.05           -1.06\n",
      "    -2.46           -3.35\n",
      "    -1.29           -2.29\n",
      "    8.78            6.60\n",
      "    -7.97           -7.77\n",
      "    -24.65          -21.73\n",
      "    -24.69          -21.50\n",
      "    -2.23           -9.16\n",
      "    -40.37          -34.28\n",
      "    5.72            3.93\n",
      "    -26.41          -22.96\n",
      "    -71.80          -59.23\n",
      "    1.06            0.10\n",
      "    9.01            6.65\n",
      "    -11.80          -11.61\n",
      "    7.09            4.96\n",
      "    3.61            2.16\n",
      "    -4.52           -7.88\n",
      "    33.33           27.83\n",
      "    4.28            3.55\n",
      "    -37.79          -32.31\n",
      "    -12.25          -11.33\n",
      "    -49.99          -42.20\n",
      "    -15.59          -14.18\n",
      "    23.22           19.43\n",
      "    -41.95          -36.05\n",
      "    11.75            8.99\n",
      "    16.64           13.28\n",
      "    12.63            9.89\n",
      "    -31.35          -27.28\n",
      "    10.63           10.54\n",
      "    -28.48          -24.83\n",
      "    4.05            2.01\n",
      "    -1.41            0.43\n",
      "    2.36            0.98\n",
      "    -41.23          -34.85\n",
      "    -34.68          -29.51\n",
      "    36.05           30.22\n",
      "    24.11           19.78\n",
      "    -75.09          -61.42\n",
      "    14.73           12.41\n",
      "    -39.63          -33.73\n",
      "    -11.22          -10.42\n",
      "    23.88           19.58\n",
      "    14.52           11.36\n",
      "    -8.96           -8.54\n",
      "    14.00           10.96\n",
      "    15.88           12.88\n",
      "    11.57           14.32\n",
      "    -2.49           -3.38\n",
      "    -29.26          -25.12\n",
      "    49.68           42.28\n",
      "    -1.13           -2.54\n",
      "    129.44          113.43\n",
      "    -14.00          -15.75\n",
      "    1.98            0.74\n",
      "    -16.67          -14.87\n",
      "    18.17           14.54\n",
      "    9.65            7.27\n",
      "    -3.45           -4.05\n",
      "    -1.13           -1.66\n",
      "    -10.29           -9.77\n",
      "    4.64            2.89\n",
      "    3.78            2.15\n",
      "    -25.13          -22.04\n",
      "    3.32            1.83\n",
      "    2.15            1.03\n",
      "    13.23            9.81\n",
      "    -4.28           -7.64\n",
      "    -71.43          -59.02\n",
      "    2.62            1.24\n",
      "    2.05            0.73\n",
      "    -30.32          -26.09\n",
      "    -68.91          -56.84\n",
      "    23.06           18.76\n",
      "    7.07            5.01\n",
      "    -49.47          -41.78\n",
      "    -0.92           -5.53\n",
      "    -15.25          -13.90\n",
      "    -10.08           -9.59\n",
      "    -4.02           -4.44\n",
      "    11.56            9.59\n",
      "    -9.84           -9.42\n",
      "    13.13           10.73\n",
      "    -6.89           -6.85\n",
      "    8.42            6.26\n",
      "    -30.49          -23.94\n",
      "    -7.62           -7.56\n",
      "    43.59           36.84\n",
      "    -3.05           -3.64\n",
      "    0.23           -0.99\n",
      "    5.98            4.13\n",
      "    -8.21           -7.45\n",
      "    -4.88           -5.18\n",
      "    9.47            7.18\n",
      "    -7.09           -7.04\n",
      "    19.97           16.19\n",
      "    41.82           35.12\n",
      "    -7.10           -6.80\n",
      "    9.34            6.85\n",
      "    -29.66          -25.54\n",
      "    89.17           77.34\n",
      "    -3.98           -4.43\n",
      "    16.83           13.30\n",
      "    -24.45          -21.39\n",
      "    3.17            1.49\n",
      "    0.11           -0.29\n",
      "    -11.90          -11.17\n",
      "    -12.84          -11.76\n",
      "    15.83           12.53\n",
      "    -9.49           -8.83\n",
      "    -8.24           -8.86\n",
      "    27.85           23.03\n",
      "    5.01            3.13\n",
      "    6.88            4.92\n",
      "    17.95           14.41\n",
      "    10.45            7.79\n",
      "    5.11            3.46\n",
      "    31.55           25.63\n",
      "    12.05            9.27\n",
      "    -36.83          -31.63\n",
      "    114.35           99.90\n",
      "    40.46           34.15\n",
      "    11.89            9.20\n",
      "    65.19           55.95\n",
      "    -0.70           -3.67\n",
      "    19.36           15.75\n",
      "    -0.84           -1.69\n",
      "    5.05            3.36\n",
      "    -12.04          -11.13\n",
      "    -3.87           -4.30\n",
      "    53.91           46.06\n",
      "    -28.57          -24.64\n",
      "    -6.26           -6.33\n",
      "    -7.01           -6.77\n",
      "    -34.25          -29.53\n",
      "    41.12           34.65\n",
      "    5.18            3.41\n",
      "    -16.53          -15.07\n",
      "    2.34            0.92\n",
      "    -16.19          -14.49\n",
      "    11.15            9.31\n",
      "    -7.93           -7.48\n",
      "    -34.86          -30.04\n",
      "    -11.29          -10.38\n",
      "    -12.67          -11.70\n",
      "    23.04           18.89\n",
      "    -6.09           -6.04\n",
      "    -6.50           -6.57\n",
      "    15.34           12.20\n",
      "    -33.77          -28.88\n",
      "    -34.43          -29.34\n",
      "    13.89          -27.46\n",
      "    5.95            4.03\n",
      "    -48.15          -40.49\n",
      "    -23.05          -20.17\n",
      "    -17.79          -15.93\n",
      "    -16.37          -14.83\n",
      "    -7.20           -7.03\n",
      "    16.52           13.26\n",
      "    -3.75           -4.17\n",
      "    234.27          209.26\n",
      "    13.01           10.11\n",
      "    23.65           19.64\n",
      "    5.97            4.10\n",
      "    13.74           10.76\n",
      "    31.62           26.36\n",
      "    3.95            2.32\n",
      "    -5.95           -6.27\n",
      "    14.03           10.89\n",
      "    -5.93           -6.13\n",
      "    11.02            8.16\n",
      "    -12.12          -11.27\n",
      "    11.52            8.62\n",
      "    21.50           17.29\n",
      "    24.74           19.31\n",
      "    -8.26           -8.03\n",
      "    -3.21           -3.70\n",
      "    12.85           10.35\n",
      "    3.36            1.82\n",
      "    26.34           21.57\n",
      "    -20.26          -17.87\n",
      "    4.11            2.46\n",
      "    6.83            4.82\n",
      "    -53.15          -44.56\n",
      "    -31.54          -27.25\n",
      "    9.91            7.47\n",
      "    -47.24          -39.66\n",
      "    81.62           70.56\n",
      "    -36.55          -31.09\n",
      "    -54.92          -46.07\n",
      "    22.82           18.82\n",
      "    -1.50           -2.34\n",
      "    -1.31           -2.26\n",
      "    -17.73          -17.62\n",
      "    -2.77           -2.93\n",
      "    -36.45          -31.33\n",
      "    -35.38          -30.37\n",
      "    0.20           -0.86\n",
      "    23.50           12.26\n",
      "    44.92           37.99\n",
      "    -11.13          -10.37\n",
      "    -4.55           -4.93\n",
      "    -24.33          -21.47\n",
      "    17.25           13.85\n",
      "    -6.42           -6.34\n",
      "    5.93           -4.61\n",
      "    -0.80           -1.74\n",
      "    -32.87          -28.44\n",
      "    2.46            1.08\n",
      "    23.98           19.65\n",
      "    -23.68          -20.90\n",
      "    594.44          558.64\n",
      "    -60.26          -43.89\n",
      "    1.92            0.59\n",
      "    -25.43          -22.08\n",
      "    37.01           31.03\n",
      "    -35.26          -27.50\n",
      "    21.22           17.14\n",
      "    1.55            0.13\n",
      "    -5.28           -5.68\n",
      "    -34.53          -29.62\n",
      "    41.36           34.87\n",
      "    -21.35          -18.81\n",
      "    -21.37          -18.74\n",
      "    -37.32          -32.00\n",
      "    13.24           10.37\n",
      "    -1.45           -2.19\n",
      "    10.70            8.64\n",
      "    -7.13           -7.02\n",
      "    6.91            4.87\n",
      "    7.86            5.76\n",
      "    2.26            0.69\n",
      "    1.97            0.65\n",
      "    37.87           32.16\n",
      "    -8.60           -8.22\n",
      "    3.12            1.61\n",
      "    -13.33          -12.39\n",
      "    0.27           -0.72\n",
      "    40.74           34.34\n",
      "    -33.20          -28.12\n",
      "    -33.33          -28.76\n",
      "    25.61           21.01\n",
      "    -5.06           -4.56\n",
      "    -10.81          -10.01\n",
      "    -0.99           -1.91\n",
      "    25.88           21.38\n",
      "    -4.40           -4.81\n",
      "    -1.74           -2.49\n",
      "    28.13           23.26\n",
      "    -30.59          -26.51\n",
      "    -0.26           -3.60\n",
      "    -3.96           -4.38\n",
      "    -6.97           -6.95\n",
      "    -23.84          -20.98\n",
      "    13.25           10.41\n",
      "    0.84           -0.29\n",
      "    -79.64          -65.29\n",
      "    -27.54          -23.87\n",
      "    -42.97          -36.60\n",
      "    -2.09           -2.83\n",
      "    -45.40          -37.94\n",
      "    -34.70          -29.72\n",
      "    -18.66          -16.68\n",
      "    -9.38           -8.59\n",
      "    -19.20          -17.16\n",
      "    3.67            2.21\n",
      "    3.57            2.00\n",
      "    13.53           10.67\n",
      "    0.34           -0.87\n",
      "    -51.56          -43.36\n",
      "    -5.63           -5.86\n",
      "    -5.25           -5.49\n",
      "    -30.43          -26.41\n",
      "    -2.60           -3.51\n",
      "    -55.16          -46.24\n",
      "    5.88            3.97\n",
      "    91.52           79.58\n",
      "    169.23          149.76\n",
      "    -44.12          -37.14\n",
      "    -8.81           -8.50\n",
      "    13.54           10.54\n",
      "    -30.00          -26.00\n",
      "    -39.64          -33.85\n",
      "    0.06           -2.25\n",
      "    5.52            3.72\n",
      "    12.03            9.26\n",
      "    -7.27           -5.42\n",
      "    -5.94           -6.19\n",
      "    -4.33           -4.65\n",
      "    -21.67          -19.26\n",
      "    -19.07          -17.07\n",
      "    1.05           -2.50\n",
      "    -10.50           -3.15\n",
      "    3.60            2.05\n",
      "    -27.61          -24.06\n",
      "    25.32           20.87\n",
      "    -8.07           -7.84\n",
      "    5.63            3.71\n",
      "    29.59           23.41\n",
      "    13.50           10.54\n",
      "    -8.60           -8.34\n",
      "    9.92            7.57\n",
      "    34.68           29.04\n",
      "    -13.03          -12.05\n",
      "    28.79           23.94\n",
      "    13.28            8.65\n",
      "    1.03           -0.06\n",
      "    26.63           22.03\n",
      "    -13.09          -12.07\n",
      "    0.62           -0.66\n",
      "    -35.41          -30.50\n",
      "    6.85            4.29\n",
      "    40.57           34.35\n",
      "    -13.40          -12.61\n",
      "    15.66           12.29\n",
      "    23.42           19.12\n",
      "    -19.48          -17.03\n",
      "    -48.03          -40.70\n",
      "    6.77            4.17\n",
      "    -8.00           -9.18\n",
      "    -15.26          -13.70\n",
      "    -74.76          -61.43\n",
      "    24.50           20.05\n",
      "    -0.92            0.57\n",
      "    -35.59          -30.55\n",
      "    23.78           18.94\n",
      "    36.66           30.81\n",
      "    -7.05           -7.12\n",
      "    34.10           28.53\n",
      "    -19.09          -17.10\n",
      "    -5.84           -6.26\n",
      "    8.04            5.82\n",
      "    -3.68           -4.21\n",
      "    8.23            6.01\n",
      "    -6.57           -6.59\n",
      "    35.03           25.46\n",
      "    6.95            4.85\n",
      "    6.42            4.42\n",
      "    3.43            2.03\n",
      "    -6.86           -6.86\n",
      "    1.43            0.19\n",
      "    -7.28           -6.85\n",
      "    -40.21          -34.05\n",
      "    3.96           -0.44\n",
      "    -49.72          -41.56\n",
      "    -50.00          -42.12\n",
      "    35.08           29.49\n",
      "    6.36            4.45\n",
      "    48.91           41.60\n",
      "    -1.67           -2.47\n",
      "    13.81           10.53\n",
      "    -30.00          -26.06\n",
      "    9.77            7.00\n",
      "    33.47           27.93\n",
      "    -7.78           -7.62\n",
      "    -56.67          -47.47\n",
      "    -40.75          -34.67\n",
      "    33.92           28.38\n",
      "    10.43            7.88\n",
      "    -59.21          -49.14\n",
      "    -2.77           -4.44\n",
      "    40.00           33.48\n",
      "    -57.50          -46.74\n",
      "    0.38           -0.63\n",
      "    3.87            2.31\n",
      "    1.42            0.14\n",
      "    -60.78          -50.74\n",
      "    21.60           17.55\n",
      "    44.43           37.54\n",
      "    8.45           -0.62\n",
      "    -0.57           -3.85\n",
      "    -7.41           -7.31\n",
      "    -35.61          -30.59\n",
      "    -58.70          -48.70\n",
      "    4.29            2.65\n",
      "    18.57           14.97\n",
      "    -1.56           -2.32\n",
      "    -21.14          -18.82\n",
      "    -5.43           -5.64\n",
      "    40.05           33.70\n",
      "    -77.12          -63.01\n",
      "    -20.96          -18.25\n",
      "    14.47           11.35\n",
      "    -2.78           -3.25\n",
      "    18.53           17.04\n",
      "    22.07           17.98\n",
      "    -31.27          -27.12\n",
      "    9.22            6.76\n",
      "    1.07           -0.01\n",
      "    -15.46          -14.01\n",
      "    29.27           24.27\n",
      "    -25.33          -22.24\n",
      "    -2.01           -3.04\n",
      "    2.25            0.35\n",
      "    15.11           11.91\n",
      "    0.12           -0.93\n",
      "    -1.28           -2.19\n",
      "    48.75           41.42\n",
      "    -14.02          -12.88\n",
      "    40.96           34.56\n",
      "    13.21           10.97\n",
      "    -37.34          -32.04\n",
      "    -21.02          -18.69\n",
      "    -41.95          -35.72\n",
      "    -13.33          -11.94\n",
      "    -4.70           -4.88\n",
      "    -4.62           -4.82\n",
      "    13.39           10.16\n",
      "    -5.66           -5.86\n",
      "    -22.73          -20.06\n",
      "    17.82           14.30\n",
      "    -18.97          -15.48\n",
      "    -17.33          -15.52\n",
      "    0.69           -0.31\n",
      "    23.09           18.92\n",
      "    -4.44           -4.80\n",
      "    13.02           10.06\n",
      "    -27.22          -23.74\n",
      "    29.31           24.51\n",
      "    -24.83          -22.25\n",
      "    61.58           52.75\n",
      "    -33.03          -28.52\n",
      "    -18.29          -15.51\n",
      "    7.83            5.65\n",
      "    16.82           13.91\n",
      "    -26.77          -23.43\n",
      "    10.48            8.37\n",
      "    -31.65          -27.21\n",
      "    6.45            4.55\n",
      "    6.15            4.20\n",
      "    -1.01            0.28\n",
      "    1.05           -0.26\n",
      "    -11.46          -10.29\n",
      "    7.31            3.60\n",
      "    -37.92          -32.17\n",
      "    -21.99          -19.21\n",
      "    -52.17          -43.60\n",
      "    -2.75           -3.32\n",
      "    -18.57          -16.64\n",
      "    125.66          110.17\n",
      "    7.20            5.00\n",
      "    343.95          311.03\n",
      "    54.18           46.22\n",
      "    36.95           30.96\n",
      "    -8.88           -8.59\n",
      "    -10.03           -9.30\n",
      "    7.00            3.46\n",
      "    97.62           84.90\n",
      "    -10.16           -9.70\n",
      "    -0.32           -1.30\n",
      "    17.39           13.90\n",
      "    52.60           44.82\n",
      "    -1.22           -1.97\n",
      "    0.25           -0.73\n",
      "    0.72           -0.43\n",
      "    1.93            0.66\n",
      "    14.36           11.27\n",
      "    -2.30           -2.97\n",
      "    -3.64           -4.14\n",
      "    -1.86           -2.37\n",
      "    23.93           19.66\n",
      "    -10.64           -9.78\n",
      "    13.67           10.71\n",
      "    71.80           61.77\n",
      "    19.11           15.60\n",
      "    -9.15           -8.63\n",
      "    -34.72          -29.94\n",
      "    64.62           55.41\n",
      "    -16.61          -15.09\n",
      "    354.86          320.69\n",
      "    7.04            5.00\n",
      "    -21.62          -18.91\n",
      "    -89.36          -72.70\n",
      "    -37.43          -32.00\n",
      "    -4.94           -5.23\n",
      "    -20.42          -14.41\n",
      "    -27.86          -24.17\n",
      "    -47.56          -40.49\n",
      "    14.79           11.64\n",
      "    -46.88          -39.70\n",
      "    -16.14          -14.58\n",
      "    -6.32           -6.76\n",
      "    33.17           27.67\n",
      "    -18.03          -16.22\n",
      "    -2.45           -3.00\n",
      "    -5.60           -5.77\n",
      "    -7.23           -7.20\n",
      "    -10.26           -9.65\n",
      "    1.75           -0.19\n",
      "    -16.42          -15.36\n",
      "    6.49            4.50\n",
      "    59.71           51.39\n",
      "    45.87           38.86\n",
      "    2.90            1.21\n",
      "    6.86            5.35\n",
      "    9.03            8.62\n",
      "    12.00            9.23\n",
      "    1.25            0.04\n",
      "    13.70           10.49\n",
      "    3.37            1.81\n",
      "    6.06            4.14\n",
      "    36.42           30.39\n",
      "    8.11            5.94\n",
      "    -5.33           -5.40\n",
      "    38.73           32.56\n",
      "    16.57           12.49\n",
      "    -14.73          -13.47\n",
      "    42.50           35.89\n",
      "    -9.79           -9.33\n",
      "    1058.57         1052.83\n",
      "    5.97            1.33\n",
      "    84.23           72.51\n",
      "    6.39            4.50\n",
      "    6.89            4.82\n",
      "    0.98           -0.20\n",
      "    16.42           13.33\n",
      "    15.59           12.28\n",
      "    9.23            6.80\n",
      "    -10.62           -9.90\n",
      "    11.54            8.80\n",
      "    -76.26          -62.74\n",
      "    19.17           15.47\n",
      "    11.62           -2.98\n",
      "    22.77           18.56\n",
      "    19.96           16.10\n",
      "    24.46           20.02\n",
      "    -21.92          -19.36\n",
      "    -7.36          -14.75\n",
      "    3.73            2.13\n",
      "    3.07            7.21\n",
      "    -8.81           -8.49\n",
      "    16.90           13.57\n",
      "    6.18            4.29\n",
      "    -0.57           -1.44\n",
      "    21.22           -1.53\n",
      "    -49.22          -41.17\n",
      "    6.35            3.93\n",
      "    -30.73          -26.54\n",
      "    13.38           10.67\n",
      "    -28.63          -24.63\n",
      "    6.96            5.14\n",
      "    22.27           17.73\n",
      "    -28.60          -24.68\n",
      "    7.24            5.09\n",
      "    -27.13          -23.50\n",
      "    7.90            5.87\n",
      "    137.03          120.38\n",
      "    25.36           20.77\n",
      "    1.60           -1.98\n",
      "    10.36            7.91\n",
      "    3.45            1.06\n",
      "    -1.91           -2.70\n",
      "    -16.76          -14.95\n",
      "    -6.09           -7.24\n",
      "    -25.47          -23.29\n",
      "    37.18           31.32\n",
      "    13.46           10.55\n",
      "    -18.33          -16.20\n",
      "    39.01           32.76\n",
      "    14.18           11.08\n",
      "    37.64           31.58\n",
      "    -4.87           -7.89\n",
      "    -46.67          -39.68\n",
      "    -11.39          -10.59\n",
      "    10.03           14.40\n",
      "    132.51          116.00\n",
      "    -50.29          -42.05\n",
      "    -81.18          -66.31\n",
      "    -36.64          -31.44\n",
      "    5.43            3.62\n",
      "    22.72           18.58\n",
      "    7.70            5.56\n",
      "    21.41           20.21\n",
      "    5.94            3.95\n",
      "    -6.08           -6.08\n",
      "    20.30           16.54\n",
      "    -15.21          -14.06\n",
      "    23.61           19.32\n",
      "    47.83           40.64\n",
      "    80.73           69.77\n",
      "    4.04            2.39\n",
      "    16.28           12.95\n",
      "    -10.66          -10.12\n",
      "    -3.46           -3.81\n",
      "    -4.69           -4.86\n",
      "    5.71            3.83\n",
      "    -0.31           -0.80\n",
      "    21.17           17.36\n",
      "    -9.85           -9.28\n",
      "    8.17            6.12\n",
      "    20.13           16.39\n",
      "    -2.42           -3.34\n",
      "    3.21            1.63\n",
      "    -46.51          -39.30\n",
      "    3.42            1.90\n",
      "    11.94            8.98\n",
      "    -7.40           -7.16\n",
      "    -29.11          -25.35\n",
      "    228.21          203.54\n",
      "    -17.28          -15.51\n",
      "    4.62            2.92\n",
      "    -7.30         1294.87\n",
      "    21.03           17.12\n",
      "    -15.35          -14.02\n",
      "    -20.89          -18.50\n",
      "    -2.66           -3.31\n",
      "    7.88            5.67\n",
      "    -33.88          -29.28\n",
      "    3.75            2.14\n",
      "    -1.13           -2.23\n",
      "    21.05           15.14\n",
      "    -8.30           -7.96\n",
      "    24.60           20.17\n",
      "    33.33           27.78\n",
      "    -9.58           -9.25\n",
      "    -11.77          -11.11\n",
      "    27.23           22.51\n",
      "    11.95            9.18\n",
      "    27.43           22.69\n",
      "    -5.24           -4.61\n",
      "    24.89           20.55\n",
      "    -2.16           -2.95\n",
      "    12.79            9.98\n",
      "    -14.71          -13.46\n",
      "    7.28            4.97\n",
      "    -5.62           -5.83\n",
      "    -15.97          -14.32\n",
      "    -19.92          -17.89\n",
      "    7.79            5.56\n",
      "    -21.67          -19.27\n",
      "    72.20           62.18\n",
      "    4.77            1.80\n",
      "    -10.64           -9.50\n",
      "    -59.47          -49.19\n",
      "    -8.53           -8.21\n",
      "    6.98            4.65\n",
      "    4.83            3.22\n",
      "    10.13            7.70\n",
      "    -36.79          -31.62\n",
      "    -29.38          -25.58\n",
      "    2.67            1.26\n",
      "    -8.54           -8.12\n",
      "    -25.83          -24.29\n",
      "    -22.35          -19.63\n",
      "    -74.20          -61.11\n",
      "    21.48           17.53\n",
      "    -45.17          -38.04\n",
      "    36.41           30.56\n",
      "    -5.99           -6.14\n",
      "    -17.93          -15.99\n",
      "    -16.20          -14.72\n",
      "    21.84           17.70\n",
      "    0.94           -0.26\n",
      "    -33.59          -28.53\n",
      "    25.00           20.59\n",
      "    -21.82          -19.06\n",
      "    31.83           25.51\n",
      "    -0.31           -1.83\n",
      "    30.23           25.17\n",
      "    0.47           -0.59\n",
      "    -14.29          -13.01\n",
      "    11.52            8.54\n",
      "    -26.06          -22.66\n",
      "    -16.51          -14.69\n",
      "    -36.66          -31.53\n",
      "    -0.08           -2.99\n",
      "    -12.30          -11.28\n",
      "    0.96           -0.21\n",
      "    -3.55           -2.21\n",
      "    -2.97           -3.55\n",
      "    -8.38           -8.14\n",
      "    -22.01          -19.52\n",
      "    -12.41          -11.39\n",
      "    1.85            0.46\n",
      "    -14.03          -12.95\n",
      "    -1.11           -1.78\n",
      "    -6.31           -6.13\n",
      "    -32.16          -27.68\n",
      "    151.62          133.66\n",
      "    7.07            4.99\n",
      "    -23.66          -20.88\n",
      "    3.58            6.05\n",
      "    -20.58          -18.34\n",
      "    -8.18           -8.01\n",
      "    31.68           26.37\n",
      "    -9.09           -8.58\n",
      "    -18.29          -16.43\n",
      "    4.79            1.17\n",
      "    -33.60          -28.92\n",
      "    151.43          133.25\n",
      "    95.10           82.58\n",
      "    -30.34          -26.18\n",
      "    11.93            9.14\n",
      "    -44.23          -37.30\n",
      "    -4.41           -4.55\n",
      "    -58.02          -48.24\n",
      "    29.71           26.02\n",
      "    1.09           -0.09\n",
      "    -36.03          -30.96\n",
      "    20.00           16.17\n",
      "    31.51           26.25\n",
      "    -21.64          -19.18\n",
      "    217.76          193.94\n",
      "    2.65            1.19\n",
      "    -15.01          -13.70\n",
      "    9.43            7.58\n",
      "    -24.85          -21.63\n",
      "    -20.04          -17.69\n",
      "    -32.17          -27.86\n",
      "    -7.72           -7.46\n",
      "    8.43            6.18\n",
      "    -26.83          -23.47\n",
      "    -37.77          -32.31\n",
      "    6.45            7.08\n",
      "    37.58           31.69\n",
      "    -51.10          -43.05\n",
      "    -7.09           -7.05\n",
      "    -8.41           -8.05\n",
      "    13.02           10.07\n",
      "    6.40            5.04\n",
      "    1.45            0.18\n",
      "    -37.73          -32.23\n",
      "    -4.82           -5.32\n",
      "    1.22           -0.01\n",
      "    0.11           -0.81\n",
      "    -27.98          -24.45\n",
      "    -24.59          -21.52\n",
      "    -6.53           -6.44\n",
      "    13.35           10.43\n",
      "    1.80            0.59\n",
      "    10.92            8.01\n",
      "    -7.71           -7.59\n",
      "    -17.04          -15.15\n",
      "    -11.23          -10.54\n",
      "    -6.99           -6.97\n",
      "    -14.64          -13.29\n",
      "    -14.29          -13.98\n",
      "    -6.85           -6.89\n",
      "    -33.33          -28.85\n",
      "    -1.19           -2.07\n",
      "    10.14            4.27\n",
      "    -54.34          -45.65\n",
      "    -3.50           -5.40\n",
      "    27.53           29.81\n",
      "    23.58           19.35\n",
      "    -76.54          -62.29\n",
      "    35.02           27.59\n",
      "    15.91           13.70\n",
      "    35.77           30.02\n",
      "    10.39            7.57\n",
      "    33.01           27.65\n",
      "    94.62           82.29\n",
      "    3.13            1.37\n",
      "    -24.64          -21.58\n",
      "    17.84           14.18\n",
      "    7.83            5.70\n",
      "    1.82            0.73\n",
      "    50.88           43.20\n",
      "    -3.24           -4.23\n",
      "    -22.42          -19.84\n",
      "    -6.67           -6.71\n",
      "    12.95            6.67\n",
      "    13.41           10.37\n",
      "    -3.45           -3.99\n",
      "    -1.08           -2.16\n",
      "    23.67           18.82\n",
      "    9.81            7.36\n",
      "    9.59            7.03\n",
      "    9.73            7.11\n",
      "    -0.53           -1.49\n",
      "    -34.90          -29.95\n",
      "    -21.59          -19.68\n",
      "    82.22           71.20\n",
      "    8.57            3.75\n",
      "    1.37            0.11\n",
      "    35.87           30.10\n",
      "    14.48           11.32\n",
      "    37.91           31.87\n",
      "    -2.46           -3.13\n",
      "    4.11            2.45\n",
      "    5.72            3.49\n",
      "    -8.84           -8.28\n",
      "    -1.98           -2.63\n",
      "    -10.67           -9.95\n",
      "    13.86           10.84\n",
      "    17.79           14.28\n",
      "    36.47           29.07\n",
      "    -14.47          -13.26\n",
      "    2.62           -8.59\n",
      "    10.22            7.80\n",
      "    65.52           56.47\n",
      "    -9.78           -9.33\n",
      "    19.34           15.60\n",
      "    -5.81           -5.54\n",
      "    -10.29           -9.67\n",
      "    43.37           36.71\n",
      "    -9.18           -8.89\n",
      "    2.74            1.65\n",
      "    18.79           15.28\n",
      "    -17.35          -15.69\n",
      "    -23.01          -20.35\n",
      "    62.31           53.44\n",
      "    1.67            0.37\n",
      "    -13.16          -12.14\n",
      "    -28.92          -24.71\n",
      "    4.85            3.27\n",
      "    33.27           27.76\n",
      "    32.91           27.55\n",
      "    -19.49          -18.24\n",
      "    -5.49           -4.83\n",
      "    -0.97           -1.77\n",
      "    -45.82          -38.67\n",
      "    -22.73          -20.12\n",
      "    13.95           10.97\n",
      "    -7.80           -7.65\n",
      "    61.43           52.65\n",
      "    -3.04           -3.54\n",
      "    -15.03          -13.72\n",
      "    -7.78           -7.57\n",
      "    -11.79          -10.93\n",
      "    -6.86           -6.84\n",
      "    10.00            7.38\n",
      "    22.94           18.88\n",
      "    -42.00          -35.78\n",
      "    -0.76            1.40\n",
      "    9.89            7.43\n",
      "    -2.39           -1.32\n",
      "    -13.48          -12.34\n",
      "    0.27           -3.85\n",
      "    199.03          176.92\n",
      "    -33.82          -29.14\n",
      "    -11.63          -10.76\n",
      "    7.37            5.21\n",
      "    -17.61          -15.85\n",
      "    23.61           19.35\n",
      "    37.59           31.50\n",
      "    2.89            1.16\n",
      "    0.24           -0.84\n",
      "    -2.39           -2.84\n",
      "    -5.07           -5.30\n",
      "    -23.07          -20.32\n",
      "    8.02            5.91\n",
      "    -0.42           -1.47\n",
      "    9.30            6.94\n",
      "    0.72           -0.31\n",
      "    -82.60          -67.10\n",
      "    45.12           38.20\n",
      "    8.90            6.54\n",
      "    -21.58          -19.03\n",
      "    -25.81          -22.57\n",
      "    90.36           78.43\n",
      "    -5.93           -6.14\n",
      "    0.91           -0.71\n",
      "    -6.04           -6.09\n",
      "    -14.32          -13.04\n",
      "    -3.69           -4.46\n",
      "    -5.81           -6.29\n",
      "    -11.23          -10.45\n",
      "    -61.58          -50.88\n",
      "    7.05            5.01\n",
      "    -21.25          -18.89\n",
      "    72.29           62.39\n",
      "    -48.23          -40.50\n",
      "    46.37           39.51\n",
      "    -48.91          -41.30\n",
      "    -28.86          -25.16\n",
      "    -0.22           -1.03\n",
      "    -11.44          -10.71\n",
      "    -14.08          -13.13\n",
      "    -76.43          -62.39\n",
      "    -0.40           -2.08\n",
      "    -1.91           -2.67\n",
      "    5.66            3.78\n",
      "    -3.17           -3.75\n",
      "    -33.33          -28.52\n",
      "    -28.76          -28.11\n",
      "    15.07           11.85\n",
      "    54.07           46.22\n",
      "    -11.33          -10.68\n",
      "    -4.54           -4.24\n",
      "    16.44           13.23\n",
      "    49.77           42.54\n",
      "    1.77            0.56\n",
      "    -18.46          -16.48\n",
      "    114.29           99.79\n",
      "    -13.86          -11.99\n",
      "    -1.83           -3.11\n",
      "    52.10           44.36\n",
      "    -22.35          -19.82\n",
      "    -30.47          -26.09\n",
      "    22.22           18.14\n",
      "    11.03            8.25\n",
      "    -22.11          -19.25\n",
      "    26.24           21.63\n",
      "    1.52            0.84\n",
      "    19.11           15.51\n",
      "    12.76            9.96\n",
      "    5.22            3.59\n",
      "    11.44            8.76\n",
      "    46.02           39.02\n",
      "    14.42           11.38\n",
      "    -2.04          -14.51\n",
      "    5.26            3.85\n",
      "    -1.71           -2.53\n",
      "    205.17          182.23\n",
      "    -4.42           -4.64\n",
      "    11.93            9.18\n",
      "    -3.03           -3.64\n",
      "    34.45           28.73\n",
      "    -22.30          -19.66\n",
      "    -23.16          -20.20\n",
      "    21.11           17.12\n",
      "    -4.23           -4.70\n",
      "    21.29           17.30\n",
      "    -4.07           -4.52\n",
      "    4.85            3.10\n",
      "    3.13            1.65\n",
      "    18.22           14.62\n",
      "    10.70            8.16\n",
      "    6.28            4.50\n",
      "    1.47            0.27\n",
      "    11.29            8.72\n",
      "    -5.26           -5.49\n",
      "    8.99            6.59\n",
      "    33.50           27.87\n",
      "    11.60            8.79\n",
      "    -33.61          -28.74\n",
      "    50.73           43.39\n",
      "    -26.47          -23.06\n",
      "    3.25           -0.17\n",
      "    28.56           24.23\n",
      "    5.00            3.28\n",
      "    -10.32           -9.61\n",
      "    -22.80          -20.24\n",
      "    -7.39           -7.22\n",
      "    -10.87          -10.04\n",
      "    12.93           10.08\n",
      "    -17.57          -15.09\n",
      "    12.67            9.70\n",
      "    -5.43           -5.56\n",
      "    18.92           15.19\n",
      "    -29.48          -25.27\n",
      "    -7.43           -7.25\n",
      "    -9.97          -11.01\n",
      "    127.92          112.14\n",
      "    21.93           17.66\n",
      "    41.42           34.65\n",
      "    8.33            5.37\n",
      "    -0.20           -1.08\n",
      "    7.22           12.39\n",
      "    -0.16           -0.87\n",
      "    17.06           14.52\n",
      "    133.80          117.58\n",
      "    -0.53           -1.56\n",
      "    -4.47           -4.57\n",
      "    4.76            3.14\n",
      "    -28.05          -23.76\n",
      "    -2.89           -3.97\n",
      "    7.60            5.47\n",
      "    19.20           15.49\n",
      "    22.77           18.63\n",
      "    -1.22           -2.06\n",
      "    15.19           11.82\n",
      "    22.50           18.37\n",
      "    -0.12           -1.18\n",
      "    -16.67          -14.81\n",
      "    14.06           10.49\n",
      "    25.88           21.36\n",
      "    -3.57           -3.97\n",
      "    40.43           34.18\n",
      "    -7.84           -7.61\n",
      "    0.54           -0.62\n",
      "    6.05            4.35\n",
      "    141.24          124.22\n",
      "    7.85            5.68\n",
      "    6.13            4.20\n",
      "    4.39            2.75\n",
      "    -11.40          -10.84\n",
      "    27.33           22.48\n",
      "    45.56           38.63\n",
      "    10.26            7.93\n",
      "    83.62           72.31\n",
      "    -0.51           -1.52\n",
      "    -11.16          -10.47\n",
      "    -9.44           -8.92\n",
      "    92.63           80.38\n",
      "    13.95           10.97\n",
      "    -7.88           -7.97\n",
      "    10.87            8.27\n",
      "    6.61            3.76\n",
      "    -9.47           -8.93\n",
      "    18.53           14.88\n",
      "    -27.37          -24.06\n",
      "    1.24           -0.00\n",
      "    19.45           15.46\n",
      "    10.50            7.90\n",
      "    60.85           52.16\n",
      "    1.97            0.69\n",
      "    31.72           26.31\n",
      "    -4.17           -4.29\n",
      "    -23.33          -20.36\n",
      "    -0.83           -1.76\n",
      "    -10.19          -11.09\n",
      "    3.29            1.67\n",
      "    -4.46           -5.19\n",
      "    -10.64          -10.08\n",
      "    0.67           -0.47\n",
      "    -14.41          -13.19\n",
      "    -53.11          -44.61\n",
      "    -12.07           -8.20\n",
      "    -23.33          -20.55\n",
      "    3.49            1.91\n",
      "    -25.81          -22.56\n",
      "    43.27           36.72\n",
      "    147.50          129.73\n",
      "    3.93            2.37\n",
      "    4.37            2.67\n",
      "    -22.25          -19.54\n",
      "    17.86           14.78\n",
      "    -12.32          -11.96\n",
      "    -2.48           -3.20\n",
      "    -47.87          -40.21\n",
      "    -34.19          -29.52\n",
      "    10.90           20.30\n",
      "    -20.69          -18.27\n",
      "    -11.91          -10.42\n",
      "    1.04           -1.25\n",
      "    3.23            1.73\n",
      "    -36.51          -31.13\n",
      "    -43.77          -37.07\n",
      "    25.42           20.76\n",
      "    -23.47          -21.57\n",
      "    18.24           14.68\n",
      "    41.59           35.10\n",
      "    -5.59           -5.79\n",
      "    -0.88           -1.83\n",
      "    22.22           18.11\n",
      "    6.66            4.71\n",
      "    -26.94          -23.43\n",
      "    3.15            1.54\n",
      "    -9.86           -9.28\n",
      "    -12.34          -11.38\n",
      "    0.01           -0.86\n",
      "    -65.95          -54.68\n",
      "    1948.97         1894.51\n",
      "    -7.03           -6.93\n",
      "    1.91            0.65\n",
      "    -12.35          -11.43\n",
      "    40.29           34.14\n",
      "    1.26            0.01\n",
      "    -15.73          -14.29\n",
      "    -28.21          -24.62\n",
      "    18.04           14.42\n",
      "    61.60           52.77\n",
      "    49.75           42.42\n",
      "    -1.97           -3.69\n",
      "    12.82           10.09\n",
      "    15.29           12.08\n",
      "    3.69            2.10\n",
      "    4.90            3.13\n",
      "    33.54           28.09\n",
      "    6.62            4.59\n",
      "    -1.76           -3.24\n",
      "    -60.00          -49.90\n",
      "    -48.01          -40.60\n",
      "    -12.22          -11.38\n",
      "    13.06           10.20\n",
      "    -0.44           -1.68\n",
      "    15.05           12.99\n",
      "    -11.11          -10.70\n",
      "    -12.47          -11.55\n",
      "    -35.59          -30.51\n",
      "    9.47            7.04\n",
      "    -6.66           -6.68\n",
      "    14.51            6.45\n",
      "    -27.85          -24.27\n",
      "    180.00          159.22\n",
      "    10.38            7.87\n",
      "    64.51           55.48\n",
      "    13.63           10.64\n",
      "    -17.58          -15.73\n",
      "    -2.86           -3.45\n",
      "    -1.59           -2.20\n",
      "    -26.73          -23.44\n",
      "    -7.47           -7.04\n",
      "    38.16           32.10\n",
      "    23.88           19.45\n",
      "    17.86           14.19\n",
      "    -42.27          -35.82\n",
      "    -34.40          -29.44\n",
      "    -20.52          -18.13\n",
      "    -25.93          -22.60\n",
      "    -19.60          -17.08\n",
      "    -15.39          -13.83\n",
      "    -3.47           -4.01\n",
      "    4.17            2.50\n",
      "    -12.20          -11.39\n",
      "    880.76          879.21\n",
      "    1.25            1.07\n",
      "    9.93            7.53\n",
      "    57.84           49.46\n",
      "    97.19           84.49\n",
      "    15.18           12.01\n",
      "    -51.01          -42.62\n",
      "    19.21           14.76\n",
      "    0.72           -0.44\n",
      "    -13.75          -12.66\n",
      "    -3.68           -4.09\n",
      "    -3.74           -4.21\n",
      "    -2.56           -3.20\n",
      "    -4.68           -5.01\n",
      "    24.50           20.18\n",
      "    33.72           28.14\n",
      "    -8.97           -8.63\n",
      "    -0.92           -1.85\n",
      "    101.81           88.67\n",
      "    -6.79            1.48\n",
      "    19.08           15.36\n",
      "    -38.24          -32.52\n",
      "    59.93           50.65\n",
      "    37.63           31.62\n",
      "    -24.26          -21.53\n",
      "    9.88           -6.08\n",
      "    -2.72           -3.32\n",
      "    -19.31          -17.03\n",
      "    5.73            3.78\n",
      "    0.89           -0.22\n",
      "    14.70           11.70\n",
      "    4.06            2.42\n",
      "    6.43            4.94\n",
      "    1.69            0.49\n",
      "    -1.99           -4.03\n",
      "    -16.99          -15.28\n",
      "    -35.71          -30.82\n",
      "    13.32            9.84\n",
      "    -30.91          -26.79\n",
      "    6.01            4.04\n",
      "    -32.24          -25.50\n",
      "    -19.49          -18.35\n",
      "    -19.74          -17.28\n",
      "    8.60            6.38\n",
      "    -46.42          -39.18\n",
      "    0.93           -0.20\n",
      "    7.66            5.45\n",
      "    -6.30           -6.39\n",
      "    -8.73           -8.41\n",
      "    30.07           25.09\n",
      "    13.97           10.28\n",
      "    5.00            3.29\n",
      "    17.44           13.84\n",
      "    -9.34           -8.92\n",
      "    -13.77          -12.51\n",
      "    6.67            4.64\n",
      "    4.45            2.76\n",
      "    24.67           20.77\n",
      "    9.21            6.90\n",
      "    -19.18          -17.05\n",
      "    -13.79          -12.60\n",
      "    18.71           14.57\n",
      "    7.17            5.10\n",
      "    -17.50          -15.77\n",
      "    27.94           23.07\n",
      "    -0.99           -1.87\n",
      "    26.58           21.79\n",
      "    -18.09          -16.17\n",
      "    -1.05           -1.86\n",
      "    -6.54           -6.44\n",
      "    10.37            7.73\n",
      "    -3.63           -3.98\n",
      "    -29.54          -25.64\n",
      "    3.56            2.31\n",
      "    -27.13          -23.72\n",
      "    8.52            6.31\n",
      "    9.13            6.90\n",
      "    -70.52          -57.74\n",
      "    -55.58          -46.59\n",
      "    19.12           15.95\n",
      "    -51.60          -43.06\n",
      "    30.65           25.48\n",
      "    -4.00           -4.46\n",
      "    46.73           39.64\n",
      "    41.99           35.43\n",
      "    -19.75          -17.47\n",
      "    -13.87          -12.72\n",
      "    -2.48           -3.51\n",
      "    -10.04           -9.47\n",
      "    -35.54          -30.61\n",
      "    -14.54          -13.14\n",
      "    1.53            0.23\n",
      "    -65.46          -54.37\n",
      "    -30.82          -26.76\n",
      "    -21.31          -18.97\n",
      "    0.13           -0.94\n",
      "    45.71           38.80\n",
      "    -2.56           -3.11\n",
      "    -28.32          -24.71\n",
      "    -13.33          -12.23\n",
      "    -0.70           -1.63\n",
      "    8.51            5.78\n",
      "    -5.23           -5.52\n",
      "    -20.15          -18.05\n",
      "    8.60            6.48\n",
      "    30.35           25.26\n",
      "    1.73            0.51\n",
      "    0.16           -0.94\n",
      "    0.97           -0.36\n",
      "    -40.51          -34.61\n",
      "    -8.56           -8.25\n",
      "    -21.43          -18.91\n",
      "    -40.19          -34.36\n",
      "    -15.28          -14.05\n",
      "    -49.37          -41.72\n",
      "    12.50            9.69\n",
      "    -8.83           -8.53\n",
      "    -18.48          -16.53\n",
      "    9.55            6.10\n",
      "    -43.34          -36.78\n",
      "    -17.11          -15.44\n",
      "    -32.38          -28.05\n",
      "    7.46            4.32\n",
      "    33.33           27.82\n",
      "    38.42           32.26\n",
      "    38.33           32.22\n",
      "    -14.69          -13.46\n",
      "    -40.17          -34.36\n",
      "    -2.43           -3.34\n",
      "    11.11            8.57\n",
      "    -56.91          -47.69\n",
      "    1484.70         1463.57\n",
      "    4.58            2.99\n",
      "    9.11            6.68\n",
      "    -24.15          -21.21\n",
      "    7.15            5.13\n",
      "    12.19            9.43\n",
      "    -8.47           -8.01\n",
      "    -15.15          -13.82\n",
      "    47.22           40.08\n",
      "    12.45            9.42\n",
      "    11.82            9.22\n",
      "    -9.94           -9.43\n",
      "    28.31           22.24\n",
      "    -23.61          -20.73\n",
      "    -22.59          -19.99\n",
      "    -26.59          -22.39\n",
      "    -19.10          -16.93\n",
      "    -29.50          -25.61\n",
      "    8.62            7.50\n",
      "    39.37           33.54\n",
      "    -47.14          -39.84\n",
      "    5.11            3.31\n",
      "    -6.19           -6.30\n",
      "    57.77           49.48\n",
      "    -11.41          -10.64\n",
      "    -20.14          -18.46\n",
      "    1.76            0.71\n",
      "    27.36           22.60\n",
      "    20.16           16.32\n",
      "    38.24           32.23\n",
      "    5.51            2.73\n",
      "    28.38           23.55\n",
      "    10.26            7.86\n",
      "    -15.68          -14.12\n",
      "    4.04            2.25\n",
      "    11.33            8.64\n",
      "    -64.25          -53.25\n",
      "    -19.96          -17.82\n",
      "    7.88            5.66\n",
      "    4.22            2.71\n",
      "    21.89           17.90\n",
      "    22.25           18.19\n",
      "    -25.72          -22.65\n",
      "    0.14           -0.85\n",
      "    545.83          506.94\n",
      "    1.43            0.25\n",
      "    18.96           15.32\n",
      "    6.37            4.44\n",
      "    -38.15          -32.63\n",
      "    -14.38          -13.05\n",
      "    -79.17          -64.91\n",
      "    -8.17           -7.90\n",
      "    32.50           27.06\n",
      "    55.00           46.92\n",
      "    30.66           25.53\n",
      "    20.95           17.04\n",
      "    2.44            1.20\n",
      "    11.05            8.49\n",
      "    2.86            1.43\n",
      "    12.22            9.45\n",
      "    -23.03          -20.40\n",
      "    -31.70          -27.49\n",
      "    61.07           52.28\n",
      "    36.26           30.96\n",
      "    16.85           13.01\n",
      "    11.39            8.33\n",
      "    -15.58          -14.15\n",
      "    62.44           53.63\n",
      "    -0.81           -2.09\n",
      "    18.57           13.59\n",
      "    -7.64           -7.48\n",
      "    -73.11          -60.20\n",
      "    -4.21           -4.56\n",
      "    21.46           17.15\n",
      "    10.78            8.21\n",
      "    -4.13           -4.60\n",
      "    522.22          484.76\n",
      "    58.97           50.44\n",
      "    6.18            4.28\n",
      "    -9.09           -8.73\n",
      "    -8.23           -8.40\n",
      "    4.20            2.59\n",
      "    0.90           -0.16\n",
      "    2.55            1.13\n",
      "    -17.31          -15.79\n",
      "    1.15            0.04\n",
      "    16.51           11.62\n",
      "    -28.40          -24.74\n",
      "    77.69           67.10\n",
      "    6.77            4.86\n",
      "    -22.02          -19.43\n",
      "    6.69            4.59\n",
      "    -11.14          -10.32\n",
      "    -21.05          -18.59\n",
      "    6.10            0.90\n",
      "    12.16            9.46\n",
      "    0.17           -2.84\n",
      "    -15.30          -14.02\n",
      "    -3.01           -3.53\n",
      "    7.98            5.83\n",
      "    -4.33           -4.64\n",
      "    3.66            2.07\n",
      "    0.42           -2.17\n",
      "    18.78           15.09\n",
      "    -16.38          -14.70\n",
      "    16.87           13.82\n",
      "    -11.49          -10.82\n",
      "    -5.57           -5.93\n",
      "    12.37            8.60\n",
      "    28.57           23.71\n",
      "    159.49          140.55\n",
      "    34.78           29.22\n",
      "    60.82           52.10\n",
      "    4.21          -14.40\n",
      "    -49.30          -41.25\n",
      "    -5.29           -5.58\n",
      "    7.66            5.39\n",
      "    -20.96          -18.66\n",
      "    22.14           18.03\n",
      "    3.47            1.77\n",
      "    -3.05           -3.61\n",
      "    -5.84           -6.01\n",
      "    -13.07          -12.07\n",
      "    20.91           17.01\n",
      "    23.63           19.35\n",
      "    -6.35           -6.05\n",
      "    -33.09          -28.39\n",
      "    4.30            3.04\n",
      "    19.11           15.42\n",
      "    -1.67           -2.45\n",
      "    -16.22          -14.74\n",
      "    25.13           20.91\n",
      "    65.71           56.52\n",
      "    -14.48          -13.56\n",
      "    -9.59           -9.13\n",
      "    23.78           19.51\n",
      "    40.76           34.44\n",
      "    -43.86          -37.33\n",
      "    3.75            2.22\n",
      "    18.90           15.26\n",
      "    -35.99          -30.77\n",
      "    -5.51           -6.02\n",
      "    23.41           18.94\n",
      "    22.84           18.74\n",
      "    -11.56          -10.69\n",
      "    11.44            8.72\n",
      "    -1.49           -1.82\n",
      "    12.62            9.76\n",
      "    60.49           51.79\n",
      "    18.75           15.08\n",
      "    -14.12          -12.98\n",
      "    -2.21           -3.15\n",
      "    33.50           27.96\n",
      "    -5.43           -5.57\n",
      "    52.42           44.73\n",
      "    7.79            4.78\n",
      "    -38.97          -33.43\n",
      "    14.42           11.41\n",
      "    19.32           15.48\n",
      "    -20.28          -18.60\n",
      "    38.32           32.21\n",
      "    28.00           23.15\n",
      "    3.97            2.32\n",
      "    7.62            5.31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    13.12           10.20\n",
      "    -70.48          -58.22\n",
      "    42.77           36.25\n",
      "    18.53           15.00\n",
      "    -18.17          -16.40\n",
      "    94.55           82.96\n",
      "    12.27            9.46\n",
      "    -15.63          -14.23\n",
      "    35.45           29.75\n",
      "    -27.61          -24.14\n",
      "    -7.09           -7.05\n",
      "    -26.67          -23.91\n",
      "    -2.70           -3.63\n",
      "    7.89            3.57\n",
      "    17.42           13.70\n",
      "    6.89            4.94\n",
      "    -30.67          -26.55\n",
      "    -6.67           -6.44\n",
      "    5.23            3.27\n",
      "    56.11           48.23\n",
      "    -3.70           -4.31\n",
      "    -16.70          -14.87\n",
      "    -33.85          -28.88\n",
      "    43.85           37.15\n",
      "    3.59            1.62\n",
      "    -5.66           -5.76\n",
      "    -2.56           -3.17\n",
      "    -3.17           -4.75\n",
      "    -67.71          -55.74\n",
      "    25.49           20.95\n",
      "    -19.94          -17.61\n",
      "    66.13           56.82\n",
      "    11.77            8.96\n",
      "    1.17           -0.06\n",
      "    -28.07          -23.73\n",
      "    11.94            9.26\n",
      "    -37.65          -32.30\n",
      "    0.79           -0.91\n",
      "    177.62          157.37\n",
      "    -45.60          -38.44\n",
      "    -27.13          -24.07\n",
      "    2.81            1.44\n",
      "    1.95            0.65\n",
      "    4.92            3.32\n",
      "    -14.81          -13.53\n",
      "    3.75            1.71\n",
      "    0.59           -0.43\n",
      "    5.45            3.64\n",
      "    -6.81           -6.67\n",
      "    39.05           32.84\n",
      "    0.51           -0.63\n",
      "    17.28           13.83\n",
      "    47.65           40.56\n",
      "    3.17            1.12\n",
      "    -15.35          -13.78\n",
      "    50.76           43.16\n",
      "    -15.20          -13.98\n",
      "    17.56           14.12\n",
      "    16.66           13.26\n",
      "    -48.95          -40.90\n",
      "    16.87           13.49\n",
      "    -27.29          -23.56\n",
      "    33.07           27.62\n",
      "    12.66            9.82\n",
      "    -21.09          -18.69\n",
      "    2.65            0.98\n",
      "    43.12           36.30\n",
      "    6.48            4.51\n",
      "    -3.06           -3.58\n",
      "    16.45           13.10\n",
      "    13.58           10.62\n",
      "    -2.67           -4.49\n",
      "    67.37           57.90\n",
      "    48.59           41.20\n",
      "    2.30           -0.49\n",
      "    44.71           37.85\n",
      "    -47.93          -40.51\n",
      "    34.14           28.45\n",
      "    3.50            1.97\n",
      "    12.77           10.05\n",
      "    1.78           -1.15\n",
      "    10.86            8.19\n",
      "    5.16            2.88\n",
      "    207.77          184.82\n",
      "    -62.69          -51.92\n",
      "    9.30            6.85\n",
      "    40.09           33.80\n",
      "    139.26          122.47\n",
      "    6.38            4.08\n",
      "    -39.85          -33.11\n",
      "    7.58            5.52\n",
      "    -7.38           -8.02\n",
      "    12.39            9.59\n",
      "    3.92            2.19\n",
      "    30.57           25.42\n",
      "    0.07           -0.97\n",
      "    14.26           11.24\n",
      "    -16.67          -14.97\n",
      "    -13.26          -12.28\n",
      "    15.87           11.76\n",
      "    5.15            3.43\n",
      "    3.34            1.71\n",
      "    -7.69           -7.44\n",
      "    -27.46          -23.79\n",
      "    -4.90           -5.18\n",
      "    2.81            1.49\n",
      "    -0.57           -1.46\n",
      "    2.70            1.25\n",
      "    21.06           17.08\n",
      "    6.24            4.13\n",
      "    -39.50          -33.69\n",
      "    -2.14           -2.84\n",
      "    30.82           25.32\n",
      "    -4.49           -4.83\n",
      "    -5.03           -5.19\n",
      "    -20.04          -17.87\n",
      "    8.81            6.42\n",
      "    -36.60          -31.44\n",
      "    6.53            4.56\n",
      "    70.03           60.26\n",
      "    -1.67           -2.34\n",
      "    -25.20          -22.11\n",
      "    464.36          424.59\n",
      "    -0.22           -1.25\n",
      "    -14.04          -12.83\n",
      "    -0.14            0.32\n",
      "    -0.57           -1.48\n",
      "    5.59            2.89\n",
      "    -23.13          -20.40\n",
      "    61.07           52.29\n",
      "    7.51            6.14\n",
      "    -45.15          -38.09\n",
      "    -11.84          -11.03\n",
      "    -39.60          -33.74\n",
      "    -32.73          -28.29\n",
      "    19.88           15.91\n",
      "    -2.86           -3.40\n",
      "    -25.60          -22.23\n",
      "    -51.16          -43.14\n",
      "    -13.34          -12.28\n",
      "    -8.55           -8.35\n",
      "    -1.96           -2.62\n",
      "    3.13            1.85\n",
      "    13.58           10.74\n",
      "    -9.37           -9.84\n",
      "    17.80           14.26\n",
      "    0.12           -0.93\n",
      "    -7.27           -7.22\n",
      "    -17.13          -15.43\n",
      "    45.09           38.19\n",
      "    30.44           23.81\n",
      "    -11.23          -10.34\n",
      "    3.38           -2.08\n",
      "    -6.73           -5.84\n",
      "    -34.04          -29.35\n",
      "    31.82           26.38\n",
      "    8.42            6.36\n",
      "    5.57            6.20\n",
      "    -15.37          -14.08\n",
      "    -2.47           -3.03\n",
      "    36.38           30.57\n",
      "    -34.07          -29.08\n",
      "    -2.03           -2.67\n",
      "    5.24            3.02\n",
      "    3.33            1.78\n",
      "    -32.58          -28.17\n",
      "    5.42           -1.15\n",
      "    -14.29          -12.84\n",
      "    -44.08          -37.11\n",
      "    -29.78          -25.89\n",
      "    -68.82          -56.47\n",
      "    213.10          189.50\n",
      "    4.57            2.89\n",
      "    -3.32           -3.65\n",
      "    3.72            2.16\n",
      "    26.05           21.49\n",
      "    -35.65          -30.61\n",
      "    -9.01           -8.97\n",
      "    25.50           21.18\n",
      "    32.40            3.08\n",
      "    -10.69          -10.12\n",
      "    -7.17           -7.13\n",
      "    17.91           14.65\n",
      "    13.91           10.91\n",
      "    -2.46           -3.23\n",
      "    6.28            4.29\n",
      "    -28.13          -24.54\n",
      "    -5.00           -5.21\n",
      "    -9.41           -8.66\n",
      "    5.59            3.79\n",
      "    -32.43          -27.86\n",
      "    -23.87          -20.88\n",
      "    -15.83          -14.42\n",
      "    -15.00          -13.64\n",
      "    -26.96          -23.57\n",
      "    -15.93          -14.44\n",
      "    -0.54           -1.78\n",
      "    -18.73          -16.79\n",
      "    -2.58           -3.27\n",
      "    1.69            0.37\n",
      "    0.80            0.75\n",
      "    29.43           24.52\n",
      "    49.06           41.83\n",
      "    -41.67          -35.40\n",
      "    28.32           23.51\n",
      "    41.94           36.68\n",
      "    -21.65          -19.08\n",
      "    7.83            5.57\n",
      "    -5.84           -5.92\n",
      "    -42.38          -35.99\n",
      "    7.61            5.46\n",
      "    -22.40          -19.83\n",
      "    -13.33          -12.02\n",
      "    29.76           24.71\n",
      "    2.75            1.05\n",
      "    -41.39          -35.12\n",
      "    25.86           21.32\n",
      "    -37.31          -31.97\n",
      "    5.19            3.12\n",
      "    -49.98          -41.95\n",
      "    -0.22           -1.58\n",
      "    -33.21          -28.71\n",
      "    -1.95            6.39\n",
      "    47.33           40.15\n",
      "    -16.15          -14.46\n",
      "    13.91           10.91\n",
      "    23.08           18.62\n",
      "    -37.67          -32.24\n",
      "    -0.16           -1.21\n",
      "    7.15            4.36\n",
      "    42.62           35.85\n",
      "    -46.72          -39.64\n",
      "    -1.41           -2.85\n",
      "    -19.78          -15.26\n",
      "    11.14            8.71\n",
      "    5.26            3.46\n",
      "    71.21           61.28\n",
      "    19.80           15.65\n",
      "    -0.81           -1.71\n",
      "    -18.77          -16.44\n",
      "    -35.17          -30.43\n",
      "    37.10           31.12\n",
      "    -4.85           -5.12\n",
      "    22.16           18.13\n",
      "    -18.83          -16.84\n",
      "    8.30           17.51\n",
      "    5.11            3.24\n",
      "    389.30          353.08\n",
      "    -1.17           -2.14\n",
      "    1.71            0.39\n",
      "    18.53           14.77\n",
      "    4.12            2.50\n",
      "    27.76           22.98\n",
      "    -36.34          -30.85\n",
      "    10.55            7.96\n",
      "    -13.16          -12.02\n",
      "    2.24            0.94\n",
      "    -6.68           -6.71\n",
      "    2.11            0.75\n",
      "    -4.19           -4.80\n",
      "    13.68           10.76\n",
      "    7.90            5.17\n",
      "    -23.17          -20.42\n",
      "    -3.70           -3.98\n",
      "    -0.95           -1.93\n",
      "    15.00           11.84\n",
      "    -2.06           -2.83\n",
      "    4.47            2.58\n",
      "    14.09           11.20\n",
      "    38.21           32.24\n",
      "    24.79           20.48\n",
      "    -55.66          -46.44\n",
      "    22.76           18.54\n",
      "    4.19            2.54\n",
      "    -42.90          -36.54\n",
      "    -8.15           -8.09\n",
      "    16.85           13.42\n",
      "    33.95           30.82\n",
      "    -14.96          -13.11\n",
      "    85.20           73.84\n",
      "    -25.06          -21.69\n",
      "    -17.26          -15.57\n",
      "    -41.03          -35.04\n",
      "    -56.66          -47.34\n",
      "    23.78           19.69\n",
      "    -30.82          -26.66\n",
      "    -19.02          -17.10\n",
      "    138.64          122.12\n",
      "    20.25           16.50\n",
      "    -2.50           -3.18\n",
      "    6.54            4.98\n",
      "    19.45           15.74\n",
      "    -1.69           -2.43\n",
      "    -38.15          -32.91\n",
      "    -9.76           -9.47\n",
      "    18.47           11.17\n",
      "    -41.18          -34.89\n",
      "    33.33           27.84\n",
      "    -9.95           -9.24\n",
      "    13.47           10.59\n",
      "    -60.59          -50.23\n",
      "    -9.64           -9.04\n",
      "    -60.78          -50.43\n",
      "    -38.84          -33.15\n",
      "    6.20            4.30\n",
      "    -31.76          -27.53\n",
      "    19.81           16.34\n",
      "    23.47           28.18\n",
      "    10.49            7.94\n",
      "    16.18           12.92\n",
      "    5.11            3.40\n",
      "    11.44            8.69\n",
      "    -23.29          -20.45\n",
      "    -33.81          -29.03\n",
      "    -5.16           -5.43\n",
      "    -2.46           -3.15\n",
      "    -8.90           -8.39\n",
      "    -12.98          -11.95\n",
      "    12.84            9.88\n",
      "    2.60            1.16\n",
      "    -10.06           -9.42\n",
      "    2.72            1.24\n",
      "    12.82           10.00\n",
      "    3.17            1.28\n",
      "    1.29           -0.88\n",
      "    -3.00           -4.72\n",
      "    2.54            1.09\n",
      "    25.49           20.62\n",
      "    -55.52          -46.40\n",
      "    5.78            3.40\n",
      "    24.65           20.11\n",
      "    -10.79          -15.63\n",
      "    -0.50           -1.46\n",
      "    -39.93          -32.85\n",
      "    -21.92          -19.39\n",
      "    1.40           -0.15\n",
      "    -2.75           -3.33\n",
      "    -8.37           -8.04\n",
      "    3.06            1.55\n",
      "    58.28           49.78\n",
      "    -1.16           -2.02\n",
      "    -3.97           -5.51\n",
      "    15.93           12.64\n",
      "    -10.94          -10.49\n",
      "    46.57           39.00\n",
      "    -0.68           -1.19\n",
      "    12.51            9.89\n",
      "    -18.95          -16.90\n",
      "    14.49           11.65\n",
      "    6.02            4.14\n",
      "    12.62            9.94\n",
      "    13.34           10.40\n",
      "    -20.31          -18.11\n",
      "    3.13            1.63\n",
      "    -27.78          -24.13\n",
      "    17.22           13.80\n",
      "    5.85            4.50\n",
      "    0.13           -0.96\n",
      "    -25.92          -22.57\n",
      "    -13.04          -11.86\n",
      "    3.24            1.72\n",
      "    88.74           76.93\n",
      "    7.98            8.42\n",
      "    1.08           -0.00\n",
      "    7.89            5.70\n",
      "    -37.31          -31.95\n",
      "    -19.82          -17.85\n",
      "    10.87            8.24\n",
      "    17.85           14.21\n",
      "    38.66           32.63\n",
      "    -7.92           -7.79\n",
      "    13.03           13.23\n",
      "    -59.44          -49.22\n",
      "    14.67           11.66\n",
      "    16.15           13.21\n",
      "    3.80            2.07\n",
      "    -58.74          -49.03\n",
      "    11.16            8.50\n",
      "    20.76           16.82\n",
      "    4.54            1.73\n",
      "    9.55            7.30\n",
      "    -4.42           -4.83\n",
      "    7.06            5.20\n",
      "    -9.47           -8.97\n",
      "    -5.93           -6.18\n",
      "    17.27           14.02\n",
      "    25.70           21.22\n",
      "    6.79            4.79\n",
      "    10.54            7.98\n",
      "    -4.00           -5.51\n",
      "    9.45            6.78\n",
      "    -12.35          -11.46\n",
      "    -15.92          -12.07\n",
      "    -39.61          -33.93\n",
      "    2.29            0.91\n",
      "    -54.51          -45.70\n",
      "    -1.49           -2.30\n",
      "    -28.89          -25.20\n",
      "    54.30           46.37\n",
      "    61.01           52.39\n",
      "    39.46           33.25\n",
      "    16.73           13.45\n",
      "    -31.07          -26.82\n",
      "    15.67           12.43\n",
      "    3.27            1.73\n",
      "    -9.67           -7.35\n",
      "    -13.63          -12.44\n",
      "    -21.35          -18.82\n",
      "    -23.81          -21.01\n",
      "    12.61            9.73\n",
      "    44.58           37.76\n",
      "    6.66            5.26\n",
      "    19.33           15.61\n",
      "    -11.08          -10.21\n",
      "    -26.80          -23.41\n",
      "    6.38            4.69\n",
      "    4.07            2.37\n",
      "    -11.91          -11.20\n",
      "    -0.41           -1.39\n",
      "    4.62            2.78\n",
      "    44.09           37.34\n",
      "    7.26            5.16\n",
      "    -9.86           -9.35\n",
      "    -28.15          -24.34\n",
      "    1.39            0.16\n",
      "    60.00           51.68\n",
      "    -23.35          -13.98\n",
      "    14.89           11.67\n",
      "    -48.16          -40.62\n",
      "    15.54           12.51\n",
      "    -19.31          -16.91\n",
      "    8.60            6.39\n",
      "    -14.75          -12.65\n",
      "    -1.52           -2.33\n",
      "    -0.83            1.75\n",
      "    53.81           46.36\n",
      "    17.98           18.92\n",
      "    26.77           22.10\n",
      "    68.11           58.34\n",
      "    -9.17           -8.69\n",
      "    3.08            1.72\n",
      "    0.68           -0.41\n",
      "    2.11            0.74\n",
      "    -26.83          -23.34\n",
      "    36.60           30.74\n",
      "    -0.36           -0.14\n",
      "    15.38            7.80\n",
      "    -4.71           -6.87\n",
      "    -10.02           -8.55\n",
      "    -34.07          -29.30\n",
      "    -13.01          -11.96\n",
      "    -26.18          -22.69\n",
      "    -3.59           -4.07\n",
      "    29.49           24.44\n",
      "    -20.31          -17.32\n",
      "    -31.03          -26.87\n",
      "    -35.62          -30.55\n",
      "    0.96           -0.25\n",
      "    11.54            8.64\n",
      "    11.74            9.04\n",
      "    -20.85          -18.53\n",
      "    117.58          102.80\n",
      "    5.30            1.51\n",
      "    -32.73          -28.12\n",
      "    40.18           33.86\n",
      "    -12.05          -11.17\n",
      "    24.04          -29.55\n",
      "    -24.49          -21.44\n",
      "    -6.03           -6.12\n",
      "    3.85            2.35\n",
      "    5.70            3.56\n",
      "    -9.88           -9.68\n",
      "    -5.80           -5.95\n",
      "    -8.16           -7.74\n",
      "    -8.46          -34.35\n",
      "    -2.06           -2.83\n",
      "    2.69            1.38\n",
      "    26.92           22.20\n",
      "    -19.24          -17.21\n",
      "    -61.21          -50.74\n",
      "    2.53           -0.24\n",
      "    19.99           16.17\n",
      "    7.21            5.30\n",
      "    -11.58          -10.82\n",
      "    -68.63          -57.14\n",
      "    -1.74           -2.45\n",
      "    -4.42           -4.67\n",
      "    46.24           39.10\n",
      "    -24.24          -21.07\n",
      "    -6.33           -6.41\n",
      "    -15.55          -16.57\n",
      "    5.07            3.40\n",
      "    16.53           13.28\n",
      "    9.80            7.42\n",
      "    3.41            1.89\n",
      "    3.02            1.52\n",
      "    -25.10          -22.04\n",
      "    16.50           -6.49\n",
      "    -23.20          -20.49\n",
      "    -0.55           -1.72\n",
      "    -26.41          -23.06\n",
      "    -4.41           -5.45\n",
      "    4.52            2.83\n",
      "    59.63           50.99\n",
      "    -53.73          -44.73\n",
      "    -12.04           -6.93\n",
      "    -4.89           -5.16\n",
      "    -7.69           -7.34\n",
      "    11.56            8.94\n",
      "    32.90           27.48\n",
      "    -62.22          -51.81\n",
      "    6.68            4.55\n",
      "    -7.64           -7.55\n",
      "    -18.90          -16.71\n",
      "    -0.32           -1.38\n",
      "    -7.27           -7.07\n",
      "    53.60           45.61\n",
      "    -0.87           -1.80\n",
      "    -50.84          -42.77\n",
      "    -7.63           -7.37\n",
      "    -16.00          -14.53\n",
      "    13.53           10.55\n",
      "    10.24            8.03\n",
      "    -5.63           -5.63\n",
      "    -4.98           -5.34\n",
      "    18.81           15.19\n",
      "    -0.60           -1.12\n",
      "    23.50           19.43\n",
      "    -5.02           -5.30\n",
      "    -42.98          -36.49\n",
      "    -23.81          -20.93\n",
      "    -48.66          -41.13\n",
      "    3.62            2.73\n",
      "    -45.05          -37.73\n",
      "    44.00           37.21\n",
      "    12.11            9.26\n",
      "    -16.20          -14.70\n",
      "    -28.57          -24.90\n",
      "    16.52           13.12\n",
      "    -53.44          -44.56\n",
      "    8.57            6.28\n",
      "    -10.47           -9.87\n",
      "    -0.31           -1.29\n",
      "    -5.87           -6.08\n",
      "    -13.84          -12.79\n",
      "    9.31            6.80\n",
      "    -44.39          -37.72\n",
      "    -14.56          -12.72\n",
      "    -11.30           -8.72\n",
      "    19.51           15.75\n",
      "    158.59          139.70\n",
      "    -30.43          -26.29\n",
      "    12.78            9.81\n",
      "    9.31            6.98\n",
      "    3.48            1.98\n",
      "    41.98           35.28\n",
      "    13.60           10.63\n",
      "    14.19           11.15\n",
      "    -0.45           -1.39\n",
      "    -72.73          -59.96\n",
      "    94.44           81.99\n",
      "    0.78           -0.38\n",
      "    -2.59           -2.97\n",
      "    19.58           15.98\n",
      "    -34.44          -29.64\n",
      "    23.77           18.82\n",
      "    48.71           41.38\n",
      "    52.98           45.16\n",
      "    -1.61           -3.07\n",
      "    3.46            1.95\n",
      "    -57.96          -48.42\n",
      "    -3.93           -4.38\n",
      "    -1.53           -2.09\n",
      "    -31.45          -27.28\n",
      "    21.03           17.09\n",
      "    -6.85           -7.38\n",
      "    20.79           16.87\n",
      "    18.77           15.26\n",
      "    0.99           -0.73\n",
      "    -0.88           -2.64\n",
      "    -23.36          -21.53\n",
      "    2.71            1.16\n",
      "    15.10           11.99\n",
      "    7.89            5.68\n",
      "    -13.84          -12.73\n",
      "    -3.68           -4.24\n",
      "    -77.01          -63.03\n",
      "    2.17            1.21\n",
      "    -23.11          -20.42\n",
      "    32.96           26.95\n",
      "    -18.35          -16.98\n",
      "    1.60            0.42\n",
      "    -32.98          -28.47\n",
      "    7.51            5.24\n",
      "    10.33          -41.66\n",
      "    34.62           29.07\n",
      "    -8.11           -7.83\n",
      "    10.10            7.57\n",
      "    -8.76           -8.57\n",
      "    51.68           43.98\n",
      "    11.24            8.76\n",
      "    -27.29          -23.91\n",
      "    -29.72          -25.65\n",
      "    -12.12            1.25\n",
      "    -3.75           -4.28\n",
      "    36.33           30.70\n",
      "    31.96           26.61\n",
      "    22.44           11.91\n",
      "    -4.92           -5.28\n",
      "    11.98            9.27\n",
      "    -1.89           -2.07\n",
      "    -3.10           -3.26\n",
      "    -21.40          -19.00\n",
      "    24.55           20.10\n",
      "    -4.56           -5.05\n",
      "    0.56           -0.45\n",
      "    -0.21           -1.24\n",
      "    -8.79           -8.38\n",
      "    -20.36          -17.99\n",
      "    5.00            3.21\n",
      "    16.72           13.44\n",
      "    15.35           12.65\n",
      "    81.33           70.39\n",
      "    -19.03          -17.15\n",
      "    -4.38           -4.77\n",
      "    4.56            3.06\n",
      "    -7.18           -7.07\n",
      "    -6.79           -6.63\n",
      "    17.24           13.67\n",
      "    -31.12          -27.02\n",
      "    -4.49           -4.93\n",
      "    0.26           -0.79\n",
      "    1.38            0.13\n",
      "    13.55           10.56\n",
      "    -10.16          -10.07\n",
      "    16.91           13.18\n",
      "    1.16           -0.29\n",
      "    18.11           14.43\n",
      "    2.27            1.00\n",
      "    34.12           28.58\n",
      "    -65.16          -53.83\n",
      "    -4.90           -5.21\n",
      "    10.18            7.67\n",
      "    623.19          593.23\n",
      "    -67.65          -55.34\n",
      "    82.03           71.13\n",
      "    22.21           17.98\n",
      "    -8.03           -7.84\n",
      "    -8.30           -9.53\n",
      "    -21.38          -19.01\n",
      "    1.30            0.15\n",
      "    -0.90           -2.24\n",
      "    -2.51           -3.08\n",
      "    -17.65          -15.89\n",
      "    34.65           28.99\n",
      "    -16.21          -14.70\n",
      "    -25.51          -22.30\n",
      "    -7.50           -7.19\n",
      "    7.14            5.07\n",
      "    -8.55           -8.27\n",
      "    -21.68          -19.74\n",
      "    44.69           37.88\n",
      "    -5.97           -5.90\n",
      "    4.05           -2.08\n",
      "    -14.21          -13.03\n",
      "    10.75            7.74\n",
      "    0.50           -0.47\n",
      "    -49.75          -41.72\n",
      "    20.22           16.40\n",
      "    68.28           58.80\n",
      "    4.08            2.52\n",
      "    0.53           -0.53\n",
      "    2.25            0.84\n",
      "    -48.07          -40.58\n",
      "    -45.46          -38.64\n",
      "    -11.17          -10.51\n",
      "    0.08           -1.22\n",
      "    7.45            5.63\n",
      "    9.33            7.24\n",
      "    -30.23          -26.02\n",
      "    92.48           80.23\n",
      "    42.72           35.78\n",
      "    -40.52          -34.52\n",
      "    -12.38          -12.30\n",
      "    -0.12           -1.73\n",
      "    0.21           -0.86\n",
      "    35.07           29.28\n",
      "    -8.99           -8.65\n",
      "    -3.23           -3.50\n",
      "    5.07            3.25\n",
      "    8.53            6.24\n",
      "    1568.83         1542.59\n",
      "    18.61           14.95\n",
      "    0.33           -0.77\n",
      "    1.96            0.60\n",
      "    37.04           30.84\n",
      "    -25.94          -22.55\n",
      "    -14.23          -12.73\n",
      "    2.32            0.97\n",
      "    8.62            6.25\n",
      "    20.18           16.31\n",
      "    -1.55           -2.26\n",
      "    -37.50          -32.20\n",
      "    31.14           25.88\n",
      "    -7.71           -6.73\n",
      "    14.68           11.58\n",
      "    12.29            9.45\n",
      "    -13.45          -12.33\n",
      "    3.77            0.14\n",
      "    7.63            5.47\n",
      "    16.10            6.76\n",
      "    12.60            9.87\n",
      "    -4.67           -5.00\n",
      "    2.05            0.31\n",
      "    -3.81           -4.22\n",
      "    15.08           11.93\n",
      "    151.27          132.95\n",
      "    8.54            5.84\n",
      "    57.79           49.38\n",
      "    -31.09          -26.70\n",
      "    -1.02           -1.86\n",
      "    37.65           31.62\n",
      "    -19.51          -17.12\n",
      "    -10.04           -6.66\n",
      "    -40.22          -34.23\n",
      "    -22.29          -19.73\n",
      "    -20.63          -18.41\n",
      "    5.02            3.24\n",
      "    -18.53          -16.62\n",
      "    -20.83          -18.57\n",
      "    -15.32          -13.92\n",
      "    13.03           10.24\n",
      "    0.03           -1.04\n",
      "    -54.79          -45.52\n",
      "    25.33           21.10\n",
      "    5.42            3.64\n",
      "    -10.15           -9.63\n",
      "    -10.87          -10.19\n",
      "    -29.46          -25.39\n",
      "    25.82           20.99\n",
      "    3.06            0.52\n",
      "    -1.08           -1.93\n",
      "    -0.18           -1.30\n",
      "    -5.79           -5.92\n",
      "    -35.03          -30.09\n",
      "    1.03           -0.02\n",
      "    -10.47          -10.01\n",
      "    85.56           74.16\n",
      "    -38.96          -33.31\n",
      "    -22.78          -20.03\n",
      "    -6.47           -6.43\n",
      "    44.11           37.34\n",
      "    15.98           11.49\n",
      "    46.29           39.19\n",
      "    1.81            0.21\n",
      "    6.40            1.70\n",
      "    1.49            0.14\n",
      "    -6.36           -7.16\n",
      "    -2.91          -33.62\n",
      "    9.10            6.73\n",
      "    -7.43           -7.32\n",
      "    14.60           11.22\n",
      "    14.84           11.70\n",
      "    -16.53          -16.08\n",
      "    29.82           24.81\n",
      "    63.52           54.63\n",
      "    -12.17          -11.33\n",
      "    -10.19           -9.67\n",
      "    59.09           50.58\n",
      "    -7.57           -7.41\n",
      "    7.61            5.51\n",
      "    -14.48          -13.23\n",
      "    -1.03           -1.82\n",
      "    13.49           10.53\n",
      "    -13.56          -12.51\n",
      "    -6.38           -6.44\n",
      "    5.99          -11.29\n",
      "    19.24           16.14\n",
      "    5.56            3.70\n",
      "    -8.76           -8.33\n",
      "    -6.05           -6.26\n",
      "    3.08            1.51\n",
      "    -2.45           -3.35\n",
      "    93.65           81.33\n",
      "    57.54           49.40\n",
      "    23.79           19.43\n",
      "    4.94            3.22\n",
      "    3.60            1.96\n",
      "    13.13           15.89\n",
      "    -20.40          -18.03\n",
      "    10.56            8.18\n",
      "    24.55           20.00\n",
      "    -32.73          -28.29\n",
      "    -12.04          -11.23\n",
      "    -7.08           -7.36\n",
      "    -9.73           -9.20\n",
      "    2.18            0.86\n",
      "    -22.29          -19.48\n",
      "    -6.17           -6.16\n",
      "    43.14           36.44\n",
      "    -49.16          -41.48\n",
      "    -2.59           -3.89\n",
      "    -8.60           -8.30\n",
      "    11.45            8.80\n",
      "    1.69            0.51\n",
      "    -9.51           -9.09\n",
      "    -21.72          -19.36\n",
      "    -1.92           -2.31\n",
      "    16.60           13.28\n",
      "    2.28            1.25\n",
      "    19.01           15.31\n",
      "    -46.45          -39.35\n",
      "    77.81           67.17\n",
      "    2.27            0.86\n",
      "    -33.77          -27.15\n",
      "    -0.53           -1.69\n",
      "    -2.60           -3.25\n",
      "    -18.33          -16.29\n",
      "    -15.34          -13.91\n",
      "    -47.74          -40.48\n",
      "    5.37            3.47\n",
      "    -2.81           -3.44\n",
      "    -21.99          -13.61\n",
      "    5.97            1.15\n",
      "    -0.35           -1.40\n",
      "    69.73           59.93\n",
      "    -28.38          -24.50\n",
      "    283.57          254.76\n",
      "    -18.20          -16.32\n",
      "    1.89           -0.52\n",
      "    -44.59          -37.65\n",
      "    -32.09          -27.66\n",
      "    3.65            1.08\n",
      "    39.97           33.64\n",
      "    -6.47           -6.49\n",
      "    -40.80          -34.86\n",
      "    -25.96          -22.70\n",
      "    -5.78           -6.00\n",
      "    -18.29          -16.21\n",
      "    37.14           31.15\n",
      "    -29.44          -25.60\n",
      "    4.85            3.11\n",
      "    2.07            1.08\n",
      "    134.04          117.68\n",
      "    -6.78           -6.80\n",
      "    31.13           25.89\n",
      "    -33.70          -29.16\n",
      "    2.59            1.12\n",
      "    911.76          912.14\n",
      "    8.47            6.28\n",
      "    59.01           50.52\n",
      "    -0.14           24.05\n",
      "    9.91           14.20\n",
      "    -16.63          -15.46\n",
      "    7.41            5.25\n",
      "    -38.53          -33.00\n",
      "    -6.92           -8.46\n",
      "    62.23           53.30\n",
      "    37.27           31.44\n",
      "    -29.37          -31.27\n",
      "    48.18           40.94\n",
      "    -2.44           -2.86\n",
      "    29.79           24.73\n",
      "    -13.77          -12.68\n",
      "    -11.30          -10.54\n",
      "    4.44            2.73\n",
      "    21.79           17.77\n",
      "    -13.61          -12.51\n",
      "    5.79            3.98\n",
      "    20.21           16.27\n",
      "    -20.17          -17.99\n",
      "    31.15           25.94\n",
      "    60.72           52.09\n",
      "    -6.65           -6.62\n",
      "    10.77            8.09\n",
      "    -3.71           -4.22\n",
      "    -1.17           -1.71\n",
      "    72.22           62.03\n",
      "    -6.45           -9.12\n",
      "    1.02           -1.60\n",
      "    -2.71           -2.79\n",
      "    -21.40          -18.82\n",
      "    2.93            1.29\n",
      "    -11.07          -12.34\n",
      "    9.25            6.55\n",
      "    -14.19          -12.98\n",
      "    -23.00          -20.30\n",
      "    2.39            1.05\n",
      "    27.69           22.99\n",
      "    -13.79          -12.63\n",
      "    -43.79          -36.90\n",
      "    -4.22           -4.56\n",
      "    1.01            0.07\n",
      "    -20.39          -17.95\n",
      "    -39.42          -33.52\n",
      "    17.11           15.26\n",
      "    -3.21           -3.70\n",
      "    -23.29          -20.17\n",
      "    -20.47          -18.20\n",
      "    14.99           11.80\n",
      "    -5.20           -5.47\n",
      "    5.73            3.81\n",
      "    -45.35          -38.25\n",
      "    0.78            0.03\n",
      "    -8.13           -8.25\n",
      "    10.09            7.65\n",
      "    13.96           10.96\n",
      "    38.37           32.19\n",
      "    13.53           10.36\n",
      "    17.26           17.72\n",
      "    50.00           42.31\n",
      "    7.01            9.04\n",
      "    47.93           40.73\n",
      "    -26.03          -22.81\n",
      "    8.80            6.61\n",
      "    -2.66           -3.30\n",
      "    -35.96          -30.95\n",
      "    -9.71           -9.27\n",
      "    17.44           13.92\n",
      "    -17.75          -15.87\n",
      "    36.77           30.99\n",
      "    1.14           -0.06\n",
      "    -32.50          -28.08\n",
      "    11.90            9.16\n",
      "    1.19            0.02\n",
      "    -35.71          -30.72\n",
      "    -9.24           -8.83\n",
      "    -14.61          -13.34\n",
      "    -23.20          -20.47\n",
      "    8.56            6.30\n",
      "    6.53            4.57\n",
      "    -9.41           -8.88\n",
      "    18.11           14.36\n",
      "    -8.46           -8.03\n",
      "    -30.97          -26.92\n",
      "    27.04           21.97\n",
      "    27.36           22.61\n",
      "    13.82           72.12\n",
      "    9.03            6.65\n",
      "    -16.23          -14.60\n",
      "    -26.25          -23.00\n",
      "    -3.17           -3.89\n",
      "    35.13           29.43\n",
      "    10.45            7.96\n",
      "    6.44            4.48\n",
      "    -24.51          -21.58\n",
      "    -21.26          -18.83\n",
      "    -1.19           -2.05\n",
      "    9.76            7.43\n",
      "    16.44           13.10\n",
      "    -20.07          -17.57\n",
      "    6.23            4.07\n",
      "    -26.73          -23.20\n",
      "    1714.59         1679.74\n",
      "    -36.43          -30.99\n",
      "    22.12           18.10\n",
      "    15.63           12.36\n",
      "    15.09           11.99\n",
      "    -11.42          -10.63\n",
      "    -7.60           -7.44\n",
      "    -12.30          -11.33\n",
      "    138.91          121.95\n",
      "    -17.02          -15.09\n",
      "    7.18            4.65\n",
      "    -49.28          -41.57\n",
      "    -26.58          -23.36\n",
      "    3.32            1.83\n",
      "    -12.41          -11.37\n",
      "    -10.36           -9.90\n",
      "    9.00            6.70\n",
      "    -33.02          -27.38\n",
      "    5.31            3.56\n",
      "    -0.19           -1.19\n",
      "    -30.25          -26.22\n",
      "    -27.19          -23.97\n",
      "    -3.61           -3.99\n",
      "    0.70           -0.27\n",
      "    -35.43          -30.49\n",
      "    -34.59          -29.55\n",
      "    -8.48           -8.16\n",
      "    6.59            4.04\n",
      "    -0.17           -1.30\n",
      "    -22.44          -19.73\n",
      "    -8.32           -8.12\n",
      "    2.58            1.09\n",
      "    -16.85          -15.21\n",
      "    -4.06           -4.37\n",
      "    -36.02          -30.85\n",
      "    75.90           65.47\n",
      "    -1.79           -2.59\n",
      "    -40.71          -34.42\n",
      "    57.59           49.24\n",
      "    0.72            4.33\n",
      "    40.20           33.88\n",
      "    11.96            9.32\n",
      "    4.61            2.95\n",
      "    -26.29          -23.04\n",
      "    13.93           10.95\n",
      "    4.00            2.51\n",
      "    19.12           15.44\n",
      "    -14.47          -13.31\n",
      "    -1.33           -2.17\n",
      "    -2.53           -3.05\n",
      "    17.95           14.41\n",
      "    -19.59          -17.34\n",
      "    88.37           76.58\n",
      "    -9.72           -9.28\n",
      "    -46.08          -38.96\n",
      "    -29.63          -25.74\n",
      "    2.05            0.68\n",
      "    17.29           13.98\n",
      "    -3.99           -4.48\n",
      "    1.26            0.09\n",
      "    8.39            6.13\n",
      "    -46.91          -39.75\n",
      "    17.56           14.11\n",
      "    -25.03          -21.94\n",
      "    27.72           23.00\n",
      "    -13.68          -12.47\n",
      "    4.29            2.87\n",
      "    0.04           -0.90\n",
      "    -1.45           -2.14\n",
      "    20.32           16.45\n",
      "    -0.31           -1.26\n",
      "    -8.37           -7.97\n",
      "    21150.00        24881.50\n",
      "    1501.42         1485.68\n",
      "    11.40            8.70\n",
      "    -9.18           -8.66\n",
      "    -69.52          -57.45\n",
      "    -15.08          -13.70\n",
      "    4.96            3.21\n",
      "    -18.40          -16.57\n",
      "    9.78            7.37\n",
      "    -33.49          -28.68\n",
      "    20.86           16.83\n",
      "    -6.94           -7.11\n",
      "    1.00           -0.18\n",
      "    0.91           -0.94\n",
      "    -1.98           -3.21\n",
      "    -8.33           -8.10\n",
      "    0.06           -0.54\n",
      "    11.84            8.72\n",
      "    -3.38           -3.89\n",
      "    -0.52           -1.54\n",
      "    -18.68          -16.70\n",
      "    27.90           23.11\n",
      "    31.67           26.36\n",
      "    49.05           41.69\n",
      "    33.60           27.22\n",
      "    4.87           12.26\n",
      "    8.09            5.99\n",
      "    -37.47          -31.45\n",
      "    27.87           22.19\n",
      "    -8.86           -8.56\n",
      "    -24.26          -21.37\n",
      "    16.35           13.08\n",
      "    24.56           20.80\n",
      "    -23.85          -21.09\n",
      "    13.73           10.68\n",
      "    -4.08           -4.52\n",
      "    -36.84          -31.35\n",
      "    -1.49           -2.22\n",
      "    -8.81           -8.36\n",
      "    11.54            9.07\n",
      "    12.11            9.14\n",
      "    -8.95           -2.78\n",
      "    27.40           22.71\n",
      "    3.16            1.66\n",
      "    -24.11          -21.04\n",
      "    0.14           -2.64\n",
      "    9.25            6.95\n",
      "    657.92          628.51\n",
      "    5.23            3.44\n",
      "    133.28          117.06\n",
      "    -48.83          -41.60\n",
      "    -26.20          -22.85\n",
      "    91.14           79.19\n",
      "    1.40            0.33\n",
      "    -1.57           -2.39\n",
      "    -18.67          -16.79\n",
      "    4.68            3.53\n",
      "    -42.55          -35.76\n",
      "    39.80           33.55\n",
      "    -48.09          -40.63\n",
      "    -16.88          -14.67\n",
      "    37.15           31.18\n",
      "    16.15            5.29\n",
      "    2.36            1.11\n",
      "    -28.84          -24.90\n",
      "    -21.89          -19.06\n",
      "    20.42           16.59\n",
      "    53.72           46.02\n",
      "    27.72           23.03\n",
      "    294.69          264.90\n",
      "    -7.57           -7.35\n",
      "    -5.84           -6.01\n",
      "    -12.83          -11.72\n",
      "    36.89           31.37\n",
      "    33.79           28.30\n",
      "    -35.96          -30.92\n",
      "    2.54            1.23\n",
      "    -2.11           -2.72\n",
      "    14.15           11.21\n",
      "    -9.89           -9.79\n",
      "    65.94           56.63\n",
      "    -8.27           -7.89\n",
      "    -14.48          -13.27\n",
      "    7.05            5.02\n",
      "    -2.60           -3.48\n",
      "    -18.58          -16.22\n",
      "    2.17           -0.09\n",
      "    38.79           32.64\n",
      "    30.85           25.63\n",
      "    -88.97          -72.31\n",
      "    -13.69          -12.56\n",
      "    -5.27           -4.82\n",
      "    5.96            4.16\n",
      "    -29.58          -25.55\n",
      "    0.65           -0.56\n",
      "    14.80           11.71\n",
      "    -22.49          -19.86\n",
      "    -4.39           -4.78\n",
      "    -15.92          -14.65\n",
      "    7.92            5.38\n",
      "    26.40           21.73\n",
      "    8.45            6.17\n",
      "    -8.30           -7.97\n",
      "    10.97            8.38\n",
      "    -11.42          -10.47\n",
      "    -19.84          -17.22\n",
      "    -43.80          -36.61\n",
      "    -7.62           -7.47\n",
      "    16.38           13.01\n",
      "    1.86            0.60\n",
      "    4.49            2.74\n",
      "    687.13          660.90\n",
      "    6.02            4.24\n",
      "    -13.88          -12.70\n",
      "    -7.81          -10.43\n",
      "    2.99            1.44\n",
      "    -65.98          -54.57\n",
      "    -13.27          -12.25\n",
      "    29.74           24.54\n",
      "    26.70           22.08\n",
      "    8.00            5.69\n",
      "    52.93           45.18\n",
      "    -0.58           -1.61\n",
      "    -0.94           -1.91\n",
      "    -15.04          -13.67\n",
      "    -15.03          -13.69\n",
      "    10.27            7.28\n",
      "    -35.48          -22.17\n",
      "    2.66            1.42\n",
      "    -9.46           -8.84\n",
      "    -17.48          -15.76\n",
      "    -1.97           -2.44\n",
      "    -0.39           -1.40\n",
      "    -8.74           -8.48\n",
      "    -11.93          -11.09\n",
      "    4.17            2.50\n",
      "    11.98            9.30\n",
      "    -5.15           -5.41\n",
      "    -2.75           -3.35\n",
      "    9.95            7.50\n",
      "    33.22           27.76\n",
      "    52.90           45.07\n",
      "    -2.05           -2.83\n",
      "    15.13           11.95\n",
      "    9.98            6.94\n",
      "    69.35           59.53\n",
      "    -62.69          -52.16\n",
      "    2.04            0.65\n",
      "    -15.07          -13.95\n",
      "    -6.22           -6.15\n",
      "    2.19            0.78\n",
      "    -15.33          -13.91\n",
      "    14.46           11.71\n",
      "    1.09           -0.20\n",
      "    24.80           20.35\n",
      "    -31.76          -27.47\n",
      "    -19.03          -11.78\n",
      "    5.45            3.70\n",
      "    8.53            6.22\n",
      "    27.02           23.40\n",
      "    23.10           18.96\n",
      "    -11.53          -10.88\n",
      "    3.92            2.25\n",
      "    -17.49          -16.21\n",
      "    7.04            4.66\n",
      "    9.32            6.82\n",
      "    13.85           10.83\n",
      "    -10.65           -9.89\n",
      "    -14.91          -13.85\n",
      "    -16.38          -14.64\n",
      "    -42.42          -36.15\n",
      "    -5.88           -6.03\n",
      "    -9.63           -9.09\n",
      "    -7.51           -7.37\n",
      "    17.39           14.01\n",
      "    -3.68           -4.16\n",
      "    1.19           -0.00\n",
      "    -6.81           -6.72\n",
      "    -4.47           -4.88\n",
      "    1.18           -0.01\n",
      "    34.11           28.56\n",
      "    -22.01          -19.46\n",
      "    10.30            7.78\n",
      "    -12.33          -11.43\n",
      "    -8.04           -7.67\n",
      "    1.30            0.11\n",
      "    -20.21          -18.02\n",
      "    6.17            4.21\n",
      "    -4.82           -5.91\n",
      "    78.34           67.77\n",
      "    -5.39           -5.70\n",
      "    37.00           30.53\n",
      "    2.65            0.02\n",
      "    27.82           23.06\n",
      "    -2.34           -2.79\n",
      "    -46.50          -39.56\n",
      "    -2.00           -2.76\n",
      "    30.03           25.02\n",
      "    -13.34          -12.20\n",
      "    5.59            3.62\n",
      "    18.33           14.73\n",
      "    20.74           16.93\n",
      "    -17.98          -16.15\n",
      "    -54.02          -49.09\n",
      "    1.68            0.58\n",
      "    -9.63           -8.79\n",
      "    99.00           86.37\n",
      "    -9.27           -8.93\n",
      "    -59.21          -49.08\n",
      "    1.52            0.25\n",
      "    -4.35           -4.76\n",
      "    2.04            0.37\n",
      "    -32.65          -27.92\n",
      "    -16.67          -14.84\n",
      "    18.05           14.54\n",
      "    -8.24           -7.89\n",
      "    -27.11          -42.70\n",
      "    -22.49          -19.68\n",
      "    9.71            7.49\n",
      "    -8.61           -8.36\n",
      "    99.92           86.91\n",
      "    -13.87          -12.84\n",
      "    37.23           31.24\n",
      "    4.57            2.94\n",
      "    8.28            5.96\n",
      "    7.90            5.68\n",
      "    3.41            1.54\n",
      "    9.14            6.69\n",
      "    -8.69           -8.42\n",
      "    22.94           18.73\n",
      "    77.28           66.67\n",
      "    22.14           18.42\n",
      "    23.54           20.03\n",
      "    2.40            0.92\n",
      "    21.10           17.16\n",
      "    0.59           -0.42\n",
      "    -1.17           -1.85\n",
      "    -10.48           -9.88\n",
      "    -16.88          -14.62\n",
      "    -38.55          -32.94\n",
      "    1.45            0.25\n",
      "    -12.94          -11.94\n",
      "    -14.81          -13.39\n",
      "    42.81           36.05\n",
      "    -10.04           -9.39\n",
      "    -73.82          -60.85\n",
      "    11.36            8.73\n",
      "    2.60            1.18\n",
      "    12.99           10.08\n",
      "    5.88            4.04\n",
      "    4.81            3.12\n",
      "    -52.50          -44.08\n",
      "    30.12           25.09\n",
      "    32.94           27.22\n",
      "    -18.16          -16.26\n",
      "    -39.39          -33.72\n",
      "    2.50            0.84\n",
      "    2.20            0.83\n",
      "    8.06            4.27\n",
      "    4.77            3.06\n",
      "    -46.90          -39.62\n",
      "    3.40            4.64\n",
      "    -4.62           -4.25\n",
      "    25.45           20.92\n",
      "    -5.88           -6.01\n",
      "    39.20           32.31\n",
      "    7.43            5.27\n",
      "    -59.31          -49.39\n",
      "    17.92           13.90\n",
      "    -9.09           -8.64\n",
      "    -11.07          -12.27\n",
      "    53.29           45.52\n",
      "    1.53            0.25\n",
      "    2.02            0.74\n",
      "    9.89            7.63\n",
      "    23.88           19.82\n",
      "    -2.38           -2.67\n",
      "    13.24           10.33\n",
      "    -51.88          -43.33\n",
      "    3.71            2.03\n",
      "    7.58            5.28\n",
      "    15.90           12.69\n",
      "    -16.54          -14.92\n",
      "    -32.17          -27.65\n",
      "    -22.02          -19.58\n",
      "    -36.95          -31.49\n",
      "    -19.07          -17.89\n",
      "    56.69           48.37\n",
      "    23.54           19.35\n",
      "    -6.91           -6.98\n",
      "    -32.45          -27.84\n",
      "    12.30            9.55\n",
      "    33.17           27.68\n",
      "    -13.83          -12.37\n",
      "    3.41            7.13\n",
      "    -19.39          -17.39\n",
      "    -0.26            0.20\n",
      "    18.04           14.44\n",
      "    -15.02          -13.65\n",
      "    -20.75          -18.54\n",
      "    0.35           -0.74\n",
      "    27.60           22.42\n",
      "    -39.50          -33.55\n",
      "    -37.95          -32.57\n",
      "    3.95            2.43\n",
      "    -0.38           -1.01\n",
      "    -2.23           -2.97\n",
      "    5.28            3.58\n",
      "    -7.77           -7.60\n",
      "    20.67           16.88\n",
      "    18.63           15.02\n",
      "    18.87           15.18\n",
      "    766.67          755.99\n",
      "    -39.06          -34.25\n",
      "    47.77           40.39\n",
      "    0.40           -0.54\n",
      "    6.89            4.86\n",
      "    76.74           66.34\n",
      "    6.16            4.12\n",
      "    -23.27          -20.35\n",
      "    -1.73           -3.74\n",
      "    101.68           88.75\n",
      "    22.51           18.31\n",
      "    5.75            5.70\n",
      "    -34.20          -29.40\n",
      "    -27.77          -24.00\n",
      "    -0.52           -1.48\n",
      "    4.12            2.46\n",
      "    -43.10          -36.56\n",
      "    -28.05          -24.35\n",
      "    23.61           19.17\n",
      "    -21.00          -18.68\n",
      "    2.50            1.05\n",
      "    1.19            0.02\n",
      "    -19.46          -17.14\n",
      "    14.12           11.07\n",
      "    -19.05          -16.65\n",
      "    47.65           40.43\n",
      "    7.94            5.77\n",
      "    7.11            5.08\n",
      "    -13.46          -12.38\n",
      "    -59.48          -49.53\n",
      "    -3.50           -4.02\n",
      "    10.42            6.16\n",
      "    28.67           23.72\n",
      "    3.05            1.57\n",
      "    20.57           16.57\n",
      "    19.52           15.77\n",
      "    -4.13           -4.52\n",
      "    21.26           17.26\n",
      "    18.87           15.62\n",
      "    -42.11          -36.73\n",
      "    -6.31           -6.26\n",
      "    30.61           25.50\n",
      "    7.37            5.36\n",
      "    0.49           -0.60\n",
      "    35.04           29.36\n",
      "    -3.49           -4.12\n",
      "    5.65            3.72\n",
      "    21.61           18.17\n",
      "    26.53           21.81\n",
      "    16.62           13.20\n",
      "    12.14            8.99\n",
      "    -22.73          -19.91\n",
      "    10.67            8.10\n",
      "    236.60          211.14\n",
      "    24.68           20.28\n",
      "    5.80            3.90\n",
      "    -46.36          -39.09\n",
      "    10.38            7.84\n",
      "    -21.44          -18.86\n",
      "    15.05           11.59\n",
      "    -3.28           -4.13\n",
      "    17.55           14.14\n",
      "    12.02            9.28\n",
      "    4.61            2.96\n",
      "    11.61            8.94\n",
      "    -8.73           -8.45\n",
      "    -9.46           -8.91\n",
      "    30.38           25.23\n",
      "    -23.28          -20.79\n",
      "    162.91          143.55\n",
      "    -44.25          -37.63\n",
      "    -5.82           -6.13\n",
      "    1.56            0.11\n",
      "    2.11            0.81\n",
      "    6.62          -10.94\n",
      "    -17.27          -15.39\n",
      "    1.22           -0.02\n",
      "    0.71           -0.67\n",
      "    4.62            2.91\n",
      "    -11.37           -9.81\n",
      "    1.08           -0.14\n",
      "    383.62          347.68\n",
      "    4.43            2.76\n",
      "    -11.27          -10.55\n",
      "    -38.84          -33.16\n",
      "    -10.99           -7.62\n",
      "    2.50            1.17\n",
      "    6.60            4.60\n",
      "    -3.23           -3.80\n",
      "    1.60            0.37\n",
      "    -14.66          -13.39\n",
      "    -38.20          -32.45\n",
      "    -1.51           -3.32\n",
      "    7.04            4.96\n",
      "    2.58            0.69\n",
      "    -36.16          -31.06\n",
      "    575.32          539.74\n",
      "    28.39           23.57\n",
      "    16.96           13.57\n",
      "    -49.10          -41.23\n",
      "    13.17           10.32\n",
      "    10.73            8.12\n",
      "    -35.20          -30.02\n",
      "    24.63           20.23\n",
      "    7.37            5.22\n",
      "    690.00          666.42\n",
      "    -4.94           -5.69\n",
      "    -8.59           -8.26\n",
      "    6.20            4.38\n",
      "    4.17            2.62\n",
      "    29.73           24.68\n",
      "    -44.62          -35.26\n",
      "    13.11           10.31\n",
      "    -33.98          -29.27\n",
      "    13.89           11.46\n",
      "    -16.90          -15.27\n",
      "    -74.01          -60.53\n",
      "    -24.69          -21.44\n",
      "    -21.87          -19.40\n",
      "    40.27           33.98\n",
      "    22.08           15.85\n",
      "    36.37           30.30\n",
      "    -19.38          -17.29\n",
      "    -19.43          -17.45\n",
      "    16.68           13.64\n",
      "    20.25           16.24\n",
      "    20.63           14.61\n",
      "    1753.33         1709.65\n",
      "    -17.53          -15.58\n",
      "    7.56            4.83\n",
      "    -0.59           -1.44\n",
      "    -19.57          -17.22\n",
      "    16.30           13.05\n",
      "    1831.24         1794.70\n",
      "    -42.47          -35.93\n",
      "    2.51            0.73\n",
      "    17.05           13.98\n",
      "    -8.82           -8.48\n",
      "    0.64            0.06\n",
      "    -10.00           -9.42\n",
      "    -29.20          -25.30\n",
      "    -35.10          -30.26\n",
      "    4.06            2.57\n",
      "    -15.16          -13.66\n",
      "    -7.91           -8.22\n",
      "    7.76            6.18\n",
      "    61.76           52.93\n",
      "    2.69            1.20\n",
      "    -32.61          -28.22\n",
      "    17.15           13.82\n",
      "    -71.01          -58.60\n",
      "    4.08            2.48\n",
      "    -23.12          -20.48\n",
      "    -27.99          -24.43\n",
      "    223.29          199.25\n",
      "    17.03           13.60\n",
      "    37.28           31.31\n",
      "    31.38           25.97\n",
      "    -19.35          -17.23\n",
      "    -42.86          -36.26\n",
      "    525.71          487.32\n",
      "    12.27            9.25\n",
      "    11.32            8.75\n",
      "    -15.69          -14.22\n",
      "    -14.56          -13.53\n",
      "    41.40           33.41\n",
      "    -5.71           -5.87\n",
      "    -1.41           -2.23\n",
      "    0.57           -0.55\n",
      "    -25.08          -22.04\n",
      "    2.99            1.59\n",
      "    -7.34           -7.34\n",
      "    -2.16           -2.93\n",
      "    4.71            3.12\n",
      "    99.21           86.40\n",
      "    8.57            6.24\n",
      "    3.74            2.74\n",
      "    13.98           10.91\n",
      "    11.52            7.92\n",
      "    38.77           32.60\n",
      "    1.53            0.06\n",
      "    24.58           21.92\n",
      "    5.20            3.42\n",
      "    8.96            6.61\n",
      "    -2.83           -3.20\n",
      "    20.87           16.97\n",
      "    -29.54          -25.65\n",
      "    -8.46           -8.09\n",
      "    64.11           55.78\n",
      "    -29.47          -25.71\n",
      "    -19.44          -17.48\n",
      "    -23.90          -21.00\n",
      "    11.26            8.61\n",
      "    -32.87          -28.18\n",
      "    -17.48          -15.26\n",
      "    1.52            0.21\n",
      "    0.01           -1.16\n",
      "    2.75            1.25\n",
      "    4.44            2.80\n",
      "    43.98           37.29\n",
      "    -4.97           -5.24\n",
      "    -2.95           -3.56\n",
      "    -56.92          -47.35\n",
      "    79.17           68.41\n",
      "    -17.98          -16.18\n",
      "    -12.91          -11.89\n",
      "    -30.30          -26.26\n",
      "    9.09            6.81\n",
      "    33.33           27.90\n",
      "    -4.21           -4.54\n",
      "    13.21            8.55\n",
      "    5.89            3.55\n",
      "    -23.82          -21.01\n",
      "    1.48            0.21\n",
      "    13.12            9.98\n",
      "    -9.78           -9.31\n",
      "    2.40            0.97\n",
      "    -6.71           -6.50\n",
      "    -10.70          -10.25\n",
      "    8.14            5.91\n",
      "    15.48           12.32\n",
      "    -34.07          -29.20\n",
      "    23.10           18.34\n",
      "    -0.31           -1.32\n",
      "    -36.83          -31.63\n",
      "    -42.80          -36.25\n",
      "    3.08            1.57\n",
      "    -5.49           -5.61\n",
      "    -25.56          -22.31\n",
      "    -3.00           -3.47\n",
      "    11.06            8.14\n",
      "    -26.67          -23.32\n",
      "    7.10            5.09\n",
      "    81.24           70.17\n",
      "    8.91            6.55\n",
      "    33.32           27.82\n",
      "    -23.97          -21.05\n",
      "    -42.00          -35.50\n",
      "    -29.27          -25.26\n",
      "    5.33            3.76\n",
      "    -5.70           -5.87\n",
      "    5.28            2.07\n",
      "    -46.39          -39.32\n",
      "    -54.14          -45.40\n",
      "    -10.68          -10.06\n",
      "    -4.17           -4.53\n",
      "    1.87            0.44\n",
      "    24.77           20.31\n",
      "    -21.59          -19.08\n",
      "    -2.72           -3.22\n",
      "    490.17          451.85\n",
      "    577.98          540.84\n",
      "    -28.95          -25.18\n",
      "    58.19           50.46\n",
      "    5.89            3.96\n",
      "    15.90           12.76\n",
      "    -56.72          -48.84\n",
      "    -12.28          -11.39\n",
      "    -40.57          -34.53\n",
      "    5.00            3.35\n",
      "    -12.73          -11.69\n",
      "    71.16           61.29\n",
      "    -3.15           -1.93\n",
      "    -22.03          -18.28\n",
      "    2.20            0.97\n",
      "    -5.02           -6.56\n",
      "    14.94           11.95\n",
      "    6.48            4.04\n",
      "    1.83            0.52\n",
      "    52.69           44.88\n",
      "    -6.84           -6.83\n",
      "    6.80            4.87\n",
      "    26.61           21.93\n",
      "    25.21           20.77\n",
      "    7.48            5.35\n",
      "    -48.94          -41.29\n",
      "    2.12            0.82\n",
      "    -50.10          -42.28\n",
      "    10.88            8.39\n",
      "    -22.23          -19.15\n",
      "    636.00          607.21\n",
      "    -23.49          -20.72\n",
      "    -8.61           -8.19\n",
      "    -16.85          -15.15\n",
      "    30.02           24.18\n",
      "    3.60            1.11\n",
      "    113.58           99.25\n",
      "    5.84            3.92\n",
      "    -3.40           -3.75\n",
      "    0.08           -1.56\n",
      "    23.15           18.90\n",
      "    16.45           12.96\n",
      "    7.11            5.16\n",
      "    46.97           39.81\n",
      "    -17.33          -15.53\n",
      "    -40.16          -52.30\n",
      "    6.36            3.19\n",
      "    19.01           15.26\n",
      "    29.38           24.35\n",
      "    32.70           27.23\n",
      "    -29.29          -25.59\n",
      "    -19.03          -17.24\n",
      "    40.09           33.75\n",
      "    -0.35           -1.31\n",
      "    -60.00          -50.04\n",
      "    -1.12           -2.93\n",
      "    -5.03         -278.13\n",
      "    9.07           -0.19\n",
      "    50.35           42.82\n",
      "    0.20           -0.74\n",
      "    -5.03           -5.43\n",
      "    -3.17           -3.62\n",
      "    102.37           89.02\n",
      "    -3.00           -3.80\n",
      "    10.31            7.86\n",
      "    50.09           42.67\n",
      "    0.32           -0.74\n",
      "    1.62            0.18\n",
      "    -9.15           -8.79\n",
      "    -7.36           -7.15\n",
      "    -8.56           -8.15\n",
      "    7.35            5.08\n",
      "    10.18            7.96\n",
      "    -19.64          -17.57\n",
      "    7.19            5.12\n",
      "    3.67            2.11\n",
      "    3.80            2.22\n",
      "    -3.75           -4.18\n",
      "    1.40            0.10\n",
      "    -67.84          -56.21\n",
      "    -4.36           -4.77\n",
      "    -0.36           -1.31\n",
      "    -10.59          -10.24\n",
      "    -8.99           -8.42\n",
      "    -7.95           -7.93\n",
      "    1.76            0.65\n",
      "    4.08            2.47\n",
      "    12.26            9.69\n",
      "    5.17            3.37\n",
      "    43.38           36.78\n",
      "    -39.60          -33.93\n",
      "    -1.05           -2.10\n",
      "    9.47            7.08\n",
      "    14.69           11.64\n",
      "    96.00           83.45\n",
      "    -50.04          -42.22\n",
      "    -35.25          -30.91\n",
      "    -9.67           -8.88\n",
      "    0.21           -1.16\n",
      "    -10.31           -8.25\n",
      "    9.77            7.30\n",
      "    31.76           26.48\n",
      "    12.15            9.62\n",
      "    6.95            5.90\n",
      "    25.97           21.42\n",
      "    52.12           44.42\n",
      "    -72.58          -59.45\n",
      "    17.23           13.76\n",
      "    4.54            5.58\n",
      "    -0.55           -1.52\n",
      "    1.51            0.24\n",
      "    0.53           -0.59\n",
      "    20.20           16.24\n",
      "    216.90          193.25\n",
      "    9.83            3.20\n",
      "    11.35            8.66\n",
      "    43.71           37.24\n",
      "    3.66            2.31\n",
      "    16.43           13.06\n",
      "    1.89            0.87\n",
      "    -13.50          -12.17\n",
      "    -2.66           -3.52\n",
      "    7.76            5.58\n",
      "    22.57           18.36\n",
      "    -4.21           -5.90\n",
      "    8.45            6.19\n",
      "    18.45           14.89\n",
      "    -79.62          -64.93\n",
      "    9.46            6.81\n",
      "    -8.09           -7.54\n",
      "    16.41           13.19\n",
      "    -36.00          -30.69\n",
      "    2.75            1.25\n",
      "    -0.57           -1.90\n",
      "    2.41            1.00\n",
      "    2.05            0.74\n",
      "    -20.60          -17.81\n",
      "    4.85            3.18\n",
      "    5.42            5.60\n",
      "    50.23           42.83\n",
      "    1.16           -2.10\n",
      "    9.74            7.43\n",
      "    -5.28           -5.53\n",
      "    -10.43           -9.79\n",
      "    30.28           25.28\n",
      "    -19.07          -17.22\n",
      "    -30.26          -26.12\n",
      "    16.35           13.05\n",
      "    5.85            3.97\n",
      "    2.91            1.43\n",
      "    3.28            1.91\n",
      "    21.56           17.57\n",
      "    -2.03           -2.71\n",
      "    -10.26           21.77\n",
      "    -41.43          -35.36\n",
      "    6.05            4.18\n",
      "    -1.70           -2.57\n",
      "    24.96           20.58\n",
      "    7.70            5.62\n",
      "    117.51          102.76\n",
      "    -17.53          -15.78\n",
      "    -4.83           -5.18\n",
      "    43.88           37.12\n",
      "    13.86           11.82\n",
      "    16.76           13.41\n",
      "    26.56           21.91\n",
      "    -2.36           -3.06\n",
      "    -1.77           -2.41\n",
      "    38.15           32.04\n",
      "    37.02           31.18\n",
      "    -4.40           -4.83\n",
      "    -24.91          -22.08\n",
      "    6.41            4.49\n",
      "    26.65           22.01\n",
      "    -37.28          -31.54\n",
      "    38.96           32.75\n",
      "    32.44           27.08\n",
      "    7.13            6.49\n",
      "    -5.37           -5.51\n",
      "    0.87           -1.12\n",
      "    27.04           23.08\n",
      "    24.23           19.59\n",
      "    22.26           18.20\n",
      "    2.18           -2.38\n",
      "    18.31           14.44\n",
      "    -0.86           -1.97\n",
      "    -39.22          -33.41\n",
      "    -8.99           -8.67\n",
      "    -14.29          -12.53\n",
      "    5.44            3.63\n",
      "    67.35           57.86\n",
      "    20.71           16.85\n",
      "    37.13           31.03\n",
      "    -9.69           -8.58\n",
      "    7.38            5.13\n",
      "    0.48           -0.52\n",
      "    1.59            0.33\n",
      "    -2.23           -2.94\n",
      "    35.94           30.11\n",
      "    -30.91          -26.52\n",
      "    41.46           34.98\n",
      "    11.31            8.76\n",
      "    6.99            5.00\n",
      "    -14.35          -12.58\n",
      "    9.58            6.11\n",
      "    -13.94          -12.80\n",
      "    -7.76           -7.45\n",
      "    55.28           47.20\n",
      "    -4.97           -5.26\n",
      "    -28.05          -24.46\n",
      "    122.99          107.57\n",
      "    11.16            8.78\n",
      "    -44.42          -37.73\n",
      "    -38.08          -32.50\n",
      "    5.95            4.17\n",
      "    37.13           31.17\n",
      "    41.26           34.77\n",
      "    -39.42          -33.75\n",
      "    -33.55          -28.92\n",
      "    458.82          419.15\n",
      "    -84.14          -68.47\n",
      "    -5.12           -5.18\n",
      "    18.18           14.85\n",
      "    8.26            6.20\n",
      "    -11.59          -11.03\n",
      "    -15.28          -13.88\n",
      "    0.78           -0.35\n",
      "    -13.71          -12.87\n",
      "    -2.39           -3.36\n",
      "    -4.89           -6.00\n",
      "    -11.20          -10.57\n",
      "    -41.02          -35.02\n",
      "    -9.43           -8.94\n",
      "    86.74           75.22\n",
      "    14.94           14.51\n",
      "    23.53           19.48\n",
      "    -6.53           -6.29\n",
      "    39.95           33.71\n",
      "    -63.95          -53.20\n",
      "    -7.78           -7.51\n",
      "    8.64            6.39\n",
      "    7.95            5.77\n",
      "    -6.28           -6.33\n",
      "    2.20           -2.59\n",
      "    -28.18          -23.74\n",
      "    -20.45          -18.40\n",
      "    -20.00          -17.77\n",
      "    -57.34          -47.68\n",
      "    6.33            4.43\n",
      "    51.43           43.76\n",
      "    -1.85           -2.69\n",
      "    -53.00          -44.58\n",
      "    -43.63          -37.09\n",
      "    7.85            5.88\n",
      "    17.54           14.10\n",
      "    -1.23           -2.13\n",
      "    29.19           24.10\n",
      "    106.64           92.92\n",
      "    42.03           36.98\n",
      "    -2.14           -2.87\n",
      "    0.29           -0.70\n",
      "    -0.06           -1.17\n",
      "    -3.34           -4.29\n",
      "    13.71           10.71\n",
      "    31.26           26.05\n",
      "    -7.48           -7.40\n",
      "    -63.79          -52.45\n",
      "    -24.01          -21.07\n",
      "    -3.13           -3.54\n",
      "    -9.91           -9.36\n",
      "    5.75            2.47\n",
      "    2.66            1.38\n",
      "    4.85            3.23\n",
      "    -47.16          -39.79\n",
      "    -14.68           49.46\n",
      "    17.17           14.06\n",
      "    -47.78          -40.16\n",
      "    17.01           13.48\n",
      "    40.04           35.19\n",
      "    45.07           38.18\n",
      "    3.49           -2.22\n",
      "    26.89           22.15\n",
      "    21.01           17.10\n",
      "    -74.44          -60.59\n",
      "    -4.91           -5.10\n",
      "    2.20            0.86\n",
      "    -3.35           -3.91\n",
      "    12.33            9.54\n",
      "    0.31           -1.07\n",
      "    141.42          124.69\n",
      "    5.26            3.44\n",
      "    1.34           -1.12\n",
      "    2.25            0.85\n",
      "    40.89           34.47\n",
      "    -10.82          -10.19\n",
      "    27.39           22.74\n",
      "    3.26            3.12\n",
      "    -11.40          -10.44\n",
      "    -3.67           -4.73\n",
      "    -11.81          -10.91\n",
      "    4.30            2.92\n",
      "    -11.01           -7.97\n",
      "    0.83           -0.31\n",
      "    1.10           -0.10\n",
      "    2.65            1.19\n",
      "    10.57            8.10\n",
      "    -14.04          -12.85\n",
      "    15.96           12.81\n",
      "    -0.91           -1.88\n",
      "    660.00          630.76\n",
      "    41.41           34.97\n",
      "    1.89            0.54\n",
      "    -16.30          -14.85\n",
      "    -18.83          -16.87\n",
      "    6.33            4.32\n",
      "    19.01           15.35\n",
      "    -21.64          -19.29\n",
      "    8.10            5.95\n",
      "    -2.39           -3.16\n",
      "    3.06           11.38\n",
      "    3.81            2.71\n",
      "    14.09           11.06\n",
      "    32.64           27.09\n",
      "    1.87           -2.34\n",
      "    6.27            4.40\n",
      "    9.60            8.37\n",
      "    8.27            6.05\n",
      "    0.24           -1.05\n",
      "    -12.69          -11.73\n",
      "    10.61            7.76\n",
      "    24.77           20.38\n",
      "    61.32           52.81\n",
      "    -15.55          -13.63\n",
      "    2.35            0.96\n",
      "    -17.71          -16.25\n",
      "    -78.85          -64.62\n",
      "    -7.62           -7.83\n",
      "    21.11           16.79\n",
      "    -7.67           -7.53\n",
      "    9.54            7.16\n",
      "    20.65           17.86\n",
      "    23.89           19.59\n",
      "    0.16           -0.95\n",
      "    53.85           45.92\n",
      "    12.42            9.63\n",
      "    -6.76           -6.74\n",
      "    -13.64          -12.54\n",
      "    16.36           12.67\n",
      "    -17.37          -18.10\n",
      "    -32.92          -28.31\n",
      "    -7.42           -7.31\n",
      "    2.16            0.94\n",
      "    13.19           10.24\n",
      "    18.15           15.36\n",
      "    6.91            5.47\n",
      "    22.77           18.53\n",
      "    -35.58          -30.61\n",
      "    1.94            0.62\n",
      "    4.52            2.85\n",
      "    22.40           18.41\n",
      "    -11.36          -10.45\n",
      "    -39.15          -33.99\n",
      "    -6.18           -6.28\n",
      "    -75.10          -61.47\n",
      "    -3.29           -3.62\n",
      "    -16.59          -14.95\n",
      "    0.69           -0.39\n",
      "    -23.62          -20.57\n",
      "    -4.45           -4.74\n",
      "    -4.49           -4.93\n",
      "    -24.48          -21.31\n",
      "    -0.81           -1.57\n",
      "    2.11            0.59\n",
      "    6.29            4.49\n",
      "    25.92           21.70\n",
      "    -1.27           -2.08\n",
      "    -4.17           -4.54\n",
      "    -5.82           -5.77\n",
      "    46.45           39.32\n",
      "    33.94           28.27\n",
      "    17.89           14.45\n",
      "    5.40            3.25\n",
      "    -18.10          -16.28\n",
      "    9.08            6.56\n",
      "    -15.87          -14.17\n",
      "    1.01            3.56\n",
      "    -7.98           -7.69\n",
      "    -24.92          -21.83\n",
      "    -5.11           -5.27\n",
      "    34.04           28.40\n",
      "    11.10            8.54\n",
      "    146.15          128.49\n",
      "    7.71            5.54\n",
      "    2.86            1.53\n",
      "    3.89            3.19\n",
      "    0.64           -2.59\n",
      "    4.36            2.47\n",
      "    -28.45          -24.81\n",
      "    -2.30           -6.36\n",
      "    -6.84           -6.84\n",
      "    6.19            4.29\n",
      "    7.48            5.37\n",
      "    -37.76          -32.24\n",
      "    3.23            1.80\n",
      "    14.93           11.79\n",
      "    155.02          136.73\n",
      "    2.67            1.26\n",
      "    -1.98           -2.71\n",
      "    13.67           10.08\n",
      "    -24.31          -21.32\n",
      "    7.82            5.50\n",
      "    -76.00          -62.33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    31.70           26.40\n",
      "    -13.02          -12.01\n",
      "    -2.37           -2.98\n",
      "    8.29            5.34\n",
      "    -31.79          -27.60\n",
      "    10.83            7.19\n",
      "    51.76           44.14\n",
      "    2.85            1.36\n",
      "    -11.01          -10.15\n",
      "    -30.58          -26.67\n",
      "    5.26            3.53\n",
      "    2.26            0.91\n",
      "    -13.77          -12.49\n",
      "    6.19            1.71\n",
      "    -10.92          -10.28\n",
      "    -16.76          -14.91\n",
      "    5.69            3.84\n",
      "    13.24           10.27\n",
      "    46.26           39.15\n",
      "    -6.54           -6.43\n",
      "    -6.72           -6.70\n",
      "    1.37           -0.58\n",
      "    10.54            8.02\n",
      "    9.68            8.18\n",
      "    -29.88          -25.90\n",
      "    50.88           43.29\n",
      "    4.27            3.85\n",
      "    -14.18          -12.89\n",
      "    13.89           10.80\n",
      "    0.25          -22.46\n",
      "    2.33            2.10\n",
      "    -2.26           -2.96\n",
      "    1016.33         1021.06\n",
      "    -7.77           -7.45\n",
      "    4.47            2.93\n",
      "    -2.91           -3.53\n",
      "    -56.17          -47.10\n",
      "    -34.10          -29.44\n",
      "    -1.08           -1.90\n",
      "    -21.19          -18.72\n",
      "    -23.09          -20.21\n",
      "    15.15           11.97\n",
      "    6.83            4.60\n",
      "    28.79           23.83\n",
      "    -18.94          -17.03\n",
      "    -30.61          -26.54\n",
      "    -34.45          -29.49\n",
      "    -35.73          -30.53\n",
      "    19.62           16.34\n",
      "    3.60            2.02\n",
      "    -41.41          -35.10\n",
      "    -11.40          -10.76\n",
      "    -29.07          -25.32\n",
      "    18.32           14.73\n",
      "    23.08           18.91\n",
      "    16.84           13.44\n",
      "    -13.98          -12.62\n",
      "    -8.89           -8.49\n",
      "    2.53            1.11\n",
      "    7.65            5.59\n",
      "    -17.54          -15.73\n",
      "    -1.22           -1.92\n",
      "    0.50            0.02\n",
      "    -84.14          -68.75\n",
      "    412.59          374.88\n",
      "    81.95           70.94\n",
      "    40.00           33.68\n",
      "    15.11           12.18\n",
      "    -0.17           -0.40\n",
      "    -7.71           -7.54\n",
      "    -37.77          -32.12\n",
      "    -58.28          -48.52\n",
      "    -10.16           -9.69\n",
      "    -5.39           -6.92\n",
      "    17.47           13.91\n",
      "    12.86            8.90\n",
      "    -25.03          -22.04\n",
      "    -4.62           -4.87\n",
      "    -17.64          -15.76\n",
      "    18.88           14.81\n",
      "    2.55            1.02\n",
      "    -13.53          -12.40\n",
      "    0.77           -0.32\n",
      "    -33.28          -28.72\n",
      "    -37.28          -31.57\n",
      "    0.59            0.05\n",
      "    26.87           22.06\n",
      "    18.44           14.30\n",
      "    -65.66          -54.51\n",
      "    -55.64          -46.68\n",
      "    -0.95           -1.70\n",
      "    39.19           32.86\n",
      "    6.69            3.61\n",
      "    5.60            5.15\n",
      "    -10.89          -10.18\n",
      "    11.98            9.24\n",
      "    34.57           28.51\n",
      "    5.14            3.30\n",
      "    -3.23           -3.58\n",
      "    24.56           19.91\n",
      "    -13.11          -12.06\n",
      "    1.66            0.48\n",
      "    -31.02          -26.79\n",
      "    16.44            9.97\n",
      "    23.58           19.35\n",
      "    1.63            0.45\n",
      "    -24.86          -21.73\n",
      "    -21.05          -18.73\n",
      "    -61.07          -50.54\n",
      "    9.14            1.08\n",
      "    58.12           49.68\n",
      "    -12.91          -11.76\n",
      "    -11.92          -11.13\n",
      "    8.24            5.97\n",
      "    -11.58          -10.83\n",
      "    4.37            2.76\n",
      "    -4.53           -4.92\n",
      "    -70.16          -57.99\n",
      "    3.59            1.70\n",
      "    11.53            8.88\n",
      "    -3.45           -3.76\n",
      "    -10.03           -9.42\n",
      "    -25.70          -22.43\n",
      "    22.44           18.14\n",
      "    -13.24          -10.32\n",
      "    14.70           11.75\n",
      "    -16.21          -14.58\n",
      "    19.84           16.01\n",
      "    116.35          101.90\n",
      "    48.77           41.43\n",
      "    29.93           24.84\n",
      "    -8.29           -7.89\n",
      "    2.02            0.75\n",
      "    -17.49          -15.77\n",
      "    -0.62           -1.57\n",
      "    -20.13          -17.94\n",
      "    26.28           21.62\n",
      "    -35.16          -30.13\n",
      "    114.39           99.47\n",
      "    15.73           12.51\n",
      "    -5.19           -5.06\n",
      "    100.69           87.64\n",
      "    -0.05           -0.43\n",
      "    94.97           82.41\n",
      "    30.10           24.97\n",
      "    -1.15           -2.65\n",
      "    6.27            4.37\n",
      "    -6.48           -6.51\n",
      "    -8.94           -8.62\n",
      "    14.99           11.99\n",
      "    -0.37           -1.31\n",
      "    5.11            3.37\n",
      "    -16.94          -15.17\n",
      "    13.44           10.53\n",
      "    6.53            4.57\n",
      "    -0.48           -4.12\n",
      "    -10.64           -9.94\n",
      "    20.23           16.35\n",
      "    0.23           -1.76\n",
      "    2.23            0.64\n",
      "    16.80           13.36\n",
      "    3.76            2.25\n",
      "    -15.72          -14.10\n",
      "    -17.77          -15.91\n",
      "    -30.52          -26.49\n",
      "    -18.00          -16.20\n",
      "    -41.50          -35.68\n",
      "    11.13            8.02\n",
      "    -17.13          -15.68\n",
      "    -12.20          -11.24\n",
      "    -16.38          -14.84\n",
      "    5.69            3.86\n",
      "    -0.80           -1.68\n",
      "    -62.07          -51.61\n",
      "    0.40           -0.35\n",
      "    -41.02          -26.03\n",
      "    10.61            8.05\n",
      "    -6.02           -6.04\n",
      "    0.70           -0.20\n",
      "    24.09           19.75\n",
      "    0.06           -0.81\n",
      "    -1.47           -2.42\n",
      "    16.40           13.24\n",
      "    1.83           -2.42\n",
      "    -29.26          -25.45\n",
      "    3.17            1.65\n",
      "    -3.55           -3.97\n",
      "    5.39            3.59\n",
      "    4.68            2.95\n",
      "    1.24            0.42\n",
      "    3.02            1.53\n",
      "    -0.17           -1.14\n",
      "    -5.05           -5.43\n",
      "    3.01            1.50\n",
      "    -11.95          -11.05\n",
      "    -1.29           -2.15\n",
      "    -4.90           -5.29\n",
      "    -3.61           -4.03\n",
      "    -19.70          -17.60\n",
      "    -4.48           -4.86\n",
      "    -0.50           -1.18\n",
      "    -4.85           -5.09\n",
      "    -2.63           -3.31\n",
      "    -5.66           -6.46\n",
      "    6.73            4.56\n",
      "    0.72           -0.40\n",
      "    7.30            5.62\n",
      "    -19.10          -17.32\n",
      "    7.45            5.41\n",
      "    -29.83          -25.87\n",
      "    13.83           10.87\n",
      "    -2.64           -3.27\n",
      "    -41.41          -35.11\n",
      "    -29.07          -25.24\n",
      "    -9.27           -8.77\n",
      "    10.56            8.02\n",
      "    3.11            1.59\n",
      "    -5.19           -5.41\n",
      "    -18.64          -16.55\n",
      "    18.27           14.69\n",
      "    0.39           -0.54\n",
      "    10.10            7.62\n",
      "    -26.85          -23.79\n",
      "    -64.01          -53.06\n",
      "    -9.46           -9.08\n",
      "    74.60           64.39\n",
      "    3.11            1.68\n",
      "    -79.18          -64.73\n",
      "    -19.53          -17.39\n",
      "    -23.64          -20.64\n",
      "    -9.52           -8.90\n",
      "    -19.88          -17.70\n",
      "    -39.92          -34.11\n",
      "    -10.12           -9.63\n",
      "    9.53            7.08\n",
      "    119.72          104.65\n",
      "    -16.33          -14.76\n",
      "    -24.81          -21.85\n",
      "    34.64           29.05\n",
      "    3.09            1.53\n",
      "    23.04           18.79\n",
      "    -5.45           -5.60\n",
      "    6.51            4.69\n",
      "    -8.16           -7.89\n",
      "    0.28           -9.56\n",
      "    2.67            1.31\n",
      "    11.88            9.22\n",
      "    12.03            9.16\n",
      "    78.33           67.64\n",
      "    19.77           15.97\n",
      "    -19.24          -17.23\n",
      "    98.18           85.63\n",
      "    -14.37          -12.97\n",
      "    17.08           13.81\n",
      "    7.44            5.32\n",
      "    153.89          135.58\n",
      "    -15.62          -12.74\n",
      "    -59.57          -49.78\n",
      "    29.25           24.23\n",
      "    56.82           48.57\n",
      "    3.71            2.12\n",
      "    -44.33          -37.62\n",
      "    28.94           24.02\n",
      "    60.00           51.35\n",
      "    -34.69          -29.65\n",
      "    -61.98          -51.36\n",
      "    4.74            3.02\n",
      "    10.22            7.61\n",
      "    -2.38           -3.16\n",
      "    2.05            0.94\n",
      "    -6.22           -6.29\n",
      "    27.86           23.02\n",
      "    0.63           -0.53\n",
      "    11.37            8.70\n",
      "    6.50            4.06\n",
      "    13.30           18.42\n",
      "    -15.46          -13.74\n",
      "    1.00           -3.42\n",
      "    8.67            6.23\n",
      "    -5.33           -5.63\n",
      "    22.16           18.00\n",
      "    14.79           10.39\n",
      "    -1.55           -2.32\n",
      "    3.19            1.76\n",
      "    16.05           13.11\n",
      "    6.39            4.66\n",
      "    -22.65          -20.04\n",
      "    40.27           33.90\n",
      "    14.71           11.63\n",
      "    5.70            3.86\n",
      "    23.05           18.85\n",
      "    10.34            7.84\n",
      "    55.86           47.93\n",
      "    60.56           51.87\n",
      "    10.75            8.07\n",
      "    3453.72         3484.26\n",
      "    -9.83           -9.15\n",
      "    -25.03          -22.01\n",
      "    -34.69          -28.88\n",
      "    -19.64          -17.36\n",
      "    1.35            1.65\n",
      "    -0.66           -1.55\n",
      "    71.45           61.57\n",
      "    -27.59          -24.31\n",
      "    0.63           -0.51\n",
      "    1.02           -0.22\n",
      "    11.79            9.18\n",
      "    2.84            1.46\n",
      "    33.07           27.66\n",
      "    5.93            4.00\n",
      "    3.14            1.42\n",
      "    -7.76           -7.63\n",
      "    17.24           13.51\n",
      "    21.97           17.96\n",
      "    -4.94           -5.31\n",
      "    -0.89           -2.07\n",
      "    -12.04          -11.05\n",
      "    -5.02           -5.20\n",
      "    -1.94           -2.97\n",
      "    -17.15          -15.42\n",
      "    -14.06          -12.91\n",
      "    -72.22          -59.51\n",
      "    16.81           13.38\n",
      "    -38.73          -33.09\n",
      "    -13.35          -12.49\n",
      "    53.59           45.82\n",
      "    2.71            1.32\n",
      "    -10.89          -10.20\n",
      "    -8.66           -8.19\n",
      "    -17.54          -13.72\n",
      "    -1.39           -2.43\n",
      "    500.00          459.10\n",
      "    4.65           17.97\n",
      "    11.38            8.74\n",
      "    -14.86          -13.64\n",
      "    5.81            3.89\n",
      "    -26.93          -23.47\n",
      "    9.23            6.78\n",
      "    -2.28           -2.35\n",
      "    25.78           21.50\n",
      "    5.41            3.01\n",
      "    54.51           46.58\n",
      "    15.20           11.89\n",
      "    16.32           11.41\n",
      "    37.47           31.52\n",
      "    20.47           16.55\n",
      "    5.49            3.64\n",
      "    11.74            9.12\n",
      "    9.05            6.59\n",
      "    -32.39          -29.32\n",
      "    -11.50          -11.16\n",
      "    17.26           14.67\n",
      "    -15.84          -14.26\n",
      "    -3.80           -3.87\n",
      "    44.62           37.85\n",
      "    -12.66          -11.50\n",
      "    28.65           23.74\n",
      "    -41.38          -35.28\n",
      "    2.68            1.30\n",
      "    -45.07          -38.17\n",
      "    -18.28          -16.23\n",
      "    -33.33          -28.79\n",
      "    9.78            7.49\n",
      "    -1.93           -2.60\n",
      "    -33.79          -28.75\n",
      "    23.37           18.93\n",
      "    -14.96          -12.12\n",
      "    -12.89          -11.88\n",
      "    -5.90           -7.29\n",
      "    22.97           18.77\n",
      "    19.44           15.73\n",
      "    1.12           -0.31\n",
      "    46.25           39.22\n",
      "    43.26           36.56\n",
      "    -33.41          -28.61\n",
      "    -8.47           -8.23\n",
      "    23.96           19.78\n",
      "    3.62            2.30\n",
      "    -17.32          -15.62\n",
      "    -29.33          -25.53\n",
      "    33.50           27.98\n",
      "    -5.77           -5.95\n",
      "    12.54            9.64\n",
      "    3.31            1.10\n",
      "    -24.66          -20.87\n",
      "    -6.60           -6.73\n",
      "    3.68            2.26\n",
      "    -19.50          -17.39\n",
      "    -5.09           -5.06\n",
      "    2.61            1.21\n",
      "    -8.38           -8.83\n",
      "    2.75            1.19\n",
      "    -38.67          -32.29\n",
      "    -0.51           -1.58\n",
      "    12.72           11.10\n",
      "    29.22           24.28\n",
      "    67.78           58.21\n",
      "    15.80           12.56\n",
      "    9.67            7.27\n",
      "    -47.01          -39.62\n",
      "    7.51            5.48\n",
      "    9.55            7.12\n",
      "    8.14            5.75\n",
      "    -21.74          -19.27\n",
      "    -38.02          -31.95\n",
      "    -6.56           -6.60\n",
      "    -9.91           -9.48\n",
      "    -34.16          -29.37\n",
      "    0.82           -4.87\n",
      "    29.57           23.39\n",
      "    -16.43          -14.86\n",
      "    -58.33          -48.78\n",
      "    0.77           -0.25\n",
      "    81.82           70.86\n",
      "    156.22          137.57\n",
      "    8.53            6.12\n",
      "    21.30           17.33\n",
      "    -5.15           -5.33\n",
      "    -26.69          -23.34\n",
      "    28.72           23.87\n",
      "    -1.27           -1.95\n",
      "    18.67           15.03\n",
      "    -15.22          -13.98\n",
      "    22.25           18.71\n",
      "    -3.02           -3.53\n",
      "    10.45            7.87\n",
      "    -6.08           -6.13\n",
      "    3.83            2.28\n",
      "    77.25           66.80\n",
      "    2.82            1.68\n",
      "    -23.23          -20.50\n",
      "    14.36           10.68\n",
      "    5.72            0.15\n",
      "    143.24          125.87\n",
      "    62.70           53.74\n",
      "    -0.95           -1.73\n",
      "    0.77           -0.41\n",
      "    14.58           11.42\n",
      "    13.01            9.67\n",
      "    -30.66          -26.58\n",
      "    -80.54          -65.54\n",
      "    -12.72          -11.65\n",
      "    -8.53           -8.35\n",
      "    82.30           71.27\n",
      "    15.74           12.53\n",
      "    47.60           40.39\n",
      "    -29.80          -26.17\n",
      "    10.29            7.87\n",
      "    -2.60           -3.18\n",
      "    2.58            1.17\n",
      "    -61.94          -51.22\n",
      "    -15.29          -13.82\n",
      "    1.75            0.44\n",
      "    7.38            5.35\n",
      "    -1.79           -3.32\n",
      "    4.27            2.57\n",
      "    -3.83           -4.24\n",
      "    7.80            6.14\n",
      "    6.92            4.81\n",
      "    53.89           45.85\n",
      "    7.17            5.33\n",
      "    0.21            2.09\n",
      "    15.18           11.98\n",
      "    -22.48          -19.88\n",
      "    -4.47           -3.08\n",
      "    -43.65          -37.84\n",
      "    19.84           17.52\n",
      "    -12.60          -11.63\n",
      "    33.88           28.35\n",
      "    -39.27          -33.46\n",
      "    -1.82           -2.57\n",
      "    37.67           31.69\n",
      "    4.80            3.05\n",
      "    14.91           11.84\n",
      "    12.74            5.13\n",
      "    1.27           -0.23\n",
      "    18.23           -7.64\n",
      "    -34.31          -29.10\n",
      "    -17.47         4428.87\n",
      "    2.84            1.75\n",
      "    -0.77           -1.71\n",
      "    24.18           20.47\n",
      "    -58.00          -48.42\n",
      "    -6.96           -1.97\n",
      "    -15.75          -14.28\n",
      "    -22.55          -19.95\n",
      "    16.25           13.04\n",
      "    -7.47           -7.33\n",
      "    13.85           10.85\n",
      "    -18.00          -16.23\n",
      "    8.24            6.32\n",
      "    -12.10          -11.28\n",
      "    20.92           16.98\n",
      "    -5.87           -5.82\n",
      "    -1.96           -1.92\n",
      "    7.82            5.58\n",
      "    -52.01          -43.45\n",
      "    8.02            5.22\n",
      "    4.33            2.72\n",
      "    -9.01           -8.64\n",
      "    -49.64          -41.89\n",
      "    0.47           -0.40\n",
      "    33.33           27.50\n",
      "    4.54            3.03\n",
      "    8.18            5.96\n",
      "    5.25            3.43\n",
      "    -0.73           -1.39\n",
      "    -3.31           -3.77\n",
      "    -57.55          -47.83\n",
      "    2.77            8.77\n",
      "    -39.81          -33.75\n",
      "    32.00           26.40\n",
      "    10.13            7.61\n",
      "    22.74           18.62\n",
      "    0.60           -0.54\n",
      "    -6.99           -7.01\n",
      "    1.00           -0.43\n",
      "    1.04           -0.20\n",
      "    25.36           20.84\n",
      "    -11.02          -10.33\n",
      "    -30.63          -25.70\n",
      "    2.68            1.14\n",
      "    -8.70           -8.33\n",
      "    -3.77           -4.35\n",
      "    3.14           -1.20\n",
      "    9.58            7.08\n",
      "    24.76           17.30\n",
      "    -18.93          -16.92\n",
      "    -50.94          -42.64\n",
      "    7.52            5.54\n",
      "    31.82           26.57\n",
      "    0.10           -1.18\n",
      "    -22.36          -19.73\n",
      "    20.83           16.95\n",
      "    -28.26          -24.51\n",
      "    -10.75          -10.03\n",
      "    -0.98           -2.04\n",
      "    14.41           13.77\n",
      "    4.71            2.91\n",
      "    -30.27          -26.32\n",
      "    -4.69           -4.16\n",
      "    -23.66          -20.74\n",
      "    1.94            0.89\n",
      "    -0.53           -1.39\n",
      "    6.25            4.49\n",
      "    -39.94          -34.27\n",
      "    -10.10           -9.58\n",
      "    -44.78          -38.06\n",
      "    37.76           31.76\n",
      "    5.78            3.48\n",
      "    -10.50           -9.98\n",
      "    -7.84           -7.84\n",
      "    -13.86          -12.74\n",
      "    -17.04          -15.14\n",
      "    -22.26          -19.78\n",
      "    19.04           15.28\n",
      "    -15.94          -14.73\n",
      "    13.03           10.33\n",
      "    162.07          143.29\n",
      "    -0.47           -1.31\n",
      "    -23.89          -21.05\n",
      "    -16.51          -14.95\n",
      "    17.36           13.90\n",
      "    -54.28          -45.77\n",
      "    -19.79          -18.20\n",
      "    -33.77          -28.91\n",
      "    -13.24          -12.16\n",
      "    -2.94           -3.35\n",
      "    40.45           33.99\n",
      "    16.80           13.41\n",
      "    89.62           77.79\n",
      "    40.39           34.05\n",
      "    -37.66          -32.31\n",
      "    148.18          130.71\n",
      "    0.60           -0.64\n",
      "    -8.77           -8.44\n",
      "    17.57           14.16\n",
      "    -25.00          -21.80\n",
      "    7.10            5.03\n",
      "    -5.99           -6.12\n",
      "    8.99            6.65\n",
      "    -19.21          -17.22\n",
      "    -30.37          -26.04\n",
      "    8.37            6.28\n",
      "    17.30           17.31\n",
      "    32.80           27.30\n",
      "    6.38            4.38\n",
      "    -36.02          -30.54\n",
      "    11.35            8.73\n",
      "    41.18           34.75\n",
      "    53.49           45.62\n",
      "    1.87            1.23\n",
      "    11.41            8.68\n",
      "    10.25            7.62\n",
      "    -11.82          -10.90\n",
      "    0.41           -0.55\n",
      "    73.03           62.93\n",
      "    -74.67          -61.45\n",
      "    -1.85           -2.60\n",
      "    12.20            9.27\n",
      "    22.14           16.32\n",
      "    -37.19          -31.85\n",
      "    -56.50          -47.17\n",
      "    -29.33          -25.32\n",
      "    2.17            0.77\n",
      "    14.95           11.16\n",
      "    -2.75           -3.38\n",
      "    -22.56          -20.23\n",
      "    -5.02           -5.92\n",
      "    14.03           11.01\n",
      "    -20.03          -17.86\n",
      "    -41.32          -35.11\n",
      "    -9.87           -9.87\n",
      "    1.62            0.43\n",
      "    -11.32          -10.59\n",
      "    -16.98          -15.31\n",
      "    8.23            6.05\n",
      "    -8.76           -8.47\n",
      "    -9.65           -9.12\n",
      "    -10.37          -11.06\n",
      "    -8.22           -8.02\n",
      "    -23.64          -20.67\n",
      "    8.77            6.46\n",
      "    -22.37          -19.78\n",
      "    68.98           59.30\n",
      "    76.80           66.25\n",
      "    10.89            8.75\n",
      "    -42.07          -35.72\n",
      "    3.62            2.04\n",
      "    -6.29           -7.87\n",
      "    4.37            2.82\n",
      "    -1.49           -2.25\n",
      "    10.25            7.73\n",
      "    -17.96          -15.98\n",
      "    -2.05           -3.16\n",
      "    -13.53          -12.48\n",
      "    -9.75          -10.01\n",
      "    17.50           14.03\n",
      "    2.09            0.72\n",
      "    -12.23          -11.24\n",
      "    -1.79           -2.44\n",
      "    18.13           14.65\n",
      "    -2.20           -4.81\n",
      "    3.73            2.29\n",
      "    33.07           27.82\n",
      "    -55.00          -45.98\n",
      "    -4.28           -4.68\n",
      "    15.94           13.06\n",
      "    49.90           43.35\n",
      "    0.25           -0.89\n",
      "    -5.71           -5.89\n",
      "    60.91           52.15\n",
      "    -19.35          -17.16\n",
      "    4.57            2.80\n",
      "    0.35           -0.78\n",
      "    25.44           19.58\n",
      "    7.85            5.78\n",
      "    35.05           29.42\n",
      "    -18.35          -16.46\n",
      "    3.83            2.16\n",
      "    -45.85          -38.86\n",
      "    4.25            2.59\n",
      "    29.60           24.60\n",
      "    -16.81          -14.66\n",
      "    -5.98           -6.15\n",
      "    1.09           -0.11\n",
      "    38.30           32.30\n",
      "    -7.72           -7.75\n",
      "    -4.67           -4.69\n",
      "    19.23           15.26\n",
      "    -61.56          -51.16\n",
      "    6.03            4.01\n",
      "    2.12            0.79\n",
      "    31.84           26.61\n",
      "    -7.14           -6.24\n",
      "    7.52            4.82\n",
      "    -21.48          -19.08\n",
      "    6.40            4.44\n",
      "    17.85           15.01\n",
      "    80.35           68.64\n",
      "    195.31          173.38\n",
      "    110.54           96.63\n",
      "    -30.00          -25.78\n",
      "    16.52           12.13\n",
      "    1.48            0.24\n",
      "    18.61           15.02\n",
      "    61.34           51.38\n",
      "    68.44           59.03\n",
      "    -11.54          -10.76\n",
      "    12.34            9.44\n",
      "    51.16           43.53\n",
      "    -21.09          -18.92\n",
      "    20.96           17.23\n",
      "    -5.61           -5.82\n",
      "    -78.00          -64.07\n",
      "    25.83           21.08\n",
      "    17.88           14.22\n",
      "    -1.70           -2.50\n",
      "    56.00           47.80\n",
      "    42.12           37.28\n",
      "    270.72          242.48\n",
      "    13.22           10.33\n",
      "    -17.52          -15.73\n",
      "    6.12            4.09\n",
      "    -44.44          -37.82\n",
      "    -1.76           -5.43\n",
      "    18.87           15.24\n",
      "    -39.22          -33.56\n",
      "    12.39            9.71\n",
      "    19.60           16.01\n",
      "    39.28           33.04\n",
      "    -66.62          -50.60\n",
      "    7.88            5.69\n",
      "    -3.88           -4.32\n",
      "    -3.95           -4.41\n",
      "    44.29           34.47\n",
      "    24.00           19.65\n",
      "    64.44           55.30\n",
      "    8.63            5.10\n",
      "    10.81            8.22\n",
      "    38.33           32.22\n",
      "    -4.94           -5.22\n",
      "    58.86           50.37\n",
      "    -6.23           -6.09\n",
      "    24.29           20.15\n",
      "    -44.12          -37.27\n",
      "    -38.69          -33.11\n",
      "    12.53            7.62\n",
      "    -4.76           -5.00\n",
      "    13.53           10.45\n",
      "    -18.55          -16.35\n",
      "    -1.91           -3.05\n",
      "    122.42          107.08\n",
      "    -25.40          -22.18\n",
      "    37.52           31.78\n",
      "    3.87            2.32\n",
      "    -8.85           -8.33\n",
      "    0.15           -1.19\n",
      "    2.94            1.49\n",
      "    3.32            3.05\n",
      "    -0.56           -1.45\n",
      "    -8.53           -8.78\n",
      "    -4.84           -5.09\n",
      "    9.24            6.91\n",
      "    4.66            2.94\n",
      "    81.75           70.87\n",
      "    24.44           20.05\n",
      "    -0.97           -1.86\n",
      "    -9.86           -9.14\n",
      "    112.50           98.49\n",
      "    51.83           44.07\n",
      "    2.68            1.16\n",
      "    0.96           -0.19\n",
      "    9.37            6.79\n",
      "    8.54            5.00\n",
      "    12.27            9.33\n",
      "    2.63            0.87\n",
      "    3.61            2.06\n",
      "    -52.07          -43.83\n",
      "    2.36            0.52\n",
      "    67.34           57.79\n",
      "    -6.31           -6.40\n",
      "    -15.52          -13.98\n",
      "    12.87            9.15\n",
      "    1.03           -0.19\n",
      "    16.95            8.75\n",
      "    -26.77          -23.28\n",
      "    2.00            0.66\n",
      "    -10.43           -9.66\n",
      "    124.36          108.97\n",
      "    -5.71           -7.02\n",
      "    -7.44           -7.35\n",
      "    -43.41          -36.95\n",
      "    25.66           21.29\n",
      "    14.38           11.31\n",
      "    13.89            9.78\n",
      "    -31.24          -26.96\n",
      "    -66.13          -54.89\n",
      "    3.37            1.84\n",
      "    -27.27          -23.73\n",
      "    15.14           12.08\n",
      "    -30.61          -26.99\n",
      "    -15.33          -13.89\n",
      "    7.78            5.65\n",
      "    -2.31           -3.01\n",
      "    -17.59          -16.18\n",
      "    -36.11          -31.00\n",
      "    10.72            8.13\n",
      "    13.29           10.25\n",
      "    17.50           13.99\n",
      "    -20.42          -18.20\n",
      "    -1.63           -2.42\n",
      "    -17.46          -15.51\n",
      "    21.55           18.26\n",
      "    -12.05          -11.33\n",
      "    -1.11           -1.97\n",
      "    -12.04          -10.83\n",
      "    -10.40           -9.82\n",
      "    -21.03          -18.54\n",
      "    -0.33           -1.32\n",
      "    -8.46           -8.22\n",
      "    -2.37           -3.01\n",
      "    -10.30           -9.61\n",
      "    -18.71          -16.70\n",
      "    -21.24          -18.90\n",
      "    26.89           22.23\n",
      "    1.77            0.48\n",
      "    18.45           14.82\n",
      "    8.10            5.88\n",
      "    -11.38          -10.58\n",
      "    -0.79            5.30\n",
      "    -16.76          -15.16\n",
      "    -5.16           -5.52\n",
      "    -4.30           -4.59\n",
      "    -18.91          -16.78\n",
      "    -17.21          -15.40\n",
      "    -54.99          -46.19\n",
      "    8.70           24.64\n",
      "    9.84            7.44\n",
      "    -17.83          -16.20\n",
      "    15.47           12.27\n",
      "    -5.98           -6.18\n",
      "    -8.37           -7.95\n",
      "    -36.29          -31.26\n",
      "    -1.04           -1.58\n",
      "    -31.48          -27.28\n",
      "    -11.30          -11.99\n",
      "    -7.85           -7.54\n",
      "    2.03           -0.27\n",
      "    11.34            8.69\n",
      "    10.67            8.26\n",
      "    -3.57           -6.29\n",
      "    6.34            4.36\n",
      "    -24.03          -21.06\n",
      "    -47.75          -40.12\n",
      "    2.55            1.11\n",
      "    -39.67          -33.71\n",
      "    18.94           15.35\n",
      "    -3.14           -3.70\n",
      "    0.20            1.05\n",
      "    -18.91          -16.23\n",
      "    11.03            9.08\n",
      "    -2.02           -2.65\n",
      "    -0.74           -1.65\n",
      "    12.23            9.58\n",
      "    -17.50          -15.51\n",
      "    -13.64            2.73\n",
      "    8.58            6.34\n",
      "    13.45           10.51\n",
      "    0.78           -0.39\n",
      "    -3.63           -4.06\n",
      "    2.71            1.64\n",
      "    25.89           21.31\n",
      "    13.74           10.77\n",
      "    -0.01           -0.91\n",
      "    -3.87           -4.35\n",
      "    -17.22          -15.48\n",
      "    19.21           15.49\n",
      "    8.08            5.88\n",
      "    12.14            9.78\n",
      "    -0.89           -0.21\n",
      "    -4.62           -4.81\n",
      "    -18.29          -16.43\n",
      "    -14.94          -13.42\n",
      "    -9.56           -8.87\n",
      "    16.43           13.10\n",
      "    18.68           14.94\n",
      "    -11.26          -11.06\n",
      "    -15.01          -13.67\n",
      "    -27.13          -23.51\n",
      "    -22.50          -19.92\n",
      "    13.96           10.73\n",
      "    -50.60          -42.55\n",
      "    -0.73           -1.42\n",
      "    9.45            7.06\n",
      "    -10.89          -10.54\n",
      "    20.40           16.61\n",
      "    10.95            8.36\n",
      "    15.27           12.27\n",
      "    468.03          429.51\n",
      "    53.85           45.92\n",
      "    -3.19           -2.26\n",
      "    -14.82          -13.57\n",
      "    -5.28           -5.41\n",
      "    -1.74           -2.49\n",
      "    -9.96           -9.50\n",
      "    39.15           33.11\n",
      "    -10.15           -8.36\n",
      "    10.41            7.93\n",
      "    -13.96          -13.37\n",
      "    20.88           16.76\n",
      "    -25.00          -22.00\n",
      "    -83.14          -67.97\n",
      "    -1.35           -5.27\n",
      "    -2.88           -3.46\n",
      "    9.23            6.92\n",
      "    -14.14          -12.59\n",
      "    -5.09           -5.17\n",
      "    43.35           36.66\n",
      "    -27.37          -23.75\n",
      "    -2.27           -2.92\n",
      "    8.26            6.12\n",
      "    3.09            1.62\n",
      "    2.58            1.01\n",
      "    -50.35          -42.39\n",
      "    27.51           22.72\n",
      "    -11.25          -10.55\n",
      "    -2.03           -3.13\n",
      "    -0.62           -1.67\n",
      "    53.35           45.60\n",
      "    1.35            0.22\n",
      "    21.44           17.42\n",
      "    11.50            9.78\n",
      "    82.13           71.09\n",
      "    22.89           20.85\n",
      "    1.77           -0.59\n",
      "    1.48            0.18\n",
      "    14.34           11.16\n",
      "    -18.56          -16.51\n",
      "    16.34           13.12\n",
      "    -5.47           -5.58\n",
      "    -41.37          -34.95\n",
      "    -59.85          -49.66\n",
      "    14.12           10.96\n",
      "    -37.50          -32.27\n",
      "    -53.01          -44.69\n",
      "    14.37           11.19\n",
      "    -72.73          -59.98\n",
      "    0.69           -0.43\n",
      "    10.29            7.87\n",
      "    19.34           15.52\n",
      "    57.78           49.46\n",
      "    -16.41          -14.87\n",
      "    0.40            0.14\n",
      "    8.92            6.64\n",
      "    -34.62          -29.80\n",
      "    7.35            4.98\n",
      "    16.32           12.99\n",
      "    8.87            1.81\n",
      "    18.01           14.33\n",
      "    56.49           48.26\n",
      "    5.52            3.67\n",
      "    47.58           40.39\n",
      "    3.16            1.72\n",
      "    4.11            2.47\n",
      "    2.43            0.95\n",
      "    23.55           19.30\n",
      "    -7.89           -7.72\n",
      "    -4.55           -5.16\n",
      "    6.64            4.62\n",
      "    10.49            7.98\n",
      "    31.51           26.22\n",
      "    -30.51          -26.49\n",
      "    5.63            3.77\n",
      "    -14.94          -13.65\n",
      "    3.22            1.90\n",
      "    -26.53          -23.25\n",
      "    -1.55           -2.36\n",
      "    -0.52           -0.25\n",
      "    54.55           46.53\n",
      "    3.04            1.64\n",
      "    7.08            4.95\n",
      "    -4.07           -4.48\n",
      "    5.07            3.33\n",
      "    35.94           30.21\n",
      "    5.22            3.40\n",
      "    6.55            4.63\n",
      "    -2.16           -4.68\n",
      "    15.47           11.68\n",
      "    -45.68          -38.73\n",
      "    11.15            8.55\n",
      "    -49.48          -41.30\n",
      "    11.18           12.66\n",
      "    1053.85         1051.42\n",
      "    -19.36          -17.61\n",
      "    -15.48          -13.97\n",
      "    8.85            6.51\n",
      "    54.72           46.66\n",
      "    -8.72           -8.41\n",
      "    -3.69           -2.21\n",
      "    35.01           29.30\n",
      "    39.76           33.50\n",
      "    2.58            1.14\n",
      "    23.70           19.44\n",
      "    -34.12          -30.47\n",
      "    -13.22          -12.21\n",
      "    -13.73          -12.51\n",
      "    17.24           13.70\n",
      "    -7.70           -7.59\n",
      "    0.79           -0.40\n",
      "    -17.53          -15.73\n",
      "    -45.38          -38.41\n",
      "    5.31            3.54\n",
      "    -23.50          -20.61\n",
      "    -6.90           -6.95\n",
      "    -8.56           -8.24\n",
      "    10.36            7.89\n",
      "    -63.53          -52.55\n",
      "    -0.05           -1.29\n",
      "    26.92           22.23\n",
      "    -17.77          -15.74\n",
      "    -4.32           -4.77\n",
      "    -38.99          -33.21\n",
      "    6.25            4.27\n",
      "    39.92           33.47\n",
      "    -40.23          -34.26\n",
      "    5.31            3.64\n",
      "    -8.37           -8.00\n",
      "    -54.09          -45.41\n",
      "    -69.15          -56.77\n",
      "    6.47            2.36\n",
      "    35.56           29.72\n",
      "    39.68           32.62\n",
      "    1.47            0.57\n",
      "    -41.11          -34.67\n",
      "    -25.00          -22.19\n",
      "    49.53           42.14\n",
      "    -0.54           -1.36\n",
      "    0.99           -0.33\n",
      "    24.38           19.71\n",
      "    -46.47          -38.74\n",
      "    -19.97          -17.93\n",
      "    -27.73          -23.70\n",
      "    -7.06           -7.01\n",
      "    10.38            7.91\n",
      "    17.82           14.44\n",
      "    -30.17          -24.09\n",
      "    -14.86          -13.50\n",
      "    -50.57          -42.51\n",
      "    -35.79          -29.93\n",
      "    5.85            4.08\n",
      "    2.44            1.01\n",
      "    1.39            0.42\n",
      "    5.55            4.79\n",
      "    6.68            4.65\n",
      "    72.22           62.26\n",
      "    3.02            1.57\n",
      "    44.00           37.23\n",
      "    61.47           52.68\n",
      "    3.85            2.25\n",
      "    -6.24           -6.85\n",
      "    0.26           -0.87\n",
      "    -27.18          -23.77\n",
      "    30.81           25.69\n",
      "    -17.66          -15.31\n",
      "    -13.26          -12.20\n",
      "    1.32           -0.01\n",
      "    97.57           84.95\n",
      "    -6.00           -6.04\n",
      "    -18.46          -16.37\n",
      "    52.89           45.22\n",
      "    6.68            4.66\n",
      "    -5.66           -5.83\n",
      "    -22.50          -19.25\n",
      "    36.00           34.15\n",
      "    55.46           47.34\n",
      "    5.67            3.81\n",
      "    -4.71           -5.03\n",
      "    -1.79           -2.38\n",
      "    9.58           -2.06\n",
      "    17.70           14.19\n",
      "    -25.43          -22.70\n",
      "    3.74            1.88\n",
      "    -4.85           -5.05\n",
      "    11.55            8.72\n",
      "    2.73            1.16\n",
      "    -14.83          -13.43\n",
      "    1.60            0.36\n",
      "    -22.55          -19.71\n",
      "    64.68           52.03\n",
      "    19.57           15.79\n",
      "    31.08           25.97\n",
      "    2.94            1.41\n",
      "    -44.93          -38.07\n",
      "    -22.00          -19.59\n",
      "    -15.19          -13.65\n",
      "    10.05            7.54\n",
      "    291.01          261.29\n",
      "    -32.43          -27.95\n",
      "    -13.75          -12.25\n",
      "    -43.49          -36.67\n",
      "    -0.25           -1.38\n",
      "    3.00            1.46\n",
      "    105.93           92.28\n",
      "    0.77           -0.42\n",
      "    2604.00         2524.54\n",
      "    -3.70           -4.09\n",
      "    23.20           19.64\n",
      "    33.33           27.83\n",
      "    12.14            8.88\n",
      "    1.53           -0.03\n",
      "    127.09          111.30\n",
      "    -18.17          -16.21\n",
      "    134.30          117.81\n",
      "    -6.89           -7.70\n",
      "    596.31          562.73\n",
      "    -45.52          -38.62\n",
      "    3.65            1.74\n",
      "    -4.94           -5.36\n",
      "    8.31            5.70\n",
      "    17.19           14.08\n",
      "    278.26          249.60\n",
      "    13.44           13.05\n",
      "    1.15           -0.09\n",
      "    6.65            4.72\n",
      "    1.59            0.33\n",
      "    43.79           37.82\n",
      "    -13.83          -12.69\n",
      "    -1.09           -1.95\n",
      "    -18.05          -15.67\n",
      "    -35.88          -30.70\n",
      "    -6.25           -6.16\n",
      "    -3.48           -3.97\n",
      "    -0.21           -1.18\n",
      "    -13.27          -12.17\n",
      "    0.93            0.31\n",
      "    -1.98           -2.41\n",
      "    10.55            8.09\n",
      "    -44.24          -37.58\n",
      "    -17.09          -14.87\n",
      "    8.22            5.86\n",
      "    8.38            6.03\n",
      "    -48.99          -41.01\n",
      "    -3.86           -4.35\n",
      "    -13.86          -12.89\n",
      "    3.33            2.06\n",
      "    112.50           98.32\n",
      "    0.26           -0.68\n",
      "    28.00           23.23\n",
      "    -2.75           -2.74\n",
      "    -43.09          -36.67\n",
      "    27.98           23.25\n",
      "    -10.04           -9.38\n",
      "    11.39            8.82\n",
      "    2.23            0.55\n",
      "    41.65           35.27\n",
      "    -3.04           -3.69\n",
      "    34.96           29.20\n",
      "    4.17            4.60\n",
      "    -16.12          -14.52\n",
      "    400.35          363.31\n",
      "    -20.05          -17.84\n",
      "    -5.05           -4.90\n",
      "    -5.24           -6.96\n",
      "    -14.17          -11.90\n",
      "    46.57           39.58\n",
      "    11.01            8.07\n",
      "    -22.99          -20.31\n",
      "    5.45            3.61\n",
      "    11.11            8.51\n",
      "    24.95           19.62\n",
      "    0.29           -0.80\n",
      "    -14.31          -13.23\n",
      "    -7.09           -7.00\n",
      "    17.35           13.86\n",
      "    7.15            3.29\n",
      "    28.52           23.66\n",
      "    -23.30          -20.14\n",
      "    -7.84           -5.97\n",
      "    -16.68          -15.05\n",
      "    8.46            6.35\n",
      "    3.75            2.14\n",
      "    -4.99           -5.26\n",
      "    17.84           14.34\n",
      "    34.99           29.49\n",
      "    0.72           -0.28\n",
      "    5.38            3.70\n",
      "    49.51           42.19\n",
      "    -11.94          -11.10\n",
      "    -9.11           -8.57\n",
      "    149.25          131.52\n",
      "    4.96            3.15\n",
      "    -21.77          -19.14\n",
      "    7.20            5.21\n",
      "    50.32           42.87\n",
      "    -20.01          -17.55\n",
      "    3.72            2.15\n",
      "    3.12            1.53\n",
      "    1.09           -0.63\n",
      "    88.12           76.42\n",
      "    41.48           34.90\n",
      "    -61.70          -50.50\n",
      "    -4.48           -3.68\n",
      "    -0.29           -1.24\n",
      "    -22.41          -19.85\n",
      "    16.77           13.17\n",
      "    17.85           14.91\n",
      "    -3.37           -3.90\n",
      "    -18.80          -16.78\n",
      "    25.00           20.74\n",
      "    -18.51          -16.59\n",
      "    -17.32          -15.63\n",
      "    -20.04          -17.71\n",
      "    -54.43          -45.64\n",
      "    2.72            1.19\n",
      "    21.14           17.19\n",
      "    0.28           -0.69\n",
      "    26.64           22.00\n",
      "    3.98            1.20\n",
      "    8.50            6.11\n",
      "    -10.87          -10.19\n",
      "    -21.14          -18.63\n",
      "    69.04           59.06\n",
      "    -16.14          -14.34\n",
      "    8.81            6.53\n",
      "    -21.60          -19.15\n",
      "    8.39            6.28\n",
      "    -0.84           -1.67\n",
      "    8.24           18.79\n",
      "    18.61           14.15\n",
      "    -43.02          -43.28\n",
      "    15.79           12.52\n",
      "    22.79           18.69\n",
      "    17.17           13.74\n",
      "    4.70            3.18\n",
      "    623.79          590.77\n",
      "    -12.55           -7.34\n",
      "    -13.20          -12.19\n",
      "    12.02            9.26\n",
      "    34.64           28.96\n",
      "    22.99           18.48\n",
      "    -7.58           -7.46\n",
      "    -27.69          -24.02\n",
      "    58.12           49.64\n",
      "    7.69            5.66\n",
      "    2.98            1.24\n",
      "    13.35           10.38\n",
      "    -6.40           -6.55\n",
      "    4.78            2.87\n",
      "    -43.25          -36.10\n",
      "    -48.11          -40.58\n",
      "    3.98            2.32\n",
      "    10.46            7.94\n",
      "    -11.62          -10.78\n",
      "    -43.73          -37.44\n",
      "    -4.76           -5.16\n",
      "    4.92            3.08\n",
      "    7.06            5.07\n",
      "    12.92           10.02\n",
      "    -20.39          -18.03\n",
      "    23.79           19.57\n",
      "    34.42           28.72\n",
      "    25.99           21.45\n",
      "    24.45           20.07\n",
      "    2.90            1.20\n",
      "    -17.28          -15.37\n",
      "    4.14            3.27\n",
      "    22.61           18.53\n",
      "    0.35           -2.11\n",
      "    16.04           12.70\n",
      "    10.25            7.76\n",
      "    4.63            2.91\n",
      "    8.31            5.10\n",
      "    20.93           17.01\n",
      "    10.58           10.88\n",
      "    -20.71          -17.76\n",
      "    11.76            9.13\n",
      "    -5.97           -6.07\n",
      "    8.13            6.00\n",
      "    11.43            4.25\n",
      "    -31.56          -26.64\n",
      "    -58.33          -48.80\n",
      "    35.37           29.56\n",
      "    -6.35           -6.44\n",
      "    4.61            2.91\n",
      "    -18.20          -15.74\n",
      "    12.03            8.65\n",
      "    29.89           24.80\n",
      "    4.51            3.18\n",
      "    32.78           27.34\n",
      "    67.81           57.73\n",
      "    -25.17          -22.08\n",
      "    -0.06           -0.99\n",
      "    -51.57          -43.19\n",
      "    4.79            3.06\n",
      "    61.52           52.75\n",
      "    7.35            3.74\n",
      "    2.44            1.26\n",
      "    7.64            3.10\n",
      "    2.79            1.34\n",
      "    66.92           57.90\n",
      "    6.11            4.17\n",
      "    9.59            7.16\n",
      "    -29.56          -25.60\n",
      "    -19.38          -17.22\n",
      "    7.61            5.59\n",
      "    6.27            4.22\n",
      "    -87.58          -71.18\n",
      "    33.87           28.39\n",
      "    0.40           -1.15\n",
      "    84.01           72.84\n",
      "    -54.56          -45.36\n",
      "    4.51            2.80\n",
      "    -0.84           -1.69\n",
      "    -9.73           -9.30\n",
      "    23.81           19.55\n",
      "    -19.06          -17.08\n",
      "    19.21           15.69\n",
      "    -2.82           -1.92\n",
      "    11.85            8.47\n",
      "    0.89           -0.03\n",
      "    -8.72           -8.36\n",
      "    47.69           40.73\n",
      "    32.34           26.78\n",
      "    -30.12          -26.29\n",
      "    25.00           20.66\n",
      "    -10.72          -20.12\n",
      "    0.49           -0.62\n",
      "    -1.60           -2.54\n",
      "    -14.33          -13.09\n",
      "    -20.73          -18.47\n",
      "    33.07           27.62\n",
      "    -14.34          -13.19\n",
      "    12.69            9.91\n",
      "    1.77            0.33\n",
      "    0.69           -0.46\n",
      "    22.44           17.67\n",
      "    -30.85          -26.50\n",
      "    28.41           23.53\n",
      "    -21.34          -18.96\n",
      "    63.07           54.07\n",
      "    1.15           -0.04\n",
      "    -12.30          -11.37\n",
      "    -0.32           -1.61\n",
      "    6.80            4.79\n",
      "    -57.13          -47.81\n",
      "    -0.81           -1.97\n",
      "    -42.08          -35.83\n",
      "    19.37           15.47\n",
      "    -8.83           -8.50\n",
      "    25.80           21.24\n",
      "    0.24           -0.88\n",
      "    27.61           22.79\n",
      "    -9.51           -9.44\n",
      "    -20.90          -18.39\n",
      "    17.30           13.84\n",
      "    34.06           28.37\n",
      "    20.38           14.87\n",
      "    -39.27          -33.57\n",
      "    -3.96           -4.42\n",
      "    -11.68          -11.60\n",
      "    23.24           18.85\n",
      "    12.66            9.79\n",
      "    -3.16            4.16\n",
      "    -3.90           -4.22\n",
      "    41.36           35.11\n",
      "    -83.64          -68.36\n",
      "    -10.92          -10.28\n",
      "    -10.91          -10.44\n",
      "    -5.56           -5.69\n",
      "    4.42            2.48\n",
      "    19.43           16.09\n",
      "    39.22           33.06\n",
      "    0.65           -0.36\n",
      "    -1.17           -2.02\n",
      "    -34.96          -29.78\n",
      "    25.52           21.61\n",
      "    -20.77          -18.28\n",
      "    61.92           53.08\n",
      "    5.10            3.29\n",
      "    3.77            2.17\n",
      "    -1.52           -2.32\n",
      "    10.55            7.88\n",
      "    -50.27          -42.29\n",
      "    -62.84          -51.95\n",
      "    -10.11           -9.69\n",
      "    -2.59           -3.82\n",
      "    -12.07          -10.75\n",
      "    6.01            4.12\n",
      "    95.33           82.86\n",
      "    -40.00          -34.21\n",
      "    3.96            2.41\n",
      "    -9.12           -8.89\n",
      "    20.00           16.22\n",
      "    3.49            1.98\n",
      "    -13.09          -12.11\n",
      "    12.04            9.34\n",
      "    -3.11           -3.78\n",
      "    -13.96          -12.51\n",
      "    2.61            1.16\n",
      "    3.48            1.96\n",
      "    5.96            3.70\n",
      "    42.21           35.65\n",
      "    1037.50         1033.91\n",
      "    -15.32          -13.85\n",
      "    164.38          145.34\n",
      "    -15.06          -13.63\n",
      "    -24.16          -17.05\n",
      "    6.21            4.32\n",
      "    48.39           41.18\n",
      "    9.73            7.34\n",
      "    -6.38           -6.43\n",
      "    -22.24          -19.51\n",
      "    0.39           -0.76\n",
      "    -6.76           -6.61\n",
      "    11.80            9.18\n",
      "    12.18            9.46\n",
      "    6.71            5.99\n",
      "    25.84           21.19\n",
      "    41.26           34.81\n",
      "    -1.31           -0.66\n",
      "    -2.78           -3.33\n",
      "    1.09           -0.10\n",
      "    3.47            1.94\n",
      "    0.92            0.76\n",
      "    -38.61          -33.56\n",
      "    -6.87           -6.91\n",
      "    -4.04           -4.40\n",
      "    0.41           -0.54\n",
      "    7.89            5.75\n",
      "    14.34           11.24\n",
      "    -16.24          -15.98\n",
      "    -11.45          -10.60\n",
      "    12.67            9.74\n",
      "    -3.17           -4.60\n",
      "    -1.98           -2.70\n",
      "    -0.97           -1.97\n",
      "    -15.44          -13.96\n",
      "    -16.05          -14.44\n",
      "    42.78           36.05\n",
      "    3.34            1.49\n",
      "    -22.65          -20.01\n",
      "    2.59            1.03\n",
      "    -10.00           -9.55\n",
      "    11.95            9.37\n",
      "    -35.77          -30.54\n",
      "    -6.70           -6.54\n",
      "    89.08           77.27\n",
      "    36.10           30.38\n",
      "    2.52            1.20\n",
      "    -4.81           -5.03\n",
      "    41.51           35.14\n",
      "    -3.71           -4.07\n",
      "    -2.53           -3.17\n",
      "    -17.07          -15.40\n",
      "    5.62            3.78\n",
      "    18.73           15.21\n",
      "    -4.04           -4.27\n",
      "    10.43            7.49\n",
      "    7.97            5.81\n",
      "    3.26            1.59\n",
      "    1.28            8.45\n",
      "    7.18            5.06\n",
      "    -25.83          -22.64\n",
      "    48.44           41.12\n",
      "    -0.79           -1.53\n",
      "    18.31           12.55\n",
      "    -4.08           -5.40\n",
      "    9.37            6.87\n",
      "    -37.96          -31.71\n",
      "    26.76           22.10\n",
      "    1.36           -0.33\n",
      "    -10.31           -9.80\n",
      "    15.09           19.19\n",
      "    -11.76          -11.00\n",
      "    0.73           -0.67\n",
      "    6.11            4.18\n",
      "    -4.24           -4.61\n",
      "    -49.61          -41.62\n",
      "    -32.48          -28.11\n",
      "    -27.37          -23.54\n",
      "    -10.50           -9.87\n",
      "    5.55            3.83\n",
      "    -8.89           -8.67\n",
      "    -24.30          -21.42\n",
      "    10.95            8.74\n",
      "    575.00          538.42\n",
      "    7.78            5.70\n",
      "    12.03            9.27\n",
      "    -16.03          -14.55\n",
      "    -10.26           -9.64\n",
      "    -8.73           -8.46\n",
      "    -7.48           -7.63\n",
      "    -44.19          -37.51\n",
      "    0.24           -0.71\n",
      "    -21.35          -18.97\n",
      "    33.12           27.64\n",
      "    -17.82          -15.87\n",
      "    13.10           10.14\n",
      "    -18.84          -16.61\n",
      "    -1.56           -2.36\n",
      "    -59.52          -49.45\n",
      "    28.67           23.51\n",
      "    -0.19           -1.04\n",
      "    -21.94          -19.54\n",
      "    24.15           19.88\n",
      "    -31.95          -27.48\n",
      "    20.96           16.70\n",
      "    -20.26          -17.99\n",
      "    262.66          235.11\n",
      "    32.10           26.69\n",
      "    33.14           27.73\n",
      "    4.07            0.43\n",
      "    -12.36          -11.61\n",
      "    -2.05           -2.68\n",
      "    118.18          103.27\n",
      "    -28.39          -24.76\n",
      "    -16.28          -14.73\n",
      "    3.62            2.09\n",
      "    8.32            6.16\n",
      "    -29.76          -25.86\n",
      "    0.87           -0.30\n",
      "    -37.42          -32.09\n",
      "    -9.31           -8.92\n",
      "    16.14           12.44\n",
      "    1.44            0.52\n",
      "    3.60            1.78\n",
      "    -7.34           -7.28\n",
      "    17.40           13.72\n",
      "    24.00           19.76\n",
      "    -18.63          -16.64\n",
      "    1.99            0.54\n",
      "    -7.83           -7.60\n",
      "    -42.35          -36.14\n",
      "    17.80           14.47\n",
      "    1.33            0.20\n",
      "    -4.17           -4.63\n",
      "    4.44            2.75\n",
      "    1.70            0.45\n",
      "    20.19           16.33\n",
      "    -13.39          -12.21\n",
      "    797.93          791.42\n",
      "    -45.71          -38.47\n",
      "    27.09           22.24\n",
      "    10.06            8.21\n",
      "    4.58            2.87\n",
      "    3.54          -43.31\n",
      "    1.88            0.63\n",
      "    -21.69          -18.75\n",
      "    -51.30          -43.18\n",
      "    -6.22           -6.14\n",
      "    -2.58           -3.24\n",
      "    32.51           27.04\n",
      "    -1.88           -2.79\n",
      "    16.67           13.24\n",
      "    -2.80           -3.40\n",
      "    -16.25          -14.80\n",
      "    -15.22          -13.78\n",
      "    12.61            9.76\n",
      "    129.91          113.12\n",
      "    1.15           -0.04\n",
      "    4.26            2.56\n",
      "    8.18           17.30\n",
      "    -2.94           -1.70\n",
      "    462.50          424.23\n",
      "    -0.16           -1.20\n",
      "    -3.64           -4.14\n",
      "    2.09            0.60\n",
      "    67.24           57.93\n",
      "    -10.56           -9.78\n",
      "    -4.75           -5.04\n",
      "    0.37           -0.71\n",
      "    10.53            6.43\n",
      "    -9.11           -9.45\n",
      "    -5.62           -5.77\n",
      "    15.30           12.21\n",
      "    -5.31           -5.60\n",
      "    13.70           10.80\n",
      "    0.58           -0.67\n",
      "    -1.38           -2.24\n",
      "    9.76            7.41\n",
      "    -12.07          -11.14\n",
      "    -2.52           -3.29\n",
      "    15.90           12.47\n",
      "    -13.40          -12.28\n",
      "    12.57            6.36\n",
      "    -4.00           -2.98\n",
      "    9.42            7.18\n",
      "    -19.60          -16.63\n",
      "    95.90           83.38\n",
      "    3.23            1.77\n",
      "    8.87           13.62\n",
      "    1.08            1.69\n",
      "    334.78          302.11\n",
      "    -10.40           -9.84\n",
      "    -49.22          -41.18\n",
      "    -26.38          -22.80\n",
      "    72.36           62.33\n",
      "    -28.28          -24.66\n",
      "    21.06           17.11\n",
      "    -6.49           -6.69\n",
      "    7.60            5.54\n",
      "    -0.84           -2.05\n",
      "    12.97            9.41\n",
      "    23.60           19.30\n",
      "    1.61            0.59\n",
      "    59.48           50.83\n",
      "    -2.00           -2.79\n",
      "    -59.50          -49.32\n",
      "    17.41           13.95\n",
      "    5.32            3.34\n",
      "    -11.62          -10.80\n",
      "    -1.50           -1.98\n",
      "    6.62            4.63\n",
      "    -38.38          -32.90\n",
      "    5.56            3.71\n",
      "    3.52            1.95\n",
      "    -15.09          -13.78\n",
      "    8.21            7.02\n",
      "    -18.45          -16.42\n",
      "    0.49           -0.65\n",
      "    -34.96          -30.06\n",
      "    -9.92           -9.72\n",
      "    -11.66          -10.88\n",
      "    -60.82          -50.78\n",
      "    24.77           20.31\n",
      "    -0.53           -2.54\n",
      "    15.80           12.60\n",
      "    -58.46          -48.85\n",
      "    -19.71          -17.55\n",
      "    -1.14           -2.02\n",
      "    -0.86           -1.73\n",
      "    -7.43           -7.32\n",
      "    47.30           40.10\n",
      "    -37.69          -32.22\n",
      "    -9.28           -8.85\n",
      "    20.84           18.17\n",
      "    -35.09          -30.05\n",
      "    -51.54          -43.27\n",
      "    -8.44           -8.05\n",
      "    50.20           42.59\n",
      "    -8.12           -7.95\n",
      "    -35.66          -30.72\n",
      "    0.90           -0.13\n",
      "    29.77           24.73\n",
      "    -24.22          -21.25\n",
      "    21.29           17.14\n",
      "    -0.53           -1.47\n",
      "    -1.43           -2.45\n",
      "    -38.75          -33.05\n",
      "    13.46           10.41\n",
      "    -5.56           -5.63\n",
      "    -8.26           -8.96\n",
      "    58.16           49.74\n",
      "    5.37            3.56\n",
      "    -0.02           -1.05\n",
      "    -34.82          -29.67\n",
      "    31.16           26.20\n",
      "    9.78            7.34\n",
      "    10.68            7.48\n",
      "    -3.19           -3.99\n",
      "    -31.62          -27.18\n",
      "    -43.34          -36.78\n",
      "    -3.13           -3.71\n",
      "    -1.40          -55.26\n",
      "    28.46           23.46\n",
      "    37.54           31.53\n",
      "    1748.60         1703.94\n",
      "    -40.51          -34.23\n",
      "    70.50           60.79\n",
      "    1.21            0.09\n",
      "    -16.95          -15.37\n",
      "    21.28           17.29\n",
      "    11.75            8.95\n",
      "    -7.07           -7.06\n",
      "    10.96            8.52\n",
      "    0.79           -0.51\n",
      "    16.91           12.05\n",
      "    -27.36          -23.86\n",
      "    -36.13          -30.92\n",
      "    6.40            4.43\n",
      "    -22.19          -19.61\n",
      "    17.10           13.65\n",
      "    3.54            0.70\n",
      "    33.94           28.35\n",
      "    7.34            5.29\n",
      "    7.36            5.23\n",
      "    -0.42           -1.42\n",
      "    -27.99          -24.30\n",
      "    -1.22           -2.91\n",
      "    -42.75          -36.39\n",
      "    2.11            0.50\n",
      "    -75.89          -62.36\n",
      "    1.27           -0.34\n",
      "    4.08            2.48\n",
      "    -5.99           -6.00\n",
      "    31.72           26.41\n",
      "    -3.17            6.28\n",
      "    -21.44          -19.27\n",
      "    24.83           20.37\n",
      "    33.57           28.15\n",
      "    -1.71           -2.54\n",
      "    47.52           40.35\n",
      "    13.50           10.54\n",
      "    -14.64          -13.38\n",
      "    -32.39          -27.90\n",
      "    -6.27           -6.51\n",
      "    -3.13           -3.62\n",
      "    -12.17          -11.16\n",
      "    -12.71          -11.31\n",
      "    4.52            2.78\n",
      "    13.86           10.54\n",
      "    27.20           22.46\n",
      "    21.65           26.35\n",
      "    6.29            3.11\n",
      "    -2.07           -2.61\n",
      "    28.74           23.81\n",
      "    10.70            8.28\n",
      "    20.60           16.60\n",
      "    -14.91          -13.62\n",
      "    -3.03           -3.48\n",
      "    9.24            8.20\n",
      "    4.89            3.27\n",
      "    0.35           -0.54\n",
      "    -9.71           -9.27\n",
      "    -37.71          -32.51\n",
      "    -5.56           -5.64\n",
      "    -0.79           -1.76\n",
      "    37.03           31.23\n",
      "    -7.43           -7.27\n",
      "    -30.19          -26.18\n",
      "    -21.01          -18.81\n",
      "    16.19           12.91\n",
      "    -36.86          -31.48\n",
      "    13.13           10.18\n",
      "    -1.83           -2.58\n",
      "    16.20           12.55\n",
      "    -6.91           -6.81\n",
      "    -42.15          -35.89\n",
      "    11.07            8.30\n",
      "    17.95           14.56\n",
      "    13.20           10.22\n",
      "    -18.38          -16.13\n",
      "    -14.91          -14.02\n",
      "    10.15            7.65\n",
      "    -15.52          -19.47\n",
      "    0.83            0.25\n",
      "    -2.50           -3.18\n",
      "    -21.36          -18.87\n",
      "    -11.43          -10.67\n",
      "    -9.82           -9.60\n",
      "    -3.15           -3.78\n",
      "    -14.49          -18.49\n",
      "    -19.27          -17.25\n",
      "    -3.85           -4.29\n",
      "    -19.85          -17.24\n",
      "    -19.53          -17.37\n",
      "    -31.75          -27.18\n",
      "    10.49            7.96\n",
      "    24.69           20.31\n",
      "    -66.04          -54.86\n",
      "    -0.62           -2.00\n",
      "    -3.41           -3.95\n",
      "    -3.24           -6.40\n",
      "    34.86           29.27\n",
      "    9.86            7.40\n",
      "    9.51            7.21\n",
      "    2.86            1.44\n",
      "    1.10           -1.28\n",
      "    -30.00          -25.96\n",
      "    6.68            4.77\n",
      "    -23.61          -20.91\n",
      "    -39.82          -34.14\n",
      "    0.55           -0.97\n",
      "    -22.01          -19.44\n",
      "    -2.56           -3.18\n",
      "    -11.47          -10.68\n",
      "    -4.83           -4.88\n",
      "    -9.29           -8.92\n",
      "    -23.08          -20.41\n",
      "    -39.45          -33.84\n",
      "    23.92           19.30\n",
      "    -67.26          -55.69\n",
      "    -5.85           -5.87\n",
      "    4.86            3.12\n",
      "    -6.67           -6.68\n",
      "    -11.64          -10.82\n",
      "    0.79           -0.40\n",
      "    2.41            1.05\n",
      "    14.19           10.86\n",
      "    1.42            0.26\n",
      "    -33.96          -29.26\n",
      "    -26.69          -23.24\n",
      "    -13.83          -12.98\n",
      "    -39.62          -33.56\n",
      "    -17.17          -15.42\n",
      "    -28.27          -24.60\n",
      "    10.74            8.30\n",
      "    39.21           32.86\n",
      "    -12.18          -11.51\n",
      "    -12.77          -11.31\n",
      "    6.24            4.29\n",
      "    -0.37           -2.22\n",
      "    0.77           -0.34\n",
      "    37.81           31.11\n",
      "    -19.48          -17.52\n",
      "    -43.48          -37.04\n",
      "    -5.37           -5.63\n",
      "    25.52           21.01\n",
      "    19.94           15.68\n",
      "    -46.08          -38.75\n",
      "    -21.62          -19.15\n",
      "    -12.32           -6.20\n",
      "    -16.30          -14.72\n",
      "    67.86           58.40\n",
      "    -10.73          -10.04\n",
      "    34.33           28.70\n",
      "    -19.33          -17.07\n",
      "    -25.79          -23.52\n",
      "    -21.28          -18.94\n",
      "    -21.52          -19.02\n",
      "    -6.12          -13.44\n",
      "    -40.74          -34.81\n",
      "    11.34            8.50\n",
      "    4.52            2.81\n",
      "    12.27            9.48\n",
      "    -1.01           -1.91\n",
      "    8.68            6.46\n",
      "    -21.98          -19.47\n",
      "    0.79           -0.40\n",
      "    3.58            1.99\n",
      "    -26.39          -23.12\n",
      "    -2.87           -3.51\n",
      "    34.36           28.71\n",
      "    171.79          152.02\n",
      "    24.69           20.30\n",
      "    0.31           -0.63\n",
      "    -19.66          -17.43\n",
      "    28.65           23.76\n",
      "    57.94           49.79\n",
      "    -19.07          -17.07\n",
      "    5.29            3.61\n",
      "    8.72            6.39\n",
      "    -17.27          -15.45\n",
      "    -23.82          -21.01\n",
      "    2.85            1.26\n",
      "    29.21           24.16\n",
      "    -5.25           -5.55\n",
      "    -3.98           -4.48\n",
      "    -26.73          -23.19\n",
      "    11.93            9.16\n",
      "    -12.68          -11.68\n",
      "    25.48           21.16\n",
      "    -4.31           -4.57\n",
      "    -26.21          -22.84\n",
      "    10.75            7.80\n",
      "    -5.26           -5.35\n",
      "    25.07           20.47\n",
      "    4.02            2.43\n",
      "    -3.72           -3.69\n",
      "    1.76           -1.04\n",
      "    -33.11          -28.61\n",
      "    3.47            1.89\n",
      "    -19.01          -17.00\n",
      "    -25.81          -22.49\n",
      "    -13.81          -13.05\n",
      "    -28.15          -24.58\n",
      "    -30.14          -26.27\n",
      "    24.76           20.39\n",
      "    45.06           38.42\n",
      "    9.63            7.29\n",
      "    -4.91           -5.07\n",
      "    -6.04          -10.09\n",
      "    -49.34          -41.32\n",
      "    6.57            4.46\n",
      "    -30.70          -26.56\n",
      "    15.48           12.19\n",
      "    60.09           52.23\n",
      "    -2.92           -3.50\n",
      "    12.62            9.66\n",
      "    -30.43          -26.42\n",
      "    62.42           52.95\n",
      "    -58.84          -49.00\n",
      "    21.47           17.26\n",
      "    -33.40          -28.78\n",
      "    11.10            8.45\n",
      "    7.26            7.08\n",
      "    24.71           20.26\n",
      "    23.08           18.88\n",
      "    -10.52           -9.78\n",
      "    11.21            7.83\n",
      "    -1.36           -2.21\n",
      "    -4.27           15.15\n",
      "    -18.55          -16.41\n",
      "    -1.25           -2.17\n",
      "    -25.48          -22.34\n",
      "    -5.32           -5.59\n",
      "    -2.28           -2.97\n",
      "    0.85           -0.56\n",
      "    -0.66           -1.46\n",
      "    3.09            0.47\n",
      "    -22.30          -19.88\n",
      "    29.17           24.19\n",
      "    -25.36          -22.08\n",
      "    -14.33          -13.02\n",
      "    4.67            2.99\n",
      "    -27.46          -23.97\n",
      "    -15.46          -13.91\n",
      "    -65.32          -54.24\n",
      "    18.34           14.60\n",
      "    -1.38           -2.32\n",
      "    6.56            4.56\n",
      "    28.11           23.34\n",
      "    7.92            5.90\n",
      "    -25.98          -22.73\n",
      "    -8.46           -8.26\n",
      "    2.07            0.70\n",
      "    -52.87          -44.30\n",
      "    1.71            0.50\n",
      "    -0.71           -1.54\n",
      "    -7.43           -7.34\n",
      "    -12.71          -11.80\n",
      "    -38.08          -32.65\n",
      "    4.51            2.86\n",
      "    9.99            7.46\n",
      "    5.89            1.83\n",
      "    7.80            5.77\n",
      "    -26.12          -22.96\n",
      "    -24.36          -34.09\n",
      "    -10.88          -10.39\n",
      "    12.08            9.36\n",
      "    -55.08          -46.19\n",
      "    7.73            5.99\n",
      "    66.84           57.28\n",
      "    14.29           11.29\n",
      "    17.62           14.08\n",
      "    -9.15           -8.72\n",
      "    94.47           82.26\n",
      "    52.29           44.53\n",
      "    -8.13           -7.92\n",
      "    21.28           17.31\n",
      "    18.83           15.53\n",
      "    8.35            6.09\n",
      "    9.45            7.07\n",
      "    7.49            5.33\n",
      "    19.73           15.94\n",
      "    31.36           26.27\n",
      "    -5.57           -5.63\n",
      "    -5.10           -5.21\n",
      "    -6.11           -6.23\n",
      "    17.41           13.06\n",
      "    2414.81         2333.07\n",
      "    1057.89         1063.40\n",
      "    -0.51           -1.57\n",
      "    -12.55          -11.63\n",
      "    91.15           79.24\n",
      "    4.03            2.37\n",
      "    9.94            7.04\n",
      "    -13.25          -12.18\n",
      "    -33.64          -27.25\n",
      "    -11.27          -10.38\n",
      "    -14.07          -13.01\n",
      "    63.32           54.27\n",
      "    16.88           13.50\n",
      "    -26.55          -23.26\n",
      "    -40.03          -34.16\n",
      "    -51.69          -38.86\n",
      "    -30.90          -26.67\n",
      "    -12.39          -11.70\n",
      "    -28.00          -24.20\n",
      "    -13.00          -11.93\n",
      "    14.87           11.74\n",
      "    -0.65           -1.41\n",
      "    -15.27          -13.95\n",
      "    -58.29          -48.63\n",
      "    -23.01          -20.04\n",
      "    -34.61          -29.75\n",
      "    -10.52          -10.01\n",
      "    -8.02           -7.82\n",
      "    -25.90          -22.74\n",
      "    -20.67          -18.21\n",
      "    -7.46           -7.01\n",
      "    0.58           -0.48\n",
      "    16.97           15.96\n",
      "    17.62            9.40\n",
      "    19.48           15.72\n",
      "    -0.57           -1.53\n",
      "    -23.40          -20.79\n",
      "    64.39           55.32\n",
      "    -40.01          -33.99\n",
      "    -13.33          -12.36\n",
      "    -9.78           -7.78\n",
      "    -6.39           -6.50\n",
      "    32.08           26.84\n",
      "    -26.81          -23.49\n",
      "    2.45           -0.45\n",
      "    11.78            9.78\n",
      "    5.70            3.79\n",
      "    -6.09           -6.53\n",
      "    124.85          109.28\n",
      "    5.48            3.71\n",
      "    -33.55          -28.70\n",
      "    -10.46           -9.80\n",
      "    72.15           61.29\n",
      "    0.55           -0.58\n",
      "    14.71           11.55\n",
      "    0.83           -0.36\n",
      "    -11.17          -10.36\n",
      "    -22.81          -20.10\n",
      "    -31.71          -27.40\n",
      "    27.08           22.23\n",
      "    40.89           34.53\n",
      "    0.25           -0.68\n",
      "    40.85           34.57\n",
      "    -7.22           -3.31\n",
      "    -29.44          -25.30\n",
      "    17.25           13.61\n",
      "    -6.45           -6.92\n",
      "    -32.84          -28.45\n",
      "    2.78            1.86\n",
      "    -27.41          -23.83\n",
      "    -15.00          -13.67\n",
      "    -14.23          -13.05\n",
      "    -16.48          -14.62\n",
      "    -9.79           -9.33\n",
      "    -1.34           -2.11\n",
      "    -4.58           -4.92\n",
      "    19.09           15.43\n",
      "    3.94            2.45\n",
      "    13.11            9.75\n",
      "    145.04          127.54\n",
      "    83.56           72.49\n",
      "    20.78           17.00\n",
      "    22.40           17.84\n",
      "    -0.37           -1.27\n",
      "    -3.95           -4.31\n",
      "    -3.74           -4.36\n",
      "    -1.99           -2.54\n",
      "    -5.91           -5.97\n",
      "    -29.39          -25.37\n",
      "    -1.30           -1.84\n",
      "    -23.44          -20.38\n",
      "    -6.77           -6.68\n",
      "    -17.43          -15.63\n",
      "    40.34           33.75\n",
      "    17.03           13.56\n",
      "    10.95            8.33\n",
      "    3.51            1.69\n",
      "    25.00           20.95\n",
      "    -8.11           -7.92\n",
      "    -1.77           -2.51\n",
      "    14.59           11.62\n",
      "    227.27          202.44\n",
      "    14.00           10.85\n",
      "    -1.85           -2.68\n",
      "    -18.72          -16.71\n",
      "    20.36           16.57\n",
      "    -13.13          -12.04\n",
      "    -8.42           -8.01\n",
      "    6.18            4.47\n",
      "    -19.36          -17.36\n",
      "    10.52            7.50\n",
      "    5.36            0.63\n",
      "    -25.03          -21.93\n",
      "    12.95           10.16\n",
      "    -12.06          -10.37\n",
      "    10.48            7.85\n",
      "    119.36          104.46\n",
      "    -18.77          -16.71\n",
      "    -23.92          -21.09\n",
      "    3.47            2.30\n",
      "    7.10            5.03\n",
      "    -28.71          -25.02\n",
      "    4.96            3.27\n",
      "    30.91           25.40\n",
      "    2029.60         1980.28\n",
      "    19.39           15.52\n",
      "    -24.91          -21.74\n",
      "    3.19            1.64\n",
      "    -21.06          -18.76\n",
      "    -5.75           -6.68\n",
      "    29.25           24.02\n",
      "    26.80           22.14\n",
      "    -21.22          -19.09\n",
      "    -1.13           -2.34\n",
      "    19.00           15.27\n",
      "    -0.93           -1.78\n",
      "    -39.55          -33.79\n",
      "    8.43            6.15\n",
      "    13.25           10.35\n",
      "    -14.88          -13.58\n",
      "    -18.60          -16.52\n",
      "    -67.35          -55.62\n",
      "    2.46            1.07\n",
      "    29.15           24.21\n",
      "    2.84            0.03\n",
      "    145.11          121.29\n",
      "    -53.09          -44.63\n",
      "    10.38            7.56\n",
      "    -59.48          -49.61\n",
      "    6.73            4.62\n",
      "    -23.69          -20.80\n",
      "    112.57           98.57\n",
      "    1.89            0.63\n",
      "    84.36           73.00\n",
      "    42.42           35.81\n",
      "    30.85           25.76\n",
      "    10.65            8.23\n",
      "    55.92           48.06\n",
      "    9.62            7.22\n",
      "    1.46           -0.12\n",
      "    3.84            1.56\n",
      "    19.85           16.38\n",
      "    34.56           28.92\n",
      "    -45.77          -38.48\n",
      "    -14.66          -12.71\n",
      "    6.21            4.17\n",
      "    -23.46          -20.48\n",
      "    -15.27          -13.64\n",
      "    83.48           72.24\n",
      "    3.27            1.82\n",
      "    -3.57           -4.32\n",
      "    -4.92           -5.32\n",
      "    -3.52           -4.04\n",
      "    5.99            4.13\n",
      "    -8.24           -7.98\n",
      "    13.04           10.17\n",
      "    4.25            2.59\n",
      "    -47.98          -40.61\n",
      "    -1.07           -4.92\n",
      "    11.50            8.87\n",
      "    -35.90          -30.85\n",
      "    -2.12           -2.93\n",
      "    -8.13           -8.01\n",
      "    -23.69          -20.86\n",
      "    -20.31          -18.07\n",
      "    10.73            8.26\n",
      "    40.32           33.96\n",
      "    -29.96          -25.00\n",
      "    43.21           36.07\n",
      "    11.92            9.11\n",
      "    -6.40           -6.80\n",
      "    1.56            0.14\n",
      "    3.16           20.82\n",
      "    -5.11           -5.33\n",
      "    -18.30          -17.06\n",
      "    7.48            5.66\n",
      "    13.96           11.59\n",
      "    -22.52          -19.94\n",
      "    -40.35          -34.47\n",
      "    17.75           14.25\n",
      "    -10.00           -9.55\n",
      "    -7.19           -6.96\n",
      "    78.04           67.42\n",
      "    -46.83          -39.66\n",
      "    13.78           11.09\n",
      "    6.68            4.50\n",
      "    1.33            0.11\n",
      "    72.27           62.24\n",
      "    12.73            9.92\n",
      "    -11.95          -11.08\n",
      "    -7.67           -7.42\n",
      "    -20.72          -18.43\n",
      "    3.78            6.07\n",
      "    1.16           -0.11\n",
      "    -12.30          -11.26\n",
      "    -20.63          -18.17\n",
      "    5.82          -10.43\n",
      "    3.48            1.98\n",
      "    8.80            6.61\n",
      "    -15.61          -14.36\n",
      "    -2.99           -3.66\n",
      "    27.06           22.55\n",
      "    3.01            1.49\n",
      "    -26.36          -23.08\n",
      "    -5.97           -6.27\n",
      "    -3.33           -3.84\n",
      "    2.94            1.47\n",
      "    6.51            4.52\n",
      "    -1.88           -2.46\n",
      "    -10.01           -9.76\n",
      "    -0.60           -1.56\n",
      "    -12.03          -11.16\n",
      "    -1.34           -2.07\n",
      "    14.08            9.89\n",
      "    17.43           15.25\n",
      "    17.80           14.29\n",
      "    -45.95          -39.03\n",
      "    -30.84          -27.33\n",
      "    -12.83          -11.94\n",
      "    0.41           -0.79\n",
      "    -10.53           -9.93\n",
      "    -0.72           -1.50\n",
      "    2.64            1.27\n",
      "    2.70            1.31\n",
      "    -5.46           -5.72\n",
      "    -41.15          -34.95\n",
      "    -14.73          -13.66\n",
      "    24.15           19.80\n",
      "    -4.80           -5.11\n",
      "    298.36          268.44\n",
      "    -31.90          -27.41\n",
      "    -12.61          -11.74\n",
      "    -28.92          -25.15\n",
      "    -41.14          -34.98\n",
      "    196.82          174.59\n",
      "    6.27            4.35\n",
      "    -19.44          -17.17\n",
      "    26.67           22.09\n",
      "    -5.94           -6.09\n",
      "    13.65           10.66\n",
      "    1.75            0.48\n",
      "    -0.85           -1.75\n",
      "    55.31           47.07\n",
      "    -13.99          -12.91\n",
      "    -4.37           -4.77\n",
      "    -2.51           -3.16\n",
      "    3.46            1.87\n",
      "    -42.37          -35.94\n",
      "    9.19            6.80\n",
      "    7.92            5.74\n",
      "    3.24            1.79\n",
      "    9.27            6.69\n",
      "    3.10            1.71\n",
      "    1.11           -0.13\n",
      "    -19.61          -17.23\n",
      "    14.38           11.32\n",
      "    2.11           -0.99\n",
      "    -73.08          -60.27\n",
      "    11.17            8.54\n",
      "    416.83          379.23\n",
      "    -61.59          -50.90\n",
      "    20.56           16.65\n",
      "    7.80            5.21\n",
      "    4.39            2.75\n",
      "    -42.64          -36.29\n",
      "    1.35           -3.18\n",
      "    -3.16           -3.70\n",
      "    -14.24          -12.28\n",
      "    92.27           80.06\n",
      "    -5.30           -5.50\n",
      "    1.64            0.42\n",
      "    -7.93           -7.81\n",
      "    -5.64           -5.81\n",
      "    -5.98           -5.97\n",
      "    0.78           -0.28\n",
      "    27.34           22.64\n",
      "    4.18            2.40\n",
      "    14.23           11.03\n",
      "    15.90           12.58\n",
      "    16.57           13.24\n",
      "    -29.49          -25.48\n",
      "    46.30           39.18\n",
      "    11.39            8.77\n",
      "    -40.00          -33.79\n",
      "    90.59           78.63\n",
      "    2.30            1.02\n",
      "    -8.96           -8.93\n",
      "    3.65            2.02\n",
      "    -22.58          -19.98\n",
      "    -26.95          -23.34\n",
      "    -27.56          -24.09\n",
      "    -0.82           -1.75\n",
      "    -19.15          -17.08\n",
      "    -31.49          -27.26\n",
      "    -9.78           -9.39\n",
      "    -5.75           -5.92\n",
      "    4.17            2.57\n",
      "    -14.85          -15.54\n",
      "    -13.97          -12.79\n",
      "    24.50           19.76\n",
      "    30.28           25.11\n",
      "    -11.36          -10.65\n",
      "    13.19           10.42\n",
      "    9.45            7.10\n",
      "    -35.48          -30.26\n",
      "    2.34            0.83\n",
      "    -3.82           -4.32\n",
      "    16.31           14.42\n",
      "    1.45           -0.45\n",
      "    -17.10          -14.36\n",
      "    -13.41          -12.35\n",
      "    72.14           62.27\n",
      "    -29.55          -25.48\n",
      "    3.47            1.92\n",
      "    -28.02          -24.34\n",
      "    27.27           22.61\n",
      "    -22.61          -20.00\n",
      "    -7.56           -7.69\n",
      "    -14.64          -13.40\n",
      "    -16.52          -14.98\n",
      "    -38.69          -33.05\n",
      "    -17.07          -15.43\n",
      "    30.45           25.31\n",
      "    -21.19          -18.71\n",
      "    -3.40           -3.90\n",
      "    30.71           25.40\n",
      "    39.76           33.53\n",
      "    -16.29          -15.02\n",
      "    -0.93           -1.82\n",
      "    -8.92           -8.59\n",
      "    5.98            1.78\n",
      "    -55.65          -46.71\n",
      "    -27.67          -24.00\n",
      "    -11.23          -10.64\n",
      "    -30.65          -26.52\n",
      "    -15.55          -14.03\n",
      "    -31.84          -27.39\n",
      "    12.94           10.02\n",
      "    -29.17          -25.38\n",
      "    18.23           14.84\n",
      "    13.40           10.40\n",
      "    -17.25          -15.54\n"
     ]
    }
   ],
   "source": [
    "print('Test values:    Predicted values:')\n",
    "for r,p in zip(true_y_test.flatten(),predicted_y_test.flatten()):\n",
    "    print(f'    {r:.2f}    {p:>12.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
