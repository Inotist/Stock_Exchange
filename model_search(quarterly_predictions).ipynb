{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí utilizo todos los datos de los informes trimestrales para entrenar a un modelo que sea capaz de realizar predicciones trimestre a trimestre. De esta manera, y junto con el resto de predicciones, en aquellos casos en que todos apunten en la misma dirección, podría sentir cierta seguridad de que las predicciones van \"en el buen camino\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tercer Modelo. Predicciones trimestrales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comienzo como siempre importando los módulo que voy a utilizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from joblib import dump\n",
    "\n",
    "import keras\n",
    "from keras.engine import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, concatenate\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí los chunks tendrán un tamaño de cuatro (4 trimestres = 1 año). Más me parecía excesivo y además acabaría con muchas menos entradas con las que poder entrenar al modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequence for the LSTM network\n",
    "backlook = 4\n",
    "\n",
    "# Size of data split for testing\n",
    "train_size = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargo los datos de todas aquellas empresas que tengan al menos 5 informes trimestrales, elimino las columnas referentes a la moneda para quedarme únicamente con los datos numéricos, y junto los datos en bloques de 4 ordenados por fecha.\n",
    "\n",
    "Al mismo tiempo, me creo otras dos listas, una de ellas tendrá los datos sobre el trimestre cuya variable objetivo tenemos que predecir (nexus_li), y la otra tendrá los valores que el modelo tiene que aprender a predecir (y_vals).\n",
    "\n",
    "El objetivo es tener algo así (perdón por usar el horrible paint pero no quería complicarme de más):\n",
    "![alt text](./quarterly-model-illustration.png \"Esquema\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './datasets/fundamental_data'\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "time_li = []\n",
    "nexus_li = []\n",
    "y_vals = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0).sort_values(by='fiscalDateEnding')\n",
    "    \n",
    "    if len(df) > 4:\n",
    "        df = df.drop(columns=['Unnamed: 0', 'fiscalDateEnding', 'reportedCurrency_x', 'reportedCurrency_y', 'reportedCurrency'])\n",
    "        df = df.replace('None', 0).fillna(0)\n",
    "        df = df[df['nextClossingVal'] != 0]\n",
    "        \n",
    "        for i in range(len(df)-backlook):\n",
    "            time_li.append(df.iloc[i:i+backlook])\n",
    "            y_vals.append(df.iloc[[i+backlook]]['nextClossingVal'].values[0])\n",
    "            nexus_li.append(df.drop(columns='nextClossingVal').iloc[[i+backlook]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso los datos a numpy para empezar a trabajar con ellos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_arr = np.zeros((len(time_li), 4, 100))\n",
    "nexus_arr = np.zeros((len(time_li), 99))\n",
    "y_arr = np.array(y_vals).reshape(-1, 1)\n",
    "\n",
    "for i in range(len(time_li)):\n",
    "    time_arr[i] = time_li[i].to_numpy()\n",
    "    nexus_arr[i] = nexus_li[i].to_numpy().reshape(99,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separo en train y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test split\n",
    "split = int(len(time_arr) * train_size)\n",
    "\n",
    "train_time = time_arr[:split]\n",
    "train_nexus = nexus_arr[:split]\n",
    "train_y = y_arr[:split]\n",
    "\n",
    "test_time = time_arr[split:]\n",
    "test_nexus = nexus_arr[split:]\n",
    "test_y = y_arr[split:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizo y me guardo los normalizadores para cuando despliegue el modelo en google cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise series\n",
    "time_normaliser = preprocessing.MinMaxScaler()\n",
    "train_time = time_normaliser.fit_transform(train_time.reshape(train_time.shape[0]*train_time.shape[1], train_time.shape[2])).reshape(train_time.shape)\n",
    "test_time = time_normaliser.transform(test_time.reshape(test_time.shape[0]*test_time.shape[1], test_time.shape[2])).reshape(test_time.shape)\n",
    "\n",
    "# Normalise nexus\n",
    "nexus_normaliser = preprocessing.MinMaxScaler()\n",
    "train_nexus = nexus_normaliser.fit_transform(train_nexus)\n",
    "test_nexus = nexus_normaliser.transform(test_nexus)\n",
    "\n",
    "# Y normaliser\n",
    "y_normaliser = preprocessing.MinMaxScaler()\n",
    "train_y = y_normaliser.fit_transform(train_y)\n",
    "test_y = y_normaliser.transform(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./normalisers/fundamental_y_normaliser.joblib']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save scalers for future use\n",
    "dump(time_normaliser, './normalisers/fundamental_x-time_normaliser.joblib')\n",
    "dump(nexus_normaliser, './normalisers/fundamental_x-nexus_normaliser.joblib')\n",
    "dump(y_normaliser, './normalisers/fundamental_y_normaliser.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_complex(x_time, x_nexus, y, batch_size=512, epochs=24, **params):\n",
    "    \n",
    "    # List of parameters\n",
    "    if 'lstmsize' not in params: params['lstmsize'] = x_time.shape[1]\n",
    "    if 'density' not in params: params['density'] = x_nexus.shape[1]\n",
    "    if 'merge_density' not in params: params['merge_density'] = int((params['lstmsize']//1.5)*2) + x_nexus.shape[1]\n",
    "    if 'activation' not in params: params['activation'] = 'relu'\n",
    "    if 'twice' not in params: params['twice'] = False\n",
    "    if 'optimizer' not in params: params['optimizer'] = 'adam'\n",
    "    if 'shuffle' not in params: params['shuffle'] = False\n",
    "        \n",
    "    # Time model definition\n",
    "    model_time = Sequential()\n",
    "    \n",
    "    model_time.add(LSTM(params['lstmsize'], input_shape=x_time.shape[1:], return_sequences=params['twice']))\n",
    "    \n",
    "    if 'dropout' in params:\n",
    "        model_time.add(Dropout(params['dropout']))\n",
    "    \n",
    "    if params['twice']:\n",
    "        model_time.add(LSTM(params['lstmsize']))\n",
    "        \n",
    "        if 'dropout' in params:\n",
    "            model_time.add(Dropout(params['dropout']))\n",
    "    \n",
    "    # Nexus model definition\n",
    "    model_nexus = Sequential()\n",
    "    \n",
    "    model_nexus.add(Dense(params['density'], input_shape=(99,), activation=params['activation']))\n",
    "    \n",
    "    # Ending pipe\n",
    "    model = concatenate([model_time.output, model_nexus.output])\n",
    "    \n",
    "    model = Dense(params['merge_density'], activation=params['activation'])(model)\n",
    "    \n",
    "    if 'full_density' in params and params['full_density']:\n",
    "        density = params['merge_density']//2\n",
    "        while density >= 12:\n",
    "            model = Dense(density, activation=params['activation'])(model)\n",
    "            density //= 2\n",
    "            \n",
    "    model = Dense(1, activation='linear')(model)\n",
    "    \n",
    "    model = Model([model_time.input, model_nexus.input], model)\n",
    "    \n",
    "    model.compile(loss='mse', optimizer=params['optimizer'])\n",
    "    \n",
    "    if 'callbacks' in params:\n",
    "        callback = model.fit(x=[x_time, x_nexus], y=y, validation_split=0.1, batch_size=batch_size, epochs=epochs, shuffle=params['shuffle'],\n",
    "                            callbacks=params['callbacks'])\n",
    "    else:\n",
    "        callback = model.fit(x=[x_time, x_nexus], y=y, validation_split=0.1, batch_size=batch_size, epochs=epochs, shuffle=params['shuffle'])\n",
    "    \n",
    "    return [model, callback, params]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evolutive algorith to search for the most optimal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_genes(x_time, x_nexus, y, population_size, population=[]):\n",
    "    if population_size-len(population) < 0:\n",
    "        print('population size must be greater or equal than actual population')\n",
    "        return\n",
    "    \n",
    "    if len(population) > 0:\n",
    "        if len(population) < 3:\n",
    "            print('population should be empty or 3 at least')\n",
    "            return\n",
    "        \n",
    "        population[2] = breed_genes(x_time, x_nexus, y, population[0][2].copy())\n",
    "        population[1] = breed_genes(x_time, x_nexus, y, combine=(population[0][2], population[1][2]))\n",
    "        population = population[:3]\n",
    "    \n",
    "    for _ in range(population_size-len(population)):\n",
    "        subject = breed_genes(x_time, x_nexus, y)\n",
    "        population.append(subject)\n",
    "        \n",
    "    return population\n",
    "\n",
    "def breed_genes(x_time, x_nexus, y, genes={}, combine=None):\n",
    "    genes['x_time'] = x_time\n",
    "    genes['x_nexus'] = x_nexus\n",
    "    genes['y'] = y\n",
    "    \n",
    "    if type(combine) is list or type(combine) is tuple:\n",
    "        genes['lstmsize'] = combine[np.random.randint(0,2)]['lstmsize']\n",
    "        genes['density'] = combine[np.random.randint(0,2)]['density']\n",
    "        genes['merge_density'] = combine[np.random.randint(0,2)]['merge_density']\n",
    "        genes['activation'] = combine[np.random.randint(0,2)]['activation']\n",
    "        genes['twice'] = combine[np.random.randint(0,2)]['twice']\n",
    "        genes['optimizer'] = combine[np.random.randint(0,2)]['optimizer']\n",
    "        genes['shuffle'] = combine[np.random.randint(0,2)]['shuffle']\n",
    "        \n",
    "        genes['dropout'] = combine[np.random.randint(0,2)].get('dropout')\n",
    "        if genes['dropout'] is None: del genes['dropout']\n",
    "        genes['full_density'] = combine[np.random.randint(0,2)].get('full_density')\n",
    "        if genes['full_density'] is None: del genes['full_density']\n",
    "            \n",
    "    else:\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['lstmsize'] = int((np.random.randint(x_time.shape[1],x_time.shape[1]*2)//2)*2)\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['density'] = int((np.random.randint(x_nexus.shape[1]//2,x_nexus.shape[1]*2.66)//2)*2)\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['merge_density'] = int((np.random.randint(x_time.shape[1]+(x_nexus.shape[1]//2),\n",
    "                                                            (x_time.shape[1]*2)+(x_nexus.shape[1]*2.66))//2)*2)\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            activation = [\n",
    "                'relu',\n",
    "                'sigmoid',\n",
    "                'softplus',\n",
    "                'softsign',\n",
    "                'tanh',\n",
    "                'selu',\n",
    "                'elu',\n",
    "                'exponential'\n",
    "            ]\n",
    "            genes['activation'] = activation[np.random.randint(0,8)]\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['twice'] = True\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            optimizer = [\n",
    "                'sgd',\n",
    "                'rmsprop',\n",
    "                'adam',\n",
    "                'adadelta',\n",
    "                'adagrad',\n",
    "                'adamax',\n",
    "                'nadam'\n",
    "            ]\n",
    "            genes['optimizer'] = optimizer[np.random.randint(0,7)]\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['shuffle'] = True\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['dropout'] = np.random.randint(1,4)/10\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['full_density'] = True\n",
    "            \n",
    "    new_model = build_complex(**genes)\n",
    "        \n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def breed_population(x_time, x_nexus, y, generations, population_size, population=[]):\n",
    "    \n",
    "    if generations > 1 and population_size < 3:\n",
    "        print('population size should be of a minimum of 3 for more than one generation')\n",
    "        return\n",
    "    \n",
    "    for g in range(generations):\n",
    "        print(f'\\nGENERATION {g}\\n')\n",
    "        population = set_genes(x_time, x_nexus, y, population_size, population)\n",
    "        population = sorted(population, key=lambda x: x[1].history['val_loss'][-1]+x[1].history['loss'][-1])\n",
    "        \n",
    "    return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GENERATION 0\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 2s 87us/step - loss: 0.0075 - val_loss: 3.5815e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 0s 22us/step - loss: 0.0012 - val_loss: 3.7740e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 8.2777e-04 - val_loss: 2.3965e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 0s 22us/step - loss: 6.8039e-04 - val_loss: 2.0667e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 0s 22us/step - loss: 5.4245e-04 - val_loss: 1.7795e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 0s 22us/step - loss: 4.2409e-04 - val_loss: 1.9066e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 0s 22us/step - loss: 3.4177e-04 - val_loss: 1.3676e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 0s 22us/step - loss: 2.6109e-04 - val_loss: 1.2664e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 0s 22us/step - loss: 2.1898e-04 - val_loss: 1.1174e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 0s 22us/step - loss: 1.8219e-04 - val_loss: 1.0392e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 0s 22us/step - loss: 1.1316e-04 - val_loss: 8.4852e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 0s 22us/step - loss: 1.1745e-04 - val_loss: 7.9014e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 1.1919e-04 - val_loss: 8.5108e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 1.0464e-04 - val_loss: 1.1512e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 0s 22us/step - loss: 8.4057e-05 - val_loss: 6.1677e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 7.2724e-05 - val_loss: 6.8793e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 0s 22us/step - loss: 5.4567e-05 - val_loss: 6.4202e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 8.1061e-05 - val_loss: 1.4792e-04\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 0s 22us/step - loss: 7.7842e-05 - val_loss: 8.0120e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 0s 22us/step - loss: 6.3458e-05 - val_loss: 9.5346e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 0s 22us/step - loss: 6.2188e-05 - val_loss: 5.7609e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 0s 22us/step - loss: 5.5924e-05 - val_loss: 5.6499e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 0s 22us/step - loss: 4.9255e-05 - val_loss: 5.0902e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 0s 22us/step - loss: 6.0582e-05 - val_loss: 7.2633e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 1s 63us/step - loss: 0.0035 - val_loss: 1.6317e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 4.3269e-04 - val_loss: 9.8327e-05\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 2.1177e-04 - val_loss: 5.2668e-05\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 1.1304e-04 - val_loss: 4.0761e-05\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 7.9828e-05 - val_loss: 4.6126e-05\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 7.9837e-05 - val_loss: 1.2781e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 6.5685e-05 - val_loss: 4.0109e-05\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 6.4287e-05 - val_loss: 4.4350e-05\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 5.1437e-05 - val_loss: 3.4079e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 0s 22us/step - loss: 4.8367e-05 - val_loss: 3.3213e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 4.9607e-05 - val_loss: 3.1740e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 4.8019e-05 - val_loss: 3.0954e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 6.2488e-05 - val_loss: 4.0823e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 5.4992e-05 - val_loss: 6.0188e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 5.5183e-05 - val_loss: 4.4458e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 4.5259e-05 - val_loss: 1.1638e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 8.1038e-05 - val_loss: 4.0033e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 5.6985e-05 - val_loss: 7.7674e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 5.3437e-05 - val_loss: 3.8179e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 4.5904e-05 - val_loss: 4.6467e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 9.2770e-05 - val_loss: 6.6843e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 4.6083e-05 - val_loss: 2.9542e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 3.8841e-05 - val_loss: 4.2417e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 4.4707e-05 - val_loss: 3.2092e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 1s 66us/step - loss: 0.0048 - val_loss: 1.6843e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 0.0010 - val_loss: 1.9043e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 9.2206e-04 - val_loss: 1.3326e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 8.7319e-04 - val_loss: 1.4229e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 8.2895e-04 - val_loss: 1.2263e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 7.8025e-04 - val_loss: 1.2104e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 6.8816e-04 - val_loss: 1.0108e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 5.3941e-04 - val_loss: 9.3784e-05\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 3.7219e-04 - val_loss: 9.7820e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 3.0893e-04 - val_loss: 5.3296e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 2.4703e-04 - val_loss: 4.6864e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 2.1416e-04 - val_loss: 3.9218e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 1.5478e-04 - val_loss: 4.0550e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 1.6213e-04 - val_loss: 4.0266e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 1.4020e-04 - val_loss: 5.9316e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 1.5139e-04 - val_loss: 3.9768e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 1.1511e-04 - val_loss: 4.2002e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 1.3902e-04 - val_loss: 5.4910e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 1.2615e-04 - val_loss: 5.1568e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 1.2205e-04 - val_loss: 3.6916e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 8.9974e-05 - val_loss: 3.2176e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 0s 22us/step - loss: 1.3402e-04 - val_loss: 4.6121e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 1.0993e-04 - val_loss: 3.2944e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 9.8567e-05 - val_loss: 1.1670e-04\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 0.0075 - val_loss: 8.9513e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 0s 22us/step - loss: 0.0011 - val_loss: 2.0076e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 0s 22us/step - loss: 8.1905e-04 - val_loss: 1.4458e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 7.5438e-04 - val_loss: 1.2039e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 6.8055e-04 - val_loss: 1.1281e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 6.1991e-04 - val_loss: 1.3070e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 5.6182e-04 - val_loss: 9.5041e-05\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 0s 22us/step - loss: 4.9753e-04 - val_loss: 8.5183e-05\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 0s 22us/step - loss: 4.1628e-04 - val_loss: 9.6690e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 2.7249e-04 - val_loss: 3.6045e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 1.9887e-04 - val_loss: 3.4081e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 1.6550e-04 - val_loss: 3.5312e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 1.2651e-04 - val_loss: 3.5728e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 1.1498e-04 - val_loss: 3.4650e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 0s 22us/step - loss: 9.9181e-05 - val_loss: 6.8197e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 1.0718e-04 - val_loss: 3.6831e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 8.0187e-05 - val_loss: 3.1302e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 6.2134e-05 - val_loss: 2.8788e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 9.6334e-05 - val_loss: 3.1093e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 0s 22us/step - loss: 9.2003e-05 - val_loss: 3.8999e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 6.9071e-05 - val_loss: 3.0702e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 7.4576e-05 - val_loss: 2.9829e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 5.6145e-05 - val_loss: 2.7120e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 0s 22us/step - loss: 6.6320e-05 - val_loss: 3.0600e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 0.0286 - val_loss: 2.0245e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 0s 22us/step - loss: 0.0014 - val_loss: 1.3255e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 8.5993e-04 - val_loss: 1.4132e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 7.8294e-04 - val_loss: 1.3254e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 7.3011e-04 - val_loss: 1.1533e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 6.7343e-04 - val_loss: 1.1483e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 6.1934e-04 - val_loss: 1.0217e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 5.7009e-04 - val_loss: 9.4537e-05\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 5.2303e-04 - val_loss: 9.5235e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 4.7349e-04 - val_loss: 8.1772e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 4.2788e-04 - val_loss: 7.4811e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 3.7538e-04 - val_loss: 7.0854e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 3.2636e-04 - val_loss: 6.0078e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 2.6865e-04 - val_loss: 5.4269e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 0s 22us/step - loss: 2.1775e-04 - val_loss: 3.8537e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 1.5998e-04 - val_loss: 3.2892e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 0s 22us/step - loss: 1.4898e-04 - val_loss: 5.3399e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 1.3567e-04 - val_loss: 3.0991e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 1.1317e-04 - val_loss: 3.3420e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 9.4093e-05 - val_loss: 4.3705e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 9.4977e-05 - val_loss: 2.8877e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 9.2349e-05 - val_loss: 3.0090e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 0s 22us/step - loss: 7.8027e-05 - val_loss: 3.8100e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 6.7641e-05 - val_loss: 2.8382e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 1s 77us/step - loss: 0.0066 - val_loss: 3.7029e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 0s 22us/step - loss: 8.8821e-04 - val_loss: 2.4933e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 7.4385e-04 - val_loss: 1.1273e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 6.5221e-04 - val_loss: 1.0738e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 5.8799e-04 - val_loss: 1.0334e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 5.1955e-04 - val_loss: 1.0606e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 4.5002e-04 - val_loss: 2.3830e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 4.0602e-04 - val_loss: 6.6887e-05\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 0s 22us/step - loss: 2.9381e-04 - val_loss: 4.8491e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 0s 22us/step - loss: 2.1657e-04 - val_loss: 4.3659e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 1.8363e-04 - val_loss: 4.1673e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 0s 22us/step - loss: 1.5298e-04 - val_loss: 8.6825e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 1.2636e-04 - val_loss: 6.1680e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 1.1717e-04 - val_loss: 6.0048e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 0s 22us/step - loss: 9.8765e-05 - val_loss: 3.5328e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 0s 22us/step - loss: 8.5329e-05 - val_loss: 3.8999e-05\n",
      "Epoch 17/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18465/18465 [==============================] - 0s 23us/step - loss: 9.8893e-05 - val_loss: 4.5542e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 0s 22us/step - loss: 8.0580e-05 - val_loss: 3.3365e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 0s 22us/step - loss: 7.6283e-05 - val_loss: 5.4734e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 0s 22us/step - loss: 1.9315e-04 - val_loss: 6.8155e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 7.3876e-05 - val_loss: 4.3689e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 5.9922e-05 - val_loss: 9.4711e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 7.3578e-05 - val_loss: 4.0637e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 5.8480e-05 - val_loss: 3.2987e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 1s 80us/step - loss: 0.0393 - val_loss: 3.6846e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 0.0017 - val_loss: 3.0800e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 8.7873e-04 - val_loss: 1.6799e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 8.0613e-04 - val_loss: 1.4807e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 7.3190e-04 - val_loss: 1.1703e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 6.2629e-04 - val_loss: 9.1889e-05\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 4.2977e-04 - val_loss: 7.7295e-05\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 2.2627e-04 - val_loss: 5.1108e-05\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 1.6999e-04 - val_loss: 3.3637e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 1.1639e-04 - val_loss: 3.1862e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 1.0805e-04 - val_loss: 3.6011e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 1.4493e-04 - val_loss: 3.8874e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 7.8227e-05 - val_loss: 3.7674e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 8.2015e-05 - val_loss: 3.8486e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 8.2147e-05 - val_loss: 2.9015e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 6.7315e-05 - val_loss: 2.7436e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 7.6030e-05 - val_loss: 5.0667e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 6.9350e-05 - val_loss: 5.0799e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 8.5319e-05 - val_loss: 3.4809e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 7.2904e-05 - val_loss: 2.3309e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 6.6973e-05 - val_loss: 2.2683e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 5.8037e-05 - val_loss: 4.3554e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 5.2929e-05 - val_loss: 3.1358e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 7.7963e-05 - val_loss: 3.5908e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 2s 84us/step - loss: 0.0379 - val_loss: 0.0034\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 0.0016 - val_loss: 1.4275e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 0.0010 - val_loss: 1.4046e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 9.4204e-04 - val_loss: 1.5074e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 9.0195e-04 - val_loss: 1.3003e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 8.6589e-04 - val_loss: 1.2898e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 8.2692e-04 - val_loss: 1.3561e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 7.8925e-04 - val_loss: 1.1457e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 7.4870e-04 - val_loss: 1.1835e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 6.9699e-04 - val_loss: 1.0425e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 6.1857e-04 - val_loss: 8.6591e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 5.0084e-04 - val_loss: 7.1045e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 3.0475e-04 - val_loss: 3.5109e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 1.9072e-04 - val_loss: 4.7256e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 1.4680e-04 - val_loss: 3.4037e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 1.1931e-04 - val_loss: 2.6967e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 9.1381e-05 - val_loss: 2.6443e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 9.2529e-05 - val_loss: 2.7698e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 8.4964e-05 - val_loss: 3.4234e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 9.6175e-05 - val_loss: 1.2664e-04\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 9.8295e-05 - val_loss: 2.8955e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 6.6520e-05 - val_loss: 3.2246e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 7.2494e-05 - val_loss: 2.5900e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 7.0211e-05 - val_loss: 2.5533e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 2s 87us/step - loss: 0.0060 - val_loss: 0.0011\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 0.0011 - val_loss: 1.4230e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 9.2315e-04 - val_loss: 1.4378e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 8.7647e-04 - val_loss: 1.7435e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 8.5302e-04 - val_loss: 1.3861e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 0s 22us/step - loss: 7.4628e-04 - val_loss: 1.8700e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 5.6234e-04 - val_loss: 5.4378e-05\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 0s 22us/step - loss: 2.9311e-04 - val_loss: 1.0781e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 1.7785e-04 - val_loss: 4.2099e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 1.3557e-04 - val_loss: 4.4713e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 1.1093e-04 - val_loss: 3.8756e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 1.3471e-04 - val_loss: 4.8777e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 9.1236e-05 - val_loss: 3.6780e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 8.4710e-05 - val_loss: 3.9429e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 1.0494e-04 - val_loss: 3.3913e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 8.8678e-05 - val_loss: 3.2991e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 1.0601e-04 - val_loss: 3.9965e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 1.0298e-04 - val_loss: 3.4333e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 8.9095e-05 - val_loss: 3.6221e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 9.2676e-05 - val_loss: 3.0192e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 6.3489e-05 - val_loss: 3.0788e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 1.1161e-04 - val_loss: 1.3853e-04\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 1.1818e-04 - val_loss: 4.2475e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 7.0052e-05 - val_loss: 5.9192e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 2s 98us/step - loss: 0.1330 - val_loss: 0.0071\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 0.0020 - val_loss: 3.1960e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 0.0011 - val_loss: 1.5791e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 0.0010 - val_loss: 1.5672e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 0.0010 - val_loss: 1.6594e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 0.0010 - val_loss: 1.7001e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 0.0010 - val_loss: 1.6625e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 0.0010 - val_loss: 1.6711e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 0.0010 - val_loss: 1.7003e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 0.0010 - val_loss: 1.6554e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 0.0010 - val_loss: 1.6210e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 0.0010 - val_loss: 1.7051e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 0.0010 - val_loss: 1.6777e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 0.0010 - val_loss: 1.5899e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 0.0010 - val_loss: 1.5806e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 0.0010 - val_loss: 1.7695e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 0.0010 - val_loss: 2.1176e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 0.0011 - val_loss: 1.6614e-04\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 0.0010 - val_loss: 1.6657e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 0.0010 - val_loss: 1.5745e-04\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 0.0010 - val_loss: 1.6161e-04\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 0.0010 - val_loss: 1.5895e-04\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 0.0010 - val_loss: 1.6363e-04\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 0.0010 - val_loss: 1.6709e-04\n",
      "\n",
      "GENERATION 1\n",
      "\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 2s 99us/step - loss: 0.0267 - val_loss: 0.0014\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 9.5628e-04 - val_loss: 1.5435e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 4.8472e-04 - val_loss: 2.8572e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 2.8159e-04 - val_loss: 8.3444e-05\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 1.7549e-04 - val_loss: 5.6202e-05\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 1.1962e-04 - val_loss: 5.5933e-05\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 8.5399e-05 - val_loss: 7.6384e-05\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 6.9575e-05 - val_loss: 5.7230e-05\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 6.4939e-05 - val_loss: 6.6774e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 5.8625e-05 - val_loss: 5.7457e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 5.3926e-05 - val_loss: 6.0697e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 5.7367e-05 - val_loss: 5.2171e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 5.3035e-05 - val_loss: 6.1293e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 4.9569e-05 - val_loss: 5.2502e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 4.9077e-05 - val_loss: 6.0821e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 5.1707e-05 - val_loss: 6.4006e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 4.8907e-05 - val_loss: 4.4568e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 4.6208e-05 - val_loss: 4.7949e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 4.9324e-05 - val_loss: 8.3659e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 5.4257e-05 - val_loss: 8.3545e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 5.0134e-05 - val_loss: 7.1704e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 5.1615e-05 - val_loss: 4.1766e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 4.5963e-05 - val_loss: 5.3978e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 4.4952e-05 - val_loss: 4.3608e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 2s 100us/step - loss: 0.0095 - val_loss: 5.7189e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 9.8401e-04 - val_loss: 1.0622e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 5.0164e-04 - val_loss: 6.7320e-05\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 2.8795e-04 - val_loss: 3.9913e-05\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 1.5867e-04 - val_loss: 4.9767e-05\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 1.0157e-04 - val_loss: 3.9684e-05\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 6.8288e-05 - val_loss: 3.8984e-05\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 5.8643e-05 - val_loss: 5.9483e-05\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 5.9191e-05 - val_loss: 8.8640e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 5.4055e-05 - val_loss: 4.3975e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 4.7258e-05 - val_loss: 5.0481e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 4.8212e-05 - val_loss: 5.2943e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 4.9698e-05 - val_loss: 4.7032e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 4.4836e-05 - val_loss: 4.5383e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 5.0251e-05 - val_loss: 6.5085e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 4.2571e-05 - val_loss: 6.9900e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 4.8881e-05 - val_loss: 6.2199e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 4.9216e-05 - val_loss: 7.2009e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 4.4594e-05 - val_loss: 4.2612e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 4.2374e-05 - val_loss: 4.6589e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 4.1682e-05 - val_loss: 5.3300e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 4.2057e-05 - val_loss: 4.5275e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 0s 23us/step - loss: 4.7344e-05 - val_loss: 4.9538e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 3.9113e-05 - val_loss: 3.7800e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 2s 104us/step - loss: 0.0035 - val_loss: 1.4551e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 5.7001e-04 - val_loss: 1.2609e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 2.8408e-04 - val_loss: 6.6023e-05\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 1.3666e-04 - val_loss: 6.6222e-05\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 9.2206e-05 - val_loss: 7.4404e-05\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 6.6318e-05 - val_loss: 9.4072e-05\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 6.0289e-05 - val_loss: 6.3401e-05\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 5.7380e-05 - val_loss: 6.1947e-05\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 6.9187e-05 - val_loss: 6.5453e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 6.6464e-05 - val_loss: 6.8659e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 5.6501e-05 - val_loss: 8.9159e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 5.2505e-05 - val_loss: 5.7536e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 4.9472e-05 - val_loss: 6.1651e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 4.4058e-05 - val_loss: 6.2280e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 4.8599e-05 - val_loss: 7.3555e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 5.2201e-05 - val_loss: 5.7745e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 5.0693e-05 - val_loss: 5.2648e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 4.0586e-05 - val_loss: 5.1158e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 4.5465e-05 - val_loss: 4.8685e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 1.2064e-04 - val_loss: 4.3326e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 4.2077e-05 - val_loss: 4.4998e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 4.5426e-05 - val_loss: 5.2534e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 3.8662e-05 - val_loss: 7.1647e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 4.4290e-05 - val_loss: 4.1789e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 2s 107us/step - loss: 0.0043 - val_loss: 1.9874e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 4.4972e-04 - val_loss: 1.1148e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 1.7783e-04 - val_loss: 9.9381e-05\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 1.1853e-04 - val_loss: 4.2205e-05\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 7.3788e-05 - val_loss: 5.4086e-05\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 5.8537e-05 - val_loss: 3.5039e-05\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 5.3864e-05 - val_loss: 3.3799e-05\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 4.9580e-05 - val_loss: 6.6448e-05\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 4.8932e-05 - val_loss: 3.2715e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 4.2469e-05 - val_loss: 3.2197e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 4.2168e-05 - val_loss: 3.1972e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 4.1850e-05 - val_loss: 3.0180e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 5.3561e-05 - val_loss: 2.6361e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 4.4413e-05 - val_loss: 2.9512e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 4.9088e-05 - val_loss: 7.3140e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 5.4040e-05 - val_loss: 7.7105e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 4.9006e-05 - val_loss: 3.3288e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 5.2529e-05 - val_loss: 3.7092e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 4.5634e-05 - val_loss: 2.5119e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 4.0263e-05 - val_loss: 5.7424e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 4.4359e-05 - val_loss: 3.5260e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 4.5072e-05 - val_loss: 2.4690e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 4.9927e-05 - val_loss: 4.5505e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 4.9751e-05 - val_loss: 3.6602e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 2s 111us/step - loss: 0.0080 - val_loss: 2.1760e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 7.3730e-04 - val_loss: 1.6897e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 3.9099e-04 - val_loss: 1.0165e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 1.7532e-04 - val_loss: 2.4206e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 1.1765e-04 - val_loss: 6.6250e-05\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 7.4238e-05 - val_loss: 6.2158e-05\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 27us/step - loss: 5.9039e-05 - val_loss: 7.4096e-05\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 5.6586e-05 - val_loss: 8.3921e-05\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 5.3914e-05 - val_loss: 7.4281e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 5.4840e-05 - val_loss: 7.4934e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 4.9318e-05 - val_loss: 7.2111e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 5.9354e-05 - val_loss: 7.4024e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 4.7869e-05 - val_loss: 7.9017e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 4.8364e-05 - val_loss: 1.2765e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 5.4429e-05 - val_loss: 1.0662e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 4.9394e-05 - val_loss: 8.4327e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 4.9825e-05 - val_loss: 7.6608e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 5.2550e-05 - val_loss: 8.6592e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 4.4806e-05 - val_loss: 7.9409e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 4.3504e-05 - val_loss: 6.6676e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 4.7899e-05 - val_loss: 7.8393e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 4.4217e-05 - val_loss: 7.9423e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 4.2109e-05 - val_loss: 7.6878e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 0s 24us/step - loss: 4.8089e-05 - val_loss: 5.6221e-04\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 2s 120us/step - loss: 0.0012 - val_loss: 4.1427e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 5.9498e-04 - val_loss: 2.9213e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 4.1890e-04 - val_loss: 1.8672e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 3.3342e-04 - val_loss: 5.6027e-05\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 2.3263e-04 - val_loss: 4.8772e-05\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 1.8433e-04 - val_loss: 2.9572e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 1.7534e-04 - val_loss: 8.2589e-05\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 0s 27us/step - loss: 1.1252e-04 - val_loss: 5.6484e-05\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 1.1050e-04 - val_loss: 2.6755e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 1.5517e-04 - val_loss: 1.2297e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 7.2075e-05 - val_loss: 3.1675e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 5.3007e-05 - val_loss: 4.2296e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 5.3462e-05 - val_loss: 1.4229e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 6.2628e-05 - val_loss: 3.3005e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 5.4014e-05 - val_loss: 1.2078e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 5.7000e-05 - val_loss: 4.0294e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 5.3860e-05 - val_loss: 3.4757e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 5.1212e-05 - val_loss: 3.3748e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 4.3822e-05 - val_loss: 4.5790e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 5.5186e-05 - val_loss: 4.1985e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 5.0154e-05 - val_loss: 3.5970e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 4.4469e-05 - val_loss: 6.2051e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 6.3605e-05 - val_loss: 3.3998e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 8.9065e-05 - val_loss: 5.6708e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 2s 122us/step - loss: 0.0015 - val_loss: 1.0722e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 5.9915e-04 - val_loss: 8.5422e-05\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 3.5505e-04 - val_loss: 4.4142e-05\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 1.3560e-04 - val_loss: 2.9640e-05\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 8.0890e-05 - val_loss: 2.2803e-05\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 0s 27us/step - loss: 5.3294e-05 - val_loss: 1.7985e-05\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 5.3995e-05 - val_loss: 2.3610e-05\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 4.5771e-05 - val_loss: 1.7187e-05\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 5.6189e-05 - val_loss: 8.2799e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 5.4887e-05 - val_loss: 4.6144e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 4.7719e-05 - val_loss: 2.4296e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 5.2504e-05 - val_loss: 1.6586e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 4.6162e-05 - val_loss: 2.4041e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 8.9247e-05 - val_loss: 4.5417e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 5.1256e-05 - val_loss: 1.7279e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 3.6385e-05 - val_loss: 3.0161e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 3.6609e-05 - val_loss: 4.9139e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 5.0346e-05 - val_loss: 7.5364e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 4.9967e-05 - val_loss: 4.9003e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 27us/step - loss: 4.0376e-05 - val_loss: 2.4079e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 6.4719e-05 - val_loss: 2.2908e-04\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 8.0410e-05 - val_loss: 3.3358e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 4.1436e-05 - val_loss: 1.6083e-04\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 7.0218e-05 - val_loss: 2.7100e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 2s 127us/step - loss: 0.0023 - val_loss: 1.4842e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 6.8299e-04 - val_loss: 1.1837e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 4.6729e-04 - val_loss: 5.4733e-05\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 2.7732e-04 - val_loss: 1.0222e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 2.0384e-04 - val_loss: 3.4995e-05\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 1.1653e-04 - val_loss: 4.2100e-05\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 7.6868e-05 - val_loss: 3.2349e-05\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 6.3496e-05 - val_loss: 1.1901e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 1.0308e-04 - val_loss: 3.5854e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 0s 27us/step - loss: 4.8606e-05 - val_loss: 3.3200e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 5.0482e-05 - val_loss: 2.7287e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 4.0958e-05 - val_loss: 2.6100e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 4.2415e-05 - val_loss: 2.6349e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 4.5929e-05 - val_loss: 7.6559e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 5.5916e-05 - val_loss: 7.1159e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 5.1444e-05 - val_loss: 2.6741e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 4.5017e-05 - val_loss: 4.1769e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 7.0434e-05 - val_loss: 4.7441e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 7.1734e-05 - val_loss: 8.7314e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 6.4847e-05 - val_loss: 8.2753e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 7.4040e-05 - val_loss: 2.3281e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 6.6000e-05 - val_loss: 1.2922e-04\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 5.7766e-05 - val_loss: 2.3689e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 4.0379e-05 - val_loss: 5.6821e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 2s 132us/step - loss: 0.0011 - val_loss: 1.2923e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 7.4551e-04 - val_loss: 1.1387e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 27us/step - loss: 5.2255e-04 - val_loss: 1.3851e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 3.0012e-04 - val_loss: 6.5931e-05\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 1.7399e-04 - val_loss: 4.0116e-05\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 1.0961e-04 - val_loss: 9.8448e-05\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 0s 27us/step - loss: 8.7123e-05 - val_loss: 3.4192e-05\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 0s 27us/step - loss: 6.2050e-05 - val_loss: 6.0998e-05\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 7.0385e-05 - val_loss: 1.2667e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 0s 27us/step - loss: 6.2105e-05 - val_loss: 3.8780e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 5.7770e-05 - val_loss: 4.4112e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 1.0441e-04 - val_loss: 2.3291e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 0s 27us/step - loss: 4.2675e-05 - val_loss: 4.0014e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 0s 27us/step - loss: 4.2475e-05 - val_loss: 1.1029e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 0s 27us/step - loss: 6.6285e-05 - val_loss: 2.5430e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 4.3064e-05 - val_loss: 2.2368e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 3.6758e-05 - val_loss: 1.9861e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 0s 27us/step - loss: 4.0636e-05 - val_loss: 2.5179e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 4.0746e-05 - val_loss: 3.4635e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 3.9491e-05 - val_loss: 2.0740e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 0s 27us/step - loss: 4.2306e-05 - val_loss: 3.1709e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 5.3768e-05 - val_loss: 1.9499e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 4.9836e-05 - val_loss: 2.0087e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 0s 27us/step - loss: 6.7545e-05 - val_loss: 1.3559e-04\n",
      "\n",
      "GENERATION 2\n",
      "\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 3s 138us/step - loss: 0.0052 - val_loss: 0.0044\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 0.0073 - val_loss: 0.0027\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 0s 27us/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 0s 27us/step - loss: 0.0030 - val_loss: 0.0022\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 0.0031 - val_loss: 0.0019\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 0s 27us/step - loss: 0.0030 - val_loss: 9.7331e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 0.0018 - val_loss: 9.2728e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 0.0017 - val_loss: 9.0750e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 0.0015 - val_loss: 2.4925e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 0.0014 - val_loss: 2.1241e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 8.7178e-04 - val_loss: 0.0016\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 9.3498e-04 - val_loss: 4.9178e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 9.3323e-04 - val_loss: 2.4531e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 7.9406e-04 - val_loss: 5.9052e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 7.6369e-04 - val_loss: 6.2502e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 6.9820e-04 - val_loss: 1.8381e-04\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 5.9705e-04 - val_loss: 9.7571e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 6.0549e-04 - val_loss: 1.8576e-04\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 4.8061e-04 - val_loss: 7.8603e-04\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 0s 27us/step - loss: 4.6455e-04 - val_loss: 2.3003e-04\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 4.5812e-04 - val_loss: 2.6461e-04\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 0s 27us/step - loss: 3.8826e-04 - val_loss: 0.0013\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 3s 143us/step - loss: 0.0031 - val_loss: 1.7910e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 4.8671e-04 - val_loss: 2.5267e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 0s 27us/step - loss: 2.2160e-04 - val_loss: 6.4963e-05\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 9.9904e-05 - val_loss: 5.4796e-05\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 0s 27us/step - loss: 8.4375e-05 - val_loss: 2.5701e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 8.7374e-05 - val_loss: 4.4701e-05\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 6.1616e-05 - val_loss: 4.6996e-05\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 6.1380e-05 - val_loss: 4.7932e-05\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 6.1017e-05 - val_loss: 5.2446e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 6.0660e-05 - val_loss: 6.0098e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 1.1941e-04 - val_loss: 1.6721e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 1.1243e-04 - val_loss: 4.3637e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 5.3778e-05 - val_loss: 3.9067e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 5.2356e-05 - val_loss: 3.8400e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 4.7258e-05 - val_loss: 3.5673e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 4.7343e-05 - val_loss: 3.5824e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 4.8488e-05 - val_loss: 3.6629e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 4.4737e-05 - val_loss: 4.1917e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 4.4504e-05 - val_loss: 4.2970e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 5.0181e-05 - val_loss: 3.7490e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 4.3696e-05 - val_loss: 4.3942e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 4.1041e-05 - val_loss: 5.1732e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 0s 25us/step - loss: 4.2856e-05 - val_loss: 5.7762e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 5.0481e-05 - val_loss: 3.8246e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 3s 145us/step - loss: 0.0025 - val_loss: 2.0630e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 7.0042e-04 - val_loss: 1.9124e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 4.6202e-04 - val_loss: 4.2932e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - ETA: 0s - loss: 2.6131e-0 - 0s 27us/step - loss: 2.5667e-04 - val_loss: 4.8278e-05\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 0s 27us/step - loss: 1.2811e-04 - val_loss: 8.0238e-05\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 0s 27us/step - loss: 8.7899e-05 - val_loss: 5.9708e-05\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 0s 27us/step - loss: 7.3485e-05 - val_loss: 9.4430e-05\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 0s 27us/step - loss: 6.3121e-05 - val_loss: 5.7001e-05\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 0s 27us/step - loss: 5.8689e-05 - val_loss: 5.4054e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 0s 27us/step - loss: 5.8314e-05 - val_loss: 4.6419e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 0s 27us/step - loss: 5.3879e-05 - val_loss: 6.3824e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 0s 27us/step - loss: 5.8771e-05 - val_loss: 5.4111e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 4.7181e-05 - val_loss: 5.4518e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 0s 26us/step - loss: 5.6036e-05 - val_loss: 4.9521e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 27us/step - loss: 4.5496e-05 - val_loss: 5.0999e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 0s 27us/step - loss: 4.6936e-05 - val_loss: 1.5228e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 0s 27us/step - loss: 8.0462e-05 - val_loss: 7.4250e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 0s 27us/step - loss: 5.4656e-05 - val_loss: 5.4117e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 0s 27us/step - loss: 4.4674e-05 - val_loss: 5.7378e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 0s 27us/step - loss: 4.0730e-05 - val_loss: 4.6715e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 0s 27us/step - loss: 4.4583e-05 - val_loss: 4.8615e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 0s 27us/step - loss: 4.7141e-05 - val_loss: 4.7404e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 0s 27us/step - loss: 4.2119e-05 - val_loss: 4.7975e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 0s 27us/step - loss: 5.5831e-05 - val_loss: 7.0543e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 3s 150us/step - loss: 9.3534e-04 - val_loss: 1.1140e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 27us/step - loss: 3.9543e-04 - val_loss: 5.3550e-05\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 27us/step - loss: 1.7187e-04 - val_loss: 3.1403e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 0s 27us/step - loss: 1.1422e-04 - val_loss: 3.2537e-05\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 27us/step - loss: 5.7805e-05 - val_loss: 4.9503e-05\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 27us/step - loss: 5.6606e-05 - val_loss: 5.1721e-05\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 0s 27us/step - loss: 8.2859e-05 - val_loss: 3.2700e-05\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 0s 27us/step - loss: 5.6863e-05 - val_loss: 1.6854e-05\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 0s 27us/step - loss: 5.6154e-05 - val_loss: 2.0121e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 0s 27us/step - loss: 4.4934e-05 - val_loss: 2.7872e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 0s 27us/step - loss: 1.1183e-04 - val_loss: 2.3787e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 27us/step - loss: 4.5574e-05 - val_loss: 1.5216e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 0s 27us/step - loss: 4.9954e-05 - val_loss: 1.5878e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 0s 27us/step - loss: 4.0516e-05 - val_loss: 1.3385e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 0s 27us/step - loss: 5.8452e-05 - val_loss: 2.7898e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 0s 27us/step - loss: 4.3024e-05 - val_loss: 2.6863e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 0s 27us/step - loss: 4.0959e-05 - val_loss: 2.2258e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 27us/step - loss: 4.6171e-05 - val_loss: 2.4631e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 0s 27us/step - loss: 4.4845e-05 - val_loss: 1.5275e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 27us/step - loss: 5.4225e-05 - val_loss: 4.0847e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 28us/step - loss: 7.3939e-05 - val_loss: 5.5422e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 0s 27us/step - loss: 4.4618e-05 - val_loss: 3.7663e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 0s 27us/step - loss: 4.3177e-05 - val_loss: 4.1695e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 0s 27us/step - loss: 4.6543e-05 - val_loss: 2.0999e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 3s 160us/step - loss: 0.0027 - val_loss: 1.5715e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 28us/step - loss: 0.0015 - val_loss: 1.4451e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 28us/step - loss: 9.4154e-04 - val_loss: 4.2514e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 28us/step - loss: 8.6309e-04 - val_loss: 2.3663e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 28us/step - loss: 0.0012 - val_loss: 1.7735e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 28us/step - loss: 7.4700e-04 - val_loss: 2.3566e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 28us/step - loss: 5.8690e-04 - val_loss: 0.0011\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 28us/step - loss: 5.4359e-04 - val_loss: 2.6762e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 28us/step - loss: 2.7169e-04 - val_loss: 1.0839e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 28us/step - loss: 2.4166e-04 - val_loss: 7.4737e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 28us/step - loss: 2.4116e-04 - val_loss: 8.4885e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 28us/step - loss: 2.2385e-04 - val_loss: 1.2398e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 1.9612e-04 - val_loss: 2.3200e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 2.0383e-04 - val_loss: 3.1607e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 2.9566e-04 - val_loss: 1.1116e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 28us/step - loss: 2.1118e-04 - val_loss: 2.4939e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 28us/step - loss: 1.7156e-04 - val_loss: 5.8487e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 2.8285e-04 - val_loss: 1.2612e-04\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 28us/step - loss: 1.6342e-04 - val_loss: 3.3184e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 28us/step - loss: 1.2085e-04 - val_loss: 3.5045e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 28us/step - loss: 2.0966e-04 - val_loss: 8.6528e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 28us/step - loss: 1.3489e-04 - val_loss: 7.8926e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 1.0842e-04 - val_loss: 6.3281e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 1.0960e-04 - val_loss: 8.9617e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 3s 169us/step - loss: 0.0018 - val_loss: 5.2007e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 0.0010 - val_loss: 0.0045\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 9.5225e-04 - val_loss: 2.1289e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 5.5052e-04 - val_loss: 1.9642e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 0.0022 - val_loss: 1.5371e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - ETA: 0s - loss: 3.1558e-0 - 1s 28us/step - loss: 3.1243e-04 - val_loss: 1.3857e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 4.1889e-04 - val_loss: 6.8555e-05\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 30us/step - loss: 3.0846e-04 - val_loss: 1.6871e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 2.5075e-04 - val_loss: 1.6286e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 2.3808e-04 - val_loss: 1.1776e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 2.9304e-04 - val_loss: 1.4009e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 28us/step - loss: 2.6777e-04 - val_loss: 1.1346e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 2.3586e-04 - val_loss: 1.0096e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 2.4687e-04 - val_loss: 2.4712e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 28us/step - loss: 1.9409e-04 - val_loss: 1.3625e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 28us/step - loss: 3.7980e-04 - val_loss: 1.3265e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 2.5726e-04 - val_loss: 1.4369e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 2.1243e-04 - val_loss: 1.9283e-04\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 1.6103e-04 - val_loss: 1.2592e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 1.9739e-04 - val_loss: 1.2106e-04\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 28us/step - loss: 1.3995e-04 - val_loss: 1.4680e-04\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 2.1299e-04 - val_loss: 1.3644e-04\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 2.3011e-04 - val_loss: 1.0683e-04\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 1.8968e-04 - val_loss: 1.3483e-04\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 3s 169us/step - loss: 0.0014 - val_loss: 1.2959e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 28us/step - loss: 6.7621e-04 - val_loss: 1.7789e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 28us/step - loss: 3.9015e-04 - val_loss: 1.7021e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 28us/step - loss: 1.5105e-04 - val_loss: 6.6120e-05\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 28us/step - loss: 7.8385e-05 - val_loss: 9.6417e-05\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 28us/step - loss: 6.3459e-05 - val_loss: 6.4638e-05\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 28us/step - loss: 7.8451e-05 - val_loss: 9.2500e-05\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 28us/step - loss: 7.3924e-05 - val_loss: 3.0624e-05\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 28us/step - loss: 5.4913e-05 - val_loss: 7.8054e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 28us/step - loss: 4.8569e-05 - val_loss: 3.9746e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 28us/step - loss: 6.2265e-05 - val_loss: 7.7424e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 28us/step - loss: 6.7932e-05 - val_loss: 2.9026e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 28us/step - loss: 4.0001e-05 - val_loss: 9.7058e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 28us/step - loss: 7.4150e-05 - val_loss: 1.0440e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 28us/step - loss: 4.9485e-05 - val_loss: 2.7892e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 28us/step - loss: 3.7409e-05 - val_loss: 2.7578e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 4.0520e-05 - val_loss: 2.6180e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 28us/step - loss: 4.3928e-05 - val_loss: 2.8633e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 28us/step - loss: 3.7803e-05 - val_loss: 2.9327e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 28us/step - loss: 4.1381e-05 - val_loss: 3.4432e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 28us/step - loss: 4.3720e-05 - val_loss: 2.9470e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 28us/step - loss: 4.8041e-05 - val_loss: 2.6445e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 28us/step - loss: 6.6947e-05 - val_loss: 3.3212e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 28us/step - loss: 4.7184e-05 - val_loss: 8.2715e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 3s 173us/step - loss: 0.0014 - val_loss: 1.5885e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 7.4623e-04 - val_loss: 1.1493e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 28us/step - loss: 5.2523e-04 - val_loss: 1.9129e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 28us/step - loss: 3.4145e-04 - val_loss: 3.1197e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 1.7967e-04 - val_loss: 8.6431e-05\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 28us/step - loss: 8.0537e-05 - val_loss: 3.2595e-05\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 6.6967e-05 - val_loss: 2.4221e-05\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 5.4624e-05 - val_loss: 2.0825e-05\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 28us/step - loss: 4.8260e-05 - val_loss: 3.0846e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 4.5254e-05 - val_loss: 1.2645e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 28us/step - loss: 6.5361e-05 - val_loss: 1.8946e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 28us/step - loss: 5.5300e-05 - val_loss: 2.2354e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 5.6934e-05 - val_loss: 2.2119e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 4.2344e-05 - val_loss: 2.6379e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 28us/step - loss: 5.0633e-05 - val_loss: 1.6877e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 6.2987e-05 - val_loss: 7.2133e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 1.0046e-04 - val_loss: 4.6822e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 28us/step - loss: 3.6541e-04 - val_loss: 1.1420e-04\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 5.5064e-05 - val_loss: 2.9634e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 3.8114e-05 - val_loss: 2.2080e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 28us/step - loss: 3.7161e-05 - val_loss: 2.1015e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 3.4072e-05 - val_loss: 2.7881e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 3.6047e-05 - val_loss: 3.2448e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 4.2965e-05 - val_loss: 2.1138e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 3s 179us/step - loss: 0.0019 - val_loss: 1.2604e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 7.5046e-04 - val_loss: 1.5113e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 4.9036e-04 - val_loss: 7.5861e-05\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 3.0126e-04 - val_loss: 5.1719e-05\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 1.6645e-04 - val_loss: 1.2952e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 9.8685e-05 - val_loss: 2.1862e-05\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 8.3223e-05 - val_loss: 3.1469e-05\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 6.4939e-05 - val_loss: 1.0295e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 6.9288e-05 - val_loss: 1.7388e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 5.1400e-05 - val_loss: 5.9198e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 7.3909e-05 - val_loss: 3.9288e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 5.0744e-05 - val_loss: 1.8146e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 4.4120e-05 - val_loss: 1.7278e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 31us/step - loss: 9.2465e-05 - val_loss: 4.6490e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 5.3044e-05 - val_loss: 1.7782e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 5.5176e-05 - val_loss: 2.9070e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 4.4555e-05 - val_loss: 6.1669e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 30us/step - loss: 5.8120e-05 - val_loss: 1.9289e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 6.0214e-05 - val_loss: 4.0574e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 5.0003e-05 - val_loss: 2.0609e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 30us/step - loss: 3.8511e-05 - val_loss: 2.0666e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 4.4549e-05 - val_loss: 2.3892e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 4.0407e-05 - val_loss: 1.8565e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 4.4199e-05 - val_loss: 9.0949e-05\n",
      "\n",
      "GENERATION 3\n",
      "\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 3s 183us/step - loss: 9.6455e-04 - val_loss: 2.1992e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 3.4994e-04 - val_loss: 5.6602e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 3.0118e-04 - val_loss: 1.2033e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 8.7234e-05 - val_loss: 8.8003e-05\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 31us/step - loss: 7.6089e-05 - val_loss: 1.7898e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 30us/step - loss: 9.2564e-05 - val_loss: 6.5354e-05\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 5.9597e-05 - val_loss: 4.3086e-05\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 4.6824e-05 - val_loss: 3.2272e-05\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 4.4424e-05 - val_loss: 3.2870e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 4.7408e-05 - val_loss: 4.1477e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 6.7007e-05 - val_loss: 3.5431e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 4.3576e-05 - val_loss: 3.7300e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 9.3306e-05 - val_loss: 2.8528e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 4.9288e-05 - val_loss: 2.7020e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 30us/step - loss: 3.6173e-05 - val_loss: 2.8758e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 4.3810e-05 - val_loss: 3.0844e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 4.2155e-05 - val_loss: 2.9734e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 30us/step - loss: 4.0718e-05 - val_loss: 3.0883e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 4.5076e-05 - val_loss: 3.1491e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 4.0354e-05 - val_loss: 3.8708e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 3.5839e-05 - val_loss: 7.2257e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 6.8784e-05 - val_loss: 3.0651e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 5.5133e-05 - val_loss: 3.1321e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 9.5990e-05 - val_loss: 7.8118e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 4s 195us/step - loss: 0.0045 - val_loss: 1.4623e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 30us/step - loss: 6.3672e-04 - val_loss: 1.4666e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 3.9970e-04 - val_loss: 1.3678e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 30us/step - loss: 1.8895e-04 - val_loss: 8.2986e-05\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 30us/step - loss: 8.2520e-05 - val_loss: 3.0454e-05\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 30us/step - loss: 7.4116e-05 - val_loss: 2.9604e-05\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 30us/step - loss: 5.6690e-05 - val_loss: 2.6119e-05\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 30us/step - loss: 6.0083e-05 - val_loss: 9.4533e-05\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 30us/step - loss: 6.4283e-05 - val_loss: 4.0694e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 30us/step - loss: 7.0760e-05 - val_loss: 1.4273e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 30us/step - loss: 8.5148e-05 - val_loss: 2.5509e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 30us/step - loss: 5.3395e-05 - val_loss: 2.4778e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 30us/step - loss: 4.3865e-05 - val_loss: 5.1842e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 30us/step - loss: 4.5736e-05 - val_loss: 2.8280e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 30us/step - loss: 5.5743e-05 - val_loss: 3.2111e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 30us/step - loss: 4.5630e-05 - val_loss: 3.5042e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 30us/step - loss: 4.7569e-05 - val_loss: 6.0595e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 30us/step - loss: 4.5965e-05 - val_loss: 2.2269e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 30us/step - loss: 4.4298e-05 - val_loss: 6.5997e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 30us/step - loss: 6.9995e-05 - val_loss: 9.9859e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 30us/step - loss: 5.8661e-05 - val_loss: 2.4331e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 30us/step - loss: 4.0440e-05 - val_loss: 2.5241e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 29us/step - loss: 3.8529e-05 - val_loss: 2.3591e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 30us/step - loss: 4.4030e-05 - val_loss: 6.7405e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 4s 195us/step - loss: 0.0012 - val_loss: 1.4110e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 30us/step - loss: 6.6865e-04 - val_loss: 1.9515e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 31us/step - loss: 4.4261e-04 - val_loss: 8.2373e-05\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 30us/step - loss: 1.7583e-04 - val_loss: 6.5179e-05\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 30us/step - loss: 8.4807e-05 - val_loss: 4.4194e-05\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 30us/step - loss: 7.1896e-05 - val_loss: 1.5925e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 30us/step - loss: 7.3921e-05 - val_loss: 5.0638e-05\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 30us/step - loss: 5.7408e-05 - val_loss: 1.4234e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 30us/step - loss: 6.2447e-05 - val_loss: 3.0451e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 30us/step - loss: 5.6653e-05 - val_loss: 1.8503e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 30us/step - loss: 6.1081e-05 - val_loss: 4.1251e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 30us/step - loss: 4.3397e-05 - val_loss: 8.8613e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 30us/step - loss: 5.8172e-05 - val_loss: 1.1091e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 30us/step - loss: 7.0957e-05 - val_loss: 2.4516e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 31us/step - loss: 4.2810e-05 - val_loss: 3.0477e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 30us/step - loss: 4.6727e-05 - val_loss: 2.5059e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 30us/step - loss: 5.9418e-05 - val_loss: 5.2057e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 30us/step - loss: 6.3155e-05 - val_loss: 6.2506e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 31us/step - loss: 6.6819e-05 - val_loss: 4.9883e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 30us/step - loss: 5.7884e-05 - val_loss: 2.4180e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 31us/step - loss: 3.6926e-05 - val_loss: 2.2375e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 31us/step - loss: 4.7555e-05 - val_loss: 5.3609e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 30us/step - loss: 4.2791e-05 - val_loss: 3.2933e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 31us/step - loss: 3.9069e-05 - val_loss: 4.8361e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 4s 204us/step - loss: 0.0111 - val_loss: 9.4140e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 31us/step - loss: 0.0010 - val_loss: 1.3754e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: 8.8183e-04 - val_loss: 1.3596e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 33us/step - loss: 7.9799e-04 - val_loss: 1.2735e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 31us/step - loss: 6.9744e-04 - val_loss: 1.1186e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: 5.9475e-04 - val_loss: 9.8143e-05\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 31us/step - loss: 4.6159e-04 - val_loss: 7.8708e-05\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: 3.1297e-04 - val_loss: 6.4712e-05\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 31us/step - loss: 1.7977e-04 - val_loss: 6.1828e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 31us/step - loss: 1.0551e-04 - val_loss: 3.1874e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 31us/step - loss: 6.1384e-05 - val_loss: 3.0151e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: 4.4343e-05 - val_loss: 2.7863e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: 3.8928e-05 - val_loss: 3.3939e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 31us/step - loss: 3.8261e-05 - val_loss: 2.6219e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 31us/step - loss: 3.5472e-05 - val_loss: 2.8877e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: 3.5882e-05 - val_loss: 2.6180e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: 3.5775e-05 - val_loss: 2.3794e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: 3.4754e-05 - val_loss: 2.3765e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: 3.5306e-05 - val_loss: 3.1313e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: 3.6089e-05 - val_loss: 2.2536e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 31us/step - loss: 3.5326e-05 - val_loss: 2.2619e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 31us/step - loss: 3.5271e-05 - val_loss: 2.2668e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 31us/step - loss: 3.4748e-05 - val_loss: 8.5458e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 31us/step - loss: 5.0635e-05 - val_loss: 2.0928e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 4s 215us/step - loss: 0.0074 - val_loss: 1.4319e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: 0.0010 - val_loss: 1.3545e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: 9.0025e-04 - val_loss: 1.6187e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: 8.1562e-04 - val_loss: 1.1669e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: 7.1478e-04 - val_loss: 1.2107e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: 5.7147e-04 - val_loss: 7.6833e-05\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: 3.7205e-04 - val_loss: 6.1497e-05\n",
      "Epoch 8/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18465/18465 [==============================] - 1s 32us/step - loss: 1.7624e-04 - val_loss: 2.2324e-05\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: 8.0162e-05 - val_loss: 5.7832e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: 5.6478e-05 - val_loss: 2.0341e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: 5.0173e-05 - val_loss: 2.0207e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: 4.2019e-05 - val_loss: 2.0130e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: 3.8469e-05 - val_loss: 2.4552e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: 3.9456e-05 - val_loss: 2.3790e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: 4.3432e-05 - val_loss: 1.9306e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: 3.8665e-05 - val_loss: 3.0288e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 33us/step - loss: 4.2270e-05 - val_loss: 2.2777e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 33us/step - loss: 3.7755e-05 - val_loss: 1.8069e-04\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: 9.0501e-05 - val_loss: 2.1803e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: 4.3184e-05 - val_loss: 2.8562e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: 4.2751e-05 - val_loss: 1.9422e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: 3.5951e-05 - val_loss: 3.3460e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: 4.0143e-05 - val_loss: 3.4720e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: 4.4859e-05 - val_loss: 2.4872e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 4s 215us/step - loss: 0.1694 - val_loss: 0.0074\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: 0.0022 - val_loss: 1.3550e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 31us/step - loss: 8.8350e-04 - val_loss: 1.4865e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: 7.8897e-04 - val_loss: 1.3601e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: 7.2123e-04 - val_loss: 1.1795e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 31us/step - loss: 6.5543e-04 - val_loss: 1.1167e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: 5.8902e-04 - val_loss: 1.4909e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 31us/step - loss: 5.2493e-04 - val_loss: 1.0153e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 31us/step - loss: 4.2385e-04 - val_loss: 8.0893e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 31us/step - loss: 3.5320e-04 - val_loss: 7.4303e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: 2.8404e-04 - val_loss: 6.4372e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 31us/step - loss: 2.2572e-04 - val_loss: 1.1482e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: 1.6728e-04 - val_loss: 4.7537e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 31us/step - loss: 1.2050e-04 - val_loss: 3.6179e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: 9.4984e-05 - val_loss: 3.6044e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 31us/step - loss: 7.8166e-05 - val_loss: 3.3636e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: 6.5792e-05 - val_loss: 2.9671e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 31us/step - loss: 5.8042e-05 - val_loss: 3.1230e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: 5.3943e-05 - val_loss: 2.7301e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 31us/step - loss: 5.0732e-05 - val_loss: 2.7375e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 31us/step - loss: 4.9751e-05 - val_loss: 2.5887e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 31us/step - loss: 4.6670e-05 - val_loss: 2.5428e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 31us/step - loss: 4.6663e-05 - val_loss: 2.5183e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: 4.5118e-05 - val_loss: 2.4721e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 4s 224us/step - loss: 0.0839 - val_loss: 0.0015\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: 0.0018 - val_loss: 1.6676e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: 7.7581e-04 - val_loss: 1.2806e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: 6.7090e-04 - val_loss: 1.2241e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 33us/step - loss: 6.0067e-04 - val_loss: 1.1441e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 33us/step - loss: 5.3075e-04 - val_loss: 1.1033e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: 4.5907e-04 - val_loss: 9.1551e-05\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: 3.9069e-04 - val_loss: 7.9019e-05\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: 3.1992e-04 - val_loss: 7.1212e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: 2.5810e-04 - val_loss: 6.5266e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: 2.0446e-04 - val_loss: 6.0406e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: 1.6126e-04 - val_loss: 5.2520e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: 1.2373e-04 - val_loss: 4.8357e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: 9.8709e-05 - val_loss: 4.6639e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: 8.0242e-05 - val_loss: 4.5866e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: 7.0346e-05 - val_loss: 4.5669e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: 6.0147e-05 - val_loss: 4.4154e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 31us/step - loss: 5.3860e-05 - val_loss: 4.3697e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 33us/step - loss: 4.8851e-05 - val_loss: 5.9508e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: 4.7987e-05 - val_loss: 4.6348e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: 4.3937e-05 - val_loss: 4.2564e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: 4.2244e-05 - val_loss: 4.1957e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: 4.0278e-05 - val_loss: 4.4846e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: 4.0624e-05 - val_loss: 4.1111e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 4s 224us/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 31us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 31us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 31us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 31us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 31us/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 31us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 31us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 31us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 31us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 31us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 31us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 31us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 31us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 31us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 31us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 31us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 31us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 31us/step - loss: nan - val_loss: nan\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 4s 229us/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 31us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 31us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 31us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 31us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 33us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 33us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 31us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 31us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 32us/step - loss: nan - val_loss: nan\n",
      "\n",
      "GENERATION 4\n",
      "\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 4s 242us/step - loss: 0.0026 - val_loss: 3.5985e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 33us/step - loss: 6.9841e-04 - val_loss: 9.9280e-05\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 33us/step - loss: 4.3256e-04 - val_loss: 9.1555e-05\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 33us/step - loss: 2.4463e-04 - val_loss: 9.0692e-05\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 33us/step - loss: 1.6687e-04 - val_loss: 2.8542e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 9.9110e-05 - val_loss: 4.8162e-05\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 33us/step - loss: 6.0666e-05 - val_loss: 7.3538e-05\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 33us/step - loss: 5.6151e-05 - val_loss: 4.7905e-05\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 33us/step - loss: 5.2700e-05 - val_loss: 5.4404e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 33us/step - loss: 5.2343e-05 - val_loss: 4.6698e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 33us/step - loss: 5.1494e-05 - val_loss: 6.5407e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 33us/step - loss: 5.2960e-05 - val_loss: 9.4918e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 33us/step - loss: 6.1478e-05 - val_loss: 4.8640e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 33us/step - loss: 8.4746e-05 - val_loss: 4.4442e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 33us/step - loss: 5.3814e-05 - val_loss: 6.9179e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 33us/step - loss: 7.3544e-05 - val_loss: 1.0541e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 33us/step - loss: 8.7634e-05 - val_loss: 4.4762e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 33us/step - loss: 3.8693e-05 - val_loss: 3.5518e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 33us/step - loss: 4.7303e-05 - val_loss: 3.7820e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 33us/step - loss: 5.9769e-05 - val_loss: 5.4461e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 33us/step - loss: 3.9916e-05 - val_loss: 4.1959e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 33us/step - loss: 5.0113e-05 - val_loss: 5.4435e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 33us/step - loss: 5.4615e-05 - val_loss: 1.2330e-04\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 33us/step - loss: 9.1491e-05 - val_loss: 3.8418e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 5s 252us/step - loss: 0.0013 - val_loss: 1.8429e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 5.6203e-04 - val_loss: 1.7178e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 2.8251e-04 - val_loss: 7.2879e-05\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 1.3503e-04 - val_loss: 4.7988e-05\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 9.5533e-05 - val_loss: 1.5651e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 6.3975e-05 - val_loss: 1.8346e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 1.1541e-04 - val_loss: 5.4316e-05\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 7.2750e-05 - val_loss: 2.8080e-05\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 6.1830e-05 - val_loss: 1.8420e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 9.4949e-05 - val_loss: 3.7514e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 5.2395e-05 - val_loss: 7.8665e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 9.9104e-05 - val_loss: 1.2663e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 7.5063e-05 - val_loss: 2.5505e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 4.1289e-05 - val_loss: 1.9516e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 4.4767e-05 - val_loss: 2.6230e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 4.3117e-05 - val_loss: 1.5157e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 3.9530e-05 - val_loss: 5.8204e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 5.0440e-05 - val_loss: 6.1179e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 4.0959e-05 - val_loss: 3.2690e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 5.3876e-05 - val_loss: 8.1998e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 4.7631e-05 - val_loss: 2.1646e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 6.3239e-05 - val_loss: 5.9366e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 6.4978e-05 - val_loss: 8.4433e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 4.4746e-05 - val_loss: 1.4900e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 5s 253us/step - loss: 0.0352 - val_loss: 2.7848e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 9.5455e-04 - val_loss: 3.6351e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 8.0358e-04 - val_loss: 1.4519e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 5.0403e-04 - val_loss: 1.9074e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 9.5860e-04 - val_loss: 1.4241e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 33us/step - loss: 8.7102e-04 - val_loss: 7.5752e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 6.2361e-04 - val_loss: 1.5474e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 3.9722e-04 - val_loss: 1.1738e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 3.1190e-04 - val_loss: 2.1272e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 2.2359e-04 - val_loss: 1.3106e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 2.3750e-04 - val_loss: 1.0864e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 1.9817e-04 - val_loss: 9.5276e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 2.0434e-04 - val_loss: 1.1696e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 2.3624e-04 - val_loss: 1.5711e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 1.5301e-04 - val_loss: 8.2686e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 1.6986e-04 - val_loss: 1.2149e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 1.5608e-04 - val_loss: 1.5290e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 1.5026e-04 - val_loss: 1.1413e-04\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 1.1758e-04 - val_loss: 4.5659e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 1.3340e-04 - val_loss: 1.0381e-04\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 1.0723e-04 - val_loss: 3.7371e-04\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 1.1838e-04 - val_loss: 4.3886e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 9.0172e-05 - val_loss: 2.9332e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 33us/step - loss: 7.6562e-05 - val_loss: 1.9259e-04\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 5s 253us/step - loss: 0.0110 - val_loss: 1.4737e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 8.5458e-04 - val_loss: 4.4432e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 33us/step - loss: 7.3958e-04 - val_loss: 1.7853e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 33us/step - loss: 6.5604e-04 - val_loss: 1.3756e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 5.4308e-04 - val_loss: 1.3146e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 33us/step - loss: 4.5426e-04 - val_loss: 1.2676e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 3.3029e-04 - val_loss: 1.9128e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 3.2673e-04 - val_loss: 2.4652e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 2.4860e-04 - val_loss: 2.9668e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 2.5316e-04 - val_loss: 6.0670e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 1.8920e-04 - val_loss: 7.6550e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 2.3174e-04 - val_loss: 1.5227e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 33us/step - loss: 1.5479e-04 - val_loss: 1.8518e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 33us/step - loss: 1.2589e-04 - val_loss: 7.0311e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 1.1895e-04 - val_loss: 9.9139e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 1.1080e-04 - val_loss: 4.2385e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 33us/step - loss: 9.7192e-05 - val_loss: 1.3886e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 33us/step - loss: 9.5630e-05 - val_loss: 1.2164e-04\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 9.9800e-05 - val_loss: 1.5578e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 33us/step - loss: 9.6075e-05 - val_loss: 2.1465e-04\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 33us/step - loss: 8.5419e-05 - val_loss: 3.7565e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 33us/step - loss: 8.2992e-05 - val_loss: 3.7261e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 33us/step - loss: 8.0659e-05 - val_loss: 3.9282e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 7.4010e-05 - val_loss: 2.4608e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 5s 260us/step - loss: 0.0059 - val_loss: 1.5091e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 9.1257e-04 - val_loss: 1.2731e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 8.4732e-04 - val_loss: 1.4440e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 7.9512e-04 - val_loss: 1.2502e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 7.4006e-04 - val_loss: 2.9713e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 6.1693e-04 - val_loss: 1.2175e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 5.8309e-04 - val_loss: 1.2714e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 3.0543e-04 - val_loss: 7.8106e-05\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 2.3133e-04 - val_loss: 8.4988e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 2.1112e-04 - val_loss: 1.0278e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 1.8266e-04 - val_loss: 1.0197e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 2.0542e-04 - val_loss: 1.0078e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 2.2655e-04 - val_loss: 5.6580e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 1.5428e-04 - val_loss: 4.4627e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 1.4762e-04 - val_loss: 5.4075e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 1.1243e-04 - val_loss: 4.7738e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 1.0652e-04 - val_loss: 1.4621e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 1.0269e-04 - val_loss: 9.1391e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 1.2768e-04 - val_loss: 6.6654e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 1.1252e-04 - val_loss: 1.0237e-04\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 1.0559e-04 - val_loss: 4.1629e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 1.1428e-04 - val_loss: 3.7061e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 9.8792e-05 - val_loss: 8.7628e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 8.8250e-05 - val_loss: 1.9820e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 5s 270us/step - loss: 0.0035 - val_loss: 1.4515e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 8.0660e-04 - val_loss: 0.0067\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 0.0012 - val_loss: 1.4890e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 9.1517e-04 - val_loss: 1.6185e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 8.1395e-04 - val_loss: 1.8301e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 6.5703e-04 - val_loss: 1.5811e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 3.6971e-04 - val_loss: 0.0200\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 0.0016 - val_loss: 1.5116e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 8.7110e-04 - val_loss: 1.6120e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 5.3132e-04 - val_loss: 1.5751e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 3.2587e-04 - val_loss: 9.2694e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 3.3390e-04 - val_loss: 1.2156e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 2.4275e-04 - val_loss: 1.3949e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 3.2618e-04 - val_loss: 1.6697e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 2.5355e-04 - val_loss: 9.9368e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 1.9671e-04 - val_loss: 1.1118e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 1.8844e-04 - val_loss: 8.3690e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 1.5671e-04 - val_loss: 7.0028e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 3.0040e-04 - val_loss: 1.4096e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 2.4792e-04 - val_loss: 1.2257e-04\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 2.0293e-04 - val_loss: 1.1535e-04\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 1.4011e-04 - val_loss: 1.4031e-04\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 1.7819e-04 - val_loss: 8.4978e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 1.1463e-04 - val_loss: 3.4685e-04\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 5s 269us/step - loss: 1.2855 - val_loss: 2.0291e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 0.0012 - val_loss: 2.0829e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 0.0011 - val_loss: 1.8815e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 33us/step - loss: 0.0011 - val_loss: 1.9540e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 0.0010 - val_loss: 2.0311e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 9.6058e-04 - val_loss: 1.8340e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 9.2575e-04 - val_loss: 2.1261e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 8.8735e-04 - val_loss: 2.1303e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 8.5586e-04 - val_loss: 1.7602e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 8.2748e-04 - val_loss: 1.8905e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 7.9279e-04 - val_loss: 1.7221e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 7.6844e-04 - val_loss: 1.9055e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 7.3996e-04 - val_loss: 1.7282e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 7.0973e-04 - val_loss: 1.7291e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 6.8411e-04 - val_loss: 1.7169e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 6.6217e-04 - val_loss: 1.7043e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 6.3756e-04 - val_loss: 2.2423e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 6.1483e-04 - val_loss: 1.7073e-04\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 5.9504e-04 - val_loss: 1.7127e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 33us/step - loss: 5.7059e-04 - val_loss: 1.7064e-04\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 5.5042e-04 - val_loss: 1.6244e-04\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 5.2953e-04 - val_loss: 1.8216e-04\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 5.1089e-04 - val_loss: 1.7126e-04\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 4.9274e-04 - val_loss: 1.7325e-04\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 5s 282us/step - loss: 1.5262 - val_loss: 1.5747e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 8.7094e-04 - val_loss: 1.2271e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 8.2212e-04 - val_loss: 1.1958e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 7.7838e-04 - val_loss: 1.1679e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 7.4547e-04 - val_loss: 1.9871e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 7.2008e-04 - val_loss: 1.1228e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 6.9552e-04 - val_loss: 1.1522e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 6.7282e-04 - val_loss: 1.1214e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 6.5122e-04 - val_loss: 1.0736e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 6.3142e-04 - val_loss: 1.2439e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 6.1261e-04 - val_loss: 1.1404e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 5.9440e-04 - val_loss: 1.0100e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 5.7711e-04 - val_loss: 9.9555e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 5.6025e-04 - val_loss: 1.0104e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 5.4287e-04 - val_loss: 9.8333e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 5.2471e-04 - val_loss: 9.5214e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 5.0947e-04 - val_loss: 1.0355e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 4.9154e-04 - val_loss: 9.6942e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 4.7728e-04 - val_loss: 1.0002e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 4.6084e-04 - val_loss: 9.1062e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 4.4482e-04 - val_loss: 9.9380e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 4.2856e-04 - val_loss: 8.0313e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 4.1264e-04 - val_loss: 1.6513e-04\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 3.9716e-04 - val_loss: 5.0133e-04\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 6s 308us/step - loss: 0.0682 - val_loss: 2.7054e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 0.0039 - val_loss: 1.3923e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 9.3923e-04 - val_loss: 0.0031\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 0.0016 - val_loss: 1.8484e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0027 - val_loss: 1.5530e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 7.8502e-04 - val_loss: 1.1022e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 0.0018 - val_loss: 6.5441e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 7.6663e-04 - val_loss: 0.0031\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0014 - val_loss: 1.0696e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 0.0014 - val_loss: 1.6023e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 6.7188e-04 - val_loss: 3.6843e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 6.1980e-04 - val_loss: 4.9270e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 4.4877e-04 - val_loss: 0.0014\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - ETA: 0s - loss: 5.0797e-0 - 1s 36us/step - loss: 5.0859e-04 - val_loss: 8.2769e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 3.9015e-04 - val_loss: 7.5909e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 4.0104e-04 - val_loss: 4.4528e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 3.4899e-04 - val_loss: 1.8845e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 2.9502e-04 - val_loss: 1.1503e-04\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 2.9027e-04 - val_loss: 5.5706e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 3.2257e-04 - val_loss: 1.4281e-04\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 2.6771e-04 - val_loss: 1.8965e-04\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 3.0828e-04 - val_loss: 4.6086e-04\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 2.4821e-04 - val_loss: 3.1767e-04\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 2.3738e-04 - val_loss: 5.6785e-05\n",
      "\n",
      "GENERATION 5\n",
      "\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 6s 304us/step - loss: 0.0016 - val_loss: 1.6246e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 0.0016 - val_loss: 1.5690e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 0.0010 - val_loss: 3.4031e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0011 - val_loss: 9.3499e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0011 - val_loss: 6.2291e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 9.7384e-04 - val_loss: 0.0012\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 9.6238e-04 - val_loss: 1.3321e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 8.5623e-04 - val_loss: 2.8832e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 9.6126e-04 - val_loss: 2.4414e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 8.5765e-04 - val_loss: 1.9252e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 8.5886e-04 - val_loss: 1.4551e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 8.9307e-04 - val_loss: 1.3791e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 7.7897e-04 - val_loss: 1.2660e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 8.0299e-04 - val_loss: 1.4680e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 7.4386e-04 - val_loss: 0.0022\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 8.6253e-04 - val_loss: 1.2053e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 7.0202e-04 - val_loss: 1.8019e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 7.3596e-04 - val_loss: 4.3547e-04\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 7.0256e-04 - val_loss: 3.2605e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 6.6248e-04 - val_loss: 8.4590e-04\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 6.5485e-04 - val_loss: 3.9447e-04\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 6.5413e-04 - val_loss: 1.3732e-04\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 5.9265e-04 - val_loss: 1.8117e-04\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 6.1257e-04 - val_loss: 1.1882e-04\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 6s 310us/step - loss: 0.0016 - val_loss: 1.2357e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 4.6832e-04 - val_loss: 2.8944e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 2.7600e-04 - val_loss: 3.5172e-05\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 9.9594e-05 - val_loss: 9.2683e-05\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 9.2598e-05 - val_loss: 6.3428e-05\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 1.2450e-04 - val_loss: 5.7393e-05\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 5.6440e-05 - val_loss: 1.9163e-05\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 4.8545e-05 - val_loss: 6.0499e-05\n",
      "Epoch 9/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18465/18465 [==============================] - 1s 36us/step - loss: 6.8659e-05 - val_loss: 2.9691e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 6.1521e-05 - val_loss: 2.0216e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 5.2441e-05 - val_loss: 3.1337e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 6.0528e-05 - val_loss: 3.1965e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 4.8455e-05 - val_loss: 2.0727e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 5.6936e-05 - val_loss: 3.3378e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 4.3679e-05 - val_loss: 2.1677e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 6.7774e-05 - val_loss: 2.1222e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 4.2333e-05 - val_loss: 2.0453e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 3.6006e-05 - val_loss: 3.6925e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 4.1357e-05 - val_loss: 6.9205e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 6.3415e-05 - val_loss: 3.7012e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 4.2012e-05 - val_loss: 3.3833e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 3.9071e-05 - val_loss: 3.8356e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 4.8352e-05 - val_loss: 5.6357e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 4.8300e-05 - val_loss: 2.0089e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 6s 317us/step - loss: 0.6002 - val_loss: 0.0497\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0111 - val_loss: 1.7018e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0011 - val_loss: 1.4871e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0010 - val_loss: 1.6736e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0010 - val_loss: 1.6627e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0010 - val_loss: 1.6721e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0010 - val_loss: 1.6343e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0010 - val_loss: 1.6563e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0010 - val_loss: 1.6524e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 0.0010 - val_loss: 1.6573e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0010 - val_loss: 1.6587e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0010 - val_loss: 1.6754e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0010 - val_loss: 1.6638e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 0.0010 - val_loss: 1.6481e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 0.0010 - val_loss: 1.6709e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0010 - val_loss: 1.6411e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0010 - val_loss: 1.6411e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0010 - val_loss: 1.6594e-04\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0010 - val_loss: 1.6519e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0010 - val_loss: 1.6331e-04\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0010 - val_loss: 1.7453e-04\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0010 - val_loss: 1.6258e-04\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0010 - val_loss: 1.6952e-04\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0010 - val_loss: 1.6665e-04\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 6s 327us/step - loss: 0.0044 - val_loss: 5.3275e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0011 - val_loss: 1.4863e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0010 - val_loss: 1.7010e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0010 - val_loss: 1.6604e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 0.0010 - val_loss: 1.4997e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0010 - val_loss: 1.7221e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0010 - val_loss: 1.7738e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0010 - val_loss: 1.6067e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0010 - val_loss: 1.5394e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0010 - val_loss: 1.6910e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 0.0010 - val_loss: 1.8997e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 0.0010 - val_loss: 1.8690e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 0.0010 - val_loss: 1.6871e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0010 - val_loss: 1.8454e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0010 - val_loss: 1.4418e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 9.8055e-04 - val_loss: 1.2471e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 9.0084e-04 - val_loss: 8.3657e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 8.1461e-04 - val_loss: 5.7331e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 7.3459e-04 - val_loss: 4.0860e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 6.5786e-04 - val_loss: 4.4317e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 6.0929e-04 - val_loss: 6.1265e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 5.7072e-04 - val_loss: 6.4073e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 5.3219e-04 - val_loss: 4.4010e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 4.8497e-04 - val_loss: 5.6506e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 6s 334us/step - loss: 0.0128 - val_loss: 8.9119e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0012 - val_loss: 1.6737e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 0.0010 - val_loss: 1.6924e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0010 - val_loss: 1.5539e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0010 - val_loss: 1.6079e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 0.0010 - val_loss: 1.6895e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0010 - val_loss: 1.6781e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0010 - val_loss: 1.9976e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 0.0010 - val_loss: 1.6222e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0010 - val_loss: 1.5569e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 0.0010 - val_loss: 1.6421e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 0.0010 - val_loss: 1.7885e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 0.0010 - val_loss: 1.5367e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 0.0010 - val_loss: 1.8449e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 0.0010 - val_loss: 1.6320e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0010 - val_loss: 1.4705e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0010 - val_loss: 1.7945e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0010 - val_loss: 1.4634e-04\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 9.9668e-04 - val_loss: 1.4299e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 9.4966e-04 - val_loss: 1.1155e-04\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 8.9030e-04 - val_loss: 7.5220e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 8.2599e-04 - val_loss: 5.5264e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 7.8316e-04 - val_loss: 7.1626e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 7.4277e-04 - val_loss: 6.8611e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 6s 344us/step - loss: 0.0184 - val_loss: 0.0015\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0013 - val_loss: 1.5164e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 0.0010 - val_loss: 1.6999e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 0.0010 - val_loss: 1.6794e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 0.0010 - val_loss: 1.7078e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 0.0010 - val_loss: 1.6978e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0010 - val_loss: 1.5633e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 0.0010 - val_loss: 1.7153e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0010 - val_loss: 1.6681e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0010 - val_loss: 1.5011e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0010 - val_loss: 1.7003e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0010 - val_loss: 1.5346e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 0.0010 - val_loss: 1.7763e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0010 - val_loss: 1.6513e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0010 - val_loss: 1.5599e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 0.0010 - val_loss: 1.7041e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 0.0010 - val_loss: 1.5866e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 0.0010 - val_loss: 1.8483e-04\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 0.0010 - val_loss: 1.6990e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 0.0010 - val_loss: 1.6122e-04\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 0.0010 - val_loss: 1.6539e-04\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 0.0010 - val_loss: 1.6671e-04\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 0.0010 - val_loss: 1.7773e-04\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 0.0010 - val_loss: 1.8001e-04\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 6s 351us/step - loss: 0.0016 - val_loss: 1.3600e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 7.5783e-04 - val_loss: 1.0881e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 5.2181e-04 - val_loss: 1.1289e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 3.2240e-04 - val_loss: 2.1896e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 2.0795e-04 - val_loss: 8.0391e-05\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 8.9209e-05 - val_loss: 5.7874e-05\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 1.5523e-04 - val_loss: 8.8442e-05\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 6.1324e-05 - val_loss: 5.8535e-05\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 4.9416e-05 - val_loss: 7.4426e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 5.6515e-05 - val_loss: 8.1403e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 5.3712e-05 - val_loss: 4.9754e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 4.2850e-05 - val_loss: 5.8455e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 8.2260e-05 - val_loss: 2.7062e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 7.0130e-05 - val_loss: 4.6414e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 6.6476e-05 - val_loss: 4.4597e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 4.1364e-05 - val_loss: 4.1204e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 4.0750e-05 - val_loss: 3.9350e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 4.2843e-05 - val_loss: 6.8290e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 4.2939e-05 - val_loss: 3.9730e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 4.1463e-05 - val_loss: 1.0214e-04\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 5.5323e-05 - val_loss: 6.1117e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 7.2039e-05 - val_loss: 4.9268e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 5.5070e-05 - val_loss: 3.5825e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 3.5652e-05 - val_loss: 3.2538e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 7s 363us/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18465/18465 [==============================] - 1s 38us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: nan - val_loss: nan\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 7s 372us/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: nan - val_loss: nan\n",
      "\n",
      "GENERATION 6\n",
      "\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 7s 371us/step - loss: 0.0014 - val_loss: 1.8373e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0013 - val_loss: 1.6897e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0013 - val_loss: 1.6289e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0013 - val_loss: 3.1033e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0012 - val_loss: 1.5851e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0012 - val_loss: 1.8091e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0012 - val_loss: 1.7168e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0012 - val_loss: 1.5111e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0012 - val_loss: 1.5347e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0011 - val_loss: 1.5137e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0011 - val_loss: 1.4639e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0011 - val_loss: 1.5538e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0011 - val_loss: 1.5175e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0011 - val_loss: 1.4737e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0011 - val_loss: 1.7582e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0011 - val_loss: 2.2036e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0011 - val_loss: 1.6223e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0011 - val_loss: 2.3303e-04\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0011 - val_loss: 1.4253e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0011 - val_loss: 1.4562e-04\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0011 - val_loss: 1.4941e-04\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0010 - val_loss: 1.4257e-04\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0010 - val_loss: 1.4792e-04\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0010 - val_loss: 1.5122e-04\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 7s 389us/step - loss: 9.9739e-04 - val_loss: 1.3294e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 6.9224e-04 - val_loss: 9.4335e-05\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 4.5499e-04 - val_loss: 2.4443e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 2.1856e-04 - val_loss: 5.0842e-05\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 1.1993e-04 - val_loss: 6.0865e-05\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 8.0412e-05 - val_loss: 2.8467e-05\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 5.2252e-05 - val_loss: 2.2665e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 9.7421e-05 - val_loss: 9.2409e-05\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 6.5128e-05 - val_loss: 4.8229e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 6.5137e-05 - val_loss: 4.4721e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 4.6870e-05 - val_loss: 2.4548e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 4.5777e-05 - val_loss: 2.7429e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 4.9061e-05 - val_loss: 4.1564e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 4.9091e-05 - val_loss: 2.3109e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 5.0700e-05 - val_loss: 2.5158e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 4.3567e-05 - val_loss: 3.2508e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 4.6238e-05 - val_loss: 2.8721e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 4.2885e-05 - val_loss: 6.4192e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 5.6656e-05 - val_loss: 2.3574e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 4.0648e-05 - val_loss: 9.0710e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 5.3370e-05 - val_loss: 7.2430e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 5.0379e-05 - val_loss: 3.2076e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 3.9943e-05 - val_loss: 2.5114e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 3.4817e-05 - val_loss: 1.8177e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 7s 371us/step - loss: 0.0019 - val_loss: 1.8295e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 6.5857e-04 - val_loss: 1.6349e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 4.0715e-04 - val_loss: 1.1107e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 2.7496e-04 - val_loss: 8.5036e-05\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 1.6317e-04 - val_loss: 6.6275e-05\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 1.2371e-04 - val_loss: 1.5260e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 8.7993e-05 - val_loss: 2.2348e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 1.2004e-04 - val_loss: 4.1074e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 1.2189e-04 - val_loss: 8.0624e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - ETA: 0s - loss: 6.9805e-0 - 1s 36us/step - loss: 6.8005e-05 - val_loss: 6.6058e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 5.3336e-05 - val_loss: 5.0606e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 4.2998e-05 - val_loss: 5.1860e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 4.7621e-05 - val_loss: 4.4657e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 4.5335e-05 - val_loss: 8.5964e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 5.2146e-05 - val_loss: 4.5975e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 9.0250e-05 - val_loss: 1.1985e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 6.4480e-05 - val_loss: 6.0842e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 4.6398e-05 - val_loss: 7.6121e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 4.8947e-05 - val_loss: 5.4994e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 4.9484e-05 - val_loss: 7.9684e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 5.6623e-05 - val_loss: 5.7825e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 4.5194e-05 - val_loss: 3.9895e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 5.0745e-05 - val_loss: 4.8436e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 5.7943e-05 - val_loss: 6.0323e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 7s 379us/step - loss: 0.0040 - val_loss: 1.7369e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 5.9071e-04 - val_loss: 2.3612e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 3.9596e-04 - val_loss: 8.8511e-05\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 1.7290e-04 - val_loss: 4.3781e-05\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 8.4642e-05 - val_loss: 3.9136e-05\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 1.2318e-04 - val_loss: 6.5128e-05\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 8.2165e-05 - val_loss: 2.3545e-05\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 5.4690e-05 - val_loss: 1.5188e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 6.3071e-05 - val_loss: 8.3319e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 9.4399e-05 - val_loss: 2.3207e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 4.0535e-05 - val_loss: 1.9722e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 5.8700e-05 - val_loss: 2.6234e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 4.2472e-05 - val_loss: 3.8794e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 8.3387e-05 - val_loss: 4.9172e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 5.1131e-05 - val_loss: 2.6061e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 4.2100e-05 - val_loss: 1.9842e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 4.8460e-05 - val_loss: 9.8207e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 5.2248e-05 - val_loss: 2.1778e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 4.0171e-05 - val_loss: 2.2531e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 5.9633e-05 - val_loss: 3.6355e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 6.9541e-05 - val_loss: 3.4811e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 6.8027e-05 - val_loss: 8.3897e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 5.8682e-05 - val_loss: 5.1785e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 4.7872e-05 - val_loss: 1.8962e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 7s 385us/step - loss: 0.0039 - val_loss: 3.4083e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 0.0013 - val_loss: 1.4814e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0012 - val_loss: 2.9046e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 0.0010 - val_loss: 1.7586e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 4.3379e-04 - val_loss: 0.0082\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 8.3720e-04 - val_loss: 2.0151e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0011 - val_loss: 1.8876e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 3.7926e-04 - val_loss: 1.7866e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 4.7932e-04 - val_loss: 2.8062e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 3.7146e-04 - val_loss: 0.0122\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 8.2292e-04 - val_loss: 1.6142e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 3.4886e-04 - val_loss: 2.2080e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 6.0815e-04 - val_loss: 2.3922e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 3.7586e-04 - val_loss: 1.2291e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 4.2383e-04 - val_loss: 1.4849e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 3.5740e-04 - val_loss: 0.0010\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 5.7929e-04 - val_loss: 1.1990e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 3.4387e-04 - val_loss: 1.5659e-04\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 4.4810e-04 - val_loss: 2.3498e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 2.8790e-04 - val_loss: 2.5864e-04\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 2.9334e-04 - val_loss: 1.0018e-04\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 6.7167e-04 - val_loss: 9.8486e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 2.3197e-04 - val_loss: 9.1101e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 5.9252e-04 - val_loss: 1.5787e-04\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 7s 391us/step - loss: 0.0057 - val_loss: 1.4194e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 0.0010 - val_loss: 1.5265e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 0.0011 - val_loss: 2.3100e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 5.9957e-04 - val_loss: 1.3699e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 4.7615e-04 - val_loss: 0.0221\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0012 - val_loss: 1.3026e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 4.0967e-04 - val_loss: 1.4946e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 0.0010 - val_loss: 1.5612e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 3.7058e-04 - val_loss: 1.7824e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 6.1378e-04 - val_loss: 2.6655e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 4.0011e-04 - val_loss: 1.7126e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 3.7103e-04 - val_loss: 1.5057e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0022 - val_loss: 4.0049e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 3.1453e-04 - val_loss: 1.7496e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 3.6538e-04 - val_loss: 3.4884e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 3.8585e-04 - val_loss: 1.5063e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 6.3207e-04 - val_loss: 1.9765e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 2.6537e-04 - val_loss: 1.5704e-04\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 3.2598e-04 - val_loss: 2.0879e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 3.6734e-04 - val_loss: 1.4503e-04\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 3.1508e-04 - val_loss: 1.5351e-04\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 2.9740e-04 - val_loss: 1.5397e-04\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 5.8756e-04 - val_loss: 1.3667e-04\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 2.4780e-04 - val_loss: 1.3864e-04\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 7s 393us/step - loss: 0.0041 - val_loss: 1.6916e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0012 - val_loss: 1.5075e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 9.2567e-04 - val_loss: 1.4740e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 8.2222e-04 - val_loss: 1.6293e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 6.0211e-04 - val_loss: 2.0175e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 4.8953e-04 - val_loss: 0.0013\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 4.6380e-04 - val_loss: 2.1504e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 4.9437e-04 - val_loss: 1.5133e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 8.2232e-04 - val_loss: 5.7910e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 3.8787e-04 - val_loss: 3.9300e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 4.4009e-04 - val_loss: 1.8529e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 3.6853e-04 - val_loss: 1.5674e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 3.7879e-04 - val_loss: 1.3834e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 3.7663e-04 - val_loss: 2.7871e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 3.2039e-04 - val_loss: 1.1844e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 4.0886e-04 - val_loss: 1.5352e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 2.9485e-04 - val_loss: 1.5224e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 7.3645e-04 - val_loss: 1.5590e-04\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 2.7149e-04 - val_loss: 1.4626e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 4.5615e-04 - val_loss: 1.3343e-04\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 2.9951e-04 - val_loss: 1.3615e-04\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 3.2013e-04 - val_loss: 1.4085e-04\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 3.1574e-04 - val_loss: 1.8516e-04\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 2.9709e-04 - val_loss: 1.5379e-04\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 7s 403us/step - loss: 0.0025 - val_loss: 5.3857e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0016 - val_loss: 1.5041e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0012 - val_loss: 1.4329e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0010 - val_loss: 1.5544e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 7.5204e-04 - val_loss: 1.6969e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 7.7399e-04 - val_loss: 1.3364e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 5.0460e-04 - val_loss: 1.6765e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 5.4780e-04 - val_loss: 1.4885e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 3.4095e-04 - val_loss: 1.3116e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 0.0011 - val_loss: 1.9701e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 3.4193e-04 - val_loss: 1.4636e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 4.3723e-04 - val_loss: 1.4125e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 4.5178e-04 - val_loss: 2.8602e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 3.5055e-04 - val_loss: 1.9662e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 3.6244e-04 - val_loss: 1.4119e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 5.5536e-04 - val_loss: 3.5869e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 3.1393e-04 - val_loss: 1.5349e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 3.5958e-04 - val_loss: 1.8448e-04\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 4.1296e-04 - val_loss: 1.6187e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 3.3453e-04 - val_loss: 1.5000e-04\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 4.0791e-04 - val_loss: 1.1438e-04\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 2.5378e-04 - val_loss: 2.1421e-04\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 4.0473e-04 - val_loss: 1.7928e-04\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 3.0538e-04 - val_loss: 2.3053e-04\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 8s 410us/step - loss: 0.0013 - val_loss: 1.8633e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 0.0014 - val_loss: 2.2419e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 9.6917e-04 - val_loss: 3.3671e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 7.9610e-04 - val_loss: 0.0248\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 0.0013 - val_loss: 1.5378e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 4.2109e-04 - val_loss: 2.0094e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 5.2640e-04 - val_loss: 1.4972e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 3.6975e-04 - val_loss: 2.4212e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 3.4713e-04 - val_loss: 4.9752e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 3.4128e-04 - val_loss: 1.8851e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 3.4519e-04 - val_loss: 5.4862e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 3.3204e-04 - val_loss: 1.3350e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 35us/step - loss: 3.2706e-04 - val_loss: 2.7451e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 3.7169e-04 - val_loss: 1.4541e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 2.8269e-04 - val_loss: 4.4549e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 2.9964e-04 - val_loss: 1.4803e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 2.5790e-04 - val_loss: 1.5045e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 2.9980e-04 - val_loss: 1.2051e-04\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 2.7057e-04 - val_loss: 1.0329e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 2.9333e-04 - val_loss: 1.3135e-04\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 2.4750e-04 - val_loss: 1.3530e-04\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 2.2385e-04 - val_loss: 8.1266e-04\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 2.3068e-04 - val_loss: 3.9325e-04\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 34us/step - loss: 2.2605e-04 - val_loss: 9.9958e-05\n",
      "\n",
      "GENERATION 7\n",
      "\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 8s 430us/step - loss: 0.0011 - val_loss: 1.3803e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 6.6897e-04 - val_loss: 2.5318e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 2.4383e-04 - val_loss: 7.6928e-05\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 1.4529e-04 - val_loss: 6.2227e-05\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 8.1107e-05 - val_loss: 4.9162e-05\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 7.1354e-05 - val_loss: 1.0253e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 1.1391e-04 - val_loss: 1.3465e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 8.8807e-05 - val_loss: 7.0458e-05\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 6.0862e-05 - val_loss: 4.1042e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 5.3518e-05 - val_loss: 8.4449e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 7.7060e-05 - val_loss: 1.3526e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 6.8197e-05 - val_loss: 2.9017e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 4.5754e-05 - val_loss: 5.4656e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 6.5398e-05 - val_loss: 5.9715e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 6.1353e-05 - val_loss: 3.1381e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 4.5446e-05 - val_loss: 1.0555e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 7.5701e-05 - val_loss: 2.7930e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 4.2375e-05 - val_loss: 2.6946e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 4.5340e-05 - val_loss: 1.1816e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 1.3097e-04 - val_loss: 4.5986e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 4.9521e-05 - val_loss: 3.0783e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 4.2967e-05 - val_loss: 3.3547e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 4.8477e-05 - val_loss: 5.5163e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 5.7855e-05 - val_loss: 3.1478e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 8s 434us/step - loss: 0.0034 - val_loss: 1.8808e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 7.9700e-04 - val_loss: 1.8730e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 4.9309e-04 - val_loss: 8.8608e-05\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 2.4731e-04 - val_loss: 9.6479e-05\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 1.4982e-04 - val_loss: 1.0481e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 8.5812e-05 - val_loss: 6.9189e-05\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 6.6342e-05 - val_loss: 4.6674e-05\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 6.9182e-05 - val_loss: 1.0078e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 8.0347e-05 - val_loss: 5.2521e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 6.1254e-05 - val_loss: 4.7404e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 5.8129e-05 - val_loss: 5.4645e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 5.3385e-05 - val_loss: 5.1467e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 6.2258e-05 - val_loss: 3.9565e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 6.3411e-05 - val_loss: 5.9894e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 5.5535e-05 - val_loss: 5.7941e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 4.7528e-05 - val_loss: 5.0931e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 5.8185e-05 - val_loss: 1.4376e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 8.3930e-05 - val_loss: 3.4743e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 4.5438e-05 - val_loss: 4.2574e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 4.4158e-05 - val_loss: 3.3204e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 4.5985e-05 - val_loss: 5.9474e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 5.2586e-05 - val_loss: 3.4048e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 4.6766e-05 - val_loss: 4.0176e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 4.5790e-05 - val_loss: 4.0300e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 8s 439us/step - loss: 0.0057 - val_loss: 1.7184e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 7.9458e-04 - val_loss: 1.0813e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 5.0062e-04 - val_loss: 7.9828e-05\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 2.4138e-04 - val_loss: 6.7536e-05\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 9.7597e-05 - val_loss: 1.1738e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 7.9053e-05 - val_loss: 3.1455e-05\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 6.1561e-05 - val_loss: 1.8271e-05\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 4.9488e-05 - val_loss: 1.1892e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 6.0918e-05 - val_loss: 2.4768e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 5.8832e-05 - val_loss: 3.5471e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 5.9837e-05 - val_loss: 1.9179e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 5.1428e-05 - val_loss: 1.1766e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 5.7506e-05 - val_loss: 2.6224e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 4.9222e-05 - val_loss: 1.1005e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 8.6068e-05 - val_loss: 5.9109e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 6.8998e-05 - val_loss: 2.4033e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 4.2673e-05 - val_loss: 1.7317e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 4.0231e-05 - val_loss: 1.6653e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 4.1113e-05 - val_loss: 1.7846e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 4.1670e-05 - val_loss: 3.7630e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 3.9210e-05 - val_loss: 1.7188e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 4.4743e-05 - val_loss: 1.9312e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - ETA: 0s - loss: 4.6454e-0 - 1s 36us/step - loss: 4.4924e-05 - val_loss: 2.5130e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 4.1331e-05 - val_loss: 2.4818e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 8s 448us/step - loss: 0.6415 - val_loss: 3.7288e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 0.0027 - val_loss: 5.5103e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 9.7791e-04 - val_loss: 2.0361e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 8.9739e-04 - val_loss: 1.9137e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 8.8014e-04 - val_loss: 1.8587e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 8.5426e-04 - val_loss: 1.8351e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 8.3470e-04 - val_loss: 1.7956e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 8.1569e-04 - val_loss: 1.7640e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 7.9505e-04 - val_loss: 1.6690e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 7.7712e-04 - val_loss: 1.6604e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 7.5895e-04 - val_loss: 1.5891e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 7.4037e-04 - val_loss: 1.5920e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 7.2065e-04 - val_loss: 1.4819e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 7.0467e-04 - val_loss: 1.5062e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 6.8644e-04 - val_loss: 1.4525e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 6.6837e-04 - val_loss: 1.3985e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 6.4889e-04 - val_loss: 1.3382e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 6.3242e-04 - val_loss: 1.3348e-04\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 6.1111e-04 - val_loss: 1.2979e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 5.9487e-04 - val_loss: 1.3129e-04\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 5.7792e-04 - val_loss: 1.2376e-04\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - ETA: 0s - loss: 5.5958e-0 - 1s 36us/step - loss: 5.5930e-04 - val_loss: 1.1637e-04\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 5.4265e-04 - val_loss: 1.1461e-04\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 5.2317e-04 - val_loss: 1.1148e-04\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 8s 456us/step - loss: 1.7430 - val_loss: 0.0705\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 0.0116 - val_loss: 2.2070e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0017 - val_loss: 2.0004e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0014 - val_loss: 1.9796e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 0.0013 - val_loss: 1.9354e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 0.0013 - val_loss: 1.9257e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 0.0012 - val_loss: 1.8377e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0012 - val_loss: 1.7330e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 0.0011 - val_loss: 1.7973e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 0.0011 - val_loss: 1.7286e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 0.0010 - val_loss: 1.6821e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 0.0010 - val_loss: 1.6011e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 9.6941e-04 - val_loss: 1.6527e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 9.3112e-04 - val_loss: 1.7121e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 8.9398e-04 - val_loss: 1.6416e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 8.6207e-04 - val_loss: 1.4826e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 8.2873e-04 - val_loss: 1.4416e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 36us/step - loss: 7.8959e-04 - val_loss: 1.4004e-04\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 7.5478e-04 - val_loss: 1.3833e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 7.2000e-04 - val_loss: 1.3073e-04\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 7.0089e-04 - val_loss: 1.2718e-04\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 6.6910e-04 - val_loss: 1.2063e-04\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 6.4073e-04 - val_loss: 1.1539e-04\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 6.1194e-04 - val_loss: 1.0922e-04\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 9s 498us/step - loss: 2.1860 - val_loss: 0.0024\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 0.0031 - val_loss: 3.5185e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 0.0011 - val_loss: 1.6183e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 0.0010 - val_loss: 1.7184e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 9.7905e-04 - val_loss: 1.6257e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 9.4887e-04 - val_loss: 1.5949e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 9.1612e-04 - val_loss: 1.5360e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 8.8531e-04 - val_loss: 1.5793e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 8.5721e-04 - val_loss: 1.6936e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 8.2815e-04 - val_loss: 1.3860e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 7.9674e-04 - val_loss: 1.4143e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 7.7127e-04 - val_loss: 1.4083e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 7.4105e-04 - val_loss: 1.3604e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 7.1001e-04 - val_loss: 1.2910e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 6.7916e-04 - val_loss: 1.2436e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 6.5138e-04 - val_loss: 1.3107e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 6.1776e-04 - val_loss: 1.8888e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 5.7784e-04 - val_loss: 1.3161e-04\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 5.4197e-04 - val_loss: 1.2282e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 5.0956e-04 - val_loss: 1.1090e-04\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 4.7997e-04 - val_loss: 1.1035e-04\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 4.5217e-04 - val_loss: 1.1825e-04\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 4.2981e-04 - val_loss: 1.0401e-04\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 4.0786e-04 - val_loss: 1.1162e-04\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 9s 506us/step - loss: 1.8306 - val_loss: 0.0054\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 0.0033 - val_loss: 3.5335e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 0.0011 - val_loss: 1.6882e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 9.9498e-04 - val_loss: 1.6227e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 9.5199e-04 - val_loss: 1.5957e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 9.1470e-04 - val_loss: 1.4620e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 8.8233e-04 - val_loss: 1.3876e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 8.5666e-04 - val_loss: 1.3918e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 8.3135e-04 - val_loss: 1.3364e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 8.0037e-04 - val_loss: 1.2626e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 7.8071e-04 - val_loss: 1.3975e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 7.5096e-04 - val_loss: 1.1813e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 7.2946e-04 - val_loss: 1.1476e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 7.0317e-04 - val_loss: 1.2353e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 6.8077e-04 - val_loss: 1.0808e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 6.5596e-04 - val_loss: 1.1501e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 6.3414e-04 - val_loss: 1.0303e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 6.1085e-04 - val_loss: 9.9853e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 5.8653e-04 - val_loss: 9.6775e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 5.6074e-04 - val_loss: 1.0116e-04\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 5.4415e-04 - val_loss: 9.4640e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 5.2259e-04 - val_loss: 8.9468e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 5.0517e-04 - val_loss: 9.0665e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 4.8115e-04 - val_loss: 8.3932e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 9s 506us/step - loss: 3.5341 - val_loss: 0.0033\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 0.0054 - val_loss: 0.0011\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 0.0013 - val_loss: 1.4468e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 0.0012 - val_loss: 1.3864e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 0.0011 - val_loss: 1.3071e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 0.0011 - val_loss: 1.3449e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 0.0011 - val_loss: 1.4108e-04\n",
      "Epoch 8/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18465/18465 [==============================] - 1s 39us/step - loss: 0.0011 - val_loss: 1.2809e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 0.0011 - val_loss: 1.3604e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 0.0010 - val_loss: 1.3512e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 0.0010 - val_loss: 1.4760e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 0.0010 - val_loss: 1.2373e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 9.8021e-04 - val_loss: 1.3104e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 9.5607e-04 - val_loss: 1.2771e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 9.5769e-04 - val_loss: 1.2659e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 9.2285e-04 - val_loss: 1.2540e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 9.1271e-04 - val_loss: 1.2306e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 8.8659e-04 - val_loss: 1.1634e-04\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 8.7772e-04 - val_loss: 1.1628e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 8.5560e-04 - val_loss: 1.2007e-04\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 8.4931e-04 - val_loss: 1.1354e-04\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 8.1667e-04 - val_loss: 1.1262e-04\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 8.0770e-04 - val_loss: 1.1185e-04\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 7.9007e-04 - val_loss: 1.1178e-04\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 9s 501us/step - loss: 3.2713 - val_loss: 0.0087\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 0.0025 - val_loss: 2.7882e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 0.0012 - val_loss: 2.5221e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 0.0011 - val_loss: 1.9689e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 0.0011 - val_loss: 2.0705e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 0.0011 - val_loss: 2.2606e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 0.0011 - val_loss: 1.8217e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 0.0010 - val_loss: 1.7369e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 0.0010 - val_loss: 2.0004e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 0.0010 - val_loss: 1.7862e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 9.8197e-04 - val_loss: 2.0146e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 9.6796e-04 - val_loss: 1.7512e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 9.5413e-04 - val_loss: 1.9232e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 9.3380e-04 - val_loss: 1.7626e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 9.2137e-04 - val_loss: 1.6267e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 9.0614e-04 - val_loss: 1.6149e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 8.9336e-04 - val_loss: 1.6434e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 8.7973e-04 - val_loss: 1.6518e-04\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 8.6660e-04 - val_loss: 1.6373e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 8.5476e-04 - val_loss: 1.6694e-04\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 8.4065e-04 - val_loss: 2.0247e-04\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 8.3360e-04 - val_loss: 1.4737e-04\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 8.2189e-04 - val_loss: 1.7539e-04\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 8.0315e-04 - val_loss: 1.4822e-04\n",
      "\n",
      "GENERATION 8\n",
      "\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 9s 511us/step - loss: 0.0092 - val_loss: 1.4733e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 8.1300e-04 - val_loss: 2.0611e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 6.4599e-04 - val_loss: 1.5523e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 8.1245e-04 - val_loss: 5.3525e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 4.6633e-04 - val_loss: 1.8054e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 3.5259e-04 - val_loss: 1.4131e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 2.7957e-04 - val_loss: 6.8504e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 3.6630e-04 - val_loss: 1.5070e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 2.5259e-04 - val_loss: 1.3190e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 2.3846e-04 - val_loss: 1.1604e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 2.1304e-04 - val_loss: 1.0707e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 2.1992e-04 - val_loss: 1.3797e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 2.3554e-04 - val_loss: 7.1182e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 1.7555e-04 - val_loss: 1.6687e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 2.1687e-04 - val_loss: 1.1559e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 1.4848e-04 - val_loss: 1.4215e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 1.6833e-04 - val_loss: 1.9545e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 1.9471e-04 - val_loss: 1.2786e-04\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 1.8842e-04 - val_loss: 1.3796e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 1.5885e-04 - val_loss: 1.2262e-04\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 1.4808e-04 - val_loss: 6.6595e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 1.2975e-04 - val_loss: 4.8317e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 1.4473e-04 - val_loss: 5.5503e-04\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 2.8472e-04 - val_loss: 9.6343e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 10s 524us/step - loss: 0.0012 - val_loss: 2.1199e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 6.3915e-04 - val_loss: 1.1647e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 3.3947e-04 - val_loss: 1.3868e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 1.4452e-04 - val_loss: 8.2919e-05\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 1.6108e-04 - val_loss: 8.1975e-05\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 3.8745e-04 - val_loss: 1.2982e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 2.6698e-04 - val_loss: 5.9721e-05\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 6.7405e-05 - val_loss: 4.7866e-05\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 5.3424e-05 - val_loss: 5.5928e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 6.1279e-05 - val_loss: 5.0442e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 4.8761e-05 - val_loss: 6.9341e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 7.8128e-05 - val_loss: 6.0208e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 6.0443e-05 - val_loss: 1.1433e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 6.3840e-05 - val_loss: 4.9337e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 4.0853e-05 - val_loss: 4.8973e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 3.7114e-05 - val_loss: 7.0463e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 4.3635e-05 - val_loss: 4.0312e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 6.4547e-05 - val_loss: 1.1246e-04\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 6.1201e-05 - val_loss: 3.9566e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 37us/step - loss: 3.8297e-05 - val_loss: 4.0670e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 3.9749e-05 - val_loss: 7.0927e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 4.4539e-05 - val_loss: 6.7545e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 3.8638e-05 - val_loss: 5.9248e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 5.4568e-05 - val_loss: 5.1014e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 10s 531us/step - loss: 0.0027 - val_loss: 1.2222e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 6.4740e-04 - val_loss: 8.9920e-05\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 3.2490e-04 - val_loss: 6.7491e-05\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 2.7438e-04 - val_loss: 5.2873e-05\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 1.0726e-04 - val_loss: 7.7915e-05\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 6.8297e-05 - val_loss: 5.0474e-05\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 5.4771e-05 - val_loss: 2.4319e-05\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 4.5551e-05 - val_loss: 5.8641e-05\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 5.7965e-05 - val_loss: 3.0799e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 4.7478e-05 - val_loss: 4.2187e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 4.4666e-05 - val_loss: 4.9543e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 3.9928e-05 - val_loss: 2.4943e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 4.3053e-05 - val_loss: 4.3797e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 4.4285e-05 - val_loss: 2.4591e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 5.5254e-05 - val_loss: 1.1743e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 6.0966e-05 - val_loss: 6.3428e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 4.8997e-05 - val_loss: 2.5528e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 4.2909e-05 - val_loss: 3.7872e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 4.4924e-05 - val_loss: 2.4420e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 5.5238e-05 - val_loss: 4.1359e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 4.5757e-05 - val_loss: 9.5757e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 1.1098e-04 - val_loss: 3.8489e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 5.1362e-05 - val_loss: 5.1089e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 4.3547e-05 - val_loss: 2.8483e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 10s 547us/step - loss: 0.0538 - val_loss: 9.4254e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 0.0015 - val_loss: 3.4402e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 0.0010 - val_loss: 1.5301e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 9.7269e-04 - val_loss: 1.4799e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 9.4814e-04 - val_loss: 1.3648e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 9.2247e-04 - val_loss: 1.6057e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 8.9497e-04 - val_loss: 1.4648e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 8.7220e-04 - val_loss: 1.2802e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 8.4785e-04 - val_loss: 1.2440e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 8.2496e-04 - val_loss: 1.2379e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 8.0028e-04 - val_loss: 1.3410e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 7.6224e-04 - val_loss: 1.3075e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 7.0177e-04 - val_loss: 9.2239e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 5.7828e-04 - val_loss: 4.6709e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 3.9791e-04 - val_loss: 8.7627e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 3.4810e-04 - val_loss: 3.6561e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 3.0728e-04 - val_loss: 3.3194e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 2.4286e-04 - val_loss: 4.2115e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 2.0143e-04 - val_loss: 3.1691e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 1.5660e-04 - val_loss: 4.3930e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 1.3722e-04 - val_loss: 3.3004e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 1.0855e-04 - val_loss: 8.0082e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 1.0358e-04 - val_loss: 3.2983e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 9.4098e-05 - val_loss: 4.2510e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 10s 552us/step - loss: 0.3782 - val_loss: 0.0013\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 0.0020 - val_loss: 1.9311e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 0.0010 - val_loss: 1.6390e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 0.0010 - val_loss: 1.8024e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 0.0010 - val_loss: 1.6219e-04\n",
      "Epoch 6/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18465/18465 [==============================] - 1s 39us/step - loss: 0.0010 - val_loss: 1.6586e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 0.0010 - val_loss: 1.5713e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 0.0010 - val_loss: 1.6430e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 0.0010 - val_loss: 1.5818e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 9.9943e-04 - val_loss: 1.5296e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 9.9563e-04 - val_loss: 1.5522e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 9.8977e-04 - val_loss: 1.5991e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 9.8458e-04 - val_loss: 1.5451e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 9.7935e-04 - val_loss: 1.6627e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 9.7426e-04 - val_loss: 1.4607e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 9.6818e-04 - val_loss: 1.6218e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 9.6158e-04 - val_loss: 1.5831e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 9.5526e-04 - val_loss: 1.5213e-04\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 9.4915e-04 - val_loss: 1.5530e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 9.4209e-04 - val_loss: 1.4908e-04\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 9.3589e-04 - val_loss: 1.5518e-04\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 9.2796e-04 - val_loss: 1.4371e-04\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 9.2117e-04 - val_loss: 1.5761e-04\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 9.1428e-04 - val_loss: 1.4277e-04\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 11s 571us/step - loss: 0.1583 - val_loss: 0.0030\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 0.0014 - val_loss: 1.9863e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 0.0010 - val_loss: 1.6393e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 0.0010 - val_loss: 1.6075e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 0.0010 - val_loss: 1.5764e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 0.0010 - val_loss: 1.6821e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 0.0010 - val_loss: 1.6179e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 0.0010 - val_loss: 1.7261e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 0.0010 - val_loss: 1.6156e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 0.0010 - val_loss: 1.5901e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 0.0010 - val_loss: 1.6135e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 0.0010 - val_loss: 1.6264e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 0.0010 - val_loss: 1.6244e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 0.0010 - val_loss: 1.6469e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 0.0010 - val_loss: 1.6180e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 0.0010 - val_loss: 1.5667e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 0.0010 - val_loss: 1.5682e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 0.0010 - val_loss: 1.5555e-04\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 42us/step - loss: 0.0010 - val_loss: 1.5669e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 0.0010 - val_loss: 1.6048e-04\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 9.9896e-04 - val_loss: 1.7011e-04\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 9.9691e-04 - val_loss: 1.7159e-04\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 9.9417e-04 - val_loss: 1.6046e-04\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 9.9093e-04 - val_loss: 1.5945e-04\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 11s 583us/step - loss: 0.1352 - val_loss: 6.1218e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 0.0014 - val_loss: 1.5144e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 42us/step - loss: 0.0010 - val_loss: 1.6117e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 0.0010 - val_loss: 1.5881e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 9.9162e-04 - val_loss: 1.4902e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 9.6370e-04 - val_loss: 1.5711e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 9.3436e-04 - val_loss: 1.3707e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 8.9891e-04 - val_loss: 1.4133e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 8.5983e-04 - val_loss: 1.2913e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 8.1388e-04 - val_loss: 1.3557e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 7.6609e-04 - val_loss: 1.1889e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 7.1752e-04 - val_loss: 1.1533e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 6.5021e-04 - val_loss: 1.2086e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 5.7559e-04 - val_loss: 9.8715e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 4.8559e-04 - val_loss: 8.0522e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 3.8109e-04 - val_loss: 6.4509e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 2.8250e-04 - val_loss: 4.8144e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 1.9367e-04 - val_loss: 3.9373e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 1.2321e-04 - val_loss: 2.9302e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 8.8281e-05 - val_loss: 2.6075e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 6.8350e-05 - val_loss: 4.7849e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 5.6280e-05 - val_loss: 4.7593e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 5.8221e-05 - val_loss: 4.7702e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 4.5268e-05 - val_loss: 3.9240e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 11s 591us/step - loss: 0.1238 - val_loss: 0.0034\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 0.0015 - val_loss: 1.4936e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 0.0010 - val_loss: 1.6156e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 0.0010 - val_loss: 1.6224e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 9.8683e-04 - val_loss: 1.5151e-04\n",
      "Epoch 6/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18465/18465 [==============================] - 1s 40us/step - loss: 9.6825e-04 - val_loss: 1.5719e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 9.4892e-04 - val_loss: 1.5340e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 9.2837e-04 - val_loss: 1.5359e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 9.0522e-04 - val_loss: 1.4193e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 8.7748e-04 - val_loss: 1.3142e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 8.5144e-04 - val_loss: 1.4074e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 8.1951e-04 - val_loss: 1.3290e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 7.8375e-04 - val_loss: 1.2855e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 7.4604e-04 - val_loss: 1.3237e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 7.0080e-04 - val_loss: 1.1563e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 6.5345e-04 - val_loss: 1.0965e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 5.9628e-04 - val_loss: 1.1115e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 5.3194e-04 - val_loss: 1.0142e-04\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 4.5718e-04 - val_loss: 8.8281e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 3.6899e-04 - val_loss: 6.9107e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 2.8231e-04 - val_loss: 6.2769e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 2.0567e-04 - val_loss: 4.5912e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 1.4532e-04 - val_loss: 4.0195e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 1.0416e-04 - val_loss: 3.2198e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 11s 602us/step - loss: 0.1524 - val_loss: 0.0017\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 0.0013 - val_loss: 1.4628e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 0.0010 - val_loss: 1.5612e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 9.8436e-04 - val_loss: 1.5209e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 9.6310e-04 - val_loss: 1.5722e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 9.4502e-04 - val_loss: 1.4420e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 9.1779e-04 - val_loss: 1.4564e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 8.9085e-04 - val_loss: 1.4243e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 8.5660e-04 - val_loss: 1.8755e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 8.1585e-04 - val_loss: 1.2654e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 7.5552e-04 - val_loss: 1.2748e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 7.1131e-04 - val_loss: 1.4067e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 6.6257e-04 - val_loss: 1.1740e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 42us/step - loss: 6.0902e-04 - val_loss: 1.1349e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 5.4166e-04 - val_loss: 1.0909e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 4.6708e-04 - val_loss: 1.1208e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 3.8769e-04 - val_loss: 8.4619e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 2.9911e-04 - val_loss: 7.0908e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 2.2489e-04 - val_loss: 6.1579e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 1.7005e-04 - val_loss: 5.3853e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 1.3003e-04 - val_loss: 4.2820e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 1.0320e-04 - val_loss: 3.5175e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 8.5345e-05 - val_loss: 2.9361e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 7.3926e-05 - val_loss: 2.2690e-05\n",
      "\n",
      "GENERATION 9\n",
      "\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 11s 615us/step - loss: 0.0113 - val_loss: 4.4758e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 7.9721e-04 - val_loss: 1.2349e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 5.2709e-04 - val_loss: 6.9145e-05\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 3.2404e-04 - val_loss: 9.1951e-05\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 1.7586e-04 - val_loss: 1.3900e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 1.2995e-04 - val_loss: 5.1613e-05\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 6.9174e-05 - val_loss: 5.0289e-05\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 5.8406e-05 - val_loss: 4.5027e-05\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 5.4144e-05 - val_loss: 4.5508e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 5.1183e-05 - val_loss: 5.4947e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 4.8621e-05 - val_loss: 4.2602e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 4.6461e-05 - val_loss: 4.4726e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 4.3552e-05 - val_loss: 4.1809e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 4.2762e-05 - val_loss: 1.3997e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 7.1596e-05 - val_loss: 4.2822e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 3.8766e-05 - val_loss: 3.3016e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 4.7809e-05 - val_loss: 4.2216e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 42us/step - loss: 4.7503e-05 - val_loss: 4.9566e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 5.3183e-05 - val_loss: 3.8025e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 4.4949e-05 - val_loss: 4.7090e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 4.4765e-05 - val_loss: 2.8948e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 3.6385e-05 - val_loss: 3.9299e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 3.9974e-05 - val_loss: 3.1691e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 3.7740e-05 - val_loss: 3.4139e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 11s 622us/step - loss: 0.0011 - val_loss: 2.0270e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 8.4904e-04 - val_loss: 9.6336e-05\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 2.8262e-04 - val_loss: 5.1568e-05\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 1.2468e-04 - val_loss: 3.2957e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 1.1752e-04 - val_loss: 3.0582e-05\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 7.4814e-05 - val_loss: 2.2035e-05\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 6.1192e-05 - val_loss: 2.7751e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 1.0372e-04 - val_loss: 2.1726e-05\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 6.0130e-05 - val_loss: 2.7595e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 6.6479e-05 - val_loss: 1.9004e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 5.4385e-05 - val_loss: 3.9873e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 5.8318e-05 - val_loss: 4.2791e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 5.0437e-05 - val_loss: 2.1749e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 7.2139e-05 - val_loss: 3.1189e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 5.6355e-05 - val_loss: 5.6791e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 4.9579e-05 - val_loss: 7.9827e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 5.3235e-05 - val_loss: 1.9877e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 3.6728e-05 - val_loss: 2.1079e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 4.9742e-05 - val_loss: 3.2670e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 4.5439e-05 - val_loss: 1.5621e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 42us/step - loss: 6.2110e-05 - val_loss: 1.5792e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 3.9952e-05 - val_loss: 1.4996e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 4.6012e-05 - val_loss: 1.5974e-04\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 7.9865e-05 - val_loss: 1.9898e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 12s 624us/step - loss: 0.0015 - val_loss: 1.5785e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 0.0011 - val_loss: 1.5240e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 0.0011 - val_loss: 1.4931e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 0.0011 - val_loss: 1.4991e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 0.0011 - val_loss: 1.5439e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 0.0010 - val_loss: 1.4814e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 0.0010 - val_loss: 1.6086e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 0.0010 - val_loss: 1.5345e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 0.0010 - val_loss: 1.4537e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 0.0010 - val_loss: 1.7128e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 0.0010 - val_loss: 1.5162e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 0.0010 - val_loss: 1.4837e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 0.0010 - val_loss: 1.4794e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 0.0010 - val_loss: 1.5528e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 9.9869e-04 - val_loss: 1.4977e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 9.9464e-04 - val_loss: 1.4470e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 9.9082e-04 - val_loss: 1.5478e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 9.8725e-04 - val_loss: 1.5540e-04\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 9.8385e-04 - val_loss: 1.3994e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 9.8018e-04 - val_loss: 1.4347e-04\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 38us/step - loss: 9.7511e-04 - val_loss: 1.4892e-04\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 9.7117e-04 - val_loss: 1.4453e-04\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 9.6903e-04 - val_loss: 1.3966e-04\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 9.6570e-04 - val_loss: 1.4490e-04\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 12s 634us/step - loss: 1.0819 - val_loss: 1.9238e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 0.0011 - val_loss: 1.5830e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 9.9343e-04 - val_loss: 2.0519e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 9.2694e-04 - val_loss: 1.3561e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 8.6950e-04 - val_loss: 1.8532e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 8.3194e-04 - val_loss: 1.2634e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 7.8907e-04 - val_loss: 1.9142e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 7.4999e-04 - val_loss: 1.1863e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 7.1683e-04 - val_loss: 1.5161e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 6.9361e-04 - val_loss: 1.1333e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 6.5550e-04 - val_loss: 1.2722e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 6.3353e-04 - val_loss: 1.1158e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 6.0495e-04 - val_loss: 1.1677e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 5.7563e-04 - val_loss: 1.1247e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 5.5276e-04 - val_loss: 9.8655e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 5.3140e-04 - val_loss: 1.2235e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 5.0986e-04 - val_loss: 9.1915e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 4.8222e-04 - val_loss: 1.1947e-04\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 4.7013e-04 - val_loss: 1.0108e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 4.4050e-04 - val_loss: 9.0891e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 39us/step - loss: 4.1945e-04 - val_loss: 8.5314e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 3.9909e-04 - val_loss: 8.3716e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 3.7996e-04 - val_loss: 7.9248e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 3.6936e-04 - val_loss: 8.2281e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 12s 666us/step - loss: 1.5231 - val_loss: 1.5621e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 0.0010 - val_loss: 1.4972e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 9.7716e-04 - val_loss: 1.5807e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 9.4322e-04 - val_loss: 2.1154e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 42us/step - loss: 9.2095e-04 - val_loss: 1.5148e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 8.9881e-04 - val_loss: 1.5379e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 8.7689e-04 - val_loss: 3.0579e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 42us/step - loss: 8.6472e-04 - val_loss: 1.3443e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 8.4477e-04 - val_loss: 1.4499e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 8.2414e-04 - val_loss: 1.3172e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 8.0810e-04 - val_loss: 1.3547e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 7.9360e-04 - val_loss: 2.7082e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 7.8268e-04 - val_loss: 1.2714e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 7.6493e-04 - val_loss: 1.4178e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 7.4882e-04 - val_loss: 1.5273e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 7.3828e-04 - val_loss: 1.3852e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 7.2661e-04 - val_loss: 1.4614e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 7.1272e-04 - val_loss: 1.2477e-04\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 7.0120e-04 - val_loss: 1.4658e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 6.8968e-04 - val_loss: 1.2228e-04\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 6.7738e-04 - val_loss: 1.2031e-04\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 6.6492e-04 - val_loss: 2.0839e-04\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 6.5443e-04 - val_loss: 1.3002e-04\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 6.4008e-04 - val_loss: 1.6681e-04\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 12s 654us/step - loss: 1.5754 - val_loss: 1.4892e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 42us/step - loss: 0.0010 - val_loss: 1.4981e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 42us/step - loss: 9.7717e-04 - val_loss: 1.5442e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 42us/step - loss: 9.4754e-04 - val_loss: 1.4667e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 9.2171e-04 - val_loss: 4.9489e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 42us/step - loss: 9.0213e-04 - val_loss: 1.4499e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 42us/step - loss: 8.7470e-04 - val_loss: 1.3394e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 8.5561e-04 - val_loss: 1.3776e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 42us/step - loss: 8.3557e-04 - val_loss: 1.3419e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 42us/step - loss: 8.1901e-04 - val_loss: 1.4739e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 42us/step - loss: 8.0093e-04 - val_loss: 1.3013e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 42us/step - loss: 7.8441e-04 - val_loss: 1.3137e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 42us/step - loss: 7.7097e-04 - val_loss: 1.2997e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 7.5364e-04 - val_loss: 1.3064e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 42us/step - loss: 7.3762e-04 - val_loss: 1.5152e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 42us/step - loss: 7.2179e-04 - val_loss: 1.3045e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 7.0592e-04 - val_loss: 1.2594e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 42us/step - loss: 6.9088e-04 - val_loss: 1.2684e-04\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 42us/step - loss: 6.7461e-04 - val_loss: 1.3012e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 42us/step - loss: 6.5995e-04 - val_loss: 1.2399e-04\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 42us/step - loss: 6.4453e-04 - val_loss: 1.2324e-04\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 42us/step - loss: 6.3016e-04 - val_loss: 1.3814e-04\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 6.1378e-04 - val_loss: 1.5389e-04\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 42us/step - loss: 5.9931e-04 - val_loss: 1.1919e-04\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 13s 700us/step - loss: 0.0302 - val_loss: 0.0012\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 0.0013 - val_loss: 1.4858e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 9.9562e-04 - val_loss: 1.8703e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 9.5794e-04 - val_loss: 1.4393e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 9.1667e-04 - val_loss: 1.4540e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 8.7553e-04 - val_loss: 1.3690e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 45us/step - loss: 8.2547e-04 - val_loss: 1.5243e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 7.6274e-04 - val_loss: 1.2343e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 6.8458e-04 - val_loss: 1.5836e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 5.5809e-04 - val_loss: 9.2033e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 4.1061e-04 - val_loss: 6.8919e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 2.6561e-04 - val_loss: 5.0239e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 1.5758e-04 - val_loss: 3.8044e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 1.0332e-04 - val_loss: 4.3561e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 7.3979e-05 - val_loss: 3.3921e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 6.2071e-05 - val_loss: 3.8347e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 5.4453e-05 - val_loss: 3.9457e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 5.1183e-05 - val_loss: 3.0859e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 4.5916e-05 - val_loss: 3.3040e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 4.3961e-05 - val_loss: 4.6254e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 4.5361e-05 - val_loss: 2.9896e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 3.9578e-05 - val_loss: 3.7656e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 4.0823e-05 - val_loss: 2.9430e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 3.7569e-05 - val_loss: 2.9957e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 13s 691us/step - loss: 0.0017 - val_loss: 2.6713e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 0.0011 - val_loss: 2.0155e-04\n",
      "Epoch 3/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18465/18465 [==============================] - 1s 41us/step - loss: 0.0010 - val_loss: 1.5903e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 0.0011 - val_loss: 1.5331e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 42us/step - loss: 0.0010 - val_loss: 1.6206e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 0.0010 - val_loss: 1.4732e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 0.0010 - val_loss: 1.6041e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 0.0010 - val_loss: 1.3744e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 9.5112e-04 - val_loss: 1.0290e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 8.4547e-04 - val_loss: 7.2371e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 7.2336e-04 - val_loss: 5.1425e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 5.8873e-04 - val_loss: 1.4106e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 5.1927e-04 - val_loss: 1.9803e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 4.6199e-04 - val_loss: 4.3434e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 3.5876e-04 - val_loss: 5.6802e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 2.8967e-04 - val_loss: 2.2754e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 2.6457e-04 - val_loss: 6.4125e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 1.8709e-04 - val_loss: 3.6773e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 1.3448e-04 - val_loss: 3.5403e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 1.2202e-04 - val_loss: 8.8681e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 1.3086e-04 - val_loss: 4.0559e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 1.0784e-04 - val_loss: 6.2426e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 7.8500e-05 - val_loss: 2.9595e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 40us/step - loss: 8.5161e-05 - val_loss: 8.9900e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 13s 719us/step - loss: 0.0014 - val_loss: 1.4996e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 0.0013 - val_loss: 3.1307e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 46us/step - loss: 0.0012 - val_loss: 3.3152e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 0.0012 - val_loss: 1.5469e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 0.0011 - val_loss: 3.3009e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 0.0013 - val_loss: 1.6229e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 0.0011 - val_loss: 5.6827e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 0.0012 - val_loss: 3.7967e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 9.7891e-04 - val_loss: 4.0855e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 9.8651e-04 - val_loss: 2.4050e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 8.6609e-04 - val_loss: 2.5446e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 7.9325e-04 - val_loss: 9.9244e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 6.6297e-04 - val_loss: 8.3382e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 6.5015e-04 - val_loss: 1.2100e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 5.3077e-04 - val_loss: 2.2261e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 4.4268e-04 - val_loss: 2.2427e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 3.6817e-04 - val_loss: 3.7731e-04\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 3.3729e-04 - val_loss: 2.4025e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 2.9388e-04 - val_loss: 8.9493e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 2.7447e-04 - val_loss: 1.3231e-04\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 2.5188e-04 - val_loss: 9.3694e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 45us/step - loss: 2.3565e-04 - val_loss: 4.7159e-04\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 2.6109e-04 - val_loss: 2.6176e-04\n",
      "\n",
      "GENERATION 10\n",
      "\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 13s 726us/step - loss: 0.0014 - val_loss: 1.5696e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 6.1462e-04 - val_loss: 6.0014e-05\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 4.3949e-04 - val_loss: 5.0120e-05\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 1.7331e-04 - val_loss: 1.7055e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 1.3319e-04 - val_loss: 5.2805e-05\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 7.9101e-05 - val_loss: 5.6163e-05\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 8.3620e-05 - val_loss: 5.5535e-05\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 2.1694e-04 - val_loss: 5.3349e-05\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 6.0427e-05 - val_loss: 8.7565e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 5.0066e-05 - val_loss: 9.4810e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 4.5052e-05 - val_loss: 6.2185e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 42us/step - loss: 5.1300e-05 - val_loss: 6.5104e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 4.4929e-05 - val_loss: 2.4905e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 9.2002e-05 - val_loss: 6.7548e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 4.0897e-05 - val_loss: 3.9333e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 6.3869e-05 - val_loss: 5.5741e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 4.8135e-05 - val_loss: 3.9005e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 4.2150e-05 - val_loss: 4.1918e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 3.7914e-05 - val_loss: 4.2548e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 4.6924e-05 - val_loss: 6.0129e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 4.7252e-05 - val_loss: 7.6881e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 5.3147e-05 - val_loss: 9.7923e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 5.8636e-05 - val_loss: 4.9833e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 4.0520e-05 - val_loss: 6.1892e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 14s 744us/step - loss: 0.0294 - val_loss: 9.6380e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 0.0012 - val_loss: 1.6636e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 9.7341e-04 - val_loss: 1.4593e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 9.3996e-04 - val_loss: 1.6522e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 8.9683e-04 - val_loss: 1.3388e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 8.4603e-04 - val_loss: 1.5343e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 7.8718e-04 - val_loss: 1.6240e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 7.1439e-04 - val_loss: 1.2697e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 6.2166e-04 - val_loss: 1.0435e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 5.0192e-04 - val_loss: 8.8215e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 3.6134e-04 - val_loss: 7.6572e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 2.3659e-04 - val_loss: 6.7328e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 1.5087e-04 - val_loss: 3.7619e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 46us/step - loss: 1.0158e-04 - val_loss: 3.1631e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 45us/step - loss: 7.7803e-05 - val_loss: 2.7396e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 6.3881e-05 - val_loss: 2.7117e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 5.5702e-05 - val_loss: 2.6818e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 5.1060e-05 - val_loss: 3.0796e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 4.8399e-05 - val_loss: 3.9402e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 4.6023e-05 - val_loss: 2.4111e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 4.2704e-05 - val_loss: 2.3589e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 4.1010e-05 - val_loss: 2.4151e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 3.9580e-05 - val_loss: 2.4341e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 3.9936e-05 - val_loss: 2.3035e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 14s 746us/step - loss: 0.0158 - val_loss: 0.0112\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 0.0036 - val_loss: 0.0012\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 0.0027 - val_loss: 4.2790e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 0.0021 - val_loss: 8.9651e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 0.0020 - val_loss: 1.6491e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 0.0014 - val_loss: 4.2535e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 0.0013 - val_loss: 1.4679e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 0.0010 - val_loss: 0.0531\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 45us/step - loss: 0.0026 - val_loss: 1.6107e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 8.3211e-04 - val_loss: 3.4657e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 9.9476e-04 - val_loss: 1.4596e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 7.9707e-04 - val_loss: 9.5724e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 7.6371e-04 - val_loss: 5.9849e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 8.7844e-04 - val_loss: 3.3322e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 7.7944e-04 - val_loss: 2.2193e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 8.2119e-04 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 7.4527e-04 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 7.4916e-04 - val_loss: 9.4691e-04\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 7.4299e-04 - val_loss: 3.2151e-04\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 6.7737e-04 - val_loss: 2.1696e-04\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 6.9119e-04 - val_loss: 3.9133e-04\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 7.6924e-04 - val_loss: 3.0093e-04\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 14s 758us/step - loss: 0.0225 - val_loss: 0.0033\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 0.0031 - val_loss: 0.0017\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 0.0027 - val_loss: 8.5558e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 45us/step - loss: 0.0021 - val_loss: 0.0048\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 0.0021 - val_loss: 0.0050\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 0.0012 - val_loss: 2.5866e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 9.6785e-04 - val_loss: 8.7604e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 0.0010 - val_loss: 2.2105e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 8.7690e-04 - val_loss: 0.0026\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 9.4587e-04 - val_loss: 4.1413e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 9.6539e-04 - val_loss: 5.2897e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 0.0010 - val_loss: 1.5516e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 7.0314e-04 - val_loss: 3.8713e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 8.3936e-04 - val_loss: 8.7960e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 7.6910e-04 - val_loss: 2.9405e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 0.0013 - val_loss: 2.2284e-04\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 6.9836e-04 - val_loss: 6.8251e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 6.5861e-04 - val_loss: 6.1473e-04\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 7.9685e-04 - val_loss: 0.0019\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 7.5857e-04 - val_loss: 1.4640e-04\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 6.7859e-04 - val_loss: 8.1619e-04\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 45us/step - loss: 6.5337e-04 - val_loss: 2.0544e-04\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 14s 771us/step - loss: 0.4030 - val_loss: 0.0295\n",
      "Epoch 2/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18465/18465 [==============================] - 1s 41us/step - loss: 0.0406 - val_loss: 0.0235\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 0.0190 - val_loss: 0.0012\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 0.0118 - val_loss: 3.5169e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 0.0084 - val_loss: 1.6422e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 0.0037 - val_loss: 1.6260e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 0.0023 - val_loss: 0.0067\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 0.0018 - val_loss: 1.9579e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 0.0010 - val_loss: 2.0152e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 42us/step - loss: 0.0032 - val_loss: 1.0406e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 8.2098e-04 - val_loss: 9.7230e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 0.0013 - val_loss: 2.4038e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 42us/step - loss: 0.0011 - val_loss: 3.4056e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 42us/step - loss: 0.0012 - val_loss: 3.3099e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 8.3944e-04 - val_loss: 1.0542e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 7.2312e-04 - val_loss: 2.0185e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 0.0013 - val_loss: 2.5379e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 9.1134e-04 - val_loss: 4.3006e-04\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 0.0011 - val_loss: 2.3163e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 6.8594e-04 - val_loss: 8.1838e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 6.6955e-04 - val_loss: 7.4439e-04\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 9.3198e-04 - val_loss: 5.1023e-04\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 6.3361e-04 - val_loss: 5.4294e-04\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 42us/step - loss: 7.9046e-04 - val_loss: 4.4733e-04\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 15s 797us/step - loss: 1.0517 - val_loss: 1.4493e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 0.0010 - val_loss: 1.5458e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 0.0010 - val_loss: 1.5674e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 45us/step - loss: 9.9910e-04 - val_loss: 2.1149e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 9.8978e-04 - val_loss: 1.3962e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 9.7759e-04 - val_loss: 1.4941e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 9.7125e-04 - val_loss: 1.3790e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 9.6330e-04 - val_loss: 0.0012\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 9.7602e-04 - val_loss: 7.9443e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 9.5579e-04 - val_loss: 1.3496e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 45us/step - loss: 9.3111e-04 - val_loss: 1.8183e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 46us/step - loss: 9.2455e-04 - val_loss: 1.3259e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 9.1440e-04 - val_loss: 1.3492e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 9.0488e-04 - val_loss: 1.3082e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 8.9806e-04 - val_loss: 1.3132e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 8.8960e-04 - val_loss: 1.2927e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 8.8161e-04 - val_loss: 1.6301e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 45us/step - loss: 8.7194e-04 - val_loss: 1.3234e-04\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 8.6409e-04 - val_loss: 1.2860e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 8.5737e-04 - val_loss: 1.2717e-04\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 45us/step - loss: 8.4627e-04 - val_loss: 1.2660e-04\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 8.4137e-04 - val_loss: 1.6098e-04\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 8.3019e-04 - val_loss: 1.2562e-04\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 8.1917e-04 - val_loss: 1.5655e-04\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 15s 804us/step - loss: 0.3424 - val_loss: 1.5581e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 46us/step - loss: 0.0010 - val_loss: 1.7584e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 46us/step - loss: 0.0010 - val_loss: 1.9034e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 46us/step - loss: 0.0010 - val_loss: 1.5464e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 46us/step - loss: 0.0010 - val_loss: 1.4928e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 45us/step - loss: 0.0010 - val_loss: 1.4583e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 45us/step - loss: 0.0010 - val_loss: 1.6898e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 45us/step - loss: 0.0010 - val_loss: 1.4717e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 45us/step - loss: 0.0010 - val_loss: 1.4434e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 45us/step - loss: 0.0010 - val_loss: 1.5175e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 45us/step - loss: 9.9769e-04 - val_loss: 2.0091e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 45us/step - loss: 9.9564e-04 - val_loss: 1.4978e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 45us/step - loss: 9.9073e-04 - val_loss: 1.7248e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 45us/step - loss: 9.8677e-04 - val_loss: 1.4543e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 45us/step - loss: 9.8494e-04 - val_loss: 0.0010\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 45us/step - loss: 9.9879e-04 - val_loss: 1.6747e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 45us/step - loss: 9.7591e-04 - val_loss: 1.4101e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 45us/step - loss: 9.7320e-04 - val_loss: 1.6150e-04\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 45us/step - loss: 9.7050e-04 - val_loss: 1.4793e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 45us/step - loss: 9.6683e-04 - val_loss: 2.0080e-04\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 45us/step - loss: 9.6501e-04 - val_loss: 3.5380e-04\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 46us/step - loss: 9.6138e-04 - val_loss: 1.4991e-04\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 9.5365e-04 - val_loss: 1.8462e-04\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 45us/step - loss: 9.4979e-04 - val_loss: 1.4136e-04\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 15s 798us/step - loss: 0.1509 - val_loss: 1.4839e-04\n",
      "Epoch 2/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18465/18465 [==============================] - 1s 41us/step - loss: 0.0010 - val_loss: 1.6037e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 0.0010 - val_loss: 1.6957e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 9.9298e-04 - val_loss: 1.4451e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 9.8297e-04 - val_loss: 1.4293e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 9.7202e-04 - val_loss: 1.8730e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 9.6263e-04 - val_loss: 1.4017e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 9.5184e-04 - val_loss: 2.6163e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 9.4186e-04 - val_loss: 1.4844e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 9.3264e-04 - val_loss: 1.3966e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 9.2714e-04 - val_loss: 1.7256e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 9.2023e-04 - val_loss: 1.3721e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 9.0744e-04 - val_loss: 4.6668e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 9.0668e-04 - val_loss: 1.3622e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 42us/step - loss: 8.9400e-04 - val_loss: 1.4217e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 42us/step - loss: 8.8976e-04 - val_loss: 1.3786e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 8.7807e-04 - val_loss: 1.3165e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - ETA: 0s - loss: 8.7519e-0 - 1s 41us/step - loss: 8.7222e-04 - val_loss: 1.8945e-04\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 8.6574e-04 - val_loss: 1.3102e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 8.5781e-04 - val_loss: 1.3604e-04\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 8.5372e-04 - val_loss: 1.2901e-04\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 8.4582e-04 - val_loss: 1.2822e-04\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 8.4029e-04 - val_loss: 2.6349e-04\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 41us/step - loss: 8.3160e-04 - val_loss: 1.3384e-04\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 15s 803us/step - loss: 0.0020 - val_loss: 2.2413e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 0.0014 - val_loss: 3.7796e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 0.0014 - val_loss: 0.0022\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 0.0014 - val_loss: 2.3181e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 0.0013 - val_loss: 3.2609e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 0.0013 - val_loss: 2.4281e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 0.0013 - val_loss: 2.0997e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 45us/step - loss: 0.0013 - val_loss: 2.3920e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 0.0013 - val_loss: 4.8810e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 0.0012 - val_loss: 2.1967e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 0.0012 - val_loss: 2.0488e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 0.0012 - val_loss: 1.9779e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 0.0012 - val_loss: 1.9657e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 0.0012 - val_loss: 2.1689e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 0.0011 - val_loss: 8.3223e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 0.0012 - val_loss: 1.9687e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 0.0011 - val_loss: 2.2058e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 0.0011 - val_loss: 2.6431e-04\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 0.0011 - val_loss: 2.1430e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 0.0011 - val_loss: 1.8875e-04\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 0.0011 - val_loss: 3.1578e-04\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 0.0011 - val_loss: 2.0968e-04\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 43us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 44us/step - loss: 0.0011 - val_loss: 1.8122e-04\n",
      "\n",
      "GENERATION 11\n",
      "\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 15s 838us/step - loss: 0.0041 - val_loss: 1.5982e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 45us/step - loss: 8.8695e-04 - val_loss: 1.5327e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 46us/step - loss: 6.7037e-04 - val_loss: 9.5286e-05\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 45us/step - loss: 3.4832e-04 - val_loss: 1.1103e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 45us/step - loss: 1.5090e-04 - val_loss: 4.8974e-05\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 45us/step - loss: 7.0834e-05 - val_loss: 3.4998e-05\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 45us/step - loss: 5.1723e-05 - val_loss: 3.4338e-05\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 45us/step - loss: 1.6705e-04 - val_loss: 3.7922e-05\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 45us/step - loss: 6.3715e-05 - val_loss: 5.7882e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 45us/step - loss: 5.3116e-05 - val_loss: 2.6184e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 46us/step - loss: 4.0762e-05 - val_loss: 2.3194e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 45us/step - loss: 3.8866e-05 - val_loss: 2.1260e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 45us/step - loss: 4.4618e-05 - val_loss: 3.2179e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 45us/step - loss: 4.6196e-05 - val_loss: 3.7920e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 45us/step - loss: 5.3378e-05 - val_loss: 1.1412e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 45us/step - loss: 4.0887e-05 - val_loss: 2.5322e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 46us/step - loss: 6.1448e-05 - val_loss: 2.7481e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 46us/step - loss: 4.3380e-05 - val_loss: 2.2837e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 45us/step - loss: 4.2912e-05 - val_loss: 5.6895e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 45us/step - loss: 4.5365e-05 - val_loss: 2.5119e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 45us/step - loss: 4.3810e-05 - val_loss: 2.6560e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 45us/step - loss: 3.9597e-05 - val_loss: 2.2486e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 45us/step - loss: 3.7081e-05 - val_loss: 2.4646e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 45us/step - loss: 6.0798e-05 - val_loss: 3.2958e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 16s 853us/step - loss: 0.0061 - val_loss: 1.4575e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 45us/step - loss: 7.2502e-04 - val_loss: 4.5060e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 45us/step - loss: 4.3765e-04 - val_loss: 1.4233e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 45us/step - loss: 1.7980e-04 - val_loss: 4.2585e-05\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 46us/step - loss: 1.2140e-04 - val_loss: 2.7122e-05\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: 7.2373e-05 - val_loss: 3.5918e-05\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 45us/step - loss: 6.1796e-05 - val_loss: 3.2105e-05\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 46us/step - loss: 5.2675e-05 - val_loss: 2.3187e-05\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 45us/step - loss: 5.1386e-05 - val_loss: 2.1351e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 45us/step - loss: 1.3133e-04 - val_loss: 4.9971e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 46us/step - loss: 5.3795e-05 - val_loss: 5.3136e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 45us/step - loss: 5.2389e-05 - val_loss: 3.6623e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 45us/step - loss: 4.2619e-05 - val_loss: 4.9600e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 46us/step - loss: 4.1987e-05 - val_loss: 4.6782e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 45us/step - loss: 4.2540e-05 - val_loss: 2.4563e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 45us/step - loss: 7.8595e-05 - val_loss: 2.1383e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 46us/step - loss: 8.4062e-05 - val_loss: 2.6853e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 46us/step - loss: 3.9281e-05 - val_loss: 2.4670e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 46us/step - loss: 4.5623e-05 - val_loss: 2.4814e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 45us/step - loss: 4.3246e-05 - val_loss: 2.8740e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 45us/step - loss: 4.9814e-05 - val_loss: 3.7429e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 45us/step - loss: 4.5805e-05 - val_loss: 2.2467e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 46us/step - loss: 4.0270e-05 - val_loss: 2.6824e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 45us/step - loss: 4.8004e-05 - val_loss: 3.4425e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 16s 866us/step - loss: 0.0238 - val_loss: 0.0028\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 46us/step - loss: 0.0014 - val_loss: 1.5564e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 46us/step - loss: 0.0010 - val_loss: 1.5914e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 46us/step - loss: 9.9824e-04 - val_loss: 1.5727e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 46us/step - loss: 9.8267e-04 - val_loss: 1.6397e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 46us/step - loss: 9.8026e-04 - val_loss: 1.8190e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 45us/step - loss: 9.4641e-04 - val_loss: 1.4049e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 46us/step - loss: 9.2269e-04 - val_loss: 1.4177e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 46us/step - loss: 9.0592e-04 - val_loss: 1.4862e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 46us/step - loss: 8.7262e-04 - val_loss: 1.5326e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 45us/step - loss: 8.1941e-04 - val_loss: 1.6167e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 46us/step - loss: 7.4461e-04 - val_loss: 1.1479e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: 5.6398e-04 - val_loss: 8.7042e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 46us/step - loss: 4.2831e-04 - val_loss: 3.7273e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 46us/step - loss: 3.2462e-04 - val_loss: 5.6960e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 46us/step - loss: 2.4809e-04 - val_loss: 3.3695e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 46us/step - loss: 1.8295e-04 - val_loss: 1.4906e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 46us/step - loss: 1.9157e-04 - val_loss: 3.7456e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 45us/step - loss: 1.2693e-04 - val_loss: 1.0447e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 46us/step - loss: 1.2994e-04 - val_loss: 5.2846e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 46us/step - loss: 1.1646e-04 - val_loss: 4.1403e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 46us/step - loss: 1.0344e-04 - val_loss: 6.4546e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 46us/step - loss: 8.3816e-05 - val_loss: 3.2194e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 46us/step - loss: 9.3922e-05 - val_loss: 4.7445e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 16s 884us/step - loss: 0.0762 - val_loss: 0.0012\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 0.0017 - val_loss: 1.8531e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 46us/step - loss: 9.6649e-04 - val_loss: 1.3947e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 9.0285e-04 - val_loss: 1.3440e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 46us/step - loss: 8.4777e-04 - val_loss: 1.2716e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 7.9370e-04 - val_loss: 1.2746e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 7.3775e-04 - val_loss: 1.1979e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 6.7318e-04 - val_loss: 1.3101e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 46us/step - loss: 6.0453e-04 - val_loss: 1.2190e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 5.1976e-04 - val_loss: 1.8099e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 4.1100e-04 - val_loss: 7.6649e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 2.9781e-04 - val_loss: 5.0345e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 46us/step - loss: 2.0614e-04 - val_loss: 4.5642e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 46us/step - loss: 1.4970e-04 - val_loss: 2.9406e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 46us/step - loss: 9.9438e-05 - val_loss: 2.9168e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 46us/step - loss: 7.7443e-05 - val_loss: 2.8782e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 46us/step - loss: 6.4716e-05 - val_loss: 3.0983e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 5.8762e-05 - val_loss: 3.0822e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 5.6512e-05 - val_loss: 3.4432e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 4.8206e-05 - val_loss: 3.5298e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 46us/step - loss: 4.7146e-05 - val_loss: 3.2499e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 46us/step - loss: 4.8053e-05 - val_loss: 2.7795e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 4.7365e-05 - val_loss: 4.2163e-05\n",
      "Epoch 24/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18465/18465 [==============================] - 1s 46us/step - loss: 4.4177e-05 - val_loss: 8.1941e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 16s 887us/step - loss: 0.0708 - val_loss: 0.0040\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 46us/step - loss: 0.0016 - val_loss: 1.8991e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 8.7020e-04 - val_loss: 1.2590e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 7.9692e-04 - val_loss: 1.2189e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 7.2944e-04 - val_loss: 1.1337e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 6.6430e-04 - val_loss: 1.2248e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 5.9365e-04 - val_loss: 1.1018e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 46us/step - loss: 5.0843e-04 - val_loss: 8.9940e-05\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 46us/step - loss: 4.1782e-04 - val_loss: 8.9920e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 3.1445e-04 - val_loss: 6.3218e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 46us/step - loss: 2.2844e-04 - val_loss: 5.2444e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 1.6000e-04 - val_loss: 4.0995e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 46us/step - loss: 1.1231e-04 - val_loss: 7.2386e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 8.7620e-05 - val_loss: 6.0983e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 8.4563e-05 - val_loss: 3.1670e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 5.8945e-05 - val_loss: 2.7110e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 46us/step - loss: 5.3204e-05 - val_loss: 2.2152e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 4.9535e-05 - val_loss: 2.4386e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 46us/step - loss: 4.8417e-05 - val_loss: 2.5179e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 5.1094e-05 - val_loss: 2.4869e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 4.7292e-05 - val_loss: 2.3061e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 4.5950e-05 - val_loss: 2.1629e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: 4.4105e-05 - val_loss: 2.2065e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 4.3783e-05 - val_loss: 2.1753e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 17s 901us/step - loss: 0.0898 - val_loss: 2.5039e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 46us/step - loss: 0.0018 - val_loss: 1.9832e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 9.1766e-04 - val_loss: 1.5657e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 8.0986e-04 - val_loss: 1.3126e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 7.3834e-04 - val_loss: 1.1734e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 6.6508e-04 - val_loss: 1.0957e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 5.7854e-04 - val_loss: 9.7089e-05\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: 4.9552e-04 - val_loss: 8.5965e-05\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 4.1724e-04 - val_loss: 7.3471e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 3.3987e-04 - val_loss: 6.4792e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 2.7023e-04 - val_loss: 5.5180e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 2.1402e-04 - val_loss: 5.3437e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 1.6181e-04 - val_loss: 3.6113e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 1.1938e-04 - val_loss: 3.0944e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 9.3306e-05 - val_loss: 3.0891e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 7.6116e-05 - val_loss: 2.4461e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 6.4311e-05 - val_loss: 2.1149e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 5.7067e-05 - val_loss: 1.9874e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 5.2081e-05 - val_loss: 1.9698e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 4.9467e-05 - val_loss: 2.0719e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 4.6751e-05 - val_loss: 1.8847e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 4.5196e-05 - val_loss: 1.8672e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 4.4377e-05 - val_loss: 1.9282e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 4.3530e-05 - val_loss: 1.8290e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 17s 930us/step - loss: 0.1273 - val_loss: 0.0039\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: 0.0015 - val_loss: 2.2289e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: 8.8595e-04 - val_loss: 1.7122e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: 8.1858e-04 - val_loss: 1.2282e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: 7.3047e-04 - val_loss: 1.2197e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: 6.5975e-04 - val_loss: 1.1382e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: 5.7856e-04 - val_loss: 1.0676e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: 4.9722e-04 - val_loss: 1.2795e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: 4.1859e-04 - val_loss: 9.7671e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 3.1159e-04 - val_loss: 7.8171e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 50us/step - loss: 2.2714e-04 - val_loss: 5.2524e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 1.5891e-04 - val_loss: 5.0522e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: 1.0937e-04 - val_loss: 4.0399e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: 7.8148e-05 - val_loss: 5.0872e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: 7.0747e-05 - val_loss: 3.5131e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: 6.0945e-05 - val_loss: 3.5270e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: 5.1573e-05 - val_loss: 3.5075e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: 5.0871e-05 - val_loss: 3.5777e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: 4.7857e-05 - val_loss: 3.5516e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 5.0303e-05 - val_loss: 3.5715e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: 5.0687e-05 - val_loss: 4.1380e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: 4.8618e-05 - val_loss: 3.4809e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: 4.6879e-05 - val_loss: 3.5077e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: 4.6546e-05 - val_loss: 3.7610e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 17s 942us/step - loss: 0.1615 - val_loss: 0.0023\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 0.0014 - val_loss: 1.6949e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 0.0010 - val_loss: 1.4756e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 9.7069e-04 - val_loss: 1.4417e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 9.4751e-04 - val_loss: 1.5586e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 9.2895e-04 - val_loss: 1.4966e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 9.0521e-04 - val_loss: 1.4307e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 8.8366e-04 - val_loss: 1.3721e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 8.6454e-04 - val_loss: 1.3852e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 8.4191e-04 - val_loss: 1.4174e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 8.2050e-04 - val_loss: 1.3785e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: 7.9669e-04 - val_loss: 1.3099e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: 7.8174e-04 - val_loss: 1.2698e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 7.5483e-04 - val_loss: 1.3374e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: 7.3392e-04 - val_loss: 1.2863e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 7.1100e-04 - val_loss: 1.2983e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 6.8916e-04 - val_loss: 1.3032e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 6.6126e-04 - val_loss: 1.1078e-04\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 6.3534e-04 - val_loss: 1.1383e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 6.1097e-04 - val_loss: 1.0610e-04\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 5.8521e-04 - val_loss: 1.1121e-04\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 5.6082e-04 - val_loss: 1.0014e-04\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 5.3570e-04 - val_loss: 1.0095e-04\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 5.0718e-04 - val_loss: 9.5581e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 17s 941us/step - loss: 0.1497 - val_loss: 0.0059\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 0.0020 - val_loss: 1.7762e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 9.9241e-04 - val_loss: 1.6102e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 46us/step - loss: 9.1321e-04 - val_loss: 1.4626e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 46us/step - loss: 8.5862e-04 - val_loss: 1.3689e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 8.0897e-04 - val_loss: 1.3416e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 46us/step - loss: 7.6382e-04 - val_loss: 1.1767e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 7.2297e-04 - val_loss: 1.1216e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 46us/step - loss: 6.7761e-04 - val_loss: 1.0921e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 46us/step - loss: 6.3869e-04 - val_loss: 1.0734e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 5.9783e-04 - val_loss: 1.0118e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 46us/step - loss: 5.5976e-04 - val_loss: 9.2239e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 46us/step - loss: 5.2361e-04 - val_loss: 9.3322e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 4.8756e-04 - val_loss: 8.8341e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: 4.5104e-04 - val_loss: 8.0795e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 4.1898e-04 - val_loss: 7.5266e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 3.8659e-04 - val_loss: 7.1479e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 46us/step - loss: 3.5615e-04 - val_loss: 7.0866e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 3.2316e-04 - val_loss: 6.5675e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 2.9527e-04 - val_loss: 5.9590e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 2.6901e-04 - val_loss: 5.6867e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: 2.4353e-04 - val_loss: 5.4527e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 46us/step - loss: 2.2152e-04 - val_loss: 5.1813e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 46us/step - loss: 1.9838e-04 - val_loss: 5.0881e-05\n",
      "\n",
      "GENERATION 12\n",
      "\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 19s 1ms/step - loss: 0.0013 - val_loss: 1.3282e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: 5.8659e-04 - val_loss: 1.0686e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: 2.5522e-04 - val_loss: 1.4447e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: 1.2861e-04 - val_loss: 7.2175e-05\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: 1.1319e-04 - val_loss: 1.1576e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: 6.6540e-05 - val_loss: 3.6131e-05\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: 1.1224e-04 - val_loss: 9.1977e-05\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: 9.3017e-05 - val_loss: 5.0802e-05\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 6.8767e-05 - val_loss: 1.4443e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 1.0050e-04 - val_loss: 7.9970e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: 6.0277e-05 - val_loss: 2.9511e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 51us/step - loss: 4.7188e-05 - val_loss: 2.5807e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: 4.5924e-05 - val_loss: 1.7629e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: 1.1616e-04 - val_loss: 4.1598e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 1.7192e-04 - val_loss: 4.1368e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 5.5801e-05 - val_loss: 3.3735e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: 4.9636e-05 - val_loss: 1.9070e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 5.1196e-05 - val_loss: 2.4130e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 4.2787e-05 - val_loss: 1.7962e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: 4.4457e-05 - val_loss: 2.1700e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 4.5311e-05 - val_loss: 1.8441e-05\n",
      "Epoch 22/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18465/18465 [==============================] - 1s 49us/step - loss: 3.9406e-05 - val_loss: 2.0654e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: 4.5686e-05 - val_loss: 3.1761e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 6.2890e-05 - val_loss: 4.0372e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 18s 975us/step - loss: 0.0014 - val_loss: 1.3327e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 5.4645e-04 - val_loss: 1.8722e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 2.5182e-04 - val_loss: 1.1721e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 1.2474e-04 - val_loss: 1.0975e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 3.1248e-04 - val_loss: 1.3673e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 1.6663e-04 - val_loss: 6.8320e-05\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: 7.7840e-05 - val_loss: 6.4187e-05\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: 6.3381e-05 - val_loss: 8.6565e-05\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 9.0265e-05 - val_loss: 4.7205e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 1.3564e-04 - val_loss: 7.8687e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 51us/step - loss: 6.1546e-05 - val_loss: 6.6591e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: 5.6906e-05 - val_loss: 9.3411e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 4.9265e-05 - val_loss: 7.0200e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 4.9723e-05 - val_loss: 6.9589e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: 5.8351e-05 - val_loss: 7.3472e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: 4.9807e-05 - val_loss: 1.7523e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 6.8104e-05 - val_loss: 7.6157e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 4.0755e-05 - val_loss: 7.5723e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: 7.3153e-05 - val_loss: 8.8857e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: 4.8327e-05 - val_loss: 9.9374e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 5.9219e-05 - val_loss: 6.8646e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: 6.5646e-05 - val_loss: 6.7964e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 3.9161e-05 - val_loss: 6.5823e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 5.3561e-05 - val_loss: 5.9825e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 19s 1ms/step - loss: 0.0041 - val_loss: 0.0011\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: 0.0013 - val_loss: 2.5136e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: 0.0016 - val_loss: 2.3257e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 0.0012 - val_loss: 2.3236e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 6.5865e-04 - val_loss: 2.0995e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: 5.2712e-04 - val_loss: 1.8262e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 4.8915e-04 - val_loss: 1.6691e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: 4.2469e-04 - val_loss: 2.1140e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 50us/step - loss: 3.8872e-04 - val_loss: 1.6424e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 3.6439e-04 - val_loss: 1.4083e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 4.0344e-04 - val_loss: 2.0006e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 4.0921e-04 - val_loss: 1.5431e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: 3.9482e-04 - val_loss: 1.9504e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 3.3104e-04 - val_loss: 1.2768e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: 3.2963e-04 - val_loss: 1.4613e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: 4.2211e-04 - val_loss: 1.3784e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 2.5625e-04 - val_loss: 1.4810e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 2.8169e-04 - val_loss: 1.5437e-04\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 3.1383e-04 - val_loss: 7.3942e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 2.6439e-04 - val_loss: 1.0383e-04\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 2.6884e-04 - val_loss: 2.4969e-04\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 2.4455e-04 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 2.8933e-04 - val_loss: 1.3808e-04\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 2.5998e-04 - val_loss: 1.1292e-04\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 19s 1ms/step - loss: 0.0026 - val_loss: 1.3435e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 50us/step - loss: 7.3892e-04 - val_loss: 1.2511e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 4.5303e-04 - val_loss: 7.0496e-05\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 1.7532e-04 - val_loss: 2.3561e-05\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 1.6153e-04 - val_loss: 3.4083e-05\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 1.0939e-04 - val_loss: 2.4960e-05\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 50us/step - loss: 8.2492e-05 - val_loss: 2.5461e-05\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 1.0357e-04 - val_loss: 1.6650e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 50us/step - loss: 1.1684e-04 - val_loss: 2.5428e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 6.9027e-05 - val_loss: 4.8310e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 6.3669e-05 - val_loss: 1.9690e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 5.8829e-05 - val_loss: 3.0027e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 50us/step - loss: 3.3600e-04 - val_loss: 9.0290e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 1.0482e-04 - val_loss: 2.8825e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 50us/step - loss: 6.0717e-05 - val_loss: 8.8525e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 50us/step - loss: 1.0093e-04 - val_loss: 4.9614e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 4.5605e-05 - val_loss: 1.8851e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 4.5356e-05 - val_loss: 1.2485e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 50us/step - loss: 4.7468e-05 - val_loss: 1.2294e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 4.4346e-05 - val_loss: 4.7310e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 50us/step - loss: 8.3434e-05 - val_loss: 1.5402e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 4.7837e-05 - val_loss: 5.2145e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 50us/step - loss: 5.7780e-05 - val_loss: 2.2133e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 5.0566e-05 - val_loss: 1.2919e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 20s 1ms/step - loss: 0.1004 - val_loss: 0.0049\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 53us/step - loss: 0.0022 - val_loss: 3.8656e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 9.9703e-04 - val_loss: 1.4319e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 8.5962e-04 - val_loss: 1.3194e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 50us/step - loss: 7.6648e-04 - val_loss: 1.2380e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 50us/step - loss: 6.7132e-04 - val_loss: 1.1720e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 50us/step - loss: 5.8111e-04 - val_loss: 1.0728e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 50us/step - loss: 4.8467e-04 - val_loss: 1.0080e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 3.9853e-04 - val_loss: 9.3602e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 3.1017e-04 - val_loss: 8.9234e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 50us/step - loss: 2.3831e-04 - val_loss: 8.4872e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 1.7965e-04 - val_loss: 8.3041e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 1.3449e-04 - val_loss: 8.0402e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 1.0091e-04 - val_loss: 8.2643e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 7.9936e-05 - val_loss: 8.1380e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 6.4432e-05 - val_loss: 8.0389e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 5.4759e-05 - val_loss: 8.2443e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 4.9736e-05 - val_loss: 7.8098e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 50us/step - loss: 4.6088e-05 - val_loss: 8.2691e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 51us/step - loss: 4.5521e-05 - val_loss: 7.8249e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 4.4148e-05 - val_loss: 7.3046e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 50us/step - loss: 4.2059e-05 - val_loss: 7.0305e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 4.2187e-05 - val_loss: 6.5612e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 4.2827e-05 - val_loss: 6.3245e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 19s 1ms/step - loss: 0.0202 - val_loss: 0.0016\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 0.0012 - val_loss: 1.4488e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 8.3999e-04 - val_loss: 1.4833e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 7.1507e-04 - val_loss: 1.6992e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 50us/step - loss: 5.8592e-04 - val_loss: 9.8736e-05\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 4.3008e-04 - val_loss: 7.3340e-05\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 2.9430e-04 - val_loss: 5.3336e-05\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 1.9240e-04 - val_loss: 5.6202e-05\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 1.3023e-04 - val_loss: 6.1068e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 9.8681e-05 - val_loss: 3.5013e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 50us/step - loss: 7.7979e-05 - val_loss: 6.1169e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 7.1366e-05 - val_loss: 3.6162e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 6.1668e-05 - val_loss: 4.5029e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 5.7869e-05 - val_loss: 3.8052e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 51us/step - loss: 5.2262e-05 - val_loss: 5.2338e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 51us/step - loss: 5.7234e-05 - val_loss: 3.5167e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 4.7478e-05 - val_loss: 4.1927e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 50us/step - loss: 4.5966e-05 - val_loss: 8.1932e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 5.4019e-05 - val_loss: 3.6397e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 50us/step - loss: 4.3553e-05 - val_loss: 3.7223e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 4.3096e-05 - val_loss: 3.7482e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 4.6990e-05 - val_loss: 5.4657e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 4.2981e-05 - val_loss: 3.7930e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 50us/step - loss: 4.0943e-05 - val_loss: 3.8819e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 20s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 51us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 50us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 50us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 50us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 51us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 51us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 50us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 51us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 50us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 50us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 50us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 50us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 50us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 51us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 51us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 51us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 51us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 51us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 50us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 50us/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 50us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 50us/step - loss: nan - val_loss: nan\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 20s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 53us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 50us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 50us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 50us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 50us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 50us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 50us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 50us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 50us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 50us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 50us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 50us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 50us/step - loss: nan - val_loss: nan\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 21s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 47us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: nan - val_loss: nan\n",
      "\n",
      "GENERATION 13\n",
      "\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 21s 1ms/step - loss: 0.0033 - val_loss: 1.3701e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 51us/step - loss: 8.3445e-04 - val_loss: 1.3926e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 6.7603e-04 - val_loss: 1.3809e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 53us/step - loss: 4.9495e-04 - val_loss: 2.7300e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 51us/step - loss: 3.3382e-04 - val_loss: 8.9077e-05\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 1.9291e-04 - val_loss: 3.9679e-05\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 51us/step - loss: 1.1011e-04 - val_loss: 3.0957e-05\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 51us/step - loss: 7.9637e-05 - val_loss: 5.8100e-05\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 51us/step - loss: 7.3077e-05 - val_loss: 5.0585e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 7.1292e-05 - val_loss: 5.2754e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 51us/step - loss: 6.0802e-05 - val_loss: 2.8874e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 51us/step - loss: 5.1556e-05 - val_loss: 4.0552e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 51us/step - loss: 5.8859e-05 - val_loss: 5.5844e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 5.1015e-05 - val_loss: 3.3780e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 51us/step - loss: 4.5450e-05 - val_loss: 2.1920e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 51us/step - loss: 4.5602e-05 - val_loss: 3.4165e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 50us/step - loss: 5.4101e-05 - val_loss: 2.6268e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 5.0743e-05 - val_loss: 4.4106e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 51us/step - loss: 5.6048e-05 - val_loss: 4.1071e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - ETA: 0s - loss: 4.6726e-0 - 1s 54us/step - loss: 4.7273e-05 - val_loss: 4.6258e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 4.3771e-05 - val_loss: 1.8439e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 5.1678e-05 - val_loss: 3.1592e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 51us/step - loss: 4.4916e-05 - val_loss: 3.9643e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 51us/step - loss: 5.0925e-05 - val_loss: 2.7988e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 22s 1ms/step - loss: 0.0013 - val_loss: 1.4823e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 6.3867e-04 - val_loss: 1.5808e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 3.7201e-04 - val_loss: 7.7795e-05\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 1.5433e-04 - val_loss: 7.3340e-05\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 1.2550e-04 - val_loss: 1.4332e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 1.2292e-04 - val_loss: 4.9900e-05\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 1.0361e-04 - val_loss: 4.7062e-05\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 6.2170e-05 - val_loss: 1.4617e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 9.1010e-05 - val_loss: 4.9353e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 55us/step - loss: 9.7909e-05 - val_loss: 4.4167e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 6.5409e-05 - val_loss: 5.1731e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 4.6699e-05 - val_loss: 5.8565e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 6.1091e-05 - val_loss: 2.1727e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 9.0982e-05 - val_loss: 3.1361e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 4.8602e-05 - val_loss: 4.4147e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 5.5692e-05 - val_loss: 6.3561e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 51us/step - loss: 4.6877e-05 - val_loss: 5.6268e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 4.6474e-05 - val_loss: 8.1788e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 5.3251e-05 - val_loss: 3.1560e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 4.0205e-05 - val_loss: 3.8437e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 4.8871e-05 - val_loss: 3.2582e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 4.7030e-05 - val_loss: 6.0420e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 4.7502e-05 - val_loss: 4.7141e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 51us/step - loss: 5.2238e-05 - val_loss: 2.8478e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 22s 1ms/step - loss: 0.0024 - val_loss: 1.4178e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 51us/step - loss: 7.3033e-04 - val_loss: 1.6393e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 51us/step - loss: 4.4018e-04 - val_loss: 1.1053e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 51us/step - loss: 2.0572e-04 - val_loss: 4.1339e-05\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 50us/step - loss: 3.4888e-04 - val_loss: 1.1686e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 50us/step - loss: 9.8085e-05 - val_loss: 2.5634e-05\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 51us/step - loss: 6.0545e-05 - val_loss: 1.9132e-05\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 51us/step - loss: 5.8840e-05 - val_loss: 4.2294e-05\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 51us/step - loss: 5.5522e-05 - val_loss: 2.9503e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 51us/step - loss: 5.8978e-05 - val_loss: 2.1902e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 51us/step - loss: 4.8575e-05 - val_loss: 3.5816e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 51us/step - loss: 5.1578e-05 - val_loss: 2.9691e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 51us/step - loss: 6.0133e-05 - val_loss: 5.0341e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 5.5654e-05 - val_loss: 1.9286e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 51us/step - loss: 3.9105e-05 - val_loss: 2.4463e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 4.7465e-05 - val_loss: 3.0981e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 4.7473e-05 - val_loss: 3.2498e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 4.2026e-05 - val_loss: 7.1303e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 51us/step - loss: 7.0147e-05 - val_loss: 2.5800e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 51us/step - loss: 4.6535e-05 - val_loss: 2.4525e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 51us/step - loss: 4.3503e-05 - val_loss: 2.7846e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 3.8164e-05 - val_loss: 2.2755e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 51us/step - loss: 4.1195e-05 - val_loss: 1.9994e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 50us/step - loss: 5.0193e-05 - val_loss: 4.4486e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 23s 1ms/step - loss: 0.0024 - val_loss: 1.4047e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 8.2929e-04 - val_loss: 1.2002e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 5.5945e-04 - val_loss: 1.5430e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 51us/step - loss: 2.6145e-04 - val_loss: 4.8565e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 2.5097e-04 - val_loss: 4.7047e-05\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 1.1862e-04 - val_loss: 6.0745e-05\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 8.7701e-05 - val_loss: 3.9131e-05\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 6.3904e-05 - val_loss: 4.0134e-05\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 5.1261e-05 - val_loss: 5.1036e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 5.9932e-05 - val_loss: 3.8762e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 5.4601e-05 - val_loss: 3.9439e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 5.1595e-05 - val_loss: 5.6319e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 5.0955e-05 - val_loss: 6.2336e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 5.7447e-05 - val_loss: 2.5579e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 9.4344e-05 - val_loss: 5.2217e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 4.3753e-05 - val_loss: 3.7863e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 4.1978e-05 - val_loss: 3.1570e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 1.0709e-04 - val_loss: 5.0489e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 5.0495e-05 - val_loss: 3.1269e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 3.7684e-05 - val_loss: 3.0570e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 51us/step - loss: 4.3612e-05 - val_loss: 3.5567e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 50us/step - loss: 3.9986e-05 - val_loss: 3.1525e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 49us/step - loss: 4.3173e-05 - val_loss: 2.9347e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 48us/step - loss: 4.0166e-05 - val_loss: 3.2639e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 23s 1ms/step - loss: 9.4890e-04 - val_loss: 1.9955e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 51us/step - loss: 5.5477e-04 - val_loss: 1.4889e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 2.4261e-04 - val_loss: 7.0563e-05\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 51us/step - loss: 1.7184e-04 - val_loss: 2.8098e-05\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 51us/step - loss: 2.1069e-04 - val_loss: 5.8799e-05\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 1.4795e-04 - val_loss: 1.1828e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 9.1552e-05 - val_loss: 5.6952e-05\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 4.7913e-05 - val_loss: 1.5857e-05\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 53us/step - loss: 4.6372e-05 - val_loss: 2.8525e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 6.1587e-05 - val_loss: 1.6819e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 3.9977e-05 - val_loss: 2.1107e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 51us/step - loss: 3.9313e-05 - val_loss: 1.5727e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 4.9164e-05 - val_loss: 1.4430e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 7.3879e-05 - val_loss: 3.2462e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 7.9712e-05 - val_loss: 4.5693e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 6.5964e-05 - val_loss: 4.9741e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 53us/step - loss: 4.5517e-05 - val_loss: 1.5000e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 51us/step - loss: 4.5145e-05 - val_loss: 1.7769e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 3.9599e-05 - val_loss: 3.3709e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 4.4227e-05 - val_loss: 1.3749e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 6.3197e-05 - val_loss: 5.2110e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 4.8289e-05 - val_loss: 2.1975e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 3.8577e-05 - val_loss: 4.6842e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 1.0558e-04 - val_loss: 1.1670e-04\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 23s 1ms/step - loss: 0.0019 - val_loss: 3.0888e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 0.0017 - val_loss: 1.3620e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 0.0011 - val_loss: 0.0045\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 0.0013 - val_loss: 2.0573e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 9.3908e-04 - val_loss: 1.3421e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 8.9997e-04 - val_loss: 4.5412e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 8.9003e-04 - val_loss: 2.1653e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 8.9117e-04 - val_loss: 1.8754e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 7.9762e-04 - val_loss: 1.9975e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 7.6992e-04 - val_loss: 1.5540e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 53us/step - loss: 6.5921e-04 - val_loss: 1.6903e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 55us/step - loss: 6.0445e-04 - val_loss: 7.1605e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 6.0212e-04 - val_loss: 3.1597e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 6.8702e-04 - val_loss: 1.4396e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 4.5097e-04 - val_loss: 1.5738e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 53us/step - loss: 4.9882e-04 - val_loss: 1.3871e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 4.5396e-04 - val_loss: 1.3580e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 5.1294e-04 - val_loss: 1.6242e-04\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 4.4815e-04 - val_loss: 1.6807e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 3.7183e-04 - val_loss: 1.3691e-04\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 4.3361e-04 - val_loss: 1.3681e-04\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 4.1799e-04 - val_loss: 1.4481e-04\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 3.4294e-04 - val_loss: 1.2599e-04\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 4.1761e-04 - val_loss: 1.4225e-04\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 24s 1ms/step - loss: 0.0036 - val_loss: 9.4884e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 0.0013 - val_loss: 0.0027\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 55us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 53us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 0.0011 - val_loss: 5.1914e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 0.0015 - val_loss: 3.1899e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 53us/step - loss: 9.6962e-04 - val_loss: 1.4394e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 53us/step - loss: 9.4539e-04 - val_loss: 2.6103e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 53us/step - loss: 9.0779e-04 - val_loss: 2.0410e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 8.4206e-04 - val_loss: 1.6794e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 55us/step - loss: 8.5186e-04 - val_loss: 1.9787e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 57us/step - loss: 9.4244e-04 - val_loss: 1.6587e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 8.3482e-04 - val_loss: 2.0522e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 7.0217e-04 - val_loss: 2.3879e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 6.6622e-04 - val_loss: 1.6995e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 6.5566e-04 - val_loss: 1.5611e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 58us/step - loss: 7.4332e-04 - val_loss: 1.8008e-04\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 57us/step - loss: 6.0850e-04 - val_loss: 2.1332e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 5.8473e-04 - val_loss: 9.3073e-04\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 5.2812e-04 - val_loss: 0.0041\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 9.2743e-04 - val_loss: 1.5280e-04\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 5.2499e-04 - val_loss: 4.0006e-04\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 4.9917e-04 - val_loss: 1.5796e-04\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 24s 1ms/step - loss: 0.0027 - val_loss: 9.5383e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 0.0011 - val_loss: 1.7881e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 0.0013 - val_loss: 5.2744e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 0.0011 - val_loss: 1.5737e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 9.9662e-04 - val_loss: 1.3804e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 9.1379e-04 - val_loss: 1.4908e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 8.7893e-04 - val_loss: 1.6679e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 55us/step - loss: 9.4106e-04 - val_loss: 1.8188e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 55us/step - loss: 7.6356e-04 - val_loss: 2.1314e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 7.4142e-04 - val_loss: 3.2674e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 55us/step - loss: 7.2104e-04 - val_loss: 1.7749e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 55us/step - loss: 6.7911e-04 - val_loss: 4.1184e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 57us/step - loss: 7.3170e-04 - val_loss: 2.2977e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 5.2437e-04 - val_loss: 1.5940e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 5.8939e-04 - val_loss: 2.1810e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 5.1489e-04 - val_loss: 1.6916e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 6.2415e-04 - val_loss: 1.6002e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 4.3954e-04 - val_loss: 2.2891e-04\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 55us/step - loss: 5.0799e-04 - val_loss: 1.5646e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 4.1504e-04 - val_loss: 2.7999e-04\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 55us/step - loss: 3.9950e-04 - val_loss: 0.0026\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 55us/step - loss: 4.8505e-04 - val_loss: 2.3801e-04\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 55us/step - loss: 3.0054e-04 - val_loss: 1.7543e-04\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 55us/step - loss: 3.7483e-04 - val_loss: 1.8791e-04\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 24s 1ms/step - loss: 2.6147 - val_loss: 4.4105e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 53us/step - loss: 0.0013 - val_loss: 1.7683e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 53us/step - loss: 0.0012 - val_loss: 1.8286e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 53us/step - loss: 0.0010 - val_loss: 1.3967e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 9.6814e-04 - val_loss: 1.1551e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 53us/step - loss: 8.9317e-04 - val_loss: 3.7412e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 53us/step - loss: 8.6491e-04 - val_loss: 1.2355e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 53us/step - loss: 8.0823e-04 - val_loss: 1.0144e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 53us/step - loss: 7.6407e-04 - val_loss: 9.0395e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 7.3050e-04 - val_loss: 1.1831e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 6.9894e-04 - val_loss: 1.2332e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 6.6176e-04 - val_loss: 9.8224e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 6.3529e-04 - val_loss: 9.4799e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 6.1865e-04 - val_loss: 1.0389e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 53us/step - loss: 5.8978e-04 - val_loss: 1.1116e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 53us/step - loss: 5.6468e-04 - val_loss: 1.7468e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 5.4362e-04 - val_loss: 6.5725e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 53us/step - loss: 5.2060e-04 - val_loss: 6.4355e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 5.0634e-04 - val_loss: 1.0214e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 4.8474e-04 - val_loss: 6.0945e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 4.7200e-04 - val_loss: 5.9604e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 4.5664e-04 - val_loss: 5.5708e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 52us/step - loss: 4.4200e-04 - val_loss: 5.2837e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 53us/step - loss: 4.3087e-04 - val_loss: 2.0228e-04\n",
      "\n",
      "GENERATION 14\n",
      "\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 24s 1ms/step - loss: 0.0021 - val_loss: 1.3729e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 6.9830e-04 - val_loss: 6.5104e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 53us/step - loss: 4.0550e-04 - val_loss: 1.0859e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 1.2774e-04 - val_loss: 5.0845e-05\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 7.9188e-05 - val_loss: 4.0577e-05\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 8.8856e-05 - val_loss: 5.8719e-05\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 6.2615e-05 - val_loss: 4.3746e-05\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 5.3690e-05 - val_loss: 2.5439e-05\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 53us/step - loss: 6.3141e-05 - val_loss: 3.1966e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 7.0173e-05 - val_loss: 4.4398e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 53us/step - loss: 8.2861e-05 - val_loss: 4.9511e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 4.9922e-05 - val_loss: 4.5007e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 57us/step - loss: 4.9014e-05 - val_loss: 2.4399e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 4.2495e-05 - val_loss: 4.1354e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 7.5559e-05 - val_loss: 2.8589e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 4.5277e-05 - val_loss: 2.7070e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 6.9599e-05 - val_loss: 3.0910e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 6.8292e-05 - val_loss: 7.2550e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 5.1171e-05 - val_loss: 2.0087e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 1.3016e-04 - val_loss: 3.8607e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 4.6424e-05 - val_loss: 2.9101e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 53us/step - loss: 4.4862e-05 - val_loss: 2.6181e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 4.3492e-05 - val_loss: 1.0686e-04\n",
      "Epoch 24/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18465/18465 [==============================] - 1s 54us/step - loss: 5.3130e-05 - val_loss: 1.5404e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 25s 1ms/step - loss: 0.0016 - val_loss: 1.2479e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 7.1838e-04 - val_loss: 1.0555e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 4.5670e-04 - val_loss: 7.1268e-05\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 2.1309e-04 - val_loss: 1.3339e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 1.2253e-04 - val_loss: 3.8749e-05\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 9.4553e-05 - val_loss: 3.3863e-05\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 8.3307e-05 - val_loss: 3.3309e-05\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 6.4398e-05 - val_loss: 3.1381e-05\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 8.9547e-05 - val_loss: 7.9712e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 8.7950e-05 - val_loss: 4.8255e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 55us/step - loss: 9.2591e-05 - val_loss: 1.3620e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 8.0093e-05 - val_loss: 5.8547e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 53us/step - loss: 5.1046e-05 - val_loss: 2.4421e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 55us/step - loss: 4.7819e-05 - val_loss: 4.6115e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 53us/step - loss: 5.5694e-05 - val_loss: 4.1013e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 53us/step - loss: 5.3907e-05 - val_loss: 5.9701e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 53us/step - loss: 2.8212e-04 - val_loss: 1.8411e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 53us/step - loss: 1.2273e-04 - val_loss: 6.0478e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 53us/step - loss: 7.0833e-05 - val_loss: 2.5644e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 6.1731e-05 - val_loss: 1.0995e-04\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 5.8406e-05 - val_loss: 2.5035e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 4.4240e-05 - val_loss: 2.2260e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 4.7528e-05 - val_loss: 2.2101e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 3.9383e-05 - val_loss: 2.0926e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 25s 1ms/step - loss: 0.0390 - val_loss: 0.0016\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 55us/step - loss: 0.0016 - val_loss: 2.6279e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 8.9800e-04 - val_loss: 1.3641e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 7.5706e-04 - val_loss: 1.1377e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 6.1450e-04 - val_loss: 1.0050e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 4.4747e-04 - val_loss: 7.0776e-05\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 55us/step - loss: 2.9218e-04 - val_loss: 4.9217e-05\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 55us/step - loss: 1.7434e-04 - val_loss: 4.3018e-05\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 58us/step - loss: 1.1907e-04 - val_loss: 6.0609e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 8.9968e-05 - val_loss: 5.3186e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 55us/step - loss: 7.6388e-05 - val_loss: 3.0187e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 55us/step - loss: 6.0859e-05 - val_loss: 3.2241e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 5.5909e-05 - val_loss: 3.1738e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 5.1732e-05 - val_loss: 2.8139e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 55us/step - loss: 4.8242e-05 - val_loss: 3.5202e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 4.9399e-05 - val_loss: 2.7106e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 55us/step - loss: 4.5659e-05 - val_loss: 2.6820e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 4.3885e-05 - val_loss: 3.0013e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 53us/step - loss: 4.6048e-05 - val_loss: 3.1254e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 55us/step - loss: 4.4653e-05 - val_loss: 3.4969e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 55us/step - loss: 4.2445e-05 - val_loss: 2.8358e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 4.2685e-05 - val_loss: 3.1732e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 55us/step - loss: 4.2431e-05 - val_loss: 3.0457e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 55us/step - loss: 4.2502e-05 - val_loss: 2.7091e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 25s 1ms/step - loss: 0.1582 - val_loss: 0.0037\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 55us/step - loss: 0.0015 - val_loss: 2.9487e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 55us/step - loss: 9.6434e-04 - val_loss: 1.4617e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 9.0229e-04 - val_loss: 1.3914e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 57us/step - loss: 8.6649e-04 - val_loss: 1.2527e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 55us/step - loss: 8.1908e-04 - val_loss: 1.2138e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 7.7960e-04 - val_loss: 1.2256e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 7.3669e-04 - val_loss: 1.1649e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 55us/step - loss: 6.9889e-04 - val_loss: 1.0986e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 55us/step - loss: 6.5394e-04 - val_loss: 1.1394e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 6.1703e-04 - val_loss: 1.1270e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 5.7295e-04 - val_loss: 1.0228e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 5.3197e-04 - val_loss: 9.2311e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 4.8734e-04 - val_loss: 8.7340e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 55us/step - loss: 4.4658e-04 - val_loss: 9.0438e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 4.0082e-04 - val_loss: 7.9494e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 3.5746e-04 - val_loss: 7.4403e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 55us/step - loss: 3.1716e-04 - val_loss: 6.7154e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 2.7597e-04 - val_loss: 6.8892e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 2.4162e-04 - val_loss: 5.7988e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 57us/step - loss: 2.1216e-04 - val_loss: 5.2518e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 1.8204e-04 - val_loss: 5.0483e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 1.5711e-04 - val_loss: 7.2444e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 1.4361e-04 - val_loss: 4.2435e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 26s 1ms/step - loss: 0.4308 - val_loss: 0.0054\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - ETA: 0s - loss: 0.002 - 1s 54us/step - loss: 0.0021 - val_loss: 1.7214e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 55us/step - loss: 0.0010 - val_loss: 1.6031e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 55us/step - loss: 9.7984e-04 - val_loss: 1.6556e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 9.6499e-04 - val_loss: 1.5329e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 55us/step - loss: 9.4391e-04 - val_loss: 1.5845e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 55us/step - loss: 9.2778e-04 - val_loss: 1.5478e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 9.1314e-04 - val_loss: 1.4889e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 8.9395e-04 - val_loss: 1.5345e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 8.7964e-04 - val_loss: 1.5076e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 55us/step - loss: 8.6588e-04 - val_loss: 1.5037e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 8.4998e-04 - val_loss: 1.3933e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 8.3530e-04 - val_loss: 1.3814e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 8.1918e-04 - val_loss: 1.4469e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 8.0546e-04 - val_loss: 1.3305e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 7.8744e-04 - val_loss: 1.3495e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 57us/step - loss: 7.7352e-04 - val_loss: 1.3559e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 53us/step - loss: 7.5594e-04 - val_loss: 1.2909e-04\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 7.4390e-04 - val_loss: 1.2533e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 7.2818e-04 - val_loss: 1.2460e-04\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 7.0984e-04 - val_loss: 1.2183e-04\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 53us/step - loss: 6.9742e-04 - val_loss: 1.1884e-04\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 6.7967e-04 - val_loss: 1.1972e-04\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 53us/step - loss: 6.6501e-04 - val_loss: 1.1215e-04\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 26s 1ms/step - loss: 0.0022 - val_loss: 2.1652e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 55us/step - loss: 0.0010 - val_loss: 1.5855e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 0.0010 - val_loss: 1.5500e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 55us/step - loss: 0.0010 - val_loss: 1.8646e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 55us/step - loss: 0.0010 - val_loss: 1.9446e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 0.0010 - val_loss: 1.7950e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 0.0010 - val_loss: 1.5915e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 0.0010 - val_loss: 1.5111e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 0.0010 - val_loss: 1.5011e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 55us/step - loss: 9.9397e-04 - val_loss: 1.4795e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 9.4906e-04 - val_loss: 1.2219e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 58us/step - loss: 8.8812e-04 - val_loss: 9.2852e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 55us/step - loss: 8.2087e-04 - val_loss: 6.9215e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 7.8091e-04 - val_loss: 6.3091e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 55us/step - loss: 7.5368e-04 - val_loss: 6.1002e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 55us/step - loss: 7.2430e-04 - val_loss: 4.8232e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 6.8395e-04 - val_loss: 4.5908e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 6.4227e-04 - val_loss: 3.9797e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 55us/step - loss: 6.1980e-04 - val_loss: 4.5163e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 5.9775e-04 - val_loss: 4.7674e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 55us/step - loss: 5.8771e-04 - val_loss: 5.5818e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 55us/step - loss: 5.7045e-04 - val_loss: 3.8888e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 55us/step - loss: 5.4505e-04 - val_loss: 3.7677e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 55us/step - loss: 5.3043e-04 - val_loss: 3.2747e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 26s 1ms/step - loss: 0.0431 - val_loss: 9.3670e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 0.0014 - val_loss: 1.8916e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 53us/step - loss: 0.0011 - val_loss: 1.8850e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 55us/step - loss: 0.0010 - val_loss: 1.9038e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 55us/step - loss: 9.5235e-04 - val_loss: 1.7802e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 55us/step - loss: 9.0202e-04 - val_loss: 1.6721e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 8.5490e-04 - val_loss: 1.5757e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 8.1359e-04 - val_loss: 1.5173e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 7.7287e-04 - val_loss: 1.4764e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 55us/step - loss: 7.3035e-04 - val_loss: 1.4617e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 55us/step - loss: 6.8529e-04 - val_loss: 1.3794e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 55us/step - loss: 6.4763e-04 - val_loss: 1.4586e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 55us/step - loss: 6.0764e-04 - val_loss: 1.2536e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 5.7131e-04 - val_loss: 1.1766e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 5.4085e-04 - val_loss: 1.1305e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 5.1034e-04 - val_loss: 1.1537e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 4.8120e-04 - val_loss: 1.0790e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 55us/step - loss: 4.5038e-04 - val_loss: 9.7685e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 4.2172e-04 - val_loss: 9.8962e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 55us/step - loss: 3.9346e-04 - val_loss: 9.4769e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 55us/step - loss: 3.6333e-04 - val_loss: 8.4584e-05\n",
      "Epoch 22/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18465/18465 [==============================] - 1s 56us/step - loss: 3.3649e-04 - val_loss: 8.2389e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 3.1022e-04 - val_loss: 7.5847e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 54us/step - loss: 2.8394e-04 - val_loss: 7.2200e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 26s 1ms/step - loss: 0.2145 - val_loss: 0.0045\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 0.0016 - val_loss: 2.0858e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 0.0010 - val_loss: 1.5319e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 9.9200e-04 - val_loss: 1.5760e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 9.8502e-04 - val_loss: 1.6420e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 9.7774e-04 - val_loss: 1.6273e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 9.7125e-04 - val_loss: 1.6674e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 9.6441e-04 - val_loss: 1.6108e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 9.5596e-04 - val_loss: 1.5083e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 57us/step - loss: 9.4844e-04 - val_loss: 1.5414e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 55us/step - loss: 9.3966e-04 - val_loss: 1.4692e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 9.3134e-04 - val_loss: 1.4991e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 9.2250e-04 - val_loss: 1.6249e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 9.1208e-04 - val_loss: 1.5077e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 59us/step - loss: 9.0246e-04 - val_loss: 1.4839e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 8.9192e-04 - val_loss: 1.5552e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 8.8106e-04 - val_loss: 1.4630e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 8.7004e-04 - val_loss: 1.4616e-04\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 8.5610e-04 - val_loss: 1.4378e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 55us/step - loss: 8.4385e-04 - val_loss: 1.5169e-04\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 8.2964e-04 - val_loss: 1.4328e-04\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - ETA: 0s - loss: 8.1169e-0 - 1s 56us/step - loss: 8.1504e-04 - val_loss: 1.4949e-04\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 7.9877e-04 - val_loss: 1.4526e-04\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 7.8157e-04 - val_loss: 1.5589e-04\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 27s 1ms/step - loss: 0.0678 - val_loss: 2.8384e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 57us/step - loss: 0.0011 - val_loss: 1.5865e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 59us/step - loss: 0.0010 - val_loss: 1.6063e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 61us/step - loss: 0.0010 - val_loss: 1.5788e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 60us/step - loss: 0.0010 - val_loss: 1.5214e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 58us/step - loss: 0.0010 - val_loss: 1.5352e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 59us/step - loss: 0.0010 - val_loss: 1.5906e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 59us/step - loss: 0.0010 - val_loss: 1.5339e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 57us/step - loss: 9.9554e-04 - val_loss: 1.6063e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 57us/step - loss: 9.8733e-04 - val_loss: 1.5545e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 57us/step - loss: 9.7975e-04 - val_loss: 1.5580e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 57us/step - loss: 9.7091e-04 - val_loss: 1.5559e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 57us/step - loss: 9.6179e-04 - val_loss: 1.5333e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 58us/step - loss: 9.5295e-04 - val_loss: 1.4328e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 57us/step - loss: 9.4209e-04 - val_loss: 1.3723e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 57us/step - loss: 9.2993e-04 - val_loss: 1.3731e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 58us/step - loss: 9.1564e-04 - val_loss: 1.3129e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 59us/step - loss: 9.0215e-04 - val_loss: 1.3961e-04\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 58us/step - loss: 8.8518e-04 - val_loss: 1.4023e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 57us/step - loss: 8.6747e-04 - val_loss: 1.3546e-04\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 57us/step - loss: 8.4661e-04 - val_loss: 1.3216e-04\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 58us/step - loss: 8.2643e-04 - val_loss: 1.2525e-04\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 59us/step - loss: 8.0274e-04 - val_loss: 1.1885e-04\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 57us/step - loss: 7.7668e-04 - val_loss: 1.1891e-04\n",
      "\n",
      "GENERATION 15\n",
      "\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 28s 2ms/step - loss: 0.0012 - val_loss: 1.6172e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 59us/step - loss: 9.7010e-04 - val_loss: 1.6559e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 58us/step - loss: 0.0010 - val_loss: 1.5935e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 59us/step - loss: 9.1601e-04 - val_loss: 0.0027\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 59us/step - loss: 0.0010 - val_loss: 1.5239e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 58us/step - loss: 8.8745e-04 - val_loss: 2.6806e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 59us/step - loss: 9.1731e-04 - val_loss: 1.7002e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 58us/step - loss: 9.0603e-04 - val_loss: 4.8358e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 58us/step - loss: 9.8249e-04 - val_loss: 2.9057e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 61us/step - loss: 8.8696e-04 - val_loss: 1.4044e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 58us/step - loss: 8.5851e-04 - val_loss: 4.3824e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 58us/step - loss: 8.6986e-04 - val_loss: 1.3907e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 58us/step - loss: 8.7231e-04 - val_loss: 2.3702e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 58us/step - loss: 8.2249e-04 - val_loss: 1.5000e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 58us/step - loss: 7.9140e-04 - val_loss: 1.9705e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 58us/step - loss: 8.0003e-04 - val_loss: 1.5028e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 59us/step - loss: 7.7160e-04 - val_loss: 1.5424e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 58us/step - loss: 7.4709e-04 - val_loss: 1.6786e-04\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 59us/step - loss: 7.0513e-04 - val_loss: 2.5374e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 58us/step - loss: 6.7978e-04 - val_loss: 1.4957e-04\n",
      "Epoch 21/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18465/18465 [==============================] - 1s 58us/step - loss: 7.0341e-04 - val_loss: 1.6852e-04\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 58us/step - loss: 6.5798e-04 - val_loss: 2.4574e-04\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 58us/step - loss: 5.8953e-04 - val_loss: 1.7929e-04\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 58us/step - loss: 5.4393e-04 - val_loss: 7.2449e-04\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 27s 1ms/step - loss: 0.0012 - val_loss: 1.1605e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 5.6830e-04 - val_loss: 1.4763e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 55us/step - loss: 3.9190e-04 - val_loss: 8.1875e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 2.9871e-04 - val_loss: 1.0650e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 9.7403e-05 - val_loss: 8.1340e-05\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 6.8859e-05 - val_loss: 7.2782e-05\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 5.3844e-05 - val_loss: 6.1050e-05\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 5.1923e-05 - val_loss: 5.7919e-05\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 4.5518e-05 - val_loss: 7.2261e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 5.2508e-05 - val_loss: 5.0449e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 5.5283e-05 - val_loss: 5.6866e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 4.3537e-05 - val_loss: 5.5747e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 5.0686e-05 - val_loss: 5.6494e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 4.2432e-05 - val_loss: 4.7538e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 4.4323e-05 - val_loss: 4.6958e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 58us/step - loss: 4.5542e-05 - val_loss: 4.3077e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 4.2916e-05 - val_loss: 6.1515e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 6.0684e-05 - val_loss: 4.9288e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 5.0695e-05 - val_loss: 4.1942e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 3.7200e-05 - val_loss: 4.9951e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 3.9150e-05 - val_loss: 4.8644e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 5.1280e-05 - val_loss: 1.0851e-04\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 7.1047e-05 - val_loss: 5.5813e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 4.9590e-05 - val_loss: 7.1450e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 28s 2ms/step - loss: 0.0017 - val_loss: 1.3088e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 58us/step - loss: 8.1650e-04 - val_loss: 1.1650e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 58us/step - loss: 6.2165e-04 - val_loss: 1.3425e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 59us/step - loss: 3.9642e-04 - val_loss: 6.0421e-05\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 60us/step - loss: 2.0135e-04 - val_loss: 4.1463e-05\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 60us/step - loss: 8.6987e-05 - val_loss: 3.5847e-05\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 58us/step - loss: 1.1358e-04 - val_loss: 2.7422e-05\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 59us/step - loss: 8.6957e-05 - val_loss: 3.9113e-05\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 59us/step - loss: 5.2151e-05 - val_loss: 3.1659e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 58us/step - loss: 5.0254e-05 - val_loss: 5.0485e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 58us/step - loss: 4.4349e-05 - val_loss: 4.1158e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 58us/step - loss: 6.4200e-05 - val_loss: 5.1102e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 58us/step - loss: 4.3927e-05 - val_loss: 2.9744e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 58us/step - loss: 4.5611e-05 - val_loss: 1.6630e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 58us/step - loss: 6.6514e-05 - val_loss: 3.9897e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 59us/step - loss: 4.0500e-05 - val_loss: 7.4389e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 58us/step - loss: 5.7712e-05 - val_loss: 9.0043e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 58us/step - loss: 5.7782e-05 - val_loss: 2.9553e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 59us/step - loss: 4.0045e-05 - val_loss: 3.8624e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 60us/step - loss: 4.0418e-05 - val_loss: 4.1468e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 59us/step - loss: 5.4997e-05 - val_loss: 3.5995e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 57us/step - loss: 3.9000e-05 - val_loss: 3.6053e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 58us/step - loss: 3.8699e-05 - val_loss: 2.3496e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 58us/step - loss: 3.8943e-05 - val_loss: 2.4994e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 27s 1ms/step - loss: 0.0070 - val_loss: 1.4281e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 9.4296e-04 - val_loss: 4.5196e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 8.4407e-04 - val_loss: 1.4799e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 6.4935e-04 - val_loss: 1.5126e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 6.0906e-04 - val_loss: 1.2362e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 57us/step - loss: 3.4247e-04 - val_loss: 1.5517e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 2.3276e-04 - val_loss: 7.1050e-05\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 2.9322e-04 - val_loss: 1.6155e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 3.4876e-04 - val_loss: 1.3755e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 55us/step - loss: 1.8650e-04 - val_loss: 1.2511e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 59us/step - loss: 1.7725e-04 - val_loss: 1.9206e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 2.3005e-04 - val_loss: 1.7413e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 3.0912e-04 - val_loss: 1.4767e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 55us/step - loss: 1.9015e-04 - val_loss: 5.5501e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 1.5955e-04 - val_loss: 1.0184e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 1.4454e-04 - val_loss: 1.0622e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 1.3752e-04 - val_loss: 4.4026e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 1.4356e-04 - val_loss: 4.3483e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 57us/step - loss: 1.2718e-04 - val_loss: 1.3863e-04\n",
      "Epoch 20/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18465/18465 [==============================] - 1s 55us/step - loss: 1.4198e-04 - val_loss: 1.0928e-04\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 1.1048e-04 - val_loss: 8.2775e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 57us/step - loss: 1.0814e-04 - val_loss: 1.1382e-04\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 1.1536e-04 - val_loss: 3.9576e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 1.1914e-04 - val_loss: 4.8939e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 29s 2ms/step - loss: 0.0720 - val_loss: 2.8265e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 9.7094e-04 - val_loss: 1.4367e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 9.2711e-04 - val_loss: 1.4125e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 8.8473e-04 - val_loss: 1.3668e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 8.4472e-04 - val_loss: 1.3596e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 57us/step - loss: 8.0563e-04 - val_loss: 1.3801e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 7.5161e-04 - val_loss: 1.3604e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 6.9688e-04 - val_loss: 1.4993e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 6.3657e-04 - val_loss: 1.1785e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 5.7033e-04 - val_loss: 1.1596e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 5.0320e-04 - val_loss: 3.1416e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 4.4559e-04 - val_loss: 1.1208e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 5.4482e-04 - val_loss: 1.0923e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 59us/step - loss: 5.3311e-04 - val_loss: 1.0882e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 3.1171e-04 - val_loss: 8.8696e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 3.8014e-04 - val_loss: 1.2577e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 3.6326e-04 - val_loss: 3.6516e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 2.7987e-04 - val_loss: 1.1971e-04\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 55us/step - loss: 3.0731e-04 - val_loss: 6.2097e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 2.3328e-04 - val_loss: 5.6746e-04\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 57us/step - loss: 3.0211e-04 - val_loss: 7.7098e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 1.5079e-04 - val_loss: 2.0538e-04\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 2.7927e-04 - val_loss: 1.0879e-04\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 2.5660e-04 - val_loss: 8.3582e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 28s 2ms/step - loss: 0.0280 - val_loss: 3.5552e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 58us/step - loss: 0.0028 - val_loss: 1.4703e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 60us/step - loss: 0.0024 - val_loss: 1.9635e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 57us/step - loss: 0.0019 - val_loss: 2.4124e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 57us/step - loss: 0.0017 - val_loss: 8.4484e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 0.0012 - val_loss: 1.7907e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 57us/step - loss: 0.0010 - val_loss: 1.5094e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 57us/step - loss: 9.9419e-04 - val_loss: 1.4303e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 58us/step - loss: 7.7761e-04 - val_loss: 0.0025\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 0.0011 - val_loss: 1.8010e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 57us/step - loss: 6.4625e-04 - val_loss: 5.4173e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 57us/step - loss: 8.6550e-04 - val_loss: 1.7054e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 57us/step - loss: 6.5613e-04 - val_loss: 4.1340e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 57us/step - loss: 8.0904e-04 - val_loss: 1.6585e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 57us/step - loss: 7.1893e-04 - val_loss: 1.8375e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 57us/step - loss: 6.3670e-04 - val_loss: 5.5836e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 59us/step - loss: 6.7927e-04 - val_loss: 3.4192e-04\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 57us/step - loss: 6.5756e-04 - val_loss: 4.7609e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 57us/step - loss: 5.7335e-04 - val_loss: 0.0018\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 57us/step - loss: 6.0620e-04 - val_loss: 0.0014\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 6.2643e-04 - val_loss: 3.1175e-04\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 57us/step - loss: 6.3537e-04 - val_loss: 6.5070e-04\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 57us/step - loss: 5.3988e-04 - val_loss: 1.4418e-04\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 30s 2ms/step - loss: 0.9295 - val_loss: 7.0627e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 59us/step - loss: 0.0809 - val_loss: 0.0078\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 58us/step - loss: 0.1177 - val_loss: 8.9701e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 60us/step - loss: 0.0562 - val_loss: 0.0062\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 60us/step - loss: 0.0333 - val_loss: 0.2074\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 59us/step - loss: 0.0440 - val_loss: 0.0059\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 59us/step - loss: 0.0344 - val_loss: 1.7027e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 59us/step - loss: 0.0219 - val_loss: 0.0413\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 59us/step - loss: 0.0117 - val_loss: 0.0172\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 59us/step - loss: 0.0207 - val_loss: 0.0032\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 59us/step - loss: 0.0198 - val_loss: 2.3781e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 59us/step - loss: 0.0143 - val_loss: 5.6878e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 59us/step - loss: 0.0097 - val_loss: 0.0235\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 58us/step - loss: 0.0199 - val_loss: 1.4773e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 59us/step - loss: 0.0143 - val_loss: 1.5489e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 59us/step - loss: 0.0117 - val_loss: 0.0055\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 59us/step - loss: 0.0131 - val_loss: 0.0015\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 58us/step - loss: 0.0108 - val_loss: 0.0038\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 62us/step - loss: 0.0099 - val_loss: 0.0095\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 59us/step - loss: 0.0046 - val_loss: 0.0094\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 58us/step - loss: 0.0167 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 59us/step - loss: 0.0054 - val_loss: 3.6883e-04\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 58us/step - loss: 0.0076 - val_loss: 0.0074\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 58us/step - loss: 0.0047 - val_loss: 0.0024\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 30s 2ms/step - loss: 0.8941 - val_loss: 8.2990e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 60us/step - loss: 0.0877 - val_loss: 0.0640\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 60us/step - loss: 0.1588 - val_loss: 0.0024\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 63us/step - loss: 0.2959 - val_loss: 2.2268e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 59us/step - loss: 0.0011 - val_loss: 0.0088\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 59us/step - loss: 0.1288 - val_loss: 3.7922e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 60us/step - loss: 0.0539 - val_loss: 0.1041\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 59us/step - loss: 0.0205 - val_loss: 2.2515e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 59us/step - loss: 0.2306 - val_loss: 1.4384e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 59us/step - loss: 9.3377e-04 - val_loss: 1.5649e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 59us/step - loss: 0.0023 - val_loss: 0.0807\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 59us/step - loss: 0.0333 - val_loss: 0.0336\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 60us/step - loss: 0.0241 - val_loss: 0.0226\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 60us/step - loss: 0.0188 - val_loss: 0.0184\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 60us/step - loss: 0.0165 - val_loss: 0.0236\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 60us/step - loss: 0.0475 - val_loss: 1.3952e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 60us/step - loss: 0.0014 - val_loss: 0.0162\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 61us/step - loss: 0.0133 - val_loss: 0.0112\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 62us/step - loss: 0.0126 - val_loss: 9.9745e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 60us/step - loss: 0.0159 - val_loss: 0.1904\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 60us/step - loss: 0.0362 - val_loss: 1.7050e-04\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 60us/step - loss: 0.0012 - val_loss: 0.0024\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 60us/step - loss: 0.0110 - val_loss: 0.0068\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 60us/step - loss: 0.0088 - val_loss: 0.0119\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 30s 2ms/step - loss: 0.1312 - val_loss: 2.1816e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 63us/step - loss: 0.0250 - val_loss: 0.0107\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 60us/step - loss: 0.0167 - val_loss: 0.0124\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 60us/step - loss: 0.0114 - val_loss: 0.0095\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 60us/step - loss: 0.0080 - val_loss: 0.0030\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 60us/step - loss: 0.0063 - val_loss: 0.0018\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 60us/step - loss: 0.0058 - val_loss: 9.9361e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 60us/step - loss: 0.0032 - val_loss: 0.0074\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 60us/step - loss: 0.0032 - val_loss: 8.5977e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 59us/step - loss: 0.0039 - val_loss: 0.0020\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 60us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 59us/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 60us/step - loss: 0.0026 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 59us/step - loss: 0.0030 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 60us/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 61us/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 61us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 59us/step - loss: 0.0024 - val_loss: 0.0054\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 60us/step - loss: 0.0018 - val_loss: 3.3229e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 60us/step - loss: 0.0026 - val_loss: 0.0013\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 59us/step - loss: 0.0013 - val_loss: 8.6703e-04\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 60us/step - loss: 0.0025 - val_loss: 5.5265e-04\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 59us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 60us/step - loss: 0.0022 - val_loss: 6.1472e-04\n",
      "\n",
      "GENERATION 16\n",
      "\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 31s 2ms/step - loss: 0.3293 - val_loss: 0.0097\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 0.0033 - val_loss: 1.9871e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 0.0010 - val_loss: 1.8842e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 57us/step - loss: 9.7209e-04 - val_loss: 1.6436e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 9.5085e-04 - val_loss: 1.6141e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 9.3645e-04 - val_loss: 1.6128e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 9.2260e-04 - val_loss: 1.6049e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 9.0816e-04 - val_loss: 1.5833e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 8.9478e-04 - val_loss: 1.6096e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 8.7985e-04 - val_loss: 1.4847e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 8.6239e-04 - val_loss: 1.5094e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 55us/step - loss: 8.5112e-04 - val_loss: 1.5082e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 8.3358e-04 - val_loss: 1.6204e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 57us/step - loss: 8.1682e-04 - val_loss: 1.5344e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 58us/step - loss: 8.0192e-04 - val_loss: 1.5127e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 57us/step - loss: 7.8406e-04 - val_loss: 1.4008e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 7.7101e-04 - val_loss: 1.4051e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 7.5172e-04 - val_loss: 1.3873e-04\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 55us/step - loss: 7.3653e-04 - val_loss: 1.3696e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 7.1782e-04 - val_loss: 1.4260e-04\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 57us/step - loss: 6.9912e-04 - val_loss: 1.3390e-04\n",
      "Epoch 22/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18465/18465 [==============================] - 1s 56us/step - loss: 6.8026e-04 - val_loss: 1.4121e-04\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 6.6048e-04 - val_loss: 1.3574e-04\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 6.4040e-04 - val_loss: 1.2669e-04\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 32s 2ms/step - loss: 0.0013 - val_loss: 3.0681e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 61us/step - loss: 4.9505e-04 - val_loss: 7.4247e-05\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 61us/step - loss: 3.0256e-04 - val_loss: 6.7241e-05\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 61us/step - loss: 1.3136e-04 - val_loss: 6.7595e-05\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 61us/step - loss: 1.0514e-04 - val_loss: 9.2455e-05\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 61us/step - loss: 1.3854e-04 - val_loss: 5.4503e-05\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 61us/step - loss: 1.1711e-04 - val_loss: 1.1739e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 61us/step - loss: 5.8595e-05 - val_loss: 2.9544e-05\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 61us/step - loss: 5.6895e-05 - val_loss: 2.4162e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 62us/step - loss: 1.8545e-04 - val_loss: 7.3420e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 63us/step - loss: 5.7037e-05 - val_loss: 5.5723e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 60us/step - loss: 4.9374e-05 - val_loss: 2.7785e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 61us/step - loss: 4.1679e-05 - val_loss: 2.2639e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 61us/step - loss: 4.3782e-05 - val_loss: 2.0299e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 61us/step - loss: 4.5759e-05 - val_loss: 5.1152e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 61us/step - loss: 4.2851e-05 - val_loss: 3.1500e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 60us/step - loss: 4.3473e-05 - val_loss: 2.1032e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 61us/step - loss: 4.1835e-05 - val_loss: 2.1587e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 61us/step - loss: 4.4292e-05 - val_loss: 3.4154e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 60us/step - loss: 4.1747e-05 - val_loss: 2.0709e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 61us/step - loss: 3.8210e-05 - val_loss: 9.5752e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 61us/step - loss: 4.7481e-05 - val_loss: 2.1646e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 61us/step - loss: 4.9383e-05 - val_loss: 2.7851e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 61us/step - loss: 3.4488e-05 - val_loss: 2.4169e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 32s 2ms/step - loss: 9.9255e-04 - val_loss: 1.3623e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 57us/step - loss: 4.5247e-04 - val_loss: 1.1637e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 57us/step - loss: 2.8851e-04 - val_loss: 1.4855e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 57us/step - loss: 3.8245e-04 - val_loss: 1.5845e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 59us/step - loss: 2.6995e-04 - val_loss: 1.4191e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 57us/step - loss: 3.4088e-04 - val_loss: 1.5960e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 57us/step - loss: 5.5594e-04 - val_loss: 1.3357e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 57us/step - loss: 2.2383e-04 - val_loss: 1.6605e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 2.9717e-04 - val_loss: 9.8999e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 57us/step - loss: 1.4209e-04 - val_loss: 3.4286e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 57us/step - loss: 1.2360e-04 - val_loss: 7.6273e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 57us/step - loss: 1.7768e-04 - val_loss: 1.2492e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 57us/step - loss: 1.7087e-04 - val_loss: 6.4239e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 57us/step - loss: 1.0725e-04 - val_loss: 1.5391e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 1.0040e-04 - val_loss: 3.2210e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 56us/step - loss: 4.3361e-05 - val_loss: 2.8323e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 57us/step - loss: 4.1542e-05 - val_loss: 2.6469e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 57us/step - loss: 4.4447e-05 - val_loss: 4.1918e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 58us/step - loss: 4.2120e-05 - val_loss: 5.5337e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 59us/step - loss: 5.3147e-05 - val_loss: 4.1817e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 58us/step - loss: 5.0769e-05 - val_loss: 3.0876e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 57us/step - loss: 3.7547e-05 - val_loss: 4.8921e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 57us/step - loss: 4.4566e-05 - val_loss: 3.1178e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 57us/step - loss: 6.0533e-05 - val_loss: 4.3576e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 33s 2ms/step - loss: 0.6432 - val_loss: 0.0297\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 62us/step - loss: 0.0058 - val_loss: 2.8828e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 62us/step - loss: 0.0011 - val_loss: 1.5886e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 62us/step - loss: 9.5783e-04 - val_loss: 1.5451e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 62us/step - loss: 8.8377e-04 - val_loss: 1.6650e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 62us/step - loss: 8.1371e-04 - val_loss: 1.5543e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 62us/step - loss: 7.4952e-04 - val_loss: 1.2667e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 62us/step - loss: 6.8262e-04 - val_loss: 1.3128e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 62us/step - loss: 6.1853e-04 - val_loss: 1.0871e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 62us/step - loss: 5.5881e-04 - val_loss: 1.0313e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 62us/step - loss: 5.0003e-04 - val_loss: 9.5405e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 62us/step - loss: 4.4410e-04 - val_loss: 8.7570e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 63us/step - loss: 4.0052e-04 - val_loss: 8.4492e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 63us/step - loss: 3.5436e-04 - val_loss: 9.7177e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 62us/step - loss: 3.2027e-04 - val_loss: 8.8586e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 62us/step - loss: 2.8582e-04 - val_loss: 7.2261e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 62us/step - loss: 2.5224e-04 - val_loss: 6.7225e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 62us/step - loss: 2.2640e-04 - val_loss: 6.0155e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 62us/step - loss: 2.0118e-04 - val_loss: 7.2216e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 62us/step - loss: 1.8997e-04 - val_loss: 6.0296e-05\n",
      "Epoch 21/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18465/18465 [==============================] - 1s 62us/step - loss: 1.6293e-04 - val_loss: 6.0809e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 62us/step - loss: 1.4259e-04 - val_loss: 5.0041e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 62us/step - loss: 1.2698e-04 - val_loss: 5.3168e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 62us/step - loss: 1.1480e-04 - val_loss: 4.7907e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 33s 2ms/step - loss: 0.5704 - val_loss: 2.2781e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 63us/step - loss: 0.0332 - val_loss: 0.0892\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 63us/step - loss: 0.0045 - val_loss: 1.3843e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 63us/step - loss: 6.0428e-04 - val_loss: 1.1454e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 66us/step - loss: 0.0234 - val_loss: 0.0051\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 62us/step - loss: 8.5777e-04 - val_loss: 2.4117e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 63us/step - loss: 4.4959e-04 - val_loss: 2.9834e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 62us/step - loss: 0.0099 - val_loss: 0.0137\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 63us/step - loss: 0.0022 - val_loss: 1.7309e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 62us/step - loss: 0.0019 - val_loss: 0.0067\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 62us/step - loss: 0.0071 - val_loss: 2.1591e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 62us/step - loss: 6.7836e-04 - val_loss: 0.0022\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 63us/step - loss: 0.0055 - val_loss: 0.0030\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 62us/step - loss: 0.0012 - val_loss: 8.4988e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 63us/step - loss: 0.0031 - val_loss: 0.0074\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 63us/step - loss: 0.0034 - val_loss: 5.2250e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 62us/step - loss: 8.9855e-04 - val_loss: 0.0015\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 63us/step - loss: 0.0038 - val_loss: 0.0055\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 0.0026 - val_loss: 7.3362e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 62us/step - loss: 9.4692e-04 - val_loss: 0.0021\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 63us/step - loss: 0.0027 - val_loss: 0.0020\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 62us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 62us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 63us/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 34s 2ms/step - loss: 1.0549 - val_loss: 2.3688e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 0.0964 - val_loss: 0.1851\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 0.0086 - val_loss: 1.5320e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 6.9397e-04 - val_loss: 1.5350e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 0.0198 - val_loss: 0.2358\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 0.0362 - val_loss: 1.4290e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 5.3045e-04 - val_loss: 2.1618e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 0.0100 - val_loss: 0.0956\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 0.0378 - val_loss: 1.5660e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 3.4115e-04 - val_loss: 3.5941e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 0.0031 - val_loss: 0.0119\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 63us/step - loss: 0.0210 - val_loss: 0.0054\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 0.0084 - val_loss: 0.0255\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 0.0149 - val_loss: 0.0017\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 7.8039e-04 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 0.0082 - val_loss: 0.0261\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 0.0118 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 8.3649e-04 - val_loss: 0.0017\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 0.0050 - val_loss: 0.0110\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 0.0090 - val_loss: 0.0031\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 0.0021 - val_loss: 0.0031\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 0.0053 - val_loss: 0.0068\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 0.0056 - val_loss: 0.0028\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 35s 2ms/step - loss: 0.7776 - val_loss: 0.0041\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 0.0281 - val_loss: 5.6979e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 0.0011 - val_loss: 0.0029\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 0.0296 - val_loss: 3.2726e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 7.7143e-04 - val_loss: 1.3576e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 0.0018 - val_loss: 0.0141\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 0.0185 - val_loss: 1.5950e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 6.5581e-04 - val_loss: 2.8057e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 0.0032 - val_loss: 0.0101\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 0.0084 - val_loss: 2.2102e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 5.6928e-04 - val_loss: 9.6636e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 4.5005 - val_loss: 19.8650\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 2.5702 - val_loss: 2.4155e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 0.0012 - val_loss: 7.1605e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 0.0013 - val_loss: 2.0101e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 0.0011 - val_loss: 1.6610e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 0.0011 - val_loss: 1.5053e-04\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 0.0011 - val_loss: 2.1366e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 0.0012 - val_loss: 4.4830e-04\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 0.0011 - val_loss: 1.4893e-04\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 0.0011 - val_loss: 8.8978e-04\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 0.0016 - val_loss: 2.6879e-04\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 0.0010 - val_loss: 3.6579e-04\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 35s 2ms/step - loss: 0.0014 - val_loss: 5.6342e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 9.7374e-04 - val_loss: 1.4982e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 8.1222e-04 - val_loss: 1.5086e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 6.6073e-04 - val_loss: 2.4026e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 0.0011 - val_loss: 1.4573e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 9.3663e-04 - val_loss: 2.1571e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 0.0011 - val_loss: 1.4549e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 8.8727e-04 - val_loss: 1.8387e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 4.3100e-04 - val_loss: 1.4460e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 2.8752e-04 - val_loss: 1.0092e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 3.1017e-04 - val_loss: 1.2458e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 2.6249e-04 - val_loss: 1.5093e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 68us/step - loss: 2.7629e-04 - val_loss: 7.1764e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 3.9507e-04 - val_loss: 1.6113e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 66us/step - loss: 3.0054e-04 - val_loss: 0.0065\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 0.0011 - val_loss: 1.2759e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 2.8846e-04 - val_loss: 0.0023\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 5.7876e-04 - val_loss: 1.4594e-04\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 3.0907e-04 - val_loss: 1.5015e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 2.9925e-04 - val_loss: 1.4979e-04\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 2.8397e-04 - val_loss: 1.3077e-04\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 2.7371e-04 - val_loss: 1.2866e-04\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 2.5946e-04 - val_loss: 1.8698e-04\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 2.5796e-04 - val_loss: 1.1095e-04\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 36s 2ms/step - loss: 0.0016 - val_loss: 5.4813e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 0.0011 - val_loss: 0.0058\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 0.0011 - val_loss: 3.3800e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 7.8667e-04 - val_loss: 1.6679e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 0.0343 - val_loss: 1.4908e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 66us/step - loss: 5.8629e-04 - val_loss: 2.6265e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 5.8472e-04 - val_loss: 1.7569e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 9.4827e-04 - val_loss: 1.6630e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 0.0012 - val_loss: 2.0384e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 66us/step - loss: 7.0034e-04 - val_loss: 1.3166e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 3.2548e-04 - val_loss: 6.5656e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 3.5447e-04 - val_loss: 1.4394e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 68us/step - loss: 2.6046e-04 - val_loss: 1.0644e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 66us/step - loss: 4.3762e-04 - val_loss: 1.3885e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 2.7909e-04 - val_loss: 1.4500e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 2.2587e-04 - val_loss: 1.1386e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 66us/step - loss: 2.5962e-04 - val_loss: 2.1493e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 3.4257e-04 - val_loss: 1.3857e-04\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 2.6820e-04 - val_loss: 1.2371e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 2.1027e-04 - val_loss: 8.1388e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 1.5091e-04 - val_loss: 1.0657e-04\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 1.9657e-04 - val_loss: 1.1183e-04\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 1.1305e-04 - val_loss: 8.8625e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 1.3776e-04 - val_loss: 9.9449e-05\n",
      "\n",
      "GENERATION 17\n",
      "\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 36s 2ms/step - loss: 0.0045 - val_loss: 2.2878e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 63us/step - loss: 7.3163e-04 - val_loss: 1.1998e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 4.5151e-04 - val_loss: 1.0059e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 63us/step - loss: 2.7438e-04 - val_loss: 7.1321e-05\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 63us/step - loss: 1.3949e-04 - val_loss: 5.7419e-05\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 9.3226e-05 - val_loss: 5.0857e-05\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 9.1888e-05 - val_loss: 6.3065e-05\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 6.7701e-05 - val_loss: 3.8624e-05\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 7.6536e-05 - val_loss: 3.7421e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 63us/step - loss: 5.8999e-05 - val_loss: 3.1764e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 5.8601e-05 - val_loss: 9.3614e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 6.5581e-05 - val_loss: 1.4920e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 66us/step - loss: 8.2840e-05 - val_loss: 6.7395e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 63us/step - loss: 5.6038e-05 - val_loss: 3.0575e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 5.2647e-05 - val_loss: 6.6521e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 5.5575e-05 - val_loss: 3.3047e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 63us/step - loss: 5.5239e-05 - val_loss: 6.5988e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 63us/step - loss: 5.8065e-05 - val_loss: 6.8888e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 5.4848e-05 - val_loss: 3.9174e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 4.3821e-05 - val_loss: 5.0061e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 5.2749e-05 - val_loss: 2.9713e-05\n",
      "Epoch 22/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18465/18465 [==============================] - 1s 63us/step - loss: 4.4265e-05 - val_loss: 2.8217e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 63us/step - loss: 4.3834e-05 - val_loss: 4.1823e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 6.5174e-05 - val_loss: 6.6052e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 36s 2ms/step - loss: 0.0014 - val_loss: 8.8051e-05\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 3.8274e-04 - val_loss: 5.8440e-05\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 1.6382e-04 - val_loss: 1.9845e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 1.6893e-04 - val_loss: 3.8567e-05\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 8.4871e-05 - val_loss: 3.4055e-05\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 8.2777e-05 - val_loss: 3.5724e-05\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 7.4884e-05 - val_loss: 3.6521e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 1.9660e-04 - val_loss: 1.3752e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 9.7258e-05 - val_loss: 2.9715e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 6.3712e-05 - val_loss: 6.2057e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 5.7669e-05 - val_loss: 4.5183e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 6.3805e-05 - val_loss: 3.1912e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 5.1877e-05 - val_loss: 3.1137e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 4.3690e-05 - val_loss: 3.2964e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 5.2669e-05 - val_loss: 8.0840e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 7.2210e-05 - val_loss: 2.9740e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 4.3819e-05 - val_loss: 3.2717e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 6.0442e-05 - val_loss: 5.8913e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 6.3705e-05 - val_loss: 3.2900e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 4.4650e-05 - val_loss: 1.1688e-04\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 6.3929e-05 - val_loss: 2.7087e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 4.5806e-05 - val_loss: 4.3033e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 4.7879e-05 - val_loss: 2.8756e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 66us/step - loss: 5.8974e-05 - val_loss: 1.1882e-04\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 36s 2ms/step - loss: 0.0090 - val_loss: 0.0010\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 0.0022 - val_loss: 2.5472e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 0.0022 - val_loss: 2.2128e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 0.0025 - val_loss: 3.3188e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 7.5338e-04 - val_loss: 5.8720e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 0.0013 - val_loss: 1.7837e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 5.5230e-04 - val_loss: 6.1193e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 5.3711e-04 - val_loss: 7.2877e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 4.5935e-04 - val_loss: 1.3549e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 66us/step - loss: 4.1849e-04 - val_loss: 3.6567e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 4.6262e-04 - val_loss: 1.5852e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 4.5234e-04 - val_loss: 1.7041e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 3.8834e-04 - val_loss: 2.8425e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 3.7838e-04 - val_loss: 1.2904e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 4.1001e-04 - val_loss: 2.7782e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 4.7097e-04 - val_loss: 2.1719e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 4.4373e-04 - val_loss: 1.4757e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 3.5172e-04 - val_loss: 1.7547e-04\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 3.4831e-04 - val_loss: 1.4815e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 3.6432e-04 - val_loss: 1.3520e-04\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 5.1228e-04 - val_loss: 1.4879e-04\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 3.2324e-04 - val_loss: 1.5239e-04\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 3.2189e-04 - val_loss: 7.4007e-04\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 3.2511e-04 - val_loss: 2.7509e-04\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 36s 2ms/step - loss: 0.3601 - val_loss: 0.0106\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 0.0285 - val_loss: 4.3172e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 0.0170 - val_loss: 0.0184\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 0.0097 - val_loss: 3.0972e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 0.0099 - val_loss: 2.5941e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 0.0062 - val_loss: 1.5912e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 0.0035 - val_loss: 0.0183\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 0.0039 - val_loss: 0.0013\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 0.0012 - val_loss: 4.5108e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 0.0019 - val_loss: 7.3784e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 0.0049 - val_loss: 7.8086e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 0.0016 - val_loss: 7.4603e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 0.0016 - val_loss: 1.0644e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 0.0015 - val_loss: 1.4868e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 0.0010 - val_loss: 2.4832e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 0.0011 - val_loss: 1.2688e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 7.1724e-04 - val_loss: 4.7715e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 7.9024e-04 - val_loss: 1.4384e-04\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 0.0012 - val_loss: 7.1384e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 2.9438e-04 - val_loss: 0.0041\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 7.5804e-04 - val_loss: 0.0030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 0.0018 - val_loss: 5.8941e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 3.3961e-04 - val_loss: 4.6080e-04\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 64us/step - loss: 8.6628e-04 - val_loss: 3.0571e-04\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 37s 2ms/step - loss: 0.2422 - val_loss: 1.5641e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 66us/step - loss: 0.0010 - val_loss: 7.4062e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 0.0020 - val_loss: 7.3490e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 0.0019 - val_loss: 7.8474e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 0.0017 - val_loss: 5.0614e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 66us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 66us/step - loss: 0.0017 - val_loss: 2.5467e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 66us/step - loss: 0.0017 - val_loss: 5.6088e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 66us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 66us/step - loss: 0.0016 - val_loss: 5.7144e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 66us/step - loss: 0.0015 - val_loss: 4.7473e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 0.0016 - val_loss: 2.3433e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 66us/step - loss: 0.0015 - val_loss: 8.8395e-04\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 68us/step - loss: 0.0016 - val_loss: 8.4863e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 66us/step - loss: 0.0015 - val_loss: 7.0637e-04\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 66us/step - loss: 0.0015 - val_loss: 7.4080e-04\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 0.0015 - val_loss: 2.6885e-04\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 0.0015 - val_loss: 5.1630e-04\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 38s 2ms/step - loss: 0.1338 - val_loss: 1.4952e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 66us/step - loss: 0.0010 - val_loss: 1.8136e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 66us/step - loss: 0.0012 - val_loss: 3.5235e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 0.0013 - val_loss: 8.7086e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 66us/step - loss: 0.0012 - val_loss: 2.9280e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 66us/step - loss: 0.0013 - val_loss: 8.0200e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 0.0012 - val_loss: 1.5638e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 66us/step - loss: 0.0012 - val_loss: 1.6412e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 66us/step - loss: 0.0012 - val_loss: 6.3086e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 66us/step - loss: 0.0012 - val_loss: 3.7771e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 66us/step - loss: 0.0012 - val_loss: 1.4863e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 66us/step - loss: 0.0012 - val_loss: 2.5325e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 66us/step - loss: 0.0012 - val_loss: 4.7138e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 68us/step - loss: 0.0012 - val_loss: 2.2446e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 0.0012 - val_loss: 2.1211e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 66us/step - loss: 0.0012 - val_loss: 1.7655e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 0.0012 - val_loss: 2.6726e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 66us/step - loss: 0.0012 - val_loss: 3.4053e-04\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 66us/step - loss: 0.0012 - val_loss: 8.4837e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 66us/step - loss: 0.0012 - val_loss: 1.8516e-04\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 66us/step - loss: 0.0012 - val_loss: 8.1677e-04\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 66us/step - loss: 0.0012 - val_loss: 5.1086e-04\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 0.0011 - val_loss: 8.5585e-04\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 65us/step - loss: 0.0012 - val_loss: 3.8722e-04\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 38s 2ms/step - loss: 0.0056 - val_loss: 1.5404e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 68us/step - loss: 0.0015 - val_loss: 2.1490e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 0.0014 - val_loss: 1.4212e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 0.0015 - val_loss: 1.4442e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 68us/step - loss: 0.0013 - val_loss: 4.0371e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 0.0012 - val_loss: 6.5262e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 0.0012 - val_loss: 3.8782e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 68us/step - loss: 0.0014 - val_loss: 2.7424e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 0.0011 - val_loss: 4.7087e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 0.0013 - val_loss: 7.2729e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 0.0011 - val_loss: 2.6576e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 0.0012 - val_loss: 7.7456e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 0.0012 - val_loss: 2.3081e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 68us/step - loss: 0.0013 - val_loss: 2.3229e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 0.0011 - val_loss: 4.1635e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 66us/step - loss: 0.0013 - val_loss: 2.9349e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 0.0012 - val_loss: 1.3369e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 0.0012 - val_loss: 2.1538e-04\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 68us/step - loss: 0.0011 - val_loss: 5.7235e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 0.0012 - val_loss: 7.5071e-04\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 68us/step - loss: 9.9965e-04 - val_loss: 4.9091e-04\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 69us/step - loss: 0.0012 - val_loss: 6.8361e-04\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 68us/step - loss: 0.0011 - val_loss: 1.4263e-04\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 0.0012 - val_loss: 3.9840e-04\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 38s 2ms/step - loss: 0.1547 - val_loss: 1.2962e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 76us/step - loss: 0.0250 - val_loss: 4.9702e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 0.0222 - val_loss: 0.0031\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 68us/step - loss: 0.0180 - val_loss: 0.0069\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 0.0717 - val_loss: 0.0025\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 9.8482e-04 - val_loss: 1.2531e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 68us/step - loss: 0.0043 - val_loss: 7.8922e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 0.0100 - val_loss: 0.0033\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 0.0524 - val_loss: 0.0130\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 0.0016 - val_loss: 1.5607e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 0.0010 - val_loss: 2.2104e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 0.0052 - val_loss: 0.0022\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 68us/step - loss: 0.0049 - val_loss: 0.0057\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 68us/step - loss: 0.0050 - val_loss: 0.0040\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 0.0048 - val_loss: 0.0029\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 0.0044 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 68us/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 68us/step - loss: 0.0031 - val_loss: 0.0016\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 0.0031 - val_loss: 8.6807e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 0.0027 - val_loss: 0.0094\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 0.0116 - val_loss: 1.5032e-04\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 66us/step - loss: 0.0011 - val_loss: 6.4915e-04\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 0.0018 - val_loss: 6.6261e-04\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 39s 2ms/step - loss: 0.0903 - val_loss: 1.7148e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 0.0270 - val_loss: 0.0013\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 0.0176 - val_loss: 0.0032\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 68us/step - loss: 0.0139 - val_loss: 0.0028\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 68us/step - loss: 0.0314 - val_loss: 1.4215e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 9.4664e-04 - val_loss: 1.3225e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 68us/step - loss: 0.0068 - val_loss: 9.7859e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 0.0065 - val_loss: 0.0051\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 68us/step - loss: 0.0054 - val_loss: 0.0049\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 0.0133 - val_loss: 0.2623\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 0.0339 - val_loss: 1.6931e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 9.4080e-04 - val_loss: 1.3957e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 66us/step - loss: 0.0018 - val_loss: 7.5440e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 68us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 68us/step - loss: 0.0024 - val_loss: 9.0888e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 68us/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 0.0015 - val_loss: 8.6980e-04\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 0.0014 - val_loss: 7.0375e-04\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 0.0012 - val_loss: 4.9399e-04\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 9.7352e-04 - val_loss: 8.3210e-04\n",
      "\n",
      "GENERATION 18\n",
      "\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 40s 2ms/step - loss: 0.0767 - val_loss: 2.9357e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 69us/step - loss: 0.0011 - val_loss: 9.7128e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 69us/step - loss: 0.0028 - val_loss: 8.4922e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 69us/step - loss: 0.0027 - val_loss: 0.0011\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 69us/step - loss: 8.8372e-04 - val_loss: 3.9788e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 68us/step - loss: 0.0026 - val_loss: 1.9710e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 69us/step - loss: 6.5263e-04 - val_loss: 0.0014\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 69us/step - loss: 0.0022 - val_loss: 1.0534e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 69us/step - loss: 0.0012 - val_loss: 3.3968e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 69us/step - loss: 7.2644e-04 - val_loss: 0.0029\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 8.4191e-04 - val_loss: 7.2321e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 5.3674e-04 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 4.5119e-04 - val_loss: 9.1134e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 69us/step - loss: 5.5814e-04 - val_loss: 4.7808e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 69us/step - loss: 5.1835e-04 - val_loss: 1.6402e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 69us/step - loss: 4.9747e-04 - val_loss: 6.4029e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 69us/step - loss: 4.5671e-04 - val_loss: 5.1949e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 69us/step - loss: 4.9754e-04 - val_loss: 3.5056e-04\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 69us/step - loss: 4.3957e-04 - val_loss: 2.4869e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 3.1254e-04 - val_loss: 9.4813e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 69us/step - loss: 4.0995e-04 - val_loss: 3.6989e-04\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 69us/step - loss: 3.3289e-04 - val_loss: 5.0112e-04\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 69us/step - loss: 3.6022e-04 - val_loss: 1.1323e-04\n",
      "Epoch 24/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.4445e-04 - val_loss: 4.8635e-04\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 40s 2ms/step - loss: 0.0014 - val_loss: 1.2094e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 5.4116e-04 - val_loss: 5.0626e-05\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 2.6095e-04 - val_loss: 4.5585e-05\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 2.5077e-04 - val_loss: 4.4731e-05\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 8.5078e-05 - val_loss: 4.8357e-05\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 6.1851e-05 - val_loss: 3.0146e-05\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 5.8076e-05 - val_loss: 2.8218e-05\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 5.2580e-05 - val_loss: 2.3609e-05- ETA: 0s - loss: 5.3400e-\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 5.8182e-05 - val_loss: 2.8574e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 5.2869e-05 - val_loss: 3.1492e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 68us/step - loss: 6.8149e-05 - val_loss: 8.7015e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 6.2856e-05 - val_loss: 1.5310e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 7.4802e-05 - val_loss: 7.3750e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 6.2818e-05 - val_loss: 5.8594e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 4.9314e-05 - val_loss: 3.7701e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 69us/step - loss: 6.1973e-05 - val_loss: 4.0862e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 4.5110e-05 - val_loss: 3.3455e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 66us/step - loss: 6.7536e-05 - val_loss: 4.9208e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 4.7362e-05 - val_loss: 6.5719e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 4.8122e-05 - val_loss: 2.4729e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 4.6182e-05 - val_loss: 3.2598e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 5.6372e-05 - val_loss: 4.3996e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 5.8010e-05 - val_loss: 2.7666e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 4.1168e-05 - val_loss: 2.6070e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 40s 2ms/step - loss: 0.0021 - val_loss: 1.4973e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 5.2584e-04 - val_loss: 6.8928e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 3.5424e-04 - val_loss: 9.3958e-05\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 68us/step - loss: 1.2199e-04 - val_loss: 5.5622e-05\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 9.2687e-05 - val_loss: 5.4038e-05\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 6.1473e-05 - val_loss: 3.5650e-05\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 6.7337e-05 - val_loss: 6.9062e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 68us/step - loss: 2.5091e-04 - val_loss: 1.7911e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 1.6185e-04 - val_loss: 5.8323e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 6.5365e-05 - val_loss: 8.5009e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 5.4635e-05 - val_loss: 2.6866e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 4.2608e-05 - val_loss: 2.6576e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 68us/step - loss: 4.2681e-05 - val_loss: 2.5386e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 4.6088e-05 - val_loss: 2.5020e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 4.2607e-05 - val_loss: 6.2236e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 5.1331e-05 - val_loss: 2.5843e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 3.7984e-05 - val_loss: 3.1336e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 4.5523e-05 - val_loss: 3.0803e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.6645e-05 - val_loss: 2.5093e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 68us/step - loss: 4.4519e-05 - val_loss: 2.2667e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 3.7270e-05 - val_loss: 3.3860e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 5.4042e-05 - val_loss: 3.1413e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 4.5317e-05 - val_loss: 2.8249e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 5.2730e-05 - val_loss: 9.1172e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 40s 2ms/step - loss: 0.2506 - val_loss: 4.4034e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 69us/step - loss: 0.0032 - val_loss: 4.6503e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 68us/step - loss: 0.0012 - val_loss: 2.9434e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 68us/step - loss: 9.5695e-04 - val_loss: 2.7789e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 68us/step - loss: 7.9274e-04 - val_loss: 2.5029e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 68us/step - loss: 6.7703e-04 - val_loss: 2.4337e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 68us/step - loss: 5.5983e-04 - val_loss: 1.9557e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 69us/step - loss: 4.6159e-04 - val_loss: 1.7020e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.7698e-04 - val_loss: 1.5132e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 68us/step - loss: 3.1059e-04 - val_loss: 1.4126e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 68us/step - loss: 2.5901e-04 - val_loss: 1.1653e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 68us/step - loss: 2.1332e-04 - val_loss: 1.0200e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 68us/step - loss: 1.8274e-04 - val_loss: 8.9217e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 69us/step - loss: 1.4925e-04 - val_loss: 8.2879e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 68us/step - loss: 1.6214e-04 - val_loss: 7.5995e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 69us/step - loss: 1.2995e-04 - val_loss: 7.4192e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 69us/step - loss: 1.0821e-04 - val_loss: 8.0538e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 69us/step - loss: 1.0147e-04 - val_loss: 6.9154e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 68us/step - loss: 9.5341e-05 - val_loss: 6.9197e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 68us/step - loss: 9.2837e-05 - val_loss: 7.2712e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 8.7665e-05 - val_loss: 8.2648e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 68us/step - loss: 8.4697e-05 - val_loss: 6.6171e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 69us/step - loss: 8.0058e-05 - val_loss: 6.4528e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 69us/step - loss: 7.7583e-05 - val_loss: 7.0443e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 41s 2ms/step - loss: 0.2374 - val_loss: 7.8212e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 0.0040 - val_loss: 4.8179e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 69us/step - loss: 9.8918e-04 - val_loss: 2.4146e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 69us/step - loss: 7.5843e-04 - val_loss: 2.1892e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 69us/step - loss: 6.3271e-04 - val_loss: 1.9581e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 69us/step - loss: 5.2839e-04 - val_loss: 1.6514e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 4.5532e-04 - val_loss: 1.4824e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.6939e-04 - val_loss: 1.3769e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 68us/step - loss: 3.0960e-04 - val_loss: 1.2489e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 69us/step - loss: 2.6250e-04 - val_loss: 1.1338e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 69us/step - loss: 2.2917e-04 - val_loss: 1.0933e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 69us/step - loss: 2.0372e-04 - val_loss: 9.8203e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 69us/step - loss: 1.8425e-04 - val_loss: 9.4985e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 1.6329e-04 - val_loss: 9.7750e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 69us/step - loss: 1.4521e-04 - val_loss: 8.6262e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 69us/step - loss: 1.3019e-04 - val_loss: 8.2694e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 69us/step - loss: 1.1951e-04 - val_loss: 7.8756e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 1.1183e-04 - val_loss: 7.8732e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 69us/step - loss: 1.0435e-04 - val_loss: 7.4562e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 9.9675e-05 - val_loss: 7.5209e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 9.4656e-05 - val_loss: 7.2962e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 69us/step - loss: 8.8364e-05 - val_loss: 7.5179e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 69us/step - loss: 9.2766e-05 - val_loss: 6.9427e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 8.1622e-05 - val_loss: 6.9999e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 41s 2ms/step - loss: 0.3900 - val_loss: 1.7675e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 9.8624e-04 - val_loss: 2.1878e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 9.1371e-04 - val_loss: 2.4287e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 68us/step - loss: 8.5246e-04 - val_loss: 1.5453e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 8.1008e-04 - val_loss: 3.3276e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 7.6892e-04 - val_loss: 1.2801e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 68us/step - loss: 7.1097e-04 - val_loss: 1.2700e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 66us/step - loss: 6.7723e-04 - val_loss: 1.2509e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 69us/step - loss: 6.3797e-04 - val_loss: 1.2471e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 66us/step - loss: 6.1672e-04 - val_loss: 1.1050e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 5.7491e-04 - val_loss: 1.1382e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 68us/step - loss: 5.5330e-04 - val_loss: 1.0136e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 5.1337e-04 - val_loss: 1.5768e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 68us/step - loss: 4.9047e-04 - val_loss: 9.3547e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 4.6327e-04 - val_loss: 8.9136e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 68us/step - loss: 4.3189e-04 - val_loss: 8.5606e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 68us/step - loss: 4.6330e-04 - val_loss: 8.8009e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 3.7692e-04 - val_loss: 8.6267e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 3.5499e-04 - val_loss: 1.7205e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 3.6918e-04 - val_loss: 9.0518e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 3.3062e-04 - val_loss: 8.7187e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 2.9613e-04 - val_loss: 7.0729e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 2.8334e-04 - val_loss: 1.3790e-04\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 3.1167e-04 - val_loss: 9.4675e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 42s 2ms/step - loss: 0.0021 - val_loss: 2.7239e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 66us/step - loss: 0.0013 - val_loss: 2.4534e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 66us/step - loss: 0.0012 - val_loss: 2.3970e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 66us/step - loss: 0.0012 - val_loss: 2.5730e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 66us/step - loss: 0.0012 - val_loss: 2.3973e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 66us/step - loss: 0.0011 - val_loss: 2.3158e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 0.0011 - val_loss: 2.4101e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 66us/step - loss: 0.0011 - val_loss: 2.2386e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 69us/step - loss: 0.0011 - val_loss: 2.2710e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 0.0011 - val_loss: 2.2244e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 66us/step - loss: 0.0011 - val_loss: 2.2028e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 66us/step - loss: 0.0011 - val_loss: 2.2939e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 66us/step - loss: 0.0011 - val_loss: 2.2657e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 66us/step - loss: 0.0011 - val_loss: 2.1812e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 66us/step - loss: 0.0011 - val_loss: 2.1961e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 66us/step - loss: 0.0011 - val_loss: 2.1589e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 0.0011 - val_loss: 2.1519e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 66us/step - loss: 0.0011 - val_loss: 2.3212e-04\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 66us/step - loss: 0.0011 - val_loss: 2.2695e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 66us/step - loss: 0.0010 - val_loss: 2.4213e-04\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 66us/step - loss: 0.0010 - val_loss: 2.2273e-04\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 69us/step - loss: 0.0010 - val_loss: 2.2276e-04\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 66us/step - loss: 0.0010 - val_loss: 2.2056e-04\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 0.0010 - val_loss: 2.1254e-04\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 43s 2ms/step - loss: 0.0023 - val_loss: 2.4637e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 6.4977e-04 - val_loss: 1.4428e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 3.7247e-04 - val_loss: 5.2941e-05\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 2.3202e-04 - val_loss: 7.3128e-05\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 9.8200e-05 - val_loss: 5.0788e-05\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 7.2683e-05 - val_loss: 3.8552e-05\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 5.3715e-05 - val_loss: 6.2709e-05\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 5.4828e-05 - val_loss: 3.9925e-05\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 4.8869e-05 - val_loss: 3.7038e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 9.9999e-05 - val_loss: 8.2124e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 5.8686e-05 - val_loss: 5.3259e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 4.4508e-05 - val_loss: 8.3226e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 5.1436e-05 - val_loss: 3.8515e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 4.1363e-05 - val_loss: 5.6076e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 5.2823e-05 - val_loss: 3.1493e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 3.9649e-05 - val_loss: 3.9026e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 4.1861e-05 - val_loss: 4.0014e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 5.1386e-05 - val_loss: 3.0673e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 5.0339e-05 - val_loss: 5.4161e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 6.5899e-05 - val_loss: 2.9297e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 4.8793e-05 - val_loss: 6.3759e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 5.4187e-05 - val_loss: 4.9775e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 5.3440e-05 - val_loss: 2.6798e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 4.7809e-05 - val_loss: 4.0300e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 41s 2ms/step - loss: 0.0192 - val_loss: 0.0011\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 0.0011 - val_loss: 1.5267e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 0.0010 - val_loss: 1.5413e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 0.0010 - val_loss: 1.5280e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 0.0010 - val_loss: 1.8363e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 9.9308e-04 - val_loss: 1.6494e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 9.7066e-04 - val_loss: 1.4411e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 9.3770e-04 - val_loss: 1.4138e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 8.8723e-04 - val_loss: 1.3663e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 8.1228e-04 - val_loss: 1.3257e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 7.0903e-04 - val_loss: 1.0189e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 4.9624e-04 - val_loss: 1.4124e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 2.4830e-04 - val_loss: 3.7228e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 1.3836e-04 - val_loss: 4.2460e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.0710e-04 - val_loss: 2.8332e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 7.4786e-05 - val_loss: 2.9764e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 6.3186e-05 - val_loss: 2.1411e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 5.4618e-05 - val_loss: 1.9451e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 4.5226e-05 - val_loss: 2.3216e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 4.5209e-05 - val_loss: 1.7725e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 4.4958e-05 - val_loss: 1.9887e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 4.3133e-05 - val_loss: 3.9667e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 4.8760e-05 - val_loss: 1.9238e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.9553e-05 - val_loss: 1.6652e-05\n",
      "\n",
      "GENERATION 19\n",
      "\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 44s 2ms/step - loss: 0.0012 - val_loss: 2.2912e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 7.8535e-04 - val_loss: 1.2736e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 5.1718e-04 - val_loss: 2.6113e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.2403e-04 - val_loss: 1.5145e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.7750e-04 - val_loss: 3.3561e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.4454e-04 - val_loss: 7.1401e-05\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 9.3377e-05 - val_loss: 1.4249e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 7.9504e-05 - val_loss: 4.7626e-05\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 5.8690e-05 - val_loss: 3.6587e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 5.2634e-05 - val_loss: 5.8138e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 5.4828e-05 - val_loss: 4.2856e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 4.3756e-05 - val_loss: 3.6645e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 5.6650e-05 - val_loss: 6.8887e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 7.4745e-05 - val_loss: 1.3283e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 6.5680e-05 - val_loss: 4.3511e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 4.0525e-05 - val_loss: 3.8080e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 3.7741e-05 - val_loss: 3.4455e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 4.3810e-05 - val_loss: 4.5597e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 4.1670e-05 - val_loss: 3.2037e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 5.7575e-05 - val_loss: 3.7510e-05\n",
      "Epoch 21/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18465/18465 [==============================] - 1s 70us/step - loss: 3.8206e-05 - val_loss: 6.7493e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 5.9473e-05 - val_loss: 3.9100e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 4.7373e-05 - val_loss: 5.1617e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 5.0732e-05 - val_loss: 3.3943e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 43s 2ms/step - loss: 0.0348 - val_loss: 7.8813e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 0.0012 - val_loss: 1.5745e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 9.5795e-04 - val_loss: 1.5854e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 69us/step - loss: 9.1680e-04 - val_loss: 1.4611e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 8.6964e-04 - val_loss: 1.4550e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 8.1363e-04 - val_loss: 1.3833e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 7.5546e-04 - val_loss: 1.2831e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 6.8786e-04 - val_loss: 1.2817e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 6.0831e-04 - val_loss: 1.1380e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 69us/step - loss: 5.1113e-04 - val_loss: 9.6758e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 3.8650e-04 - val_loss: 8.5756e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.6196e-04 - val_loss: 6.5120e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 1.6136e-04 - val_loss: 4.4319e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.0192e-04 - val_loss: 3.2308e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 6.8434e-05 - val_loss: 2.9142e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 5.3647e-05 - val_loss: 2.7315e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 4.7085e-05 - val_loss: 2.3191e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 4.2958e-05 - val_loss: 2.5017e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.9984e-05 - val_loss: 2.5669e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.9336e-05 - val_loss: 2.6114e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 3.8746e-05 - val_loss: 2.7254e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 3.9166e-05 - val_loss: 1.9898e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.6270e-05 - val_loss: 1.9380e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 69us/step - loss: 3.5730e-05 - val_loss: 2.0438e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 45s 2ms/step - loss: 0.0274 - val_loss: 2.5452e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 0.0012 - val_loss: 1.4598e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 9.7688e-04 - val_loss: 1.4208e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 9.3922e-04 - val_loss: 1.5170e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 9.0498e-04 - val_loss: 1.3859e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 8.5653e-04 - val_loss: 1.4900e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 8.0212e-04 - val_loss: 1.3256e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 7.2948e-04 - val_loss: 1.3617e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 6.3659e-04 - val_loss: 1.1692e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 5.0703e-04 - val_loss: 9.2168e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.0715e-04 - val_loss: 6.0552e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.6882e-04 - val_loss: 6.9743e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 1.2119e-04 - val_loss: 4.2204e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 9.6230e-05 - val_loss: 3.2413e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 7.8594e-05 - val_loss: 2.8433e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 6.7704e-05 - val_loss: 2.5640e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 5.9989e-05 - val_loss: 2.3235e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 5.5602e-05 - val_loss: 2.7595e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 5.3600e-05 - val_loss: 2.1161e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 4.8733e-05 - val_loss: 1.9259e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 4.2198e-05 - val_loss: 1.8996e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 4.2565e-05 - val_loss: 2.4499e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.9371e-05 - val_loss: 1.9368e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.8621e-05 - val_loss: 2.6367e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 44s 2ms/step - loss: 0.0214 - val_loss: 0.0011\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 0.0012 - val_loss: 1.9826e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 0.0010 - val_loss: 1.5824e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 9.9815e-04 - val_loss: 1.5758e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 81us/step - loss: 9.7577e-04 - val_loss: 1.4688e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 76us/step - loss: 9.5112e-04 - val_loss: 2.1399e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 77us/step - loss: 9.2396e-04 - val_loss: 1.3515e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 8.6086e-04 - val_loss: 1.2655e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 8.0546e-04 - val_loss: 1.3134e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 7.3522e-04 - val_loss: 1.1014e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 6.5158e-04 - val_loss: 9.9152e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 5.4289e-04 - val_loss: 8.1348e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.9443e-04 - val_loss: 5.6144e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.4452e-04 - val_loss: 3.4414e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 1.3334e-04 - val_loss: 2.1898e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 8.0420e-05 - val_loss: 2.0550e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 5.8646e-05 - val_loss: 2.3467e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - ETA: 0s - loss: 5.1869e-0 - 1s 73us/step - loss: 5.0893e-05 - val_loss: 1.9826e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 4.6623e-05 - val_loss: 2.2677e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 4.3469e-05 - val_loss: 3.5283e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 4.3762e-05 - val_loss: 2.0942e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.9845e-05 - val_loss: 1.7601e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 3.7915e-05 - val_loss: 1.7503e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.7852e-05 - val_loss: 1.9455e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 47s 3ms/step - loss: 0.0838 - val_loss: 2.9259e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 0.0015 - val_loss: 2.6462e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 8.4360e-04 - val_loss: 1.2457e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 7.4713e-04 - val_loss: 1.2074e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 6.6856e-04 - val_loss: 1.3670e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 5.9414e-04 - val_loss: 9.4651e-05\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 5.2272e-04 - val_loss: 1.3377e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 4.3317e-04 - val_loss: 9.0889e-05\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 76us/step - loss: 3.4778e-04 - val_loss: 6.9129e-05\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.6879e-04 - val_loss: 7.8708e-05\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0743e-04 - val_loss: 4.6730e-05\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.5123e-04 - val_loss: 3.4461e-05\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 1.1444e-04 - val_loss: 2.9639e-05\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 8.8496e-05 - val_loss: 2.8598e-05\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 7.2067e-05 - val_loss: 3.2095e-05\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 6.0977e-05 - val_loss: 2.8845e-05\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 5.6216e-05 - val_loss: 2.1524e-05\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 4.9117e-05 - val_loss: 2.3997e-05\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 4.7213e-05 - val_loss: 3.0312e-05\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 4.5341e-05 - val_loss: 1.9851e-05\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 4.4913e-05 - val_loss: 2.7681e-05\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 4.8102e-05 - val_loss: 1.9592e-05\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 4.5106e-05 - val_loss: 1.9349e-05\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 4.1134e-05 - val_loss: 1.8536e-05\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 47s 3ms/step - loss: 0.0822 - val_loss: 0.0032\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 0.0016 - val_loss: 3.3737e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 0.0010 - val_loss: 1.7335e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 0.0010 - val_loss: 1.6010e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 0.0010 - val_loss: 1.6355e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 0.0010 - val_loss: 1.5845e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 9.9368e-04 - val_loss: 1.6274e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 9.8403e-04 - val_loss: 1.4796e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 9.7278e-04 - val_loss: 1.5342e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 9.6377e-04 - val_loss: 1.7019e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 9.5222e-04 - val_loss: 1.3870e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 9.4421e-04 - val_loss: 1.5726e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 9.2604e-04 - val_loss: 1.4951e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 9.0911e-04 - val_loss: 1.3530e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 8.9803e-04 - val_loss: 1.5260e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 8.8863e-04 - val_loss: 1.3160e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 8.6435e-04 - val_loss: 1.3891e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 8.4519e-04 - val_loss: 1.3581e-04\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 8.2157e-04 - val_loss: 1.4541e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 8.0417e-04 - val_loss: 1.5830e-04\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 7.8235e-04 - val_loss: 1.2724e-04\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 7.5697e-04 - val_loss: 2.0984e-04\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 7.4345e-04 - val_loss: 1.2101e-04\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 6.9344e-04 - val_loss: 1.2517e-04\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 47s 3ms/step - loss: 0.8343 - val_loss: 1.5162e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 0.0010 - val_loss: 1.5034e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 68us/step - loss: 0.0010 - val_loss: 1.4817e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 0.0010 - val_loss: 1.5363e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 0.0010 - val_loss: 1.5348e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 68us/step - loss: 0.0010 - val_loss: 1.4755e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 0.0010 - val_loss: 1.6678e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 68us/step - loss: 0.0010 - val_loss: 1.5032e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 0.0010 - val_loss: 1.8787e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 68us/step - loss: 0.0010 - val_loss: 1.7735e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 0.0010 - val_loss: 1.5507e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 0.0010 - val_loss: 1.4674e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 69us/step - loss: 0.0010 - val_loss: 1.4702e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 0.0010 - val_loss: 5.3860e-04ETA: 0s - \n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 0.0010 - val_loss: 1.5518e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 0.0010 - val_loss: 1.7052e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 68us/step - loss: 0.0010 - val_loss: 1.8814e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 68us/step - loss: 0.0010 - val_loss: 1.6825e-04\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 68us/step - loss: 0.0010 - val_loss: 1.4784e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 68us/step - loss: 0.0010 - val_loss: 1.6081e-04\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 68us/step - loss: 0.0010 - val_loss: 1.4925e-04\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 0.0010 - val_loss: 1.5695e-04\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 0.0010 - val_loss: 1.4426e-04\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 67us/step - loss: 0.0010 - val_loss: 1.5083e-04\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 47s 3ms/step - loss: 0.5871 - val_loss: 1.5076e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 0.0010 - val_loss: 1.5066e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 0.0010 - val_loss: 1.4651e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 0.0010 - val_loss: 1.4663e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 0.0010 - val_loss: 1.4995e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 0.0010 - val_loss: 3.1065e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 0.0010 - val_loss: 1.4531e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 0.0010 - val_loss: 1.5600e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 0.0010 - val_loss: 1.4445e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 0.0010 - val_loss: 1.7144e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 0.0010 - val_loss: 2.7864e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 0.0010 - val_loss: 2.5895e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 9.9924e-04 - val_loss: 1.6729e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 9.9588e-04 - val_loss: 1.4790e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 9.9465e-04 - val_loss: 1.5311e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 9.9152e-04 - val_loss: 1.4661e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 9.8780e-04 - val_loss: 1.8513e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 9.8598e-04 - val_loss: 1.4273e-04\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 9.8374e-04 - val_loss: 1.9985e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 9.8292e-04 - val_loss: 1.4737e-04\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 9.7904e-04 - val_loss: 1.7034e-04\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 9.7608e-04 - val_loss: 1.5708e-04\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 9.7399e-04 - val_loss: 1.4342e-04\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 9.7129e-04 - val_loss: 1.6860e-04\n",
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/24\n",
      "18465/18465 [==============================] - 48s 3ms/step - loss: 2.1809 - val_loss: 1.5996e-04\n",
      "Epoch 2/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 0.0010 - val_loss: 2.0814e-04\n",
      "Epoch 3/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 9.9975e-04 - val_loss: 1.7797e-04\n",
      "Epoch 4/24\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 9.9841e-04 - val_loss: 1.5225e-04\n",
      "Epoch 5/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 9.8798e-04 - val_loss: 1.4656e-04\n",
      "Epoch 6/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 9.8289e-04 - val_loss: 1.4368e-04\n",
      "Epoch 7/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 9.7912e-04 - val_loss: 1.4346e-04\n",
      "Epoch 8/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 9.7297e-04 - val_loss: 7.7477e-04\n",
      "Epoch 9/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 9.7871e-04 - val_loss: 1.5573e-04\n",
      "Epoch 10/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 9.6168e-04 - val_loss: 7.4208e-04\n",
      "Epoch 11/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 9.7315e-04 - val_loss: 1.4924e-04\n",
      "Epoch 12/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 9.5318e-04 - val_loss: 1.7311e-04\n",
      "Epoch 13/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 9.4676e-04 - val_loss: 1.6031e-04\n",
      "Epoch 14/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 9.4553e-04 - val_loss: 1.7267e-04\n",
      "Epoch 15/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 9.4198e-04 - val_loss: 1.3796e-04\n",
      "Epoch 16/24\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 9.3748e-04 - val_loss: 1.3774e-04\n",
      "Epoch 17/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 9.2899e-04 - val_loss: 1.5618e-04\n",
      "Epoch 18/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 9.2635e-04 - val_loss: 7.8475e-04\n",
      "Epoch 19/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 9.3782e-04 - val_loss: 1.9350e-04\n",
      "Epoch 20/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 9.1774e-04 - val_loss: 1.3502e-04\n",
      "Epoch 21/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 9.1460e-04 - val_loss: 1.9158e-04\n",
      "Epoch 22/24\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 9.0904e-04 - val_loss: 1.3504e-04\n",
      "Epoch 23/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 9.0751e-04 - val_loss: 1.7294e-04\n",
      "Epoch 24/24\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 9.0533e-04 - val_loss: 1.3333e-04\n"
     ]
    }
   ],
   "source": [
    "best_models = breed_population(train_time, train_nexus, train_y, generations=20, population_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.00013294491533552647,\n",
       " 9.433451294093384e-05,\n",
       " 0.00024443345026841084,\n",
       " 5.084194772439731e-05,\n",
       " 6.086511855305501e-05,\n",
       " 2.8466620017275668e-05,\n",
       " 0.00022664676140925755,\n",
       " 9.240883775940437e-05,\n",
       " 4.8228700760548635e-05,\n",
       " 4.472073499405721e-05,\n",
       " 2.4547553969038885e-05,\n",
       " 2.7429191690933625e-05,\n",
       " 4.1564037334845634e-05,\n",
       " 2.310892973343327e-05,\n",
       " 2.5157512207754807e-05,\n",
       " 3.250769267976216e-05,\n",
       " 2.8720995912282522e-05,\n",
       " 6.419182370264096e-05,\n",
       " 2.3574085557093465e-05,\n",
       " 9.071044565133522e-05,\n",
       " 7.243006553768214e-05,\n",
       " 3.207610189724309e-05,\n",
       " 2.511422016643025e-05,\n",
       " 1.8176598550816367e-05]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models[0][1].history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal parameters\n",
      "_______________________\n",
      "twice: True\n",
      "dropout: 0.2\n",
      "shuffle: True\n",
      "density: 54\n",
      "activation: relu\n",
      "lstmsize: 4\n",
      "merge_density: 176\n",
      "optimizer: adam\n",
      "full_density: True\n"
     ]
    }
   ],
   "source": [
    "print('optimal parameters')\n",
    "print('_______________________')\n",
    "for key,val in best_models[0][2].items():\n",
    "    if key != 'x' and key != 'y': print(f'{key}: {val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_57\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "lstm_113_input (InputLayer)     (None, 4, 100)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_113 (LSTM)                 (None, 4, 4)         1680        lstm_113_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_113 (Dropout)           (None, 4, 4)         0           lstm_113[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_114 (LSTM)                 (None, 4)            144         dropout_113[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_285_input (InputLayer)    (None, 99)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_114 (Dropout)           (None, 4)            0           lstm_114[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_285 (Dense)               (None, 54)           5400        dense_285_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_57 (Concatenate)    (None, 58)           0           dropout_114[0][0]                \n",
      "                                                                 dense_285[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_286 (Dense)               (None, 176)          10384       concatenate_57[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_287 (Dense)               (None, 88)           15576       dense_286[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_288 (Dense)               (None, 44)           3916        dense_287[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_289 (Dense)               (None, 22)           990         dense_288[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_290 (Dense)               (None, 1)            23          dense_289[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 38,113\n",
      "Trainable params: 38,113\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_models[0][0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\n",
    "    filepath='./checkpoints/fundamental.{epoch}-{val_loss}.hdf5',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = best_models[0][2]\n",
    "params['x_time'] = train_time\n",
    "params['x_nexus'] = train_nexus\n",
    "params['y'] = train_y\n",
    "params['epochs'] = 2000\n",
    "params['callbacks'] = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18465 samples, validate on 2052 samples\n",
      "Epoch 1/2000\n",
      "18465/18465 [==============================] - 49s 3ms/step - loss: 0.0031 - val_loss: 1.4996e-04\n",
      "Epoch 2/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 7.5622e-04 - val_loss: 1.0301e-04\n",
      "Epoch 3/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 5.6354e-04 - val_loss: 1.0758e-04\n",
      "Epoch 4/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.3730e-04 - val_loss: 6.6341e-05\n",
      "Epoch 5/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.7616e-04 - val_loss: 7.8136e-05\n",
      "Epoch 6/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 1.0736e-04 - val_loss: 2.7518e-05\n",
      "Epoch 7/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 5.7798e-05 - val_loss: 2.4425e-05\n",
      "Epoch 8/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 5.6417e-05 - val_loss: 4.1140e-05\n",
      "Epoch 9/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 6.5760e-05 - val_loss: 7.7181e-05\n",
      "Epoch 10/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 5.1382e-05 - val_loss: 5.4321e-05\n",
      "Epoch 11/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 4.9339e-05 - val_loss: 1.8735e-05\n",
      "Epoch 12/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 6.0520e-05 - val_loss: 1.9676e-05\n",
      "Epoch 13/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 4.7433e-05 - val_loss: 2.0885e-05\n",
      "Epoch 14/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 4.4444e-05 - val_loss: 3.1236e-05\n",
      "Epoch 15/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 4.3115e-05 - val_loss: 2.6702e-05\n",
      "Epoch 16/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 4.7231e-05 - val_loss: 5.8692e-05\n",
      "Epoch 17/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 5.7784e-05 - val_loss: 5.3861e-05\n",
      "Epoch 18/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 4.9137e-05 - val_loss: 2.0724e-05\n",
      "Epoch 19/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 5.6771e-05 - val_loss: 2.1023e-05\n",
      "Epoch 20/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 6.0997e-05 - val_loss: 2.7858e-05\n",
      "Epoch 21/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 5.4134e-05 - val_loss: 5.4224e-05\n",
      "Epoch 22/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 5.1242e-05 - val_loss: 1.6722e-04\n",
      "Epoch 23/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.1464e-04 - val_loss: 4.1549e-05\n",
      "Epoch 24/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 4.7713e-05 - val_loss: 1.8896e-05\n",
      "Epoch 25/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 4.0033e-05 - val_loss: 1.8973e-05\n",
      "Epoch 26/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 3.5866e-05 - val_loss: 2.2711e-05\n",
      "Epoch 27/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.8853e-05 - val_loss: 5.3527e-05\n",
      "Epoch 28/2000\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 4.3850e-05 - val_loss: 4.7385e-05\n",
      "Epoch 29/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 5.0853e-05 - val_loss: 2.0466e-05\n",
      "Epoch 30/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 4.0102e-05 - val_loss: 9.4424e-05\n",
      "Epoch 31/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 4.4334e-05 - val_loss: 2.7025e-05\n",
      "Epoch 32/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 4.7476e-05 - val_loss: 2.9431e-05\n",
      "Epoch 33/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 4.2421e-05 - val_loss: 2.5855e-05\n",
      "Epoch 34/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 5.3615e-05 - val_loss: 3.4154e-05\n",
      "Epoch 35/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.6364e-05 - val_loss: 2.8501e-05\n",
      "Epoch 36/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 5.0304e-05 - val_loss: 1.7421e-05\n",
      "Epoch 37/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 4.9023e-05 - val_loss: 2.3730e-05\n",
      "Epoch 38/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 4.1565e-05 - val_loss: 4.5623e-05\n",
      "Epoch 39/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.9042e-05 - val_loss: 3.6135e-05\n",
      "Epoch 40/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 4.0122e-05 - val_loss: 1.5703e-05\n",
      "Epoch 41/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 4.2054e-05 - val_loss: 2.0666e-05\n",
      "Epoch 42/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 5.3192e-05 - val_loss: 1.1167e-04\n",
      "Epoch 43/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 6.3485e-05 - val_loss: 1.6998e-05\n",
      "Epoch 44/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.6339e-05 - val_loss: 1.5589e-05\n",
      "Epoch 45/2000\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 3.5356e-05 - val_loss: 1.7841e-05\n",
      "Epoch 46/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 4.1606e-05 - val_loss: 2.5162e-05\n",
      "Epoch 47/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 4.6463e-05 - val_loss: 2.2161e-05\n",
      "Epoch 48/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.3900e-05 - val_loss: 1.5677e-05\n",
      "Epoch 49/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.3565e-05 - val_loss: 3.2472e-05\n",
      "Epoch 50/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 4.2864e-05 - val_loss: 2.3334e-05\n",
      "Epoch 51/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.7388e-05 - val_loss: 1.7636e-05\n",
      "Epoch 52/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.7997e-05 - val_loss: 1.5931e-05\n",
      "Epoch 53/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.6894e-05 - val_loss: 5.0446e-05\n",
      "Epoch 54/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 6.2134e-05 - val_loss: 4.3708e-05\n",
      "Epoch 55/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 8.6842e-05 - val_loss: 2.9925e-05\n",
      "Epoch 56/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.8957e-05 - val_loss: 3.4238e-05\n",
      "Epoch 57/2000\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 3.8196e-05 - val_loss: 1.7477e-05\n",
      "Epoch 58/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.3215e-05 - val_loss: 1.8235e-05\n",
      "Epoch 59/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.1263e-05 - val_loss: 1.7388e-05\n",
      "Epoch 60/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.8816e-05 - val_loss: 1.8250e-05\n",
      "Epoch 61/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.6341e-05 - val_loss: 3.5805e-05\n",
      "Epoch 62/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.9305e-05 - val_loss: 2.1716e-05\n",
      "Epoch 63/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 4.0612e-05 - val_loss: 2.0717e-05\n",
      "Epoch 64/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 4.2530e-05 - val_loss: 7.6235e-05\n",
      "Epoch 65/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 6.0905e-05 - val_loss: 6.3758e-05\n",
      "Epoch 66/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 6.9851e-05 - val_loss: 1.6766e-05\n",
      "Epoch 67/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.2644e-05 - val_loss: 5.6525e-05\n",
      "Epoch 68/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.6877e-05 - val_loss: 3.7518e-05\n",
      "Epoch 69/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 5.3315e-05 - val_loss: 2.0695e-05\n",
      "Epoch 70/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.4699e-05 - val_loss: 1.8664e-05\n",
      "Epoch 71/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 4.6068e-05 - val_loss: 3.1109e-04\n",
      "Epoch 72/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.9183e-04 - val_loss: 4.3622e-05\n",
      "Epoch 73/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 4.5606e-05 - val_loss: 2.0304e-05\n",
      "Epoch 74/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 4.0473e-05 - val_loss: 1.7446e-05\n",
      "Epoch 75/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.8289e-05 - val_loss: 2.4876e-05\n",
      "Epoch 76/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.6453e-05 - val_loss: 1.9437e-05\n",
      "Epoch 77/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.4928e-05 - val_loss: 2.1067e-05\n",
      "Epoch 78/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 3.6125e-05 - val_loss: 2.6254e-05\n",
      "Epoch 79/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.4552e-05 - val_loss: 1.6687e-05\n",
      "Epoch 80/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.4800e-05 - val_loss: 2.2917e-05\n",
      "Epoch 81/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.5501e-05 - val_loss: 2.3071e-05\n",
      "Epoch 82/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.0715e-05 - val_loss: 1.8084e-05\n",
      "Epoch 83/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.5506e-05 - val_loss: 2.1529e-05\n",
      "Epoch 84/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.2714e-05 - val_loss: 1.7928e-05\n",
      "Epoch 85/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.0849e-05 - val_loss: 1.6582e-05\n",
      "Epoch 86/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.0314e-05 - val_loss: 3.5290e-05\n",
      "Epoch 87/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.2440e-05 - val_loss: 1.5352e-05\n",
      "Epoch 88/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.8497e-05 - val_loss: 1.5939e-05\n",
      "Epoch 89/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.8962e-05 - val_loss: 2.0870e-05\n",
      "Epoch 90/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 4.1176e-05 - val_loss: 1.6294e-05\n",
      "Epoch 91/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 4.8200e-05 - val_loss: 2.4610e-05\n",
      "Epoch 92/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.5651e-05 - val_loss: 2.4602e-05\n",
      "Epoch 93/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.5955e-05 - val_loss: 1.6796e-05\n",
      "Epoch 94/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.7392e-05 - val_loss: 2.3342e-05\n",
      "Epoch 95/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.3977e-05 - val_loss: 1.6086e-05\n",
      "Epoch 96/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.2597e-05 - val_loss: 1.8224e-05\n",
      "Epoch 97/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.4021e-05 - val_loss: 1.6565e-05\n",
      "Epoch 98/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.0699e-05 - val_loss: 1.7361e-05\n",
      "Epoch 99/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.7536e-05 - val_loss: 3.2201e-05\n",
      "Epoch 100/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 4.0848e-05 - val_loss: 2.0234e-05\n",
      "Epoch 101/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.4636e-05 - val_loss: 1.7014e-05\n",
      "Epoch 102/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 3.3520e-05 - val_loss: 2.3282e-05\n",
      "Epoch 103/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 3.6422e-05 - val_loss: 5.2111e-05\n",
      "Epoch 104/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 4.4974e-05 - val_loss: 1.8962e-05\n",
      "Epoch 105/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.8426e-05 - val_loss: 1.7944e-05\n",
      "Epoch 106/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.2158e-05 - val_loss: 3.0397e-05\n",
      "Epoch 107/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.5550e-05 - val_loss: 3.1030e-05\n",
      "Epoch 108/2000\n",
      "18465/18465 [==============================] - ETA: 0s - loss: 3.1982e-0 - 1s 71us/step - loss: 3.3954e-05 - val_loss: 2.8185e-05\n",
      "Epoch 109/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 4.0345e-05 - val_loss: 3.0196e-05\n",
      "Epoch 110/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.7689e-05 - val_loss: 4.0307e-05\n",
      "Epoch 111/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.4107e-05 - val_loss: 2.3227e-05\n",
      "Epoch 112/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.5419e-05 - val_loss: 1.9862e-05\n",
      "Epoch 113/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.2875e-05 - val_loss: 2.0585e-05\n",
      "Epoch 114/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.0015e-05 - val_loss: 1.3281e-04\n",
      "Epoch 115/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 9.7526e-05 - val_loss: 1.6492e-05\n",
      "Epoch 116/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.0046e-05 - val_loss: 2.1395e-05\n",
      "Epoch 117/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.0704e-05 - val_loss: 2.2903e-05\n",
      "Epoch 118/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.0501e-05 - val_loss: 2.1988e-05\n",
      "Epoch 119/2000\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 3.9483e-05 - val_loss: 3.4795e-05\n",
      "Epoch 120/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.1981e-05 - val_loss: 1.9088e-05\n",
      "Epoch 121/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.0018e-05 - val_loss: 1.0746e-04\n",
      "Epoch 122/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.2723e-04 - val_loss: 6.8240e-05\n",
      "Epoch 123/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 4.1202e-05 - val_loss: 1.8175e-05\n",
      "Epoch 124/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.0831e-05 - val_loss: 1.6558e-05\n",
      "Epoch 125/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.8600e-05 - val_loss: 2.4929e-05\n",
      "Epoch 126/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.9103e-05 - val_loss: 2.0042e-05\n",
      "Epoch 127/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 3.3875e-05 - val_loss: 1.6073e-05\n",
      "Epoch 128/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.0967e-05 - val_loss: 1.7278e-05\n",
      "Epoch 129/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.9787e-05 - val_loss: 1.9395e-05\n",
      "Epoch 130/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.0517e-05 - val_loss: 3.6244e-05\n",
      "Epoch 131/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.0245e-05 - val_loss: 1.7399e-05\n",
      "Epoch 132/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.9580e-05 - val_loss: 2.6945e-05\n",
      "Epoch 133/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.3903e-05 - val_loss: 3.8434e-05\n",
      "Epoch 134/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.2378e-05 - val_loss: 1.5953e-05\n",
      "Epoch 135/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.7954e-05 - val_loss: 2.1983e-05\n",
      "Epoch 136/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.3466e-05 - val_loss: 2.1628e-05\n",
      "Epoch 137/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.1324e-05 - val_loss: 2.4486e-05\n",
      "Epoch 138/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.3757e-05 - val_loss: 1.8334e-05\n",
      "Epoch 139/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.7998e-05 - val_loss: 2.3272e-05\n",
      "Epoch 140/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.9974e-05 - val_loss: 1.7058e-05\n",
      "Epoch 141/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18465/18465 [==============================] - 1s 70us/step - loss: 2.9625e-05 - val_loss: 1.6435e-05\n",
      "Epoch 142/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.6255e-05 - val_loss: 2.1109e-05\n",
      "Epoch 143/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.9248e-05 - val_loss: 1.9141e-05\n",
      "Epoch 144/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.1315e-05 - val_loss: 4.8921e-05\n",
      "Epoch 145/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.7786e-05 - val_loss: 2.2848e-05\n",
      "Epoch 146/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.0388e-05 - val_loss: 3.1628e-05\n",
      "Epoch 147/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.9153e-05 - val_loss: 3.4131e-05\n",
      "Epoch 148/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.8616e-05 - val_loss: 2.4914e-05\n",
      "Epoch 149/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.1363e-05 - val_loss: 1.8590e-05\n",
      "Epoch 150/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.9533e-05 - val_loss: 2.0633e-05\n",
      "Epoch 151/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 3.5999e-05 - val_loss: 3.0150e-05\n",
      "Epoch 152/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.9343e-05 - val_loss: 3.5772e-05\n",
      "Epoch 153/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.4480e-05 - val_loss: 3.0488e-05\n",
      "Epoch 154/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.6886e-05 - val_loss: 2.5877e-05\n",
      "Epoch 155/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.0056e-05 - val_loss: 2.2453e-05\n",
      "Epoch 156/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 5.6429e-05 - val_loss: 1.1730e-04\n",
      "Epoch 157/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.5171e-04 - val_loss: 2.4681e-05\n",
      "Epoch 158/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 6.6613e-05 - val_loss: 3.4208e-05\n",
      "Epoch 159/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 4.2923e-05 - val_loss: 3.0867e-05\n",
      "Epoch 160/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.7418e-05 - val_loss: 1.7775e-05\n",
      "Epoch 161/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.9519e-05 - val_loss: 9.9006e-05\n",
      "Epoch 162/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 5.8267e-05 - val_loss: 2.6392e-05\n",
      "Epoch 163/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 3.2852e-05 - val_loss: 3.1386e-05\n",
      "Epoch 164/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.4825e-05 - val_loss: 2.0184e-05\n",
      "Epoch 165/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.5105e-05 - val_loss: 2.0608e-05\n",
      "Epoch 166/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.2704e-05 - val_loss: 2.0005e-05\n",
      "Epoch 167/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.7577e-05 - val_loss: 3.3532e-05\n",
      "Epoch 168/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.4773e-05 - val_loss: 2.8331e-05\n",
      "Epoch 169/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.3028e-05 - val_loss: 3.8499e-05\n",
      "Epoch 170/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 5.0951e-05 - val_loss: 3.7509e-05\n",
      "Epoch 171/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.5218e-05 - val_loss: 2.2276e-05\n",
      "Epoch 172/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.8476e-05 - val_loss: 1.7069e-05\n",
      "Epoch 173/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.2501e-05 - val_loss: 2.5587e-05\n",
      "Epoch 174/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.0703e-05 - val_loss: 2.2772e-05\n",
      "Epoch 175/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 2.9558e-05 - val_loss: 3.4679e-05\n",
      "Epoch 176/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.5083e-05 - val_loss: 2.5929e-05\n",
      "Epoch 177/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.4265e-05 - val_loss: 2.4491e-05\n",
      "Epoch 178/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.2475e-05 - val_loss: 2.7458e-05\n",
      "Epoch 179/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.3475e-05 - val_loss: 1.1744e-04\n",
      "Epoch 180/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 8.5753e-05 - val_loss: 2.2611e-05\n",
      "Epoch 181/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.1665e-05 - val_loss: 2.0293e-05\n",
      "Epoch 182/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.9465e-05 - val_loss: 2.2363e-05\n",
      "Epoch 183/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.1636e-05 - val_loss: 2.3666e-05\n",
      "Epoch 184/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.9556e-05 - val_loss: 2.3360e-05\n",
      "Epoch 185/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.8739e-05 - val_loss: 5.8850e-05\n",
      "Epoch 186/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.5172e-05 - val_loss: 2.1044e-05\n",
      "Epoch 187/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 2.7148e-05 - val_loss: 4.7174e-05\n",
      "Epoch 188/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.5089e-05 - val_loss: 2.8699e-05\n",
      "Epoch 189/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.7618e-05 - val_loss: 1.8947e-05\n",
      "Epoch 190/2000\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 2.8630e-05 - val_loss: 2.6385e-05\n",
      "Epoch 191/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.1592e-05 - val_loss: 2.2131e-05\n",
      "Epoch 192/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.8790e-05 - val_loss: 2.2278e-05\n",
      "Epoch 193/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.4673e-05 - val_loss: 2.9788e-05\n",
      "Epoch 194/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.3025e-05 - val_loss: 2.0845e-05\n",
      "Epoch 195/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.1929e-05 - val_loss: 2.5545e-05\n",
      "Epoch 196/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.9550e-05 - val_loss: 2.4333e-05\n",
      "Epoch 197/2000\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 2.9095e-05 - val_loss: 3.1493e-05\n",
      "Epoch 198/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.9001e-05 - val_loss: 2.3634e-05\n",
      "Epoch 199/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 3.0415e-05 - val_loss: 3.2021e-05\n",
      "Epoch 200/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.1276e-05 - val_loss: 2.2150e-05\n",
      "Epoch 201/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.7136e-05 - val_loss: 5.6991e-05\n",
      "Epoch 202/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.4294e-05 - val_loss: 2.3466e-05\n",
      "Epoch 203/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.9818e-05 - val_loss: 2.2710e-05\n",
      "Epoch 204/2000\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 2.9929e-05 - val_loss: 5.2311e-05\n",
      "Epoch 205/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.7545e-05 - val_loss: 5.3069e-05\n",
      "Epoch 206/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 4.3507e-05 - val_loss: 2.6401e-05\n",
      "Epoch 207/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.5049e-05 - val_loss: 3.1972e-05\n",
      "Epoch 208/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.0737e-05 - val_loss: 2.7685e-05\n",
      "Epoch 209/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.0460e-05 - val_loss: 4.6420e-05\n",
      "Epoch 210/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.8383e-05 - val_loss: 2.3794e-05\n",
      "Epoch 211/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 2.8866e-05 - val_loss: 2.5427e-05\n",
      "Epoch 212/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.9224e-05 - val_loss: 3.1854e-05\n",
      "Epoch 213/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.2113e-05 - val_loss: 3.5096e-05\n",
      "Epoch 214/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.9890e-05 - val_loss: 2.8862e-05\n",
      "Epoch 215/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.7650e-05 - val_loss: 3.0516e-05\n",
      "Epoch 216/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.2249e-05 - val_loss: 2.8461e-05\n",
      "Epoch 217/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.1272e-05 - val_loss: 2.8688e-05\n",
      "Epoch 218/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.3214e-05 - val_loss: 3.8650e-05\n",
      "Epoch 219/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.6756e-05 - val_loss: 2.5946e-05\n",
      "Epoch 220/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.9224e-05 - val_loss: 2.2328e-05\n",
      "Epoch 221/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.8308e-05 - val_loss: 3.5590e-05\n",
      "Epoch 222/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.7579e-05 - val_loss: 3.3244e-05\n",
      "Epoch 223/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 2.9487e-05 - val_loss: 3.2186e-05\n",
      "Epoch 224/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.3021e-05 - val_loss: 2.5605e-05\n",
      "Epoch 225/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.9605e-05 - val_loss: 7.1605e-05\n",
      "Epoch 226/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 4.9670e-05 - val_loss: 6.3876e-05\n",
      "Epoch 227/2000\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 3.8015e-05 - val_loss: 2.9013e-05\n",
      "Epoch 228/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.7909e-05 - val_loss: 2.4921e-05\n",
      "Epoch 229/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.1208e-05 - val_loss: 3.3531e-05\n",
      "Epoch 230/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.7589e-05 - val_loss: 3.3445e-05\n",
      "Epoch 231/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.5829e-05 - val_loss: 3.8008e-05\n",
      "Epoch 232/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.8876e-05 - val_loss: 3.2763e-05\n",
      "Epoch 233/2000\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 3.0524e-05 - val_loss: 3.3005e-05\n",
      "Epoch 234/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.8165e-05 - val_loss: 3.3949e-05\n",
      "Epoch 235/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 3.0095e-05 - val_loss: 3.0080e-05\n",
      "Epoch 236/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 3.0267e-05 - val_loss: 3.7252e-05\n",
      "Epoch 237/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.7160e-05 - val_loss: 2.7784e-05\n",
      "Epoch 238/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.8430e-05 - val_loss: 3.9885e-05\n",
      "Epoch 239/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.3555e-05 - val_loss: 3.9510e-05\n",
      "Epoch 240/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 4.5919e-05 - val_loss: 3.5813e-05\n",
      "Epoch 241/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.9055e-05 - val_loss: 5.1462e-05\n",
      "Epoch 242/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.9692e-05 - val_loss: 3.5023e-05\n",
      "Epoch 243/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.7161e-05 - val_loss: 3.6696e-05\n",
      "Epoch 244/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.7346e-05 - val_loss: 3.8502e-05\n",
      "Epoch 245/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 4.8118e-05 - val_loss: 4.7274e-05\n",
      "Epoch 246/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 4.4037e-05 - val_loss: 3.1963e-05\n",
      "Epoch 247/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.6751e-05 - val_loss: 4.6264e-05\n",
      "Epoch 248/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.9848e-05 - val_loss: 3.4405e-05\n",
      "Epoch 249/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.8713e-05 - val_loss: 3.4550e-05\n",
      "Epoch 250/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.0561e-05 - val_loss: 2.8648e-05\n",
      "Epoch 251/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.1580e-05 - val_loss: 7.7898e-05\n",
      "Epoch 252/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 8.2028e-05 - val_loss: 9.5393e-05\n",
      "Epoch 253/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 5.6965e-05 - val_loss: 3.1920e-05\n",
      "Epoch 254/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.9387e-05 - val_loss: 3.2774e-05\n",
      "Epoch 255/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.6347e-05 - val_loss: 3.3412e-05\n",
      "Epoch 256/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.6494e-05 - val_loss: 3.5737e-05\n",
      "Epoch 257/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.4622e-05 - val_loss: 3.4799e-05\n",
      "Epoch 258/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.5466e-05 - val_loss: 3.6710e-05\n",
      "Epoch 259/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.7277e-05 - val_loss: 3.9576e-05\n",
      "Epoch 260/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 2.5604e-05 - val_loss: 3.7839e-05\n",
      "Epoch 261/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.7110e-05 - val_loss: 3.6261e-05\n",
      "Epoch 262/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.5397e-05 - val_loss: 4.3831e-05\n",
      "Epoch 263/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.7330e-05 - val_loss: 3.4826e-05\n",
      "Epoch 264/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.5151e-05 - val_loss: 3.2241e-05\n",
      "Epoch 265/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.9220e-05 - val_loss: 3.5755e-05\n",
      "Epoch 266/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.0769e-05 - val_loss: 4.6026e-05\n",
      "Epoch 267/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.2058e-05 - val_loss: 6.6042e-05\n",
      "Epoch 268/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.0768e-05 - val_loss: 6.2861e-05\n",
      "Epoch 269/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.1601e-05 - val_loss: 3.5214e-05\n",
      "Epoch 270/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.9791e-05 - val_loss: 4.6622e-05\n",
      "Epoch 271/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 3.5158e-05 - val_loss: 4.3451e-05\n",
      "Epoch 272/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.9920e-05 - val_loss: 3.9092e-05\n",
      "Epoch 273/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.6965e-05 - val_loss: 3.7776e-05\n",
      "Epoch 274/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.7510e-05 - val_loss: 3.8242e-05\n",
      "Epoch 275/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.0225e-05 - val_loss: 6.3804e-05\n",
      "Epoch 276/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.6444e-05 - val_loss: 4.1580e-05\n",
      "Epoch 277/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.6959e-05 - val_loss: 5.6084e-05\n",
      "Epoch 278/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.7685e-05 - val_loss: 4.1640e-05\n",
      "Epoch 279/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.5098e-05 - val_loss: 5.3475e-05\n",
      "Epoch 280/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.7299e-05 - val_loss: 5.2558e-05\n",
      "Epoch 281/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.7827e-05 - val_loss: 3.4081e-05\n",
      "Epoch 282/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.1505e-05 - val_loss: 6.1061e-05\n",
      "Epoch 283/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 3.2551e-05 - val_loss: 4.6534e-05\n",
      "Epoch 284/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 2.7644e-05 - val_loss: 5.5332e-05\n",
      "Epoch 285/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.6866e-05 - val_loss: 6.7460e-05\n",
      "Epoch 286/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.9472e-05 - val_loss: 4.0139e-05\n",
      "Epoch 287/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.8574e-05 - val_loss: 3.9439e-05\n",
      "Epoch 288/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.5387e-05 - val_loss: 4.9307e-05\n",
      "Epoch 289/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.9989e-05 - val_loss: 4.6510e-05\n",
      "Epoch 290/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.7947e-05 - val_loss: 3.2048e-05\n",
      "Epoch 291/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.9780e-05 - val_loss: 4.1407e-05\n",
      "Epoch 292/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.6585e-05 - val_loss: 6.4794e-05\n",
      "Epoch 293/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.3475e-05 - val_loss: 5.2054e-05\n",
      "Epoch 294/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.8919e-05 - val_loss: 4.2946e-05\n",
      "Epoch 295/2000\n",
      "18465/18465 [==============================] - ETA: 0s - loss: 2.5511e-0 - 1s 73us/step - loss: 2.6180e-05 - val_loss: 4.5786e-05\n",
      "Epoch 296/2000\n",
      "18465/18465 [==============================] - 1s 76us/step - loss: 2.6412e-05 - val_loss: 4.4321e-05\n",
      "Epoch 297/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.6297e-05 - val_loss: 4.2645e-05\n",
      "Epoch 298/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3722e-05 - val_loss: 3.6758e-05\n",
      "Epoch 299/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.8327e-05 - val_loss: 4.6433e-05\n",
      "Epoch 300/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.8972e-05 - val_loss: 4.0651e-05\n",
      "Epoch 301/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.2868e-05 - val_loss: 4.7851e-05\n",
      "Epoch 302/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 8.4573e-05 - val_loss: 4.9655e-05\n",
      "Epoch 303/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 8.6024e-05 - val_loss: 5.1446e-05\n",
      "Epoch 304/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.4337e-05 - val_loss: 3.5932e-05\n",
      "Epoch 305/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.6955e-05 - val_loss: 3.8237e-05\n",
      "Epoch 306/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4931e-05 - val_loss: 3.6818e-05\n",
      "Epoch 307/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 3.0543e-05 - val_loss: 2.6528e-05\n",
      "Epoch 308/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 3.0473e-05 - val_loss: 1.0074e-04\n",
      "Epoch 309/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 9.3474e-05 - val_loss: 5.8790e-05\n",
      "Epoch 310/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.8191e-05 - val_loss: 4.3487e-05\n",
      "Epoch 311/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.6685e-05 - val_loss: 7.8187e-05\n",
      "Epoch 312/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.9905e-05 - val_loss: 5.9473e-05\n",
      "Epoch 313/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.1991e-05 - val_loss: 5.6684e-05\n",
      "Epoch 314/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.8312e-05 - val_loss: 5.4937e-05\n",
      "Epoch 315/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.8168e-05 - val_loss: 3.8575e-05\n",
      "Epoch 316/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.5147e-05 - val_loss: 4.8731e-05\n",
      "Epoch 317/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4462e-05 - val_loss: 5.5721e-05\n",
      "Epoch 318/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.5952e-05 - val_loss: 5.5466e-05\n",
      "Epoch 319/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.9880e-05 - val_loss: 7.6179e-05\n",
      "Epoch 320/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 2.8066e-05 - val_loss: 6.5032e-05\n",
      "Epoch 321/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.5543e-05 - val_loss: 5.2262e-05\n",
      "Epoch 322/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4525e-05 - val_loss: 5.5398e-05\n",
      "Epoch 323/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.4654e-05 - val_loss: 5.5246e-05\n",
      "Epoch 324/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3759e-05 - val_loss: 6.0911e-05\n",
      "Epoch 325/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.8109e-05 - val_loss: 4.2335e-05\n",
      "Epoch 326/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.5673e-05 - val_loss: 5.6673e-05\n",
      "Epoch 327/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.5782e-05 - val_loss: 4.6429e-05\n",
      "Epoch 328/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.7309e-05 - val_loss: 6.4129e-05\n",
      "Epoch 329/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.7838e-05 - val_loss: 4.0035e-05\n",
      "Epoch 330/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.8637e-05 - val_loss: 5.4968e-05\n",
      "Epoch 331/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.4686e-05 - val_loss: 5.1619e-05\n",
      "Epoch 332/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 2.5975e-05 - val_loss: 4.7285e-05\n",
      "Epoch 333/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.6136e-05 - val_loss: 6.0856e-05\n",
      "Epoch 334/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4907e-05 - val_loss: 5.7052e-05\n",
      "Epoch 335/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.7124e-05 - val_loss: 5.5884e-05\n",
      "Epoch 336/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.5842e-05 - val_loss: 6.0366e-05\n",
      "Epoch 337/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.7373e-05 - val_loss: 4.4480e-05\n",
      "Epoch 338/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.6381e-05 - val_loss: 5.8742e-05\n",
      "Epoch 339/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.5943e-05 - val_loss: 7.3765e-05\n",
      "Epoch 340/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.2195e-05 - val_loss: 7.7584e-05\n",
      "Epoch 341/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.8074e-05 - val_loss: 5.4816e-05\n",
      "Epoch 342/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.4375e-05 - val_loss: 5.8706e-05\n",
      "Epoch 343/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 2.5209e-05 - val_loss: 7.6845e-05\n",
      "Epoch 344/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.5734e-05 - val_loss: 7.0372e-05\n",
      "Epoch 345/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.7961e-05 - val_loss: 4.7534e-05\n",
      "Epoch 346/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.6879e-05 - val_loss: 7.4587e-05\n",
      "Epoch 347/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 2.7662e-05 - val_loss: 5.7790e-05\n",
      "Epoch 348/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4940e-05 - val_loss: 4.5464e-05\n",
      "Epoch 349/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.5011e-05 - val_loss: 4.9121e-05\n",
      "Epoch 350/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.6190e-05 - val_loss: 5.6342e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 351/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.5737e-05 - val_loss: 4.4189e-05\n",
      "Epoch 352/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.6988e-05 - val_loss: 6.2751e-05\n",
      "Epoch 353/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.9814e-05 - val_loss: 6.0914e-05\n",
      "Epoch 354/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4722e-05 - val_loss: 5.1313e-05\n",
      "Epoch 355/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 2.9416e-05 - val_loss: 4.4629e-05\n",
      "Epoch 356/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.7475e-05 - val_loss: 4.6546e-05\n",
      "Epoch 357/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.0341e-05 - val_loss: 6.4045e-05\n",
      "Epoch 358/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.9679e-05 - val_loss: 5.7683e-05\n",
      "Epoch 359/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.5291e-05 - val_loss: 4.8418e-05\n",
      "Epoch 360/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4556e-05 - val_loss: 5.1040e-05\n",
      "Epoch 361/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.8034e-05 - val_loss: 4.8225e-05\n",
      "Epoch 362/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.7699e-05 - val_loss: 4.3114e-05\n",
      "Epoch 363/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 3.0137e-05 - val_loss: 5.1270e-05\n",
      "Epoch 364/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4660e-05 - val_loss: 4.3246e-05\n",
      "Epoch 365/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.5164e-05 - val_loss: 5.3510e-05\n",
      "Epoch 366/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.6744e-05 - val_loss: 4.7832e-05\n",
      "Epoch 367/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 2.2368e-05 - val_loss: 4.1226e-05\n",
      "Epoch 368/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.5261e-05 - val_loss: 5.0109e-05\n",
      "Epoch 369/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4375e-05 - val_loss: 5.6446e-05\n",
      "Epoch 370/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.5824e-05 - val_loss: 4.9981e-05\n",
      "Epoch 371/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4785e-05 - val_loss: 8.0436e-05\n",
      "Epoch 372/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.8220e-05 - val_loss: 6.1167e-05\n",
      "Epoch 373/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.5465e-05 - val_loss: 4.3757e-05\n",
      "Epoch 374/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.0317e-05 - val_loss: 6.6854e-05\n",
      "Epoch 375/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4193e-05 - val_loss: 5.6264e-05\n",
      "Epoch 376/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.8516e-05 - val_loss: 5.3052e-05\n",
      "Epoch 377/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.7358e-05 - val_loss: 7.3447e-05\n",
      "Epoch 378/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.8175e-05 - val_loss: 5.1674e-05\n",
      "Epoch 379/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 2.5056e-05 - val_loss: 5.5862e-05\n",
      "Epoch 380/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.6276e-05 - val_loss: 7.8295e-05\n",
      "Epoch 381/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.1838e-05 - val_loss: 3.7340e-05\n",
      "Epoch 382/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.6653e-05 - val_loss: 4.3205e-05\n",
      "Epoch 383/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3815e-05 - val_loss: 4.9615e-05\n",
      "Epoch 384/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.4744e-05 - val_loss: 5.0599e-05\n",
      "Epoch 385/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.0377e-05 - val_loss: 4.5135e-05\n",
      "Epoch 386/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4940e-05 - val_loss: 5.0082e-05\n",
      "Epoch 387/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.8922e-05 - val_loss: 8.6894e-05\n",
      "Epoch 388/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 4.2766e-05 - val_loss: 1.0046e-04\n",
      "Epoch 389/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 5.4432e-05 - val_loss: 4.4150e-05\n",
      "Epoch 390/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.3338e-05 - val_loss: 3.2941e-05\n",
      "Epoch 391/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 2.5133e-05 - val_loss: 3.2795e-05\n",
      "Epoch 392/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4514e-05 - val_loss: 4.7290e-05\n",
      "Epoch 393/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.6338e-05 - val_loss: 4.7583e-05\n",
      "Epoch 394/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.7745e-05 - val_loss: 5.3627e-05\n",
      "Epoch 395/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.6287e-05 - val_loss: 4.3980e-05\n",
      "Epoch 396/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.7233e-05 - val_loss: 4.4402e-05\n",
      "Epoch 397/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 5.2149e-05 - val_loss: 6.9111e-05\n",
      "Epoch 398/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.9474e-05 - val_loss: 3.7697e-05\n",
      "Epoch 399/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4228e-05 - val_loss: 4.8917e-05\n",
      "Epoch 400/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.9469e-05 - val_loss: 6.2800e-05\n",
      "Epoch 401/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.9361e-05 - val_loss: 4.7836e-05\n",
      "Epoch 402/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4466e-05 - val_loss: 5.9338e-05\n",
      "Epoch 403/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 2.5654e-05 - val_loss: 4.2918e-05\n",
      "Epoch 404/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4858e-05 - val_loss: 4.8243e-05\n",
      "Epoch 405/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.6370e-05 - val_loss: 4.4292e-05\n",
      "Epoch 406/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3455e-05 - val_loss: 7.8549e-05\n",
      "Epoch 407/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.0863e-05 - val_loss: 3.9357e-05\n",
      "Epoch 408/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.5967e-05 - val_loss: 4.8678e-05\n",
      "Epoch 409/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1744e-05 - val_loss: 4.2460e-05\n",
      "Epoch 410/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.7380e-05 - val_loss: 4.3859e-05\n",
      "Epoch 411/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.5378e-05 - val_loss: 4.4718e-05\n",
      "Epoch 412/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.8739e-05 - val_loss: 5.2070e-05\n",
      "Epoch 413/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4013e-05 - val_loss: 4.6262e-05\n",
      "Epoch 414/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.4808e-05 - val_loss: 4.6892e-05\n",
      "Epoch 415/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 2.6085e-05 - val_loss: 4.8222e-05\n",
      "Epoch 416/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.6535e-05 - val_loss: 6.2174e-05\n",
      "Epoch 417/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.3469e-05 - val_loss: 5.1062e-05\n",
      "Epoch 418/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.5818e-05 - val_loss: 4.6382e-05\n",
      "Epoch 419/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.5967e-05 - val_loss: 4.9050e-05\n",
      "Epoch 420/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.7596e-05 - val_loss: 4.6612e-05\n",
      "Epoch 421/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3617e-05 - val_loss: 4.8090e-05\n",
      "Epoch 422/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3723e-05 - val_loss: 4.6618e-05\n",
      "Epoch 423/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.7489e-05 - val_loss: 5.1066e-05\n",
      "Epoch 424/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4116e-05 - val_loss: 6.4987e-05\n",
      "Epoch 425/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.5123e-05 - val_loss: 5.1734e-05\n",
      "Epoch 426/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4483e-05 - val_loss: 4.7707e-05\n",
      "Epoch 427/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 2.2547e-05 - val_loss: 4.5280e-05\n",
      "Epoch 428/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4846e-05 - val_loss: 4.6000e-05\n",
      "Epoch 429/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.6072e-05 - val_loss: 3.5118e-05\n",
      "Epoch 430/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2826e-05 - val_loss: 4.8301e-05\n",
      "Epoch 431/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4095e-05 - val_loss: 4.1386e-05\n",
      "Epoch 432/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.0315e-05 - val_loss: 5.5122e-05\n",
      "Epoch 433/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.5110e-05 - val_loss: 5.8262e-05\n",
      "Epoch 434/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.5395e-05 - val_loss: 3.0381e-05\n",
      "Epoch 435/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3902e-05 - val_loss: 7.3096e-05\n",
      "Epoch 436/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.7610e-05 - val_loss: 4.5952e-05\n",
      "Epoch 437/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4797e-05 - val_loss: 4.5519e-05\n",
      "Epoch 438/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3141e-05 - val_loss: 4.2892e-05\n",
      "Epoch 439/2000\n",
      "18465/18465 [==============================] - 1s 76us/step - loss: 3.3693e-05 - val_loss: 5.0458e-05\n",
      "Epoch 440/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.5365e-05 - val_loss: 5.6504e-05\n",
      "Epoch 441/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.6002e-05 - val_loss: 5.1705e-05\n",
      "Epoch 442/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3448e-05 - val_loss: 5.6201e-05\n",
      "Epoch 443/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4135e-05 - val_loss: 5.0039e-05\n",
      "Epoch 444/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3485e-05 - val_loss: 5.1972e-05\n",
      "Epoch 445/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4289e-05 - val_loss: 5.0038e-05\n",
      "Epoch 446/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.6323e-05 - val_loss: 6.3435e-05\n",
      "Epoch 447/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.4028e-05 - val_loss: 4.4531e-05\n",
      "Epoch 448/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.5703e-05 - val_loss: 3.9172e-05\n",
      "Epoch 449/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4900e-05 - val_loss: 5.3363e-05\n",
      "Epoch 450/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.9412e-05 - val_loss: 5.1636e-05\n",
      "Epoch 451/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 2.8216e-05 - val_loss: 5.0986e-05\n",
      "Epoch 452/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.7313e-05 - val_loss: 4.6271e-05\n",
      "Epoch 453/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.3201e-05 - val_loss: 4.7678e-05\n",
      "Epoch 454/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.3990e-05 - val_loss: 1.3105e-04\n",
      "Epoch 455/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 4.0058e-05 - val_loss: 4.1966e-05\n",
      "Epoch 456/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.5375e-05 - val_loss: 4.7503e-05\n",
      "Epoch 457/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.2830e-05 - val_loss: 4.8642e-05\n",
      "Epoch 458/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3641e-05 - val_loss: 4.6022e-05\n",
      "Epoch 459/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.5473e-05 - val_loss: 4.2300e-05\n",
      "Epoch 460/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.5401e-05 - val_loss: 4.8573e-05\n",
      "Epoch 461/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.6494e-05 - val_loss: 4.3855e-05\n",
      "Epoch 462/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.5391e-05 - val_loss: 9.6801e-05\n",
      "Epoch 463/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 1.1433e-04 - val_loss: 3.7049e-05\n",
      "Epoch 464/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.0620e-05 - val_loss: 3.9227e-05\n",
      "Epoch 465/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.5257e-05 - val_loss: 4.3166e-05\n",
      "Epoch 466/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.9685e-05 - val_loss: 8.0523e-05\n",
      "Epoch 467/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 5.8105e-05 - val_loss: 1.1234e-05\n",
      "Epoch 468/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.9248e-05 - val_loss: 1.1795e-05\n",
      "Epoch 469/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.6953e-05 - val_loss: 1.2790e-05\n",
      "Epoch 470/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.6965e-05 - val_loss: 1.3942e-05\n",
      "Epoch 471/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.7921e-05 - val_loss: 1.2731e-05\n",
      "Epoch 472/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.8081e-05 - val_loss: 1.5943e-05\n",
      "Epoch 473/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.6968e-05 - val_loss: 1.3336e-05\n",
      "Epoch 474/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.7209e-05 - val_loss: 1.5539e-05\n",
      "Epoch 475/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 2.6854e-05 - val_loss: 2.0296e-05\n",
      "Epoch 476/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.0743e-05 - val_loss: 1.5484e-05\n",
      "Epoch 477/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.6459e-05 - val_loss: 1.7230e-05\n",
      "Epoch 478/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.7581e-05 - val_loss: 2.2362e-05\n",
      "Epoch 479/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.0637e-05 - val_loss: 1.2950e-05\n",
      "Epoch 480/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.6152e-05 - val_loss: 1.3545e-05\n",
      "Epoch 481/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.8198e-05 - val_loss: 1.3954e-05\n",
      "Epoch 482/2000\n",
      "18465/18465 [==============================] - ETA: 0s - loss: 2.5410e-0 - 1s 72us/step - loss: 2.5646e-05 - val_loss: 1.5363e-05\n",
      "Epoch 483/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.7517e-05 - val_loss: 4.5507e-05\n",
      "Epoch 484/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.0015e-05 - val_loss: 3.4364e-05\n",
      "Epoch 485/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.1714e-05 - val_loss: 1.8473e-05\n",
      "Epoch 486/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.6530e-05 - val_loss: 2.4311e-05\n",
      "Epoch 487/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 2.6587e-05 - val_loss: 3.4295e-05\n",
      "Epoch 488/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4542e-05 - val_loss: 2.5916e-05\n",
      "Epoch 489/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.6317e-05 - val_loss: 2.5747e-05\n",
      "Epoch 490/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.4192e-05 - val_loss: 3.6643e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 491/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3549e-05 - val_loss: 3.1105e-05\n",
      "Epoch 492/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.7122e-05 - val_loss: 3.1039e-05\n",
      "Epoch 493/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4622e-05 - val_loss: 3.6298e-05\n",
      "Epoch 494/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.6572e-05 - val_loss: 4.0073e-05\n",
      "Epoch 495/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.8229e-05 - val_loss: 4.8577e-05\n",
      "Epoch 496/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.7692e-05 - val_loss: 3.7251e-05\n",
      "Epoch 497/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.0709e-05 - val_loss: 3.6683e-05\n",
      "Epoch 498/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4714e-05 - val_loss: 3.4316e-05\n",
      "Epoch 499/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 2.5326e-05 - val_loss: 3.7400e-05\n",
      "Epoch 500/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4126e-05 - val_loss: 4.2639e-05\n",
      "Epoch 501/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.6788e-05 - val_loss: 5.0154e-05\n",
      "Epoch 502/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.5969e-05 - val_loss: 6.5217e-05\n",
      "Epoch 503/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.4726e-05 - val_loss: 4.5727e-05\n",
      "Epoch 504/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.8061e-05 - val_loss: 3.8978e-05\n",
      "Epoch 505/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.4322e-05 - val_loss: 4.1573e-05\n",
      "Epoch 506/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.5816e-05 - val_loss: 5.9582e-05\n",
      "Epoch 507/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.8732e-05 - val_loss: 3.9491e-05\n",
      "Epoch 508/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.6082e-05 - val_loss: 4.7151e-05\n",
      "Epoch 509/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.3981e-05 - val_loss: 4.9168e-05\n",
      "Epoch 510/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.6106e-05 - val_loss: 4.5087e-05\n",
      "Epoch 511/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 2.6124e-05 - val_loss: 4.9724e-05\n",
      "Epoch 512/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.5798e-05 - val_loss: 4.4572e-05\n",
      "Epoch 513/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.3184e-05 - val_loss: 4.7818e-05\n",
      "Epoch 514/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.3222e-05 - val_loss: 3.8363e-05\n",
      "Epoch 515/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.5071e-05 - val_loss: 5.6561e-05\n",
      "Epoch 516/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.5249e-05 - val_loss: 4.7011e-05\n",
      "Epoch 517/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4803e-05 - val_loss: 4.3383e-05\n",
      "Epoch 518/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.1202e-05 - val_loss: 4.5792e-05\n",
      "Epoch 519/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.5586e-05 - val_loss: 4.9120e-05\n",
      "Epoch 520/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.4722e-05 - val_loss: 3.9172e-05\n",
      "Epoch 521/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3153e-05 - val_loss: 4.1843e-05\n",
      "Epoch 522/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.5773e-05 - val_loss: 3.8683e-05\n",
      "Epoch 523/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 2.3564e-05 - val_loss: 5.5010e-05\n",
      "Epoch 524/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4907e-05 - val_loss: 4.0167e-05\n",
      "Epoch 525/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3123e-05 - val_loss: 4.2519e-05\n",
      "Epoch 526/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.7623e-05 - val_loss: 4.7446e-05\n",
      "Epoch 527/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3364e-05 - val_loss: 5.7303e-05\n",
      "Epoch 528/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.6697e-05 - val_loss: 4.4821e-05\n",
      "Epoch 529/2000\n",
      "18465/18465 [==============================] - 2s 96us/step - loss: 2.3180e-05 - val_loss: 4.2949e-05\n",
      "Epoch 530/2000\n",
      "18465/18465 [==============================] - 2s 82us/step - loss: 2.4547e-05 - val_loss: 4.8071e-05\n",
      "Epoch 531/2000\n",
      "18465/18465 [==============================] - 1s 81us/step - loss: 2.4086e-05 - val_loss: 4.3325e-05\n",
      "Epoch 532/2000\n",
      "18465/18465 [==============================] - 1s 81us/step - loss: 2.2897e-05 - val_loss: 4.3297e-05\n",
      "Epoch 533/2000\n",
      "18465/18465 [==============================] - 1s 81us/step - loss: 2.5282e-05 - val_loss: 4.2704e-05\n",
      "Epoch 534/2000\n",
      "18465/18465 [==============================] - 2s 84us/step - loss: 2.2779e-05 - val_loss: 1.9986e-05\n",
      "Epoch 535/2000\n",
      "18465/18465 [==============================] - 1s 81us/step - loss: 2.4376e-05 - val_loss: 2.2120e-05\n",
      "Epoch 536/2000\n",
      "18465/18465 [==============================] - 1s 81us/step - loss: 2.7155e-05 - val_loss: 5.3302e-05\n",
      "Epoch 537/2000\n",
      "18465/18465 [==============================] - 1s 81us/step - loss: 2.6457e-05 - val_loss: 3.7696e-05\n",
      "Epoch 538/2000\n",
      "18465/18465 [==============================] - 2s 81us/step - loss: 2.3678e-05 - val_loss: 4.0550e-05\n",
      "Epoch 539/2000\n",
      "18465/18465 [==============================] - 1s 81us/step - loss: 2.2931e-05 - val_loss: 4.1376e-05\n",
      "Epoch 540/2000\n",
      "18465/18465 [==============================] - 2s 81us/step - loss: 2.4658e-05 - val_loss: 4.3914e-05\n",
      "Epoch 541/2000\n",
      "18465/18465 [==============================] - 1s 80us/step - loss: 2.2764e-05 - val_loss: 4.3908e-05\n",
      "Epoch 542/2000\n",
      "18465/18465 [==============================] - 1s 80us/step - loss: 2.7773e-05 - val_loss: 3.0802e-05\n",
      "Epoch 543/2000\n",
      "18465/18465 [==============================] - 2s 82us/step - loss: 2.6485e-05 - val_loss: 4.0456e-05\n",
      "Epoch 544/2000\n",
      "18465/18465 [==============================] - 2s 81us/step - loss: 2.4809e-05 - val_loss: 4.3610e-05\n",
      "Epoch 545/2000\n",
      "18465/18465 [==============================] - 2s 84us/step - loss: 2.9343e-05 - val_loss: 3.0801e-05\n",
      "Epoch 546/2000\n",
      "18465/18465 [==============================] - 1s 78us/step - loss: 2.5322e-05 - val_loss: 4.0135e-05\n",
      "Epoch 547/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 2.4672e-05 - val_loss: 5.6817e-05\n",
      "Epoch 548/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4950e-05 - val_loss: 3.9125e-05\n",
      "Epoch 549/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.3295e-05 - val_loss: 6.0205e-05\n",
      "Epoch 550/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.5186e-05 - val_loss: 3.6287e-05\n",
      "Epoch 551/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2111e-05 - val_loss: 3.4568e-05\n",
      "Epoch 552/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3881e-05 - val_loss: 4.0569e-05\n",
      "Epoch 553/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4487e-05 - val_loss: 3.3582e-05\n",
      "Epoch 554/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.5124e-05 - val_loss: 4.1131e-05\n",
      "Epoch 555/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4237e-05 - val_loss: 4.6861e-05\n",
      "Epoch 556/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.4905e-05 - val_loss: 3.9415e-05\n",
      "Epoch 557/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.1619e-05 - val_loss: 4.1563e-05\n",
      "Epoch 558/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.3350e-05 - val_loss: 3.7997e-05\n",
      "Epoch 559/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.2783e-05 - val_loss: 4.7477e-05\n",
      "Epoch 560/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4463e-05 - val_loss: 3.8471e-05\n",
      "Epoch 561/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4598e-05 - val_loss: 4.5133e-05\n",
      "Epoch 562/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.5734e-05 - val_loss: 4.3654e-05\n",
      "Epoch 563/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.6999e-05 - val_loss: 8.3449e-05\n",
      "Epoch 564/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 4.4114e-05 - val_loss: 5.4752e-05\n",
      "Epoch 565/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.7104e-05 - val_loss: 5.5465e-05\n",
      "Epoch 566/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.7288e-05 - val_loss: 3.5692e-05\n",
      "Epoch 567/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.7128e-05 - val_loss: 6.2324e-05\n",
      "Epoch 568/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 2.9602e-05 - val_loss: 5.5174e-05\n",
      "Epoch 569/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 3.0296e-05 - val_loss: 5.1018e-05\n",
      "Epoch 570/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.1279e-05 - val_loss: 3.7886e-05\n",
      "Epoch 571/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2980e-05 - val_loss: 4.1608e-05\n",
      "Epoch 572/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.4570e-05 - val_loss: 4.6493e-05\n",
      "Epoch 573/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3506e-05 - val_loss: 3.9571e-05\n",
      "Epoch 574/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4776e-05 - val_loss: 4.1178e-05\n",
      "Epoch 575/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.4788e-05 - val_loss: 4.3901e-05\n",
      "Epoch 576/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4739e-05 - val_loss: 4.1048e-05\n",
      "Epoch 577/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.6035e-05 - val_loss: 5.5071e-05\n",
      "Epoch 578/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3561e-05 - val_loss: 5.3574e-05\n",
      "Epoch 579/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.6440e-05 - val_loss: 5.0530e-05\n",
      "Epoch 580/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 2.2740e-05 - val_loss: 4.6367e-05\n",
      "Epoch 581/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 3.5644e-05 - val_loss: 7.8607e-05\n",
      "Epoch 582/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.3102e-05 - val_loss: 5.9914e-05\n",
      "Epoch 583/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.5021e-05 - val_loss: 4.6760e-05\n",
      "Epoch 584/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.1265e-05 - val_loss: 4.2187e-05\n",
      "Epoch 585/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3593e-05 - val_loss: 3.9726e-05\n",
      "Epoch 586/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4174e-05 - val_loss: 4.5646e-05\n",
      "Epoch 587/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.6260e-05 - val_loss: 4.1373e-05\n",
      "Epoch 588/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.6307e-05 - val_loss: 4.8746e-05\n",
      "Epoch 589/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3218e-05 - val_loss: 5.1395e-05\n",
      "Epoch 590/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.3113e-05 - val_loss: 5.6808e-05\n",
      "Epoch 591/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.5093e-05 - val_loss: 6.6245e-05\n",
      "Epoch 592/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 2.4284e-05 - val_loss: 5.7711e-05\n",
      "Epoch 593/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 3.3983e-05 - val_loss: 7.6951e-05\n",
      "Epoch 594/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.5510e-05 - val_loss: 4.4892e-05\n",
      "Epoch 595/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3733e-05 - val_loss: 4.4041e-05\n",
      "Epoch 596/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.5621e-05 - val_loss: 3.6897e-05\n",
      "Epoch 597/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3512e-05 - val_loss: 3.5714e-05\n",
      "Epoch 598/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.5145e-05 - val_loss: 4.4663e-05\n",
      "Epoch 599/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3945e-05 - val_loss: 4.6362e-05\n",
      "Epoch 600/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.5298e-05 - val_loss: 4.3011e-05\n",
      "Epoch 601/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2985e-05 - val_loss: 3.9446e-05\n",
      "Epoch 602/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.3003e-05 - val_loss: 4.2515e-05\n",
      "Epoch 603/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.5370e-05 - val_loss: 8.7872e-05\n",
      "Epoch 604/2000\n",
      "18465/18465 [==============================] - 1s 76us/step - loss: 5.1418e-05 - val_loss: 5.5102e-05\n",
      "Epoch 605/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.6095e-05 - val_loss: 4.5158e-05\n",
      "Epoch 606/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.2971e-05 - val_loss: 3.9233e-05\n",
      "Epoch 607/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.3237e-05 - val_loss: 3.8871e-05\n",
      "Epoch 608/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.6112e-05 - val_loss: 4.7972e-05\n",
      "Epoch 609/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.5665e-05 - val_loss: 4.1860e-05\n",
      "Epoch 610/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.4627e-05 - val_loss: 4.1683e-05\n",
      "Epoch 611/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3557e-05 - val_loss: 3.6793e-05\n",
      "Epoch 612/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2508e-05 - val_loss: 4.4280e-05\n",
      "Epoch 613/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3019e-05 - val_loss: 4.6654e-05\n",
      "Epoch 614/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3360e-05 - val_loss: 4.6705e-05\n",
      "Epoch 615/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4198e-05 - val_loss: 4.1007e-05\n",
      "Epoch 616/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 2.3464e-05 - val_loss: 4.6292e-05\n",
      "Epoch 617/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.5700e-05 - val_loss: 3.5199e-05\n",
      "Epoch 618/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.1744e-05 - val_loss: 3.8047e-05\n",
      "Epoch 619/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4139e-05 - val_loss: 4.2994e-05\n",
      "Epoch 620/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2562e-05 - val_loss: 3.8804e-05\n",
      "Epoch 621/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2258e-05 - val_loss: 4.1296e-05\n",
      "Epoch 622/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.5702e-05 - val_loss: 3.8181e-05\n",
      "Epoch 623/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.8680e-05 - val_loss: 3.7768e-05\n",
      "Epoch 624/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 2.3726e-05 - val_loss: 5.1226e-05\n",
      "Epoch 625/2000\n",
      "18465/18465 [==============================] - 1s 78us/step - loss: 2.4033e-05 - val_loss: 3.5132e-05\n",
      "Epoch 626/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.1930e-05 - val_loss: 3.8249e-05\n",
      "Epoch 627/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.4132e-05 - val_loss: 4.7574e-05\n",
      "Epoch 628/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 2.5506e-05 - val_loss: 4.4186e-05\n",
      "Epoch 629/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.5582e-05 - val_loss: 5.0005e-05\n",
      "Epoch 630/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.1966e-05 - val_loss: 5.4789e-05\n",
      "Epoch 631/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.5511e-05 - val_loss: 3.8377e-05\n",
      "Epoch 632/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2416e-05 - val_loss: 4.5526e-05\n",
      "Epoch 633/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2104e-05 - val_loss: 3.7784e-05\n",
      "Epoch 634/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2028e-05 - val_loss: 4.3052e-05\n",
      "Epoch 635/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.2215e-05 - val_loss: 4.5997e-05\n",
      "Epoch 636/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.5975e-05 - val_loss: 3.6290e-05\n",
      "Epoch 637/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3798e-05 - val_loss: 3.5154e-05\n",
      "Epoch 638/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3566e-05 - val_loss: 4.1873e-05\n",
      "Epoch 639/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.3226e-05 - val_loss: 3.4757e-05\n",
      "Epoch 640/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 2.2323e-05 - val_loss: 3.7568e-05\n",
      "Epoch 641/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3122e-05 - val_loss: 3.1754e-05\n",
      "Epoch 642/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.5377e-05 - val_loss: 4.4063e-05\n",
      "Epoch 643/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.2982e-05 - val_loss: 3.4794e-05\n",
      "Epoch 644/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.5560e-05 - val_loss: 4.1144e-05\n",
      "Epoch 645/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.9583e-05 - val_loss: 3.6584e-05\n",
      "Epoch 646/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.5830e-05 - val_loss: 4.2936e-05\n",
      "Epoch 647/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4476e-05 - val_loss: 4.7547e-05\n",
      "Epoch 648/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.8110e-05 - val_loss: 3.4383e-05\n",
      "Epoch 649/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3882e-05 - val_loss: 3.6907e-05\n",
      "Epoch 650/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.9628e-05 - val_loss: 4.2968e-05\n",
      "Epoch 651/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.5144e-05 - val_loss: 3.5287e-05\n",
      "Epoch 652/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 2.4408e-05 - val_loss: 3.4904e-05\n",
      "Epoch 653/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 2.5237e-05 - val_loss: 4.3172e-05\n",
      "Epoch 654/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 5.3491e-05 - val_loss: 2.9014e-05\n",
      "Epoch 655/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.5152e-05 - val_loss: 6.0050e-05\n",
      "Epoch 656/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.7677e-05 - val_loss: 3.6625e-05\n",
      "Epoch 657/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2035e-05 - val_loss: 6.5634e-05\n",
      "Epoch 658/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4924e-05 - val_loss: 3.8082e-05\n",
      "Epoch 659/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1359e-05 - val_loss: 3.5719e-05\n",
      "Epoch 660/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.1959e-05 - val_loss: 3.7640e-05\n",
      "Epoch 661/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3603e-05 - val_loss: 4.0849e-05\n",
      "Epoch 662/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1866e-05 - val_loss: 4.3871e-05\n",
      "Epoch 663/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.3126e-05 - val_loss: 3.8052e-05\n",
      "Epoch 664/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 2.2361e-05 - val_loss: 4.2017e-05\n",
      "Epoch 665/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2157e-05 - val_loss: 3.5636e-05\n",
      "Epoch 666/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.3404e-05 - val_loss: 3.8860e-05\n",
      "Epoch 667/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2177e-05 - val_loss: 3.6145e-05\n",
      "Epoch 668/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.6579e-05 - val_loss: 2.9447e-05\n",
      "Epoch 669/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.3842e-05 - val_loss: 3.8055e-05\n",
      "Epoch 670/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0994e-05 - val_loss: 3.2445e-05\n",
      "Epoch 671/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2242e-05 - val_loss: 3.5092e-05\n",
      "Epoch 672/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1544e-05 - val_loss: 3.3971e-05\n",
      "Epoch 673/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3372e-05 - val_loss: 3.5669e-05\n",
      "Epoch 674/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.2140e-05 - val_loss: 3.8591e-05\n",
      "Epoch 675/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.3684e-05 - val_loss: 3.3315e-05\n",
      "Epoch 676/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 2.2459e-05 - val_loss: 6.4356e-05\n",
      "Epoch 677/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.6654e-05 - val_loss: 3.8673e-05\n",
      "Epoch 678/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3638e-05 - val_loss: 3.9141e-05\n",
      "Epoch 679/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3653e-05 - val_loss: 3.5242e-05\n",
      "Epoch 680/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2934e-05 - val_loss: 3.3893e-05\n",
      "Epoch 681/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.3351e-05 - val_loss: 3.3647e-05\n",
      "Epoch 682/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3245e-05 - val_loss: 3.6259e-05\n",
      "Epoch 683/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2327e-05 - val_loss: 3.4466e-05\n",
      "Epoch 684/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1403e-05 - val_loss: 3.7802e-05\n",
      "Epoch 685/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3054e-05 - val_loss: 3.5592e-05\n",
      "Epoch 686/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2790e-05 - val_loss: 3.7189e-05\n",
      "Epoch 687/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2129e-05 - val_loss: 3.3634e-05\n",
      "Epoch 688/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 2.3095e-05 - val_loss: 3.5280e-05\n",
      "Epoch 689/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.6138e-05 - val_loss: 3.9451e-05\n",
      "Epoch 690/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3293e-05 - val_loss: 3.1711e-05\n",
      "Epoch 691/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1212e-05 - val_loss: 3.8744e-05\n",
      "Epoch 692/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.6068e-05 - val_loss: 4.9650e-05\n",
      "Epoch 693/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.5115e-05 - val_loss: 3.3673e-05\n",
      "Epoch 694/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2573e-05 - val_loss: 3.5411e-05\n",
      "Epoch 695/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.2777e-05 - val_loss: 3.7251e-05\n",
      "Epoch 696/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2585e-05 - val_loss: 3.4903e-05\n",
      "Epoch 697/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.6198e-05 - val_loss: 3.3420e-05\n",
      "Epoch 698/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1880e-05 - val_loss: 3.6967e-05\n",
      "Epoch 699/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.6572e-05 - val_loss: 3.4182e-05\n",
      "Epoch 700/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 2.2440e-05 - val_loss: 3.5671e-05\n",
      "Epoch 701/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2887e-05 - val_loss: 2.8465e-05\n",
      "Epoch 702/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2850e-05 - val_loss: 2.1781e-05\n",
      "Epoch 703/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2832e-05 - val_loss: 3.5958e-05\n",
      "Epoch 704/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.4957e-05 - val_loss: 3.3628e-05\n",
      "Epoch 705/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.6543e-05 - val_loss: 3.3434e-05\n",
      "Epoch 706/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1670e-05 - val_loss: 3.0963e-05\n",
      "Epoch 707/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1276e-05 - val_loss: 2.7279e-05\n",
      "Epoch 708/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.3100e-05 - val_loss: 4.1418e-05\n",
      "Epoch 709/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.5256e-05 - val_loss: 2.8133e-05\n",
      "Epoch 710/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2961e-05 - val_loss: 2.9768e-05\n",
      "Epoch 711/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.1753e-05 - val_loss: 3.0617e-05\n",
      "Epoch 712/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 2.2464e-05 - val_loss: 2.8313e-05\n",
      "Epoch 713/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.5086e-05 - val_loss: 4.4044e-05\n",
      "Epoch 714/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3491e-05 - val_loss: 4.4257e-05\n",
      "Epoch 715/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.2797e-05 - val_loss: 3.5975e-05\n",
      "Epoch 716/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2341e-05 - val_loss: 3.0371e-05\n",
      "Epoch 717/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2353e-05 - val_loss: 4.2080e-05\n",
      "Epoch 718/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2596e-05 - val_loss: 3.4642e-05\n",
      "Epoch 719/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.3074e-05 - val_loss: 3.5572e-05\n",
      "Epoch 720/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2264e-05 - val_loss: 3.3833e-05\n",
      "Epoch 721/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1226e-05 - val_loss: 4.1039e-05\n",
      "Epoch 722/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.0843e-05 - val_loss: 3.0575e-05\n",
      "Epoch 723/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2563e-05 - val_loss: 3.5205e-05\n",
      "Epoch 724/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 2.4460e-05 - val_loss: 3.4033e-05\n",
      "Epoch 725/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4451e-05 - val_loss: 4.4135e-05\n",
      "Epoch 726/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4919e-05 - val_loss: 2.8815e-05\n",
      "Epoch 727/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2060e-05 - val_loss: 3.0865e-05\n",
      "Epoch 728/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.2961e-05 - val_loss: 3.5490e-05\n",
      "Epoch 729/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.2742e-05 - val_loss: 3.3671e-05\n",
      "Epoch 730/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2203e-05 - val_loss: 3.4127e-05\n",
      "Epoch 731/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3209e-05 - val_loss: 3.9820e-05\n",
      "Epoch 732/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1240e-05 - val_loss: 3.6714e-05\n",
      "Epoch 733/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.4436e-05 - val_loss: 3.9384e-05\n",
      "Epoch 734/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.4073e-05 - val_loss: 5.1728e-05\n",
      "Epoch 735/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.5571e-05 - val_loss: 3.2994e-05\n",
      "Epoch 736/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 2.4278e-05 - val_loss: 3.7380e-05\n",
      "Epoch 737/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.4144e-05 - val_loss: 3.2394e-05\n",
      "Epoch 738/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1078e-05 - val_loss: 3.3800e-05\n",
      "Epoch 739/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4551e-05 - val_loss: 3.0700e-05\n",
      "Epoch 740/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0940e-05 - val_loss: 3.1215e-05\n",
      "Epoch 741/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1764e-05 - val_loss: 3.1343e-05\n",
      "Epoch 742/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.0784e-05 - val_loss: 2.9950e-05\n",
      "Epoch 743/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3849e-05 - val_loss: 3.2748e-05\n",
      "Epoch 744/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4774e-05 - val_loss: 4.6074e-05\n",
      "Epoch 745/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4704e-05 - val_loss: 2.7345e-05\n",
      "Epoch 746/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2169e-05 - val_loss: 3.7486e-05\n",
      "Epoch 747/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.3008e-05 - val_loss: 3.1964e-05\n",
      "Epoch 748/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 2.1487e-05 - val_loss: 3.5206e-05\n",
      "Epoch 749/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1861e-05 - val_loss: 3.1366e-05\n",
      "Epoch 750/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2088e-05 - val_loss: 2.7831e-05\n",
      "Epoch 751/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0852e-05 - val_loss: 3.9213e-05\n",
      "Epoch 752/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.4779e-05 - val_loss: 5.3246e-05\n",
      "Epoch 753/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.4287e-05 - val_loss: 3.1064e-05\n",
      "Epoch 754/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.4528e-05 - val_loss: 3.0070e-05\n",
      "Epoch 755/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3926e-05 - val_loss: 3.6508e-05\n",
      "Epoch 756/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1862e-05 - val_loss: 3.8398e-05\n",
      "Epoch 757/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4672e-05 - val_loss: 3.6042e-05\n",
      "Epoch 758/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2416e-05 - val_loss: 3.6626e-05\n",
      "Epoch 759/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.3576e-05 - val_loss: 3.2650e-05\n",
      "Epoch 760/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 2.2469e-05 - val_loss: 3.8328e-05\n",
      "Epoch 761/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.7576e-05 - val_loss: 2.9758e-05\n",
      "Epoch 762/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.3218e-05 - val_loss: 2.9474e-05\n",
      "Epoch 763/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.2031e-05 - val_loss: 3.8651e-05\n",
      "Epoch 764/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.2667e-05 - val_loss: 2.6233e-05\n",
      "Epoch 765/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0952e-05 - val_loss: 3.1243e-05\n",
      "Epoch 766/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1148e-05 - val_loss: 3.0633e-05\n",
      "Epoch 767/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4098e-05 - val_loss: 3.2084e-05\n",
      "Epoch 768/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.2595e-05 - val_loss: 3.4221e-05\n",
      "Epoch 769/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3543e-05 - val_loss: 3.6571e-05\n",
      "Epoch 770/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3583e-05 - val_loss: 3.5778e-05\n",
      "Epoch 771/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1263e-05 - val_loss: 3.1710e-05\n",
      "Epoch 772/2000\n",
      "18465/18465 [==============================] - 1s 76us/step - loss: 2.1996e-05 - val_loss: 4.9441e-05\n",
      "Epoch 773/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.3304e-05 - val_loss: 3.4641e-05\n",
      "Epoch 774/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.1901e-05 - val_loss: 2.7531e-05\n",
      "Epoch 775/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2369e-05 - val_loss: 3.5693e-05\n",
      "Epoch 776/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.2195e-05 - val_loss: 6.4844e-05\n",
      "Epoch 777/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.6284e-05 - val_loss: 3.2252e-05\n",
      "Epoch 778/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2112e-05 - val_loss: 6.5380e-05\n",
      "Epoch 779/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.8479e-05 - val_loss: 4.3266e-05\n",
      "Epoch 780/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.6923e-05 - val_loss: 3.2125e-05\n",
      "Epoch 781/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2391e-05 - val_loss: 3.2903e-05\n",
      "Epoch 782/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1011e-05 - val_loss: 4.2473e-05\n",
      "Epoch 783/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.5971e-05 - val_loss: 3.4341e-05\n",
      "Epoch 784/2000\n",
      "18465/18465 [==============================] - 1s 76us/step - loss: 2.1636e-05 - val_loss: 3.1588e-05\n",
      "Epoch 785/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2236e-05 - val_loss: 2.7987e-05\n",
      "Epoch 786/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0814e-05 - val_loss: 3.4187e-05\n",
      "Epoch 787/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.2781e-05 - val_loss: 2.8873e-05\n",
      "Epoch 788/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2167e-05 - val_loss: 3.4219e-05\n",
      "Epoch 789/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.7745e-05 - val_loss: 3.2214e-05\n",
      "Epoch 790/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4213e-05 - val_loss: 3.3277e-05\n",
      "Epoch 791/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3648e-05 - val_loss: 3.5387e-05\n",
      "Epoch 792/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.3938e-05 - val_loss: 3.6115e-05\n",
      "Epoch 793/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2811e-05 - val_loss: 3.6304e-05\n",
      "Epoch 794/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3901e-05 - val_loss: 3.4041e-05\n",
      "Epoch 795/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3239e-05 - val_loss: 3.2426e-05\n",
      "Epoch 796/2000\n",
      "18465/18465 [==============================] - 1s 76us/step - loss: 2.2117e-05 - val_loss: 3.7755e-05\n",
      "Epoch 797/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.4285e-05 - val_loss: 4.4340e-05\n",
      "Epoch 798/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.2340e-05 - val_loss: 4.9903e-05\n",
      "Epoch 799/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.4776e-05 - val_loss: 3.8814e-05\n",
      "Epoch 800/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.1096e-05 - val_loss: 3.6825e-05\n",
      "Epoch 801/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.0149e-05 - val_loss: 5.9914e-05\n",
      "Epoch 802/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.4215e-05 - val_loss: 3.3372e-05\n",
      "Epoch 803/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.1576e-05 - val_loss: 3.4513e-05\n",
      "Epoch 804/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.4864e-05 - val_loss: 3.1549e-05\n",
      "Epoch 805/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2551e-05 - val_loss: 3.4030e-05\n",
      "Epoch 806/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0362e-05 - val_loss: 3.6942e-05\n",
      "Epoch 807/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2585e-05 - val_loss: 3.5362e-05\n",
      "Epoch 808/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 2.2095e-05 - val_loss: 1.8054e-05\n",
      "Epoch 809/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4903e-05 - val_loss: 2.0617e-05\n",
      "Epoch 810/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.2203e-05 - val_loss: 4.3773e-05\n",
      "Epoch 811/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.3715e-05 - val_loss: 5.4816e-05\n",
      "Epoch 812/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.5493e-05 - val_loss: 3.8236e-05\n",
      "Epoch 813/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.1014e-05 - val_loss: 3.1439e-05\n",
      "Epoch 814/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.1652e-05 - val_loss: 3.5301e-05\n",
      "Epoch 815/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.1904e-05 - val_loss: 3.2720e-05\n",
      "Epoch 816/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1623e-05 - val_loss: 3.3543e-05\n",
      "Epoch 817/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.5255e-05 - val_loss: 2.8732e-05\n",
      "Epoch 818/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2209e-05 - val_loss: 3.2790e-05\n",
      "Epoch 819/2000\n",
      "18465/18465 [==============================] - 2s 87us/step - loss: 2.2959e-05 - val_loss: 3.4651e-05\n",
      "Epoch 820/2000\n",
      "18465/18465 [==============================] - 2s 88us/step - loss: 2.3936e-05 - val_loss: 3.9627e-05\n",
      "Epoch 821/2000\n",
      "18465/18465 [==============================] - 1s 81us/step - loss: 2.2786e-05 - val_loss: 4.2651e-05\n",
      "Epoch 822/2000\n",
      "18465/18465 [==============================] - 1s 81us/step - loss: 2.2898e-05 - val_loss: 4.0948e-05\n",
      "Epoch 823/2000\n",
      "18465/18465 [==============================] - 1s 81us/step - loss: 2.2670e-05 - val_loss: 3.5461e-05\n",
      "Epoch 824/2000\n",
      "18465/18465 [==============================] - 2s 84us/step - loss: 2.1659e-05 - val_loss: 2.9746e-05\n",
      "Epoch 825/2000\n",
      "18465/18465 [==============================] - 2s 82us/step - loss: 2.8955e-05 - val_loss: 4.0508e-05\n",
      "Epoch 826/2000\n",
      "18465/18465 [==============================] - 1s 80us/step - loss: 3.0290e-05 - val_loss: 2.8603e-05\n",
      "Epoch 827/2000\n",
      "18465/18465 [==============================] - 1s 80us/step - loss: 2.3818e-05 - val_loss: 7.1507e-05\n",
      "Epoch 828/2000\n",
      "18465/18465 [==============================] - 1s 81us/step - loss: 3.1731e-05 - val_loss: 2.4404e-05\n",
      "Epoch 829/2000\n",
      "18465/18465 [==============================] - 1s 81us/step - loss: 2.3021e-05 - val_loss: 4.1410e-05\n",
      "Epoch 830/2000\n",
      "18465/18465 [==============================] - 2s 84us/step - loss: 2.2636e-05 - val_loss: 4.5512e-05\n",
      "Epoch 831/2000\n",
      "18465/18465 [==============================] - 2s 81us/step - loss: 2.1887e-05 - val_loss: 2.9971e-05\n",
      "Epoch 832/2000\n",
      "18465/18465 [==============================] - 1s 81us/step - loss: 2.1202e-05 - val_loss: 2.0937e-05\n",
      "Epoch 833/2000\n",
      "18465/18465 [==============================] - 1s 81us/step - loss: 2.2256e-05 - val_loss: 3.0196e-05\n",
      "Epoch 834/2000\n",
      "18465/18465 [==============================] - 1s 80us/step - loss: 2.1695e-05 - val_loss: 2.9342e-05\n",
      "Epoch 835/2000\n",
      "18465/18465 [==============================] - 1s 81us/step - loss: 2.0745e-05 - val_loss: 2.9551e-05\n",
      "Epoch 836/2000\n",
      "18465/18465 [==============================] - 1s 79us/step - loss: 2.2334e-05 - val_loss: 3.9177e-05\n",
      "Epoch 837/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 2.2880e-05 - val_loss: 4.0797e-05\n",
      "Epoch 838/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1645e-05 - val_loss: 3.6700e-05\n",
      "Epoch 839/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0953e-05 - val_loss: 3.5014e-05\n",
      "Epoch 840/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.5820e-05 - val_loss: 3.5651e-05\n",
      "Epoch 841/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18465/18465 [==============================] - 1s 74us/step - loss: 2.1823e-05 - val_loss: 3.4370e-05\n",
      "Epoch 842/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.2119e-05 - val_loss: 8.2278e-05\n",
      "Epoch 843/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 5.6559e-05 - val_loss: 3.5543e-05\n",
      "Epoch 844/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.5886e-05 - val_loss: 1.9780e-05\n",
      "Epoch 845/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4888e-05 - val_loss: 3.3950e-05\n",
      "Epoch 846/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3851e-05 - val_loss: 2.6413e-05\n",
      "Epoch 847/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0371e-05 - val_loss: 4.5605e-05\n",
      "Epoch 848/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.5977e-05 - val_loss: 3.1723e-05\n",
      "Epoch 849/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4063e-05 - val_loss: 3.3513e-05\n",
      "Epoch 850/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0002e-05 - val_loss: 3.8259e-05\n",
      "Epoch 851/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.0732e-05 - val_loss: 3.3530e-05\n",
      "Epoch 852/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1547e-05 - val_loss: 3.2937e-05\n",
      "Epoch 853/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 2.1345e-05 - val_loss: 3.9085e-05\n",
      "Epoch 854/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2638e-05 - val_loss: 4.9007e-05\n",
      "Epoch 855/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.3881e-05 - val_loss: 3.0284e-05\n",
      "Epoch 856/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9676e-05 - val_loss: 4.3311e-05\n",
      "Epoch 857/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.1280e-05 - val_loss: 3.0257e-05\n",
      "Epoch 858/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2832e-05 - val_loss: 3.1555e-05\n",
      "Epoch 859/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0305e-05 - val_loss: 2.9064e-05\n",
      "Epoch 860/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4385e-05 - val_loss: 2.9955e-05\n",
      "Epoch 861/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1298e-05 - val_loss: 3.3032e-05\n",
      "Epoch 862/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2203e-05 - val_loss: 3.5132e-05\n",
      "Epoch 863/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4110e-05 - val_loss: 3.6787e-05\n",
      "Epoch 864/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.1962e-05 - val_loss: 2.9808e-05\n",
      "Epoch 865/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 2.2551e-05 - val_loss: 5.3521e-05\n",
      "Epoch 866/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2728e-05 - val_loss: 2.5954e-05\n",
      "Epoch 867/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.2991e-05 - val_loss: 3.5469e-05\n",
      "Epoch 868/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2461e-05 - val_loss: 4.2763e-05\n",
      "Epoch 869/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.2558e-05 - val_loss: 4.2298e-05\n",
      "Epoch 870/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.8263e-05 - val_loss: 3.6205e-05\n",
      "Epoch 871/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.0947e-05 - val_loss: 3.1319e-05\n",
      "Epoch 872/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3919e-05 - val_loss: 3.2006e-05\n",
      "Epoch 873/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.3513e-05 - val_loss: 4.1049e-05\n",
      "Epoch 874/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.0925e-05 - val_loss: 4.5774e-05\n",
      "Epoch 875/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1043e-05 - val_loss: 3.8539e-05\n",
      "Epoch 876/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1310e-05 - val_loss: 2.9114e-05\n",
      "Epoch 877/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 2.0461e-05 - val_loss: 3.7513e-05\n",
      "Epoch 878/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0975e-05 - val_loss: 3.6762e-05\n",
      "Epoch 879/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0273e-05 - val_loss: 4.4134e-05\n",
      "Epoch 880/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0759e-05 - val_loss: 3.6085e-05\n",
      "Epoch 881/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.3934e-05 - val_loss: 3.6611e-05\n",
      "Epoch 882/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0901e-05 - val_loss: 4.3820e-05\n",
      "Epoch 883/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2890e-05 - val_loss: 3.3624e-05\n",
      "Epoch 884/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0185e-05 - val_loss: 3.7062e-05\n",
      "Epoch 885/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2588e-05 - val_loss: 3.9997e-05\n",
      "Epoch 886/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1573e-05 - val_loss: 4.2164e-05\n",
      "Epoch 887/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.2973e-05 - val_loss: 3.3567e-05\n",
      "Epoch 888/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3687e-05 - val_loss: 3.4963e-05\n",
      "Epoch 889/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 2.3297e-05 - val_loss: 3.0158e-05\n",
      "Epoch 890/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.2189e-05 - val_loss: 2.8058e-05\n",
      "Epoch 891/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 2.0909e-05 - val_loss: 2.7170e-05\n",
      "Epoch 892/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1441e-05 - val_loss: 3.2659e-05\n",
      "Epoch 893/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 3.3074e-05 - val_loss: 3.0750e-05\n",
      "Epoch 894/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2977e-05 - val_loss: 3.0070e-05\n",
      "Epoch 895/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3434e-05 - val_loss: 3.3924e-05\n",
      "Epoch 896/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.0614e-05 - val_loss: 3.9061e-05\n",
      "Epoch 897/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.1914e-05 - val_loss: 3.6970e-05\n",
      "Epoch 898/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0724e-05 - val_loss: 3.3749e-05\n",
      "Epoch 899/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.3925e-05 - val_loss: 3.5325e-05\n",
      "Epoch 900/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2711e-05 - val_loss: 7.5820e-05\n",
      "Epoch 901/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 3.7748e-05 - val_loss: 5.6781e-05\n",
      "Epoch 902/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.6824e-05 - val_loss: 2.4663e-05\n",
      "Epoch 903/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1845e-05 - val_loss: 4.1442e-05\n",
      "Epoch 904/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3178e-05 - val_loss: 3.7900e-05\n",
      "Epoch 905/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.1894e-05 - val_loss: 4.5539e-05\n",
      "Epoch 906/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1277e-05 - val_loss: 4.8432e-05\n",
      "Epoch 907/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2823e-05 - val_loss: 3.6493e-05\n",
      "Epoch 908/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4373e-05 - val_loss: 2.7577e-05\n",
      "Epoch 909/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3515e-05 - val_loss: 4.3024e-05\n",
      "Epoch 910/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2679e-05 - val_loss: 2.7927e-05\n",
      "Epoch 911/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.1069e-05 - val_loss: 3.1750e-05\n",
      "Epoch 912/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.1457e-05 - val_loss: 2.4519e-05\n",
      "Epoch 913/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 2.3598e-05 - val_loss: 3.4925e-05\n",
      "Epoch 914/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2879e-05 - val_loss: 2.7281e-05\n",
      "Epoch 915/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3590e-05 - val_loss: 3.7702e-05\n",
      "Epoch 916/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.5334e-05 - val_loss: 5.0549e-05\n",
      "Epoch 917/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0330e-05 - val_loss: 3.1340e-05\n",
      "Epoch 918/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1737e-05 - val_loss: 5.5808e-05\n",
      "Epoch 919/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3827e-05 - val_loss: 3.3330e-05\n",
      "Epoch 920/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 2.0820e-05 - val_loss: 5.8302e-05\n",
      "Epoch 921/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 2.7189e-05 - val_loss: 3.2931e-05\n",
      "Epoch 922/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.8942e-05 - val_loss: 2.4417e-05\n",
      "Epoch 923/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.0331e-05 - val_loss: 1.4012e-05\n",
      "Epoch 924/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4171e-05 - val_loss: 1.6235e-05\n",
      "Epoch 925/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 2.5992e-05 - val_loss: 3.9481e-05\n",
      "Epoch 926/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3432e-05 - val_loss: 4.5580e-05\n",
      "Epoch 927/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1827e-05 - val_loss: 5.2564e-05\n",
      "Epoch 928/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.5296e-05 - val_loss: 4.7133e-05\n",
      "Epoch 929/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4121e-05 - val_loss: 5.1855e-05\n",
      "Epoch 930/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1847e-05 - val_loss: 5.8920e-05\n",
      "Epoch 931/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.1971e-05 - val_loss: 5.1133e-05\n",
      "Epoch 932/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9692e-05 - val_loss: 5.2644e-05\n",
      "Epoch 933/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.7161e-05 - val_loss: 4.5658e-05\n",
      "Epoch 934/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1207e-05 - val_loss: 4.2537e-05\n",
      "Epoch 935/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.3410e-05 - val_loss: 4.5584e-05\n",
      "Epoch 936/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.4993e-05 - val_loss: 4.9194e-05\n",
      "Epoch 937/2000\n",
      "18465/18465 [==============================] - 1s 76us/step - loss: 2.1703e-05 - val_loss: 4.4216e-05\n",
      "Epoch 938/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1972e-05 - val_loss: 3.9238e-05\n",
      "Epoch 939/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0377e-05 - val_loss: 4.4762e-05\n",
      "Epoch 940/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.0504e-05 - val_loss: 4.7556e-05\n",
      "Epoch 941/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4163e-05 - val_loss: 5.3947e-05\n",
      "Epoch 942/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1205e-05 - val_loss: 5.8389e-05\n",
      "Epoch 943/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2735e-05 - val_loss: 5.6669e-05\n",
      "Epoch 944/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2883e-05 - val_loss: 4.1324e-05\n",
      "Epoch 945/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1529e-05 - val_loss: 5.2630e-05\n",
      "Epoch 946/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2526e-05 - val_loss: 4.1661e-05\n",
      "Epoch 947/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.2207e-05 - val_loss: 4.1152e-05\n",
      "Epoch 948/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.1410e-05 - val_loss: 4.3238e-05\n",
      "Epoch 949/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 2.1850e-05 - val_loss: 4.7937e-05\n",
      "Epoch 950/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3518e-05 - val_loss: 3.1767e-05\n",
      "Epoch 951/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.0507e-05 - val_loss: 3.6356e-05\n",
      "Epoch 952/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9600e-05 - val_loss: 4.4656e-05\n",
      "Epoch 953/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.0901e-05 - val_loss: 4.3692e-05\n",
      "Epoch 954/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1610e-05 - val_loss: 4.4261e-05\n",
      "Epoch 955/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.1874e-05 - val_loss: 4.5742e-05\n",
      "Epoch 956/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2689e-05 - val_loss: 3.7572e-05\n",
      "Epoch 957/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.3757e-05 - val_loss: 3.9585e-05\n",
      "Epoch 958/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3402e-05 - val_loss: 3.5466e-05\n",
      "Epoch 959/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4012e-05 - val_loss: 4.3662e-05\n",
      "Epoch 960/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3618e-05 - val_loss: 4.1316e-05\n",
      "Epoch 961/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 2.2612e-05 - val_loss: 4.7254e-05\n",
      "Epoch 962/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2785e-05 - val_loss: 6.7257e-05\n",
      "Epoch 963/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.7776e-05 - val_loss: 4.0273e-05\n",
      "Epoch 964/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1286e-05 - val_loss: 3.5589e-05\n",
      "Epoch 965/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.2544e-05 - val_loss: 5.0558e-05\n",
      "Epoch 966/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2700e-05 - val_loss: 3.8446e-05\n",
      "Epoch 967/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.1258e-05 - val_loss: 3.8178e-05\n",
      "Epoch 968/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1703e-05 - val_loss: 3.9410e-05\n",
      "Epoch 969/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.1114e-05 - val_loss: 3.8738e-05\n",
      "Epoch 970/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 2.0554e-05 - val_loss: 4.1199e-05\n",
      "Epoch 971/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.1423e-05 - val_loss: 4.4470e-05\n",
      "Epoch 972/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3242e-05 - val_loss: 4.1408e-05\n",
      "Epoch 973/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 2.0940e-05 - val_loss: 6.4232e-05\n",
      "Epoch 974/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.1338e-05 - val_loss: 2.0005e-05\n",
      "Epoch 975/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4310e-05 - val_loss: 3.9579e-05\n",
      "Epoch 976/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.3857e-05 - val_loss: 4.8653e-05\n",
      "Epoch 977/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1833e-05 - val_loss: 4.0973e-05\n",
      "Epoch 978/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0476e-05 - val_loss: 4.3178e-05\n",
      "Epoch 979/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.1005e-05 - val_loss: 3.8252e-05\n",
      "Epoch 980/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.1885e-05 - val_loss: 5.3974e-05\n",
      "Epoch 981/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1120e-05 - val_loss: 7.7505e-05\n",
      "Epoch 982/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.0717e-05 - val_loss: 5.0051e-05\n",
      "Epoch 983/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.2833e-05 - val_loss: 3.1351e-05\n",
      "Epoch 984/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.4611e-05 - val_loss: 5.8375e-05\n",
      "Epoch 985/2000\n",
      "18465/18465 [==============================] - 1s 76us/step - loss: 2.2464e-05 - val_loss: 1.8817e-05\n",
      "Epoch 986/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1329e-05 - val_loss: 4.5169e-05\n",
      "Epoch 987/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4047e-05 - val_loss: 4.5102e-05\n",
      "Epoch 988/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1183e-05 - val_loss: 3.1934e-05\n",
      "Epoch 989/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3752e-05 - val_loss: 3.3126e-05\n",
      "Epoch 990/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.2804e-05 - val_loss: 4.1570e-05\n",
      "Epoch 991/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1959e-05 - val_loss: 4.0415e-05\n",
      "Epoch 992/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1404e-05 - val_loss: 4.2373e-05\n",
      "Epoch 993/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.0488e-05 - val_loss: 3.6411e-05\n",
      "Epoch 994/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1283e-05 - val_loss: 3.4712e-05\n",
      "Epoch 995/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1839e-05 - val_loss: 4.6282e-05\n",
      "Epoch 996/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.1086e-05 - val_loss: 3.4704e-05\n",
      "Epoch 997/2000\n",
      "18465/18465 [==============================] - 1s 76us/step - loss: 2.1327e-05 - val_loss: 4.0017e-05\n",
      "Epoch 998/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.9783e-05 - val_loss: 4.3076e-05\n",
      "Epoch 999/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3678e-05 - val_loss: 4.9842e-05\n",
      "Epoch 1000/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.1023e-05 - val_loss: 3.9617e-05\n",
      "Epoch 1001/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0250e-05 - val_loss: 4.5638e-05\n",
      "Epoch 1002/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1600e-05 - val_loss: 5.2135e-05\n",
      "Epoch 1003/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.2916e-05 - val_loss: 3.4334e-05\n",
      "Epoch 1004/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1274e-05 - val_loss: 4.7320e-05\n",
      "Epoch 1005/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.4562e-05 - val_loss: 3.7994e-05\n",
      "Epoch 1006/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.0686e-05 - val_loss: 3.0250e-05\n",
      "Epoch 1007/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.0842e-05 - val_loss: 3.8966e-05\n",
      "Epoch 1008/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1854e-05 - val_loss: 4.4428e-05\n",
      "Epoch 1009/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 2.6094e-05 - val_loss: 3.1279e-05\n",
      "Epoch 1010/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 2.2741e-05 - val_loss: 3.5206e-05\n",
      "Epoch 1011/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0936e-05 - val_loss: 4.2554e-05\n",
      "Epoch 1012/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3325e-05 - val_loss: 3.8732e-05\n",
      "Epoch 1013/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1007e-05 - val_loss: 4.1116e-05\n",
      "Epoch 1014/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1073e-05 - val_loss: 3.7672e-05\n",
      "Epoch 1015/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1568e-05 - val_loss: 3.4013e-05\n",
      "Epoch 1016/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.0318e-05 - val_loss: 5.5932e-05\n",
      "Epoch 1017/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.9585e-05 - val_loss: 2.9749e-05\n",
      "Epoch 1018/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0753e-05 - val_loss: 3.7278e-05\n",
      "Epoch 1019/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1356e-05 - val_loss: 4.2022e-05\n",
      "Epoch 1020/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0388e-05 - val_loss: 4.7103e-05\n",
      "Epoch 1021/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 2.1080e-05 - val_loss: 4.1248e-05\n",
      "Epoch 1022/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.2016e-05 - val_loss: 3.7603e-05\n",
      "Epoch 1023/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0387e-05 - val_loss: 3.5790e-05\n",
      "Epoch 1024/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9439e-05 - val_loss: 3.0098e-05\n",
      "Epoch 1025/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.1345e-05 - val_loss: 3.3247e-05\n",
      "Epoch 1026/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1716e-05 - val_loss: 4.5011e-05\n",
      "Epoch 1027/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.2621e-05 - val_loss: 3.8896e-05\n",
      "Epoch 1028/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.1641e-05 - val_loss: 2.9826e-05\n",
      "Epoch 1029/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0733e-05 - val_loss: 4.1593e-05\n",
      "Epoch 1030/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.1696e-05 - val_loss: 2.9876e-05\n",
      "Epoch 1031/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.9779e-05 - val_loss: 3.3960e-05\n",
      "Epoch 1032/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0987e-05 - val_loss: 3.3557e-05\n",
      "Epoch 1033/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 2.0167e-05 - val_loss: 3.3413e-05\n",
      "Epoch 1034/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0346e-05 - val_loss: 5.1515e-05\n",
      "Epoch 1035/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3461e-05 - val_loss: 3.2149e-05\n",
      "Epoch 1036/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.0720e-05 - val_loss: 3.8325e-05\n",
      "Epoch 1037/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0560e-05 - val_loss: 4.5775e-05\n",
      "Epoch 1038/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1199e-05 - val_loss: 3.5761e-05\n",
      "Epoch 1039/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0290e-05 - val_loss: 3.9590e-05\n",
      "Epoch 1040/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1148e-05 - val_loss: 3.3476e-05\n",
      "Epoch 1041/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9944e-05 - val_loss: 3.1072e-05\n",
      "Epoch 1042/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 1.9725e-05 - val_loss: 2.9955e-05\n",
      "Epoch 1043/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0497e-05 - val_loss: 3.2977e-05\n",
      "Epoch 1044/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3027e-05 - val_loss: 4.1300e-05\n",
      "Epoch 1045/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 2.6820e-05 - val_loss: 3.1259e-05\n",
      "Epoch 1046/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.0931e-05 - val_loss: 3.5153e-05\n",
      "Epoch 1047/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0809e-05 - val_loss: 3.6465e-05\n",
      "Epoch 1048/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.1325e-05 - val_loss: 3.8843e-05\n",
      "Epoch 1049/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0248e-05 - val_loss: 2.9964e-05\n",
      "Epoch 1050/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.3697e-05 - val_loss: 3.6872e-05\n",
      "Epoch 1051/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.7354e-05 - val_loss: 4.9429e-05\n",
      "Epoch 1052/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2285e-05 - val_loss: 2.2396e-05\n",
      "Epoch 1053/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0667e-05 - val_loss: 2.4029e-05\n",
      "Epoch 1054/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2327e-05 - val_loss: 2.8926e-05\n",
      "Epoch 1055/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.1181e-05 - val_loss: 2.8509e-05\n",
      "Epoch 1056/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.0546e-05 - val_loss: 2.8165e-05\n",
      "Epoch 1057/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 2.1510e-05 - val_loss: 2.7536e-05\n",
      "Epoch 1058/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0694e-05 - val_loss: 2.3451e-05\n",
      "Epoch 1059/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0345e-05 - val_loss: 2.9225e-05\n",
      "Epoch 1060/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9563e-05 - val_loss: 2.3884e-05\n",
      "Epoch 1061/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.0852e-05 - val_loss: 2.3984e-05\n",
      "Epoch 1062/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0955e-05 - val_loss: 2.8958e-05\n",
      "Epoch 1063/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9750e-05 - val_loss: 4.7896e-05\n",
      "Epoch 1064/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.4638e-05 - val_loss: 2.4736e-05\n",
      "Epoch 1065/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.4721e-05 - val_loss: 2.6236e-05\n",
      "Epoch 1066/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1349e-05 - val_loss: 2.7442e-05\n",
      "Epoch 1067/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.0200e-05 - val_loss: 2.8184e-05\n",
      "Epoch 1068/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 1.9862e-05 - val_loss: 2.4803e-05\n",
      "Epoch 1069/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 2.2112e-05 - val_loss: 2.3599e-05\n",
      "Epoch 1070/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1305e-05 - val_loss: 2.7632e-05\n",
      "Epoch 1071/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.9979e-05 - val_loss: 2.7100e-05\n",
      "Epoch 1072/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1285e-05 - val_loss: 2.4287e-05\n",
      "Epoch 1073/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 1.9505e-05 - val_loss: 2.5598e-05\n",
      "Epoch 1074/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9620e-05 - val_loss: 2.8074e-05\n",
      "Epoch 1075/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9815e-05 - val_loss: 2.4918e-05\n",
      "Epoch 1076/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9654e-05 - val_loss: 2.4622e-05\n",
      "Epoch 1077/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.0368e-05 - val_loss: 2.3447e-05\n",
      "Epoch 1078/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0539e-05 - val_loss: 2.9632e-05\n",
      "Epoch 1079/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1427e-05 - val_loss: 2.5548e-05\n",
      "Epoch 1080/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.1642e-05 - val_loss: 2.9557e-05\n",
      "Epoch 1081/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 2.0172e-05 - val_loss: 2.8953e-05\n",
      "Epoch 1082/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3213e-05 - val_loss: 3.3129e-05\n",
      "Epoch 1083/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2608e-05 - val_loss: 1.8855e-05\n",
      "Epoch 1084/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0259e-05 - val_loss: 6.3606e-05\n",
      "Epoch 1085/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.2030e-05 - val_loss: 3.3206e-05\n",
      "Epoch 1086/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9637e-05 - val_loss: 3.3603e-05\n",
      "Epoch 1087/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1761e-05 - val_loss: 3.2215e-05\n",
      "Epoch 1088/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.9891e-05 - val_loss: 3.8878e-05\n",
      "Epoch 1089/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4449e-05 - val_loss: 4.2478e-05\n",
      "Epoch 1090/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.6249e-05 - val_loss: 3.2638e-05\n",
      "Epoch 1091/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3235e-05 - val_loss: 3.3142e-05\n",
      "Epoch 1092/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 2.2012e-05 - val_loss: 2.7674e-05\n",
      "Epoch 1093/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.0653e-05 - val_loss: 4.7393e-05\n",
      "Epoch 1094/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2943e-05 - val_loss: 5.7555e-05\n",
      "Epoch 1095/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 9.6743e-05 - val_loss: 2.7274e-05\n",
      "Epoch 1096/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.7593e-05 - val_loss: 1.7078e-05\n",
      "Epoch 1097/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.9565e-05 - val_loss: 3.1649e-05\n",
      "Epoch 1098/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.3665e-05 - val_loss: 2.9902e-05\n",
      "Epoch 1099/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.5502e-05 - val_loss: 4.0028e-05\n",
      "Epoch 1100/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4354e-05 - val_loss: 3.5140e-05\n",
      "Epoch 1101/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1225e-05 - val_loss: 8.3086e-05\n",
      "Epoch 1102/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 4.0520e-05 - val_loss: 1.7353e-05\n",
      "Epoch 1103/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.5560e-05 - val_loss: 2.1135e-05\n",
      "Epoch 1104/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.1674e-05 - val_loss: 4.0255e-05\n",
      "Epoch 1105/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 2.2556e-05 - val_loss: 5.2965e-05\n",
      "Epoch 1106/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.4113e-05 - val_loss: 3.3436e-05\n",
      "Epoch 1107/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.2195e-05 - val_loss: 3.7150e-05\n",
      "Epoch 1108/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.1849e-05 - val_loss: 2.8197e-05\n",
      "Epoch 1109/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0470e-05 - val_loss: 2.9150e-05\n",
      "Epoch 1110/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3627e-05 - val_loss: 3.4138e-05\n",
      "Epoch 1111/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3657e-05 - val_loss: 3.7689e-05\n",
      "Epoch 1112/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4101e-05 - val_loss: 4.4050e-05\n",
      "Epoch 1113/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4981e-05 - val_loss: 5.8979e-05\n",
      "Epoch 1114/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.6436e-05 - val_loss: 3.2394e-05\n",
      "Epoch 1115/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1909e-05 - val_loss: 3.2316e-05\n",
      "Epoch 1116/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 2.1426e-05 - val_loss: 2.9771e-05\n",
      "Epoch 1117/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 2.0210e-05 - val_loss: 3.2797e-05\n",
      "Epoch 1118/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3752e-05 - val_loss: 3.5732e-05\n",
      "Epoch 1119/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1384e-05 - val_loss: 3.1610e-05\n",
      "Epoch 1120/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.1924e-05 - val_loss: 3.1028e-05\n",
      "Epoch 1121/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1018e-05 - val_loss: 2.9943e-05\n",
      "Epoch 1122/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.2791e-05 - val_loss: 2.8228e-05\n",
      "Epoch 1123/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.9508e-05 - val_loss: 2.7998e-05\n",
      "Epoch 1124/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2687e-05 - val_loss: 3.0172e-05\n",
      "Epoch 1125/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1063e-05 - val_loss: 3.1866e-05\n",
      "Epoch 1126/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.1386e-05 - val_loss: 3.1056e-05\n",
      "Epoch 1127/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2543e-05 - val_loss: 3.1139e-05\n",
      "Epoch 1128/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.1139e-05 - val_loss: 2.7399e-05\n",
      "Epoch 1129/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.1283e-05 - val_loss: 2.8009e-05\n",
      "Epoch 1130/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9885e-05 - val_loss: 2.8951e-05\n",
      "Epoch 1131/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9945e-05 - val_loss: 2.6610e-05\n",
      "Epoch 1132/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0233e-05 - val_loss: 3.3439e-05\n",
      "Epoch 1133/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0050e-05 - val_loss: 3.0847e-05\n",
      "Epoch 1134/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9207e-05 - val_loss: 2.8389e-05\n",
      "Epoch 1135/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.9431e-05 - val_loss: 3.6066e-05\n",
      "Epoch 1136/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3841e-05 - val_loss: 2.3953e-05\n",
      "Epoch 1137/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1148e-05 - val_loss: 3.1535e-05\n",
      "Epoch 1138/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0430e-05 - val_loss: 3.6632e-05\n",
      "Epoch 1139/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0542e-05 - val_loss: 3.4759e-05\n",
      "Epoch 1140/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1599e-05 - val_loss: 2.6348e-05\n",
      "Epoch 1141/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 2.1915e-05 - val_loss: 2.8800e-05\n",
      "Epoch 1142/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1077e-05 - val_loss: 3.4870e-05\n",
      "Epoch 1143/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0916e-05 - val_loss: 3.4966e-05\n",
      "Epoch 1144/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1381e-05 - val_loss: 3.4722e-05\n",
      "Epoch 1145/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0305e-05 - val_loss: 3.5130e-05\n",
      "Epoch 1146/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1733e-05 - val_loss: 3.0160e-05\n",
      "Epoch 1147/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0263e-05 - val_loss: 3.2137e-05\n",
      "Epoch 1148/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1135e-05 - val_loss: 2.8596e-05\n",
      "Epoch 1149/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.5176e-05 - val_loss: 3.4701e-05\n",
      "Epoch 1150/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1849e-05 - val_loss: 2.9151e-05\n",
      "Epoch 1151/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4163e-05 - val_loss: 3.3347e-05\n",
      "Epoch 1152/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 2.4292e-05 - val_loss: 3.3517e-05\n",
      "Epoch 1153/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.1362e-05 - val_loss: 4.3692e-05\n",
      "Epoch 1154/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.2655e-05 - val_loss: 2.9700e-05\n",
      "Epoch 1155/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0632e-05 - val_loss: 3.1100e-05\n",
      "Epoch 1156/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0276e-05 - val_loss: 3.5691e-05\n",
      "Epoch 1157/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0142e-05 - val_loss: 3.2670e-05\n",
      "Epoch 1158/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0738e-05 - val_loss: 3.1041e-05\n",
      "Epoch 1159/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.0005e-05 - val_loss: 3.0272e-05\n",
      "Epoch 1160/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0594e-05 - val_loss: 3.1919e-05\n",
      "Epoch 1161/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.9179e-05 - val_loss: 3.6467e-05\n",
      "Epoch 1162/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4625e-05 - val_loss: 3.2442e-05\n",
      "Epoch 1163/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1407e-05 - val_loss: 3.4177e-05\n",
      "Epoch 1164/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 2.1063e-05 - val_loss: 2.8531e-05\n",
      "Epoch 1165/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.0878e-05 - val_loss: 4.1124e-05\n",
      "Epoch 1166/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2113e-05 - val_loss: 3.9517e-05\n",
      "Epoch 1167/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2410e-05 - val_loss: 3.4072e-05\n",
      "Epoch 1168/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0834e-05 - val_loss: 3.3580e-05\n",
      "Epoch 1169/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0004e-05 - val_loss: 2.9107e-05\n",
      "Epoch 1170/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2964e-05 - val_loss: 3.1585e-05\n",
      "Epoch 1171/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2549e-05 - val_loss: 4.8086e-05\n",
      "Epoch 1172/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.1580e-05 - val_loss: 2.4714e-05\n",
      "Epoch 1173/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0726e-05 - val_loss: 2.9386e-05\n",
      "Epoch 1174/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2776e-05 - val_loss: 2.9318e-05\n",
      "Epoch 1175/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4374e-05 - val_loss: 2.5929e-05\n",
      "Epoch 1176/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 1.9994e-05 - val_loss: 4.1922e-05\n",
      "Epoch 1177/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1290e-05 - val_loss: 3.8841e-05\n",
      "Epoch 1178/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.0572e-05 - val_loss: 2.6486e-05\n",
      "Epoch 1179/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 1.9981e-05 - val_loss: 3.5441e-05\n",
      "Epoch 1180/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0546e-05 - val_loss: 3.2422e-05\n",
      "Epoch 1181/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0309e-05 - val_loss: 3.2391e-05\n",
      "Epoch 1182/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.2244e-05 - val_loss: 2.9958e-05\n",
      "Epoch 1183/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9952e-05 - val_loss: 2.5174e-05\n",
      "Epoch 1184/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0982e-05 - val_loss: 3.0161e-05\n",
      "Epoch 1185/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0128e-05 - val_loss: 2.6808e-05\n",
      "Epoch 1186/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0082e-05 - val_loss: 2.7009e-05\n",
      "Epoch 1187/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9832e-05 - val_loss: 3.4817e-05\n",
      "Epoch 1188/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 2.1324e-05 - val_loss: 3.1410e-05\n",
      "Epoch 1189/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9202e-05 - val_loss: 2.9104e-05\n",
      "Epoch 1190/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9820e-05 - val_loss: 4.1268e-05\n",
      "Epoch 1191/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.5938e-05 - val_loss: 2.5157e-05\n",
      "Epoch 1192/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1291e-05 - val_loss: 2.2030e-05\n",
      "Epoch 1193/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1314e-05 - val_loss: 2.6411e-05\n",
      "Epoch 1194/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1278e-05 - val_loss: 2.2541e-05\n",
      "Epoch 1195/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2590e-05 - val_loss: 2.5258e-05\n",
      "Epoch 1196/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1821e-05 - val_loss: 3.3937e-05\n",
      "Epoch 1197/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0915e-05 - val_loss: 3.9406e-05\n",
      "Epoch 1198/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9707e-05 - val_loss: 4.5372e-05\n",
      "Epoch 1199/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0159e-05 - val_loss: 3.9444e-05\n",
      "Epoch 1200/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 1.9616e-05 - val_loss: 4.2323e-05\n",
      "Epoch 1201/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1241e-05 - val_loss: 4.6457e-05\n",
      "Epoch 1202/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2566e-05 - val_loss: 3.1143e-05\n",
      "Epoch 1203/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.9995e-05 - val_loss: 4.1104e-05\n",
      "Epoch 1204/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3351e-05 - val_loss: 3.2603e-05\n",
      "Epoch 1205/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9371e-05 - val_loss: 3.7279e-05\n",
      "Epoch 1206/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4161e-05 - val_loss: 3.4750e-05\n",
      "Epoch 1207/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.4411e-05 - val_loss: 4.5861e-05\n",
      "Epoch 1208/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.1928e-05 - val_loss: 3.7114e-05\n",
      "Epoch 1209/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.2597e-05 - val_loss: 4.7375e-05\n",
      "Epoch 1210/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1154e-05 - val_loss: 3.4682e-05\n",
      "Epoch 1211/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0542e-05 - val_loss: 4.0934e-05\n",
      "Epoch 1212/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 2.1215e-05 - val_loss: 4.3397e-05\n",
      "Epoch 1213/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.2109e-05 - val_loss: 5.0358e-05\n",
      "Epoch 1214/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9967e-05 - val_loss: 4.1398e-05\n",
      "Epoch 1215/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.9570e-05 - val_loss: 3.9013e-05\n",
      "Epoch 1216/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.0209e-05 - val_loss: 4.0329e-05\n",
      "Epoch 1217/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9597e-05 - val_loss: 3.9778e-05\n",
      "Epoch 1218/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.0251e-05 - val_loss: 3.6585e-05\n",
      "Epoch 1219/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2581e-05 - val_loss: 3.6542e-05\n",
      "Epoch 1220/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1644e-05 - val_loss: 3.8199e-05\n",
      "Epoch 1221/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.3158e-05 - val_loss: 3.9934e-05\n",
      "Epoch 1222/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1574e-05 - val_loss: 3.1743e-05\n",
      "Epoch 1223/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1550e-05 - val_loss: 3.8084e-05\n",
      "Epoch 1224/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 2.2082e-05 - val_loss: 2.9316e-05\n",
      "Epoch 1225/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.2057e-05 - val_loss: 3.0554e-05\n",
      "Epoch 1226/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9920e-05 - val_loss: 3.7555e-05\n",
      "Epoch 1227/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.1398e-05 - val_loss: 3.5860e-05\n",
      "Epoch 1228/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.2029e-05 - val_loss: 4.9327e-05\n",
      "Epoch 1229/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.1153e-05 - val_loss: 3.6342e-05\n",
      "Epoch 1230/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2757e-05 - val_loss: 4.2349e-05\n",
      "Epoch 1231/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0695e-05 - val_loss: 2.8761e-05\n",
      "Epoch 1232/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.9112e-05 - val_loss: 4.0348e-05\n",
      "Epoch 1233/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4294e-05 - val_loss: 5.2200e-05\n",
      "Epoch 1234/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0750e-05 - val_loss: 5.1356e-05\n",
      "Epoch 1235/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0786e-05 - val_loss: 3.9588e-05\n",
      "Epoch 1236/2000\n",
      "18465/18465 [==============================] - 1s 76us/step - loss: 1.9855e-05 - val_loss: 3.6092e-05\n",
      "Epoch 1237/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0053e-05 - val_loss: 3.5110e-05\n",
      "Epoch 1238/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1469e-05 - val_loss: 3.3476e-05\n",
      "Epoch 1239/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9574e-05 - val_loss: 3.6263e-05\n",
      "Epoch 1240/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0074e-05 - val_loss: 4.5787e-05\n",
      "Epoch 1241/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.3605e-05 - val_loss: 2.7448e-05\n",
      "Epoch 1242/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1828e-05 - val_loss: 4.7352e-05\n",
      "Epoch 1243/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0813e-05 - val_loss: 3.7289e-05\n",
      "Epoch 1244/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0956e-05 - val_loss: 3.9615e-05\n",
      "Epoch 1245/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0223e-05 - val_loss: 4.5783e-05\n",
      "Epoch 1246/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2590e-05 - val_loss: 4.1015e-05\n",
      "Epoch 1247/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9632e-05 - val_loss: 3.7823e-05\n",
      "Epoch 1248/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 2.1013e-05 - val_loss: 4.8136e-05\n",
      "Epoch 1249/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1665e-05 - val_loss: 3.8339e-05\n",
      "Epoch 1250/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0432e-05 - val_loss: 4.1378e-05\n",
      "Epoch 1251/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.8921e-05 - val_loss: 3.9841e-05\n",
      "Epoch 1252/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.8690e-05 - val_loss: 4.2420e-05\n",
      "Epoch 1253/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0759e-05 - val_loss: 4.7933e-05\n",
      "Epoch 1254/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.0072e-05 - val_loss: 3.5828e-05\n",
      "Epoch 1255/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0139e-05 - val_loss: 3.5314e-05\n",
      "Epoch 1256/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.9334e-05 - val_loss: 3.4062e-05\n",
      "Epoch 1257/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1479e-05 - val_loss: 3.4674e-05\n",
      "Epoch 1258/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.9360e-05 - val_loss: 3.7386e-05\n",
      "Epoch 1259/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.0829e-05 - val_loss: 5.0363e-05\n",
      "Epoch 1260/2000\n",
      "18465/18465 [==============================] - 1s 77us/step - loss: 2.2777e-05 - val_loss: 4.1428e-05\n",
      "Epoch 1261/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.2938e-05 - val_loss: 3.9548e-05\n",
      "Epoch 1262/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0135e-05 - val_loss: 4.0649e-05\n",
      "Epoch 1263/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0878e-05 - val_loss: 4.3322e-05\n",
      "Epoch 1264/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.9224e-05 - val_loss: 5.8046e-05\n",
      "Epoch 1265/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.3610e-05 - val_loss: 3.9110e-05\n",
      "Epoch 1266/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0686e-05 - val_loss: 4.4231e-05\n",
      "Epoch 1267/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1922e-05 - val_loss: 4.0132e-05\n",
      "Epoch 1268/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.0412e-05 - val_loss: 3.2853e-05\n",
      "Epoch 1269/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1617e-05 - val_loss: 4.5507e-05\n",
      "Epoch 1270/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.0735e-05 - val_loss: 4.6163e-05\n",
      "Epoch 1271/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9175e-05 - val_loss: 4.1267e-05\n",
      "Epoch 1272/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 2.0196e-05 - val_loss: 4.4036e-05\n",
      "Epoch 1273/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.0571e-05 - val_loss: 4.6624e-05\n",
      "Epoch 1274/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0727e-05 - val_loss: 4.2095e-05\n",
      "Epoch 1275/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0441e-05 - val_loss: 4.6838e-05\n",
      "Epoch 1276/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0454e-05 - val_loss: 3.6359e-05\n",
      "Epoch 1277/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.8438e-05 - val_loss: 3.8913e-05\n",
      "Epoch 1278/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9222e-05 - val_loss: 5.0974e-05\n",
      "Epoch 1279/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.6958e-05 - val_loss: 4.7966e-05\n",
      "Epoch 1280/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.1944e-05 - val_loss: 3.2578e-05\n",
      "Epoch 1281/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0099e-05 - val_loss: 5.2222e-05\n",
      "Epoch 1282/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4052e-05 - val_loss: 3.6137e-05\n",
      "Epoch 1283/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9851e-05 - val_loss: 3.5247e-05\n",
      "Epoch 1284/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 2.0590e-05 - val_loss: 3.9772e-05\n",
      "Epoch 1285/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.9797e-05 - val_loss: 4.3779e-05\n",
      "Epoch 1286/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0442e-05 - val_loss: 4.0539e-05\n",
      "Epoch 1287/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0532e-05 - val_loss: 3.7104e-05\n",
      "Epoch 1288/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0507e-05 - val_loss: 4.0739e-05\n",
      "Epoch 1289/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0603e-05 - val_loss: 4.9591e-05\n",
      "Epoch 1290/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1004e-05 - val_loss: 3.3767e-05\n",
      "Epoch 1291/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0375e-05 - val_loss: 4.5652e-05\n",
      "Epoch 1292/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.0653e-05 - val_loss: 3.6761e-05\n",
      "Epoch 1293/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.9405e-05 - val_loss: 4.7680e-05\n",
      "Epoch 1294/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.0704e-05 - val_loss: 2.9524e-05\n",
      "Epoch 1295/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9482e-05 - val_loss: 3.6282e-05\n",
      "Epoch 1296/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 2.2168e-05 - val_loss: 4.2653e-05\n",
      "Epoch 1297/2000\n",
      "18465/18465 [==============================] - ETA: 0s - loss: 2.2844e-0 - 1s 76us/step - loss: 2.3008e-05 - val_loss: 4.8531e-05\n",
      "Epoch 1298/2000\n",
      "18465/18465 [==============================] - 1s 78us/step - loss: 2.1254e-05 - val_loss: 5.6317e-05\n",
      "Epoch 1299/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.4446e-05 - val_loss: 3.3088e-05\n",
      "Epoch 1300/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4925e-05 - val_loss: 4.1513e-05\n",
      "Epoch 1301/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.2164e-05 - val_loss: 4.1543e-05\n",
      "Epoch 1302/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.1232e-05 - val_loss: 3.3784e-05\n",
      "Epoch 1303/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0760e-05 - val_loss: 3.4251e-05\n",
      "Epoch 1304/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.1234e-05 - val_loss: 3.9348e-05\n",
      "Epoch 1305/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2750e-05 - val_loss: 3.3329e-05\n",
      "Epoch 1306/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2257e-05 - val_loss: 3.7532e-05\n",
      "Epoch 1307/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.5156e-05 - val_loss: 3.7689e-05\n",
      "Epoch 1308/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 2.4651e-05 - val_loss: 4.2887e-05\n",
      "Epoch 1309/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 6.8284e-05 - val_loss: 5.7079e-05\n",
      "Epoch 1310/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.4314e-05 - val_loss: 3.1511e-05\n",
      "Epoch 1311/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3278e-05 - val_loss: 3.2086e-05\n",
      "Epoch 1312/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.6972e-05 - val_loss: 2.8982e-05\n",
      "Epoch 1313/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.2764e-05 - val_loss: 3.7819e-05\n",
      "Epoch 1314/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0932e-05 - val_loss: 4.3569e-05\n",
      "Epoch 1315/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 1.9026e-05 - val_loss: 3.8073e-05\n",
      "Epoch 1316/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.1206e-05 - val_loss: 3.0123e-05\n",
      "Epoch 1317/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.0237e-05 - val_loss: 2.5238e-05\n",
      "Epoch 1318/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.0293e-05 - val_loss: 2.3463e-05\n",
      "Epoch 1319/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9203e-05 - val_loss: 2.5191e-05\n",
      "Epoch 1320/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 2.0812e-05 - val_loss: 2.7764e-05\n",
      "Epoch 1321/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.0599e-05 - val_loss: 3.2744e-05\n",
      "Epoch 1322/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2357e-05 - val_loss: 2.5431e-05\n",
      "Epoch 1323/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.0225e-05 - val_loss: 2.6642e-05\n",
      "Epoch 1324/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.9412e-05 - val_loss: 2.7540e-05\n",
      "Epoch 1325/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.9130e-05 - val_loss: 2.3367e-05\n",
      "Epoch 1326/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0329e-05 - val_loss: 2.4981e-05\n",
      "Epoch 1327/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9402e-05 - val_loss: 2.5629e-05\n",
      "Epoch 1328/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0944e-05 - val_loss: 2.6344e-05\n",
      "Epoch 1329/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.1092e-05 - val_loss: 3.2234e-05\n",
      "Epoch 1330/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1099e-05 - val_loss: 3.3022e-05\n",
      "Epoch 1331/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.1970e-05 - val_loss: 2.5285e-05\n",
      "Epoch 1332/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 2.1931e-05 - val_loss: 3.2043e-05\n",
      "Epoch 1333/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1085e-05 - val_loss: 3.0713e-05\n",
      "Epoch 1334/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0676e-05 - val_loss: 6.4688e-05\n",
      "Epoch 1335/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 4.8281e-05 - val_loss: 3.3622e-05\n",
      "Epoch 1336/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4267e-05 - val_loss: 1.6930e-05\n",
      "Epoch 1337/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.0673e-05 - val_loss: 4.5935e-05\n",
      "Epoch 1338/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9551e-05 - val_loss: 2.9190e-05\n",
      "Epoch 1339/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0039e-05 - val_loss: 3.3426e-05\n",
      "Epoch 1340/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1246e-05 - val_loss: 2.7229e-05\n",
      "Epoch 1341/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.1420e-05 - val_loss: 2.4918e-05\n",
      "Epoch 1342/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.1910e-05 - val_loss: 2.8894e-05\n",
      "Epoch 1343/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.9731e-05 - val_loss: 3.1743e-05\n",
      "Epoch 1344/2000\n",
      "18465/18465 [==============================] - 1s 76us/step - loss: 2.1173e-05 - val_loss: 2.9492e-05\n",
      "Epoch 1345/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.8507e-05 - val_loss: 3.3699e-05\n",
      "Epoch 1346/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.0444e-05 - val_loss: 3.7173e-05\n",
      "Epoch 1347/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.9744e-05 - val_loss: 2.8897e-05\n",
      "Epoch 1348/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1663e-05 - val_loss: 2.7116e-05\n",
      "Epoch 1349/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0763e-05 - val_loss: 3.4395e-05\n",
      "Epoch 1350/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0561e-05 - val_loss: 3.0668e-05\n",
      "Epoch 1351/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9988e-05 - val_loss: 3.0955e-05\n",
      "Epoch 1352/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9454e-05 - val_loss: 3.0211e-05\n",
      "Epoch 1353/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9754e-05 - val_loss: 3.9413e-05\n",
      "Epoch 1354/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.0300e-05 - val_loss: 3.1161e-05\n",
      "Epoch 1355/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0142e-05 - val_loss: 3.3987e-05\n",
      "Epoch 1356/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 1.9958e-05 - val_loss: 2.9065e-05\n",
      "Epoch 1357/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9575e-05 - val_loss: 2.8883e-05\n",
      "Epoch 1358/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 1.9672e-05 - val_loss: 3.6628e-05\n",
      "Epoch 1359/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0981e-05 - val_loss: 2.4738e-05\n",
      "Epoch 1360/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9942e-05 - val_loss: 2.3911e-05\n",
      "Epoch 1361/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0029e-05 - val_loss: 2.9542e-05\n",
      "Epoch 1362/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.8690e-05 - val_loss: 3.5610e-05\n",
      "Epoch 1363/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0249e-05 - val_loss: 2.5345e-05\n",
      "Epoch 1364/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.0194e-05 - val_loss: 2.7758e-05\n",
      "Epoch 1365/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9862e-05 - val_loss: 3.3115e-05\n",
      "Epoch 1366/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.0073e-05 - val_loss: 2.8146e-05\n",
      "Epoch 1367/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0707e-05 - val_loss: 2.2449e-05\n",
      "Epoch 1368/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 1.9273e-05 - val_loss: 2.3497e-05\n",
      "Epoch 1369/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9523e-05 - val_loss: 2.7852e-05\n",
      "Epoch 1370/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1138e-05 - val_loss: 2.9415e-05\n",
      "Epoch 1371/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9715e-05 - val_loss: 2.7739e-05\n",
      "Epoch 1372/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0667e-05 - val_loss: 2.8499e-05\n",
      "Epoch 1373/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.0800e-05 - val_loss: 3.4544e-05\n",
      "Epoch 1374/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.0589e-05 - val_loss: 2.2709e-05\n",
      "Epoch 1375/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0323e-05 - val_loss: 3.1838e-05\n",
      "Epoch 1376/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.9693e-05 - val_loss: 3.3032e-05\n",
      "Epoch 1377/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0299e-05 - val_loss: 3.1354e-05\n",
      "Epoch 1378/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.9699e-05 - val_loss: 2.4466e-05\n",
      "Epoch 1379/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0733e-05 - val_loss: 2.5631e-05\n",
      "Epoch 1380/2000\n",
      "18465/18465 [==============================] - 1s 76us/step - loss: 1.9931e-05 - val_loss: 2.9738e-05\n",
      "Epoch 1381/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0569e-05 - val_loss: 3.1060e-05\n",
      "Epoch 1382/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0536e-05 - val_loss: 2.7404e-05\n",
      "Epoch 1383/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0764e-05 - val_loss: 3.1496e-05\n",
      "Epoch 1384/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.0491e-05 - val_loss: 2.9938e-05\n",
      "Epoch 1385/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9601e-05 - val_loss: 2.4527e-05\n",
      "Epoch 1386/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1422e-05 - val_loss: 3.0176e-05\n",
      "Epoch 1387/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0678e-05 - val_loss: 2.6641e-05\n",
      "Epoch 1388/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9486e-05 - val_loss: 2.6036e-05\n",
      "Epoch 1389/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.8749e-05 - val_loss: 2.6069e-05\n",
      "Epoch 1390/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.9174e-05 - val_loss: 2.5950e-05\n",
      "Epoch 1391/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1515e-05 - val_loss: 3.8082e-05\n",
      "Epoch 1392/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 2.0661e-05 - val_loss: 2.9162e-05\n",
      "Epoch 1393/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.0496e-05 - val_loss: 3.9942e-05\n",
      "Epoch 1394/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9547e-05 - val_loss: 3.8701e-05\n",
      "Epoch 1395/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.0317e-05 - val_loss: 3.0033e-05\n",
      "Epoch 1396/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4936e-05 - val_loss: 3.1485e-05\n",
      "Epoch 1397/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0124e-05 - val_loss: 3.0899e-05\n",
      "Epoch 1398/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.1739e-05 - val_loss: 3.0650e-05\n",
      "Epoch 1399/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9585e-05 - val_loss: 2.5773e-05\n",
      "Epoch 1400/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0109e-05 - val_loss: 2.9843e-05\n",
      "Epoch 1401/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9446e-05 - val_loss: 2.8553e-05\n",
      "Epoch 1402/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2745e-05 - val_loss: 2.9218e-05\n",
      "Epoch 1403/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3170e-05 - val_loss: 2.8216e-05\n",
      "Epoch 1404/2000\n",
      "18465/18465 [==============================] - 1s 76us/step - loss: 2.0241e-05 - val_loss: 2.9655e-05\n",
      "Epoch 1405/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.8874e-05 - val_loss: 2.6670e-05\n",
      "Epoch 1406/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9340e-05 - val_loss: 2.6110e-05\n",
      "Epoch 1407/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 1.9552e-05 - val_loss: 2.7456e-05\n",
      "Epoch 1408/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 1.8961e-05 - val_loss: 2.5552e-05\n",
      "Epoch 1409/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9083e-05 - val_loss: 2.4930e-05\n",
      "Epoch 1410/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9893e-05 - val_loss: 3.1245e-05\n",
      "Epoch 1411/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.2618e-05 - val_loss: 2.9246e-05\n",
      "Epoch 1412/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.9327e-05 - val_loss: 3.9516e-05\n",
      "Epoch 1413/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.8617e-05 - val_loss: 6.1456e-05\n",
      "Epoch 1414/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0784e-05 - val_loss: 2.0829e-05\n",
      "Epoch 1415/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9544e-05 - val_loss: 2.4122e-05\n",
      "Epoch 1416/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 1.9263e-05 - val_loss: 3.3333e-05\n",
      "Epoch 1417/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1927e-05 - val_loss: 1.6068e-05\n",
      "Epoch 1418/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9089e-05 - val_loss: 1.7768e-05\n",
      "Epoch 1419/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9257e-05 - val_loss: 1.9710e-05\n",
      "Epoch 1420/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.0174e-05 - val_loss: 2.6659e-05\n",
      "Epoch 1421/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0122e-05 - val_loss: 2.0854e-05\n",
      "Epoch 1422/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9038e-05 - val_loss: 2.2976e-05\n",
      "Epoch 1423/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9655e-05 - val_loss: 2.1860e-05\n",
      "Epoch 1424/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.1508e-05 - val_loss: 2.8025e-05\n",
      "Epoch 1425/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1015e-05 - val_loss: 2.7429e-05\n",
      "Epoch 1426/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9305e-05 - val_loss: 3.0514e-05\n",
      "Epoch 1427/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0198e-05 - val_loss: 2.8644e-05\n",
      "Epoch 1428/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 2.0916e-05 - val_loss: 2.3335e-05\n",
      "Epoch 1429/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9012e-05 - val_loss: 3.0867e-05\n",
      "Epoch 1430/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.8998e-05 - val_loss: 2.3524e-05\n",
      "Epoch 1431/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.0339e-05 - val_loss: 2.5633e-05\n",
      "Epoch 1432/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.9281e-05 - val_loss: 3.1843e-05\n",
      "Epoch 1433/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.8326e-05 - val_loss: 3.2352e-05\n",
      "Epoch 1434/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0435e-05 - val_loss: 2.1345e-05\n",
      "Epoch 1435/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.0415e-05 - val_loss: 3.2336e-05\n",
      "Epoch 1436/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.5055e-05 - val_loss: 2.2836e-05\n",
      "Epoch 1437/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0710e-05 - val_loss: 2.4881e-05\n",
      "Epoch 1438/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9873e-05 - val_loss: 2.8120e-05\n",
      "Epoch 1439/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.5682e-05 - val_loss: 1.8460e-05\n",
      "Epoch 1440/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 2.0812e-05 - val_loss: 3.6352e-05\n",
      "Epoch 1441/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.2646e-05 - val_loss: 2.3766e-05\n",
      "Epoch 1442/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0589e-05 - val_loss: 2.2397e-05\n",
      "Epoch 1443/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1873e-05 - val_loss: 2.0352e-05\n",
      "Epoch 1444/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.0506e-05 - val_loss: 2.3036e-05\n",
      "Epoch 1445/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.0224e-05 - val_loss: 2.2258e-05\n",
      "Epoch 1446/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9857e-05 - val_loss: 2.2620e-05\n",
      "Epoch 1447/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.9455e-05 - val_loss: 2.8980e-05\n",
      "Epoch 1448/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9275e-05 - val_loss: 3.0594e-05\n",
      "Epoch 1449/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.6322e-05 - val_loss: 3.1126e-05\n",
      "Epoch 1450/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0282e-05 - val_loss: 3.1573e-05\n",
      "Epoch 1451/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9341e-05 - val_loss: 3.1902e-05\n",
      "Epoch 1452/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 1.9707e-05 - val_loss: 3.2996e-05\n",
      "Epoch 1453/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9659e-05 - val_loss: 2.7900e-05\n",
      "Epoch 1454/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9295e-05 - val_loss: 2.6395e-05\n",
      "Epoch 1455/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9088e-05 - val_loss: 2.7912e-05\n",
      "Epoch 1456/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0303e-05 - val_loss: 2.0986e-05\n",
      "Epoch 1457/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0902e-05 - val_loss: 2.3812e-05\n",
      "Epoch 1458/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0794e-05 - val_loss: 2.7558e-05\n",
      "Epoch 1459/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2095e-05 - val_loss: 3.5607e-05\n",
      "Epoch 1460/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2360e-05 - val_loss: 4.7253e-05\n",
      "Epoch 1461/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1503e-05 - val_loss: 3.6541e-05\n",
      "Epoch 1462/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0752e-05 - val_loss: 3.7998e-05\n",
      "Epoch 1463/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0488e-05 - val_loss: 2.8699e-05\n",
      "Epoch 1464/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 1.8575e-05 - val_loss: 3.9763e-05\n",
      "Epoch 1465/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1122e-05 - val_loss: 3.3544e-05\n",
      "Epoch 1466/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.0512e-05 - val_loss: 3.7806e-05\n",
      "Epoch 1467/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.6722e-05 - val_loss: 4.4417e-05\n",
      "Epoch 1468/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1520e-05 - val_loss: 2.3388e-05\n",
      "Epoch 1469/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0305e-05 - val_loss: 2.6126e-05\n",
      "Epoch 1470/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1096e-05 - val_loss: 2.0793e-05\n",
      "Epoch 1471/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0443e-05 - val_loss: 2.3360e-05\n",
      "Epoch 1472/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0154e-05 - val_loss: 2.4368e-05\n",
      "Epoch 1473/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0801e-05 - val_loss: 2.9836e-05\n",
      "Epoch 1474/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9896e-05 - val_loss: 2.5441e-05\n",
      "Epoch 1475/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.0182e-05 - val_loss: 2.8538e-05\n",
      "Epoch 1476/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 2.2403e-05 - val_loss: 2.3485e-05\n",
      "Epoch 1477/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0546e-05 - val_loss: 3.0694e-05\n",
      "Epoch 1478/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1065e-05 - val_loss: 2.0759e-05\n",
      "Epoch 1479/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9862e-05 - val_loss: 2.9015e-05\n",
      "Epoch 1480/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.0073e-05 - val_loss: 2.0741e-05\n",
      "Epoch 1481/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0376e-05 - val_loss: 2.2607e-05\n",
      "Epoch 1482/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.0121e-05 - val_loss: 3.4656e-05\n",
      "Epoch 1483/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0786e-05 - val_loss: 2.5194e-05\n",
      "Epoch 1484/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.8611e-05 - val_loss: 2.5984e-05\n",
      "Epoch 1485/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.9461e-05 - val_loss: 2.4924e-05\n",
      "Epoch 1486/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 1.9418e-05 - val_loss: 3.0881e-05\n",
      "Epoch 1487/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.2342e-05 - val_loss: 2.6499e-05\n",
      "Epoch 1488/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 2.0824e-05 - val_loss: 2.3069e-05\n",
      "Epoch 1489/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.8869e-05 - val_loss: 2.9605e-05\n",
      "Epoch 1490/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.2086e-05 - val_loss: 2.7161e-05\n",
      "Epoch 1491/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9568e-05 - val_loss: 1.8807e-05\n",
      "Epoch 1492/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.8870e-05 - val_loss: 2.0849e-05\n",
      "Epoch 1493/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 1.9616e-05 - val_loss: 2.1266e-05\n",
      "Epoch 1494/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 1.9001e-05 - val_loss: 2.7465e-05\n",
      "Epoch 1495/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.8385e-05 - val_loss: 3.3093e-05\n",
      "Epoch 1496/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.1921e-05 - val_loss: 2.6603e-05\n",
      "Epoch 1497/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9618e-05 - val_loss: 2.3933e-05\n",
      "Epoch 1498/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9153e-05 - val_loss: 2.3669e-05\n",
      "Epoch 1499/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 1.8996e-05 - val_loss: 2.3757e-05\n",
      "Epoch 1500/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 1.9633e-05 - val_loss: 2.4961e-05\n",
      "Epoch 1501/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.8790e-05 - val_loss: 2.4284e-05\n",
      "Epoch 1502/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.8784e-05 - val_loss: 2.2996e-05\n",
      "Epoch 1503/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9868e-05 - val_loss: 2.2969e-05\n",
      "Epoch 1504/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0455e-05 - val_loss: 2.3711e-05\n",
      "Epoch 1505/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 1.9665e-05 - val_loss: 2.3770e-05\n",
      "Epoch 1506/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9313e-05 - val_loss: 2.2116e-05\n",
      "Epoch 1507/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9422e-05 - val_loss: 2.0517e-05\n",
      "Epoch 1508/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.1328e-05 - val_loss: 3.0719e-05\n",
      "Epoch 1509/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1607e-05 - val_loss: 5.7256e-05\n",
      "Epoch 1510/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0291e-05 - val_loss: 2.1679e-05\n",
      "Epoch 1511/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 1.8997e-05 - val_loss: 2.1853e-05\n",
      "Epoch 1512/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 1.9095e-05 - val_loss: 2.6983e-05\n",
      "Epoch 1513/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0776e-05 - val_loss: 2.4371e-05\n",
      "Epoch 1514/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9492e-05 - val_loss: 2.1524e-05\n",
      "Epoch 1515/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0653e-05 - val_loss: 3.6734e-05\n",
      "Epoch 1516/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.0645e-05 - val_loss: 2.3488e-05\n",
      "Epoch 1517/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9006e-05 - val_loss: 2.1242e-05\n",
      "Epoch 1518/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0328e-05 - val_loss: 2.4108e-05\n",
      "Epoch 1519/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9461e-05 - val_loss: 3.2104e-05\n",
      "Epoch 1520/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0013e-05 - val_loss: 2.1213e-05\n",
      "Epoch 1521/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0981e-05 - val_loss: 2.1812e-05\n",
      "Epoch 1522/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1710e-05 - val_loss: 2.3610e-05\n",
      "Epoch 1523/2000\n",
      "18465/18465 [==============================] - 1s 76us/step - loss: 1.9477e-05 - val_loss: 2.1799e-05\n",
      "Epoch 1524/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 1.7859e-05 - val_loss: 4.4163e-05\n",
      "Epoch 1525/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.5667e-05 - val_loss: 3.2115e-05\n",
      "Epoch 1526/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1338e-05 - val_loss: 2.4418e-05\n",
      "Epoch 1527/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9714e-05 - val_loss: 2.4986e-05\n",
      "Epoch 1528/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9071e-05 - val_loss: 2.8572e-05\n",
      "Epoch 1529/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.0704e-05 - val_loss: 2.3288e-05\n",
      "Epoch 1530/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0128e-05 - val_loss: 2.7757e-05\n",
      "Epoch 1531/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2188e-05 - val_loss: 2.6081e-05\n",
      "Epoch 1532/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2940e-05 - val_loss: 2.5476e-05\n",
      "Epoch 1533/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0615e-05 - val_loss: 2.5111e-05\n",
      "Epoch 1534/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9700e-05 - val_loss: 2.2332e-05\n",
      "Epoch 1535/2000\n",
      "18465/18465 [==============================] - ETA: 0s - loss: 1.9504e-0 - 1s 75us/step - loss: 1.9415e-05 - val_loss: 2.3794e-05\n",
      "Epoch 1536/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9696e-05 - val_loss: 2.1526e-05\n",
      "Epoch 1537/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.0710e-05 - val_loss: 2.2731e-05\n",
      "Epoch 1538/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9787e-05 - val_loss: 2.6605e-05\n",
      "Epoch 1539/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9047e-05 - val_loss: 2.5860e-05\n",
      "Epoch 1540/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9481e-05 - val_loss: 2.3985e-05\n",
      "Epoch 1541/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9620e-05 - val_loss: 2.5262e-05\n",
      "Epoch 1542/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9849e-05 - val_loss: 2.2272e-05\n",
      "Epoch 1543/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.8269e-05 - val_loss: 2.3319e-05\n",
      "Epoch 1544/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0508e-05 - val_loss: 2.0784e-05\n",
      "Epoch 1545/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.8930e-05 - val_loss: 2.1388e-05\n",
      "Epoch 1546/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0357e-05 - val_loss: 2.4251e-05\n",
      "Epoch 1547/2000\n",
      "18465/18465 [==============================] - 1s 76us/step - loss: 1.9719e-05 - val_loss: 2.2075e-05\n",
      "Epoch 1548/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.0236e-05 - val_loss: 2.0581e-05\n",
      "Epoch 1549/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9856e-05 - val_loss: 2.1560e-05\n",
      "Epoch 1550/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0726e-05 - val_loss: 3.7851e-05\n",
      "Epoch 1551/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4705e-05 - val_loss: 3.0384e-05\n",
      "Epoch 1552/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2003e-05 - val_loss: 2.5734e-05\n",
      "Epoch 1553/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.0489e-05 - val_loss: 2.7142e-05\n",
      "Epoch 1554/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0720e-05 - val_loss: 4.6983e-05\n",
      "Epoch 1555/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.6808e-05 - val_loss: 3.1899e-05\n",
      "Epoch 1556/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1853e-05 - val_loss: 1.9005e-05\n",
      "Epoch 1557/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2094e-05 - val_loss: 4.2379e-05\n",
      "Epoch 1558/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 4.5081e-05 - val_loss: 5.6056e-05\n",
      "Epoch 1559/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 3.0726e-05 - val_loss: 3.6283e-05\n",
      "Epoch 1560/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.5793e-05 - val_loss: 2.3462e-05\n",
      "Epoch 1561/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2257e-05 - val_loss: 4.7679e-05\n",
      "Epoch 1562/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4066e-05 - val_loss: 5.0474e-05\n",
      "Epoch 1563/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0966e-05 - val_loss: 5.4592e-05\n",
      "Epoch 1564/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.2321e-05 - val_loss: 4.5991e-05\n",
      "Epoch 1565/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2786e-05 - val_loss: 5.3615e-05\n",
      "Epoch 1566/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 4.8692e-05 - val_loss: 4.7270e-05\n",
      "Epoch 1567/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2518e-05 - val_loss: 4.8406e-05\n",
      "Epoch 1568/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2695e-05 - val_loss: 2.2504e-05\n",
      "Epoch 1569/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0404e-05 - val_loss: 2.2266e-05\n",
      "Epoch 1570/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.1669e-05 - val_loss: 2.2299e-05\n",
      "Epoch 1571/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 2.2229e-05 - val_loss: 5.0100e-05\n",
      "Epoch 1572/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.5321e-05 - val_loss: 2.8429e-05\n",
      "Epoch 1573/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2737e-05 - val_loss: 2.4904e-05\n",
      "Epoch 1574/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2597e-05 - val_loss: 2.7290e-05\n",
      "Epoch 1575/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.1451e-05 - val_loss: 3.1555e-05\n",
      "Epoch 1576/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1735e-05 - val_loss: 3.4409e-05\n",
      "Epoch 1577/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9903e-05 - val_loss: 3.0487e-05\n",
      "Epoch 1578/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1163e-05 - val_loss: 3.3493e-05\n",
      "Epoch 1579/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0009e-05 - val_loss: 3.7278e-05\n",
      "Epoch 1580/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1130e-05 - val_loss: 3.1938e-05\n",
      "Epoch 1581/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.0132e-05 - val_loss: 3.7582e-05\n",
      "Epoch 1582/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.9898e-05 - val_loss: 3.5384e-05\n",
      "Epoch 1583/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 1.9843e-05 - val_loss: 3.7267e-05\n",
      "Epoch 1584/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0167e-05 - val_loss: 3.7047e-05\n",
      "Epoch 1585/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0269e-05 - val_loss: 3.7185e-05\n",
      "Epoch 1586/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0703e-05 - val_loss: 2.9795e-05\n",
      "Epoch 1587/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0419e-05 - val_loss: 3.2913e-05\n",
      "Epoch 1588/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9835e-05 - val_loss: 3.1026e-05\n",
      "Epoch 1589/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.9858e-05 - val_loss: 3.8935e-05\n",
      "Epoch 1590/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1886e-05 - val_loss: 3.6863e-05\n",
      "Epoch 1591/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0643e-05 - val_loss: 4.1505e-05\n",
      "Epoch 1592/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9407e-05 - val_loss: 2.9721e-05\n",
      "Epoch 1593/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.0299e-05 - val_loss: 5.7420e-05\n",
      "Epoch 1594/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3129e-05 - val_loss: 3.4943e-05\n",
      "Epoch 1595/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 2.0067e-05 - val_loss: 3.9754e-05\n",
      "Epoch 1596/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.7532e-05 - val_loss: 4.9843e-05\n",
      "Epoch 1597/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.1063e-05 - val_loss: 2.9069e-05\n",
      "Epoch 1598/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.2392e-05 - val_loss: 3.6003e-05\n",
      "Epoch 1599/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4374e-05 - val_loss: 2.3889e-05\n",
      "Epoch 1600/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9876e-05 - val_loss: 2.5513e-05\n",
      "Epoch 1601/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.9509e-05 - val_loss: 2.5146e-05\n",
      "Epoch 1602/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9340e-05 - val_loss: 2.4345e-05\n",
      "Epoch 1603/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9932e-05 - val_loss: 2.4466e-05\n",
      "Epoch 1604/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9764e-05 - val_loss: 2.3158e-05\n",
      "Epoch 1605/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0759e-05 - val_loss: 2.6624e-05\n",
      "Epoch 1606/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0416e-05 - val_loss: 2.4989e-05\n",
      "Epoch 1607/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 2.1935e-05 - val_loss: 3.2137e-05\n",
      "Epoch 1608/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9951e-05 - val_loss: 2.7849e-05\n",
      "Epoch 1609/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0742e-05 - val_loss: 2.7173e-05\n",
      "Epoch 1610/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9386e-05 - val_loss: 3.1528e-05\n",
      "Epoch 1611/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9996e-05 - val_loss: 2.5968e-05\n",
      "Epoch 1612/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.0351e-05 - val_loss: 3.1395e-05\n",
      "Epoch 1613/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0824e-05 - val_loss: 3.2580e-05\n",
      "Epoch 1614/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0031e-05 - val_loss: 2.4560e-05\n",
      "Epoch 1615/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9197e-05 - val_loss: 2.1708e-05\n",
      "Epoch 1616/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9090e-05 - val_loss: 2.6007e-05\n",
      "Epoch 1617/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0550e-05 - val_loss: 2.2595e-05\n",
      "Epoch 1618/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0843e-05 - val_loss: 2.5728e-05\n",
      "Epoch 1619/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 1.9498e-05 - val_loss: 2.3506e-05\n",
      "Epoch 1620/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9055e-05 - val_loss: 3.0151e-05\n",
      "Epoch 1621/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0712e-05 - val_loss: 4.0525e-05\n",
      "Epoch 1622/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.1192e-05 - val_loss: 3.2128e-05\n",
      "Epoch 1623/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9970e-05 - val_loss: 2.7103e-05\n",
      "Epoch 1624/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2065e-05 - val_loss: 2.6838e-05\n",
      "Epoch 1625/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1487e-05 - val_loss: 3.0475e-05\n",
      "Epoch 1626/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.9273e-05 - val_loss: 2.5802e-05\n",
      "Epoch 1627/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9554e-05 - val_loss: 2.5163e-05\n",
      "Epoch 1628/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.1317e-05 - val_loss: 2.4305e-05\n",
      "Epoch 1629/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.9938e-05 - val_loss: 2.6924e-05\n",
      "Epoch 1630/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9920e-05 - val_loss: 2.8397e-05\n",
      "Epoch 1631/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 1.9398e-05 - val_loss: 2.5667e-05\n",
      "Epoch 1632/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.0099e-05 - val_loss: 3.3410e-05\n",
      "Epoch 1633/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.9938e-05 - val_loss: 2.8109e-05\n",
      "Epoch 1634/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9482e-05 - val_loss: 2.8348e-05\n",
      "Epoch 1635/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9984e-05 - val_loss: 2.5979e-05\n",
      "Epoch 1636/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.1416e-05 - val_loss: 3.2426e-05\n",
      "Epoch 1637/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0972e-05 - val_loss: 3.5617e-05\n",
      "Epoch 1638/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 1.9114e-05 - val_loss: 3.2970e-05\n",
      "Epoch 1639/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1926e-05 - val_loss: 1.9095e-05\n",
      "Epoch 1640/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3629e-05 - val_loss: 3.1563e-05\n",
      "Epoch 1641/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1395e-05 - val_loss: 3.2336e-05\n",
      "Epoch 1642/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 2.1164e-05 - val_loss: 3.2047e-05\n",
      "Epoch 1643/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 2.1333e-05 - val_loss: 4.5170e-05\n",
      "Epoch 1644/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.9850e-05 - val_loss: 2.7528e-05\n",
      "Epoch 1645/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.8696e-05 - val_loss: 2.4824e-05\n",
      "Epoch 1646/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1765e-05 - val_loss: 3.8853e-05\n",
      "Epoch 1647/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.0048e-05 - val_loss: 3.1069e-05\n",
      "Epoch 1648/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1559e-05 - val_loss: 2.5374e-05\n",
      "Epoch 1649/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1458e-05 - val_loss: 2.8423e-05\n",
      "Epoch 1650/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.9583e-05 - val_loss: 4.2379e-05\n",
      "Epoch 1651/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9712e-05 - val_loss: 3.0085e-05\n",
      "Epoch 1652/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9813e-05 - val_loss: 3.6760e-05\n",
      "Epoch 1653/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9965e-05 - val_loss: 2.6198e-05\n",
      "Epoch 1654/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 1.9825e-05 - val_loss: 2.6241e-05\n",
      "Epoch 1655/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 1.9643e-05 - val_loss: 3.5144e-05\n",
      "Epoch 1656/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 1.9780e-05 - val_loss: 3.2413e-05\n",
      "Epoch 1657/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9326e-05 - val_loss: 3.2662e-05\n",
      "Epoch 1658/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9071e-05 - val_loss: 3.1543e-05\n",
      "Epoch 1659/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.0039e-05 - val_loss: 2.6852e-05\n",
      "Epoch 1660/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9330e-05 - val_loss: 2.8223e-05\n",
      "Epoch 1661/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9377e-05 - val_loss: 3.3740e-05\n",
      "Epoch 1662/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1409e-05 - val_loss: 3.7009e-05\n",
      "Epoch 1663/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0153e-05 - val_loss: 3.0465e-05\n",
      "Epoch 1664/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 1.9891e-05 - val_loss: 3.1973e-05\n",
      "Epoch 1665/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9621e-05 - val_loss: 3.9819e-05\n",
      "Epoch 1666/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9915e-05 - val_loss: 4.4163e-05\n",
      "Epoch 1667/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 2.2056e-05 - val_loss: 2.9648e-05\n",
      "Epoch 1668/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1190e-05 - val_loss: 2.5843e-05\n",
      "Epoch 1669/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.8887e-05 - val_loss: 3.3119e-05\n",
      "Epoch 1670/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9865e-05 - val_loss: 3.3971e-05\n",
      "Epoch 1671/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3380e-05 - val_loss: 1.7018e-05\n",
      "Epoch 1672/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0629e-05 - val_loss: 4.6922e-05\n",
      "Epoch 1673/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9177e-05 - val_loss: 4.1627e-05\n",
      "Epoch 1674/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9162e-05 - val_loss: 4.4552e-05\n",
      "Epoch 1675/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.0511e-05 - val_loss: 1.6282e-05\n",
      "Epoch 1676/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1077e-05 - val_loss: 3.5031e-05\n",
      "Epoch 1677/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0828e-05 - val_loss: 4.1142e-05\n",
      "Epoch 1678/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0177e-05 - val_loss: 4.6255e-05\n",
      "Epoch 1679/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 2.2581e-05 - val_loss: 5.2063e-05\n",
      "Epoch 1680/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2199e-05 - val_loss: 3.4840e-05\n",
      "Epoch 1681/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1228e-05 - val_loss: 4.2536e-05\n",
      "Epoch 1682/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9409e-05 - val_loss: 3.4620e-05\n",
      "Epoch 1683/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9318e-05 - val_loss: 3.8950e-05\n",
      "Epoch 1684/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0793e-05 - val_loss: 4.8940e-05\n",
      "Epoch 1685/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1502e-05 - val_loss: 3.7069e-05\n",
      "Epoch 1686/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.8465e-05 - val_loss: 4.0564e-05\n",
      "Epoch 1687/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9664e-05 - val_loss: 7.8522e-05\n",
      "Epoch 1688/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 3.2986e-05 - val_loss: 3.7905e-05\n",
      "Epoch 1689/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0458e-05 - val_loss: 3.8414e-05\n",
      "Epoch 1690/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0357e-05 - val_loss: 3.3538e-05\n",
      "Epoch 1691/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 1.9486e-05 - val_loss: 3.5165e-05\n",
      "Epoch 1692/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9242e-05 - val_loss: 3.0959e-05\n",
      "Epoch 1693/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.8318e-05 - val_loss: 2.5840e-05\n",
      "Epoch 1694/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.0874e-05 - val_loss: 5.1852e-05\n",
      "Epoch 1695/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2099e-05 - val_loss: 3.5547e-05\n",
      "Epoch 1696/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0175e-05 - val_loss: 4.9584e-05\n",
      "Epoch 1697/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9515e-05 - val_loss: 3.7496e-05\n",
      "Epoch 1698/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 1.8754e-05 - val_loss: 3.6270e-05\n",
      "Epoch 1699/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9010e-05 - val_loss: 3.5516e-05\n",
      "Epoch 1700/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9410e-05 - val_loss: 3.2986e-05\n",
      "Epoch 1701/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.8295e-05 - val_loss: 2.7107e-05\n",
      "Epoch 1702/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.8770e-05 - val_loss: 2.9985e-05\n",
      "Epoch 1703/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 1.9965e-05 - val_loss: 3.1562e-05\n",
      "Epoch 1704/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.0620e-05 - val_loss: 3.3885e-05\n",
      "Epoch 1705/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9300e-05 - val_loss: 3.8017e-05\n",
      "Epoch 1706/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 1.9827e-05 - val_loss: 3.2757e-05\n",
      "Epoch 1707/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9450e-05 - val_loss: 3.3148e-05\n",
      "Epoch 1708/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1254e-05 - val_loss: 3.1355e-05\n",
      "Epoch 1709/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.0082e-05 - val_loss: 3.8087e-05\n",
      "Epoch 1710/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9188e-05 - val_loss: 3.3399e-05\n",
      "Epoch 1711/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.8851e-05 - val_loss: 3.1449e-05\n",
      "Epoch 1712/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.0883e-05 - val_loss: 2.7089e-05\n",
      "Epoch 1713/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 1.9803e-05 - val_loss: 3.4439e-05\n",
      "Epoch 1714/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.8986e-05 - val_loss: 3.6991e-05\n",
      "Epoch 1715/2000\n",
      "18465/18465 [==============================] - 1s 76us/step - loss: 1.9417e-05 - val_loss: 2.9859e-05\n",
      "Epoch 1716/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9812e-05 - val_loss: 3.9140e-05\n",
      "Epoch 1717/2000\n",
      "18465/18465 [==============================] - ETA: 0s - loss: 2.0782e-0 - 1s 74us/step - loss: 2.0517e-05 - val_loss: 4.6711e-05\n",
      "Epoch 1718/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.2122e-05 - val_loss: 3.9174e-05\n",
      "Epoch 1719/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.8823e-05 - val_loss: 4.3200e-05\n",
      "Epoch 1720/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0886e-05 - val_loss: 4.0658e-05\n",
      "Epoch 1721/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9899e-05 - val_loss: 3.5445e-05\n",
      "Epoch 1722/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 2.0140e-05 - val_loss: 3.4066e-05\n",
      "Epoch 1723/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 1.9704e-05 - val_loss: 3.9273e-05\n",
      "Epoch 1724/2000\n",
      "18465/18465 [==============================] - 1s 77us/step - loss: 1.9836e-05 - val_loss: 3.5252e-05\n",
      "Epoch 1725/2000\n",
      "18465/18465 [==============================] - 1s 77us/step - loss: 1.8553e-05 - val_loss: 3.8654e-05\n",
      "Epoch 1726/2000\n",
      "18465/18465 [==============================] - 1s 77us/step - loss: 1.9989e-05 - val_loss: 3.0581e-05\n",
      "Epoch 1727/2000\n",
      "18465/18465 [==============================] - 1s 77us/step - loss: 1.9398e-05 - val_loss: 3.2418e-05\n",
      "Epoch 1728/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 1.9989e-05 - val_loss: 2.7243e-05\n",
      "Epoch 1729/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 2.0342e-05 - val_loss: 4.3411e-05\n",
      "Epoch 1730/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 2.0863e-05 - val_loss: 3.0711e-05\n",
      "Epoch 1731/2000\n",
      "18465/18465 [==============================] - 1s 78us/step - loss: 2.0916e-05 - val_loss: 2.9197e-05\n",
      "Epoch 1732/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 1.9323e-05 - val_loss: 2.8571e-05\n",
      "Epoch 1733/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 1.9558e-05 - val_loss: 3.7835e-05\n",
      "Epoch 1734/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 2.6695e-05 - val_loss: 2.7725e-05\n",
      "Epoch 1735/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.3864e-05 - val_loss: 2.7351e-05\n",
      "Epoch 1736/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0595e-05 - val_loss: 2.5954e-05\n",
      "Epoch 1737/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.0580e-05 - val_loss: 3.1451e-05\n",
      "Epoch 1738/2000\n",
      "18465/18465 [==============================] - 1s 76us/step - loss: 2.0434e-05 - val_loss: 2.9772e-05\n",
      "Epoch 1739/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 1.9107e-05 - val_loss: 3.2409e-05\n",
      "Epoch 1740/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0653e-05 - val_loss: 3.8278e-05\n",
      "Epoch 1741/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2268e-05 - val_loss: 3.4215e-05\n",
      "Epoch 1742/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9980e-05 - val_loss: 2.7520e-05\n",
      "Epoch 1743/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.0317e-05 - val_loss: 3.5567e-05\n",
      "Epoch 1744/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.9432e-05 - val_loss: 3.3165e-05\n",
      "Epoch 1745/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 1.9548e-05 - val_loss: 3.3919e-05\n",
      "Epoch 1746/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 1.8968e-05 - val_loss: 3.8663e-05\n",
      "Epoch 1747/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.0840e-05 - val_loss: 3.4344e-05\n",
      "Epoch 1748/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.9462e-05 - val_loss: 3.6479e-05\n",
      "Epoch 1749/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1912e-05 - val_loss: 5.3427e-05\n",
      "Epoch 1750/2000\n",
      "18465/18465 [==============================] - 1s 76us/step - loss: 2.2051e-05 - val_loss: 4.0981e-05\n",
      "Epoch 1751/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1127e-05 - val_loss: 3.7110e-05\n",
      "Epoch 1752/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0261e-05 - val_loss: 4.1128e-05\n",
      "Epoch 1753/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.0181e-05 - val_loss: 3.7892e-05\n",
      "Epoch 1754/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0232e-05 - val_loss: 3.8211e-05\n",
      "Epoch 1755/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.9323e-05 - val_loss: 3.3391e-05\n",
      "Epoch 1756/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 1.9804e-05 - val_loss: 2.8848e-05\n",
      "Epoch 1757/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0087e-05 - val_loss: 3.8827e-05\n",
      "Epoch 1758/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9023e-05 - val_loss: 4.2891e-05\n",
      "Epoch 1759/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9259e-05 - val_loss: 3.5132e-05\n",
      "Epoch 1760/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.9078e-05 - val_loss: 4.4436e-05\n",
      "Epoch 1761/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.8546e-05 - val_loss: 4.0369e-05\n",
      "Epoch 1762/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 2.4638e-05 - val_loss: 4.0205e-05\n",
      "Epoch 1763/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.4828e-05 - val_loss: 4.0879e-05\n",
      "Epoch 1764/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0459e-05 - val_loss: 2.2800e-05\n",
      "Epoch 1765/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.1081e-05 - val_loss: 3.5153e-05\n",
      "Epoch 1766/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9465e-05 - val_loss: 2.7341e-05\n",
      "Epoch 1767/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.8633e-05 - val_loss: 3.4993e-05\n",
      "Epoch 1768/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9555e-05 - val_loss: 3.7309e-05\n",
      "Epoch 1769/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.8762e-05 - val_loss: 3.4661e-05\n",
      "Epoch 1770/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.8277e-05 - val_loss: 3.1519e-05\n",
      "Epoch 1771/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9662e-05 - val_loss: 3.7237e-05\n",
      "Epoch 1772/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9009e-05 - val_loss: 2.9711e-05\n",
      "Epoch 1773/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9002e-05 - val_loss: 3.2121e-05\n",
      "Epoch 1774/2000\n",
      "18465/18465 [==============================] - 1s 76us/step - loss: 1.9720e-05 - val_loss: 3.5186e-05\n",
      "Epoch 1775/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9616e-05 - val_loss: 3.5785e-05\n",
      "Epoch 1776/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0562e-05 - val_loss: 3.0908e-05\n",
      "Epoch 1777/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9941e-05 - val_loss: 4.1793e-05\n",
      "Epoch 1778/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0224e-05 - val_loss: 3.6245e-05\n",
      "Epoch 1779/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0243e-05 - val_loss: 3.5452e-05\n",
      "Epoch 1780/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0270e-05 - val_loss: 3.3119e-05\n",
      "Epoch 1781/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.9830e-05 - val_loss: 3.6967e-05\n",
      "Epoch 1782/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.8939e-05 - val_loss: 4.2976e-05\n",
      "Epoch 1783/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1228e-05 - val_loss: 2.4112e-05\n",
      "Epoch 1784/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0504e-05 - val_loss: 4.2042e-05\n",
      "Epoch 1785/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2241e-05 - val_loss: 3.0834e-05\n",
      "Epoch 1786/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 2.2136e-05 - val_loss: 3.0871e-05\n",
      "Epoch 1787/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9279e-05 - val_loss: 3.4531e-05\n",
      "Epoch 1788/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9876e-05 - val_loss: 3.9534e-05\n",
      "Epoch 1789/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1998e-05 - val_loss: 4.1844e-05\n",
      "Epoch 1790/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.1098e-05 - val_loss: 3.7100e-05\n",
      "Epoch 1791/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9873e-05 - val_loss: 4.7028e-05\n",
      "Epoch 1792/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2338e-05 - val_loss: 3.0523e-05\n",
      "Epoch 1793/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.9217e-05 - val_loss: 3.3512e-05\n",
      "Epoch 1794/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 1.9790e-05 - val_loss: 4.7943e-05\n",
      "Epoch 1795/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1373e-05 - val_loss: 3.1089e-05\n",
      "Epoch 1796/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9599e-05 - val_loss: 2.6048e-05\n",
      "Epoch 1797/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1147e-05 - val_loss: 5.9495e-05\n",
      "Epoch 1798/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 2.0355e-05 - val_loss: 4.9296e-05\n",
      "Epoch 1799/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.9163e-05 - val_loss: 5.0233e-05\n",
      "Epoch 1800/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0812e-05 - val_loss: 4.2969e-05\n",
      "Epoch 1801/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.1288e-05 - val_loss: 7.4846e-05\n",
      "Epoch 1802/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.1924e-05 - val_loss: 4.9816e-05\n",
      "Epoch 1803/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1531e-05 - val_loss: 3.7032e-05\n",
      "Epoch 1804/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2267e-05 - val_loss: 2.8209e-05\n",
      "Epoch 1805/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9509e-05 - val_loss: 3.2761e-05\n",
      "Epoch 1806/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0992e-05 - val_loss: 1.1093e-04\n",
      "Epoch 1807/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 5.7853e-05 - val_loss: 2.7148e-05\n",
      "Epoch 1808/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.1681e-05 - val_loss: 5.3088e-05\n",
      "Epoch 1809/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1671e-05 - val_loss: 3.8829e-05\n",
      "Epoch 1810/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 2.0234e-05 - val_loss: 5.9399e-05\n",
      "Epoch 1811/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.8383e-05 - val_loss: 4.0034e-05\n",
      "Epoch 1812/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.1540e-05 - val_loss: 3.9690e-05\n",
      "Epoch 1813/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1075e-05 - val_loss: 5.0189e-05\n",
      "Epoch 1814/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3945e-05 - val_loss: 3.7359e-05\n",
      "Epoch 1815/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9635e-05 - val_loss: 4.0122e-05\n",
      "Epoch 1816/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1762e-05 - val_loss: 3.7974e-05\n",
      "Epoch 1817/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0931e-05 - val_loss: 3.4787e-05\n",
      "Epoch 1818/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1286e-05 - val_loss: 3.6435e-05\n",
      "Epoch 1819/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 1.9700e-05 - val_loss: 3.8783e-05\n",
      "Epoch 1820/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0618e-05 - val_loss: 3.6218e-05\n",
      "Epoch 1821/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.0667e-05 - val_loss: 4.2527e-05\n",
      "Epoch 1822/2000\n",
      "18465/18465 [==============================] - 1s 76us/step - loss: 2.0362e-05 - val_loss: 4.0533e-05\n",
      "Epoch 1823/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1535e-05 - val_loss: 3.6470e-05\n",
      "Epoch 1824/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0387e-05 - val_loss: 3.8372e-05\n",
      "Epoch 1825/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2495e-05 - val_loss: 3.2558e-05\n",
      "Epoch 1826/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0514e-05 - val_loss: 4.0907e-05\n",
      "Epoch 1827/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.8872e-05 - val_loss: 3.8175e-05\n",
      "Epoch 1828/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0847e-05 - val_loss: 4.5309e-05\n",
      "Epoch 1829/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.9465e-05 - val_loss: 2.9110e-05\n",
      "Epoch 1830/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.8885e-05 - val_loss: 3.6364e-05\n",
      "Epoch 1831/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1467e-05 - val_loss: 3.4523e-05\n",
      "Epoch 1832/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.0596e-05 - val_loss: 2.2238e-05\n",
      "Epoch 1833/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.9883e-05 - val_loss: 2.9389e-05\n",
      "Epoch 1834/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 1.9041e-05 - val_loss: 3.1759e-05\n",
      "Epoch 1835/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0251e-05 - val_loss: 3.6347e-05\n",
      "Epoch 1836/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.0195e-05 - val_loss: 3.2713e-05\n",
      "Epoch 1837/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.9462e-05 - val_loss: 2.9438e-05\n",
      "Epoch 1838/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9418e-05 - val_loss: 3.8862e-05\n",
      "Epoch 1839/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.8328e-05 - val_loss: 4.1276e-05\n",
      "Epoch 1840/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.5034e-05 - val_loss: 3.3302e-05\n",
      "Epoch 1841/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.2708e-05 - val_loss: 3.6298e-05\n",
      "Epoch 1842/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0762e-05 - val_loss: 3.4865e-05\n",
      "Epoch 1843/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 2.2414e-05 - val_loss: 4.0646e-05\n",
      "Epoch 1844/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0878e-05 - val_loss: 3.9583e-05\n",
      "Epoch 1845/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1543e-05 - val_loss: 2.9064e-05\n",
      "Epoch 1846/2000\n",
      "18465/18465 [==============================] - 1s 76us/step - loss: 2.2345e-05 - val_loss: 4.3893e-05\n",
      "Epoch 1847/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.4318e-05 - val_loss: 2.6978e-05\n",
      "Epoch 1848/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1577e-05 - val_loss: 4.7895e-05\n",
      "Epoch 1849/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 3.2308e-05 - val_loss: 4.5102e-05\n",
      "Epoch 1850/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1292e-05 - val_loss: 4.5812e-05\n",
      "Epoch 1851/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.9240e-05 - val_loss: 4.2712e-05\n",
      "Epoch 1852/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.9044e-05 - val_loss: 4.4394e-05\n",
      "Epoch 1853/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9283e-05 - val_loss: 4.5000e-05\n",
      "Epoch 1854/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0867e-05 - val_loss: 4.5478e-05\n",
      "Epoch 1855/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.0057e-05 - val_loss: 3.8242e-05\n",
      "Epoch 1856/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.8499e-05 - val_loss: 4.4157e-05\n",
      "Epoch 1857/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.9127e-05 - val_loss: 3.9927e-05\n",
      "Epoch 1858/2000\n",
      "18465/18465 [==============================] - 1s 77us/step - loss: 1.9301e-05 - val_loss: 4.1587e-05\n",
      "Epoch 1859/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.1137e-05 - val_loss: 4.5502e-05\n",
      "Epoch 1860/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1625e-05 - val_loss: 4.2571e-05\n",
      "Epoch 1861/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.1418e-05 - val_loss: 4.5197e-05\n",
      "Epoch 1862/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.8945e-05 - val_loss: 3.9812e-05\n",
      "Epoch 1863/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0222e-05 - val_loss: 4.5612e-05\n",
      "Epoch 1864/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9204e-05 - val_loss: 4.0461e-05\n",
      "Epoch 1865/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.0241e-05 - val_loss: 2.4134e-05\n",
      "Epoch 1866/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.0832e-05 - val_loss: 4.1454e-05\n",
      "Epoch 1867/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.8676e-05 - val_loss: 4.5748e-05\n",
      "Epoch 1868/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.9953e-05 - val_loss: 4.3853e-05\n",
      "Epoch 1869/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0566e-05 - val_loss: 4.4055e-05\n",
      "Epoch 1870/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 1.9432e-05 - val_loss: 4.1670e-05\n",
      "Epoch 1871/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.8126e-05 - val_loss: 4.4078e-05\n",
      "Epoch 1872/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9440e-05 - val_loss: 4.5429e-05\n",
      "Epoch 1873/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.8619e-05 - val_loss: 4.6090e-05\n",
      "Epoch 1874/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0345e-05 - val_loss: 3.2181e-05\n",
      "Epoch 1875/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.8348e-05 - val_loss: 3.6994e-05\n",
      "Epoch 1876/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9179e-05 - val_loss: 3.9694e-05\n",
      "Epoch 1877/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9520e-05 - val_loss: 3.8166e-05\n",
      "Epoch 1878/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9994e-05 - val_loss: 3.7081e-05\n",
      "Epoch 1879/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 1.9225e-05 - val_loss: 4.0558e-05\n",
      "Epoch 1880/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.8580e-05 - val_loss: 3.2604e-05\n",
      "Epoch 1881/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0963e-05 - val_loss: 3.8699e-05\n",
      "Epoch 1882/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 1.8730e-05 - val_loss: 4.1569e-05\n",
      "Epoch 1883/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.8425e-05 - val_loss: 4.2588e-05\n",
      "Epoch 1884/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 1.9831e-05 - val_loss: 4.3385e-05\n",
      "Epoch 1885/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0430e-05 - val_loss: 3.4203e-05\n",
      "Epoch 1886/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9730e-05 - val_loss: 3.7671e-05\n",
      "Epoch 1887/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9816e-05 - val_loss: 3.8376e-05\n",
      "Epoch 1888/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.8836e-05 - val_loss: 3.5032e-05\n",
      "Epoch 1889/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9743e-05 - val_loss: 3.8859e-05\n",
      "Epoch 1890/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.8725e-05 - val_loss: 4.0409e-05\n",
      "Epoch 1891/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9554e-05 - val_loss: 2.9984e-05\n",
      "Epoch 1892/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9247e-05 - val_loss: 3.5728e-05\n",
      "Epoch 1893/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9551e-05 - val_loss: 3.8877e-05\n",
      "Epoch 1894/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 2.0493e-05 - val_loss: 4.0628e-05\n",
      "Epoch 1895/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0233e-05 - val_loss: 3.2149e-05\n",
      "Epoch 1896/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.8763e-05 - val_loss: 3.6667e-05\n",
      "Epoch 1897/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0771e-05 - val_loss: 3.3742e-05\n",
      "Epoch 1898/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9841e-05 - val_loss: 3.4289e-05\n",
      "Epoch 1899/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.9970e-05 - val_loss: 3.4922e-05\n",
      "Epoch 1900/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.0450e-05 - val_loss: 4.0329e-05\n",
      "Epoch 1901/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 2.0859e-05 - val_loss: 4.3920e-05\n",
      "Epoch 1902/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2733e-05 - val_loss: 3.8864e-05\n",
      "Epoch 1903/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0322e-05 - val_loss: 4.2473e-05\n",
      "Epoch 1904/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9281e-05 - val_loss: 3.7163e-05\n",
      "Epoch 1905/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 1.8894e-05 - val_loss: 3.2190e-05\n",
      "Epoch 1906/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 1.9748e-05 - val_loss: 3.3400e-05\n",
      "Epoch 1907/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9910e-05 - val_loss: 3.8546e-05\n",
      "Epoch 1908/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.9800e-05 - val_loss: 4.2137e-05\n",
      "Epoch 1909/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.9109e-05 - val_loss: 2.9119e-05\n",
      "Epoch 1910/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9420e-05 - val_loss: 3.2217e-05\n",
      "Epoch 1911/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0896e-05 - val_loss: 3.4130e-05\n",
      "Epoch 1912/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1345e-05 - val_loss: 3.8887e-05\n",
      "Epoch 1913/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.0547e-05 - val_loss: 3.8051e-05\n",
      "Epoch 1914/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9713e-05 - val_loss: 4.3944e-05\n",
      "Epoch 1915/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.8421e-05 - val_loss: 4.9427e-05\n",
      "Epoch 1916/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.3111e-05 - val_loss: 5.3104e-05\n",
      "Epoch 1917/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.1769e-05 - val_loss: 4.9960e-05\n",
      "Epoch 1918/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 1.8998e-05 - val_loss: 3.1735e-05\n",
      "Epoch 1919/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9659e-05 - val_loss: 3.6363e-05\n",
      "Epoch 1920/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.8604e-05 - val_loss: 4.0448e-05\n",
      "Epoch 1921/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9660e-05 - val_loss: 2.9715e-05\n",
      "Epoch 1922/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9563e-05 - val_loss: 3.3757e-05\n",
      "Epoch 1923/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9453e-05 - val_loss: 4.2347e-05\n",
      "Epoch 1924/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 1.9827e-05 - val_loss: 3.4549e-05\n",
      "Epoch 1925/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9931e-05 - val_loss: 4.2014e-05\n",
      "Epoch 1926/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.9611e-05 - val_loss: 3.7829e-05\n",
      "Epoch 1927/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.9108e-05 - val_loss: 3.1689e-05\n",
      "Epoch 1928/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.9425e-05 - val_loss: 3.1375e-05\n",
      "Epoch 1929/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 2.0955e-05 - val_loss: 3.8020e-05\n",
      "Epoch 1930/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 1.9159e-05 - val_loss: 4.3090e-05\n",
      "Epoch 1931/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.9570e-05 - val_loss: 2.4410e-05\n",
      "Epoch 1932/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.8865e-05 - val_loss: 3.2439e-05\n",
      "Epoch 1933/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.2086e-05 - val_loss: 3.7323e-05\n",
      "Epoch 1934/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.8786e-05 - val_loss: 4.8117e-05\n",
      "Epoch 1935/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 3.6909e-05 - val_loss: 4.5594e-05\n",
      "Epoch 1936/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9955e-05 - val_loss: 3.7321e-05\n",
      "Epoch 1937/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.1383e-05 - val_loss: 4.4275e-05\n",
      "Epoch 1938/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.9133e-05 - val_loss: 4.5446e-05\n",
      "Epoch 1939/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9446e-05 - val_loss: 5.0397e-05\n",
      "Epoch 1940/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.8709e-05 - val_loss: 5.0617e-05\n",
      "Epoch 1941/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9211e-05 - val_loss: 4.6849e-05\n",
      "Epoch 1942/2000\n",
      "18465/18465 [==============================] - 1s 75us/step - loss: 1.8769e-05 - val_loss: 4.6155e-05\n",
      "Epoch 1943/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.8637e-05 - val_loss: 4.7395e-05\n",
      "Epoch 1944/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.8732e-05 - val_loss: 5.1597e-05\n",
      "Epoch 1945/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0545e-05 - val_loss: 4.6904e-05\n",
      "Epoch 1946/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0304e-05 - val_loss: 5.3559e-05\n",
      "Epoch 1947/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0218e-05 - val_loss: 3.3959e-05\n",
      "Epoch 1948/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.8680e-05 - val_loss: 4.0683e-05\n",
      "Epoch 1949/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 2.3095e-05 - val_loss: 4.1067e-05\n",
      "Epoch 1950/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9935e-05 - val_loss: 2.6423e-05\n",
      "Epoch 1951/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0702e-05 - val_loss: 3.3024e-05\n",
      "Epoch 1952/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9502e-05 - val_loss: 4.0578e-05\n",
      "Epoch 1953/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 1.9377e-05 - val_loss: 2.9731e-05\n",
      "Epoch 1954/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 2.0125e-05 - val_loss: 4.8174e-05\n",
      "Epoch 1955/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.0866e-05 - val_loss: 3.1382e-05\n",
      "Epoch 1956/2000\n",
      "18465/18465 [==============================] - ETA: 0s - loss: 2.2977e-0 - 1s 72us/step - loss: 2.2595e-05 - val_loss: 3.7955e-05\n",
      "Epoch 1957/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0150e-05 - val_loss: 3.0045e-05\n",
      "Epoch 1958/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.0820e-05 - val_loss: 3.1606e-05\n",
      "Epoch 1959/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1711e-05 - val_loss: 3.2398e-05\n",
      "Epoch 1960/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.2973e-05 - val_loss: 2.3782e-05\n",
      "Epoch 1961/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.0302e-05 - val_loss: 3.9882e-05\n",
      "Epoch 1962/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.1165e-05 - val_loss: 3.9859e-05\n",
      "Epoch 1963/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.8985e-05 - val_loss: 2.9852e-05\n",
      "Epoch 1964/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9279e-05 - val_loss: 2.8851e-05\n",
      "Epoch 1965/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 1.8453e-05 - val_loss: 2.6134e-05\n",
      "Epoch 1966/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 1.9267e-05 - val_loss: 3.4274e-05\n",
      "Epoch 1967/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9827e-05 - val_loss: 4.0866e-05\n",
      "Epoch 1968/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9590e-05 - val_loss: 2.8201e-05\n",
      "Epoch 1969/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9316e-05 - val_loss: 3.9640e-05\n",
      "Epoch 1970/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.9460e-05 - val_loss: 2.5684e-05\n",
      "Epoch 1971/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9802e-05 - val_loss: 3.9844e-05\n",
      "Epoch 1972/2000\n",
      "18465/18465 [==============================] - 1s 79us/step - loss: 2.0002e-05 - val_loss: 3.1818e-05\n",
      "Epoch 1973/2000\n",
      "18465/18465 [==============================] - 1s 76us/step - loss: 2.0698e-05 - val_loss: 4.0408e-05\n",
      "Epoch 1974/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.1972e-05 - val_loss: 3.5338e-05\n",
      "Epoch 1975/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.9337e-05 - val_loss: 3.3642e-05\n",
      "Epoch 1976/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.8415e-05 - val_loss: 3.8782e-05\n",
      "Epoch 1977/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 1.8898e-05 - val_loss: 2.3845e-05\n",
      "Epoch 1978/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 1.9516e-05 - val_loss: 2.3636e-05\n",
      "Epoch 1979/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0049e-05 - val_loss: 2.9076e-05\n",
      "Epoch 1980/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0126e-05 - val_loss: 2.8104e-05\n",
      "Epoch 1981/2000\n",
      "18465/18465 [==============================] - 1s 73us/step - loss: 1.8458e-05 - val_loss: 4.2108e-05\n",
      "Epoch 1982/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9980e-05 - val_loss: 3.9076e-05\n",
      "Epoch 1983/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.8122e-05 - val_loss: 3.8846e-05\n",
      "Epoch 1984/2000\n",
      "18465/18465 [==============================] - 1s 70us/step - loss: 1.9107e-05 - val_loss: 2.9382e-05\n",
      "Epoch 1985/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.9758e-05 - val_loss: 4.2400e-05\n",
      "Epoch 1986/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.8872e-05 - val_loss: 2.9153e-05\n",
      "Epoch 1987/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.4788e-05 - val_loss: 4.3720e-05\n",
      "Epoch 1988/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.8998e-05 - val_loss: 3.3338e-05\n",
      "Epoch 1989/2000\n",
      "18465/18465 [==============================] - 1s 74us/step - loss: 1.9459e-05 - val_loss: 3.9945e-05\n",
      "Epoch 1990/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0749e-05 - val_loss: 4.1941e-05\n",
      "Epoch 1991/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.7423e-05 - val_loss: 5.6370e-05\n",
      "Epoch 1992/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.0962e-05 - val_loss: 3.3450e-05\n",
      "Epoch 1993/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9741e-05 - val_loss: 3.4916e-05\n",
      "Epoch 1994/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.0252e-05 - val_loss: 3.0299e-05\n",
      "Epoch 1995/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 1.9512e-05 - val_loss: 3.6385e-05\n",
      "Epoch 1996/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.9098e-05 - val_loss: 4.0134e-05\n",
      "Epoch 1997/2000\n",
      "18465/18465 [==============================] - 1s 72us/step - loss: 2.0466e-05 - val_loss: 4.3715e-05\n",
      "Epoch 1998/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.9861e-05 - val_loss: 3.0873e-05\n",
      "Epoch 1999/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 1.9204e-05 - val_loss: 4.8814e-05\n",
      "Epoch 2000/2000\n",
      "18465/18465 [==============================] - 1s 71us/step - loss: 2.1732e-05 - val_loss: 3.2457e-05\n"
     ]
    }
   ],
   "source": [
    "final_model = build_complex(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'twice': True,\n",
       " 'dropout': 0.2,\n",
       " 'shuffle': True,\n",
       " 'density': 54,\n",
       " 'activation': 'relu',\n",
       " 'lstmsize': 4,\n",
       " 'merge_density': 176,\n",
       " 'optimizer': 'adam',\n",
       " 'full_density': True,\n",
       " 'callbacks': [<keras.callbacks.callbacks.ModelCheckpoint at 0x221c0bba208>]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_182\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "lstm_363_input (InputLayer)     (None, 4, 100)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_363 (LSTM)                 (None, 4, 4)         1680        lstm_363_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_363 (Dropout)           (None, 4, 4)         0           lstm_363[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_364 (LSTM)                 (None, 4)            144         dropout_363[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1048_input (InputLayer)   (None, 99)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_364 (Dropout)           (None, 4)            0           lstm_364[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1048 (Dense)              (None, 54)           5400        dense_1048_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_182 (Concatenate)   (None, 58)           0           dropout_364[0][0]                \n",
      "                                                                 dense_1048[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1049 (Dense)              (None, 176)          10384       concatenate_182[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1050 (Dense)              (None, 88)           15576       dense_1049[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1051 (Dense)              (None, 44)           3916        dense_1050[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1052 (Dense)              (None, 22)           990         dense_1051[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1053 (Dense)              (None, 1)            23          dense_1052[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 38,113\n",
      "Trainable params: 38,113\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model[0].load_weights('./checkpoints/fundamental.(best).hdf5')\n",
    "y_predicted = final_model[0].predict([test_time, test_nexus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y_test = y_normaliser.inverse_transform(y_predicted)\n",
    "true_y_test = y_normaliser.inverse_transform(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE is 119.15\n",
      "Medium error is 5.81\n"
     ]
    }
   ],
   "source": [
    "loss = np.mean((true_y_test - predicted_y_test)**2)\n",
    "medium_error = np.mean(abs(true_y_test - predicted_y_test))\n",
    "print(f'MSE is {loss:.2f}\\nMedium error is {medium_error:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_down_test = []\n",
    "up_down_predicted = []\n",
    "\n",
    "for y,x in zip(test_y,test_nexus):\n",
    "    if y[0] > x[-1]: up_down_test.append(1)\n",
    "    elif y[0] < x[-1]: up_down_test.append(-1)\n",
    "    else: up_down_test.append(0)\n",
    "        \n",
    "for y,x in zip(y_predicted,test_nexus):\n",
    "    if y[0] > x[-1]: up_down_predicted.append(1)\n",
    "    elif y[0] < x[-1]: up_down_predicted.append(-1)\n",
    "    else: up_down_predicted.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trend accuracy is: 78.73%\n"
     ]
    }
   ],
   "source": [
    "print(f'Trend accuracy is: {(sum(1 for r,p in zip(up_down_test,up_down_predicted) if r == p)/len(up_down_test))*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for upward trend is: 42.29%\n",
      "Accuracy for downward trend is: 82.76%\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy for upward trend is: {(sum(1 for r,p in zip(up_down_test,up_down_predicted) if r == 1 and p == 1)/sum(1 for v in up_down_test if v == 1))*100:.2f}%')\n",
    "print(f'Accuracy for downward trend is: {(sum(1 for r,p in zip(up_down_test,up_down_predicted) if r == -1 and p == -1)/sum(1 for v in up_down_test if v == -1))*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test growth trends:        Predicted growth trends:\n",
      "227                        450\n",
      "Test decreasing trends:    Predicted decreasing trends:\n",
      "2053                       1830\n"
     ]
    }
   ],
   "source": [
    "print('Test growth trends:        Predicted growth trends:')\n",
    "print(sum(1 for v in up_down_test if v > 0),'                      ',sum(1 for v in up_down_predicted if v > 0))\n",
    "print('Test decreasing trends:    Predicted decreasing trends:')\n",
    "print(sum(1 for v in up_down_test if v < 0),'                     ',sum(1 for v in up_down_predicted if v < 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test mean: 32.93601798245614\n",
      "Predictions mean: 31.7650089263916\n"
     ]
    }
   ],
   "source": [
    "print(f'Test mean: {np.mean(true_y_test)}')\n",
    "print(f'Predictions mean: {np.mean(predicted_y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Results seem pretty good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test values:    Predicted values:\n",
      "    40.89           30.40\n",
      "    55.71           36.53\n",
      "    51.07           50.62\n",
      "    53.94           46.07\n",
      "    51.45           48.67\n",
      "    46.29           45.96\n",
      "    38.68           41.07\n",
      "    30.38           35.23\n",
      "    17.39           27.31\n",
      "    19.01           16.84\n",
      "    30.15           27.08\n",
      "    32.01           28.78\n",
      "    35.67           29.59\n",
      "    39.25           32.78\n",
      "    40.64           36.31\n",
      "    35.88           38.55\n",
      "    32.84           33.05\n",
      "    43.46           30.21\n",
      "    32.91           40.42\n",
      "    40.40           29.54\n",
      "    45.11           36.58\n",
      "    38.81           41.06\n",
      "    41.69           35.10\n",
      "    31.83           37.41\n",
      "    43.19           29.49\n",
      "    35.65           24.58\n",
      "    31.79           31.21\n",
      "    32.16           27.98\n",
      "    33.12           28.26\n",
      "    31.86           28.98\n",
      "    31.16           27.97\n",
      "    32.63           27.44\n",
      "    33.65           28.70\n",
      "    28.43           29.49\n",
      "    33.63           25.39\n",
      "    33.25           29.84\n",
      "    34.11           29.54\n",
      "    34.51           30.19\n",
      "    23.30           30.53\n",
      "    24.52           21.50\n",
      "    10.80           11.05\n",
      "    12.70           10.95\n",
      "    12.15           12.50\n",
      "    13.55           12.05\n",
      "    14.25           13.18\n",
      "    15.65           13.77\n",
      "    18.90           14.92\n",
      "    22.85           17.57\n",
      "    19.02           20.79\n",
      "    22.98           17.67\n",
      "    25.59           20.90\n",
      "    25.61           23.04\n",
      "    31.86           23.06\n",
      "    26.50           28.16\n",
      "    25.86           23.79\n",
      "    83.90           72.26\n",
      "    90.65           78.24\n",
      "    97.88           85.94\n",
      "    104.93           91.71\n",
      "    112.30          105.91\n",
      "    107.97          110.92\n",
      "    116.09          106.33\n",
      "    109.18          114.90\n",
      "    92.32          105.83\n",
      "    100.12           90.36\n",
      "    109.71           92.88\n",
      "    114.25          105.81\n",
      "    121.84          111.32\n",
      "    97.65          118.64\n",
      "    123.50           98.09\n",
      "    8.75            7.81\n",
      "    7.85            9.13\n",
      "    7.75            8.41\n",
      "    8.90            8.34\n",
      "    9.20            9.29\n",
      "    8.45            9.49\n",
      "    8.90            8.92\n",
      "    8.50            9.32\n",
      "    6.86            8.99\n",
      "    7.76            7.69\n",
      "    7.92            8.52\n",
      "    8.15            8.65\n",
      "    8.67            8.82\n",
      "    5.41            9.26\n",
      "    6.33            6.66\n",
      "    12.50            9.75\n",
      "    15.47           12.14\n",
      "    19.93           14.70\n",
      "    15.79           18.28\n",
      "    11.20           14.92\n",
      "    9.46           11.05\n",
      "    10.09            9.73\n",
      "    14.10           10.27\n",
      "    9.06           13.54\n",
      "    6.64            9.32\n",
      "    5.46            7.43\n",
      "    3.40            6.59\n",
      "    4.75            5.02\n",
      "    2.42            5.81\n",
      "    2.58            4.36\n",
      "    6.84           11.14\n",
      "    6.95            8.09\n",
      "    4.54            7.78\n",
      "    6.16            5.90\n",
      "    5.63           10.71\n",
      "    4.32            6.73\n",
      "    4.21           95.19\n",
      "    4.11           71.06\n",
      "    2.62            5.11\n",
      "    1.46            4.41\n",
      "    1.97            3.06\n",
      "    5.88            7.49\n",
      "    3.67            6.81\n",
      "    2.30            5.18\n",
      "    2.55            4.27\n",
      "    1.60            4.46\n",
      "    1.64            3.83\n",
      "    1.44            3.86\n",
      "    2.12            3.73\n",
      "    0.43            4.17\n",
      "    1.56            3.06\n",
      "    1.03            3.81\n",
      "    0.97            3.45\n",
      "    0.84            3.41\n",
      "    0.57            3.33\n",
      "    1.50            3.16\n",
      "    30.40           23.88\n",
      "    37.34           27.02\n",
      "    31.24           32.87\n",
      "    22.30           27.68\n",
      "    27.98           20.41\n",
      "    29.88           25.10\n",
      "    27.64           26.63\n",
      "    27.50           24.67\n",
      "    26.50           24.66\n",
      "    29.74           23.74\n",
      "    28.16           26.53\n",
      "    18.29           25.10\n",
      "    19.35           17.18\n",
      "    18.21           17.91\n",
      "    26.00           23.41\n",
      "    26.80           23.47\n",
      "    27.20           24.17\n",
      "    26.55           24.48\n",
      "    25.00           24.02\n",
      "    22.88           22.96\n",
      "    75.81           61.24\n",
      "    68.97           70.49\n",
      "    54.21           62.70\n",
      "    63.29           49.17\n",
      "    74.75           57.35\n",
      "    63.02           69.26\n",
      "    76.49           57.03\n",
      "    90.88           71.44\n",
      "    83.44           87.90\n",
      "    97.76           79.24\n",
      "    108.80           95.48\n",
      "    90.44          108.61\n",
      "    93.44           87.26\n",
      "    84.55           90.87\n",
      "    131.79           80.05\n",
      "    19.03           14.55\n",
      "    23.05           17.57\n",
      "    23.85           20.95\n",
      "    30.75           21.69\n",
      "    34.08           27.26\n",
      "    26.91           30.07\n",
      "    22.01           24.08\n",
      "    21.76           20.10\n",
      "    14.74           19.88\n",
      "    16.56           13.90\n",
      "    15.77           15.49\n",
      "    19.24           14.83\n",
      "    24.06           17.59\n",
      "    15.92           21.51\n",
      "    19.09           14.91\n",
      "    5.65            7.46\n",
      "    5.50            6.77\n",
      "    7.35            6.65\n",
      "    4.25            8.10\n",
      "    5.10            5.68\n",
      "    6.00            6.34\n",
      "    5.15            7.03\n",
      "    7.50            6.38\n",
      "    5.55            8.24\n",
      "    5.30            6.69\n",
      "    4.85            6.49\n",
      "    4.29            6.14\n",
      "    3.20            5.71\n",
      "    3.46            4.95\n",
      "    3.36            5.12\n",
      "    30.50           25.77\n",
      "    29.60           27.17\n",
      "    40.80           26.51\n",
      "    41.75           36.37\n",
      "    40.25           37.26\n",
      "    30.70           35.66\n",
      "    34.55           27.38\n",
      "    25.90           30.47\n",
      "    28.57           23.60\n",
      "    36.23           25.45\n",
      "    46.59           31.75\n",
      "    47.88           41.58\n",
      "    39.62           42.78\n",
      "    36.72           35.09\n",
      "    46.56           32.28\n",
      "    48.95           43.81\n",
      "    58.50           44.47\n",
      "    68.30           53.49\n",
      "    51.77           62.76\n",
      "    59.59           46.83\n",
      "    78.55           54.08\n",
      "    79.20           74.61\n",
      "    86.76           74.64\n",
      "    87.47           83.72\n",
      "    86.16           84.42\n",
      "    85.60           83.06\n",
      "    70.62           82.24\n",
      "    75.28           64.88\n",
      "    79.12           70.21\n",
      "    13.63           11.75\n",
      "    16.13           13.43\n",
      "    17.36           15.69\n",
      "    15.37           16.70\n",
      "    15.67           15.10\n",
      "    15.29           14.88\n",
      "    17.63           14.67\n",
      "    15.91           16.60\n",
      "    9.73           15.21\n",
      "    11.73            9.85\n",
      "    10.20           11.71\n",
      "    12.20           10.47\n",
      "    15.05           12.14\n",
      "    10.34           14.61\n",
      "    11.86           10.72\n",
      "    4.00            6.91\n",
      "    3.30            5.50\n",
      "    1.90            5.02\n",
      "    1.75            4.10\n",
      "    1.32            4.01\n",
      "    1.05            3.70\n",
      "    1.09            3.54\n",
      "    0.21            3.57\n",
      "    0.22            2.99\n",
      "    1.78            2.98\n",
      "    1.28            4.00\n",
      "    0.27            3.67\n",
      "    0.19            3.01\n",
      "    0.23            2.96\n",
      "    0.31            2.95\n",
      "    1.86            4.15\n",
      "    2.31            4.08\n",
      "    2.17            4.37\n",
      "    1.75            4.28\n",
      "    1.86            4.00\n",
      "    1.97            4.08\n",
      "    2.14            4.15\n",
      "    2.15            4.27\n",
      "    1.36            4.27\n",
      "    1.74            3.75\n",
      "    19.63           16.38\n",
      "    32.06           18.72\n",
      "    33.96           29.00\n",
      "    29.10           30.56\n",
      "    17.98           26.72\n",
      "    16.65           16.87\n",
      "    6.88           15.74\n",
      "    2.48            7.59\n",
      "    2.20            4.39\n",
      "    0.75            4.12\n",
      "    1.18            3.15\n",
      "    41.75           31.92\n",
      "    46.35           38.06\n",
      "    46.18           41.98\n",
      "    42.04           41.72\n",
      "    52.16           37.43\n",
      "    58.14           47.56\n",
      "    21.74           23.86\n",
      "    24.82           19.98\n",
      "    23.04           22.33\n",
      "    14.75           21.06\n",
      "    16.65           14.22\n",
      "    15.10           15.81\n",
      "    10.59           14.44\n",
      "    11.02           10.75\n",
      "    6.98           11.13\n",
      "    5.54            7.75\n",
      "    13.00           10.97\n",
      "    15.87           13.64\n",
      "    16.10           16.11\n",
      "    13.66           16.28\n",
      "    14.81           14.30\n",
      "    14.79           15.29\n",
      "    13.60           15.04\n",
      "    11.07           14.05\n",
      "    10.94           11.97\n",
      "    12.50           10.94\n",
      "    14.44           12.17\n",
      "    13.98           13.81\n",
      "    14.54           13.43\n",
      "    10.66           13.96\n",
      "    12.22           10.88\n",
      "    0.57            4.27\n",
      "    33.72           25.69\n",
      "    23.88           29.62\n",
      "    23.82           21.49\n",
      "    21.00           21.48\n",
      "    24.84           19.09\n",
      "    30.58           22.36\n",
      "    32.71           26.94\n",
      "    45.30           28.82\n",
      "    5.77            7.48\n",
      "    7.20            6.69\n",
      "    5.27            7.81\n",
      "    5.29            6.30\n",
      "    6.04            6.32\n",
      "    4.87            6.89\n",
      "    6.24            5.97\n",
      "    6.56            7.00\n",
      "    3.81            7.22\n",
      "    4.87            5.12\n",
      "    2.60            5.89\n",
      "    3.63            4.39\n",
      "    2.42            5.03\n",
      "    1.06            4.20\n",
      "    1.25            3.28\n",
      "    72.97           65.18\n",
      "    80.56           67.52\n",
      "    76.93           75.67\n",
      "    89.64           72.05\n",
      "    104.44           86.41\n",
      "    103.89           99.32\n",
      "    110.25           99.29\n",
      "    107.29          106.48\n",
      "    94.50          102.89\n",
      "    106.07           88.76\n",
      "    114.76          101.07\n",
      "    129.24          110.80\n",
      "    128.29          125.44\n",
      "    99.93          123.38\n",
      "    126.97           94.31\n",
      "    48.24           34.61\n",
      "    44.53           43.26\n",
      "    50.95           39.85\n",
      "    49.14           45.97\n",
      "    52.68           44.21\n",
      "    57.78           47.50\n",
      "    65.51           52.61\n",
      "    69.29           59.67\n",
      "    59.70           63.29\n",
      "    62.19           53.48\n",
      "    53.67           56.75\n",
      "    52.52           48.50\n",
      "    56.32           47.44\n",
      "    41.30           50.56\n",
      "    52.57           36.99\n",
      "    3.75            5.11\n",
      "    2.88            5.29\n",
      "    3.00            4.68\n",
      "    5.28            4.77\n",
      "    6.38            6.43\n",
      "    2.23            7.27\n",
      "    3.16            4.25\n",
      "    2.78            4.91\n",
      "    3.69            4.66\n",
      "    1.76            5.20\n",
      "    1.22            3.92\n",
      "    1.19            3.59\n",
      "    1.40            3.56\n",
      "    1.10            3.70\n",
      "    1.33            3.50\n",
      "    10.27           10.47\n",
      "    10.35           10.49\n",
      "    10.35           10.55\n",
      "    10.44           10.56\n",
      "    10.46           10.63\n",
      "    10.56           10.65\n",
      "    10.52           10.73\n",
      "    10.54           10.70\n",
      "    72.88           49.10\n",
      "    70.64           72.26\n",
      "    75.25           64.47\n",
      "    60.88           70.98\n",
      "    67.40           56.10\n",
      "    69.47           69.91\n",
      "    69.73           62.85\n",
      "    89.06           65.74\n",
      "    83.73           82.61\n",
      "    79.78           76.07\n",
      "    87.55           73.78\n",
      "    88.41           83.57\n",
      "    88.09           83.74\n",
      "    31.55           68.12\n",
      "    34.61           35.47\n",
      "    7.75            7.33\n",
      "    7.30            8.52\n",
      "    9.25            8.11\n",
      "    9.50            9.72\n",
      "    11.00            9.94\n",
      "    10.75           11.16\n",
      "    11.20           10.95\n",
      "    11.10           11.31\n",
      "    9.58           11.23\n",
      "    10.60           10.03\n",
      "    11.39           10.82\n",
      "    10.52           11.45\n",
      "    10.73           10.73\n",
      "    6.40           10.97\n",
      "    6.69            7.39\n",
      "    21.41           18.44\n",
      "    20.81           19.60\n",
      "    23.35           19.11\n",
      "    22.50           21.18\n",
      "    22.20           20.49\n",
      "    22.00           20.25\n",
      "    22.00           20.08\n",
      "    22.90           20.08\n",
      "    20.02           20.82\n",
      "    23.11           18.48\n",
      "    20.17           21.01\n",
      "    20.02           18.60\n",
      "    22.71           18.48\n",
      "    16.25           20.70\n",
      "    18.00           15.40\n",
      "    9.50            8.64\n",
      "    6.10            9.78\n",
      "    7.21            7.02\n",
      "    5.80            7.92\n",
      "    8.68            6.80\n",
      "    29.62           19.78\n",
      "    27.69           26.81\n",
      "    27.80           25.22\n",
      "    28.54           25.34\n",
      "    28.14           25.98\n",
      "    31.65           25.64\n",
      "    30.67           28.65\n",
      "    27.89           28.28\n",
      "    21.46           25.97\n",
      "    24.93           20.66\n",
      "    28.56           23.83\n",
      "    28.35           26.88\n",
      "    30.88           26.67\n",
      "    18.31           28.76\n",
      "    20.12           18.63\n",
      "    64.55           69.24\n",
      "    68.50           58.75\n",
      "    66.85           62.29\n",
      "    63.40           60.72\n",
      "    47.25           57.46\n",
      "    52.05           42.35\n",
      "    33.05           46.75\n",
      "    39.35           28.87\n",
      "    25.28           34.75\n",
      "    37.15           22.74\n",
      "    41.02           32.64\n",
      "    50.90           36.28\n",
      "    52.26           45.66\n",
      "    38.37           46.96\n",
      "    46.82           33.83\n",
      "    9.74            9.49\n",
      "    11.89            9.25\n",
      "    9.46           12.07\n",
      "    9.08           10.13\n",
      "    8.00            9.75\n",
      "    4.69            8.94\n",
      "    3.59            6.11\n",
      "    3.57            5.34\n",
      "    4.00            4.91\n",
      "    4.05            5.80\n",
      "    3.57            5.55\n",
      "    2.93            5.30\n",
      "    3.72            4.79\n",
      "    4.19            5.55\n",
      "    2.91            5.58\n",
      "    102.18           97.48\n",
      "    98.54          101.68\n",
      "    87.31           97.40\n",
      "    98.16           84.33\n",
      "    37.62           96.98\n",
      "    32.45           33.30\n",
      "    36.62           28.87\n",
      "    35.33           32.32\n",
      "    25.96           31.22\n",
      "    29.89           23.98\n",
      "    38.06           26.85\n",
      "    39.88           33.88\n",
      "    47.70           35.47\n",
      "    37.19           42.74\n",
      "    49.51           32.85\n",
      "    25.45           23.77\n",
      "    25.90           22.91\n",
      "    28.30           23.24\n",
      "    28.10           25.21\n",
      "    27.80           25.08\n",
      "    29.50           24.82\n",
      "    30.85           26.20\n",
      "    36.75           27.34\n",
      "    30.04           32.27\n",
      "    37.40           26.69\n",
      "    41.61           32.85\n",
      "    38.60           36.83\n",
      "    49.61           33.99\n",
      "    38.09           44.40\n",
      "    44.06           33.50\n",
      "    369.59          320.64\n",
      "    381.19          355.53\n",
      "    366.06          361.61\n",
      "    374.90          352.35\n",
      "    377.91          359.09\n",
      "    345.10          362.24\n",
      "    356.15          332.52\n",
      "    356.65          344.51\n",
      "    328.11          345.35\n",
      "    371.51          330.50\n",
      "    378.55          367.60\n",
      "    390.04          373.86\n",
      "    375.82          382.81\n",
      "    290.55          372.98\n",
      "    302.19          300.82\n",
      "    15.14           16.06\n",
      "    15.95           14.70\n",
      "    15.73           15.16\n",
      "    16.30           14.92\n",
      "    17.25           13.79\n",
      "    19.14           17.55\n",
      "    19.58           17.89\n",
      "    22.38           18.48\n",
      "    16.62           20.36\n",
      "    15.90           15.36\n",
      "    14.26           15.40\n",
      "    13.99           13.85\n",
      "    12.61           12.74\n",
      "    9.24           12.60\n",
      "    7.82           10.01\n",
      "    15.00           13.87\n",
      "    20.45           14.45\n",
      "    23.75           18.80\n",
      "    21.15           21.58\n",
      "    26.25           19.47\n",
      "    36.80           23.64\n",
      "    18.09           32.40\n",
      "    19.68           16.97\n",
      "    22.47           18.23\n",
      "    23.28           20.71\n",
      "    18.96           21.06\n",
      "    13.10           17.93\n",
      "    17.38           12.99\n",
      "    77.12           53.33\n",
      "    75.31           70.34\n",
      "    74.86           68.41\n",
      "    74.49           68.09\n",
      "    71.92           67.67\n",
      "    72.39           64.95\n",
      "    76.23           65.35\n",
      "    70.90           68.91\n",
      "    60.97           64.38\n",
      "    64.04           55.23\n",
      "    65.82           58.69\n",
      "    64.58           60.45\n",
      "    68.64           59.25\n",
      "    46.38           63.60\n",
      "    51.55           42.10\n",
      "    18.78           18.18\n",
      "    17.74           21.33\n",
      "    18.36           20.30\n",
      "    19.51           19.24\n",
      "    20.80           20.13\n",
      "    21.41           21.04\n",
      "    22.59           22.53\n",
      "    20.80           23.62\n",
      "    15.90           21.69\n",
      "    16.50           16.15\n",
      "    16.59           16.70\n",
      "    16.46           17.78\n",
      "    17.70           17.01\n",
      "    10.90           18.19\n",
      "    10.64           13.14\n",
      "    10.75           11.12\n",
      "    9.55           10.90\n",
      "    9.30            9.90\n",
      "    10.10            9.71\n",
      "    8.55           10.36\n",
      "    7.95            9.12\n",
      "    7.85            8.59\n",
      "    7.05            8.54\n",
      "    6.38            7.88\n",
      "    6.00            7.33\n",
      "    6.15            7.04\n",
      "    6.50            7.16\n",
      "    6.30            7.42\n",
      "    5.05            7.26\n",
      "    5.56            6.30\n",
      "    45.45           29.95\n",
      "    42.95           40.48\n",
      "    47.50           38.10\n",
      "    48.40           42.40\n",
      "    52.95           43.28\n",
      "    50.80           47.56\n",
      "    51.90           45.51\n",
      "    53.15           46.56\n",
      "    47.75           47.75\n",
      "    45.23           42.61\n",
      "    37.01           40.25\n",
      "    31.56           32.45\n",
      "    36.26           27.91\n",
      "    22.50           31.77\n",
      "    18.72           20.49\n",
      "    15.70           12.80\n",
      "    16.95           15.15\n",
      "    17.20           16.15\n",
      "    19.80           16.34\n",
      "    19.75           18.51\n",
      "    22.00           18.44\n",
      "    22.75           20.28\n",
      "    22.90           20.82\n",
      "    20.76           21.10\n",
      "    18.88           19.23\n",
      "    22.70           17.72\n",
      "    22.15           20.89\n",
      "    22.57           20.47\n",
      "    11.70           20.84\n",
      "    14.30           11.95\n",
      "    1.85            4.62\n",
      "    2.00            5.06\n",
      "    2.43            4.90\n",
      "    2.40            5.11\n",
      "    2.09            5.12\n",
      "    2.48            4.24\n",
      "    2.10            4.60\n",
      "    1.94            4.32\n",
      "    2.02            4.28\n",
      "    1.06            4.27\n",
      "    20.25            3.59\n",
      "    8.95            9.31\n",
      "    15.89            9.52\n",
      "    21.99           15.10\n",
      "    21.16           20.10\n",
      "    21.66           19.40\n",
      "    28.79           19.96\n",
      "    34.37           25.68\n",
      "    32.31           30.22\n",
      "    27.18           28.55\n",
      "    42.36           24.43\n",
      "    45.53           37.62\n",
      "    34.86           40.62\n",
      "    35.71           30.68\n",
      "    26.82           31.36\n",
      "    34.76           24.05\n",
      "    10.67           12.89\n",
      "    6.45           10.74\n",
      "    14.44            7.28\n",
      "    49.76           44.45\n",
      "    47.23           44.51\n",
      "    43.06           42.15\n",
      "    36.94           38.16\n",
      "    35.94           32.27\n",
      "    23.83           31.39\n",
      "    33.37           21.46\n",
      "    17.84           29.23\n",
      "    26.12           16.55\n",
      "    8.71           10.41\n",
      "    7.35            9.18\n",
      "    8.66            8.02\n",
      "    14.05            9.17\n",
      "    18.13           13.60\n",
      "    25.49           16.94\n",
      "    23.47           22.94\n",
      "    20.23           21.30\n",
      "    14.97           18.65\n",
      "    14.44           14.32\n",
      "    10.11           13.95\n",
      "    8.03           10.38\n",
      "    7.45            8.70\n",
      "    3.17            8.21\n",
      "    7.75            4.95\n",
      "    13.51           10.69\n",
      "    17.00           13.14\n",
      "    19.50           16.00\n",
      "    20.85           18.05\n",
      "    21.42           19.15\n",
      "    27.50           19.61\n",
      "    23.67           24.59\n",
      "    25.51           21.45\n",
      "    16.21           22.96\n",
      "    16.57           15.33\n",
      "    16.00           15.67\n",
      "    15.60           15.19\n",
      "    14.90           14.85\n",
      "    7.71           14.29\n",
      "    8.60            8.42\n",
      "    1.20            4.52\n",
      "    2.55            3.63\n",
      "    1.36            4.51\n",
      "    1.27            3.74\n",
      "    1.04            3.68\n",
      "    0.98            3.53\n",
      "    1.17            3.49\n",
      "    1.33            3.61\n",
      "    0.99            3.73\n",
      "    0.91            3.49\n",
      "    0.80            3.45\n",
      "    0.80            3.37\n",
      "    0.81            3.39\n",
      "    0.63            3.37\n",
      "    5.11            3.27\n",
      "    1.28            4.00\n",
      "    0.89            3.70\n",
      "    0.68            3.44\n",
      "    0.77            3.30\n",
      "    1.50            3.36\n",
      "    1.23            3.83\n",
      "    1.32            3.66\n",
      "    1.02            3.71\n",
      "    0.67            3.52\n",
      "    0.78            3.29\n",
      "    0.46            3.37\n",
      "    0.51            3.16\n",
      "    0.30            3.19\n",
      "    3.10            3.06\n",
      "    5.18            4.89\n",
      "    2.01            5.11\n",
      "    1.56            4.16\n",
      "    1.13            3.87\n",
      "    1.95            3.59\n",
      "    1.89            4.19\n",
      "    0.30            3.98\n",
      "    0.49            2.70\n",
      "    0.68            3.19\n",
      "    0.75            3.31\n",
      "    0.60            3.35\n",
      "    1.01            3.05\n",
      "    0.63            3.43\n",
      "    0.30            3.10\n",
      "    0.13            2.93\n",
      "    143.43          118.71\n",
      "    135.38          147.02\n",
      "    129.73          137.58\n",
      "    117.19          133.60\n",
      "    147.95          117.71\n",
      "    112.36          152.01\n",
      "    113.15          112.61\n",
      "    127.88          113.20\n",
      "    108.90          129.30\n",
      "    117.37          108.85\n",
      "    78.06          117.83\n",
      "    79.75           72.92\n",
      "    88.08           75.60\n",
      "    94.83           84.20\n",
      "    121.00           91.75\n",
      "    72.75           54.00\n",
      "    62.30           67.22\n",
      "    72.40           56.35\n",
      "    73.55           66.80\n",
      "    81.40           68.14\n",
      "    98.85           77.26\n",
      "    110.15           97.57\n",
      "    94.20          110.21\n",
      "    83.08           92.24\n",
      "    88.25           79.25\n",
      "    95.70           85.27\n",
      "    95.84           93.97\n",
      "    107.90           94.13\n",
      "    94.05          107.69\n",
      "    88.62           92.04\n",
      "    30.90           20.82\n",
      "    25.90           27.54\n",
      "    29.95           23.32\n",
      "    32.00           26.65\n",
      "    28.05           28.30\n",
      "    27.70           25.03\n",
      "    27.50           24.79\n",
      "    26.45           24.57\n",
      "    21.57           23.78\n",
      "    24.46           19.93\n",
      "    26.26           22.17\n",
      "    25.51           23.65\n",
      "    26.78           23.06\n",
      "    16.32           24.03\n",
      "    16.14           15.52\n",
      "    2.20            5.42\n",
      "    2.45            4.37\n",
      "    2.26            4.53\n",
      "    1.54            3.24\n",
      "    26.70           21.22\n",
      "    27.30           23.93\n",
      "    31.70           24.42\n",
      "    33.95           28.02\n",
      "    30.65           29.86\n",
      "    32.25           27.14\n",
      "    33.75           28.47\n",
      "    33.40           29.69\n",
      "    30.45           29.40\n",
      "    32.60           27.01\n",
      "    32.95           28.76\n",
      "    34.39           29.03\n",
      "    37.11           30.21\n",
      "    25.28           32.57\n",
      "    30.88           22.77\n",
      "    3.10            5.09\n",
      "    5.49            4.84\n",
      "    4.35            6.62\n",
      "    3.85            5.73\n",
      "    4.27            5.36\n",
      "    3.50            5.62\n",
      "    2.75            5.10\n",
      "    2.42            4.60\n",
      "    1.60            4.39\n",
      "    1.87            3.83\n",
      "    1.17            4.00\n",
      "    0.47            3.55\n",
      "    1.38            3.08\n",
      "    0.95            3.67\n",
      "    3.10            3.36\n",
      "    26.71           16.32\n",
      "    28.12           23.93\n",
      "    26.33           25.08\n",
      "    26.96           23.62\n",
      "    27.59           24.10\n",
      "    27.67           24.58\n",
      "    31.07           24.74\n",
      "    28.26           27.49\n",
      "    21.38           25.20\n",
      "    24.22           19.55\n",
      "    25.95           22.40\n",
      "    24.27           23.39\n",
      "    29.13           21.92\n",
      "    13.97           25.95\n",
      "    17.70           14.33\n",
      "    80.34           65.71\n",
      "    97.95           76.38\n",
      "    102.06           96.27\n",
      "    123.77          100.69\n",
      "    125.14          124.94\n",
      "    110.24          127.94\n",
      "    129.24          109.95\n",
      "    92.90          131.02\n",
      "    60.28           90.18\n",
      "    67.35           54.42\n",
      "    58.58           61.09\n",
      "    82.54           52.61\n",
      "    86.59           78.01\n",
      "    47.98           82.89\n",
      "    68.50           42.62\n",
      "    15.02           10.46\n",
      "    17.18           14.37\n",
      "    15.38           16.13\n",
      "    20.97           14.84\n",
      "    16.36           19.39\n",
      "    17.19           15.64\n",
      "    29.15           18.37\n",
      "    29.85           25.73\n",
      "    27.85           26.47\n",
      "    21.40           24.84\n",
      "    14.85           19.64\n",
      "    17.00           14.18\n",
      "    14.25           16.07\n",
      "    10.25           14.49\n",
      "    7.41            9.09\n",
      "    10.84            7.83\n",
      "    12.22           10.97\n",
      "    11.68           12.00\n",
      "    14.69           11.70\n",
      "    9.57           14.09\n",
      "    13.49           10.00\n",
      "    3.85            6.75\n",
      "    4.08            9.93\n",
      "    3.91            7.41\n",
      "    4.18            5.31\n",
      "    3.84            6.68\n",
      "    2.64            5.19\n",
      "    2.38            5.44\n",
      "    2.90            6.55\n",
      "    2.34            7.35\n",
      "    2.09            3.06\n",
      "    2.80            1.91\n",
      "    2.40            3.45\n",
      "    2.53            2.26\n",
      "    1.51            2.54\n",
      "    1.80            2.13\n",
      "    4.70            3.27\n",
      "    3.55            6.01\n",
      "    3.49            5.08\n",
      "    1.14            4.56\n",
      "    1.81            3.54\n",
      "    2.02            3.98\n",
      "    1.42            4.11\n",
      "    1.40            3.72\n",
      "    1.46            3.72\n",
      "    2.13            3.76\n",
      "    2.26            4.19\n",
      "    2.16            4.34\n",
      "    1.96            4.24\n",
      "    3.35            4.14\n",
      "    3.50            5.01\n",
      "    3.27            5.15\n",
      "    3.23            4.96\n",
      "    3.34            4.97\n",
      "    14.01            4.95\n",
      "    11.44           13.54\n",
      "    9.05           11.43\n",
      "    6.23            9.45\n",
      "    2.86            7.11\n",
      "    4.79            4.69\n",
      "    6.85            7.27\n",
      "    6.32            7.43\n",
      "    6.54            7.00\n",
      "    8.14            7.12\n",
      "    10.17            8.44\n",
      "    10.65           10.04\n",
      "    12.89           10.64\n",
      "    14.16           12.58\n",
      "    8.73           13.63\n",
      "    10.04            8.96\n",
      "    11.33           10.39\n",
      "    11.30           11.37\n",
      "    7.41           11.43\n",
      "    7.23            8.00\n",
      "    10.06            8.07\n",
      "    14.01           32.15\n",
      "    23.32           11.75\n",
      "    59.00           47.80\n",
      "    58.18           48.81\n",
      "    55.38           50.36\n",
      "    43.85           43.49\n",
      "    47.61           35.37\n",
      "    50.04           37.61\n",
      "    43.35           44.53\n",
      "    44.87           38.03\n",
      "    17.83           44.17\n",
      "    25.60           22.60\n",
      "    15.10           11.61\n",
      "    16.10           14.40\n",
      "    17.90           15.29\n",
      "    23.60           16.75\n",
      "    20.90           21.41\n",
      "    28.55           19.18\n",
      "    43.55           25.50\n",
      "    46.00           38.74\n",
      "    37.79           41.07\n",
      "    31.02           33.18\n",
      "    31.05           27.47\n",
      "    29.52           27.44\n",
      "    46.72           26.20\n",
      "    44.54           41.60\n",
      "    71.95           39.58\n",
      "    8.15            8.56\n",
      "    8.04            8.54\n",
      "    4.35            8.41\n",
      "    5.30            5.47\n",
      "    4.35            5.84\n",
      "    4.40            5.68\n",
      "    4.50            5.68\n",
      "    5.45            5.77\n",
      "    5.90            6.52\n",
      "    4.70            6.86\n",
      "    4.15            5.92\n",
      "    5.17            5.50\n",
      "    4.32            6.31\n",
      "    4.24            5.65\n",
      "    4.52            5.56\n",
      "    4.51            5.79\n",
      "    3.94            5.83\n",
      "    4.14            5.38\n",
      "    2.38            5.50\n",
      "    1.62            3.92\n",
      "    1.04            3.90\n",
      "    0.64            3.52\n",
      "    0.42            3.26\n",
      "    0.31            3.12\n",
      "    0.35            3.05\n",
      "    1.60            3.08\n",
      "    0.53            3.90\n",
      "    0.25            3.19\n",
      "    0.18            2.99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0.62            2.93\n",
      "    5.15            8.01\n",
      "    6.33            6.34\n",
      "    7.18            7.27\n",
      "    5.24            7.97\n",
      "    4.97            6.44\n",
      "    3.66            6.18\n",
      "    2.72            5.24\n",
      "    2.68            4.62\n",
      "    1.05            4.60\n",
      "    0.94            3.52\n",
      "    0.38            3.45\n",
      "    4.41            3.09\n",
      "    1.26            5.78\n",
      "    0.69            3.65\n",
      "    0.56            3.29\n",
      "    1.19            3.76\n",
      "    1.46            3.64\n",
      "    1.08            3.79\n",
      "    1.91            3.54\n",
      "    4.06            4.09\n",
      "    4.37            5.54\n",
      "    9.49            5.74\n",
      "    17.42           10.02\n",
      "    7.65           16.41\n",
      "    9.94            8.25\n",
      "    8.30           10.11\n",
      "    6.88            8.77\n",
      "    8.02            7.61\n",
      "    4.68            8.57\n",
      "    7.21            5.90\n",
      "    29.90           27.99\n",
      "    30.29           26.56\n",
      "    26.39           26.87\n",
      "    24.73           23.67\n",
      "    23.99           22.32\n",
      "    23.48           21.73\n",
      "    27.20           21.29\n",
      "    26.93           24.36\n",
      "    24.64           24.10\n",
      "    26.89           22.25\n",
      "    29.38           24.08\n",
      "    25.03           26.14\n",
      "    26.50           22.56\n",
      "    22.26           23.78\n",
      "    24.03           20.30\n",
      "    11.64            9.82\n",
      "    11.80           10.96\n",
      "    11.81           11.39\n",
      "    12.05           11.39\n",
      "    11.22           11.68\n",
      "    12.46           10.28\n",
      "    12.16           11.77\n",
      "    11.25           12.05\n",
      "    8.88           11.22\n",
      "    9.58           10.49\n",
      "    10.78           10.29\n",
      "    10.87           11.28\n",
      "    11.45           11.17\n",
      "    7.31           12.12\n",
      "    7.82            9.69\n",
      "    24.00           23.89\n",
      "    27.15           21.76\n",
      "    27.38           24.49\n",
      "    30.04           24.52\n",
      "    28.15           26.68\n",
      "    24.60           25.09\n",
      "    24.84           22.13\n",
      "    6.84            6.17\n",
      "    6.92            7.68\n",
      "    6.20            7.75\n",
      "    4.76            7.16\n",
      "    9.60            6.06\n",
      "    5.49            6.55\n",
      "    5.02            6.24\n",
      "    5.69            6.81\n",
      "    7.98            4.57\n",
      "    6.93            9.12\n",
      "    9.70            7.78\n",
      "    10.10           10.01\n",
      "    8.64           10.34\n",
      "    7.94            9.01\n",
      "    7.79            7.69\n",
      "    7.62            7.24\n",
      "    7.25            7.30\n",
      "    13.86            7.16\n",
      "    23.86           12.06\n",
      "    16.00           15.42\n",
      "    17.98           14.89\n",
      "    15.70           16.76\n",
      "    18.64           14.91\n",
      "    23.33           17.10\n",
      "    25.41           20.98\n",
      "    31.91           22.50\n",
      "    42.10           28.53\n",
      "    26.04           37.49\n",
      "    33.16           23.39\n",
      "    30.82           29.31\n",
      "    27.67           27.43\n",
      "    24.66           24.88\n",
      "    6.63           22.27\n",
      "    10.36            7.67\n",
      "    24.43           22.81\n",
      "    26.43           33.13\n",
      "    28.73           18.82\n",
      "    28.46           32.44\n",
      "    31.90           22.70\n",
      "    27.82           30.82\n",
      "    24.31           27.26\n",
      "    21.70           19.58\n",
      "    19.28           17.45\n",
      "    18.18            6.35\n",
      "    16.33          135.81\n",
      "    19.91            1.99\n",
      "    19.33           59.83\n",
      "    13.77           18.19\n",
      "    10.06            9.47\n",
      "    11.65           10.47\n",
      "    14.66           11.63\n",
      "    11.02           14.10\n",
      "    8.95           11.11\n",
      "    9.55            9.44\n",
      "    10.95            9.93\n",
      "    12.00           11.07\n",
      "    10.59           11.95\n",
      "    10.10           10.84\n",
      "    11.04           10.38\n",
      "    11.80           11.22\n",
      "    8.26           11.80\n",
      "    4.12            8.96\n",
      "    5.25            5.53\n",
      "    3.13            5.73\n",
      "    8.51            4.83\n",
      "    6.47            8.98\n",
      "    5.76            7.43\n",
      "    9.26            6.74\n",
      "    6.43            9.52\n",
      "    6.92            7.33\n",
      "    9.36            7.69\n",
      "    6.07            9.66\n",
      "    7.39            6.92\n",
      "    8.81            7.97\n",
      "    2.90            9.14\n",
      "    4.22            4.65\n",
      "    2.50            5.47\n",
      "    2.24            4.32\n",
      "    23.63           25.99\n",
      "    33.88           21.37\n",
      "    30.65           29.77\n",
      "    31.79           27.14\n",
      "    28.54           28.12\n",
      "    29.81           25.43\n",
      "    30.00           26.56\n",
      "    27.65           26.58\n",
      "    22.71           24.69\n",
      "    20.73           20.76\n",
      "    26.13           19.01\n",
      "    15.15           23.38\n",
      "    15.68           14.51\n",
      "    0.11            3.08\n",
      "    0.12            2.93\n",
      "    0.07            2.94\n",
      "    0.08            2.91\n",
      "    0.27            2.92\n",
      "    0.28            3.04\n",
      "    0.21            3.04\n",
      "    0.36            3.00\n",
      "    0.22            3.10\n",
      "    0.29            3.01\n",
      "    0.14            3.05\n",
      "    0.10            2.95\n",
      "    0.07            2.93\n",
      "    0.08            2.91\n",
      "    3.81            2.92\n",
      "    13.66           18.42\n",
      "    12.51           13.26\n",
      "    9.65           94.34\n",
      "    6.50            9.94\n",
      "    5.10            7.40\n",
      "    4.57            6.33\n",
      "    5.75            5.95\n",
      "    4.12            6.79\n",
      "    4.68            5.55\n",
      "    36.00           32.60\n",
      "    37.35           33.31\n",
      "    39.30           34.55\n",
      "    39.65           36.41\n",
      "    42.20           36.88\n",
      "    41.75           39.33\n",
      "    42.10           38.96\n",
      "    44.90           39.39\n",
      "    45.67           42.01\n",
      "    48.37           42.81\n",
      "    60.39           43.19\n",
      "    57.87           54.98\n",
      "    45.39           52.53\n",
      "    58.00           40.87\n",
      "    42.74           52.25\n",
      "    10.16           10.42\n",
      "    10.62           10.62\n",
      "    9.76           11.02\n",
      "    11.90           10.05\n",
      "    13.09           11.82\n",
      "    14.35           12.81\n",
      "    13.99           13.86\n",
      "    7.14           13.60\n",
      "    10.28            7.98\n",
      "    76.07           74.16\n",
      "    87.11           71.21\n",
      "    92.96           84.66\n",
      "    106.39           91.12\n",
      "    114.44          106.55\n",
      "    118.56          115.01\n",
      "    137.42          120.30\n",
      "    160.12          140.91\n",
      "    148.29          166.97\n",
      "    181.56          152.67\n",
      "    209.16          189.79\n",
      "    188.63          219.58\n",
      "    192.68          197.06\n",
      "    180.09          201.94\n",
      "    206.83          187.84\n",
      "    25.12           22.27\n",
      "    30.22           22.58\n",
      "    29.40           27.08\n",
      "    37.78           26.35\n",
      "    44.08           33.40\n",
      "    48.46           39.35\n",
      "    48.68           43.73\n",
      "    53.71           43.87\n",
      "    42.59           48.55\n",
      "    53.45           37.94\n",
      "    44.43           48.40\n",
      "    36.02           39.78\n",
      "    45.33           31.80\n",
      "    28.40           40.62\n",
      "    32.47           25.48\n",
      "    73.67           90.27\n",
      "    109.35           74.77\n",
      "    128.87          115.79\n",
      "    152.04          136.71\n",
      "    149.86          164.76\n",
      "    162.98          160.22\n",
      "    169.96          173.60\n",
      "    192.74          181.62\n",
      "    165.71          207.83\n",
      "    183.95          179.74\n",
      "    183.38          189.71\n",
      "    169.42          189.00\n",
      "    218.95          174.44\n",
      "    237.95          224.09\n",
      "    290.31          241.00\n",
      "    38.84           29.95\n",
      "    40.80           34.27\n",
      "    44.98           36.14\n",
      "    56.86           40.09\n",
      "    48.43           51.37\n",
      "    51.72           43.33\n",
      "    47.78           46.46\n",
      "    33.13           42.72\n",
      "    29.91           29.27\n",
      "    31.58           26.64\n",
      "    28.69           28.07\n",
      "    34.09           25.66\n",
      "    38.04           30.09\n",
      "    16.39           33.57\n",
      "    31.39           15.59\n",
      "    1.31            3.65\n",
      "    1.11            3.81\n",
      "    1.07            3.60\n",
      "    0.76            3.58\n",
      "    0.95            3.38\n",
      "    1.12            3.59\n",
      "    1.06            3.62\n",
      "    1.71            3.62\n",
      "    1.02            4.03\n",
      "    1.62            3.55\n",
      "    1.51            3.98\n",
      "    1.14            3.90\n",
      "    1.54            3.68\n",
      "    0.60            3.94\n",
      "    0.71            3.43\n",
      "    1.88            4.26\n",
      "    2.60            4.09\n",
      "    2.64            4.56\n",
      "    6.30            4.58\n",
      "    5.12            7.26\n",
      "    5.32            6.35\n",
      "    3.07            6.50\n",
      "    3.98            4.86\n",
      "    2.33            5.47\n",
      "    2.72            4.38\n",
      "    4.87            4.63\n",
      "    2.25            6.16\n",
      "    3.79            4.33\n",
      "    6.80            9.31\n",
      "    6.20            7.63\n",
      "    6.55            7.16\n",
      "    5.45            7.47\n",
      "    6.25            6.56\n",
      "    5.50            7.19\n",
      "    7.45            6.62\n",
      "    6.55            8.17\n",
      "    4.81            7.44\n",
      "    3.06            6.07\n",
      "    4.09            4.83\n",
      "    2.28            5.53\n",
      "    2.01            4.32\n",
      "    1.23            4.14\n",
      "    2.39            3.63\n",
      "    1.94            4.08\n",
      "    0.67            4.13\n",
      "    0.36            3.29\n",
      "    0.35            3.06\n",
      "    1.77            3.05\n",
      "    8.85            3.99\n",
      "    12.74           11.89\n",
      "    13.24           12.43\n",
      "    8.96           12.88\n",
      "    20.59            9.37\n",
      "    16.60           18.87\n",
      "    18.79           15.56\n",
      "    19.54           17.34\n",
      "    18.92           18.03\n",
      "    9.40           17.52\n",
      "    19.14            9.67\n",
      "    27.22           17.52\n",
      "    17.21           24.33\n",
      "    13.95           16.07\n",
      "    9.15           13.42\n",
      "    12.62            9.45\n",
      "    62.93           45.50\n",
      "    55.83           56.80\n",
      "    56.04           50.10\n",
      "    59.54           50.31\n",
      "    59.55           53.62\n",
      "    58.08           53.62\n",
      "    56.51           52.34\n",
      "    60.16           50.86\n",
      "    55.68           54.27\n",
      "    61.80           50.12\n",
      "    61.61           56.34\n",
      "    62.18           56.26\n",
      "    67.77           56.70\n",
      "    58.78           62.07\n",
      "    57.42           53.50\n",
      "    34.60           29.97\n",
      "    32.70           30.24\n",
      "    32.00           28.69\n",
      "    26.71           28.06\n",
      "    28.89           23.77\n",
      "    34.93           25.81\n",
      "    36.58           30.79\n",
      "    36.99           32.45\n",
      "    36.46           32.77\n",
      "    36.65           32.28\n",
      "    34.00           31.94\n",
      "    25.96           30.04\n",
      "    26.74           23.50\n",
      "    26.84           24.54\n",
      "    56.05           35.57\n",
      "    49.30           50.34\n",
      "    51.55           44.04\n",
      "    57.25           46.17\n",
      "    53.25           51.58\n",
      "    53.75           47.75\n",
      "    58.10           48.28\n",
      "    55.30           52.36\n",
      "    47.53           49.71\n",
      "    48.15           42.35\n",
      "    52.18           43.07\n",
      "    48.31           46.86\n",
      "    53.79           43.20\n",
      "    36.56           48.30\n",
      "    32.75           32.31\n",
      "    16.85           18.10\n",
      "    15.60           15.83\n",
      "    16.26           14.81\n",
      "    12.66           15.35\n",
      "    19.45           12.40\n",
      "    16.03           17.96\n",
      "    14.83           15.15\n",
      "    10.12           14.17\n",
      "    5.79           10.32\n",
      "    6.34            6.81\n",
      "    4.37            7.24\n",
      "    3.32            5.72\n",
      "    1.77            4.99\n",
      "    0.74            3.98\n",
      "    2.82            3.31\n",
      "    84.73           73.58\n",
      "    86.38           81.87\n",
      "    81.02           81.71\n",
      "    81.50           78.33\n",
      "    72.76           80.32\n",
      "    68.89           73.10\n",
      "    62.39           69.85\n",
      "    68.56           66.11\n",
      "    84.67           68.09\n",
      "    71.19           81.38\n",
      "    49.34           66.18\n",
      "    51.19           41.62\n",
      "    59.60           44.04\n",
      "    45.76           43.98\n",
      "    42.94           35.20\n",
      "    83.09           82.92\n",
      "    87.40           78.70\n",
      "    102.11           84.25\n",
      "    110.99          101.32\n",
      "    119.89          111.20\n",
      "    124.84          120.59\n",
      "    124.02          126.51\n",
      "    133.02          125.70\n",
      "    181.53          134.82\n",
      "    205.63          187.60\n",
      "    199.98          215.16\n",
      "    162.16          208.75\n",
      "    184.63          168.11\n",
      "    153.90          190.39\n",
      "    180.92          160.22\n",
      "    107.90          119.31\n",
      "    109.90          107.71\n",
      "    105.70          109.95\n",
      "    108.95          105.23\n",
      "    119.40          108.89\n",
      "    124.70          120.48\n",
      "    137.55          126.30\n",
      "    177.45          140.77\n",
      "    174.68          184.13\n",
      "    178.97          181.11\n",
      "    156.33          185.77\n",
      "    182.30          161.32\n",
      "    193.11          189.29\n",
      "    172.49          201.01\n",
      "    191.85          178.77\n",
      "    13.52           11.49\n",
      "    13.61           13.17\n",
      "    15.51           13.41\n",
      "    15.53           14.85\n",
      "    16.42           14.86\n",
      "    17.55           15.28\n",
      "    17.18           16.40\n",
      "    17.14           16.16\n",
      "    15.61           13.01\n",
      "    17.89           14.78\n",
      "    19.58           17.05\n",
      "    19.98           18.37\n",
      "    22.21           18.73\n",
      "    14.88           20.41\n",
      "    21.78           14.75\n",
      "    11.14           10.45\n",
      "    9.08           11.14\n",
      "    10.17            9.48\n",
      "    10.18           10.35\n",
      "    12.55           10.41\n",
      "    9.17           12.31\n",
      "    9.08            9.56\n",
      "    8.48            9.67\n",
      "    6.65            9.19\n",
      "    7.06            7.72\n",
      "    6.17            8.10\n",
      "    5.23            7.39\n",
      "    4.84            6.69\n",
      "    2.33            6.40\n",
      "    3.47            4.62\n",
      "    31.30           24.12\n",
      "    28.08           27.70\n",
      "    27.88           25.10\n",
      "    28.38           24.94\n",
      "    29.72           25.36\n",
      "    33.60           26.42\n",
      "    36.40           29.61\n",
      "    35.18           31.96\n",
      "    29.17           30.92\n",
      "    30.96           25.97\n",
      "    26.71           27.42\n",
      "    22.61           23.94\n",
      "    26.45           20.62\n",
      "    20.17           23.77\n",
      "    21.59           18.61\n",
      "    21.50           23.58\n",
      "    8.75            9.16\n",
      "    7.21            9.25\n",
      "    7.30            8.00\n",
      "    6.40            8.07\n",
      "    6.47            7.34\n",
      "    7.25            7.39\n",
      "    5.99            8.03\n",
      "    6.82            7.02\n",
      "    5.83            7.68\n",
      "    5.89            6.90\n",
      "    6.20            6.94\n",
      "    5.54            7.18\n",
      "    4.14            6.67\n",
      "    3.59            5.59\n",
      "    4.00            5.20\n",
      "    1.70            4.14\n",
      "    1.73            4.09\n",
      "    10.21            4.18\n",
      "    11.55           10.67\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    9.98           11.78\n",
      "    3.58           10.43\n",
      "    4.04            5.39\n",
      "    4.28            5.73\n",
      "    0.89            6.04\n",
      "    1.49            3.58\n",
      "    1.39            4.04\n",
      "    1.55            3.95\n",
      "    1.64            4.08\n",
      "    1.00            4.14\n",
      "    1.74            3.73\n",
      "    22.50           21.79\n",
      "    22.19           20.69\n",
      "    21.89           20.43\n",
      "    14.21           20.20\n",
      "    16.07           13.91\n",
      "    18.67           15.33\n",
      "    7.78           17.45\n",
      "    13.00            8.36\n",
      "    13.90           12.68\n",
      "    11.87           13.36\n",
      "    10.99           11.76\n",
      "    6.17           11.05\n",
      "    7.46            7.12\n",
      "    5.77            6.56\n",
      "    6.06            6.85\n",
      "    7.60            7.07\n",
      "    5.86            8.26\n",
      "    7.19            7.00\n",
      "    7.10            7.94\n",
      "    7.15            7.91\n",
      "    7.11            7.95\n",
      "    6.99            7.92\n",
      "    8.20            7.81\n",
      "    9.91            8.76\n",
      "    11.00           10.15\n",
      "    11.95           11.06\n",
      "    11.20           11.84\n",
      "    15.59           11.26\n",
      "    126.15          105.02\n",
      "    113.00          127.92\n",
      "    128.95          113.38\n",
      "    131.75          131.11\n",
      "    129.40          134.27\n",
      "    130.80          131.61\n",
      "    148.45          133.22\n",
      "    166.00          152.71\n",
      "    159.00          171.78\n",
      "    188.59          164.23\n",
      "    173.15          196.15\n",
      "    176.39          179.49\n",
      "    198.30          182.99\n",
      "    127.42          206.53\n",
      "    171.24          129.35\n",
      "    180.00           26.27\n",
      "    144.99          186.87\n",
      "    205.01          148.91\n",
      "    205.01          213.48\n",
      "    180.00          213.54\n",
      "    137.00          186.83\n",
      "    83.00          140.11\n",
      "    48.50           79.14\n",
      "    21.51           43.28\n",
      "    43.35           32.09\n",
      "    46.00           38.33\n",
      "    42.70           40.84\n",
      "    44.78           37.73\n",
      "    48.65           39.68\n",
      "    56.70           43.34\n",
      "    47.45           50.92\n",
      "    50.10           42.21\n",
      "    50.18           44.70\n",
      "    57.22           44.79\n",
      "    58.58           51.40\n",
      "    56.28           52.68\n",
      "    57.40           50.52\n",
      "    41.99           51.54\n",
      "    48.82           37.03\n",
      "    0.90            3.61\n",
      "    0.61            3.44\n",
      "    0.34            3.25\n",
      "    2.15            3.08\n",
      "    22.59           16.45\n",
      "    32.26           20.58\n",
      "    30.55           28.47\n",
      "    32.46           27.10\n",
      "    23.94           28.65\n",
      "    28.35           21.68\n",
      "    30.97           25.36\n",
      "    33.96           27.43\n",
      "    34.98           29.89\n",
      "    37.07           30.68\n",
      "    37.25           32.60\n",
      "    35.08           32.76\n",
      "    31.78           30.87\n",
      "    21.37           28.22\n",
      "    25.01           19.47\n",
      "    25.58           21.61\n",
      "    22.35           23.06\n",
      "    26.73           20.50\n",
      "    24.59           23.95\n",
      "    24.97           22.50\n",
      "    34.28           22.52\n",
      "    31.59           30.31\n",
      "    34.51           28.14\n",
      "    34.60           30.53\n",
      "    42.39           30.61\n",
      "    58.32           37.69\n",
      "    55.38           52.81\n",
      "    58.91           50.04\n",
      "    26.60           53.03\n",
      "    24.28           24.04\n",
      "    22.98           22.06\n",
      "    31.12           21.21\n",
      "    27.49           27.46\n",
      "    25.87           24.41\n",
      "    22.20           23.12\n",
      "    19.84           20.35\n",
      "    25.96           18.37\n",
      "    29.02           23.86\n",
      "    27.22           25.76\n",
      "    31.45           24.67\n",
      "    29.82           27.89\n",
      "    20.63           26.52\n",
      "    30.48           18.87\n",
      "    28.65           27.44\n",
      "    29.72           25.68\n",
      "    9.35            8.43\n",
      "    10.50            9.83\n",
      "    10.15           10.79\n",
      "    10.90           10.50\n",
      "    10.90           11.13\n",
      "    10.65           11.09\n",
      "    11.00           10.91\n",
      "    10.80           11.21\n",
      "    10.04           11.06\n",
      "    9.23           10.42\n",
      "    9.34            9.80\n",
      "    9.53            9.86\n",
      "    9.63           10.00\n",
      "    6.76           10.13\n",
      "    5.79            7.74\n",
      "    7.14            2.97\n",
      "    5.93            7.93\n",
      "    2.40            6.97\n",
      "    2.87            4.43\n",
      "    2.25            4.73\n",
      "    5.76            4.33\n",
      "    64.28           43.99\n",
      "    51.78           58.32\n",
      "    74.91           46.57\n",
      "    82.89           69.67\n",
      "    80.72           79.00\n",
      "    105.30           76.46\n",
      "    111.01          104.82\n",
      "    114.36          111.17\n",
      "    102.26          114.93\n",
      "    117.13          101.38\n",
      "    164.11          118.12\n",
      "    127.51          169.36\n",
      "    86.40          129.11\n",
      "    54.61           82.76\n",
      "    65.52           48.95\n",
      "    43.06           28.81\n",
      "    38.11           38.07\n",
      "    39.54           33.32\n",
      "    41.02           34.71\n",
      "    40.65           36.12\n",
      "    42.30           35.83\n",
      "    45.04           37.39\n",
      "    44.58           39.81\n",
      "    36.69           39.33\n",
      "    39.75           31.98\n",
      "    38.55           35.02\n",
      "    37.37           33.82\n",
      "    37.79           32.76\n",
      "    23.70           34.25\n",
      "    20.31           22.36\n",
      "    9.42           16.16\n",
      "    11.09            9.35\n",
      "    15.04           10.80\n",
      "    15.58           13.96\n",
      "    18.49           14.44\n",
      "    10.13           16.92\n",
      "    12.29           10.07\n",
      "    46.35           31.28\n",
      "    45.95           41.12\n",
      "    45.35           40.12\n",
      "    48.75           39.55\n",
      "    47.85           42.91\n",
      "    47.90           42.59\n",
      "    53.30           41.79\n",
      "    47.15           47.21\n",
      "    37.91           41.51\n",
      "    38.60           33.12\n",
      "    41.30           33.06\n",
      "    44.10           35.56\n",
      "    43.99           38.49\n",
      "    24.92           37.88\n",
      "    28.70           21.79\n",
      "    18.70           16.59\n",
      "    18.80           17.37\n",
      "    19.35           17.47\n",
      "    13.57           17.93\n",
      "    16.70           13.22\n",
      "    13.03           15.74\n",
      "    14.05           12.76\n",
      "    12.90           13.58\n",
      "    10.00           12.65\n",
      "    11.15           10.28\n",
      "    11.29           11.22\n",
      "    15.03           11.34\n",
      "    16.20           14.40\n",
      "    12.79           15.34\n",
      "    25.70           12.56\n",
      "    0.65            3.17\n",
      "    0.70            3.26\n",
      "    3.13            3.29\n",
      "    2.97            4.88\n",
      "    3.75            4.78\n",
      "    3.35            5.29\n",
      "    2.85            5.03\n",
      "    2.66            4.70\n",
      "    1.89            4.57\n",
      "    2.04            4.07\n",
      "    1.88            4.16\n",
      "    1.36            4.07\n",
      "    0.90            3.72\n",
      "    0.78            3.42\n",
      "    0.82            3.35\n",
      "    1.00            3.69\n",
      "    1.08            3.51\n",
      "    1.49            3.55\n",
      "    1.36            3.82\n",
      "    1.04            3.74\n",
      "    1.00            3.53\n",
      "    2.08            3.50\n",
      "    3.80            4.20\n",
      "    3.09            5.33\n",
      "    2.39            4.86\n",
      "    2.18            4.39\n",
      "    1.47            4.25\n",
      "    1.27            3.79\n",
      "    0.60            3.66\n",
      "    1.43            3.25\n",
      "    72.57           52.26\n",
      "    69.12           67.98\n",
      "    76.44           64.87\n",
      "    78.31           72.25\n",
      "    82.37           73.86\n",
      "    86.05           77.97\n",
      "    87.05           82.65\n",
      "    84.94           84.28\n",
      "    66.49           81.65\n",
      "    67.33           60.22\n",
      "    73.16           64.00\n",
      "    64.63           69.81\n",
      "    70.90           61.99\n",
      "    32.86           64.23\n",
      "    43.62           33.07\n",
      "    26.15           28.58\n",
      "    27.50           23.39\n",
      "    18.60           24.53\n",
      "    21.75           17.24\n",
      "    35.10           19.82\n",
      "    40.10           30.63\n",
      "    38.25           35.33\n",
      "    50.00           33.41\n",
      "    42.04           44.68\n",
      "    38.85           37.12\n",
      "    26.09           34.07\n",
      "    20.53           23.31\n",
      "    8.02           18.74\n",
      "    9.37            8.53\n",
      "    10.41            9.65\n",
      "    16.34           14.77\n",
      "    16.55           15.46\n",
      "    16.19           15.62\n",
      "    14.77           15.34\n",
      "    17.25           14.22\n",
      "    17.50           16.24\n",
      "    17.21           16.43\n",
      "    16.00           16.17\n",
      "    15.58           15.22\n",
      "    16.02           14.84\n",
      "    16.93           15.23\n",
      "    13.11           15.94\n",
      "    13.20           12.86\n",
      "    5.43            6.92\n",
      "    5.50            6.60\n",
      "    5.21            6.65\n",
      "    4.85            6.43\n",
      "    5.00            6.15\n",
      "    4.57            6.26\n",
      "    4.50            5.93\n",
      "    4.62            5.87\n",
      "    4.58            5.98\n",
      "    4.75            5.94\n",
      "    4.92            6.07\n",
      "    4.36            6.19\n",
      "    4.97            5.78\n",
      "    10.28           10.59\n",
      "    12.45           10.46\n",
      "    20.88           12.30\n",
      "    35.82           19.04\n",
      "    44.92           31.73\n",
      "    64.29           39.89\n",
      "    70.05           58.83\n",
      "    89.53           63.52\n",
      "    66.10           86.32\n",
      "    32.00           59.43\n",
      "    20.42           28.19\n",
      "    21.65           18.84\n",
      "    34.87           19.85\n",
      "    32.98           30.68\n",
      "    25.51           29.10\n",
      "    0.21            3.02\n",
      "    0.14            2.93\n",
      "    0.14            2.92\n",
      "    5.85            2.91\n",
      "    3.48            6.85\n",
      "    2.11            5.10\n",
      "    0.97            4.20\n",
      "    2.65            3.45\n",
      "    86.51           94.23\n",
      "    114.61           80.80\n",
      "    134.12          114.52\n",
      "    148.92          135.86\n",
      "    168.59          151.97\n",
      "    182.36          173.54\n",
      "    167.34          188.40\n",
      "    127.06          174.00\n",
      "    98.91          129.95\n",
      "    119.32           96.21\n",
      "    123.99          119.46\n",
      "    108.72          124.39\n",
      "    138.87          107.81\n",
      "    60.19          140.78\n",
      "    74.49           53.64\n",
      "    4.30            5.88\n",
      "    4.55            5.63\n",
      "    2.76            5.91\n",
      "    2.02            4.68\n",
      "    1.92            4.16\n",
      "    2.15            4.12\n",
      "    4.08            4.27\n",
      "    2.83            5.55\n",
      "    1.64            4.71\n",
      "    1.94            3.93\n",
      "    11.25            4.12\n",
      "    1.20           11.29\n",
      "    1.44            3.62\n",
      "    0.74            3.79\n",
      "    1.02            3.33\n",
      "    16.49           10.36\n",
      "    4.70           15.58\n",
      "    4.37            6.01\n",
      "    4.23            5.77\n",
      "    3.94            5.68\n",
      "    5.35            5.44\n",
      "    4.48            6.54\n",
      "    3.18            5.87\n",
      "    5.08            4.94\n",
      "    11.02            6.33\n",
      "    7.58           11.12\n",
      "    10.46            8.31\n",
      "    18.66           10.66\n",
      "    10.62           15.42\n",
      "    13.71           10.71\n",
      "    40.70           36.26\n",
      "    44.45           34.53\n",
      "    45.88           39.19\n",
      "    47.32           40.09\n",
      "    48.11           41.06\n",
      "    45.48           41.16\n",
      "    45.68           38.72\n",
      "    47.21           39.18\n",
      "    49.27           40.47\n",
      "    56.21           39.59\n",
      "    59.49           46.89\n",
      "    64.89           51.16\n",
      "    63.49           56.63\n",
      "    60.30           53.37\n",
      "    62.50           50.10\n",
      "    9.97           10.30\n",
      "    9.92           10.62\n",
      "    4.90           10.31\n",
      "    5.15            6.26\n",
      "    5.53            6.09\n",
      "    4.75            6.61\n",
      "    7.13            5.91\n",
      "    3.89            7.85\n",
      "    3.34            5.32\n",
      "    2.19            5.16\n",
      "    1.18            4.51\n",
      "    0.41            3.67\n",
      "    0.20            3.02\n",
      "    0.55            2.93\n",
      "    7.70            8.72\n",
      "    4.00            8.41\n",
      "    3.15            5.48\n",
      "    2.95            4.91\n",
      "    2.83            4.78\n",
      "    4.90            4.70\n",
      "    9.20            6.19\n",
      "    13.20            9.62\n",
      "    6.31           12.89\n",
      "    10.16            7.25\n",
      "    9.86           10.39\n",
      "    9.01           10.15\n",
      "    13.11            9.46\n",
      "    11.34           12.70\n",
      "    12.54           11.32\n",
      "    12.10           15.00\n",
      "    17.15           11.95\n",
      "    27.95           16.08\n",
      "    31.15           24.91\n",
      "    32.40           27.52\n",
      "    39.30           28.55\n",
      "    37.45           34.60\n",
      "    28.75           32.85\n",
      "    28.18           25.54\n",
      "    32.15           25.08\n",
      "    22.76           28.31\n",
      "    17.01           20.64\n",
      "    24.90           15.94\n",
      "    11.85           22.39\n",
      "    13.54           11.73\n",
      "    15.00           16.31\n",
      "    12.71           14.32\n",
      "    10.70           12.43\n",
      "    10.00           10.79\n",
      "    9.32           10.22\n",
      "    60.37           48.47\n",
      "    57.89           54.12\n",
      "    64.32           51.72\n",
      "    70.83           57.95\n",
      "    67.42           63.96\n",
      "    72.24           60.04\n",
      "    65.26           66.04\n",
      "    80.17           58.89\n",
      "    85.17           75.07\n",
      "    126.79           80.62\n",
      "    117.92          127.09\n",
      "    95.90          117.73\n",
      "    97.77           93.07\n",
      "    77.94           95.10\n",
      "    98.39           71.98\n",
      "    26.32           22.05\n",
      "    23.92           23.56\n",
      "    21.11           21.55\n",
      "    22.92           19.27\n",
      "    21.92           20.71\n",
      "    29.98           19.91\n",
      "    37.01           26.45\n",
      "    38.97           32.33\n",
      "    36.16           34.32\n",
      "    31.06           31.44\n",
      "    40.93           27.46\n",
      "    33.73           36.06\n",
      "    34.39           29.56\n",
      "    29.88           29.97\n",
      "    32.39           26.39\n",
      "    4.05            5.37\n",
      "    3.24            5.50\n",
      "    4.25            4.95\n",
      "    15.39            5.63\n",
      "    10.09           14.70\n",
      "    10.70           10.34\n",
      "    7.26           10.82\n",
      "    3.40            7.98\n",
      "    3.66            4.93\n",
      "    2.62            5.14\n",
      "    2.29            4.47\n",
      "    4.90            4.22\n",
      "    3.30            6.06\n",
      "    3.48            4.92\n",
      "    9.34           14.52\n",
      "    10.19            9.72\n",
      "    11.45           10.41\n",
      "    11.36           11.44\n",
      "    8.40           11.39\n",
      "    7.28            8.93\n",
      "    7.08            8.04\n",
      "    9.48            7.87\n",
      "    6.62            9.85\n",
      "    8.49            7.51\n",
      "    9.32            9.01\n",
      "    8.85            9.69\n",
      "    7.46            9.30\n",
      "    6.39            8.17\n",
      "    8.55            7.30\n",
      "    11.80            6.56\n",
      "    14.65           11.75\n",
      "    10.02           14.07\n",
      "    15.64           10.28\n",
      "    44.20           33.89\n",
      "    33.95           39.51\n",
      "    29.80           29.96\n",
      "    25.30           26.61\n",
      "    24.40           22.77\n",
      "    21.15           22.33\n",
      "    16.10           19.45\n",
      "    14.85           15.34\n",
      "    18.39           14.34\n",
      "    23.40           17.25\n",
      "    20.59           21.14\n",
      "    20.68           18.90\n",
      "    18.50           18.93\n",
      "    13.91           17.22\n",
      "    14.76           13.50\n",
      "    2.40            3.15\n",
      "    1.94            4.43\n",
      "    1.44            4.15\n",
      "    0.67            3.81\n",
      "    0.19            3.27\n",
      "    4.19            3.00\n",
      "    2.40            4.92\n",
      "    2.29            4.44\n",
      "    1.73            4.36\n",
      "    1.91            3.99\n",
      "    2.21            4.11\n",
      "    1.73            4.31\n",
      "    2.36            3.99\n",
      "    2.00            4.41\n",
      "    1.44            4.16\n",
      "    1.37            3.80\n",
      "    1.18            3.76\n",
      "    0.28            2.84\n",
      "    0.31            2.82\n",
      "    0.30            3.06\n",
      "    0.28            3.06\n",
      "    0.25            3.03\n",
      "    6.50            3.02\n",
      "    4.73            7.41\n",
      "    4.13            6.05\n",
      "    4.15            5.57\n",
      "    4.13            5.60\n",
      "    6.73            5.59\n",
      "    5.72            7.58\n",
      "    5.70            6.78\n",
      "    5.70            6.74\n",
      "    4.47            6.76\n",
      "    4.87            6.13\n",
      "    6.73            5.53\n",
      "    6.61            6.76\n",
      "    6.35            6.93\n",
      "    2.69            4.71\n",
      "    26.06           20.71\n",
      "    31.25           23.31\n",
      "    26.10           27.52\n",
      "    43.20           23.31\n",
      "    38.20           26.37\n",
      "    35.05           33.63\n",
      "    34.85           30.77\n",
      "    33.90           30.60\n",
      "    33.90           29.83\n",
      "    31.00           29.82\n",
      "    31.80           27.45\n",
      "    30.40           28.11\n",
      "    32.06           26.97\n",
      "    34.32           28.32\n",
      "    35.72           30.19\n",
      "    43.66           31.33\n",
      "    46.11           38.81\n",
      "    43.46           41.15\n",
      "    47.96           38.63\n",
      "    13.28           13.91\n",
      "    11.01           14.40\n",
      "    11.12           12.69\n",
      "    13.80           12.83\n",
      "    14.38           15.06\n",
      "    8.83           15.40\n",
      "    10.05           10.99\n",
      "    8.98           11.95\n",
      "    3.15           11.04\n",
      "    6.69            5.08\n",
      "    4.03            7.83\n",
      "    3.02            5.86\n",
      "    2.55            5.09\n",
      "    1.68            3.88\n",
      "    1.85            3.34\n",
      "    7.48           18.31\n",
      "    6.61            9.11\n",
      "    5.36            7.49\n",
      "    5.58            6.55\n",
      "    4.02            6.70\n",
      "    4.91            5.49\n",
      "    3.74            5.48\n",
      "    4.12            5.61\n",
      "    3.15            5.84\n",
      "    1.03            5.48\n",
      "    39.42           47.96\n",
      "    46.11           34.79\n",
      "    58.03           40.97\n",
      "    86.78           53.11\n",
      "    113.06           83.17\n",
      "    105.20          111.35\n",
      "    100.47          105.03\n",
      "    74.92           99.17\n",
      "    59.86           69.64\n",
      "    84.01           54.05\n",
      "    69.69           79.37\n",
      "    56.23           60.51\n",
      "    52.79           43.87\n",
      "    53.26           40.61\n",
      "    88.55           41.63\n",
      "    36.47           30.72\n",
      "    33.67           31.02\n",
      "    49.01           29.86\n",
      "    40.21           44.15\n",
      "    40.92           35.73\n",
      "    53.80           36.43\n",
      "    59.06           48.66\n",
      "    44.25           53.48\n",
      "    31.58           39.41\n",
      "    34.74           27.92\n",
      "    46.39           30.47\n",
      "    29.82           41.22\n",
      "    45.94           26.46\n",
      "    36.02           40.73\n",
      "    57.61           31.08\n",
      "    85.76           64.35\n",
      "    91.25           83.09\n",
      "    100.52           89.74\n",
      "    108.58          100.49\n",
      "    103.80          109.32\n",
      "    139.19          104.06\n",
      "    143.25          143.34\n",
      "    176.83          147.34\n",
      "    159.23          183.99\n",
      "    209.53          164.91\n",
      "    209.49          218.48\n",
      "    206.37          218.17\n",
      "    255.44          215.39\n",
      "    183.60          255.37\n",
      "    255.95          191.54\n",
      "    16.52           12.42\n",
      "    11.61           15.85\n",
      "    17.02           11.57\n",
      "    21.52           15.37\n",
      "    25.36           19.06\n",
      "    33.20           22.10\n",
      "    34.50           28.48\n",
      "    35.00           29.56\n",
      "    24.23           20.15\n",
      "    18.56           21.87\n",
      "    19.48           17.32\n",
      "    22.00           18.01\n",
      "    21.49           20.18\n",
      "    20.51           19.53\n",
      "    20.41           18.97\n",
      "    20.87           18.86\n",
      "    14.27           19.30\n",
      "    15.87           13.57\n",
      "    13.65           14.99\n",
      "    14.40           12.95\n",
      "    17.92           13.61\n",
      "    10.35           16.55\n",
      "    11.75           10.68\n",
      "    12.15           11.38\n",
      "    10.85           12.04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    14.50           10.89\n",
      "    35.05           13.87\n",
      "    40.05           30.66\n",
      "    40.05           35.35\n",
      "    44.20           35.30\n",
      "    49.60           39.23\n",
      "    36.46           44.23\n",
      "    55.01           31.71\n",
      "    47.78           49.12\n",
      "    40.04           42.43\n",
      "    52.13           34.79\n",
      "    24.73           46.42\n",
      "    27.01           21.98\n",
      "    30.00           25.82\n",
      "    29.82           25.16\n",
      "    28.20           25.61\n",
      "    28.62           23.91\n",
      "    28.29           24.08\n",
      "    27.64           21.87\n",
      "    30.28           26.30\n",
      "    28.39           27.92\n",
      "    28.70           25.95\n",
      "    30.71           26.53\n",
      "    26.02           26.51\n",
      "    25.87           29.13\n",
      "    25.73           22.68\n",
      "    25.77           21.93\n",
      "    25.36           22.54\n",
      "    25.09           21.76\n",
      "    25.09           21.40\n",
      "    24.33           19.46\n",
      "    25.69           23.87\n",
      "    25.70           24.40\n",
      "    26.00           23.88\n",
      "    25.78           24.44\n",
      "    22.80           22.81\n",
      "    25.02           26.52\n",
      "    24.50           21.86\n",
      "    25.28           20.99\n",
      "    24.09           22.17\n",
      "    24.00           20.79\n",
      "    24.46           20.58\n",
      "    21.80           18.98\n",
      "    22.95           21.94\n",
      "    23.22           22.31\n",
      "    23.98           22.02\n",
      "    24.83           22.90\n",
      "    18.16           22.04\n",
      "    20.19           22.76\n",
      "    4.94            5.45\n",
      "    4.81            6.10\n",
      "    5.69            6.01\n",
      "    4.89            6.69\n",
      "    4.38            6.07\n",
      "    4.27            5.69\n",
      "    5.39            5.63\n",
      "    5.55            6.49\n",
      "    5.73            6.61\n",
      "    6.88            6.75\n",
      "    9.09            8.07\n",
      "    7.24            9.69\n",
      "    6.78            8.25\n",
      "    4.31            7.91\n",
      "    6.90            6.01\n",
      "    19.48           21.05\n",
      "    23.22           17.94\n",
      "    29.51           20.83\n",
      "    34.87           26.16\n",
      "    32.35           30.42\n",
      "    41.59           28.31\n",
      "    1.37            3.75\n",
      "    1.20            3.73\n",
      "    3.43            3.61\n",
      "    3.41            5.07\n",
      "    2.16            5.06\n",
      "    4.76            4.24\n",
      "    4.05            6.03\n",
      "    1.28            5.49\n",
      "    0.42            3.64\n",
      "    0.76            3.11\n",
      "    0.33            3.31\n",
      "    0.25            3.03\n",
      "    0.17            2.97\n",
      "    0.18            2.90\n",
      "    0.30            2.88\n",
      "    2.57            4.96\n",
      "    2.85            4.87\n",
      "    3.64            4.97\n",
      "    3.78            5.52\n",
      "    4.00            5.65\n",
      "    3.66            5.83\n",
      "    4.07            5.56\n",
      "    4.01            5.88\n",
      "    3.93            5.89\n",
      "    5.33            5.66\n",
      "    6.13            6.76\n",
      "    5.82            7.43\n",
      "    6.12            5.93\n",
      "    6.85            7.59\n",
      "    9.54            8.18\n",
      "    0.78            3.35\n",
      "    1.90            3.34\n",
      "    1.41            4.07\n",
      "    0.82            3.74\n",
      "    0.52            3.36\n",
      "    5.04            3.18\n",
      "    4.08            6.27\n",
      "    4.09            5.52\n",
      "    2.12            5.52\n",
      "    4.77            4.21\n",
      "    3.27            6.05\n",
      "    1.56            4.97\n",
      "    1.52            3.85\n",
      "    0.56            3.83\n",
      "    0.86            3.18\n",
      "    10.67           10.25\n",
      "    14.76           10.81\n",
      "    9.60           14.16\n",
      "    8.30            9.96\n",
      "    6.74            8.85\n",
      "    6.53            7.59\n",
      "    10.16            7.45\n",
      "    7.01           10.42\n",
      "    6.11            7.73\n",
      "    3.58            7.12\n",
      "    1.97            5.15\n",
      "    2.06            4.14\n",
      "    1.65            4.15\n",
      "    3.06            3.92\n",
      "    0.30            3.05\n",
      "    0.31            3.04\n",
      "    0.60            3.05\n",
      "    1.85            3.24\n",
      "    3.18            4.05\n",
      "    3.39            4.93\n",
      "    3.10            5.06\n",
      "    2.98            4.87\n",
      "    2.94            4.79\n",
      "    4.50            4.77\n",
      "    8.99            5.86\n",
      "    9.51            9.44\n",
      "    7.87            9.87\n",
      "    11.07            8.53\n",
      "    24.87           11.14\n"
     ]
    }
   ],
   "source": [
    "print('Test values:    Predicted values:')\n",
    "for r,p in zip(true_y_test.flatten(),predicted_y_test.flatten()):\n",
    "    print(f'    {r:.2f}    {p:>12.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
