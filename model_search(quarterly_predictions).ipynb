{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from joblib import dump\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./datasets/fundamental_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23857, 98)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data = data['growth']\n",
    "data = data.drop(columns='growth')\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data, y_data, test_size=0.2, random_state=12)\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise data\n",
    "normaliser = preprocessing.MinMaxScaler()\n",
    "X_train = normaliser.fit_transform(X_train)\n",
    "X_test = normaliser.transform(X_test)\n",
    "\n",
    "# Y normaliser\n",
    "y_normaliser = preprocessing.MinMaxScaler()\n",
    "Y_train = y_normaliser.fit_transform(Y_train.to_numpy().reshape(-1, 1))\n",
    "Y_test = y_normaliser.transform(Y_test.to_numpy().reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./normalisers/fundamental_y_normaliser.joblib']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save scalers for future use\n",
    "dump(normaliser, './normalisers/fundamental_x_normaliser.joblib')\n",
    "dump(y_normaliser, './normalisers/fundamental_y_normaliser.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dense(x, y, batch_size=512, epochs=24, **params):\n",
    "    \n",
    "    # List of parameters\n",
    "    if 'density' not in params: params['density'] = x.shape[1]\n",
    "    if 'activation' not in params: params['activation'] = 'relu'\n",
    "    if 'optimizer' not in params: params['optimizer'] = 'adam'\n",
    "    if 'shuffle' not in params: params['shuffle'] = False\n",
    "    \n",
    "    # Model definition\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(params['density'], input_shape= (98,), activation=params['activation']))\n",
    "    \n",
    "    density = params['density']//2\n",
    "    while density >= 12:\n",
    "        if 'dropout' in params:\n",
    "            model.add(Dropout(params['dropout']))\n",
    "        model.add(Dense(density, activation=params['activation']))\n",
    "        density //= 2\n",
    "            \n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    \n",
    "    model.compile(loss='mse', optimizer=params['optimizer'])\n",
    "    \n",
    "    if 'callbacks' in params:\n",
    "        callback = model.fit(x=x, y=y, validation_split=0.1, batch_size=batch_size, epochs=epochs, shuffle=params['shuffle'],\n",
    "                            callbacks=params['callbacks'])\n",
    "    else:\n",
    "        callback = model.fit(x=x, y=y, validation_split=0.1, batch_size=batch_size, epochs=epochs, shuffle=params['shuffle'])\n",
    "    \n",
    "    return [model, callback, params]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evolutive algorith to search for the most optimal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_genes(x, y, population_size, population=[]):\n",
    "    if population_size-len(population) < 0:\n",
    "        print('population size must be greater or equal than actual population')\n",
    "        return\n",
    "    \n",
    "    if len(population) > 0:\n",
    "        if len(population) < 3:\n",
    "            print('population should be empty or 3 at least')\n",
    "            return\n",
    "        \n",
    "        population[2] = breed_genes(x, y, population[0][2].copy())\n",
    "        population[1] = breed_genes(x, y, combine=(population[0][2], population[1][2]))\n",
    "        population = population[:3]\n",
    "    \n",
    "    for _ in range(population_size-len(population)):\n",
    "        subject = breed_genes(x, y)\n",
    "        population.append(subject)\n",
    "        \n",
    "    return population\n",
    "\n",
    "def breed_genes(x, y, genes={}, combine=None):\n",
    "    genes['x'] = x\n",
    "    genes['y'] = y\n",
    "    \n",
    "    if type(combine) is list or type(combine) is tuple:\n",
    "        genes['density'] = combine[np.random.randint(0,2)]['density']\n",
    "        genes['activation'] = combine[np.random.randint(0,2)]['activation']\n",
    "        genes['optimizer'] = combine[np.random.randint(0,2)]['optimizer']\n",
    "        genes['shuffle'] = combine[np.random.randint(0,2)]['shuffle']\n",
    "        \n",
    "        genes['dropout'] = combine[np.random.randint(0,2)].get('dropout')\n",
    "        if genes['dropout'] is None: del genes['dropout']\n",
    "            \n",
    "    else:\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['density'] = int((np.random.randint(x.shape[1]//2,x.shape[1]*2.66)//2)*2)\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            activation = [\n",
    "                'relu',\n",
    "                'sigmoid',\n",
    "                'softplus',\n",
    "                'softsign',\n",
    "                'tanh',\n",
    "                'selu',\n",
    "                'elu',\n",
    "                'exponential'\n",
    "            ]\n",
    "            genes['activation'] = activation[np.random.randint(0,8)]\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            optimizer = [\n",
    "                'sgd',\n",
    "                'rmsprop',\n",
    "                'adam',\n",
    "                'adadelta',\n",
    "                'adagrad',\n",
    "                'adamax',\n",
    "                'nadam'\n",
    "            ]\n",
    "            genes['optimizer'] = optimizer[np.random.randint(0,7)]\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['shuffle'] = True\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['dropout'] = np.random.randint(1,4)/10\n",
    "            \n",
    "    new_model = build_dense(**genes)\n",
    "        \n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def breed_population(x, y, generations, population_size, population=[]):\n",
    "    \n",
    "    if generations > 1 and population_size < 3:\n",
    "        print('population size should be of a minimum of 3 for more than one generation')\n",
    "        return\n",
    "    \n",
    "    for g in range(generations):\n",
    "        print(f'\\nGENERATION {g}\\n')\n",
    "        population = set_genes(x, y, population_size, population)\n",
    "        population = sorted(population, key=lambda x: x[1].history['val_loss'][-1]+x[1].history['loss'][-1])\n",
    "        \n",
    "    return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GENERATION 0\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 32us/step - loss: 0.0037 - val_loss: 3.4480e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 9.0661e-05 - val_loss: 3.4474e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 9.0677e-05 - val_loss: 3.4482e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 9.0647e-05 - val_loss: 3.4474e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 9.0671e-05 - val_loss: 3.4481e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 9.0664e-05 - val_loss: 3.4495e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 9.0668e-05 - val_loss: 3.4507e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 9.0642e-05 - val_loss: 3.4674e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 9.0628e-05 - val_loss: 3.4770e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 9.0674e-05 - val_loss: 3.4558e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 9.0693e-05 - val_loss: 3.4477e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 9.0632e-05 - val_loss: 3.4470e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 9.0640e-05 - val_loss: 3.4485e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 9.0685e-05 - val_loss: 3.4473e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 9.0640e-05 - val_loss: 3.4604e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 9.0664e-05 - val_loss: 3.4473e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 9.0642e-05 - val_loss: 3.4480e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 9.0680e-05 - val_loss: 3.4471e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 9.0651e-05 - val_loss: 3.4486e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 9.0665e-05 - val_loss: 3.4467e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 9.0629e-05 - val_loss: 3.4468e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 9.0658e-05 - val_loss: 3.4511e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 9.0639e-05 - val_loss: 3.4475e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 9.0670e-05 - val_loss: 3.4524e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0745 - val_loss: 3.2558e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 8.8824e-05 - val_loss: 3.2554e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 8.8834e-05 - val_loss: 3.2554e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 8.8826e-05 - val_loss: 3.2562e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 8.8798e-05 - val_loss: 3.2573e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 8.8813e-05 - val_loss: 3.2557e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 8.8822e-05 - val_loss: 3.2558e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 8.8827e-05 - val_loss: 3.2581e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 8.8828e-05 - val_loss: 3.2556e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 8.8820e-05 - val_loss: 3.2556e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 8.8820e-05 - val_loss: 3.2553e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 8.8822e-05 - val_loss: 3.2553e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 8.8811e-05 - val_loss: 3.2606e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 8.8811e-05 - val_loss: 3.2561e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 8.8825e-05 - val_loss: 3.2553e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 8.8819e-05 - val_loss: 3.2591e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 8.8820e-05 - val_loss: 3.2564e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 8.8811e-05 - val_loss: 3.2765e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 8.8831e-05 - val_loss: 3.2552e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 8.8807e-05 - val_loss: 3.2552e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 8.8807e-05 - val_loss: 3.2559e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 8.8839e-05 - val_loss: 3.2552e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 8.8829e-05 - val_loss: 3.2552e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 8.8819e-05 - val_loss: 3.2552e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.2578 - val_loss: 4.4453e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 1.0363e-04 - val_loss: 4.4409e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 1.0365e-04 - val_loss: 4.4428e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 4us/step - loss: 1.0352e-04 - val_loss: 4.4431e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 1.0355e-04 - val_loss: 4.4409e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 1.0367e-04 - val_loss: 4.4466e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 1.0362e-04 - val_loss: 4.4498e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 1.0356e-04 - val_loss: 4.4391e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 1.0361e-04 - val_loss: 4.4728e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 1.0348e-04 - val_loss: 4.4371e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 1.0361e-04 - val_loss: 4.4655e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 1.0358e-04 - val_loss: 4.4369e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 1.0359e-04 - val_loss: 4.4377e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 1.0363e-04 - val_loss: 4.4344e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 1.0354e-04 - val_loss: 4.4369e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 1.0358e-04 - val_loss: 4.4438e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 1.0349e-04 - val_loss: 4.4320e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 4us/step - loss: 1.0357e-04 - val_loss: 4.4315e-05\n",
      "Epoch 19/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 5us/step - loss: 1.0348e-04 - val_loss: 4.4441e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 1.0345e-04 - val_loss: 4.4341e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 4us/step - loss: 1.0349e-04 - val_loss: 4.4329e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 1.0339e-04 - val_loss: 4.4380e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 1.0344e-04 - val_loss: 4.4468e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 1.0341e-04 - val_loss: 4.4298e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0131 - val_loss: 5.7720e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0026 - val_loss: 0.0153\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 0.0064 - val_loss: 0.0040\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0057 - val_loss: 0.0041\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0041 - val_loss: 0.0035\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 0.0040 - val_loss: 0.0035\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 0.0030 - val_loss: 0.0023\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0086 - val_loss: 0.0022\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0072 - val_loss: 0.0039\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0063 - val_loss: 0.0044\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0054 - val_loss: 0.0044\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0043 - val_loss: 0.0036\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0035 - val_loss: 0.0027\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0014 - val_loss: 9.6793e-04\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0010 - val_loss: 7.5699e-04\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 8.9491e-04 - val_loss: 9.6670e-04\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 7.1275e-04 - val_loss: 7.2966e-04\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 8.3382e-04 - val_loss: 6.9297e-04\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 6.5485e-04 - val_loss: 6.3782e-04\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0107 - val_loss: 0.0124\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0091 - val_loss: 0.0073\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0079 - val_loss: 0.0061\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0070 - val_loss: 0.0050\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0059 - val_loss: 0.0055\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0041 - val_loss: 0.0033\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0012 - val_loss: 9.8775e-04\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 8.5392e-04 - val_loss: 9.3914e-04\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0010 - val_loss: 6.2851e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 7.8548e-04 - val_loss: 9.8642e-04\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 7.0891e-04 - val_loss: 5.3329e-04\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0728 - val_loss: 2.0127e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0144 - val_loss: 2.9158e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0061 - val_loss: 1.9898e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 0.0024 - val_loss: 4.3866e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 9.2294e-04 - val_loss: 2.2185e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 4.8196e-04 - val_loss: 1.6586e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 3.0812e-04 - val_loss: 6.7992e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 2.5806e-04 - val_loss: 5.3147e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 2.2892e-04 - val_loss: 6.4593e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 1.7746e-04 - val_loss: 5.7831e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.4843e-04 - val_loss: 3.8723e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.4570e-04 - val_loss: 4.8098e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.5371e-04 - val_loss: 6.9556e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.1997e-04 - val_loss: 4.4026e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 1.3347e-04 - val_loss: 4.7046e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 1.1967e-04 - val_loss: 7.0650e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 1.3530e-04 - val_loss: 6.0790e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 1.1753e-04 - val_loss: 4.3341e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 1.2666e-04 - val_loss: 8.5435e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 1.1260e-04 - val_loss: 4.0966e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 1.3410e-04 - val_loss: 8.2518e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 1.3514e-04 - val_loss: 5.8425e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 1.1567e-04 - val_loss: 5.8488e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 1.1228e-04 - val_loss: 5.0435e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: nan - val_loss: nan\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - ETA: 0s - loss: n - 0s 6us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: nan - val_loss: nan\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 6us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: nan - val_loss: nan\n",
      "\n",
      "GENERATION 1\n",
      "\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0459 - val_loss: 1.3451e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 2.8042e-04 - val_loss: 5.1383e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 9.0877e-05 - val_loss: 3.1554e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 8.7870e-05 - val_loss: 3.1482e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 8.7857e-05 - val_loss: 3.1473e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 8.7850e-05 - val_loss: 3.1477e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 8.7871e-05 - val_loss: 3.1482e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 8.7852e-05 - val_loss: 3.1475e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 8.7838e-05 - val_loss: 3.1511e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 8.7872e-05 - val_loss: 3.1487e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 8.7865e-05 - val_loss: 3.1474e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 8.7860e-05 - val_loss: 3.1473e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 8.7847e-05 - val_loss: 3.1479e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 8.7866e-05 - val_loss: 3.1483e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 8.7845e-05 - val_loss: 3.1528e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 8.7876e-05 - val_loss: 3.1512e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 8.7857e-05 - val_loss: 3.1471e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 8.7865e-05 - val_loss: 3.1482e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 8.7849e-05 - val_loss: 3.1484e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 8.7851e-05 - val_loss: 3.1473e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 8.7859e-05 - val_loss: 3.1475e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 8.7858e-05 - val_loss: 3.1548e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 8.7866e-05 - val_loss: 3.1524e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 8.7870e-05 - val_loss: 3.1511e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.3704 - val_loss: 4.0277e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 9.7343e-05 - val_loss: 4.0296e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 9.7338e-05 - val_loss: 4.0279e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 9.7377e-05 - val_loss: 4.0268e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 9.7383e-05 - val_loss: 4.0265e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 9.7344e-05 - val_loss: 4.0257e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 9.7324e-05 - val_loss: 4.0249e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 9.7342e-05 - val_loss: 4.0277e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 9.7345e-05 - val_loss: 4.0327e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 9.7348e-05 - val_loss: 4.0235e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 9.7314e-05 - val_loss: 4.0237e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 9.7312e-05 - val_loss: 4.0246e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 9.7317e-05 - val_loss: 4.0306e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 9.7333e-05 - val_loss: 4.0224e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 9.7323e-05 - val_loss: 4.0223e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 9.7317e-05 - val_loss: 4.0219e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 9.7304e-05 - val_loss: 4.0291e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 9.7311e-05 - val_loss: 4.0228e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 9.7285e-05 - val_loss: 4.0221e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 9.7292e-05 - val_loss: 4.0195e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 9.7286e-05 - val_loss: 4.0190e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 9.7251e-05 - val_loss: 4.0228e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 9.7274e-05 - val_loss: 4.0177e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 5us/step - loss: 9.7268e-05 - val_loss: 4.0183e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 24us/step - loss: 0.0036 - val_loss: 0.0015\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.5813e-04 - val_loss: 4.0018e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.3056e-05 - val_loss: 3.7825e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.2133e-05 - val_loss: 4.3710e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.3004e-05 - val_loss: 3.6172e-05\n",
      "Epoch 6/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.1693e-04 - val_loss: 1.9917e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 2.9863e-04 - val_loss: 3.6013e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.6183e-05 - val_loss: 3.5303e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 1.8232e-04 - val_loss: 2.6862e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 1.2036e-04 - val_loss: 4.6833e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 1.0142e-04 - val_loss: 3.6935e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.5842e-05 - val_loss: 4.1097e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 2.2973e-04 - val_loss: 3.7480e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.0489e-05 - val_loss: 3.3826e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.1073e-05 - val_loss: 3.3836e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.2613e-05 - val_loss: 3.3566e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.0046e-04 - val_loss: 3.5252e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.0818e-04 - val_loss: 4.3909e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.0861e-05 - val_loss: 3.4182e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.3809e-04 - val_loss: 8.7083e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.5353e-05 - val_loss: 3.2898e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.3566e-05 - val_loss: 3.4656e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.1077e-04 - val_loss: 1.7486e-04\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.3646e-04 - val_loss: 3.3019e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 25us/step - loss: 7.8751e-04 - val_loss: 3.1524e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.2026e-05 - val_loss: 3.1523e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.8076e-05 - val_loss: 3.1489e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.5396e-05 - val_loss: 3.1494e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 8.9977e-05 - val_loss: 3.1479e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 8.7923e-05 - val_loss: 3.1547e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 8.7858e-05 - val_loss: 3.1461e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.7935e-05 - val_loss: 3.1480e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.7873e-05 - val_loss: 3.1493e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.7901e-05 - val_loss: 3.1498e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 8.7880e-05 - val_loss: 3.1486e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.7883e-05 - val_loss: 3.1463e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 8.7882e-05 - val_loss: 3.1462e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 8.7850e-05 - val_loss: 3.1531e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 8.7881e-05 - val_loss: 3.1461e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 8.7878e-05 - val_loss: 3.1588e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 8.7895e-05 - val_loss: 3.1496e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 8.7946e-05 - val_loss: 3.1502e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 8.7867e-05 - val_loss: 3.1458e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 8.7865e-05 - val_loss: 3.1467e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 8.7897e-05 - val_loss: 3.1488e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 8.7899e-05 - val_loss: 3.1471e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 8.7901e-05 - val_loss: 3.1709e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - ETA: 0s - loss: 9.3826e-0 - 0s 7us/step - loss: 8.7906e-05 - val_loss: 3.1506e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 27us/step - loss: 0.0031 - val_loss: 6.1812e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.2905e-05 - val_loss: 3.3344e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.0353e-05 - val_loss: 3.3067e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.1385e-05 - val_loss: 3.2928e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.0681e-05 - val_loss: 3.4131e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.3757e-05 - val_loss: 4.6265e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.5826e-05 - val_loss: 3.5902e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 9.0891e-05 - val_loss: 6.4534e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0036 - val_loss: 3.3449e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 9.0015e-05 - val_loss: 9.6069e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 9.3560e-05 - val_loss: 3.2044e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.8267e-05 - val_loss: 3.8270e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.8665e-05 - val_loss: 3.2235e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 8.8461e-05 - val_loss: 3.1747e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.8619e-05 - val_loss: 3.1741e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 8.8494e-05 - val_loss: 3.1965e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.8730e-05 - val_loss: 3.2015e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.8532e-05 - val_loss: 3.1723e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 8.8968e-05 - val_loss: 3.7841e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.9618e-05 - val_loss: 3.3225e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.9129e-05 - val_loss: 3.2102e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 8.9067e-05 - val_loss: 3.2353e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.9221e-05 - val_loss: 3.1907e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.9298e-05 - val_loss: 3.1865e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 32us/step - loss: 0.0434 - val_loss: 3.5892e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 1.5891e-04 - val_loss: 3.3559e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.1131e-04 - val_loss: 5.2483e-04\n",
      "Epoch 5/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 8us/step - loss: 1.3552e-04 - val_loss: 3.7794e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 7.5456e-04 - val_loss: 8.2233e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 1.7112e-04 - val_loss: 3.1930e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 9.6173e-05 - val_loss: 1.9915e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.9705e-04 - val_loss: 4.4569e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 9.3439e-05 - val_loss: 4.1791e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.4679e-04 - val_loss: 3.0243e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 5.5079e-04 - val_loss: 1.1475e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 1.2251e-04 - val_loss: 6.9508e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 5.4747e-04 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 2.8793e-04 - val_loss: 3.1546e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 9.9291e-05 - val_loss: 3.6937e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 1.0473e-04 - val_loss: 1.7015e-04\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.6283e-04 - val_loss: 7.4911e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.0168e-04 - val_loss: 3.1576e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.9256e-05 - val_loss: 4.3389e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 1.2379e-04 - val_loss: 8.2536e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 6.7590e-04 - val_loss: 2.8410e-04\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.1915e-04 - val_loss: 3.2370e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 9.2862e-05 - val_loss: 4.0770e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 34us/step - loss: 0.0032 - val_loss: 3.4764e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 1.4489e-04 - val_loss: 3.2070e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 1.0039e-04 - val_loss: 3.2222e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 9.3326e-05 - val_loss: 3.1649e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 9.1074e-05 - val_loss: 3.1587e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 9.0411e-05 - val_loss: 3.1509e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.9602e-05 - val_loss: 3.1463e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 8.9159e-05 - val_loss: 3.1470e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.8777e-05 - val_loss: 3.1460e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 8.8867e-05 - val_loss: 3.1456e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.8561e-05 - val_loss: 3.1462e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.8869e-05 - val_loss: 3.1461e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.8447e-05 - val_loss: 3.1456e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 9.0857e-05 - val_loss: 3.1461e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.8226e-05 - val_loss: 3.1455e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 8.8748e-05 - val_loss: 3.1475e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.8303e-05 - val_loss: 3.1455e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.8214e-05 - val_loss: 3.1474e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.8097e-05 - val_loss: 3.1468e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.8127e-05 - val_loss: 3.1466e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.8034e-05 - val_loss: 3.1484e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.8003e-05 - val_loss: 3.1457e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.8960e-05 - val_loss: 3.1505e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.8004e-05 - val_loss: 3.1458e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 34us/step - loss: 0.0342 - val_loss: 2.1167e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0076 - val_loss: 1.4556e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0049 - val_loss: 8.4888e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0034 - val_loss: 7.1641e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0025 - val_loss: 6.3025e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0019 - val_loss: 5.1241e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0014 - val_loss: 4.4215e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0010 - val_loss: 4.4557e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.4474e-04 - val_loss: 4.0265e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 6.5922e-04 - val_loss: 4.9034e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 5.2751e-04 - val_loss: 3.5941e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 4.3421e-04 - val_loss: 3.4073e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 3.6574e-04 - val_loss: 3.8540e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 3.0230e-04 - val_loss: 3.6119e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 2.6696e-04 - val_loss: 3.5856e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 2.3857e-04 - val_loss: 4.0447e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 2.1986e-04 - val_loss: 3.4024e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 2.0363e-04 - val_loss: 3.3330e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 1.9160e-04 - val_loss: 3.8473e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 1.8216e-04 - val_loss: 3.7180e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 1.7090e-04 - val_loss: 3.6181e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.6842e-04 - val_loss: 3.4668e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.6087e-04 - val_loss: 3.4895e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 1.5802e-04 - val_loss: 3.3455e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 37us/step - loss: 0.0037 - val_loss: 4.2450e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.7375e-04 - val_loss: 3.3428e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.1585e-04 - val_loss: 3.2273e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 1.0397e-04 - val_loss: 3.1908e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 9.6718e-05 - val_loss: 3.1592e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 9.4015e-05 - val_loss: 3.1633e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 9.2477e-05 - val_loss: 3.1479e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 9.0681e-05 - val_loss: 3.1473e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 9.0119e-05 - val_loss: 3.1460e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.9700e-05 - val_loss: 3.1463e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.9399e-05 - val_loss: 3.1470e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.8927e-05 - val_loss: 3.1466e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.8727e-05 - val_loss: 3.1516e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.8661e-05 - val_loss: 3.1466e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.8649e-05 - val_loss: 3.1461e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.8326e-05 - val_loss: 3.1462e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.8681e-05 - val_loss: 3.1456e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.8286e-05 - val_loss: 3.1473e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.8312e-05 - val_loss: 3.1464e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.8313e-05 - val_loss: 3.1587e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.8132e-05 - val_loss: 3.1486e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.8218e-05 - val_loss: 3.1507e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.8159e-05 - val_loss: 3.1457e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.8036e-05 - val_loss: 3.1505e-05\n",
      "\n",
      "GENERATION 2\n",
      "\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 34us/step - loss: 0.0227 - val_loss: 4.8413e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0090 - val_loss: 7.6953e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0066 - val_loss: 3.7644e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0051 - val_loss: 3.3907e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0041 - val_loss: 4.1672e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0033 - val_loss: 4.0355e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0027 - val_loss: 3.8562e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0023 - val_loss: 4.1718e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0020 - val_loss: 4.1350e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0017 - val_loss: 3.6757e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0015 - val_loss: 3.7806e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0013 - val_loss: 3.8809e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0012 - val_loss: 3.7428e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0011 - val_loss: 3.9565e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.6561e-04 - val_loss: 3.5372e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 8.7900e-04 - val_loss: 3.6813e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 7.9640e-04 - val_loss: 3.2290e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 7.2023e-04 - val_loss: 3.5276e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 6.7074e-04 - val_loss: 3.5982e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 6.3247e-04 - val_loss: 3.4519e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 5.7282e-04 - val_loss: 3.3517e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 5.3830e-04 - val_loss: 3.4059e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 5.0375e-04 - val_loss: 3.1915e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 4.6714e-04 - val_loss: 3.4833e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 32us/step - loss: 0.0016 - val_loss: 5.1743e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 6us/step - loss: 1.0282e-04 - val_loss: 3.9199e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.5300e-05 - val_loss: 3.8360e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.4338e-05 - val_loss: 3.7869e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.4074e-05 - val_loss: 3.7576e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.3761e-05 - val_loss: 3.7358e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.3205e-05 - val_loss: 3.6311e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.3087e-05 - val_loss: 3.6318e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.2230e-05 - val_loss: 3.5006e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.1671e-05 - val_loss: 3.6531e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.1810e-05 - val_loss: 3.5865e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.1943e-05 - val_loss: 3.4365e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.1045e-05 - val_loss: 3.4069e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.0662e-05 - val_loss: 3.4107e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.0455e-05 - val_loss: 3.3745e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.0724e-05 - val_loss: 3.3691e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 9.0229e-05 - val_loss: 3.6949e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.2134e-05 - val_loss: 3.5595e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.1872e-05 - val_loss: 3.3654e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.0341e-05 - val_loss: 3.3418e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.0883e-05 - val_loss: 3.3158e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.0017e-05 - val_loss: 3.4198e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 8.9850e-05 - val_loss: 3.3046e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.0344e-05 - val_loss: 3.3142e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 38us/step - loss: 0.0032 - val_loss: 3.3651e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.4005e-04 - val_loss: 3.6211e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.1742e-04 - val_loss: 3.6743e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.0804e-04 - val_loss: 3.3632e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.0323e-04 - val_loss: 3.2217e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.0029e-04 - val_loss: 3.1841e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.9748e-05 - val_loss: 3.1630e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.7185e-05 - val_loss: 3.1504e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.6464e-05 - val_loss: 3.1486e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.5310e-05 - val_loss: 3.1479e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.4370e-05 - val_loss: 3.1464e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 9.3420e-05 - val_loss: 3.1463e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.3379e-05 - val_loss: 3.1473e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.2860e-05 - val_loss: 3.1473e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.1295e-05 - val_loss: 3.1458e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.1068e-05 - val_loss: 3.1457e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.1106e-05 - val_loss: 3.1456e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.0755e-05 - val_loss: 3.1458e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.0083e-05 - val_loss: 3.1458e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.0115e-05 - val_loss: 3.1457e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 8.9868e-05 - val_loss: 3.1457e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 8.9692e-05 - val_loss: 3.1457e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 8.9540e-05 - val_loss: 3.1460e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 8.9087e-05 - val_loss: 3.1456e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 34us/step - loss: 0.0379 - val_loss: 3.2816e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 3.4253e-04 - val_loss: 3.9934e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.9079e-04 - val_loss: 3.1559e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.5332e-04 - val_loss: 3.3025e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.3292e-04 - val_loss: 3.2006e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.2013e-04 - val_loss: 3.2084e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.1538e-04 - val_loss: 3.2157e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.1128e-04 - val_loss: 3.2369e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.0561e-04 - val_loss: 3.2896e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.0435e-04 - val_loss: 3.3367e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.0297e-04 - val_loss: 3.2989e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.0183e-04 - val_loss: 3.3183e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.0020e-04 - val_loss: 3.2664e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.8346e-05 - val_loss: 3.2313e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.7994e-05 - val_loss: 3.1957e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.7696e-05 - val_loss: 3.1847e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.6275e-05 - val_loss: 3.1599e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.6993e-05 - val_loss: 3.1624e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 9.5671e-05 - val_loss: 3.1755e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.5378e-05 - val_loss: 3.1980e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 9.4993e-05 - val_loss: 3.1860e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.4218e-05 - val_loss: 3.1854e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 9.4613e-05 - val_loss: 3.2205e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.4225e-05 - val_loss: 3.1741e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 37us/step - loss: 0.0038 - val_loss: 3.1634e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 2.1532e-04 - val_loss: 3.4274e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.5470e-04 - val_loss: 3.1997e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.3019e-04 - val_loss: 3.1564e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.2166e-04 - val_loss: 3.1589e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.1459e-04 - val_loss: 3.2203e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.0854e-04 - val_loss: 3.2736e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.0283e-04 - val_loss: 3.3278e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 1.0095e-04 - val_loss: 3.4267e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.9568e-05 - val_loss: 3.5110e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.8666e-05 - val_loss: 3.6094e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.7182e-05 - val_loss: 3.2934e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.6031e-05 - val_loss: 3.2242e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.4385e-05 - val_loss: 3.1565e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.4570e-05 - val_loss: 3.1501e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.4568e-05 - val_loss: 3.1473e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.3468e-05 - val_loss: 3.1480e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.3055e-05 - val_loss: 3.1599e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.2472e-05 - val_loss: 3.1505e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.2570e-05 - val_loss: 3.1611e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.1588e-05 - val_loss: 3.1756e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.1769e-05 - val_loss: 3.1744e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.1328e-05 - val_loss: 3.1688e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 9.1276e-05 - val_loss: 3.1512e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 43us/step - loss: 0.0055 - val_loss: 6.6769e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.8336e-04 - val_loss: 3.3411e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.1850e-04 - val_loss: 3.1566e-05\n",
      "Epoch 4/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 8us/step - loss: 1.0554e-04 - val_loss: 3.1468e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 9.7423e-05 - val_loss: 3.1509e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 9.4808e-05 - val_loss: 3.1497e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 9.3107e-05 - val_loss: 3.1458e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 9.1903e-05 - val_loss: 3.1457e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 9.0806e-05 - val_loss: 3.1458e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 9.0411e-05 - val_loss: 3.1460e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 9.0280e-05 - val_loss: 3.1484e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.9585e-05 - val_loss: 3.1492e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.9228e-05 - val_loss: 3.1496e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.9127e-05 - val_loss: 3.1475e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 8.9131e-05 - val_loss: 3.1456e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.8856e-05 - val_loss: 3.1463e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.8852e-05 - val_loss: 3.1480e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 8.8818e-05 - val_loss: 3.1493e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.8507e-05 - val_loss: 3.1462e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.8757e-05 - val_loss: 3.1457e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.8435e-05 - val_loss: 3.1456e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.8639e-05 - val_loss: 3.1459e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 8.8351e-05 - val_loss: 3.1469e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 8.8312e-05 - val_loss: 3.1470e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 38us/step - loss: 0.0426 - val_loss: 0.0062\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0177 - val_loss: 0.0066\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0121 - val_loss: 0.0065\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0089 - val_loss: 0.0057\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0073 - val_loss: 0.0053\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0060 - val_loss: 0.0045\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0052 - val_loss: 0.0039\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0045 - val_loss: 0.0034\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0034 - val_loss: 0.0023\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0031 - val_loss: 0.0019\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0028 - val_loss: 0.0016\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0026 - val_loss: 0.0014\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0023 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0022 - val_loss: 9.5564e-04\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0020 - val_loss: 8.1169e-04\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0019 - val_loss: 6.6366e-04\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0017 - val_loss: 5.4871e-04\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0016 - val_loss: 4.3628e-04\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0015 - val_loss: 3.5181e-04\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0014 - val_loss: 2.9353e-04\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0013 - val_loss: 2.5536e-04\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0012 - val_loss: 2.2318e-04\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0012 - val_loss: 1.9524e-04\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 48us/step - loss: 0.0033 - val_loss: 3.4348e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 1.2372e-04 - val_loss: 3.1601e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 9.6112e-05 - val_loss: 3.1552e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 9.1806e-05 - val_loss: 3.1464e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.9947e-05 - val_loss: 3.1530e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.8973e-05 - val_loss: 3.1490e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.8781e-05 - val_loss: 3.1462e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.8660e-05 - val_loss: 3.1552e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.8680e-05 - val_loss: 3.1497e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.8346e-05 - val_loss: 3.1468e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.8277e-05 - val_loss: 3.1541e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.8145e-05 - val_loss: 3.1488e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.8204e-05 - val_loss: 3.1475e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.8080e-05 - val_loss: 3.1487e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.8122e-05 - val_loss: 3.1461e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.8039e-05 - val_loss: 3.1488e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.8019e-05 - val_loss: 3.1544e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.8034e-05 - val_loss: 3.1498e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.7948e-05 - val_loss: 3.1462e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.8056e-05 - val_loss: 3.1519e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.7968e-05 - val_loss: 3.1469e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.7984e-05 - val_loss: 3.1500e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.8036e-05 - val_loss: 3.1457e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.7938e-05 - val_loss: 3.1474e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 49us/step - loss: 0.0092 - val_loss: 4.3763e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0025 - val_loss: 3.6160e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0014 - val_loss: 3.1457e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.9764e-04 - val_loss: 3.3567e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 6.2056e-04 - val_loss: 3.4718e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 4.7214e-04 - val_loss: 3.1506e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 3.6096e-04 - val_loss: 3.3163e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 2.9334e-04 - val_loss: 3.3231e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 2.5067e-04 - val_loss: 3.2077e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 2.1318e-04 - val_loss: 3.2212e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.9434e-04 - val_loss: 3.4984e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.7724e-04 - val_loss: 3.3367e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.6843e-04 - val_loss: 3.1504e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.5407e-04 - val_loss: 3.1467e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.4958e-04 - val_loss: 3.9207e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.4210e-04 - val_loss: 3.6433e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.4164e-04 - val_loss: 3.4195e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.3681e-04 - val_loss: 3.3422e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.3752e-04 - val_loss: 1.0561e-04\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.5778e-04 - val_loss: 1.3480e-04\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 2.2703e-04 - val_loss: 1.1822e-04\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.4006e-04 - val_loss: 3.3078e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.2794e-04 - val_loss: 3.6167e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.9521e-04 - val_loss: 1.3965e-04\n",
      "\n",
      "GENERATION 3\n",
      "\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 40us/step - loss: 5.0506e-04 - val_loss: 3.7427e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 8.9291e-05 - val_loss: 3.1677e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 8.8223e-05 - val_loss: 3.1457e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 8.7964e-05 - val_loss: 3.1592e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 8.7908e-05 - val_loss: 3.1495e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 8.8016e-05 - val_loss: 3.1601e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 8.7971e-05 - val_loss: 3.1552e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 8.7974e-05 - val_loss: 3.1470e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 8.7915e-05 - val_loss: 3.1759e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 8.8046e-05 - val_loss: 3.2029e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 8.8042e-05 - val_loss: 3.1450e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 8.8045e-05 - val_loss: 3.1460e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 8.8077e-05 - val_loss: 3.1533e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 8.8079e-05 - val_loss: 3.1630e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 8.8487e-05 - val_loss: 3.1741e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 8.8402e-05 - val_loss: 3.1452e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 8.7990e-05 - val_loss: 3.1507e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 8.8267e-05 - val_loss: 3.1543e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 8.7889e-05 - val_loss: 3.1514e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 8.8010e-05 - val_loss: 3.1700e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 8.8160e-05 - val_loss: 3.1946e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 8.8113e-05 - val_loss: 3.1964e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 8.8195e-05 - val_loss: 3.1529e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 8.7962e-05 - val_loss: 3.1465e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 47us/step - loss: 0.0135 - val_loss: 7.1497e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0065 - val_loss: 3.1702e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0043 - val_loss: 3.8546e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0031 - val_loss: 3.3320e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0023 - val_loss: 3.2678e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0018 - val_loss: 3.5346e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0014 - val_loss: 3.7632e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0012 - val_loss: 3.8876e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 9.9380e-04 - val_loss: 3.3962e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.3922e-04 - val_loss: 3.2903e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 7.1774e-04 - val_loss: 3.3106e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 6.3110e-04 - val_loss: 3.2006e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 5.6350e-04 - val_loss: 3.4838e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 4.9508e-04 - val_loss: 3.2826e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 4.3903e-04 - val_loss: 3.3287e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 4.0786e-04 - val_loss: 3.4055e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 3.6938e-04 - val_loss: 3.3712e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 3.4213e-04 - val_loss: 3.2851e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 3.2637e-04 - val_loss: 3.3084e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 3.0203e-04 - val_loss: 3.2531e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 2.7635e-04 - val_loss: 3.2641e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 2.5476e-04 - val_loss: 3.3723e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 2.4469e-04 - val_loss: 3.2568e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 2.3443e-04 - val_loss: 3.2204e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 48us/step - loss: 0.1465 - val_loss: 6.0697e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0373 - val_loss: 4.2515e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0251 - val_loss: 4.0452e-05\n",
      "Epoch 4/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0176 - val_loss: 3.7946e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0129 - val_loss: 3.3173e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0110 - val_loss: 3.2080e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0088 - val_loss: 3.1632e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0077 - val_loss: 3.2521e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0068 - val_loss: 3.1665e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0061 - val_loss: 3.4846e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0052 - val_loss: 3.1588e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0046 - val_loss: 3.1646e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0041 - val_loss: 3.2696e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0036 - val_loss: 3.1496e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0032 - val_loss: 3.2769e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0032 - val_loss: 3.1482e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0029 - val_loss: 3.2675e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0026 - val_loss: 3.2369e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0023 - val_loss: 3.1457e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0023 - val_loss: 3.2335e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0021 - val_loss: 3.1490e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0020 - val_loss: 3.1738e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0020 - val_loss: 3.1988e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0017 - val_loss: 3.2688e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 54us/step - loss: 0.0233 - val_loss: 2.7028e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0038 - val_loss: 2.8010e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0018 - val_loss: 7.4907e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 9.8767e-04 - val_loss: 5.8918e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 6.1648e-04 - val_loss: 3.5038e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 4.3498e-04 - val_loss: 6.0329e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 3.2170e-04 - val_loss: 3.1853e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 2.5972e-04 - val_loss: 5.3277e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 2.2482e-04 - val_loss: 4.5169e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 1.9343e-04 - val_loss: 4.8422e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.7195e-04 - val_loss: 3.6161e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 1.5674e-04 - val_loss: 3.2415e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 1.4500e-04 - val_loss: 3.2162e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.3417e-04 - val_loss: 6.6371e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 1.3123e-04 - val_loss: 3.1544e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.2402e-04 - val_loss: 6.6684e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.2031e-04 - val_loss: 3.1717e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 1.2378e-04 - val_loss: 5.7197e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 1.2265e-04 - val_loss: 3.2999e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.1375e-04 - val_loss: 3.5122e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 1.0943e-04 - val_loss: 3.8060e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.0557e-04 - val_loss: 3.4145e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.1343e-04 - val_loss: 3.5619e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.0708e-04 - val_loss: 4.0759e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 56us/step - loss: 0.1593 - val_loss: 1.0234e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0145 - val_loss: 9.7506e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0086 - val_loss: 3.7183e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0059 - val_loss: 3.8552e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0043 - val_loss: 8.7998e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0029 - val_loss: 8.5869e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0021 - val_loss: 9.4229e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0017 - val_loss: 9.4282e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0014 - val_loss: 8.7510e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0011 - val_loss: 8.4122e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0010 - val_loss: 9.2702e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 9.2615e-04 - val_loss: 8.6535e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 7.8580e-04 - val_loss: 8.2484e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.2133e-04 - val_loss: 8.9809e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 6.7069e-04 - val_loss: 9.0411e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 6.2311e-04 - val_loss: 8.1309e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 5.7073e-04 - val_loss: 8.4909e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 5.4417e-04 - val_loss: 8.6067e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 5.1597e-04 - val_loss: 8.7108e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 4.5414e-04 - val_loss: 9.0242e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 4.5877e-04 - val_loss: 8.6362e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 4.1883e-04 - val_loss: 9.1023e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 3.9281e-04 - val_loss: 8.4268e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 3.6147e-04 - val_loss: 8.6447e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 50us/step - loss: 0.2204 - val_loss: 1.3894e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0589 - val_loss: 3.2070e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0374 - val_loss: 2.6744e-04\n",
      "Epoch 4/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0275 - val_loss: 2.3279e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0221 - val_loss: 1.4940e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0184 - val_loss: 1.9219e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0156 - val_loss: 2.4014e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0138 - val_loss: 2.9602e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0120 - val_loss: 1.7091e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0109 - val_loss: 2.0827e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0100 - val_loss: 1.8328e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0091 - val_loss: 1.9307e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0085 - val_loss: 1.9686e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0078 - val_loss: 2.0308e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0074 - val_loss: 1.6359e-04\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0069 - val_loss: 2.0233e-04\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0064 - val_loss: 2.5457e-04\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0063 - val_loss: 1.4970e-04\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0059 - val_loss: 2.1519e-04\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0055 - val_loss: 1.6396e-04\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0052 - val_loss: 1.4367e-04\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0050 - val_loss: 1.6164e-04\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0048 - val_loss: 1.8685e-04\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0046 - val_loss: 1.6189e-04\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 51us/step - loss: 0.2600 - val_loss: 0.0014\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.1000 - val_loss: 5.9991e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0643 - val_loss: 2.6380e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0465 - val_loss: 4.0330e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0361 - val_loss: 3.9074e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0303 - val_loss: 3.1009e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0255 - val_loss: 4.4332e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0219 - val_loss: 3.5917e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0188 - val_loss: 3.0527e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0164 - val_loss: 3.2291e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0151 - val_loss: 3.4462e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0135 - val_loss: 2.4740e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0123 - val_loss: 2.9621e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0113 - val_loss: 3.3724e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0107 - val_loss: 2.3199e-04\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0098 - val_loss: 2.8389e-04\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0090 - val_loss: 2.7631e-04\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0084 - val_loss: 2.4784e-04\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0080 - val_loss: 2.0599e-04\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0074 - val_loss: 1.9196e-04\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0070 - val_loss: 1.8543e-04\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0067 - val_loss: 1.8778e-04\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0064 - val_loss: 2.1264e-04\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0061 - val_loss: 2.0595e-04\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 52us/step - loss: 0.1452 - val_loss: 1.0052e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0542 - val_loss: 1.3780e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0363 - val_loss: 2.3653e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0273 - val_loss: 1.1003e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0210 - val_loss: 8.1542e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0174 - val_loss: 6.4156e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0145 - val_loss: 6.9376e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0123 - val_loss: 5.7620e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0110 - val_loss: 7.0635e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0095 - val_loss: 4.8539e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0084 - val_loss: 5.0645e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0076 - val_loss: 6.0578e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0068 - val_loss: 5.0250e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0062 - val_loss: 4.7693e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0056 - val_loss: 4.4050e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0052 - val_loss: 4.2772e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0049 - val_loss: 3.9901e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0045 - val_loss: 4.2635e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0041 - val_loss: 4.0025e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0039 - val_loss: 4.0557e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0037 - val_loss: 3.5444e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0035 - val_loss: 3.4694e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0032 - val_loss: 3.7656e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0031 - val_loss: 3.5371e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 51us/step - loss: 0.2422 - val_loss: 0.0239\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0853 - val_loss: 0.0130\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0521 - val_loss: 0.0136\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0365 - val_loss: 0.0102\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0278 - val_loss: 0.0080\n",
      "Epoch 6/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0218 - val_loss: 0.0073\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0179 - val_loss: 0.0063\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0152 - val_loss: 0.0060\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0130 - val_loss: 0.0053\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0111 - val_loss: 0.0044\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0097 - val_loss: 0.0040\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0088 - val_loss: 0.0040\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0079 - val_loss: 0.0035\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0070 - val_loss: 0.0033\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0065 - val_loss: 0.0030\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0059 - val_loss: 0.0026\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0054 - val_loss: 0.0025\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0049 - val_loss: 0.0024\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0046 - val_loss: 0.0024\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0044 - val_loss: 0.0021\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0039 - val_loss: 0.0020\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0038 - val_loss: 0.0019\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 0.0033 - val_loss: 0.0017\n",
      "\n",
      "GENERATION 4\n",
      "\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 54us/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - ETA: 0s - loss: n - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: nan - val_loss: nan\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 53us/step - loss: 0.0135 - val_loss: 1.6729e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 1.3310e-04 - val_loss: 3.4189e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.8520e-05 - val_loss: 3.1463e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.7832e-05 - val_loss: 3.1462e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.7826e-05 - val_loss: 3.1460e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.7832e-05 - val_loss: 3.1464e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.7826e-05 - val_loss: 3.1459e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.7831e-05 - val_loss: 3.1456e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 8.7843e-05 - val_loss: 3.1456e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.7839e-05 - val_loss: 3.1457e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.7829e-05 - val_loss: 3.1489e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.7829e-05 - val_loss: 3.1644e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.7905e-05 - val_loss: 3.1470e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.7856e-05 - val_loss: 3.1460e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 7us/step - loss: 8.7851e-05 - val_loss: 3.1549e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.7849e-05 - val_loss: 3.1455e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.7829e-05 - val_loss: 3.1456e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.7862e-05 - val_loss: 3.1507e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.7899e-05 - val_loss: 3.1524e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.7847e-05 - val_loss: 3.1465e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.7843e-05 - val_loss: 3.1521e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.7825e-05 - val_loss: 3.1455e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.7857e-05 - val_loss: 3.1457e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.7824e-05 - val_loss: 3.1613e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 57us/step - loss: 0.0442 - val_loss: 0.0023\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0081 - val_loss: 3.1281e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0072 - val_loss: 2.9392e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0065 - val_loss: 3.4535e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0057 - val_loss: 2.0988e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0052 - val_loss: 2.3183e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0046 - val_loss: 2.6588e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0042 - val_loss: 2.1131e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0039 - val_loss: 1.8601e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0034 - val_loss: 1.9291e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0032 - val_loss: 1.6385e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0029 - val_loss: 1.3905e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0026 - val_loss: 1.3330e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0024 - val_loss: 1.3367e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0022 - val_loss: 1.3437e-04\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0020 - val_loss: 1.3532e-04\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0018 - val_loss: 1.1513e-04\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0016 - val_loss: 1.2215e-04\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0015 - val_loss: 9.2196e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0014 - val_loss: 9.5356e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0012 - val_loss: 8.4724e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0011 - val_loss: 8.2530e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0010 - val_loss: 7.5766e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 9.7498e-04 - val_loss: 8.1336e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 58us/step - loss: 0.1569 - val_loss: 1.8687e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0416 - val_loss: 5.6782e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0270 - val_loss: 4.4687e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0212 - val_loss: 7.3870e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0171 - val_loss: 8.6280e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0144 - val_loss: 5.2762e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0124 - val_loss: 4.0814e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0107 - val_loss: 3.7929e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0093 - val_loss: 4.2210e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0082 - val_loss: 4.1999e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0073 - val_loss: 3.7530e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0065 - val_loss: 3.6197e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0058 - val_loss: 3.9033e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0054 - val_loss: 3.5850e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0048 - val_loss: 3.6657e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0044 - val_loss: 3.5807e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0041 - val_loss: 4.4412e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0037 - val_loss: 4.2969e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0033 - val_loss: 3.5849e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0030 - val_loss: 3.8341e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0028 - val_loss: 3.7924e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0025 - val_loss: 3.8247e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0022 - val_loss: 3.4064e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0020 - val_loss: 3.5478e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 59us/step - loss: 0.0772 - val_loss: 0.0025\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0096 - val_loss: 4.3458e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0013 - val_loss: 5.8151e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 9.2804e-04 - val_loss: 3.3642e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 3.4577e-04 - val_loss: 3.1868e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 3.8003e-04 - val_loss: 3.2928e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 2.2921e-04 - val_loss: 1.2646e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 1.3134e-04 - val_loss: 5.3604e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 2.0087e-04 - val_loss: 5.2862e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 1.6068e-04 - val_loss: 3.4734e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 1.4545e-04 - val_loss: 3.2244e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 1.3499e-04 - val_loss: 3.1688e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 1.4365e-04 - val_loss: 3.1579e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 1.4363e-04 - val_loss: 3.1754e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 9.5586e-05 - val_loss: 7.5797e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 1.4098e-04 - val_loss: 1.0381e-04\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 1.0708e-04 - val_loss: 2.1511e-04\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 1.0667e-04 - val_loss: 1.5983e-04\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 1.4135e-04 - val_loss: 3.6623e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.1320e-04 - val_loss: 3.7969e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 1.0432e-04 - val_loss: 3.3366e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.1702e-04 - val_loss: 3.1753e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.1475e-04 - val_loss: 3.1546e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.0823e-04 - val_loss: 3.1479e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 60us/step - loss: 0.0885 - val_loss: 4.3772e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0090 - val_loss: 2.5564e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0016 - val_loss: 3.9748e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0013 - val_loss: 3.5262e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 9.4885e-04 - val_loss: 3.5658e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.0494e-04 - val_loss: 7.3519e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.5467e-04 - val_loss: 1.3013e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 7.5052e-04 - val_loss: 3.2277e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 5.3000e-04 - val_loss: 3.1731e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 1.1254e-04 - val_loss: 1.8776e-04\n",
      "Epoch 11/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 9us/step - loss: 3.1556e-04 - val_loss: 5.3806e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 4.0716e-04 - val_loss: 3.1718e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 4.8455e-04 - val_loss: 3.1832e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 1.0089e-04 - val_loss: 3.3437e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 4.5947e-04 - val_loss: 6.5982e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 2.6789e-04 - val_loss: 3.2189e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 2.5496e-04 - val_loss: 3.1663e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 3.2518e-04 - val_loss: 3.3159e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 1.7995e-04 - val_loss: 0.0027\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 2.1075e-04 - val_loss: 3.5837e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 2.2842e-04 - val_loss: 5.4621e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 2.7895e-04 - val_loss: 3.1710e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 2.3298e-04 - val_loss: 3.6805e-04\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.1708e-04 - val_loss: 4.7014e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 61us/step - loss: 0.1064 - val_loss: 0.0017\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 0.0112 - val_loss: 1.4501e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0019 - val_loss: 4.2191e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 3.6800e-04 - val_loss: 9.3835e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.5652e-04 - val_loss: 6.1457e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.3803e-04 - val_loss: 5.4549e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 5.6631e-04 - val_loss: 3.2398e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 5.9754e-04 - val_loss: 3.5861e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.2355e-04 - val_loss: 2.5298e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 3.3103e-04 - val_loss: 4.2307e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 4.7240e-04 - val_loss: 3.2154e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 3.7702e-04 - val_loss: 3.6648e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.0061e-04 - val_loss: 3.5580e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 2.9091e-04 - val_loss: 3.2149e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 2.7920e-04 - val_loss: 3.3432e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 2.1541e-04 - val_loss: 3.2981e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.5505e-04 - val_loss: 1.5810e-04\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 2.1294e-04 - val_loss: 3.3827e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 9.1842e-05 - val_loss: 4.2262e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 2.3191e-04 - val_loss: 3.3152e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 2.9122e-04 - val_loss: 3.2011e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 2.1371e-04 - val_loss: 1.0732e-04\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 9.6165e-05 - val_loss: 3.9651e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 3.2395e-04 - val_loss: 3.1908e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 65us/step - loss: 0.2768 - val_loss: 0.0149\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0388 - val_loss: 2.6215e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0053 - val_loss: 2.4026e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0038 - val_loss: 3.7513e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 5.8498e-04 - val_loss: 3.6223e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0010 - val_loss: 4.5291e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0011 - val_loss: 3.3270e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 7.8554e-04 - val_loss: 0.0063\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 5.2437e-04 - val_loss: 1.1098e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0012 - val_loss: 3.5425e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.1293e-04 - val_loss: 3.4080e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 7.5530e-04 - val_loss: 3.3966e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 5.8491e-04 - val_loss: 3.7894e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.0629e-04 - val_loss: 9.6144e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 5.6549e-04 - val_loss: 3.4059e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.0911e-04 - val_loss: 4.7488e-04\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 4.9465e-04 - val_loss: 4.2858e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.8937e-04 - val_loss: 3.1710e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 2.1610e-04 - val_loss: 3.2934e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 2.6360e-04 - val_loss: 3.1489e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 9.7859e-05 - val_loss: 2.0522e-04\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 3.0918e-04 - val_loss: 3.3849e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 2.3589e-04 - val_loss: 3.2081e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 3.8382e-04 - val_loss: 3.5404e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 66us/step - loss: 0.0988 - val_loss: 3.6912e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0205 - val_loss: 6.1298e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0086 - val_loss: 2.0891e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0038 - val_loss: 4.9695e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0018 - val_loss: 5.0407e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.6452e-04 - val_loss: 4.8489e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 4.7897e-04 - val_loss: 4.1914e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 3.0682e-04 - val_loss: 4.0443e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 2.5942e-04 - val_loss: 4.1319e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 2.4704e-04 - val_loss: 3.9300e-05\n",
      "Epoch 11/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 9us/step - loss: 2.5257e-04 - val_loss: 3.8781e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 2.2381e-04 - val_loss: 3.7154e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 2.1250e-04 - val_loss: 3.8014e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 2.2064e-04 - val_loss: 3.9947e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 2.2175e-04 - val_loss: 3.7018e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 2.2080e-04 - val_loss: 3.7475e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 2.0580e-04 - val_loss: 3.6489e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 2.0318e-04 - val_loss: 3.5640e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 1.7611e-04 - val_loss: 3.5451e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 1.9053e-04 - val_loss: 3.5791e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.8511e-04 - val_loss: 3.5237e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.7899e-04 - val_loss: 4.2400e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.7613e-04 - val_loss: 3.5854e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.9108e-04 - val_loss: 3.6749e-05\n",
      "\n",
      "GENERATION 5\n",
      "\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 63us/step - loss: 0.1903 - val_loss: 0.0058\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.6107e-04 - val_loss: 9.0684e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 9.6015e-05 - val_loss: 3.1944e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.7959e-05 - val_loss: 3.1507e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.7892e-05 - val_loss: 3.1517e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.7892e-05 - val_loss: 3.1508e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.7888e-05 - val_loss: 3.1507e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.7899e-05 - val_loss: 3.1506e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.7889e-05 - val_loss: 3.1508e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.7895e-05 - val_loss: 3.1506e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.7900e-05 - val_loss: 3.1512e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.7913e-05 - val_loss: 3.1520e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.7895e-05 - val_loss: 3.1539e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.7884e-05 - val_loss: 3.1506e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.7891e-05 - val_loss: 3.1507e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.7899e-05 - val_loss: 3.1509e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.7896e-05 - val_loss: 3.1529e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.7899e-05 - val_loss: 3.1507e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.7901e-05 - val_loss: 3.1528e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.7894e-05 - val_loss: 3.1509e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.7894e-05 - val_loss: 3.1504e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.7894e-05 - val_loss: 3.1505e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.7902e-05 - val_loss: 3.1503e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.7902e-05 - val_loss: 3.1508e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 64us/step - loss: 0.0120 - val_loss: 2.2542e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.2572e-04 - val_loss: 3.6638e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.8608e-05 - val_loss: 3.1673e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.7884e-05 - val_loss: 3.1472e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.7836e-05 - val_loss: 3.1475e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.7834e-05 - val_loss: 3.1484e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.7828e-05 - val_loss: 3.1589e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.7834e-05 - val_loss: 3.1493e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.7835e-05 - val_loss: 3.1482e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.7841e-05 - val_loss: 3.1547e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.7819e-05 - val_loss: 3.1474e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.7852e-05 - val_loss: 3.1461e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.7849e-05 - val_loss: 3.1507e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.7856e-05 - val_loss: 3.1459e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.7842e-05 - val_loss: 3.1472e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.7832e-05 - val_loss: 3.1586e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.7841e-05 - val_loss: 3.1461e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.7823e-05 - val_loss: 3.1483e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.7825e-05 - val_loss: 3.1480e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.7875e-05 - val_loss: 3.1462e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.7837e-05 - val_loss: 3.1466e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.7860e-05 - val_loss: 3.1491e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 8us/step - loss: 8.7870e-05 - val_loss: 3.1458e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.7852e-05 - val_loss: 3.1463e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 1s 68us/step - loss: 0.0637 - val_loss: 4.3511e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0172 - val_loss: 1.4815e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0128 - val_loss: 1.8086e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0098 - val_loss: 1.3926e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0079 - val_loss: 1.2097e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0066 - val_loss: 1.1072e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0056 - val_loss: 8.4624e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0048 - val_loss: 9.2372e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0041 - val_loss: 1.2301e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0036 - val_loss: 9.2798e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0032 - val_loss: 1.0425e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0028 - val_loss: 9.5565e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0025 - val_loss: 8.0843e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0022 - val_loss: 6.7255e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0020 - val_loss: 7.7640e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0018 - val_loss: 8.9985e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0016 - val_loss: 7.2079e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0015 - val_loss: 7.8586e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0013 - val_loss: 7.4205e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0012 - val_loss: 7.5517e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0011 - val_loss: 7.0573e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0010 - val_loss: 6.1479e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 9.4786e-04 - val_loss: 6.7352e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.5242e-04 - val_loss: 7.2875e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 2s 70us/step - loss: 0.2476 - val_loss: 1.0015e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0993 - val_loss: 1.5304e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0624 - val_loss: 7.1419e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0442 - val_loss: 5.5193e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0339 - val_loss: 4.7158e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0272 - val_loss: 5.6152e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0222 - val_loss: 7.5431e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0195 - val_loss: 4.2859e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0169 - val_loss: 4.2111e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0148 - val_loss: 1.0943e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0136 - val_loss: 5.9816e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0124 - val_loss: 9.5640e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0113 - val_loss: 1.5884e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0103 - val_loss: 1.0596e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0097 - val_loss: 8.3481e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0092 - val_loss: 1.0956e-04\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0087 - val_loss: 1.0596e-04\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0081 - val_loss: 1.4037e-04\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0075 - val_loss: 9.9308e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0073 - val_loss: 1.3736e-04\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0069 - val_loss: 1.0031e-04\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0067 - val_loss: 1.0002e-04\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0063 - val_loss: 9.3451e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0062 - val_loss: 9.8683e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 2s 70us/step - loss: 0.2163 - val_loss: 9.0801e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0818 - val_loss: 6.6631e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0510 - val_loss: 4.4762e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0370 - val_loss: 2.1133e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0291 - val_loss: 1.5352e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0243 - val_loss: 9.8382e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0207 - val_loss: 6.4715e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0181 - val_loss: 4.4534e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0158 - val_loss: 4.6749e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0144 - val_loss: 3.4317e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0128 - val_loss: 3.5592e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0117 - val_loss: 3.2198e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0106 - val_loss: 3.4508e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0098 - val_loss: 3.2021e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0091 - val_loss: 3.2319e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0083 - val_loss: 3.2561e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0079 - val_loss: 3.5947e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0073 - val_loss: 4.0968e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0067 - val_loss: 3.3864e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0066 - val_loss: 3.1843e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0062 - val_loss: 3.5259e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0058 - val_loss: 4.1024e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0057 - val_loss: 4.3676e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0053 - val_loss: 3.1577e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 2s 72us/step - loss: 0.1575 - val_loss: 1.7641e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0700 - val_loss: 2.5431e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0448 - val_loss: 1.5495e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0328 - val_loss: 1.4010e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0260 - val_loss: 1.9217e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0215 - val_loss: 2.4783e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0181 - val_loss: 1.0326e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0154 - val_loss: 1.6690e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0136 - val_loss: 1.7669e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0123 - val_loss: 1.3986e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0110 - val_loss: 1.2746e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0100 - val_loss: 1.4534e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0093 - val_loss: 1.5204e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0086 - val_loss: 1.6131e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0081 - val_loss: 1.7026e-04\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0072 - val_loss: 2.0041e-04\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0069 - val_loss: 1.1626e-04\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0064 - val_loss: 1.6229e-04\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0061 - val_loss: 1.6652e-04\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0057 - val_loss: 1.7233e-04\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0054 - val_loss: 1.5209e-04\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0052 - val_loss: 1.6001e-04\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0049 - val_loss: 1.8150e-04\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0046 - val_loss: 1.5355e-04\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 2s 78us/step - loss: 0.1615 - val_loss: 0.0048\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0342 - val_loss: 5.5477e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0198 - val_loss: 1.6863e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0127 - val_loss: 1.4349e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0097 - val_loss: 5.3986e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0074 - val_loss: 3.2406e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0060 - val_loss: 3.9682e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0049 - val_loss: 3.5716e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0042 - val_loss: 4.4092e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0036 - val_loss: 4.4459e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0031 - val_loss: 5.2297e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0028 - val_loss: 3.2645e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0024 - val_loss: 3.1665e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0021 - val_loss: 3.1726e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0020 - val_loss: 3.1676e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0018 - val_loss: 3.3773e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0016 - val_loss: 3.3819e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0015 - val_loss: 3.1555e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0013 - val_loss: 3.2549e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0011 - val_loss: 3.9906e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0011 - val_loss: 3.3892e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0010 - val_loss: 3.8920e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.9364e-04 - val_loss: 3.1467e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.6357e-04 - val_loss: 3.1707e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 2s 79us/step - loss: 0.0689 - val_loss: 4.7968e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0144 - val_loss: 2.6901e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0081 - val_loss: 4.3024e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0054 - val_loss: 3.7481e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0041 - val_loss: 9.1990e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0031 - val_loss: 1.5493e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0025 - val_loss: 1.6022e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0021 - val_loss: 2.1923e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0018 - val_loss: 2.4142e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0015 - val_loss: 1.7592e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0013 - val_loss: 1.7198e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0012 - val_loss: 1.3611e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0010 - val_loss: 1.6564e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.9667e-04 - val_loss: 1.1535e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 7.5317e-04 - val_loss: 7.4181e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 7.0976e-04 - val_loss: 9.3699e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 6.4940e-04 - val_loss: 8.3580e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 5.5282e-04 - val_loss: 1.0481e-04\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 5.1444e-04 - val_loss: 8.6173e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 4.6410e-04 - val_loss: 6.5546e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 4.4342e-04 - val_loss: 6.7684e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 3.8834e-04 - val_loss: 7.2169e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 3.8019e-04 - val_loss: 5.1557e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 3.2430e-04 - val_loss: 5.4741e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 2s 77us/step - loss: 0.0150 - val_loss: 5.1391e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 9.0594e-04 - val_loss: 1.4302e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 3.7808e-04 - val_loss: 2.3294e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 2.4351e-04 - val_loss: 2.5912e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 1.8653e-04 - val_loss: 2.0091e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 1.5560e-04 - val_loss: 1.2859e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.3698e-04 - val_loss: 1.0838e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.2293e-04 - val_loss: 6.6836e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.1686e-04 - val_loss: 5.3091e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.0784e-04 - val_loss: 5.5514e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 1.0147e-04 - val_loss: 4.4911e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 9.9095e-05 - val_loss: 4.0718e-05\n",
      "Epoch 13/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 9us/step - loss: 9.7827e-05 - val_loss: 3.8181e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 9.5516e-05 - val_loss: 3.5025e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 9.4078e-05 - val_loss: 3.4211e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 9.3366e-05 - val_loss: 3.3057e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 9.2502e-05 - val_loss: 3.2628e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 9.1996e-05 - val_loss: 3.2035e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 9.2133e-05 - val_loss: 3.1982e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 9.0692e-05 - val_loss: 3.1629e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 9.0262e-05 - val_loss: 3.1548e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.9892e-05 - val_loss: 3.1553e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.9584e-05 - val_loss: 3.1502e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.9523e-05 - val_loss: 3.1489e-05\n",
      "\n",
      "GENERATION 6\n",
      "\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 2s 79us/step - loss: 0.0158 - val_loss: 3.7252e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0070 - val_loss: 5.9659e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0051 - val_loss: 6.8095e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0038 - val_loss: 6.6932e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0030 - val_loss: 4.6321e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0024 - val_loss: 4.5911e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0020 - val_loss: 4.9295e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0017 - val_loss: 5.6223e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0015 - val_loss: 3.9561e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0012 - val_loss: 4.1292e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 0.0011 - val_loss: 4.6879e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 9.3812e-04 - val_loss: 4.3745e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.3988e-04 - val_loss: 4.4597e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 7.5124e-04 - val_loss: 4.3547e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 6.6693e-04 - val_loss: 4.0416e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 5.9714e-04 - val_loss: 3.8459e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 5.7233e-04 - val_loss: 4.0733e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 5.1161e-04 - val_loss: 3.8487e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 4.7592e-04 - val_loss: 4.1097e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 4.4102e-04 - val_loss: 3.9369e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 4.1714e-04 - val_loss: 3.8661e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 3.8528e-04 - val_loss: 3.3940e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 3.6721e-04 - val_loss: 3.4266e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 3.5130e-04 - val_loss: 3.9272e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 2s 81us/step - loss: 0.0210 - val_loss: 6.8051e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 1.7268e-04 - val_loss: 4.3921e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.9676e-05 - val_loss: 3.1580e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.7847e-05 - val_loss: 3.1464e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.7827e-05 - val_loss: 3.1526e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.7849e-05 - val_loss: 3.1453e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.7821e-05 - val_loss: 3.1460e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.7831e-05 - val_loss: 3.1455e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.7820e-05 - val_loss: 3.1458e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.7868e-05 - val_loss: 3.1477e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.7837e-05 - val_loss: 3.1468e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.7841e-05 - val_loss: 3.1453e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.7825e-05 - val_loss: 3.1465e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.7832e-05 - val_loss: 3.1488e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.7846e-05 - val_loss: 3.1453e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.7867e-05 - val_loss: 3.1504e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.7876e-05 - val_loss: 3.1530e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.7845e-05 - val_loss: 3.1481e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.7832e-05 - val_loss: 3.1453e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.7854e-05 - val_loss: 3.1548e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.7827e-05 - val_loss: 3.1540e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.7838e-05 - val_loss: 3.1459e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.7825e-05 - val_loss: 3.1469e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.7818e-05 - val_loss: 3.1482e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 2s 80us/step - loss: 0.1874 - val_loss: 1.3932e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 9.8213e-05 - val_loss: 3.1511e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.7907e-05 - val_loss: 3.1506e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.7998e-05 - val_loss: 3.1763e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 2.7677e-04 - val_loss: 0.0012\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 13/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 2s 85us/step - loss: 0.2061 - val_loss: 4.8071e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0219 - val_loss: 0.0023\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0184 - val_loss: 0.0023\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0141 - val_loss: 0.0012\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0086 - val_loss: 7.1056e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0045 - val_loss: 4.5993e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0021 - val_loss: 1.4991e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0012 - val_loss: 1.0699e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0011 - val_loss: 2.1290e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0010 - val_loss: 4.1105e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 0.0011 - val_loss: 6.0478e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 9.8364e-04 - val_loss: 4.9244e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0012 - val_loss: 7.2384e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0012 - val_loss: 4.3362e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 9.1944e-04 - val_loss: 6.9592e-04\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 9.6064e-04 - val_loss: 5.0152e-04\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 9.8849e-04 - val_loss: 4.9366e-04\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.2085e-04 - val_loss: 3.7235e-04\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.6979e-04 - val_loss: 7.9236e-04\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 9.6137e-04 - val_loss: 7.1123e-04\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.1617e-04 - val_loss: 3.4376e-04\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.5526e-04 - val_loss: 6.6334e-04\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.9128e-04 - val_loss: 4.6807e-04\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 9.8287e-04 - val_loss: 5.2422e-04\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 2s 89us/step - loss: 0.1004 - val_loss: 5.0925e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0151 - val_loss: 3.8452e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0124 - val_loss: 2.0868e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0087 - val_loss: 2.1728e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0051 - val_loss: 1.0022e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0026 - val_loss: 1.1114e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0014 - val_loss: 9.1460e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 7.2215e-04 - val_loss: 2.3786e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 4.9843e-04 - val_loss: 1.5315e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 4.2127e-04 - val_loss: 2.5726e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 4.9842e-04 - val_loss: 4.3899e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 4.9944e-04 - val_loss: 5.2810e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 5.2019e-04 - val_loss: 2.7911e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 4.6310e-04 - val_loss: 4.5745e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 5.0882e-04 - val_loss: 4.0833e-04\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 5.2335e-04 - val_loss: 5.8829e-04\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 4.3893e-04 - val_loss: 4.8255e-04\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 4.9966e-04 - val_loss: 5.5917e-04\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 6.0370e-04 - val_loss: 6.4174e-04\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 4.5661e-04 - val_loss: 4.5712e-04\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 4.7637e-04 - val_loss: 7.9174e-04\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 6.2870e-04 - val_loss: 4.9130e-04\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 3.5718e-04 - val_loss: 3.5345e-04\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 4.2876e-04 - val_loss: 5.5910e-04\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 2s 94us/step - loss: 0.0436 - val_loss: 7.9202e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 1.3549e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0082 - val_loss: 1.7127e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0048 - val_loss: 9.4869e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0026 - val_loss: 1.1525e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0014 - val_loss: 3.7404e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.7197e-04 - val_loss: 2.3620e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 6.5330e-04 - val_loss: 1.4759e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 6.3720e-04 - val_loss: 1.3975e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 6.8400e-04 - val_loss: 1.9283e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 7.2963e-04 - val_loss: 1.4693e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 5.5694e-04 - val_loss: 2.3402e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 6.6401e-04 - val_loss: 1.1944e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 5.2354e-04 - val_loss: 3.0680e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 6.9153e-04 - val_loss: 4.4749e-04\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 7.1553e-04 - val_loss: 4.0558e-04\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 5.7235e-04 - val_loss: 5.4990e-04\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 6.9454e-04 - val_loss: 3.9260e-04\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 7.2234e-04 - val_loss: 4.0549e-04\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 5.5011e-04 - val_loss: 3.2302e-04\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 6.2317e-04 - val_loss: 4.9553e-04\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 7.1204e-04 - val_loss: 6.6375e-04\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 6.3996e-04 - val_loss: 4.6362e-04\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 6.9402e-04 - val_loss: 5.7267e-04\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 2s 93us/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 2s 93us/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 2s 93us/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 11us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "\n",
      "GENERATION 7\n",
      "\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 2s 92us/step - loss: 0.0116 - val_loss: 3.1614e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 9us/step - loss: 8.8175e-05 - val_loss: 3.1601e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.8112e-05 - val_loss: 3.1564e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.8100e-05 - val_loss: 3.1583e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.8068e-05 - val_loss: 3.1648e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.8098e-05 - val_loss: 3.1607e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.8097e-05 - val_loss: 3.1544e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.7986e-05 - val_loss: 3.1603e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.8120e-05 - val_loss: 3.1482e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.7996e-05 - val_loss: 3.1651e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.7990e-05 - val_loss: 3.1542e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.8056e-05 - val_loss: 3.1485e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.8207e-05 - val_loss: 3.1484e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.8062e-05 - val_loss: 3.1469e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.8057e-05 - val_loss: 3.1493e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.8012e-05 - val_loss: 3.1515e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.7948e-05 - val_loss: 3.1654e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.8167e-05 - val_loss: 3.1614e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.7983e-05 - val_loss: 3.1520e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.8085e-05 - val_loss: 3.1611e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.8092e-05 - val_loss: 3.1460e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.7997e-05 - val_loss: 3.1459e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.8142e-05 - val_loss: 3.1557e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.8062e-05 - val_loss: 3.1594e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 2s 92us/step - loss: 0.0253 - val_loss: 6.4192e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 1.7701e-04 - val_loss: 4.3773e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.9531e-05 - val_loss: 3.1811e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.7836e-05 - val_loss: 3.1496e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.7844e-05 - val_loss: 3.1489e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.7833e-05 - val_loss: 3.1463e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7838e-05 - val_loss: 3.1467e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.7834e-05 - val_loss: 3.1463e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.7850e-05 - val_loss: 3.1537e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.7862e-05 - val_loss: 3.1466e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.7828e-05 - val_loss: 3.1469e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.7836e-05 - val_loss: 3.1464e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.7866e-05 - val_loss: 3.1467e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.7837e-05 - val_loss: 3.1467e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.7840e-05 - val_loss: 3.1462e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.7864e-05 - val_loss: 3.1465e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.7844e-05 - val_loss: 3.1470e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.7887e-05 - val_loss: 3.1479e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.7835e-05 - val_loss: 3.1527e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.7867e-05 - val_loss: 3.1531e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.7868e-05 - val_loss: 3.1463e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.7874e-05 - val_loss: 3.1472e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.7869e-05 - val_loss: 3.1552e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.7878e-05 - val_loss: 3.1488e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 2s 92us/step - loss: 0.0092 - val_loss: 3.1791e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.8155e-05 - val_loss: 3.1457e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.8022e-05 - val_loss: 3.1466e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.8167e-05 - val_loss: 3.1486e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.8059e-05 - val_loss: 3.1632e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.8091e-05 - val_loss: 3.1520e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.8173e-05 - val_loss: 3.1497e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.8079e-05 - val_loss: 3.1499e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.8214e-05 - val_loss: 3.1454e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.8324e-05 - val_loss: 3.1789e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.8324e-05 - val_loss: 3.1790e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.7912e-05 - val_loss: 3.1511e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.8250e-05 - val_loss: 3.1469e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.8174e-05 - val_loss: 3.1586e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.8051e-05 - val_loss: 3.1981e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.8034e-05 - val_loss: 3.1465e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.8135e-05 - val_loss: 3.1822e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.8166e-05 - val_loss: 3.1633e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.8133e-05 - val_loss: 3.1493e-05\n",
      "Epoch 20/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.8393e-05 - val_loss: 3.1482e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.8089e-05 - val_loss: 3.1787e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.8321e-05 - val_loss: 3.1456e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.8178e-05 - val_loss: 3.1491e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: 8.8136e-05 - val_loss: 3.1479e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 2s 98us/step - loss: 0.0048 - val_loss: 3.1466e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.7917e-05 - val_loss: 3.1602e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.8114e-05 - val_loss: 3.1523e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 3.9033e-04 - val_loss: 8.3309e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0010 - val_loss: 8.3985e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0010 - val_loss: 7.1356e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 9.6869e-04 - val_loss: 0.0010\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0010 - val_loss: 8.7369e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 9.8798e-04 - val_loss: 8.7618e-04\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 9.1674e-04 - val_loss: 7.9985e-04\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7922e-04 - val_loss: 9.1902e-04\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 9.0530e-04 - val_loss: 6.2251e-04\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.0017e-04 - val_loss: 8.8533e-04\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.8262e-04 - val_loss: 9.4141e-04\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 7.7014e-04 - val_loss: 7.3724e-04\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.2101e-04 - val_loss: 8.1638e-04\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.0102e-04 - val_loss: 6.9406e-04\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.8178e-04 - val_loss: 7.9447e-04\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 2s 100us/step - loss: 0.0090 - val_loss: 3.1478e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.7871e-05 - val_loss: 3.1465e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.8057e-05 - val_loss: 3.2211e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 2.0551e-04 - val_loss: 5.1746e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 9.0519e-04 - val_loss: 0.0010\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0012 - val_loss: 9.3203e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0011 - val_loss: 8.4077e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 9.8039e-04 - val_loss: 9.2483e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 9.9715e-04 - val_loss: 7.8452e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 9.6778e-04 - val_loss: 6.7045e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.3474e-04 - val_loss: 9.5879e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0011 - val_loss: 7.4749e-04\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 7.5892e-04 - val_loss: 8.1228e-04\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 9.4903e-04 - val_loss: 9.2010e-04\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 9.4183e-04 - val_loss: 8.7567e-04\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.3781e-04 - val_loss: 7.1057e-04\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 9.3727e-04 - val_loss: 8.9119e-04\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 7.5249e-04 - val_loss: 6.3879e-04\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 7.6659e-04 - val_loss: 8.0474e-04\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.0419e-04 - val_loss: 8.2595e-04\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.4912e-04 - val_loss: 6.4928e-04\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 2s 99us/step - loss: 0.0132 - val_loss: 3.1461e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.7867e-05 - val_loss: 3.2672e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.8060e-05 - val_loss: 3.2002e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 1.5321e-04 - val_loss: 4.0291e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 9.0743e-04 - val_loss: 0.0011\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0011 - val_loss: 9.1634e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0010 - val_loss: 7.5325e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0010 - val_loss: 7.9979e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0010 - val_loss: 9.6917e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0011 - val_loss: 9.3179e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0010 - val_loss: 7.1430e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 9.9540e-04 - val_loss: 9.5418e-04\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.3688e-04 - val_loss: 7.8238e-04\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 9.5472e-04 - val_loss: 9.1784e-04\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0010 - val_loss: 8.4908e-04\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 7.2606e-04 - val_loss: 7.4498e-04\n",
      "Epoch 20/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.5861e-04 - val_loss: 8.1215e-04\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 9.2243e-04 - val_loss: 8.7975e-04\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.5390e-04 - val_loss: 7.2603e-04\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 7.8961e-04 - val_loss: 7.9920e-04\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.5342e-04 - val_loss: 7.2343e-04\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 2s 104us/step - loss: 0.0584 - val_loss: 0.0071\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0165 - val_loss: 0.0111\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0122 - val_loss: 0.0136\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0072 - val_loss: 0.0056\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0044 - val_loss: 0.0024\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0033 - val_loss: 0.0026\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 0.0026 - val_loss: 0.0021\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 9.6388e-04 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0010 - val_loss: 9.6319e-04\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 9.4393e-04 - val_loss: 8.2296e-04\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.5659e-04 - val_loss: 9.7212e-04\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 9.1176e-04 - val_loss: 0.0010\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.4604e-04 - val_loss: 7.8168e-04\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 9.3493e-04 - val_loss: 6.4452e-04\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 6.9791e-04 - val_loss: 7.9355e-04\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8637e-04 - val_loss: 5.1555e-04\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 6.7433e-04 - val_loss: 6.4106e-04\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.4536e-04 - val_loss: 8.5775e-04\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 2s 100us/step - loss: 0.0574 - val_loss: 1.5963e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 9.5655e-04 - val_loss: 0.0037\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 7.8768e-04 - val_loss: 3.2509e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 3.1220e-04 - val_loss: 8.8223e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 3.3813e-04 - val_loss: 1.4316e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 2.5731e-04 - val_loss: 1.5916e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 2.3423e-04 - val_loss: 3.0769e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 1.9834e-04 - val_loss: 7.4675e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 2.0912e-04 - val_loss: 6.1451e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.8248e-04 - val_loss: 6.8344e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 1.9108e-04 - val_loss: 8.7545e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.8757e-04 - val_loss: 1.1557e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 1.7797e-04 - val_loss: 7.7307e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 1.6965e-04 - val_loss: 1.0399e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 1.7026e-04 - val_loss: 7.6070e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 1.8190e-04 - val_loss: 9.8831e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.6681e-04 - val_loss: 9.5263e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.6784e-04 - val_loss: 5.6775e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 1.6416e-04 - val_loss: 1.2975e-04\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.6153e-04 - val_loss: 1.0259e-04\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.5814e-04 - val_loss: 1.1210e-04\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.6105e-04 - val_loss: 1.0056e-04\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 1.6116e-04 - val_loss: 7.9085e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 1.5601e-04 - val_loss: 6.4306e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 2s 104us/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 10us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 11us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: nan - val_loss: nan\n",
      "\n",
      "GENERATION 8\n",
      "\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 2s 111us/step - loss: 0.0087 - val_loss: 4.3338e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 4.8548e-04 - val_loss: 3.8458e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 3.0506e-04 - val_loss: 3.1589e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 2.1979e-04 - val_loss: 3.4794e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.8474e-04 - val_loss: 3.8709e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.5976e-04 - val_loss: 4.1322e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.4699e-04 - val_loss: 4.2066e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 1.3432e-04 - val_loss: 3.9002e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.2477e-04 - val_loss: 3.6534e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.1926e-04 - val_loss: 3.4899e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.1245e-04 - val_loss: 3.3745e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.0996e-04 - val_loss: 3.2988e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.1063e-04 - val_loss: 3.2431e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.0564e-04 - val_loss: 3.2036e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.0312e-04 - val_loss: 3.1864e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.0256e-04 - val_loss: 3.1735e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 9.9945e-05 - val_loss: 3.1692e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 9.9876e-05 - val_loss: 3.1596e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 9.8488e-05 - val_loss: 3.1576e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 9.6495e-05 - val_loss: 3.1517e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 9.5811e-05 - val_loss: 3.1489e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 9.5861e-05 - val_loss: 3.1478e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 9.4910e-05 - val_loss: 3.1460e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 9.4893e-05 - val_loss: 3.1457e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 2s 110us/step - loss: 0.0106 - val_loss: 4.7684e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 1.2901e-04 - val_loss: 3.1531e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.8422e-05 - val_loss: 3.1483e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.7878e-05 - val_loss: 3.1465e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.7808e-05 - val_loss: 3.1474e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.7825e-05 - val_loss: 3.1512e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.7842e-05 - val_loss: 3.1461e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.7822e-05 - val_loss: 3.1512e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.7837e-05 - val_loss: 3.1458e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7853e-05 - val_loss: 3.1464e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7842e-05 - val_loss: 3.1486e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7853e-05 - val_loss: 3.1510e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7810e-05 - val_loss: 3.1471e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7832e-05 - val_loss: 3.1468e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.7836e-05 - val_loss: 3.1478e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.7835e-05 - val_loss: 3.1459e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.7820e-05 - val_loss: 3.1467e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7855e-05 - val_loss: 3.1457e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.7834e-05 - val_loss: 3.1457e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.7865e-05 - val_loss: 3.1459e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.7849e-05 - val_loss: 3.1527e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.7893e-05 - val_loss: 3.1463e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.7868e-05 - val_loss: 3.1458e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.7808e-05 - val_loss: 3.1517e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 2s 105us/step - loss: 0.0024 - val_loss: 1.1135e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.0381e-04 - val_loss: 3.2979e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.7974e-05 - val_loss: 3.1460e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.7897e-05 - val_loss: 3.1674e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7848e-05 - val_loss: 3.1511e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.7911e-05 - val_loss: 3.1482e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.7847e-05 - val_loss: 3.1483e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7876e-05 - val_loss: 3.1475e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.7853e-05 - val_loss: 3.1487e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.7887e-05 - val_loss: 3.1496e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7911e-05 - val_loss: 3.1471e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.7855e-05 - val_loss: 3.1591e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7843e-05 - val_loss: 3.1563e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.7889e-05 - val_loss: 3.1561e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7852e-05 - val_loss: 3.1779e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.7926e-05 - val_loss: 3.1503e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.7925e-05 - val_loss: 3.1467e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7876e-05 - val_loss: 3.1457e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.7884e-05 - val_loss: 3.1458e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7851e-05 - val_loss: 3.1558e-05\n",
      "Epoch 21/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7898e-05 - val_loss: 3.1457e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7889e-05 - val_loss: 3.1607e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7862e-05 - val_loss: 3.1512e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8002e-05 - val_loss: 3.2011e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 2s 110us/step - loss: 0.0072 - val_loss: 7.7289e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 1.0355e-04 - val_loss: 3.9177e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 9.5298e-05 - val_loss: 3.6318e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 9.2769e-05 - val_loss: 3.4637e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 9.2174e-05 - val_loss: 3.4015e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 9.0716e-05 - val_loss: 3.3339e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 9.0359e-05 - val_loss: 3.2744e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 9.0528e-05 - val_loss: 3.2786e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.9938e-05 - val_loss: 3.3608e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 9.0387e-05 - val_loss: 3.3803e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 9.0159e-05 - val_loss: 3.3203e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.9563e-05 - val_loss: 3.2210e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.9616e-05 - val_loss: 3.2594e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.9708e-05 - val_loss: 3.3396e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.9672e-05 - val_loss: 3.2485e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.9728e-05 - val_loss: 3.2114e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.9259e-05 - val_loss: 3.2063e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.9522e-05 - val_loss: 3.2097e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.9395e-05 - val_loss: 3.2201e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.9273e-05 - val_loss: 3.3495e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.9778e-05 - val_loss: 3.2222e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.9571e-05 - val_loss: 3.2174e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.9498e-05 - val_loss: 3.2149e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.9561e-05 - val_loss: 3.4538e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 2s 110us/step - loss: 0.5263 - val_loss: 1.5581e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0087 - val_loss: 9.1065e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0083 - val_loss: 3.3734e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0082 - val_loss: 2.8520e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0082 - val_loss: 2.8212e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0081 - val_loss: 2.9616e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0079 - val_loss: 3.2056e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0075 - val_loss: 2.8782e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0077 - val_loss: 2.9359e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0075 - val_loss: 2.7659e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0072 - val_loss: 3.2184e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0071 - val_loss: 2.5584e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0069 - val_loss: 2.6867e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0067 - val_loss: 2.2019e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0066 - val_loss: 2.5383e-04\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0063 - val_loss: 2.3131e-04\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0063 - val_loss: 2.6727e-04\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0061 - val_loss: 2.7208e-04\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0059 - val_loss: 2.5050e-04\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0058 - val_loss: 2.2880e-04\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0058 - val_loss: 2.8155e-04\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0054 - val_loss: 2.0185e-04\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0053 - val_loss: 2.1881e-04\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0052 - val_loss: 2.4402e-04\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 2s 116us/step - loss: 0.0053 - val_loss: 1.3449e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0022 - val_loss: 3.4137e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0019 - val_loss: 3.2421e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0017 - val_loss: 3.1724e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0015 - val_loss: 3.1463e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0014 - val_loss: 3.1873e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0013 - val_loss: 3.2327e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0012 - val_loss: 3.3571e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0011 - val_loss: 3.1717e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 9.8055e-04 - val_loss: 3.3686e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 9.0335e-04 - val_loss: 3.2118e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.2080e-04 - val_loss: 3.1734e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 7.5697e-04 - val_loss: 3.2293e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 7.0989e-04 - val_loss: 3.2776e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 6.5745e-04 - val_loss: 3.2664e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 6.1204e-04 - val_loss: 3.2480e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 5.7869e-04 - val_loss: 3.3224e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 5.2943e-04 - val_loss: 3.3389e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 5.0558e-04 - val_loss: 3.2142e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 4.7216e-04 - val_loss: 3.5671e-05\n",
      "Epoch 21/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 13us/step - loss: 4.3484e-04 - val_loss: 3.3520e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 4.1614e-04 - val_loss: 3.2402e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 4.0146e-04 - val_loss: 3.2111e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 3.6897e-04 - val_loss: 3.2520e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 2s 115us/step - loss: 0.0192 - val_loss: 3.9315e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0053 - val_loss: 3.1609e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0045 - val_loss: 3.5469e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0041 - val_loss: 3.2992e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0038 - val_loss: 3.3781e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0034 - val_loss: 3.2293e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0032 - val_loss: 3.3715e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0029 - val_loss: 3.4534e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0026 - val_loss: 3.2304e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0025 - val_loss: 3.4245e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0022 - val_loss: 3.7000e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0021 - val_loss: 3.3183e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0019 - val_loss: 3.4634e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0018 - val_loss: 3.2258e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0017 - val_loss: 3.3497e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0016 - val_loss: 3.4491e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0014 - val_loss: 3.2092e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0013 - val_loss: 3.5276e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0012 - val_loss: 3.1553e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0012 - val_loss: 3.1845e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0011 - val_loss: 3.1755e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0010 - val_loss: 3.3289e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 9.3772e-04 - val_loss: 3.1996e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.6218e-04 - val_loss: 3.3222e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 3s 120us/step - loss: 4.3933e-04 - val_loss: 3.3902e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.1018e-04 - val_loss: 3.1801e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 9.8680e-05 - val_loss: 3.1503e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 9.3960e-05 - val_loss: 3.2119e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 9.2190e-05 - val_loss: 3.1511e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 9.1047e-05 - val_loss: 3.1609e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 9.0046e-05 - val_loss: 3.1494e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.9661e-05 - val_loss: 3.1502e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.9149e-05 - val_loss: 3.1623e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8964e-05 - val_loss: 3.1529e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8879e-05 - val_loss: 3.1470e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8793e-05 - val_loss: 3.1494e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.8608e-05 - val_loss: 3.1462e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8519e-05 - val_loss: 3.1497e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8430e-05 - val_loss: 3.1512e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8386e-05 - val_loss: 3.1480e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.8137e-05 - val_loss: 3.1457e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8181e-05 - val_loss: 3.1604e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8251e-05 - val_loss: 3.1475e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8118e-05 - val_loss: 3.1460e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8155e-05 - val_loss: 3.1524e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8133e-05 - val_loss: 3.1548e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8099e-05 - val_loss: 3.1475e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.8056e-05 - val_loss: 3.1471e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 3s 123us/step - loss: 0.0016 - val_loss: 3.8822e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.7953e-04 - val_loss: 3.2307e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.2621e-04 - val_loss: 3.2403e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.0959e-04 - val_loss: 3.1549e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.0362e-04 - val_loss: 3.1774e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.0029e-04 - val_loss: 3.1629e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 9.6295e-05 - val_loss: 3.1548e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 9.4867e-05 - val_loss: 3.1692e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 9.3849e-05 - val_loss: 3.1623e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 9.2332e-05 - val_loss: 3.1583e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 9.1727e-05 - val_loss: 3.1683e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 9.1239e-05 - val_loss: 3.1538e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 9.0458e-05 - val_loss: 3.1458e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 9.0027e-05 - val_loss: 3.1464e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.9831e-05 - val_loss: 3.1464e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.9188e-05 - val_loss: 3.1524e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.9145e-05 - val_loss: 3.1462e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.9331e-05 - val_loss: 3.1464e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8840e-05 - val_loss: 3.1457e-05\n",
      "Epoch 20/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8756e-05 - val_loss: 3.1457e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8964e-05 - val_loss: 3.1506e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.9028e-05 - val_loss: 3.1496e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8771e-05 - val_loss: 3.1457e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8787e-05 - val_loss: 3.1545e-05\n",
      "\n",
      "GENERATION 9\n",
      "\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 3s 120us/step - loss: 0.0025 - val_loss: 1.4258e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.0097e-04 - val_loss: 3.1627e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7995e-05 - val_loss: 3.1463e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7847e-05 - val_loss: 3.1465e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7841e-05 - val_loss: 3.1473e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7904e-05 - val_loss: 3.1536e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7924e-05 - val_loss: 3.1507e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7973e-05 - val_loss: 3.1488e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.7872e-05 - val_loss: 3.1461e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7840e-05 - val_loss: 3.1854e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7918e-05 - val_loss: 3.1473e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7880e-05 - val_loss: 3.1462e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7882e-05 - val_loss: 3.1582e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7883e-05 - val_loss: 3.1462e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7886e-05 - val_loss: 3.1514e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7875e-05 - val_loss: 3.1459e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7858e-05 - val_loss: 3.1459e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7863e-05 - val_loss: 3.1466e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7919e-05 - val_loss: 3.1510e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7961e-05 - val_loss: 3.1476e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7961e-05 - val_loss: 3.1635e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7839e-05 - val_loss: 3.1470e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 11us/step - loss: 8.7920e-05 - val_loss: 3.2050e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8044e-05 - val_loss: 3.1926e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 3s 120us/step - loss: 0.0171 - val_loss: 3.4387e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.4878e-04 - val_loss: 3.7832e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8581e-05 - val_loss: 3.1464e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7845e-05 - val_loss: 3.1471e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7844e-05 - val_loss: 3.1474e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7847e-05 - val_loss: 3.1458e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7832e-05 - val_loss: 3.1465e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7822e-05 - val_loss: 3.1457e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7828e-05 - val_loss: 3.1457e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7845e-05 - val_loss: 3.1538e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.7842e-05 - val_loss: 3.1466e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.7829e-05 - val_loss: 3.1460e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7838e-05 - val_loss: 3.1458e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7854e-05 - val_loss: 3.1459e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7836e-05 - val_loss: 3.1519e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7832e-05 - val_loss: 3.1465e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7832e-05 - val_loss: 3.1501e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7899e-05 - val_loss: 3.1543e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7846e-05 - val_loss: 3.1505e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7841e-05 - val_loss: 3.1472e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7833e-05 - val_loss: 3.1460e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.7873e-05 - val_loss: 3.1526e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.7845e-05 - val_loss: 3.1457e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.7829e-05 - val_loss: 3.1468e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 3s 121us/step - loss: 0.0168 - val_loss: 5.8120e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.5520e-04 - val_loss: 3.9600e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.9066e-05 - val_loss: 3.1564e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7832e-05 - val_loss: 3.1472e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7833e-05 - val_loss: 3.1470e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7837e-05 - val_loss: 3.1460e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7819e-05 - val_loss: 3.1506e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7834e-05 - val_loss: 3.1462e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7829e-05 - val_loss: 3.1496e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7824e-05 - val_loss: 3.1552e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7830e-05 - val_loss: 3.1672e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7849e-05 - val_loss: 3.1566e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7863e-05 - val_loss: 3.1469e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7848e-05 - val_loss: 3.1459e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7849e-05 - val_loss: 3.1461e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7825e-05 - val_loss: 3.1482e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7865e-05 - val_loss: 3.1497e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7828e-05 - val_loss: 3.1458e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7903e-05 - val_loss: 3.1470e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7839e-05 - val_loss: 3.1491e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7859e-05 - val_loss: 3.1500e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7861e-05 - val_loss: 3.1471e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7881e-05 - val_loss: 3.1458e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7846e-05 - val_loss: 3.1458e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 3s 129us/step - loss: 0.0167 - val_loss: 3.3031e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0018 - val_loss: 4.6670e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0016 - val_loss: 3.9573e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0015 - val_loss: 3.4374e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0014 - val_loss: 3.5328e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0013 - val_loss: 3.7326e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0012 - val_loss: 3.4189e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0012 - val_loss: 3.4620e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0011 - val_loss: 3.6280e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0010 - val_loss: 3.3589e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0010 - val_loss: 3.4291e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 9.5383e-04 - val_loss: 3.4596e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 9.0243e-04 - val_loss: 3.5634e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.2996e-04 - val_loss: 3.4059e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 7.9837e-04 - val_loss: 3.1950e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 7.5680e-04 - val_loss: 3.2485e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 7.0844e-04 - val_loss: 3.3083e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 6.8324e-04 - val_loss: 3.4733e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 6.3169e-04 - val_loss: 3.3482e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 5.9867e-04 - val_loss: 3.2882e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 5.7328e-04 - val_loss: 3.3261e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 5.3221e-04 - val_loss: 3.3616e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 5.0708e-04 - val_loss: 3.4200e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 4.7109e-04 - val_loss: 3.3102e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 3s 133us/step - loss: 0.0132 - val_loss: 3.1459e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0037 - val_loss: 3.4659e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0030 - val_loss: 3.2948e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0026 - val_loss: 3.2468e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0023 - val_loss: 3.1750e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0021 - val_loss: 3.3226e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0019 - val_loss: 3.1581e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0017 - val_loss: 3.2531e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0016 - val_loss: 3.3316e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0015 - val_loss: 3.2759e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0014 - val_loss: 3.1610e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0013 - val_loss: 3.2190e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0012 - val_loss: 3.2960e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0011 - val_loss: 3.2746e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 9.8514e-04 - val_loss: 3.2105e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 9.0890e-04 - val_loss: 3.2146e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.5488e-04 - val_loss: 3.3209e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.0678e-04 - val_loss: 3.2572e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 7.3849e-04 - val_loss: 3.2238e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 7.0268e-04 - val_loss: 3.1497e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 6.4624e-04 - val_loss: 3.1458e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 5.8976e-04 - val_loss: 3.1671e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 5.5418e-04 - val_loss: 3.1647e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 5.2254e-04 - val_loss: 3.1460e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 3s 130us/step - loss: 0.0048 - val_loss: 4.9257e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0024 - val_loss: 3.1555e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0018 - val_loss: 3.1461e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0014 - val_loss: 3.2399e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0011 - val_loss: 3.8442e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8614e-04 - val_loss: 3.1747e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 7.5648e-04 - val_loss: 3.2586e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 6.2749e-04 - val_loss: 3.1574e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 5.4946e-04 - val_loss: 3.1761e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 4.7647e-04 - val_loss: 3.1732e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 4.0955e-04 - val_loss: 3.1886e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 3.7308e-04 - val_loss: 3.2217e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 3.3432e-04 - val_loss: 3.2633e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 3.0267e-04 - val_loss: 3.2796e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 2.8133e-04 - val_loss: 3.2909e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 2.6167e-04 - val_loss: 3.1924e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 2.3975e-04 - val_loss: 3.1575e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 2.2663e-04 - val_loss: 3.1863e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 2.1058e-04 - val_loss: 3.1533e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 2.0055e-04 - val_loss: 3.1895e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.8926e-04 - val_loss: 3.1460e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.7919e-04 - val_loss: 3.1504e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.7157e-04 - val_loss: 3.1458e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 1.6465e-04 - val_loss: 3.1641e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 3s 133us/step - loss: 0.0335 - val_loss: 4.5902e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0042 - val_loss: 1.2899e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0037 - val_loss: 1.0078e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0035 - val_loss: 6.5766e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0033 - val_loss: 9.0856e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0033 - val_loss: 7.6947e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0030 - val_loss: 7.5297e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0029 - val_loss: 7.2078e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0027 - val_loss: 6.6468e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0026 - val_loss: 8.4181e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0024 - val_loss: 7.2371e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0023 - val_loss: 7.1849e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0022 - val_loss: 5.9227e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0021 - val_loss: 7.1834e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0020 - val_loss: 7.1108e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0019 - val_loss: 7.4545e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0018 - val_loss: 7.5581e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0017 - val_loss: 4.5754e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0016 - val_loss: 5.8239e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0015 - val_loss: 6.0251e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0015 - val_loss: 5.7361e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0013 - val_loss: 5.6531e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0013 - val_loss: 5.2461e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0012 - val_loss: 5.6540e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 3s 133us/step - loss: 0.7757 - val_loss: 0.0188\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.1520 - val_loss: 0.0013\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.1172 - val_loss: 0.0010\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0939 - val_loss: 0.0014\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0752 - val_loss: 8.8022e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0628 - val_loss: 0.0013\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0520 - val_loss: 0.0011\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0455 - val_loss: 9.7702e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0397 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0347 - val_loss: 8.0394e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0311 - val_loss: 8.8911e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0280 - val_loss: 5.3245e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0248 - val_loss: 6.7527e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0224 - val_loss: 5.6745e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0201 - val_loss: 3.4421e-04\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0189 - val_loss: 1.5608e-04\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0163 - val_loss: 1.0093e-04\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0152 - val_loss: 7.9364e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0142 - val_loss: 5.4691e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 0.0120 - val_loss: 3.5968e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0112 - val_loss: 3.1603e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0106 - val_loss: 3.1461e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0098 - val_loss: 4.5190e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0091 - val_loss: 3.7732e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 3s 136us/step - loss: 0.3199 - val_loss: 0.0029\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0804 - val_loss: 2.1408e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0535 - val_loss: 2.6016e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0388 - val_loss: 2.1513e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0292 - val_loss: 2.4598e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0246 - val_loss: 2.4770e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0205 - val_loss: 3.1045e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0179 - val_loss: 4.1894e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0156 - val_loss: 2.4003e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0146 - val_loss: 3.0917e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0130 - val_loss: 5.9093e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0125 - val_loss: 4.6140e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0113 - val_loss: 3.9128e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0104 - val_loss: 3.7243e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0099 - val_loss: 4.2003e-04\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0093 - val_loss: 4.7885e-04\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0085 - val_loss: 3.8472e-04\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0081 - val_loss: 4.6142e-04\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0073 - val_loss: 4.5599e-04\n",
      "Epoch 20/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0071 - val_loss: 4.4130e-04\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0066 - val_loss: 3.7661e-04\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0063 - val_loss: 3.9885e-04\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0057 - val_loss: 5.4949e-04\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0056 - val_loss: 3.2424e-04\n",
      "\n",
      "GENERATION 10\n",
      "\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 3s 135us/step - loss: 0.0091 - val_loss: 1.1372e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0022 - val_loss: 6.4882e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0013 - val_loss: 3.9734e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.8461e-04 - val_loss: 4.0089e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 6.6770e-04 - val_loss: 3.5298e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 5.4388e-04 - val_loss: 3.8585e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 4.5262e-04 - val_loss: 3.3766e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 4.0038e-04 - val_loss: 4.2289e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 3.5787e-04 - val_loss: 3.4632e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 3.2231e-04 - val_loss: 3.8745e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 3.0168e-04 - val_loss: 3.3928e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 2.8206e-04 - val_loss: 3.1813e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 2.7482e-04 - val_loss: 3.2773e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 2.5929e-04 - val_loss: 3.1615e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 2.4582e-04 - val_loss: 3.2414e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 2.3724e-04 - val_loss: 3.1937e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 2.2698e-04 - val_loss: 3.3543e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 2.2026e-04 - val_loss: 3.2773e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 2.1729e-04 - val_loss: 3.2127e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 2.1092e-04 - val_loss: 3.3106e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 2.0781e-04 - val_loss: 3.1932e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.9805e-04 - val_loss: 3.4235e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.9236e-04 - val_loss: 3.3458e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.9220e-04 - val_loss: 3.2551e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 3s 137us/step - loss: 0.0014 - val_loss: 7.5231e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 9.7013e-05 - val_loss: 3.1966e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.8130e-05 - val_loss: 3.1594e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.7915e-05 - val_loss: 3.1816e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7868e-05 - val_loss: 3.1461e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.7974e-05 - val_loss: 3.1756e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.7856e-05 - val_loss: 3.1466e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7896e-05 - val_loss: 3.1924e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.7902e-05 - val_loss: 3.1469e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7839e-05 - val_loss: 3.1660e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.7927e-05 - val_loss: 3.1472e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.7932e-05 - val_loss: 3.1617e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.7884e-05 - val_loss: 3.1510e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.7903e-05 - val_loss: 3.1618e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.7963e-05 - val_loss: 3.1503e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.7911e-05 - val_loss: 3.1487e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.7937e-05 - val_loss: 3.1647e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8017e-05 - val_loss: 3.1529e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.7925e-05 - val_loss: 3.1463e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8340e-05 - val_loss: 3.1609e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.7899e-05 - val_loss: 3.1456e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.7852e-05 - val_loss: 3.1927e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8026e-05 - val_loss: 3.1937e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.8068e-05 - val_loss: 3.1633e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 3s 139us/step - loss: 0.2767 - val_loss: 3.9382e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0013 - val_loss: 3.1539e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 3.4883e-04 - val_loss: 2.2829e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 2.8345e-04 - val_loss: 2.1046e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 2.4929e-04 - val_loss: 1.9434e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 2.2335e-04 - val_loss: 1.7714e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 2.0311e-04 - val_loss: 1.6500e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.8761e-04 - val_loss: 1.5465e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.7487e-04 - val_loss: 1.4556e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.6443e-04 - val_loss: 1.3761e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.5657e-04 - val_loss: 1.3063e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.4907e-04 - val_loss: 1.2644e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.4368e-04 - val_loss: 1.2254e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.3885e-04 - val_loss: 1.1925e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.3518e-04 - val_loss: 1.1675e-04\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.3227e-04 - val_loss: 1.1418e-04\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.2996e-04 - val_loss: 1.1192e-04\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.2746e-04 - val_loss: 1.1025e-04\n",
      "Epoch 19/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.2546e-04 - val_loss: 1.0860e-04\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.2391e-04 - val_loss: 1.0693e-04\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.2255e-04 - val_loss: 1.0576e-04\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.2140e-04 - val_loss: 1.0436e-04\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.2026e-04 - val_loss: 1.0360e-04\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.1923e-04 - val_loss: 1.0165e-04\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 3s 138us/step - loss: 0.0082 - val_loss: 3.0158e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 1.2314e-04 - val_loss: 3.4882e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.9604e-05 - val_loss: 3.2706e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 8.9242e-05 - val_loss: 3.2867e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.9216e-05 - val_loss: 3.2645e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.9147e-05 - val_loss: 3.2633e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.9072e-05 - val_loss: 3.2628e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.9025e-05 - val_loss: 3.2514e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.8966e-05 - val_loss: 3.2482e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.8948e-05 - val_loss: 3.2570e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.8919e-05 - val_loss: 3.2452e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.8886e-05 - val_loss: 3.2393e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.8828e-05 - val_loss: 3.2369e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.8807e-05 - val_loss: 3.2312e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.8731e-05 - val_loss: 3.2459e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.8695e-05 - val_loss: 3.2255e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.8671e-05 - val_loss: 3.2373e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.8652e-05 - val_loss: 3.2676e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.8717e-05 - val_loss: 3.2377e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.8586e-05 - val_loss: 3.2189e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.8593e-05 - val_loss: 3.2425e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.8619e-05 - val_loss: 3.2154e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.8584e-05 - val_loss: 3.2271e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.8530e-05 - val_loss: 3.2345e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 3s 138us/step - loss: 0.2670 - val_loss: 3.4254e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 12us/step - loss: 9.1204e-05 - val_loss: 3.4072e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 9.0890e-05 - val_loss: 3.3875e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 9.0712e-05 - val_loss: 3.3796e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 9.0624e-05 - val_loss: 3.3644e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 9.0460e-05 - val_loss: 3.3620e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 9.0358e-05 - val_loss: 3.3492e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 9.0290e-05 - val_loss: 3.3445e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 9.0214e-05 - val_loss: 3.3524e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 9.0143e-05 - val_loss: 3.3326e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 9.0115e-05 - val_loss: 3.3428e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.9997e-05 - val_loss: 3.3322e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.9928e-05 - val_loss: 3.5740e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.9920e-05 - val_loss: 3.3192e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.9818e-05 - val_loss: 3.3304e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.9897e-05 - val_loss: 3.3090e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.9755e-05 - val_loss: 3.3084e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.9784e-05 - val_loss: 3.3053e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.9772e-05 - val_loss: 3.3023e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.9638e-05 - val_loss: 3.2987e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.9649e-05 - val_loss: 3.3057e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.9622e-05 - val_loss: 3.2956e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.9506e-05 - val_loss: 3.6028e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.9625e-05 - val_loss: 3.2942e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 3s 148us/step - loss: 0.0708 - val_loss: 4.4302e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0017 - val_loss: 1.7996e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.0750e-04 - val_loss: 3.4225e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0022 - val_loss: 3.2802e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 9.2326e-05 - val_loss: 3.2543e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 9.4745e-05 - val_loss: 3.2235e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 4.2631e-04 - val_loss: 0.0040\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.9794e-04 - val_loss: 3.1988e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 9.1305e-05 - val_loss: 3.8459e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.0785e-04 - val_loss: 1.6588e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 6.4397e-04 - val_loss: 1.8186e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.1283e-04 - val_loss: 3.1784e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.1983e-04 - val_loss: 1.2197e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 5.3938e-04 - val_loss: 1.2382e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.0143e-04 - val_loss: 3.6825e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 9.4430e-05 - val_loss: 5.2264e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 3.0118e-04 - val_loss: 0.0013\n",
      "Epoch 18/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 15us/step - loss: 3.8800e-04 - val_loss: 3.4831e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 9.0867e-05 - val_loss: 3.4782e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.0861e-04 - val_loss: 6.0818e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 2.5940e-04 - val_loss: 2.5242e-04\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.2318e-04 - val_loss: 4.7573e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 2.3993e-04 - val_loss: 4.0768e-04\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.3012e-04 - val_loss: 7.9509e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 3s 146us/step - loss: 0.1040 - val_loss: 4.2098e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0154 - val_loss: 3.5163e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0105 - val_loss: 3.5035e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0074 - val_loss: 3.4247e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0054 - val_loss: 3.7936e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0040 - val_loss: 3.7745e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0031 - val_loss: 3.5005e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0027 - val_loss: 3.1973e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0022 - val_loss: 3.3095e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0020 - val_loss: 3.3454e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0018 - val_loss: 3.5064e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0016 - val_loss: 3.1709e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0015 - val_loss: 3.1933e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0013 - val_loss: 3.3198e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0013 - val_loss: 3.2239e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0011 - val_loss: 3.1557e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0011 - val_loss: 3.1558e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 9.6164e-04 - val_loss: 3.1547e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 9.2972e-04 - val_loss: 3.2291e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.4412e-04 - val_loss: 3.3169e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 7.8492e-04 - val_loss: 3.1692e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 7.5003e-04 - val_loss: 3.1658e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 6.9926e-04 - val_loss: 3.2159e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 6.7948e-04 - val_loss: 3.1539e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 3s 152us/step - loss: 0.0314 - val_loss: 8.9174e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0061 - val_loss: 4.1905e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0033 - val_loss: 3.7302e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0020 - val_loss: 4.5818e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0014 - val_loss: 4.0412e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0012 - val_loss: 7.7329e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 9.5017e-04 - val_loss: 7.5895e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.1439e-04 - val_loss: 6.6526e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 7.1570e-04 - val_loss: 5.9294e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 6.3550e-04 - val_loss: 7.9578e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 5.9242e-04 - val_loss: 9.1902e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 5.3143e-04 - val_loss: 6.4084e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 4.7513e-04 - val_loss: 6.6690e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 4.5034e-04 - val_loss: 7.0849e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 4.1440e-04 - val_loss: 6.8212e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 3.8714e-04 - val_loss: 7.2402e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 3.5762e-04 - val_loss: 8.3815e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 3.3967e-04 - val_loss: 6.3857e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 3.2086e-04 - val_loss: 6.8794e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 2.9988e-04 - val_loss: 5.9338e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 2.8166e-04 - val_loss: 5.2256e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 2.6986e-04 - val_loss: 6.5088e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 2.5733e-04 - val_loss: 6.6816e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 2.3986e-04 - val_loss: 5.7175e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 3s 147us/step - loss: 0.2816 - val_loss: 6.7177e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0288 - val_loss: 6.3464e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0230 - val_loss: 1.1923e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0185 - val_loss: 6.1834e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0155 - val_loss: 3.4355e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0134 - val_loss: 3.7825e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0118 - val_loss: 1.0845e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0106 - val_loss: 3.5369e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0096 - val_loss: 3.2020e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0085 - val_loss: 3.2804e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0078 - val_loss: 5.1300e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0072 - val_loss: 3.3293e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0067 - val_loss: 3.4064e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0061 - val_loss: 3.6213e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0058 - val_loss: 3.2757e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0054 - val_loss: 3.2334e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0051 - val_loss: 3.2267e-05\n",
      "Epoch 18/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0049 - val_loss: 4.9621e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0046 - val_loss: 3.1611e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0044 - val_loss: 3.2034e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0042 - val_loss: 3.7975e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0040 - val_loss: 3.4860e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0038 - val_loss: 3.3231e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 0.0036 - val_loss: 3.7063e-05\n",
      "\n",
      "GENERATION 11\n",
      "\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 3s 150us/step - loss: 0.0057 - val_loss: 3.1486e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.8017e-05 - val_loss: 3.1474e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.8296e-05 - val_loss: 3.1573e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.8182e-05 - val_loss: 3.1688e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.8166e-05 - val_loss: 3.1606e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.8050e-05 - val_loss: 3.1627e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.8100e-05 - val_loss: 3.1591e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.8116e-05 - val_loss: 3.1705e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.8336e-05 - val_loss: 3.1531e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.8147e-05 - val_loss: 3.1510e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.8165e-05 - val_loss: 3.1459e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.8011e-05 - val_loss: 3.1518e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.7916e-05 - val_loss: 3.1473e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.8134e-05 - val_loss: 3.1457e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.8282e-05 - val_loss: 3.1642e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.8142e-05 - val_loss: 3.1488e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.7944e-05 - val_loss: 3.1458e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.8211e-05 - val_loss: 3.1466e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.7922e-05 - val_loss: 3.1457e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.8051e-05 - val_loss: 3.1463e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.8222e-05 - val_loss: 3.1458e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.8110e-05 - val_loss: 3.1457e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.8169e-05 - val_loss: 3.1600e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.8065e-05 - val_loss: 3.1877e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 3s 152us/step - loss: 0.0561 - val_loss: 1.7923e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 3.4184e-04 - val_loss: 5.8216e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 9.1880e-05 - val_loss: 3.1526e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.7834e-05 - val_loss: 3.1468e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.7821e-05 - val_loss: 3.1463e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.7814e-05 - val_loss: 3.1468e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.7831e-05 - val_loss: 3.1474e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.7835e-05 - val_loss: 3.1478e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.7828e-05 - val_loss: 3.1472e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.7825e-05 - val_loss: 3.1463e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.7824e-05 - val_loss: 3.1485e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.7829e-05 - val_loss: 3.1463e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.7838e-05 - val_loss: 3.1470e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.7824e-05 - val_loss: 3.1478e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.7824e-05 - val_loss: 3.1462e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.7827e-05 - val_loss: 3.1500e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.7824e-05 - val_loss: 3.1462e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.7827e-05 - val_loss: 3.1463e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.7850e-05 - val_loss: 3.1468e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.7835e-05 - val_loss: 3.1462e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.7855e-05 - val_loss: 3.1462e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.7830e-05 - val_loss: 3.1462e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.7841e-05 - val_loss: 3.1483e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.7825e-05 - val_loss: 3.1599e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 3s 157us/step - loss: 0.0012 - val_loss: 8.4914e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 9.6157e-05 - val_loss: 3.1956e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.7949e-05 - val_loss: 3.1493e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.7851e-05 - val_loss: 3.1500e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.7909e-05 - val_loss: 3.1466e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.7951e-05 - val_loss: 3.1616e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.7886e-05 - val_loss: 3.1496e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.7918e-05 - val_loss: 3.1564e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.7875e-05 - val_loss: 3.1793e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.7879e-05 - val_loss: 3.1525e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.7886e-05 - val_loss: 3.1524e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.8029e-05 - val_loss: 3.1490e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.8070e-05 - val_loss: 3.1455e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.7935e-05 - val_loss: 3.1495e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.7846e-05 - val_loss: 3.1611e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.7961e-05 - val_loss: 3.1468e-05\n",
      "Epoch 17/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.7967e-05 - val_loss: 3.1566e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.7956e-05 - val_loss: 3.1593e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.7948e-05 - val_loss: 3.1459e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.8091e-05 - val_loss: 3.1979e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.8025e-05 - val_loss: 3.2242e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.7915e-05 - val_loss: 3.1455e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.7922e-05 - val_loss: 3.1496e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 13us/step - loss: 8.7990e-05 - val_loss: 3.1464e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 3s 159us/step - loss: 0.3918 - val_loss: 0.0033\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.1305 - val_loss: 0.0104\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0903 - val_loss: 0.0045\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0696 - val_loss: 0.0033\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0578 - val_loss: 0.0055\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0472 - val_loss: 0.0054\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0400 - val_loss: 0.0058\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0340 - val_loss: 0.0051\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0306 - val_loss: 0.0052\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0267 - val_loss: 0.0065\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0240 - val_loss: 0.0064\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0213 - val_loss: 0.0058\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0198 - val_loss: 0.0065\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0173 - val_loss: 0.0055\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0162 - val_loss: 0.0056\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0146 - val_loss: 0.0049\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0131 - val_loss: 0.0053\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0120 - val_loss: 0.0056\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0112 - val_loss: 0.0052\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0103 - val_loss: 0.0049\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0094 - val_loss: 0.0040\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0088 - val_loss: 0.0044\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0080 - val_loss: 0.0038\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0076 - val_loss: 0.0036\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 4s 166us/step - loss: 1.3738 - val_loss: 0.0012\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.3996 - val_loss: 0.0138\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.2677 - val_loss: 0.0130\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.2030 - val_loss: 0.0161\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.1615 - val_loss: 0.0169\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.1346 - val_loss: 0.0187\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.1158 - val_loss: 0.0183\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0995 - val_loss: 0.0190\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0891 - val_loss: 0.0178\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0779 - val_loss: 0.0151\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0705 - val_loss: 0.0159\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0629 - val_loss: 0.0148\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0585 - val_loss: 0.0138\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0520 - val_loss: 0.0126\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0486 - val_loss: 0.0129\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0446 - val_loss: 0.0130\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0415 - val_loss: 0.0112\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0372 - val_loss: 0.0108\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0350 - val_loss: 0.0097\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0322 - val_loss: 0.0101\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0308 - val_loss: 0.0094\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0284 - val_loss: 0.0088\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0257 - val_loss: 0.0084\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0248 - val_loss: 0.0077\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 4s 177us/step - loss: 1.0150 - val_loss: 0.0848\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.1788 - val_loss: 0.0232\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0745 - val_loss: 0.0113\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0428 - val_loss: 0.0045\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0270 - val_loss: 0.0027\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0189 - val_loss: 0.0016\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0132 - val_loss: 1.4939e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0100 - val_loss: 2.3112e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 6.5818e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0058 - val_loss: 6.4539e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0046 - val_loss: 6.1979e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0037 - val_loss: 6.6356e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0030 - val_loss: 6.7928e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0025 - val_loss: 8.3063e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0021 - val_loss: 6.6921e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0017 - val_loss: 7.1593e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0015 - val_loss: 7.6268e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0013 - val_loss: 7.0074e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0011 - val_loss: 7.0739e-05\n",
      "Epoch 20/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 17us/step - loss: 9.3694e-04 - val_loss: 7.9871e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.3115e-04 - val_loss: 7.3577e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 7.3981e-04 - val_loss: 8.0756e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 6.6692e-04 - val_loss: 1.0268e-04\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 6.1851e-04 - val_loss: 8.3105e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 4s 175us/step - loss: 1.7147 - val_loss: 0.0387\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.5418 - val_loss: 0.0304\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.3714 - val_loss: 0.0389\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.2867 - val_loss: 0.0319\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.2329 - val_loss: 0.0215\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.1926 - val_loss: 0.0186\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.1692 - val_loss: 0.0144\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.1437 - val_loss: 0.0124\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.1245 - val_loss: 0.0153\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.1100 - val_loss: 0.0135\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0955 - val_loss: 0.0141\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0847 - val_loss: 0.0084\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0759 - val_loss: 0.0065\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0712 - val_loss: 0.0074\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0628 - val_loss: 0.0077\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0562 - val_loss: 0.0068\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0494 - val_loss: 0.0057\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0447 - val_loss: 0.0038\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0402 - val_loss: 0.0041\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0357 - val_loss: 0.0033\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0326 - val_loss: 0.0026\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0289 - val_loss: 0.0023\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0256 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0227 - val_loss: 0.0012\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 4s 175us/step - loss: 1.8236 - val_loss: 0.1264\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.6477 - val_loss: 0.0907\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.4732 - val_loss: 0.0785\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.3773 - val_loss: 0.0875\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.3057 - val_loss: 0.0952\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.2574 - val_loss: 0.0719\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.2185 - val_loss: 0.0662\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.1868 - val_loss: 0.0279\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.1613 - val_loss: 0.0242\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.1416 - val_loss: 0.0212\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.1252 - val_loss: 0.0182\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.1093 - val_loss: 0.0130\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0939 - val_loss: 0.0133\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0837 - val_loss: 0.0112\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0737 - val_loss: 0.0084\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0680 - val_loss: 0.0077\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0597 - val_loss: 0.0067\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0555 - val_loss: 0.0069\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0509 - val_loss: 0.0056\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0455 - val_loss: 0.0067\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0410 - val_loss: 0.0058\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0384 - val_loss: 0.0051\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0355 - val_loss: 0.0044\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0319 - val_loss: 0.0043\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 4s 180us/step - loss: 0.6999 - val_loss: 0.3304\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.2387 - val_loss: 0.1566\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.1657 - val_loss: 0.1153\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.1249 - val_loss: 0.0965\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0961 - val_loss: 0.0649\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0763 - val_loss: 0.0523\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0608 - val_loss: 0.0451\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0506 - val_loss: 0.0437\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0440 - val_loss: 0.0399\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0355 - val_loss: 0.0276\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0315 - val_loss: 0.0261\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0268 - val_loss: 0.0165\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0238 - val_loss: 0.0193\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0204 - val_loss: 0.0139\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0176 - val_loss: 0.0132\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0163 - val_loss: 0.0103\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0143 - val_loss: 0.0098\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0124 - val_loss: 0.0080\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0114 - val_loss: 0.0061\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0098 - val_loss: 0.0059\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0090 - val_loss: 0.0051\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0082 - val_loss: 0.0047\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0073 - val_loss: 0.0040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0066 - val_loss: 0.0025\n",
      "\n",
      "GENERATION 12\n",
      "\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 4s 171us/step - loss: 0.9630 - val_loss: 0.0118\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 0.0027 - val_loss: 3.4964e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 4.1706e-04 - val_loss: 3.1051e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 3.5620e-04 - val_loss: 2.8624e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 3.3020e-04 - val_loss: 2.6656e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 3.0972e-04 - val_loss: 2.4805e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 2.9191e-04 - val_loss: 2.3365e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 2.7699e-04 - val_loss: 2.1779e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 2.6380e-04 - val_loss: 2.0351e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 2.5250e-04 - val_loss: 1.9015e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 2.4180e-04 - val_loss: 1.7680e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 2.3259e-04 - val_loss: 1.6691e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 2.2386e-04 - val_loss: 1.5829e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 2.1718e-04 - val_loss: 1.5062e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 2.1031e-04 - val_loss: 1.4295e-04\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 2.0448e-04 - val_loss: 1.3525e-04\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.9922e-04 - val_loss: 1.3010e-04\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.9448e-04 - val_loss: 1.2420e-04\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.9056e-04 - val_loss: 1.1948e-04\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.8672e-04 - val_loss: 1.1507e-04\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.8374e-04 - val_loss: 1.1203e-04\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.8098e-04 - val_loss: 1.0821e-04\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.7899e-04 - val_loss: 1.0620e-04\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.7540e-04 - val_loss: 1.0359e-04\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 4s 174us/step - loss: 0.0032 - val_loss: 3.1884e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 1.0397e-04 - val_loss: 3.1798e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.7901e-05 - val_loss: 3.1457e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.7834e-05 - val_loss: 3.1490e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.7853e-05 - val_loss: 3.1458e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.7857e-05 - val_loss: 3.1513e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.7889e-05 - val_loss: 3.1465e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.7854e-05 - val_loss: 3.1455e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.7856e-05 - val_loss: 3.1455e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.7857e-05 - val_loss: 3.1466e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.7881e-05 - val_loss: 3.1457e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.7833e-05 - val_loss: 3.1456e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.7839e-05 - val_loss: 3.1455e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.7915e-05 - val_loss: 3.1482e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.7865e-05 - val_loss: 3.1468e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.7844e-05 - val_loss: 3.1615e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.7978e-05 - val_loss: 3.1460e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.7877e-05 - val_loss: 3.1607e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.7921e-05 - val_loss: 3.1459e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.7844e-05 - val_loss: 3.1582e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.7920e-05 - val_loss: 3.1657e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.7860e-05 - val_loss: 3.1493e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.7951e-05 - val_loss: 3.1491e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.7895e-05 - val_loss: 3.1465e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 4s 173us/step - loss: 4.3490e-04 - val_loss: 3.2172e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.9236e-05 - val_loss: 3.1662e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.8081e-05 - val_loss: 3.1476e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.7905e-05 - val_loss: 3.1487e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.7998e-05 - val_loss: 3.1472e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.7900e-05 - val_loss: 3.1549e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.7896e-05 - val_loss: 3.1545e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.8014e-05 - val_loss: 3.1493e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.7903e-05 - val_loss: 3.1463e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.7896e-05 - val_loss: 3.1652e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.7903e-05 - val_loss: 3.1526e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.7927e-05 - val_loss: 3.1479e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.8020e-05 - val_loss: 3.1514e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.8307e-05 - val_loss: 3.1509e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.7961e-05 - val_loss: 3.1612e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.7984e-05 - val_loss: 3.1577e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.7954e-05 - val_loss: 3.1547e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.8050e-05 - val_loss: 3.1454e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.7987e-05 - val_loss: 3.1565e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.7852e-05 - val_loss: 3.1490e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.7910e-05 - val_loss: 3.2002e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.7964e-05 - val_loss: 3.1458e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.7950e-05 - val_loss: 3.2168e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.8140e-05 - val_loss: 3.1772e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 4s 175us/step - loss: 5.0109e-04 - val_loss: 4.2620e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 9.1365e-05 - val_loss: 3.2143e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.7983e-05 - val_loss: 3.1575e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.7899e-05 - val_loss: 3.1468e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.7918e-05 - val_loss: 3.1693e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.8033e-05 - val_loss: 3.1482e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.8061e-05 - val_loss: 3.1467e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.7972e-05 - val_loss: 3.1780e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.8117e-05 - val_loss: 3.1645e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.7911e-05 - val_loss: 3.1498e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.8032e-05 - val_loss: 3.1517e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.7976e-05 - val_loss: 3.1522e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.8046e-05 - val_loss: 3.1482e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.8054e-05 - val_loss: 3.2211e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.8083e-05 - val_loss: 3.2297e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.8149e-05 - val_loss: 3.1461e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.7876e-05 - val_loss: 3.1821e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.7913e-05 - val_loss: 3.1483e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.7996e-05 - val_loss: 3.1486e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.8035e-05 - val_loss: 3.1764e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.8026e-05 - val_loss: 3.1489e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.7904e-05 - val_loss: 3.1459e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.8067e-05 - val_loss: 3.1684e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.7980e-05 - val_loss: 3.1559e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 4s 181us/step - loss: 1.1669 - val_loss: 0.0464\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.3406 - val_loss: 0.0014\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.2370 - val_loss: 0.0024\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.1762 - val_loss: 0.0023\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.1458 - val_loss: 7.7706e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.1184 - val_loss: 4.5521e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.1020 - val_loss: 6.2470e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0861 - val_loss: 0.0011\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0768 - val_loss: 4.0401e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0673 - val_loss: 8.3581e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0616 - val_loss: 5.7327e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0559 - val_loss: 5.7936e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0497 - val_loss: 2.7033e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0456 - val_loss: 3.0309e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0420 - val_loss: 1.3256e-04\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0379 - val_loss: 1.1798e-04\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0351 - val_loss: 1.3730e-04\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0326 - val_loss: 4.9769e-04\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0295 - val_loss: 8.1439e-04\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0279 - val_loss: 4.6760e-04\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0260 - val_loss: 6.2467e-04\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0237 - val_loss: 9.2992e-04\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0223 - val_loss: 0.0010\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0201 - val_loss: 0.0014\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 4s 185us/step - loss: 0.9249 - val_loss: 0.0053\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.3613 - val_loss: 0.0274\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.2279 - val_loss: 0.0634\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.1666 - val_loss: 0.0406\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.1349 - val_loss: 0.0361\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.1117 - val_loss: 0.0312\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0947 - val_loss: 0.0291\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0812 - val_loss: 0.0306\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0691 - val_loss: 0.0338\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0616 - val_loss: 0.0271\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0533 - val_loss: 0.0269\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0465 - val_loss: 0.0275\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0408 - val_loss: 0.0224\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0354 - val_loss: 0.0230\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0316 - val_loss: 0.0210\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0277 - val_loss: 0.0191\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0245 - val_loss: 0.0187\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0220 - val_loss: 0.0147\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0198 - val_loss: 0.0121\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0175 - val_loss: 0.0112\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0155 - val_loss: 0.0089\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0142 - val_loss: 0.0094\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0127 - val_loss: 0.0087\n",
      "Epoch 24/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0114 - val_loss: 0.0066\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 4s 188us/step - loss: 1.0081 - val_loss: 0.0132\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.2354 - val_loss: 0.0243\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.1583 - val_loss: 0.0291\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.1297 - val_loss: 0.0248\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.1090 - val_loss: 0.0262\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0982 - val_loss: 0.0197\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0860 - val_loss: 0.0177\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0755 - val_loss: 0.0181\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0676 - val_loss: 0.0173\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0604 - val_loss: 0.0156\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0540 - val_loss: 0.0145\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0502 - val_loss: 0.0130\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0456 - val_loss: 0.0108\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0406 - val_loss: 0.0108\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0375 - val_loss: 0.0108\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0353 - val_loss: 0.0104\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0320 - val_loss: 0.0092\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0293 - val_loss: 0.0094\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0265 - val_loss: 0.0085\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0249 - val_loss: 0.0077\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0233 - val_loss: 0.0080\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0219 - val_loss: 0.0074\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0202 - val_loss: 0.0078\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0180 - val_loss: 0.0065\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 4s 191us/step - loss: 0.7667 - val_loss: 0.0297\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.1806 - val_loss: 0.0056\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.1293 - val_loss: 0.0079\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0995 - val_loss: 0.0067\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0804 - val_loss: 0.0099\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0674 - val_loss: 0.0101\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0564 - val_loss: 0.0126\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0485 - val_loss: 0.0131\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0427 - val_loss: 0.0111\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0380 - val_loss: 0.0110\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0338 - val_loss: 0.0113\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0300 - val_loss: 0.0121\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0279 - val_loss: 0.0086\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0249 - val_loss: 0.0100\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0231 - val_loss: 0.0080\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0209 - val_loss: 0.0079\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0194 - val_loss: 0.0067\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0176 - val_loss: 0.0074\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0166 - val_loss: 0.0063\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0153 - val_loss: 0.0060\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0142 - val_loss: 0.0060\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0132 - val_loss: 0.0049\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0126 - val_loss: 0.0049\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0115 - val_loss: 0.0040\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 4s 193us/step - loss: 0.8887 - val_loss: 0.2182\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.1230 - val_loss: 0.0391\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0389 - val_loss: 0.0228\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0277 - val_loss: 1.0269e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0161 - val_loss: 0.0015\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0254 - val_loss: 4.7170e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0044 - val_loss: 0.1028\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0129 - val_loss: 2.7981e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0070 - val_loss: 3.4019e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0070 - val_loss: 2.2767e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0099 - val_loss: 6.0979e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0048 - val_loss: 3.6230e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0041 - val_loss: 4.9702e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0210 - val_loss: 3.9825e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0029 - val_loss: 4.4463e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0042 - val_loss: 3.6600e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0050 - val_loss: 3.5533e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0039 - val_loss: 2.2875e-04\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0041 - val_loss: 6.3857e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0044 - val_loss: 4.9539e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0045 - val_loss: 4.0899e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0029 - val_loss: 0.0019\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0020 - val_loss: 0.0197\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0043 - val_loss: 1.3316e-04\n",
      "\n",
      "GENERATION 13\n",
      "\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 4s 189us/step - loss: 8.8113e-04 - val_loss: 3.2163e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 9.2807e-05 - val_loss: 3.1920e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.8072e-05 - val_loss: 3.1470e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.7917e-05 - val_loss: 3.1539e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.8115e-05 - val_loss: 3.1478e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.7921e-05 - val_loss: 3.1514e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.8057e-05 - val_loss: 3.1473e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.7975e-05 - val_loss: 3.1727e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.8000e-05 - val_loss: 3.1492e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.8029e-05 - val_loss: 3.1539e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.7935e-05 - val_loss: 3.1961e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.7892e-05 - val_loss: 3.1965e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.7990e-05 - val_loss: 3.1461e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.7886e-05 - val_loss: 3.1646e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.8022e-05 - val_loss: 3.1663e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.7932e-05 - val_loss: 3.1465e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.8030e-05 - val_loss: 3.1617e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.8067e-05 - val_loss: 3.1481e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.7871e-05 - val_loss: 3.2035e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.7956e-05 - val_loss: 3.1634e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.7937e-05 - val_loss: 3.1738e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.7883e-05 - val_loss: 3.1521e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.7991e-05 - val_loss: 3.1651e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.8079e-05 - val_loss: 3.1629e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 4s 190us/step - loss: 0.2750 - val_loss: 0.0081\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0018 - val_loss: 8.6546e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.0637e-04 - val_loss: 3.1732e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.8095e-05 - val_loss: 3.1485e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.7872e-05 - val_loss: 3.1486e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.7866e-05 - val_loss: 3.1485e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.7861e-05 - val_loss: 3.1488e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.7871e-05 - val_loss: 3.1492e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.7867e-05 - val_loss: 3.1488e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.7862e-05 - val_loss: 3.1486e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.7869e-05 - val_loss: 3.1502e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.7863e-05 - val_loss: 3.1486e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.7868e-05 - val_loss: 3.1484e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.7865e-05 - val_loss: 3.1488e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.7875e-05 - val_loss: 3.1486e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.7862e-05 - val_loss: 3.1496e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.7862e-05 - val_loss: 3.1484e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.7859e-05 - val_loss: 3.1493e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.7869e-05 - val_loss: 3.1484e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.7876e-05 - val_loss: 3.1484e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.7859e-05 - val_loss: 3.1497e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.7863e-05 - val_loss: 3.1489e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.7868e-05 - val_loss: 3.1493e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.7870e-05 - val_loss: 3.1483e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 4s 194us/step - loss: 0.2650 - val_loss: 0.0089\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0014 - val_loss: 1.3815e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.0242e-04 - val_loss: 3.2815e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.7944e-05 - val_loss: 3.1480e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.7826e-05 - val_loss: 3.1459e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.7813e-05 - val_loss: 3.1459e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.7820e-05 - val_loss: 3.1461e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.7819e-05 - val_loss: 3.1459e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 14us/step - loss: 8.7817e-05 - val_loss: 3.1459e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.7822e-05 - val_loss: 3.1460e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.7810e-05 - val_loss: 3.1460e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.7827e-05 - val_loss: 3.1484e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.7822e-05 - val_loss: 3.1462e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.7831e-05 - val_loss: 3.1458e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.7823e-05 - val_loss: 3.1471e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.7834e-05 - val_loss: 3.1463e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.7829e-05 - val_loss: 3.1484e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.7826e-05 - val_loss: 3.1460e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.7820e-05 - val_loss: 3.1460e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.7831e-05 - val_loss: 3.1470e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.7815e-05 - val_loss: 3.1459e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.7809e-05 - val_loss: 3.1493e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.7813e-05 - val_loss: 3.1488e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.7835e-05 - val_loss: 3.1471e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 4s 196us/step - loss: 0.0029 - val_loss: 1.7695e-04\n",
      "Epoch 2/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 9.4511e-04 - val_loss: 8.4826e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.4130e-04 - val_loss: 6.7040e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 7.8294e-04 - val_loss: 7.4284e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 7.2647e-04 - val_loss: 6.6378e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 6.7349e-04 - val_loss: 7.7415e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 6.3818e-04 - val_loss: 6.4141e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 5.9853e-04 - val_loss: 6.3789e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 5.7723e-04 - val_loss: 4.7941e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 5.2947e-04 - val_loss: 3.7741e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 5.0539e-04 - val_loss: 5.8572e-04\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 4.9493e-04 - val_loss: 3.6203e-04\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 4.5858e-04 - val_loss: 3.4468e-04\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 4.5607e-04 - val_loss: 3.5462e-04\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 4.1788e-04 - val_loss: 3.6960e-04\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 4.1865e-04 - val_loss: 2.8732e-04\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 3.9301e-04 - val_loss: 2.7099e-04\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 3.8287e-04 - val_loss: 3.6480e-04\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 3.7072e-04 - val_loss: 2.7229e-04\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 3.5338e-04 - val_loss: 2.7000e-04\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 4s 206us/step - loss: 0.0163 - val_loss: 9.3509e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0033 - val_loss: 9.0023e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0016 - val_loss: 2.8495e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 9.2769e-04 - val_loss: 2.8502e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 6.1049e-04 - val_loss: 1.6361e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 4.7021e-04 - val_loss: 1.1951e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 3.6439e-04 - val_loss: 2.9851e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 3.1282e-04 - val_loss: 3.1403e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.6795e-04 - val_loss: 3.1442e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.4206e-04 - val_loss: 1.5346e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.1500e-04 - val_loss: 1.0916e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.9691e-04 - val_loss: 1.0530e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.8080e-04 - val_loss: 6.5450e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.6147e-04 - val_loss: 8.0369e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.6262e-04 - val_loss: 4.2413e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.5245e-04 - val_loss: 1.0293e-04\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.3822e-04 - val_loss: 3.3043e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.4555e-04 - val_loss: 7.6992e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.3776e-04 - val_loss: 9.2177e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.3796e-04 - val_loss: 6.3981e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.3741e-04 - val_loss: 4.7329e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.3473e-04 - val_loss: 8.8538e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.3864e-04 - val_loss: 1.0629e-04\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.3508e-04 - val_loss: 1.1466e-04\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 4s 198us/step - loss: 0.2814 - val_loss: 0.0185\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0549 - val_loss: 0.0016\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0412 - val_loss: 0.0015\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0333 - val_loss: 6.4038e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0283 - val_loss: 0.0010\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0239 - val_loss: 0.0012\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0208 - val_loss: 0.0011\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0183 - val_loss: 9.6465e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0159 - val_loss: 0.0010\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0144 - val_loss: 9.1110e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0129 - val_loss: 0.0010\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0116 - val_loss: 0.0010\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0106 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0097 - val_loss: 7.8979e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0090 - val_loss: 7.0658e-04\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0081 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0075 - val_loss: 8.7283e-04\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0071 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0066 - val_loss: 8.6891e-04\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0062 - val_loss: 9.0936e-04\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0056 - val_loss: 7.1274e-04\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0054 - val_loss: 8.6729e-04\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0050 - val_loss: 7.8522e-04\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0047 - val_loss: 6.1993e-04\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 5s 216us/step - loss: 0.2491 - val_loss: 0.0142\n",
      "Epoch 2/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0203 - val_loss: 0.0017\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0164 - val_loss: 0.0012\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0144 - val_loss: 0.0012\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0126 - val_loss: 0.0011\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0117 - val_loss: 0.0011\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0104 - val_loss: 9.2922e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0094 - val_loss: 7.6103e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0087 - val_loss: 8.0153e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0080 - val_loss: 7.3144e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 6.5905e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0067 - val_loss: 6.1982e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0063 - val_loss: 7.1815e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0058 - val_loss: 6.0937e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0054 - val_loss: 5.0898e-04\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0050 - val_loss: 6.4154e-04\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0048 - val_loss: 4.5340e-04\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0045 - val_loss: 4.7793e-04\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0042 - val_loss: 5.4242e-04\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0039 - val_loss: 4.8183e-04\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0037 - val_loss: 4.8252e-04\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0034 - val_loss: 3.7912e-04\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0033 - val_loss: 4.2861e-04\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0030 - val_loss: 4.5192e-04\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 5s 210us/step - loss: 0.0933 - val_loss: 3.0933e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0163 - val_loss: 6.4488e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0116 - val_loss: 1.0164e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0088 - val_loss: 1.4109e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 8.9880e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0065 - val_loss: 1.0410e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0057 - val_loss: 4.4243e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0052 - val_loss: 7.3517e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0047 - val_loss: 4.1626e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0044 - val_loss: 4.5242e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0040 - val_loss: 6.4219e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0037 - val_loss: 8.6785e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0035 - val_loss: 6.8473e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0033 - val_loss: 6.3751e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0031 - val_loss: 5.4538e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0028 - val_loss: 5.2424e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0027 - val_loss: 7.0342e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0026 - val_loss: 6.8057e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0024 - val_loss: 5.9447e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0023 - val_loss: 5.0688e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0022 - val_loss: 3.8867e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0021 - val_loss: 4.4263e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0020 - val_loss: 5.0800e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0019 - val_loss: 4.3377e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 5s 218us/step - loss: 0.1363 - val_loss: 0.0010\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0315 - val_loss: 0.0028\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0227 - val_loss: 0.0013\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0182 - val_loss: 0.0012\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0153 - val_loss: 8.2556e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0130 - val_loss: 9.4208e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0112 - val_loss: 6.5946e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0101 - val_loss: 5.5901e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0090 - val_loss: 4.9957e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0081 - val_loss: 2.6917e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0073 - val_loss: 2.4975e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0066 - val_loss: 2.0151e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0061 - val_loss: 1.7274e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0055 - val_loss: 1.6471e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0052 - val_loss: 8.6934e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0048 - val_loss: 4.6629e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0044 - val_loss: 1.0103e-04\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0043 - val_loss: 7.6994e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0038 - val_loss: 7.0685e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0037 - val_loss: 3.9007e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0035 - val_loss: 6.2378e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0031 - val_loss: 4.2849e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0030 - val_loss: 3.5296e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0028 - val_loss: 3.7303e-05\n",
      "\n",
      "GENERATION 14\n",
      "\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 4s 209us/step - loss: 0.1037 - val_loss: 1.3172e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 9.8519e-05 - val_loss: 3.1472e-05\n",
      "Epoch 3/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.7868e-05 - val_loss: 3.1471e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.8024e-05 - val_loss: 3.1611e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 9.8035e-05 - val_loss: 1.7447e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 6.1825e-04 - val_loss: 7.9219e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 0.0011 - val_loss: 9.9038e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0010 - val_loss: 8.6207e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0010 - val_loss: 9.3417e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 9.7554e-04 - val_loss: 7.4381e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 9.3418e-04 - val_loss: 9.3637e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.3413e-04 - val_loss: 6.6398e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 7.4548e-04 - val_loss: 8.1303e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.5124e-04 - val_loss: 7.8035e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.6131e-04 - val_loss: 8.7633e-04\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.8607e-04 - val_loss: 6.9958e-04\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 7.4051e-04 - val_loss: 7.1173e-04\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.3304e-04 - val_loss: 7.0909e-04\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 7.2734e-04 - val_loss: 5.9020e-04\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 6.6725e-04 - val_loss: 6.9854e-04\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 7.8060e-04 - val_loss: 6.1377e-04\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 6.4737e-04 - val_loss: 6.0879e-04\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 6.4563e-04 - val_loss: 5.7880e-04\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 7.9550e-04 - val_loss: 9.9278e-04\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 5s 210us/step - loss: 0.0554 - val_loss: 3.3769e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 2.5434e-04 - val_loss: 4.8702e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 9.1909e-05 - val_loss: 3.1689e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.7847e-05 - val_loss: 3.1465e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.7818e-05 - val_loss: 3.1463e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.7824e-05 - val_loss: 3.1463e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.7836e-05 - val_loss: 3.1462e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.7818e-05 - val_loss: 3.1470e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.7810e-05 - val_loss: 3.1530e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.7841e-05 - val_loss: 3.1461e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.7845e-05 - val_loss: 3.1461e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.7821e-05 - val_loss: 3.1469e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.7826e-05 - val_loss: 3.1462e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.7821e-05 - val_loss: 3.1463e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.7825e-05 - val_loss: 3.1463e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.7818e-05 - val_loss: 3.1465e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.7843e-05 - val_loss: 3.1524e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.7839e-05 - val_loss: 3.1470e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.7879e-05 - val_loss: 3.1466e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.7850e-05 - val_loss: 3.1461e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.7829e-05 - val_loss: 3.1461e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.7845e-05 - val_loss: 3.1470e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.7824e-05 - val_loss: 3.1461e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 8.7823e-05 - val_loss: 3.1498e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 5s 211us/step - loss: 0.8526 - val_loss: 0.1476\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.1343 - val_loss: 0.0864\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.1021 - val_loss: 0.0095\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0665 - val_loss: 7.7652e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0378 - val_loss: 0.1190\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0594 - val_loss: 6.0248e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0257 - val_loss: 3.9196e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0304 - val_loss: 0.0141\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0233 - val_loss: 0.0583\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0400 - val_loss: 5.4165e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0173 - val_loss: 5.1702e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0179 - val_loss: 2.8997e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0105 - val_loss: 0.0048\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0328 - val_loss: 9.5945e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0122 - val_loss: 6.8992e-04\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0153 - val_loss: 3.7654e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0145 - val_loss: 3.5820e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0067 - val_loss: 0.0030\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0049 - val_loss: 0.0072\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0072 - val_loss: 0.0154\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0132\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0066 - val_loss: 4.6352e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0053 - val_loss: 5.8454e-04\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0045 - val_loss: 0.0027\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 5s 223us/step - loss: 0.3520 - val_loss: 0.0379\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0781 - val_loss: 0.0031\n",
      "Epoch 3/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0297 - val_loss: 0.0150\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0183 - val_loss: 2.1917e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0119 - val_loss: 0.0198\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0071 - val_loss: 2.4477e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0065 - val_loss: 2.2559e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0030 - val_loss: 5.2422e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0033 - val_loss: 0.0077\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0039 - val_loss: 9.2999e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0092 - val_loss: 1.8941e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0010 - val_loss: 1.9079e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0018 - val_loss: 0.0067\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0032 - val_loss: 3.8236e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0022 - val_loss: 5.5936e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 6.9837e-04 - val_loss: 0.0014\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0025 - val_loss: 5.4210e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0014 - val_loss: 9.6767e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0016 - val_loss: 9.8596e-04\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0016 - val_loss: 7.5255e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 9.9961e-04 - val_loss: 0.0022\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0011 - val_loss: 5.8095e-04\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0017 - val_loss: 1.6204e-04\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0015 - val_loss: 5.3236e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 5s 221us/step - loss: 0.6741 - val_loss: 0.0638\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.1118 - val_loss: 0.0337\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0487 - val_loss: 0.0030\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0263 - val_loss: 1.4525e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0168 - val_loss: 0.0069\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0152 - val_loss: 0.0014\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0147 - val_loss: 0.0241\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0164 - val_loss: 0.0029\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0108 - val_loss: 1.1449e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0043 - val_loss: 5.2104e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0050 - val_loss: 0.0017\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0050 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0063 - val_loss: 0.0022\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0085 - val_loss: 1.8212e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0047 - val_loss: 5.9817e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0052 - val_loss: 6.5709e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0057 - val_loss: 3.7422e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 3.7848e-04 - val_loss: 3.7864e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0064 - val_loss: 3.7562e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0017 - val_loss: 4.1676e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0018 - val_loss: 1.9018e-04\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0029 - val_loss: 7.6593e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0018 - val_loss: 3.5725e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0017 - val_loss: 4.0098e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 5s 228us/step - loss: 2.1176 - val_loss: 0.0049\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.3099 - val_loss: 0.0338\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.1326 - val_loss: 0.0170\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0485 - val_loss: 0.0080\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0217 - val_loss: 0.0015\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0114 - val_loss: 0.0027\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0105 - val_loss: 2.8106e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0056 - val_loss: 4.3411e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0064 - val_loss: 0.0104\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0013\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0035 - val_loss: 0.0048\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0034 - val_loss: 4.6767e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0023 - val_loss: 1.9656e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0023 - val_loss: 5.2262e-04\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0014 - val_loss: 2.2643e-04\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0020 - val_loss: 1.4497e-04\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0042 - val_loss: 3.8191e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0019 - val_loss: 3.5378e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0018 - val_loss: 3.5160e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0011 - val_loss: 1.2716e-04\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0015 - val_loss: 3.4257e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 4.6405e-04 - val_loss: 0.0014\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 5s 231us/step - loss: 1.7753 - val_loss: 0.1266\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.5997 - val_loss: 0.0266\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.4872 - val_loss: 0.0242\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.3993 - val_loss: 0.0023\n",
      "Epoch 5/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.3189 - val_loss: 0.0058\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.2623 - val_loss: 0.0171\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.2203 - val_loss: 0.0101\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.1901 - val_loss: 0.0076\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.1606 - val_loss: 0.0129\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.1392 - val_loss: 0.0131\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.1186 - val_loss: 0.0109\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.1019 - val_loss: 0.0158\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0860 - val_loss: 0.0128\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0736 - val_loss: 0.0148\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0662 - val_loss: 0.0147\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0540 - val_loss: 0.0145\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0484 - val_loss: 0.0133\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0420 - val_loss: 0.0162\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0378 - val_loss: 0.0111\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0343 - val_loss: 0.0117\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0305 - val_loss: 0.0115\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0273 - val_loss: 0.0118\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0256 - val_loss: 0.0114\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0235 - val_loss: 0.0117\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 5s 233us/step - loss: 0.5954 - val_loss: 0.1424\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.1686 - val_loss: 0.0450\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0492 - val_loss: 0.0074\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0222 - val_loss: 6.7173e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0539 - val_loss: 6.1056e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0056 - val_loss: 2.7807e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0043 - val_loss: 0.0017\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0078 - val_loss: 4.7480e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0019 - val_loss: 2.5662e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0027 - val_loss: 1.0458e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0033 - val_loss: 0.0016\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0020 - val_loss: 3.8586e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0016 - val_loss: 5.4659e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0016 - val_loss: 8.2836e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0012 - val_loss: 6.7907e-04\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0012 - val_loss: 3.8326e-04\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0012 - val_loss: 1.6226e-04\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 9.1169e-04 - val_loss: 7.4153e-04\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0017 - val_loss: 7.0766e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.9109e-04 - val_loss: 6.8371e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.4729e-04 - val_loss: 3.3978e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.1885e-04 - val_loss: 3.2771e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.5537e-04 - val_loss: 3.4533e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 5s 231us/step - loss: 0.0012 - val_loss: 3.4273e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.0719e-04 - val_loss: 3.2335e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.9515e-05 - val_loss: 3.1649e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.8428e-05 - val_loss: 3.1513e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.8157e-05 - val_loss: 3.2029e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.8294e-05 - val_loss: 3.1869e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.8148e-05 - val_loss: 3.1459e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.8160e-05 - val_loss: 3.1546e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.8236e-05 - val_loss: 3.1501e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.8229e-05 - val_loss: 3.1487e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.8179e-05 - val_loss: 3.1573e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.8144e-05 - val_loss: 3.1629e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.8193e-05 - val_loss: 3.1623e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.8208e-05 - val_loss: 3.2175e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.8156e-05 - val_loss: 3.1486e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.8132e-05 - val_loss: 3.1799e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.8146e-05 - val_loss: 3.2362e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.8243e-05 - val_loss: 3.1535e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.8068e-05 - val_loss: 3.1456e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.8087e-05 - val_loss: 3.1515e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.8074e-05 - val_loss: 3.1499e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.8208e-05 - val_loss: 3.1457e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.8106e-05 - val_loss: 3.1540e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.8369e-05 - val_loss: 3.1496e-05\n",
      "\n",
      "GENERATION 15\n",
      "\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 5s 232us/step - loss: 0.0272 - val_loss: 9.5694e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0028 - val_loss: 3.3235e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0024 - val_loss: 3.9626e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0022 - val_loss: 3.8758e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0021 - val_loss: 3.5686e-05\n",
      "Epoch 6/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0019 - val_loss: 4.2343e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0018 - val_loss: 3.5136e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0016 - val_loss: 3.7014e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0015 - val_loss: 3.9684e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0014 - val_loss: 3.8208e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0013 - val_loss: 3.5420e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0012 - val_loss: 3.3747e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0011 - val_loss: 3.9745e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0010 - val_loss: 3.4419e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 9.5156e-04 - val_loss: 3.4500e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.9450e-04 - val_loss: 3.6684e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.3804e-04 - val_loss: 3.8934e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.0315e-04 - val_loss: 3.6732e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 7.4556e-04 - val_loss: 4.0200e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 7.0199e-04 - val_loss: 3.9592e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 6.5462e-04 - val_loss: 3.4941e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 6.1628e-04 - val_loss: 3.4301e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 5.6756e-04 - val_loss: 3.4910e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 5.4560e-04 - val_loss: 3.4134e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 5s 232us/step - loss: 0.0151 - val_loss: 7.1327e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.4470e-04 - val_loss: 3.1739e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.8488e-05 - val_loss: 3.1502e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.7884e-05 - val_loss: 3.1511e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.7873e-05 - val_loss: 3.1507e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.7868e-05 - val_loss: 3.1481e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.7880e-05 - val_loss: 3.1477e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.7886e-05 - val_loss: 3.1487e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7861e-05 - val_loss: 3.1478e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7853e-05 - val_loss: 3.1533e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.7884e-05 - val_loss: 3.1492e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7872e-05 - val_loss: 3.1503e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7870e-05 - val_loss: 3.1511e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.7863e-05 - val_loss: 3.1489e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.7871e-05 - val_loss: 3.1510e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.7859e-05 - val_loss: 3.1613e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.7955e-05 - val_loss: 3.1468e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.7895e-05 - val_loss: 3.1526e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.7957e-05 - val_loss: 3.1481e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.7867e-05 - val_loss: 3.1465e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.7862e-05 - val_loss: 3.1494e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.7851e-05 - val_loss: 3.1478e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.7929e-05 - val_loss: 3.1493e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.7907e-05 - val_loss: 3.1603e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 5s 235us/step - loss: 0.1331 - val_loss: 0.0023\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 4.0057e-04 - val_loss: 3.7254e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 9.1012e-05 - val_loss: 3.1504e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.7912e-05 - val_loss: 3.1500e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.7878e-05 - val_loss: 3.1501e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.7879e-05 - val_loss: 3.1500e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.7882e-05 - val_loss: 3.1503e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.7887e-05 - val_loss: 3.1512e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.7876e-05 - val_loss: 3.1500e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.7884e-05 - val_loss: 3.1503e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.7876e-05 - val_loss: 3.1510e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.7878e-05 - val_loss: 3.1499e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.7885e-05 - val_loss: 3.1501e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.7878e-05 - val_loss: 3.1500e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.7881e-05 - val_loss: 3.1501e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.7884e-05 - val_loss: 3.1510e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.7895e-05 - val_loss: 3.1606e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.7909e-05 - val_loss: 3.1504e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.7902e-05 - val_loss: 3.1505e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.7873e-05 - val_loss: 3.1496e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.7871e-05 - val_loss: 3.1520e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.7885e-05 - val_loss: 3.1498e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.7905e-05 - val_loss: 3.1518e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.7893e-05 - val_loss: 3.1544e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 5s 232us/step - loss: 0.0020 - val_loss: 1.7292e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 2.0778e-04 - val_loss: 1.7075e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 2.0637e-04 - val_loss: 1.7048e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 2.0566e-04 - val_loss: 1.6863e-04\n",
      "Epoch 5/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.0455e-04 - val_loss: 1.6673e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 2.0389e-04 - val_loss: 1.6508e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 2.0255e-04 - val_loss: 1.6462e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 2.0284e-04 - val_loss: 1.6226e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 2.0093e-04 - val_loss: 1.6185e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 2.0015e-04 - val_loss: 1.5959e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.9892e-04 - val_loss: 1.5874e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.9828e-04 - val_loss: 1.5876e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.9724e-04 - val_loss: 1.5554e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.9644e-04 - val_loss: 1.5452e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.9558e-04 - val_loss: 1.5611e-04\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.9555e-04 - val_loss: 1.5200e-04\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.9446e-04 - val_loss: 1.5091e-04\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.9337e-04 - val_loss: 1.5031e-04\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.9262e-04 - val_loss: 1.4881e-04\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.9234e-04 - val_loss: 1.4762e-04\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.9128e-04 - val_loss: 1.4809e-04\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.9072e-04 - val_loss: 1.4542e-04\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.8983e-04 - val_loss: 1.4438e-04\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 15us/step - loss: 1.8985e-04 - val_loss: 1.4503e-04\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 5s 237us/step - loss: 0.1041 - val_loss: 9.7113e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 5.2567e-04 - val_loss: 8.2292e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.2318e-04 - val_loss: 5.1395e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.1323e-04 - val_loss: 4.8038e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.0876e-04 - val_loss: 4.6125e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.0577e-04 - val_loss: 4.4948e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.0362e-04 - val_loss: 4.4006e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.0198e-04 - val_loss: 4.3394e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.0076e-04 - val_loss: 4.2694e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.9827e-05 - val_loss: 4.2093e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 9.8966e-05 - val_loss: 4.1606e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 9.8230e-05 - val_loss: 4.1070e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 9.7615e-05 - val_loss: 4.0811e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 9.7088e-05 - val_loss: 4.0199e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 9.6606e-05 - val_loss: 3.9808e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 9.6141e-05 - val_loss: 3.9352e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 9.5751e-05 - val_loss: 3.8999e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 9.5465e-05 - val_loss: 3.8678e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 9.5022e-05 - val_loss: 3.8365e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 9.4793e-05 - val_loss: 3.7984e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 9.4403e-05 - val_loss: 3.7785e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 9.4184e-05 - val_loss: 3.7439e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 9.3908e-05 - val_loss: 3.7405e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 9.3741e-05 - val_loss: 3.6984e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 5s 239us/step - loss: 0.0893 - val_loss: 0.0013\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 4.1781e-04 - val_loss: 6.2274e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.0997e-04 - val_loss: 4.6299e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.0349e-04 - val_loss: 4.5251e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.0279e-04 - val_loss: 4.4703e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.0220e-04 - val_loss: 4.4252e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.0176e-04 - val_loss: 4.3791e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.0108e-04 - val_loss: 4.3861e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.0065e-04 - val_loss: 4.3065e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.0009e-04 - val_loss: 4.3169e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 9.9693e-05 - val_loss: 4.2338e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 9.9307e-05 - val_loss: 4.2019e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 9.8838e-05 - val_loss: 4.1729e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 9.8722e-05 - val_loss: 4.1594e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 9.8256e-05 - val_loss: 4.1406e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 9.7931e-05 - val_loss: 4.0754e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 9.7541e-05 - val_loss: 4.0476e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 9.7257e-05 - val_loss: 4.0243e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 9.7098e-05 - val_loss: 3.9974e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 9.6743e-05 - val_loss: 3.9711e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 9.6540e-05 - val_loss: 3.9629e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 9.6218e-05 - val_loss: 3.9393e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 9.6127e-05 - val_loss: 3.9542e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 9.5968e-05 - val_loss: 3.8981e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 5s 243us/step - loss: 0.0487 - val_loss: 0.0012\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 2.3822e-04 - val_loss: 4.7316e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 9.3952e-05 - val_loss: 3.5860e-05\n",
      "Epoch 4/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 16us/step - loss: 9.1856e-05 - val_loss: 3.5517e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 9.1592e-05 - val_loss: 3.5310e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 9.1351e-05 - val_loss: 3.5032e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 9.1184e-05 - val_loss: 3.4881e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 9.0963e-05 - val_loss: 3.4721e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 9.0830e-05 - val_loss: 3.4796e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 9.0755e-05 - val_loss: 3.4500e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 9.0559e-05 - val_loss: 3.4422e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 9.0571e-05 - val_loss: 3.4432e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 9.0508e-05 - val_loss: 3.4303e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 9.0428e-05 - val_loss: 3.4260e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 9.0355e-05 - val_loss: 3.4133e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 9.0272e-05 - val_loss: 3.4075e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 9.0180e-05 - val_loss: 3.4077e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 9.0146e-05 - val_loss: 3.4040e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 9.0095e-05 - val_loss: 3.4184e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 9.0134e-05 - val_loss: 3.3870e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 9.0046e-05 - val_loss: 3.3817e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.9996e-05 - val_loss: 3.3773e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.9955e-05 - val_loss: 3.3724e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.9896e-05 - val_loss: 3.3720e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 5s 246us/step - loss: 0.5383 - val_loss: 0.0138\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0023 - val_loss: 3.4122e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 3.3711e-04 - val_loss: 2.3414e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 2.7718e-04 - val_loss: 2.1380e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 2.5305e-04 - val_loss: 1.9680e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 2.3475e-04 - val_loss: 1.8072e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 2.2006e-04 - val_loss: 1.6945e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 2.0889e-04 - val_loss: 1.5852e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 2.0040e-04 - val_loss: 1.5020e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.9351e-04 - val_loss: 1.4266e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.8758e-04 - val_loss: 1.3771e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.8343e-04 - val_loss: 1.3120e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.7957e-04 - val_loss: 1.2842e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.7688e-04 - val_loss: 1.2405e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.7329e-04 - val_loss: 1.2123e-04\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.7122e-04 - val_loss: 1.1702e-04\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.6877e-04 - val_loss: 1.1602e-04\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.6686e-04 - val_loss: 1.1275e-04\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.6498e-04 - val_loss: 1.1142e-04\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.6322e-04 - val_loss: 1.0903e-04\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 1.6143e-04 - val_loss: 1.0810e-04\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.6010e-04 - val_loss: 1.0557e-04\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.5824e-04 - val_loss: 1.0542e-04\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.5689e-04 - val_loss: 1.0376e-04\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 6s 258us/step - loss: 0.1793 - val_loss: 0.0012\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.4365e-04 - val_loss: 1.7170e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 2.0667e-04 - val_loss: 1.1422e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 1.7924e-04 - val_loss: 1.0179e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.6628e-04 - val_loss: 9.3203e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.5708e-04 - val_loss: 8.7081e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.5015e-04 - val_loss: 8.3153e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.4468e-04 - val_loss: 7.9970e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.3997e-04 - val_loss: 7.7362e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.3617e-04 - val_loss: 7.4926e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.3281e-04 - val_loss: 7.3077e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.2968e-04 - val_loss: 7.0943e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.2717e-04 - val_loss: 6.9266e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.2485e-04 - val_loss: 6.8104e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.2284e-04 - val_loss: 6.6639e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.2109e-04 - val_loss: 6.5251e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.1952e-04 - val_loss: 6.4546e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.1830e-04 - val_loss: 6.3422e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.1695e-04 - val_loss: 6.2646e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.1603e-04 - val_loss: 6.1955e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.1497e-04 - val_loss: 6.2024e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.1412e-04 - val_loss: 6.0875e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.1347e-04 - val_loss: 6.0159e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.1272e-04 - val_loss: 5.9650e-05\n",
      "\n",
      "GENERATION 16\n",
      "\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 5s 252us/step - loss: 0.1533 - val_loss: 0.0114\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0173 - val_loss: 5.9895e-04\n",
      "Epoch 3/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0150 - val_loss: 8.9253e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0134 - val_loss: 9.3549e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0119 - val_loss: 6.9061e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0113 - val_loss: 6.7502e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0098 - val_loss: 5.8369e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0090 - val_loss: 5.5000e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0083 - val_loss: 5.2073e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0076 - val_loss: 4.5663e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0072 - val_loss: 4.3767e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0064 - val_loss: 4.1359e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0059 - val_loss: 3.8288e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0056 - val_loss: 3.7085e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0051 - val_loss: 3.3793e-04\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0048 - val_loss: 3.2132e-04\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 0.0044 - val_loss: 3.1205e-04\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0040 - val_loss: 3.1592e-04\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0037 - val_loss: 2.3751e-04\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0033 - val_loss: 2.0546e-04\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0031 - val_loss: 2.3369e-04\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0029 - val_loss: 1.9412e-04\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0026 - val_loss: 1.5807e-04\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 0.0023 - val_loss: 1.5123e-04\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 5s 252us/step - loss: 0.0073 - val_loss: 3.2191e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 1.3524e-04 - val_loss: 3.2618e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.8143e-05 - val_loss: 3.1656e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.7879e-05 - val_loss: 3.1522e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7860e-05 - val_loss: 3.1477e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.7837e-05 - val_loss: 3.1462e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.7836e-05 - val_loss: 3.1479e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7863e-05 - val_loss: 3.1463e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7866e-05 - val_loss: 3.1458e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7889e-05 - val_loss: 3.1453e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7842e-05 - val_loss: 3.1467e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7862e-05 - val_loss: 3.1489e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.7869e-05 - val_loss: 3.1463e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7833e-05 - val_loss: 3.1456e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7871e-05 - val_loss: 3.1480e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7865e-05 - val_loss: 3.1505e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7904e-05 - val_loss: 3.1498e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7842e-05 - val_loss: 3.1564e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.7935e-05 - val_loss: 3.1566e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.7924e-05 - val_loss: 3.1456e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.7883e-05 - val_loss: 3.1494e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7831e-05 - val_loss: 3.1465e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.7909e-05 - val_loss: 3.1468e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7922e-05 - val_loss: 3.1454e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 5s 252us/step - loss: 0.0182 - val_loss: 4.1707e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.5300e-04 - val_loss: 3.7531e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.8697e-05 - val_loss: 3.1529e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7888e-05 - val_loss: 3.1526e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7873e-05 - val_loss: 3.1486e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7882e-05 - val_loss: 3.1484e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7883e-05 - val_loss: 3.1506e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7876e-05 - val_loss: 3.1490e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7867e-05 - val_loss: 3.1483e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7866e-05 - val_loss: 3.1495e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7865e-05 - val_loss: 3.1479e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7877e-05 - val_loss: 3.1566e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7896e-05 - val_loss: 3.1477e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7866e-05 - val_loss: 3.1507e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7881e-05 - val_loss: 3.1501e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7856e-05 - val_loss: 3.1512e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7870e-05 - val_loss: 3.1495e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7898e-05 - val_loss: 3.1508e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7843e-05 - val_loss: 3.1527e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7869e-05 - val_loss: 3.1493e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7847e-05 - val_loss: 3.1498e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7867e-05 - val_loss: 3.1472e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7852e-05 - val_loss: 3.1514e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7850e-05 - val_loss: 3.1469e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 5s 255us/step - loss: 0.0308 - val_loss: 0.0013\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 2.5156e-04 - val_loss: 4.2309e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 9.0499e-05 - val_loss: 3.1475e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7844e-05 - val_loss: 3.1511e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7847e-05 - val_loss: 3.1481e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7839e-05 - val_loss: 3.1521e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7840e-05 - val_loss: 3.1475e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7838e-05 - val_loss: 3.1473e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7834e-05 - val_loss: 3.1494e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7857e-05 - val_loss: 3.1484e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7846e-05 - val_loss: 3.1480e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7866e-05 - val_loss: 3.1506e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7836e-05 - val_loss: 3.1479e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7847e-05 - val_loss: 3.1471e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7867e-05 - val_loss: 3.1486e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7860e-05 - val_loss: 3.1471e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7880e-05 - val_loss: 3.1497e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7863e-05 - val_loss: 3.1470e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7828e-05 - val_loss: 3.1472e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7861e-05 - val_loss: 3.1636e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7861e-05 - val_loss: 3.1491e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7858e-05 - val_loss: 3.1484e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7886e-05 - val_loss: 3.1476e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7849e-05 - val_loss: 3.1566e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 5s 255us/step - loss: 0.0598 - val_loss: 0.0012\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 4.7164e-04 - val_loss: 4.5194e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 9.0077e-05 - val_loss: 3.1793e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7954e-05 - val_loss: 3.1503e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7863e-05 - val_loss: 3.1516e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7885e-05 - val_loss: 3.1485e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7870e-05 - val_loss: 3.1494e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7861e-05 - val_loss: 3.1488e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 16us/step - loss: 8.7886e-05 - val_loss: 3.1493e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7880e-05 - val_loss: 3.1502e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7888e-05 - val_loss: 3.1504e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7877e-05 - val_loss: 3.1495e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7872e-05 - val_loss: 3.1480e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7874e-05 - val_loss: 3.1487e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7919e-05 - val_loss: 3.1489e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7858e-05 - val_loss: 3.1508e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7889e-05 - val_loss: 3.1484e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7895e-05 - val_loss: 3.1484e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7874e-05 - val_loss: 3.1486e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7876e-05 - val_loss: 3.1606e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7886e-05 - val_loss: 3.1493e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7893e-05 - val_loss: 3.1485e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 8.7859e-05 - val_loss: 3.1474e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7873e-05 - val_loss: 3.1571e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 6s 272us/step - loss: 0.0051 - val_loss: 3.3808e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.8395e-04 - val_loss: 3.6432e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.2928e-04 - val_loss: 3.1770e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.1480e-04 - val_loss: 3.1556e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.0617e-04 - val_loss: 3.1460e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.0219e-04 - val_loss: 3.1459e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 9.4495e-05 - val_loss: 3.1462e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.2687e-05 - val_loss: 3.1810e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.2094e-05 - val_loss: 3.1445e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.0070e-05 - val_loss: 3.1515e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.0109e-05 - val_loss: 3.1513e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.9464e-05 - val_loss: 3.1476e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.9863e-05 - val_loss: 3.1564e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.9531e-05 - val_loss: 3.1532e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.9476e-05 - val_loss: 3.1513e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.9671e-05 - val_loss: 3.1471e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.9373e-05 - val_loss: 3.1572e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.8398e-05 - val_loss: 3.1522e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.8490e-05 - val_loss: 3.1479e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.8607e-05 - val_loss: 3.1461e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.8750e-05 - val_loss: 3.1460e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.8433e-05 - val_loss: 3.1464e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8256e-05 - val_loss: 3.1474e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.8491e-05 - val_loss: 3.1456e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 6s 270us/step - loss: 0.0151 - val_loss: 2.8157e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0010 - val_loss: 1.9082e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 6.8394e-04 - val_loss: 1.7811e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 5.1569e-04 - val_loss: 1.5941e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 4.1426e-04 - val_loss: 1.5542e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 3.4934e-04 - val_loss: 1.3629e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 3.0115e-04 - val_loss: 1.2545e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 2.7164e-04 - val_loss: 1.0912e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 2.4182e-04 - val_loss: 9.3077e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 2.2170e-04 - val_loss: 8.8966e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 2.0223e-04 - val_loss: 8.4133e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.9157e-04 - val_loss: 7.6050e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.7434e-04 - val_loss: 7.1992e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.6803e-04 - val_loss: 7.1239e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.5983e-04 - val_loss: 6.6564e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.5107e-04 - val_loss: 6.4413e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.4387e-04 - val_loss: 6.1967e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 1.4002e-04 - val_loss: 5.8195e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.3600e-04 - val_loss: 5.8990e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.3089e-04 - val_loss: 5.7688e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.2855e-04 - val_loss: 5.5345e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.2375e-04 - val_loss: 5.2955e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.2324e-04 - val_loss: 5.4168e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 17us/step - loss: 1.2344e-04 - val_loss: 5.3270e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 7s 303us/step - loss: 0.0118 - val_loss: 1.6317e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 9.1403e-04 - val_loss: 5.0377e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.7860e-04 - val_loss: 3.5285e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 2.7933e-04 - val_loss: 3.2396e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 2.2567e-04 - val_loss: 3.1855e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.8936e-04 - val_loss: 3.1512e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 1.6688e-04 - val_loss: 3.1477e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 1.4775e-04 - val_loss: 3.1476e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 1.3975e-04 - val_loss: 3.1579e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 1.3590e-04 - val_loss: 3.1571e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.2694e-04 - val_loss: 3.1545e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.2654e-04 - val_loss: 3.1505e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.2054e-04 - val_loss: 3.1528e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.1539e-04 - val_loss: 3.1456e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 1.1747e-04 - val_loss: 3.1486e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 1.1344e-04 - val_loss: 3.1464e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.1247e-04 - val_loss: 3.1474e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.0956e-04 - val_loss: 3.1464e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 1.1175e-04 - val_loss: 3.1456e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 1.0580e-04 - val_loss: 3.1454e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 1.0496e-04 - val_loss: 3.1455e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.0998e-04 - val_loss: 3.1455e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 1.0730e-04 - val_loss: 3.1452e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.0545e-04 - val_loss: 3.1453e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 6s 279us/step - loss: 0.0048 - val_loss: 3.2068e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.8252e-04 - val_loss: 3.5084e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.3956e-05 - val_loss: 3.1714e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.9100e-05 - val_loss: 3.1528e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.8383e-05 - val_loss: 3.1667e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.8211e-05 - val_loss: 3.1627e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8201e-05 - val_loss: 3.2123e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.8332e-05 - val_loss: 3.1456e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8380e-05 - val_loss: 3.1493e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.8141e-05 - val_loss: 3.1561e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.8174e-05 - val_loss: 3.1812e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.8029e-05 - val_loss: 3.1489e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.8222e-05 - val_loss: 3.1532e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.8196e-05 - val_loss: 3.1848e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.8124e-05 - val_loss: 3.1551e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8193e-05 - val_loss: 3.1846e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8041e-05 - val_loss: 3.1752e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8177e-05 - val_loss: 3.1520e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.8139e-05 - val_loss: 3.1840e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8306e-05 - val_loss: 3.1548e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.8090e-05 - val_loss: 3.1577e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8265e-05 - val_loss: 3.1554e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8165e-05 - val_loss: 3.1486e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.8213e-05 - val_loss: 3.1523e-05\n",
      "\n",
      "GENERATION 17\n",
      "\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 6s 291us/step - loss: 7.2965e-04 - val_loss: 3.9497e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 6.8785e-04 - val_loss: 3.7054e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 6.3460e-04 - val_loss: 1.2094e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 1.0359e-04 - val_loss: 9.7595e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 6.0888e-04 - val_loss: 3.7332e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 1.4034e-04 - val_loss: 4.5225e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 4.7518e-04 - val_loss: 3.4196e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 1.5118e-04 - val_loss: 3.9594e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 5.2754e-04 - val_loss: 4.7853e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 1.0022e-04 - val_loss: 4.2368e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 2.0620e-04 - val_loss: 8.0989e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 4.8201e-04 - val_loss: 4.7624e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 9.4898e-05 - val_loss: 3.1454e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 1.2319e-04 - val_loss: 3.1184e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 5.4883e-04 - val_loss: 3.3403e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 9.7425e-05 - val_loss: 3.6686e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 1.0068e-04 - val_loss: 5.0413e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 4.3958e-04 - val_loss: 3.7388e-04\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 1.5531e-04 - val_loss: 4.2348e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 1.0014e-04 - val_loss: 1.3610e-04\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 1.1046e-04 - val_loss: 3.4443e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 3.9385e-04 - val_loss: 7.7153e-04\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 2.2914e-04 - val_loss: 4.4105e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 1.0741e-04 - val_loss: 4.0227e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 6s 285us/step - loss: 9.4646e-04 - val_loss: 6.7353e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.3734e-05 - val_loss: 3.2103e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7921e-05 - val_loss: 3.1611e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7844e-05 - val_loss: 3.1639e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7865e-05 - val_loss: 3.1458e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7920e-05 - val_loss: 3.1698e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7911e-05 - val_loss: 3.1462e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7881e-05 - val_loss: 3.1464e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7907e-05 - val_loss: 3.1641e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7842e-05 - val_loss: 3.1875e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7942e-05 - val_loss: 3.1463e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7916e-05 - val_loss: 3.1462e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7838e-05 - val_loss: 3.1954e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.7958e-05 - val_loss: 3.1458e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.7930e-05 - val_loss: 3.1473e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7858e-05 - val_loss: 3.1460e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7994e-05 - val_loss: 3.1892e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7981e-05 - val_loss: 3.1579e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.8027e-05 - val_loss: 3.1623e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7992e-05 - val_loss: 3.1491e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7949e-05 - val_loss: 3.1456e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7853e-05 - val_loss: 3.1551e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7891e-05 - val_loss: 3.1601e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7931e-05 - val_loss: 3.1456e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 6s 302us/step - loss: 0.0106 - val_loss: 7.0326e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.2574e-04 - val_loss: 3.2175e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8244e-05 - val_loss: 3.1471e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.7831e-05 - val_loss: 3.1459e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7804e-05 - val_loss: 3.1533e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7856e-05 - val_loss: 3.1465e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7841e-05 - val_loss: 3.1469e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.7847e-05 - val_loss: 3.1470e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7849e-05 - val_loss: 3.1514e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7831e-05 - val_loss: 3.1479e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7825e-05 - val_loss: 3.1495e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.7848e-05 - val_loss: 3.1490e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7843e-05 - val_loss: 3.1469e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7860e-05 - val_loss: 3.1459e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7830e-05 - val_loss: 3.1462e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7854e-05 - val_loss: 3.1586e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7866e-05 - val_loss: 3.1462e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7831e-05 - val_loss: 3.1458e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.7842e-05 - val_loss: 3.1466e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7850e-05 - val_loss: 3.1457e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7855e-05 - val_loss: 3.1550e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7909e-05 - val_loss: 3.1458e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7829e-05 - val_loss: 3.1640e-05\n",
      "Epoch 24/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7915e-05 - val_loss: 3.1509e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 6s 285us/step - loss: 0.1330 - val_loss: 1.8023e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 5.8896e-04 - val_loss: 8.5605e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.1301e-04 - val_loss: 4.2846e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.0298e-04 - val_loss: 4.2422e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.0216e-04 - val_loss: 4.2208e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.0156e-04 - val_loss: 4.2091e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.0109e-04 - val_loss: 4.2027e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.0066e-04 - val_loss: 4.1952e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 1.0031e-04 - val_loss: 4.1845e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.9987e-05 - val_loss: 4.1654e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.9699e-05 - val_loss: 4.1561e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.9459e-05 - val_loss: 4.1419e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.9337e-05 - val_loss: 4.1666e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.9016e-05 - val_loss: 4.1542e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.8771e-05 - val_loss: 4.0904e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.8584e-05 - val_loss: 4.0776e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 9.8465e-05 - val_loss: 4.0605e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 9.8153e-05 - val_loss: 4.0458e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.8106e-05 - val_loss: 4.0910e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.7916e-05 - val_loss: 4.0230e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.7618e-05 - val_loss: 4.0166e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.7598e-05 - val_loss: 3.9930e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.7286e-05 - val_loss: 3.9876e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.7314e-05 - val_loss: 3.9588e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 6s 298us/step - loss: 0.0309 - val_loss: 1.1628e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 2.7961e-04 - val_loss: 7.9568e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.1875e-04 - val_loss: 5.6961e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.1391e-04 - val_loss: 5.5498e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.1276e-04 - val_loss: 5.4510e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.1175e-04 - val_loss: 5.3675e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.1098e-04 - val_loss: 5.3305e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.1034e-04 - val_loss: 5.2462e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.0969e-04 - val_loss: 5.1912e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.0911e-04 - val_loss: 5.2329e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.0857e-04 - val_loss: 5.1041e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.0809e-04 - val_loss: 5.0668e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.0767e-04 - val_loss: 5.0214e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.0737e-04 - val_loss: 4.9962e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.0703e-04 - val_loss: 5.0057e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.0643e-04 - val_loss: 4.9208e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.0634e-04 - val_loss: 4.9188e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.0603e-04 - val_loss: 4.8480e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.0557e-04 - val_loss: 4.8604e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.0548e-04 - val_loss: 4.8092e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.0503e-04 - val_loss: 4.7946e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.0486e-04 - val_loss: 4.7621e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.0462e-04 - val_loss: 4.7121e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.0414e-04 - val_loss: 4.6969e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 6s 290us/step - loss: 0.1498 - val_loss: 0.0036\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 6.5063e-04 - val_loss: 3.4504e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.5247e-05 - val_loss: 3.4361e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.0474e-05 - val_loss: 3.4242e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.0304e-05 - val_loss: 3.4198e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.0251e-05 - val_loss: 3.4161e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0208e-05 - val_loss: 3.4133e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0219e-05 - val_loss: 3.4136e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 9.0255e-05 - val_loss: 3.4080e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.0121e-05 - val_loss: 3.4058e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.0137e-05 - val_loss: 3.4026e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.0060e-05 - val_loss: 3.3992e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.0065e-05 - val_loss: 3.3993e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.0011e-05 - val_loss: 3.3937e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.9970e-05 - val_loss: 3.3911e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.9951e-05 - val_loss: 3.3889e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.9904e-05 - val_loss: 3.3856e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.9903e-05 - val_loss: 3.4013e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.9977e-05 - val_loss: 3.4082e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.9923e-05 - val_loss: 3.3770e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.9821e-05 - val_loss: 3.3744e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9786e-05 - val_loss: 3.3813e-05\n",
      "Epoch 23/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.9731e-05 - val_loss: 3.3745e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.9866e-05 - val_loss: 3.3680e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 6s 302us/step - loss: 0.2416 - val_loss: 0.0015\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 6.0897e-04 - val_loss: 7.4753e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.8575e-05 - val_loss: 3.5755e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.2629e-05 - val_loss: 3.5681e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.2063e-05 - val_loss: 3.5635e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.1876e-05 - val_loss: 3.5601e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.1779e-05 - val_loss: 3.5556e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.1690e-05 - val_loss: 3.5491e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.1668e-05 - val_loss: 3.5492e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.1647e-05 - val_loss: 3.5415e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.1565e-05 - val_loss: 3.5333e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 9.1530e-05 - val_loss: 3.5282e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 9.1515e-05 - val_loss: 3.5415e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 9.1532e-05 - val_loss: 3.5178e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.1388e-05 - val_loss: 3.5134e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.1324e-05 - val_loss: 3.5130e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.1329e-05 - val_loss: 3.5035e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.1246e-05 - val_loss: 3.4978e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.1246e-05 - val_loss: 3.4923e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 9.1185e-05 - val_loss: 3.4913e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.1150e-05 - val_loss: 3.4839e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 9.1057e-05 - val_loss: 3.4996e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.1092e-05 - val_loss: 3.4830e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 9.1008e-05 - val_loss: 3.4680e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 6s 297us/step - loss: 0.2012 - val_loss: 4.6283e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 9.6416e-05 - val_loss: 3.7091e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.3099e-05 - val_loss: 3.5858e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.2055e-05 - val_loss: 3.5272e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.1693e-05 - val_loss: 3.5427e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.1683e-05 - val_loss: 3.6860e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.0993e-05 - val_loss: 3.4532e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.0628e-05 - val_loss: 3.4453e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.0746e-05 - val_loss: 3.4826e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.0496e-05 - val_loss: 3.4239e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.0502e-05 - val_loss: 3.4840e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.0240e-05 - val_loss: 3.4101e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.0005e-05 - val_loss: 3.4123e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.0128e-05 - val_loss: 3.4052e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.0064e-05 - val_loss: 3.3917e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.0049e-05 - val_loss: 3.3904e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.0366e-05 - val_loss: 3.4453e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.9790e-05 - val_loss: 3.3775e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.0008e-05 - val_loss: 3.3739e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.9718e-05 - val_loss: 3.3860e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.9907e-05 - val_loss: 3.3701e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.9819e-05 - val_loss: 3.4110e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.9724e-05 - val_loss: 3.3676e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.9783e-05 - val_loss: 3.3743e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 7s 307us/step - loss: 0.1266 - val_loss: 0.0017\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0063 - val_loss: 0.0012\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0046 - val_loss: 8.9525e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0037 - val_loss: 7.4316e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0031 - val_loss: 7.1482e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0027 - val_loss: 5.4018e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0023 - val_loss: 4.1621e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0021 - val_loss: 3.9140e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0020 - val_loss: 3.5861e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0018 - val_loss: 3.1857e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0016 - val_loss: 2.6558e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0015 - val_loss: 2.3248e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0015 - val_loss: 2.1273e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0014 - val_loss: 1.9510e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0013 - val_loss: 2.0103e-04\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0012 - val_loss: 1.6039e-04\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0012 - val_loss: 1.3754e-04\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0011 - val_loss: 1.3725e-04\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 0.0011 - val_loss: 1.3500e-04\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 9.9580e-04 - val_loss: 1.1989e-04\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.6932e-04 - val_loss: 1.1160e-04\n",
      "Epoch 22/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 19us/step - loss: 9.3503e-04 - val_loss: 9.5174e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 9.1704e-04 - val_loss: 1.0337e-04\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.7416e-04 - val_loss: 1.0796e-04\n",
      "\n",
      "GENERATION 18\n",
      "\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 6s 302us/step - loss: 0.0068 - val_loss: 2.9393e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.3359e-04 - val_loss: 3.3701e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.8103e-05 - val_loss: 3.1524e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7877e-05 - val_loss: 3.1478e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7870e-05 - val_loss: 3.1513e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7860e-05 - val_loss: 3.1471e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7897e-05 - val_loss: 3.1471e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.7883e-05 - val_loss: 3.1473e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7921e-05 - val_loss: 3.1505e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7858e-05 - val_loss: 3.1553e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7846e-05 - val_loss: 3.1468e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7837e-05 - val_loss: 3.1539e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.7851e-05 - val_loss: 3.1469e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.7890e-05 - val_loss: 3.1501e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.7887e-05 - val_loss: 3.1516e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.7867e-05 - val_loss: 3.1469e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.7912e-05 - val_loss: 3.1552e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.7857e-05 - val_loss: 3.1468e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.7895e-05 - val_loss: 3.1533e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7859e-05 - val_loss: 3.1595e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7862e-05 - val_loss: 3.1513e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7860e-05 - val_loss: 3.1699e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7935e-05 - val_loss: 3.1515e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7861e-05 - val_loss: 3.1547e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 7s 307us/step - loss: 0.0286 - val_loss: 0.0011\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 2.2364e-04 - val_loss: 4.5829e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 9.0459e-05 - val_loss: 3.1584e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7924e-05 - val_loss: 3.1494e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.7877e-05 - val_loss: 3.1507e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7892e-05 - val_loss: 3.1504e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.7887e-05 - val_loss: 3.1526e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.7888e-05 - val_loss: 3.1494e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.7883e-05 - val_loss: 3.1493e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.7873e-05 - val_loss: 3.1490e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.7869e-05 - val_loss: 3.1507e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.7885e-05 - val_loss: 3.1492e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.7900e-05 - val_loss: 3.1489e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.7881e-05 - val_loss: 3.1521e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.7893e-05 - val_loss: 3.1564e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7892e-05 - val_loss: 3.1537e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.7896e-05 - val_loss: 3.1492e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7877e-05 - val_loss: 3.1507e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.7867e-05 - val_loss: 3.1575e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7890e-05 - val_loss: 3.1484e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.7880e-05 - val_loss: 3.1496e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.7871e-05 - val_loss: 3.1569e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7883e-05 - val_loss: 3.1481e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.7889e-05 - val_loss: 3.1485e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 7s 313us/step - loss: 0.1396 - val_loss: 0.0041\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0162 - val_loss: 7.2070e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0149 - val_loss: 4.8912e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0141 - val_loss: 5.6420e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0135 - val_loss: 6.1800e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0125 - val_loss: 4.7608e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0121 - val_loss: 5.0283e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0116 - val_loss: 5.3579e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0110 - val_loss: 5.3480e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0105 - val_loss: 5.2938e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0099 - val_loss: 5.2996e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0094 - val_loss: 5.2895e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0090 - val_loss: 5.2721e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0085 - val_loss: 4.8399e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0082 - val_loss: 4.6409e-04\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0078 - val_loss: 4.5518e-04\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0073 - val_loss: 4.1229e-04\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0069 - val_loss: 4.0885e-04\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0065 - val_loss: 4.1456e-04\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0061 - val_loss: 3.6522e-04\n",
      "Epoch 21/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0059 - val_loss: 4.0500e-04\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0056 - val_loss: 3.6125e-04\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0053 - val_loss: 3.2708e-04\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0049 - val_loss: 3.5426e-04\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 7s 321us/step - loss: 0.1051 - val_loss: 9.8309e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0145 - val_loss: 5.2920e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0134 - val_loss: 3.0099e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0121 - val_loss: 3.1522e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0113 - val_loss: 3.1831e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0105 - val_loss: 3.9708e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0098 - val_loss: 2.9609e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0089 - val_loss: 3.1032e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0084 - val_loss: 3.1061e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0077 - val_loss: 2.6704e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0072 - val_loss: 1.9170e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0066 - val_loss: 1.8374e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0061 - val_loss: 2.4493e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0057 - val_loss: 2.1583e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0053 - val_loss: 1.5540e-04\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0048 - val_loss: 1.2841e-04\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0045 - val_loss: 1.7037e-04\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0042 - val_loss: 1.2822e-04\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0039 - val_loss: 1.4937e-04\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 1.2031e-04\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0034 - val_loss: 1.3429e-04\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0030 - val_loss: 1.2864e-04\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0029 - val_loss: 1.3280e-04\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0027 - val_loss: 1.3997e-04\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 7s 314us/step - loss: 0.1699 - val_loss: 3.6331e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0372 - val_loss: 8.9682e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0283 - val_loss: 0.0011\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0229 - val_loss: 9.6274e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0193 - val_loss: 0.0011\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0163 - val_loss: 0.0013\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0137 - val_loss: 0.0013\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0121 - val_loss: 0.0016\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0105 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0091 - val_loss: 0.0016\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0081 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0074 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0067 - val_loss: 0.0014\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 0.0060 - val_loss: 0.0013\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 0.0054 - val_loss: 0.0013\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0051 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0046 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0043 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0038 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0034 - val_loss: 9.7798e-04\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0031 - val_loss: 9.4626e-04\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0029 - val_loss: 9.2618e-04\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0027 - val_loss: 8.4560e-04\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 7s 330us/step - loss: 0.1183 - val_loss: 3.8352e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0272 - val_loss: 1.8336e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0181 - val_loss: 3.8247e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0141 - val_loss: 5.5517e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0116 - val_loss: 3.4716e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0100 - val_loss: 3.3471e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0087 - val_loss: 3.1553e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 3.5681e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0067 - val_loss: 5.4308e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0060 - val_loss: 3.8938e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0052 - val_loss: 3.4525e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0048 - val_loss: 3.4548e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0043 - val_loss: 3.8312e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0039 - val_loss: 3.6244e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 3.1790e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0032 - val_loss: 5.8343e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0030 - val_loss: 3.8133e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0027 - val_loss: 3.7597e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0025 - val_loss: 4.5290e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0024 - val_loss: 4.9768e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0022 - val_loss: 6.2233e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0020 - val_loss: 4.4511e-05\n",
      "Epoch 23/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0019 - val_loss: 6.0365e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0018 - val_loss: 7.0959e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 6s 303us/step - loss: 0.1404 - val_loss: 0.0025\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0337 - val_loss: 0.0050\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0229 - val_loss: 0.0025\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0174 - val_loss: 0.0014\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0141 - val_loss: 0.0012\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0120 - val_loss: 7.8091e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0102 - val_loss: 5.2599e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0087 - val_loss: 7.5526e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0077 - val_loss: 6.8838e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0068 - val_loss: 5.7198e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0061 - val_loss: 5.7625e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0054 - val_loss: 4.9833e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0050 - val_loss: 6.0741e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0045 - val_loss: 4.3502e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0041 - val_loss: 4.2940e-04\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0038 - val_loss: 2.9891e-04\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0034 - val_loss: 2.8995e-04\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0031 - val_loss: 3.6960e-04\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0029 - val_loss: 2.4830e-04\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0027 - val_loss: 2.0207e-04\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0025 - val_loss: 3.1261e-04\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0023 - val_loss: 1.6797e-04\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0021 - val_loss: 2.8179e-04\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0020 - val_loss: 2.1881e-04\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 7s 312us/step - loss: 0.0283 - val_loss: 0.0020\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0015\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0046 - val_loss: 9.8387e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0033 - val_loss: 4.1303e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0026 - val_loss: 5.8430e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0020 - val_loss: 3.3260e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0016 - val_loss: 2.0308e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0013 - val_loss: 1.8617e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0011 - val_loss: 1.4774e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.1755e-04 - val_loss: 1.2342e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 7.8083e-04 - val_loss: 1.1662e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 6.6133e-04 - val_loss: 9.8611e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 5.7138e-04 - val_loss: 8.1937e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.9916e-04 - val_loss: 6.7281e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 4.4151e-04 - val_loss: 5.8786e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 3.8102e-04 - val_loss: 5.2984e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 3.3942e-04 - val_loss: 4.6009e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 3.0622e-04 - val_loss: 4.7473e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 2.7782e-04 - val_loss: 4.3784e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 2.4287e-04 - val_loss: 4.1550e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 2.2659e-04 - val_loss: 3.9191e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.0961e-04 - val_loss: 3.9689e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 1.8777e-04 - val_loss: 3.9164e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.7376e-04 - val_loss: 3.9316e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 7s 312us/step - loss: 0.1015 - val_loss: 0.0017\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0181 - val_loss: 8.3164e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0135 - val_loss: 9.8241e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0113 - val_loss: 4.0163e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0096 - val_loss: 4.4604e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0083 - val_loss: 4.0798e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 4.6861e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0066 - val_loss: 3.7238e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0059 - val_loss: 7.6107e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0054 - val_loss: 6.5505e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0050 - val_loss: 1.0250e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0045 - val_loss: 1.0337e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0041 - val_loss: 7.5336e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0038 - val_loss: 7.7257e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0035 - val_loss: 9.8852e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0033 - val_loss: 1.0553e-04\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0030 - val_loss: 9.9139e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0028 - val_loss: 6.3345e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0026 - val_loss: 6.9021e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0024 - val_loss: 1.0839e-04\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0022 - val_loss: 1.0889e-04\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0021 - val_loss: 1.2271e-04\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0019 - val_loss: 1.0779e-04\n",
      "Epoch 24/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0018 - val_loss: 8.0978e-05\n",
      "\n",
      "GENERATION 19\n",
      "\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 7s 315us/step - loss: 6.2600e-04 - val_loss: 3.6474e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.1643e-05 - val_loss: 3.1586e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7951e-05 - val_loss: 3.2264e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.8125e-05 - val_loss: 3.1597e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.8039e-05 - val_loss: 3.1486e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7995e-05 - val_loss: 3.1470e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7955e-05 - val_loss: 3.2245e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.8004e-05 - val_loss: 3.1460e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7933e-05 - val_loss: 3.1493e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.8007e-05 - val_loss: 3.1491e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.8084e-05 - val_loss: 3.1570e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7897e-05 - val_loss: 3.1460e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.7873e-05 - val_loss: 3.1554e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.7850e-05 - val_loss: 3.2078e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7918e-05 - val_loss: 3.1599e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.8031e-05 - val_loss: 3.1468e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7959e-05 - val_loss: 3.1538e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.8053e-05 - val_loss: 3.1506e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7972e-05 - val_loss: 3.1521e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7934e-05 - val_loss: 3.1942e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.8546e-05 - val_loss: 3.2032e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.8000e-05 - val_loss: 3.1502e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.8087e-05 - val_loss: 3.1463e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.8762e-05 - val_loss: 3.1492e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 7s 313us/step - loss: 0.2274 - val_loss: 0.0070\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 0.0015 - val_loss: 7.9796e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.0446e-04 - val_loss: 3.1670e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.8017e-05 - val_loss: 3.1503e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7882e-05 - val_loss: 3.1509e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7880e-05 - val_loss: 3.1503e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7882e-05 - val_loss: 3.1502e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7887e-05 - val_loss: 3.1504e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7876e-05 - val_loss: 3.1502e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7900e-05 - val_loss: 3.1508e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7880e-05 - val_loss: 3.1505e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7881e-05 - val_loss: 3.1504e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7878e-05 - val_loss: 3.1501e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7879e-05 - val_loss: 3.1501e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7881e-05 - val_loss: 3.1502e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7887e-05 - val_loss: 3.1503e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7884e-05 - val_loss: 3.1507e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7893e-05 - val_loss: 3.1528e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7881e-05 - val_loss: 3.1503e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7871e-05 - val_loss: 3.1512e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7898e-05 - val_loss: 3.1501e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7889e-05 - val_loss: 3.1501e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7883e-05 - val_loss: 3.1500e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.7882e-05 - val_loss: 3.1502e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 7s 319us/step - loss: 0.0072 - val_loss: 2.5755e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 1.3928e-04 - val_loss: 3.5292e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.8124e-05 - val_loss: 3.1495e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.7896e-05 - val_loss: 3.1497e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.7875e-05 - val_loss: 3.1489e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.7905e-05 - val_loss: 3.1519e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.7866e-05 - val_loss: 3.1503e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.7874e-05 - val_loss: 3.1484e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.7874e-05 - val_loss: 3.1478e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.7879e-05 - val_loss: 3.1557e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.7913e-05 - val_loss: 3.1481e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.7908e-05 - val_loss: 3.1475e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.7858e-05 - val_loss: 3.1473e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.7879e-05 - val_loss: 3.1498e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.7884e-05 - val_loss: 3.1481e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.7878e-05 - val_loss: 3.1558e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.7848e-05 - val_loss: 3.1633e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.7872e-05 - val_loss: 3.1466e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.7863e-05 - val_loss: 3.1560e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.7890e-05 - val_loss: 3.1471e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.7852e-05 - val_loss: 3.1577e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.7870e-05 - val_loss: 3.1584e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.7895e-05 - val_loss: 3.1463e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.7844e-05 - val_loss: 3.1485e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 7s 335us/step - loss: 0.0016 - val_loss: 1.0700e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 4.6144e-04 - val_loss: 3.6435e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 4.7168e-04 - val_loss: 4.2993e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 4.4858e-04 - val_loss: 4.3525e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 4.3694e-04 - val_loss: 3.3619e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 4.1490e-04 - val_loss: 3.1607e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 4.1546e-04 - val_loss: 3.7422e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 3.9568e-04 - val_loss: 2.8096e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.9006e-04 - val_loss: 1.7540e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.7419e-04 - val_loss: 3.0757e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.7564e-04 - val_loss: 4.0298e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 3.5965e-04 - val_loss: 2.2902e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 3.4713e-04 - val_loss: 2.4248e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 3.5066e-04 - val_loss: 3.3469e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 3.3974e-04 - val_loss: 3.1044e-04\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 3.4000e-04 - val_loss: 2.8230e-04\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 3.2045e-04 - val_loss: 3.1875e-04\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 3.1658e-04 - val_loss: 3.4532e-04\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 3.1985e-04 - val_loss: 2.6147e-04\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 3.0944e-04 - val_loss: 3.3608e-04\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 2.9449e-04 - val_loss: 2.2290e-04\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 2.9931e-04 - val_loss: 1.9744e-04\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 2.9016e-04 - val_loss: 2.2751e-04\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 2.9051e-04 - val_loss: 2.5400e-04\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 7s 349us/step - loss: 0.1205 - val_loss: 5.8747e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0103 - val_loss: 6.6225e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0049 - val_loss: 8.5607e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0020 - val_loss: 5.4710e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 9.6105e-04 - val_loss: 1.0601e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 5.7908e-04 - val_loss: 1.1429e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 4.1270e-04 - val_loss: 8.8238e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 3.3541e-04 - val_loss: 9.9687e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 2.9189e-04 - val_loss: 1.2081e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 2.7470e-04 - val_loss: 1.9505e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 2.6771e-04 - val_loss: 1.5729e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 2.5835e-04 - val_loss: 9.5210e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 2.4171e-04 - val_loss: 1.0986e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 2.3485e-04 - val_loss: 4.6610e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 2.3263e-04 - val_loss: 6.4360e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 2.2352e-04 - val_loss: 1.0997e-04\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 2.2255e-04 - val_loss: 9.7206e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.1617e-04 - val_loss: 3.6659e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 2.0993e-04 - val_loss: 7.2972e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 2.1285e-04 - val_loss: 6.8320e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 2.1009e-04 - val_loss: 4.5801e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 2.0217e-04 - val_loss: 5.0431e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 2.0266e-04 - val_loss: 7.2524e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 1.9275e-04 - val_loss: 7.2957e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 7s 345us/step - loss: 0.1294 - val_loss: 0.0087\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0114 - val_loss: 8.2467e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0093 - val_loss: 2.1731e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0084 - val_loss: 2.8383e-04\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0073 - val_loss: 2.4897e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0064 - val_loss: 1.7512e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0056 - val_loss: 1.9821e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0050 - val_loss: 1.7896e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0044 - val_loss: 1.3435e-04\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0040 - val_loss: 1.4563e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0035 - val_loss: 1.4699e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0031 - val_loss: 1.4577e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0027 - val_loss: 1.3672e-04\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0024 - val_loss: 1.3873e-04\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0022 - val_loss: 1.0508e-04\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0020 - val_loss: 1.1206e-04\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0017 - val_loss: 9.7754e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0015 - val_loss: 9.3691e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0014 - val_loss: 9.8035e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0013 - val_loss: 1.1261e-04\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0011 - val_loss: 9.0478e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0011 - val_loss: 7.8215e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 9.5596e-04 - val_loss: 7.3371e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.7418e-04 - val_loss: 8.0916e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 8s 351us/step - loss: 0.0179 - val_loss: 1.7698e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0063 - val_loss: 1.3025e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 0.0037 - val_loss: 9.4171e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 0.0022 - val_loss: 6.8667e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 0.0015 - val_loss: 4.8180e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0011 - val_loss: 4.9264e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 7.8681e-04 - val_loss: 4.9155e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 6.3207e-04 - val_loss: 4.3890e-05\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 5.5313e-04 - val_loss: 4.1726e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.6710e-04 - val_loss: 4.9657e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.1164e-04 - val_loss: 3.8178e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.6558e-04 - val_loss: 4.2405e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.3950e-04 - val_loss: 3.8290e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.2001e-04 - val_loss: 4.1585e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.9409e-04 - val_loss: 3.7807e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 2.7482e-04 - val_loss: 4.2070e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.5734e-04 - val_loss: 3.6724e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.5003e-04 - val_loss: 3.5430e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.3437e-04 - val_loss: 3.6775e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 2.2740e-04 - val_loss: 3.6450e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.1537e-04 - val_loss: 3.5018e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 2.0834e-04 - val_loss: 3.5241e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.0385e-04 - val_loss: 3.5926e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.9807e-04 - val_loss: 3.4569e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 8s 350us/step - loss: 0.0100 - val_loss: 8.0754e-05\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 0.0023 - val_loss: 3.2492e-05\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.1379e-04 - val_loss: 4.7115e-05\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 4.1142e-04 - val_loss: 3.6175e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 3.0578e-04 - val_loss: 6.0852e-05\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.3593e-04 - val_loss: 3.5936e-04\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.8443e-04 - val_loss: 4.1142e-05\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 2.0057e-04 - val_loss: 1.3239e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.1827e-04 - val_loss: 4.6530e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.3571e-04 - val_loss: 4.6427e-05\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.9676e-04 - val_loss: 3.8276e-04\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.0060e-04 - val_loss: 4.7513e-05\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.3785e-04 - val_loss: 7.8687e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 1.2378e-04 - val_loss: 7.4357e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 1.5858e-04 - val_loss: 3.7063e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.1463e-04 - val_loss: 6.7124e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.3627e-04 - val_loss: 3.2994e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.0478e-04 - val_loss: 3.8707e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.3446e-04 - val_loss: 1.7732e-04\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.4522e-04 - val_loss: 3.1593e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.7101e-05 - val_loss: 5.7672e-05\n",
      "Epoch 22/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.4958e-04 - val_loss: 4.3651e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.3681e-04 - val_loss: 3.7366e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.0000e-04 - val_loss: 3.4233e-05\n",
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/24\n",
      "21471/21471 [==============================] - 8s 364us/step - loss: 0.0852 - val_loss: 5.4271e-04\n",
      "Epoch 2/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0106 - val_loss: 2.2981e-04\n",
      "Epoch 3/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0048 - val_loss: 6.4568e-04\n",
      "Epoch 4/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0025 - val_loss: 4.3143e-05\n",
      "Epoch 5/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 0.0018 - val_loss: 6.5760e-04\n",
      "Epoch 6/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.9390e-04 - val_loss: 6.6757e-05\n",
      "Epoch 7/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.3849e-04 - val_loss: 3.9455e-04\n",
      "Epoch 8/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 6.4857e-04 - val_loss: 6.9473e-04\n",
      "Epoch 9/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 5.7658e-04 - val_loss: 9.4101e-05\n",
      "Epoch 10/24\n",
      "21471/21471 [==============================] - 0s 23us/step - loss: 3.3127e-04 - val_loss: 2.1600e-04\n",
      "Epoch 11/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 5.7977e-04 - val_loss: 3.5116e-05\n",
      "Epoch 12/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 2.5778e-04 - val_loss: 1.2922e-04\n",
      "Epoch 13/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 4.0637e-04 - val_loss: 3.5096e-05\n",
      "Epoch 14/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.9861e-04 - val_loss: 3.4567e-05\n",
      "Epoch 15/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.8808e-04 - val_loss: 3.4363e-05\n",
      "Epoch 16/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.8075e-04 - val_loss: 3.8501e-05\n",
      "Epoch 17/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.9937e-04 - val_loss: 9.4203e-05\n",
      "Epoch 18/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.9917e-04 - val_loss: 7.1044e-05\n",
      "Epoch 19/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.0884e-04 - val_loss: 8.6948e-05\n",
      "Epoch 20/24\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 1.7264e-04 - val_loss: 7.1582e-05\n",
      "Epoch 21/24\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 1.4402e-04 - val_loss: 6.5286e-05\n",
      "Epoch 22/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 21us/step - loss: 2.0648e-04 - val_loss: 5.7903e-05\n",
      "Epoch 23/24\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 1.2848e-04 - val_loss: 3.9290e-05\n",
      "Epoch 24/24\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 1.4616e-04 - val_loss: 3.5053e-05\n"
     ]
    }
   ],
   "source": [
    "best_models = breed_population(X_train, Y_train, generations=20, population_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.00034386917341957987,\n",
       " 3.783172801830681e-05,\n",
       " 3.1464102870774164e-05,\n",
       " 3.1470912837761796e-05,\n",
       " 3.147362602970096e-05,\n",
       " 3.145755387235134e-05,\n",
       " 3.146474106008072e-05,\n",
       " 3.145733422366317e-05,\n",
       " 3.145742804341629e-05,\n",
       " 3.153769932384047e-05,\n",
       " 3.1465728658497666e-05,\n",
       " 3.1459942150548324e-05,\n",
       " 3.145837165293651e-05,\n",
       " 3.145886018805368e-05,\n",
       " 3.151930285024313e-05,\n",
       " 3.146486582476212e-05,\n",
       " 3.1501187267185085e-05,\n",
       " 3.154301745574086e-05,\n",
       " 3.1505211624956766e-05,\n",
       " 3.1472171146171304e-05,\n",
       " 3.145982097276765e-05,\n",
       " 3.1525540156521935e-05,\n",
       " 3.145735740319913e-05,\n",
       " 3.1468058131344e-05]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models[0][1].history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal parameters\n",
      "_______________________\n",
      "activation: sigmoid\n",
      "optimizer: adamax\n",
      "shuffle: True\n",
      "density: 148\n"
     ]
    }
   ],
   "source": [
    "print('optimal parameters')\n",
    "print('_______________________')\n",
    "for key,val in best_models[0][2].items():\n",
    "    if key != 'x' and key != 'y': print(f'{key}: {val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_84\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_432 (Dense)            (None, 148)               14652     \n",
      "_________________________________________________________________\n",
      "dense_433 (Dense)            (None, 74)                11026     \n",
      "_________________________________________________________________\n",
      "dense_434 (Dense)            (None, 37)                2775      \n",
      "_________________________________________________________________\n",
      "dense_435 (Dense)            (None, 18)                684       \n",
      "_________________________________________________________________\n",
      "dense_436 (Dense)            (None, 1)                 19        \n",
      "=================================================================\n",
      "Total params: 29,156\n",
      "Trainable params: 29,156\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_models[0][0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\n",
    "    filepath='./checkpoints/fundamental.{epoch}-{val_loss}.hdf5',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = best_models[0][2]\n",
    "params['x'] = X_train\n",
    "params['y'] = Y_train\n",
    "params['epochs'] = 2000\n",
    "params['callbacks'] = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21471 samples, validate on 2386 samples\n",
      "Epoch 1/2000\n",
      "21471/21471 [==============================] - 8s 350us/step - loss: 0.0162 - val_loss: 6.4895e-04\n",
      "Epoch 2/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 1.6463e-04 - val_loss: 3.9912e-05\n",
      "Epoch 3/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9299e-05 - val_loss: 3.1514e-05\n",
      "Epoch 4/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.7873e-05 - val_loss: 3.1490e-05\n",
      "Epoch 5/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.7868e-05 - val_loss: 3.1477e-05\n",
      "Epoch 6/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.7884e-05 - val_loss: 3.1485e-05\n",
      "Epoch 7/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.7869e-05 - val_loss: 3.1480e-05\n",
      "Epoch 8/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.7880e-05 - val_loss: 3.1482e-05\n",
      "Epoch 9/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.7858e-05 - val_loss: 3.1652e-05\n",
      "Epoch 10/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.7868e-05 - val_loss: 3.1476e-05\n",
      "Epoch 11/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.7898e-05 - val_loss: 3.1474e-05\n",
      "Epoch 12/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.7867e-05 - val_loss: 3.1511e-05\n",
      "Epoch 13/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.7913e-05 - val_loss: 3.1473e-05\n",
      "Epoch 14/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.7893e-05 - val_loss: 3.1473e-05\n",
      "Epoch 15/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.7876e-05 - val_loss: 3.1476e-05\n",
      "Epoch 16/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.7858e-05 - val_loss: 3.1472e-05\n",
      "Epoch 17/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.7866e-05 - val_loss: 3.1505e-05\n",
      "Epoch 18/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.7895e-05 - val_loss: 3.1471e-05\n",
      "Epoch 19/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.7860e-05 - val_loss: 3.1469e-05\n",
      "Epoch 20/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 8.7883e-05 - val_loss: 3.1472e-05\n",
      "Epoch 21/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.7877e-05 - val_loss: 3.1489e-05\n",
      "Epoch 22/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.7896e-05 - val_loss: 3.1467e-05\n",
      "Epoch 23/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.7917e-05 - val_loss: 3.1500e-05\n",
      "Epoch 24/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.7894e-05 - val_loss: 3.1469e-05\n",
      "Epoch 25/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.7876e-05 - val_loss: 3.1537e-05\n",
      "Epoch 26/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.7844e-05 - val_loss: 3.1501e-05\n",
      "Epoch 27/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.7855e-05 - val_loss: 3.1612e-05\n",
      "Epoch 28/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.7899e-05 - val_loss: 3.1477e-05\n",
      "Epoch 29/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.7921e-05 - val_loss: 3.1463e-05\n",
      "Epoch 30/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.7904e-05 - val_loss: 3.1471e-05\n",
      "Epoch 31/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.7881e-05 - val_loss: 3.1482e-05\n",
      "Epoch 32/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.7882e-05 - val_loss: 3.1776e-05\n",
      "Epoch 33/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8008e-05 - val_loss: 3.1463e-05\n",
      "Epoch 34/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.7900e-05 - val_loss: 3.1590e-05\n",
      "Epoch 35/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8000e-05 - val_loss: 3.1460e-05\n",
      "Epoch 36/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.7889e-05 - val_loss: 3.1536e-05\n",
      "Epoch 37/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.7861e-05 - val_loss: 3.1474e-05\n",
      "Epoch 38/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.7880e-05 - val_loss: 3.1479e-05\n",
      "Epoch 39/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.7898e-05 - val_loss: 3.1483e-05\n",
      "Epoch 40/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.7936e-05 - val_loss: 3.1557e-05\n",
      "Epoch 41/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.7994e-05 - val_loss: 3.1480e-05\n",
      "Epoch 42/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.7879e-05 - val_loss: 3.1457e-05\n",
      "Epoch 43/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.7849e-05 - val_loss: 3.1462e-05\n",
      "Epoch 44/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.7871e-05 - val_loss: 3.1781e-05\n",
      "Epoch 45/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.7947e-05 - val_loss: 3.1679e-05\n",
      "Epoch 46/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.7908e-05 - val_loss: 3.1651e-05\n",
      "Epoch 47/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.7894e-05 - val_loss: 3.1493e-05\n",
      "Epoch 48/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.7893e-05 - val_loss: 3.1564e-05\n",
      "Epoch 49/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8077e-05 - val_loss: 3.2120e-05\n",
      "Epoch 50/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.7950e-05 - val_loss: 3.1537e-05\n",
      "Epoch 51/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.7913e-05 - val_loss: 3.1474e-05\n",
      "Epoch 52/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.7892e-05 - val_loss: 3.1492e-05\n",
      "Epoch 53/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.7873e-05 - val_loss: 3.1529e-05\n",
      "Epoch 54/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.7928e-05 - val_loss: 3.1527e-05\n",
      "Epoch 55/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.7954e-05 - val_loss: 3.1600e-05\n",
      "Epoch 56/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.7977e-05 - val_loss: 3.1462e-05\n",
      "Epoch 57/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8010e-05 - val_loss: 3.1464e-05\n",
      "Epoch 58/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8062e-05 - val_loss: 3.1455e-05\n",
      "Epoch 59/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 8.8085e-05 - val_loss: 3.1459e-05\n",
      "Epoch 60/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8061e-05 - val_loss: 3.1658e-05\n",
      "Epoch 61/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8058e-05 - val_loss: 3.1947e-05\n",
      "Epoch 62/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.7965e-05 - val_loss: 3.2526e-05\n",
      "Epoch 63/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8207e-05 - val_loss: 3.1512e-05\n",
      "Epoch 64/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.7996e-05 - val_loss: 3.1565e-05\n",
      "Epoch 65/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8060e-05 - val_loss: 3.1513e-05\n",
      "Epoch 66/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8365e-05 - val_loss: 3.1628e-05\n",
      "Epoch 67/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.7949e-05 - val_loss: 3.1806e-05\n",
      "Epoch 68/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8142e-05 - val_loss: 3.1610e-05\n",
      "Epoch 69/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.7980e-05 - val_loss: 3.1632e-05\n",
      "Epoch 70/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8069e-05 - val_loss: 3.1632e-05\n",
      "Epoch 71/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8461e-05 - val_loss: 3.1929e-05\n",
      "Epoch 72/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8149e-05 - val_loss: 3.1942e-05\n",
      "Epoch 73/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8466e-05 - val_loss: 3.1553e-05\n",
      "Epoch 74/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8431e-05 - val_loss: 3.1884e-05\n",
      "Epoch 75/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8616e-05 - val_loss: 3.1538e-05\n",
      "Epoch 76/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8079e-05 - val_loss: 3.1874e-05\n",
      "Epoch 77/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8013e-05 - val_loss: 3.1455e-05\n",
      "Epoch 78/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.7982e-05 - val_loss: 3.1941e-05\n",
      "Epoch 79/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8083e-05 - val_loss: 3.1497e-05\n",
      "Epoch 80/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8509e-05 - val_loss: 3.1488e-05\n",
      "Epoch 81/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8752e-05 - val_loss: 3.2512e-05\n",
      "Epoch 82/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.7968e-05 - val_loss: 3.2551e-05\n",
      "Epoch 83/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8867e-05 - val_loss: 3.1885e-05\n",
      "Epoch 84/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8367e-05 - val_loss: 3.2177e-05\n",
      "Epoch 85/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8178e-05 - val_loss: 3.1457e-05\n",
      "Epoch 86/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8260e-05 - val_loss: 3.1572e-05\n",
      "Epoch 87/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8981e-05 - val_loss: 3.2292e-05\n",
      "Epoch 88/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9488e-05 - val_loss: 3.3315e-05\n",
      "Epoch 89/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8766e-05 - val_loss: 3.3021e-05\n",
      "Epoch 90/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8508e-05 - val_loss: 3.1496e-05\n",
      "Epoch 91/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9030e-05 - val_loss: 3.1892e-05\n",
      "Epoch 92/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8268e-05 - val_loss: 3.2113e-05\n",
      "Epoch 93/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9189e-05 - val_loss: 3.3181e-05\n",
      "Epoch 94/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8724e-05 - val_loss: 3.1664e-05\n",
      "Epoch 95/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8458e-05 - val_loss: 3.1633e-05\n",
      "Epoch 96/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9771e-05 - val_loss: 3.1483e-05\n",
      "Epoch 97/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8296e-05 - val_loss: 3.3068e-05\n",
      "Epoch 98/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.1715e-05 - val_loss: 3.2526e-05\n",
      "Epoch 99/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8470e-05 - val_loss: 3.1643e-05\n",
      "Epoch 100/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0352e-05 - val_loss: 3.2105e-05\n",
      "Epoch 101/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9064e-05 - val_loss: 3.1928e-05\n",
      "Epoch 102/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9024e-05 - val_loss: 3.1479e-05\n",
      "Epoch 103/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8278e-05 - val_loss: 3.1810e-05\n",
      "Epoch 104/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8309e-05 - val_loss: 3.8005e-05\n",
      "Epoch 105/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0006e-05 - val_loss: 3.2255e-05\n",
      "Epoch 106/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8398e-05 - val_loss: 3.3388e-05\n",
      "Epoch 107/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8952e-05 - val_loss: 4.1088e-05\n",
      "Epoch 108/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9390e-05 - val_loss: 3.4873e-05\n",
      "Epoch 109/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9844e-05 - val_loss: 3.2023e-05\n",
      "Epoch 110/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0702e-05 - val_loss: 3.1542e-05\n",
      "Epoch 111/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9111e-05 - val_loss: 3.1642e-05\n",
      "Epoch 112/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.1078e-05 - val_loss: 3.1485e-05\n",
      "Epoch 113/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9632e-05 - val_loss: 3.4730e-05\n",
      "Epoch 114/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9315e-05 - val_loss: 3.5928e-05\n",
      "Epoch 115/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.2022e-05 - val_loss: 3.1603e-05\n",
      "Epoch 116/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0132e-05 - val_loss: 3.1551e-05\n",
      "Epoch 117/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.9901e-05 - val_loss: 3.7462e-05\n",
      "Epoch 118/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 9.4787e-05 - val_loss: 3.1712e-05\n",
      "Epoch 119/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9952e-05 - val_loss: 3.1949e-05\n",
      "Epoch 120/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9742e-05 - val_loss: 3.2086e-05\n",
      "Epoch 121/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8934e-05 - val_loss: 3.2834e-05\n",
      "Epoch 122/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.2988e-05 - val_loss: 3.2193e-05\n",
      "Epoch 123/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9497e-05 - val_loss: 3.1585e-05\n",
      "Epoch 124/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8670e-05 - val_loss: 3.3476e-05\n",
      "Epoch 125/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 9.0348e-05 - val_loss: 3.2468e-05\n",
      "Epoch 126/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.2065e-05 - val_loss: 3.1500e-05\n",
      "Epoch 127/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 9.4695e-05 - val_loss: 4.2461e-05\n",
      "Epoch 128/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0544e-05 - val_loss: 3.2907e-05\n",
      "Epoch 129/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.9133e-05 - val_loss: 3.1834e-05\n",
      "Epoch 130/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9535e-05 - val_loss: 3.1827e-05\n",
      "Epoch 131/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 9.1172e-05 - val_loss: 3.1616e-05\n",
      "Epoch 132/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9031e-05 - val_loss: 3.1451e-05\n",
      "Epoch 133/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9622e-05 - val_loss: 3.3861e-05\n",
      "Epoch 134/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.0403e-05 - val_loss: 3.5725e-05\n",
      "Epoch 135/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 9.1197e-05 - val_loss: 3.1473e-05\n",
      "Epoch 136/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.8820e-05 - val_loss: 3.1794e-05\n",
      "Epoch 137/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 9.0745e-05 - val_loss: 3.1852e-05\n",
      "Epoch 138/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 9.1734e-05 - val_loss: 3.1536e-05\n",
      "Epoch 139/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8927e-05 - val_loss: 3.3088e-05\n",
      "Epoch 140/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9434e-05 - val_loss: 3.4583e-05\n",
      "Epoch 141/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9289e-05 - val_loss: 3.5389e-05\n",
      "Epoch 142/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.2328e-05 - val_loss: 3.2296e-05\n",
      "Epoch 143/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 9.0166e-05 - val_loss: 3.2988e-05\n",
      "Epoch 144/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 9.3072e-05 - val_loss: 3.1674e-05\n",
      "Epoch 145/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8902e-05 - val_loss: 3.1671e-05\n",
      "Epoch 146/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 9.0067e-05 - val_loss: 3.2683e-05\n",
      "Epoch 147/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.0131e-05 - val_loss: 3.7898e-05\n",
      "Epoch 148/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 9.0721e-05 - val_loss: 5.0255e-05\n",
      "Epoch 149/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.6268e-05 - val_loss: 3.6268e-05\n",
      "Epoch 150/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.8657e-05 - val_loss: 3.3518e-05\n",
      "Epoch 151/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.8670e-05 - val_loss: 3.2040e-05\n",
      "Epoch 152/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9671e-05 - val_loss: 3.4101e-05\n",
      "Epoch 153/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.8850e-05 - val_loss: 3.2349e-05\n",
      "Epoch 154/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.9546e-05 - val_loss: 3.3175e-05\n",
      "Epoch 155/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.9891e-05 - val_loss: 3.1922e-05\n",
      "Epoch 156/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9001e-05 - val_loss: 3.7275e-05\n",
      "Epoch 157/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9032e-05 - val_loss: 5.7744e-05\n",
      "Epoch 158/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 9.1996e-05 - val_loss: 3.2878e-05\n",
      "Epoch 159/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9302e-05 - val_loss: 3.2583e-05\n",
      "Epoch 160/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.9476e-05 - val_loss: 3.1449e-05\n",
      "Epoch 161/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 9.2152e-05 - val_loss: 3.1518e-05\n",
      "Epoch 162/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.1533e-05 - val_loss: 3.1724e-05\n",
      "Epoch 163/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9499e-05 - val_loss: 3.2057e-05\n",
      "Epoch 164/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9479e-05 - val_loss: 3.1874e-05\n",
      "Epoch 165/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.0526e-05 - val_loss: 4.1017e-05\n",
      "Epoch 166/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.1688e-05 - val_loss: 3.3124e-05\n",
      "Epoch 167/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.0846e-05 - val_loss: 3.2798e-05\n",
      "Epoch 168/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.1614e-05 - val_loss: 3.1516e-05\n",
      "Epoch 169/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8176e-05 - val_loss: 5.3012e-05\n",
      "Epoch 170/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.5738e-05 - val_loss: 3.3620e-05\n",
      "Epoch 171/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 9.0009e-05 - val_loss: 3.4148e-05\n",
      "Epoch 172/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9639e-05 - val_loss: 3.1863e-05\n",
      "Epoch 173/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.0070e-05 - val_loss: 3.1727e-05\n",
      "Epoch 174/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.9410e-05 - val_loss: 3.2340e-05\n",
      "Epoch 175/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 9.0299e-05 - val_loss: 3.2849e-05\n",
      "Epoch 176/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.8584e-05 - val_loss: 3.4991e-05\n",
      "Epoch 177/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.2092e-05 - val_loss: 3.2874e-05\n",
      "Epoch 178/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.2370e-05 - val_loss: 3.3341e-05\n",
      "Epoch 179/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8963e-05 - val_loss: 3.1729e-05\n",
      "Epoch 180/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.9866e-05 - val_loss: 3.6486e-05\n",
      "Epoch 181/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 9.1222e-05 - val_loss: 4.0674e-05\n",
      "Epoch 182/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.9648e-05 - val_loss: 3.2853e-05\n",
      "Epoch 183/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9166e-05 - val_loss: 3.3448e-05\n",
      "Epoch 184/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9437e-05 - val_loss: 3.1907e-05\n",
      "Epoch 185/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.0363e-05 - val_loss: 3.1455e-05\n",
      "Epoch 186/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.9259e-05 - val_loss: 3.2233e-05\n",
      "Epoch 187/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.8537e-05 - val_loss: 3.1968e-05\n",
      "Epoch 188/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.1024e-05 - val_loss: 3.2572e-05\n",
      "Epoch 189/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9444e-05 - val_loss: 3.2327e-05\n",
      "Epoch 190/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9611e-05 - val_loss: 3.4340e-05\n",
      "Epoch 191/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 9.0595e-05 - val_loss: 4.2667e-05\n",
      "Epoch 192/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 9.1125e-05 - val_loss: 3.3051e-05\n",
      "Epoch 193/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.1795e-05 - val_loss: 3.3202e-05\n",
      "Epoch 194/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.9853e-05 - val_loss: 3.6011e-05\n",
      "Epoch 195/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 9.1911e-05 - val_loss: 4.1317e-05\n",
      "Epoch 196/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.3851e-05 - val_loss: 3.1571e-05\n",
      "Epoch 197/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9781e-05 - val_loss: 3.5611e-05\n",
      "Epoch 198/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 9.0625e-05 - val_loss: 3.7531e-05\n",
      "Epoch 199/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 9.0751e-05 - val_loss: 3.7895e-05\n",
      "Epoch 200/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.9268e-05 - val_loss: 3.8554e-05\n",
      "Epoch 201/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 9.0545e-05 - val_loss: 3.1771e-05\n",
      "Epoch 202/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9117e-05 - val_loss: 3.5418e-05\n",
      "Epoch 203/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9780e-05 - val_loss: 3.1551e-05\n",
      "Epoch 204/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9849e-05 - val_loss: 3.1449e-05\n",
      "Epoch 205/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8331e-05 - val_loss: 3.4091e-05\n",
      "Epoch 206/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.0095e-05 - val_loss: 3.6991e-05\n",
      "Epoch 207/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 9.2868e-05 - val_loss: 3.3265e-05\n",
      "Epoch 208/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.8772e-05 - val_loss: 3.4280e-05\n",
      "Epoch 209/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.1779e-05 - val_loss: 3.1718e-05\n",
      "Epoch 210/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9539e-05 - val_loss: 3.3552e-05\n",
      "Epoch 211/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9623e-05 - val_loss: 3.1731e-05\n",
      "Epoch 212/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9123e-05 - val_loss: 3.3091e-05\n",
      "Epoch 213/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.9385e-05 - val_loss: 3.1507e-05\n",
      "Epoch 214/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.0083e-05 - val_loss: 3.3872e-05\n",
      "Epoch 215/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.1573e-05 - val_loss: 3.4836e-05\n",
      "Epoch 216/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.1015e-05 - val_loss: 3.2465e-05\n",
      "Epoch 217/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.1934e-05 - val_loss: 3.1681e-05\n",
      "Epoch 218/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.0991e-05 - val_loss: 3.2684e-05\n",
      "Epoch 219/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.1047e-05 - val_loss: 3.4191e-05\n",
      "Epoch 220/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9252e-05 - val_loss: 3.1449e-05\n",
      "Epoch 221/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.8642e-05 - val_loss: 3.1505e-05\n",
      "Epoch 222/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 9.1092e-05 - val_loss: 3.9258e-05\n",
      "Epoch 223/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 9.4576e-05 - val_loss: 3.1530e-05\n",
      "Epoch 224/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.9143e-05 - val_loss: 3.2129e-05\n",
      "Epoch 225/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.8820e-05 - val_loss: 3.2990e-05\n",
      "Epoch 226/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9268e-05 - val_loss: 3.1611e-05\n",
      "Epoch 227/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.8589e-05 - val_loss: 3.2269e-05\n",
      "Epoch 228/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.0302e-05 - val_loss: 4.0500e-05\n",
      "Epoch 229/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.9888e-05 - val_loss: 3.1713e-05\n",
      "Epoch 230/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9332e-05 - val_loss: 3.1736e-05\n",
      "Epoch 231/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9835e-05 - val_loss: 3.1538e-05\n",
      "Epoch 232/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.9145e-05 - val_loss: 3.2110e-05\n",
      "Epoch 233/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.1000e-05 - val_loss: 3.5581e-05\n",
      "Epoch 234/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.9613e-05 - val_loss: 4.0597e-05\n",
      "Epoch 235/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9699e-05 - val_loss: 3.2656e-05\n",
      "Epoch 236/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.4259e-05 - val_loss: 3.1962e-05\n",
      "Epoch 237/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9335e-05 - val_loss: 3.2431e-05\n",
      "Epoch 238/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8689e-05 - val_loss: 3.1469e-05\n",
      "Epoch 239/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.0300e-05 - val_loss: 3.2612e-05\n",
      "Epoch 240/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.8698e-05 - val_loss: 3.1528e-05\n",
      "Epoch 241/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.9465e-05 - val_loss: 3.5997e-05\n",
      "Epoch 242/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.9037e-05 - val_loss: 3.3818e-05\n",
      "Epoch 243/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.9764e-05 - val_loss: 3.2226e-05\n",
      "Epoch 244/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.1413e-05 - val_loss: 3.2104e-05\n",
      "Epoch 245/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.0035e-05 - val_loss: 3.2917e-05\n",
      "Epoch 246/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.9944e-05 - val_loss: 3.1449e-05\n",
      "Epoch 247/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.8735e-05 - val_loss: 3.2078e-05\n",
      "Epoch 248/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9541e-05 - val_loss: 3.1672e-05\n",
      "Epoch 249/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.8900e-05 - val_loss: 3.2561e-05\n",
      "Epoch 250/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.2604e-05 - val_loss: 3.2045e-05\n",
      "Epoch 251/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.9305e-05 - val_loss: 3.2239e-05\n",
      "Epoch 252/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.8975e-05 - val_loss: 3.3743e-05\n",
      "Epoch 253/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.9028e-05 - val_loss: 3.8526e-05\n",
      "Epoch 254/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 9.3547e-05 - val_loss: 4.3532e-05\n",
      "Epoch 255/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.0185e-05 - val_loss: 3.1610e-05\n",
      "Epoch 256/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9356e-05 - val_loss: 3.1665e-05\n",
      "Epoch 257/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.8437e-05 - val_loss: 3.2495e-05\n",
      "Epoch 258/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9387e-05 - val_loss: 3.1603e-05\n",
      "Epoch 259/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 9.0433e-05 - val_loss: 3.3722e-05\n",
      "Epoch 260/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.9963e-05 - val_loss: 3.1831e-05\n",
      "Epoch 261/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9503e-05 - val_loss: 7.8656e-05\n",
      "Epoch 262/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 9.2674e-05 - val_loss: 3.1839e-05\n",
      "Epoch 263/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.8218e-05 - val_loss: 3.1467e-05\n",
      "Epoch 264/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.9066e-05 - val_loss: 3.3487e-05\n",
      "Epoch 265/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.9875e-05 - val_loss: 3.8847e-05\n",
      "Epoch 266/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9394e-05 - val_loss: 3.1867e-05\n",
      "Epoch 267/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8396e-05 - val_loss: 3.1467e-05\n",
      "Epoch 268/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 8.8952e-05 - val_loss: 3.1606e-05\n",
      "Epoch 269/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8448e-05 - val_loss: 3.1478e-05\n",
      "Epoch 270/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8789e-05 - val_loss: 4.1530e-05\n",
      "Epoch 271/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9889e-05 - val_loss: 3.3855e-05\n",
      "Epoch 272/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 9.0441e-05 - val_loss: 3.2153e-05\n",
      "Epoch 273/2000\n",
      "21471/21471 [==============================] - 0s 18us/step - loss: 9.0813e-05 - val_loss: 3.7971e-05\n",
      "Epoch 274/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9195e-05 - val_loss: 3.5687e-05\n",
      "Epoch 275/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 9.0047e-05 - val_loss: 3.2155e-05\n",
      "Epoch 276/2000\n",
      "21471/21471 [==============================] - 0s 23us/step - loss: 9.0248e-05 - val_loss: 3.5292e-05\n",
      "Epoch 277/2000\n",
      "21471/21471 [==============================] - 1s 25us/step - loss: 8.8779e-05 - val_loss: 3.2641e-05\n",
      "Epoch 278/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 9.0531e-05 - val_loss: 3.2009e-05\n",
      "Epoch 279/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8795e-05 - val_loss: 3.2608e-05\n",
      "Epoch 280/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9398e-05 - val_loss: 3.1478e-05\n",
      "Epoch 281/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0323e-05 - val_loss: 3.6497e-05\n",
      "Epoch 282/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9514e-05 - val_loss: 3.1449e-05\n",
      "Epoch 283/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0759e-05 - val_loss: 3.4217e-05\n",
      "Epoch 284/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9344e-05 - val_loss: 3.1523e-05\n",
      "Epoch 285/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.2753e-05 - val_loss: 3.2261e-05\n",
      "Epoch 286/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8839e-05 - val_loss: 3.3096e-05\n",
      "Epoch 287/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8808e-05 - val_loss: 3.1636e-05\n",
      "Epoch 288/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8376e-05 - val_loss: 3.1470e-05\n",
      "Epoch 289/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8429e-05 - val_loss: 3.1809e-05\n",
      "Epoch 290/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8456e-05 - val_loss: 3.1449e-05\n",
      "Epoch 291/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9453e-05 - val_loss: 3.1756e-05\n",
      "Epoch 292/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0670e-05 - val_loss: 3.2023e-05\n",
      "Epoch 293/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8777e-05 - val_loss: 3.1699e-05\n",
      "Epoch 294/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8272e-05 - val_loss: 3.1574e-05\n",
      "Epoch 295/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9954e-05 - val_loss: 3.2888e-05\n",
      "Epoch 296/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 9.0393e-05 - val_loss: 3.3017e-05\n",
      "Epoch 297/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.9148e-05 - val_loss: 3.3056e-05\n",
      "Epoch 298/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8525e-05 - val_loss: 3.3648e-05\n",
      "Epoch 299/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8252e-05 - val_loss: 3.2800e-05\n",
      "Epoch 300/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9357e-05 - val_loss: 3.1501e-05\n",
      "Epoch 301/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9714e-05 - val_loss: 3.2283e-05\n",
      "Epoch 302/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0340e-05 - val_loss: 3.7653e-05\n",
      "Epoch 303/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.3988e-05 - val_loss: 3.3194e-05\n",
      "Epoch 304/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0927e-05 - val_loss: 3.5381e-05\n",
      "Epoch 305/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9373e-05 - val_loss: 3.4165e-05\n",
      "Epoch 306/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0342e-05 - val_loss: 3.2090e-05\n",
      "Epoch 307/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.9100e-05 - val_loss: 3.1590e-05\n",
      "Epoch 308/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 9.0793e-05 - val_loss: 3.2632e-05\n",
      "Epoch 309/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 9.0704e-05 - val_loss: 3.3414e-05\n",
      "Epoch 310/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9959e-05 - val_loss: 3.4373e-05\n",
      "Epoch 311/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0534e-05 - val_loss: 3.2008e-05\n",
      "Epoch 312/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.9058e-05 - val_loss: 3.4216e-05\n",
      "Epoch 313/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.9751e-05 - val_loss: 3.2309e-05\n",
      "Epoch 314/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0463e-05 - val_loss: 3.1680e-05\n",
      "Epoch 315/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.2568e-05 - val_loss: 3.1658e-05\n",
      "Epoch 316/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8504e-05 - val_loss: 3.1570e-05\n",
      "Epoch 317/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9298e-05 - val_loss: 3.5413e-05\n",
      "Epoch 318/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9188e-05 - val_loss: 3.4886e-05\n",
      "Epoch 319/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0191e-05 - val_loss: 3.1653e-05\n",
      "Epoch 320/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8831e-05 - val_loss: 3.1634e-05\n",
      "Epoch 321/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8673e-05 - val_loss: 4.2250e-05\n",
      "Epoch 322/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.2065e-05 - val_loss: 3.3233e-05\n",
      "Epoch 323/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9788e-05 - val_loss: 3.3381e-05\n",
      "Epoch 324/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0332e-05 - val_loss: 3.1527e-05\n",
      "Epoch 325/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9366e-05 - val_loss: 3.8537e-05\n",
      "Epoch 326/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 9.1218e-05 - val_loss: 3.1484e-05\n",
      "Epoch 327/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0485e-05 - val_loss: 3.3987e-05\n",
      "Epoch 328/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0643e-05 - val_loss: 3.1578e-05\n",
      "Epoch 329/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9138e-05 - val_loss: 3.9245e-05\n",
      "Epoch 330/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.1362e-05 - val_loss: 3.7255e-05\n",
      "Epoch 331/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0394e-05 - val_loss: 3.1798e-05\n",
      "Epoch 332/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9406e-05 - val_loss: 3.1799e-05\n",
      "Epoch 333/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9418e-05 - val_loss: 3.2232e-05\n",
      "Epoch 334/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9381e-05 - val_loss: 3.1835e-05\n",
      "Epoch 335/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.1547e-05 - val_loss: 3.3213e-05\n",
      "Epoch 336/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9219e-05 - val_loss: 3.3725e-05\n",
      "Epoch 337/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9011e-05 - val_loss: 3.1713e-05\n",
      "Epoch 338/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8506e-05 - val_loss: 3.1465e-05\n",
      "Epoch 339/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9280e-05 - val_loss: 3.2487e-05\n",
      "Epoch 340/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9946e-05 - val_loss: 3.1458e-05\n",
      "Epoch 341/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9388e-05 - val_loss: 3.2651e-05\n",
      "Epoch 342/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.3678e-05 - val_loss: 3.7396e-05\n",
      "Epoch 343/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9492e-05 - val_loss: 3.3101e-05\n",
      "Epoch 344/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9544e-05 - val_loss: 3.3766e-05\n",
      "Epoch 345/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.2498e-05 - val_loss: 3.3585e-05\n",
      "Epoch 346/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8772e-05 - val_loss: 3.4731e-05\n",
      "Epoch 347/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.9892e-05 - val_loss: 3.9290e-05\n",
      "Epoch 348/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 9.1842e-05 - val_loss: 3.3521e-05\n",
      "Epoch 349/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8258e-05 - val_loss: 4.5281e-05\n",
      "Epoch 350/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 9.1230e-05 - val_loss: 3.1468e-05\n",
      "Epoch 351/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9406e-05 - val_loss: 3.1783e-05\n",
      "Epoch 352/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9753e-05 - val_loss: 5.0515e-05\n",
      "Epoch 353/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0436e-05 - val_loss: 3.3400e-05\n",
      "Epoch 354/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8512e-05 - val_loss: 3.3246e-05\n",
      "Epoch 355/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9328e-05 - val_loss: 3.1484e-05\n",
      "Epoch 356/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0316e-05 - val_loss: 3.1749e-05\n",
      "Epoch 357/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0340e-05 - val_loss: 3.2871e-05\n",
      "Epoch 358/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9576e-05 - val_loss: 3.2016e-05\n",
      "Epoch 359/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8592e-05 - val_loss: 3.1691e-05\n",
      "Epoch 360/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.4770e-05 - val_loss: 3.2324e-05\n",
      "Epoch 361/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8360e-05 - val_loss: 3.4208e-05\n",
      "Epoch 362/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9088e-05 - val_loss: 3.1457e-05\n",
      "Epoch 363/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8637e-05 - val_loss: 3.1490e-05\n",
      "Epoch 364/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8621e-05 - val_loss: 3.4075e-05\n",
      "Epoch 365/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8916e-05 - val_loss: 3.1750e-05\n",
      "Epoch 366/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8146e-05 - val_loss: 3.3790e-05\n",
      "Epoch 367/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9054e-05 - val_loss: 3.2338e-05\n",
      "Epoch 368/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9638e-05 - val_loss: 3.3585e-05\n",
      "Epoch 369/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9691e-05 - val_loss: 3.1719e-05\n",
      "Epoch 370/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0134e-05 - val_loss: 3.2156e-05\n",
      "Epoch 371/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9796e-05 - val_loss: 3.1960e-05\n",
      "Epoch 372/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8771e-05 - val_loss: 3.9424e-05\n",
      "Epoch 373/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9103e-05 - val_loss: 3.7083e-05\n",
      "Epoch 374/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8750e-05 - val_loss: 3.3425e-05\n",
      "Epoch 375/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0608e-05 - val_loss: 3.7256e-05\n",
      "Epoch 376/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 9.1872e-05 - val_loss: 3.2599e-05\n",
      "Epoch 377/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.9097e-05 - val_loss: 3.6744e-05\n",
      "Epoch 378/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.9959e-05 - val_loss: 3.6864e-05\n",
      "Epoch 379/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 9.0968e-05 - val_loss: 3.1461e-05\n",
      "Epoch 380/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0150e-05 - val_loss: 3.2692e-05\n",
      "Epoch 381/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0875e-05 - val_loss: 3.2774e-05\n",
      "Epoch 382/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9963e-05 - val_loss: 3.3652e-05\n",
      "Epoch 383/2000\n",
      "21471/21471 [==============================] - 1s 24us/step - loss: 8.9220e-05 - val_loss: 3.6289e-05\n",
      "Epoch 384/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 9.0181e-05 - val_loss: 3.1919e-05\n",
      "Epoch 385/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.9558e-05 - val_loss: 3.2631e-05\n",
      "Epoch 386/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 8.9537e-05 - val_loss: 3.5096e-05\n",
      "Epoch 387/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.9201e-05 - val_loss: 3.7204e-05\n",
      "Epoch 388/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 9.0013e-05 - val_loss: 3.3138e-05\n",
      "Epoch 389/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.9839e-05 - val_loss: 3.2611e-05\n",
      "Epoch 390/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9307e-05 - val_loss: 3.1653e-05\n",
      "Epoch 391/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9061e-05 - val_loss: 3.1463e-05\n",
      "Epoch 392/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8867e-05 - val_loss: 3.3115e-05\n",
      "Epoch 393/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.2615e-05 - val_loss: 3.2994e-05\n",
      "Epoch 394/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9509e-05 - val_loss: 3.4510e-05\n",
      "Epoch 395/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9052e-05 - val_loss: 3.1552e-05\n",
      "Epoch 396/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8160e-05 - val_loss: 3.3615e-05\n",
      "Epoch 397/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9018e-05 - val_loss: 3.1526e-05\n",
      "Epoch 398/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8432e-05 - val_loss: 3.3013e-05\n",
      "Epoch 399/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0939e-05 - val_loss: 3.3769e-05\n",
      "Epoch 400/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8944e-05 - val_loss: 3.1575e-05\n",
      "Epoch 401/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9216e-05 - val_loss: 4.1866e-05\n",
      "Epoch 402/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.1412e-05 - val_loss: 3.6016e-05\n",
      "Epoch 403/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.1795e-05 - val_loss: 3.2039e-05\n",
      "Epoch 404/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8582e-05 - val_loss: 3.1853e-05\n",
      "Epoch 405/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9429e-05 - val_loss: 3.3874e-05\n",
      "Epoch 406/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8499e-05 - val_loss: 3.1826e-05\n",
      "Epoch 407/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8503e-05 - val_loss: 3.1465e-05\n",
      "Epoch 408/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8518e-05 - val_loss: 3.1451e-05\n",
      "Epoch 409/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8244e-05 - val_loss: 3.1534e-05\n",
      "Epoch 410/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0665e-05 - val_loss: 3.1544e-05\n",
      "Epoch 411/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9040e-05 - val_loss: 3.1884e-05\n",
      "Epoch 412/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8597e-05 - val_loss: 3.4112e-05\n",
      "Epoch 413/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9615e-05 - val_loss: 3.2388e-05\n",
      "Epoch 414/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8884e-05 - val_loss: 3.1919e-05\n",
      "Epoch 415/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0652e-05 - val_loss: 3.1464e-05\n",
      "Epoch 416/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 8.8647e-05 - val_loss: 3.1950e-05\n",
      "Epoch 417/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8680e-05 - val_loss: 3.2418e-05\n",
      "Epoch 418/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8570e-05 - val_loss: 3.2209e-05\n",
      "Epoch 419/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.1116e-05 - val_loss: 3.1456e-05\n",
      "Epoch 420/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8509e-05 - val_loss: 3.6167e-05\n",
      "Epoch 421/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0339e-05 - val_loss: 3.2283e-05\n",
      "Epoch 422/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8669e-05 - val_loss: 3.4075e-05\n",
      "Epoch 423/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 8.8486e-05 - val_loss: 3.1457e-05\n",
      "Epoch 424/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9859e-05 - val_loss: 3.1540e-05\n",
      "Epoch 425/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9280e-05 - val_loss: 3.3095e-05\n",
      "Epoch 426/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9984e-05 - val_loss: 3.3321e-05\n",
      "Epoch 427/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8672e-05 - val_loss: 3.1493e-05\n",
      "Epoch 428/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9668e-05 - val_loss: 3.3173e-05\n",
      "Epoch 429/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8685e-05 - val_loss: 3.1465e-05\n",
      "Epoch 430/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9638e-05 - val_loss: 3.2576e-05\n",
      "Epoch 431/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9040e-05 - val_loss: 3.1494e-05\n",
      "Epoch 432/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8395e-05 - val_loss: 3.2056e-05\n",
      "Epoch 433/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8697e-05 - val_loss: 3.2146e-05\n",
      "Epoch 434/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0031e-05 - val_loss: 3.9922e-05\n",
      "Epoch 435/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9930e-05 - val_loss: 3.1640e-05\n",
      "Epoch 436/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8743e-05 - val_loss: 3.1473e-05\n",
      "Epoch 437/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0217e-05 - val_loss: 3.7567e-05\n",
      "Epoch 438/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9744e-05 - val_loss: 3.6409e-05\n",
      "Epoch 439/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9090e-05 - val_loss: 3.1472e-05\n",
      "Epoch 440/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0693e-05 - val_loss: 3.1487e-05\n",
      "Epoch 441/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9034e-05 - val_loss: 3.2999e-05\n",
      "Epoch 442/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8704e-05 - val_loss: 3.1799e-05\n",
      "Epoch 443/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9727e-05 - val_loss: 3.1899e-05\n",
      "Epoch 444/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9035e-05 - val_loss: 3.1468e-05\n",
      "Epoch 445/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.2992e-05 - val_loss: 3.3792e-05\n",
      "Epoch 446/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.1392e-05 - val_loss: 3.2016e-05\n",
      "Epoch 447/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9308e-05 - val_loss: 3.1462e-05\n",
      "Epoch 448/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9723e-05 - val_loss: 3.1855e-05\n",
      "Epoch 449/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8829e-05 - val_loss: 3.1482e-05\n",
      "Epoch 450/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9056e-05 - val_loss: 3.2719e-05\n",
      "Epoch 451/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0788e-05 - val_loss: 3.1588e-05\n",
      "Epoch 452/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9969e-05 - val_loss: 3.1617e-05\n",
      "Epoch 453/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9006e-05 - val_loss: 3.1450e-05\n",
      "Epoch 454/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8779e-05 - val_loss: 3.1737e-05\n",
      "Epoch 455/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8878e-05 - val_loss: 3.1469e-05\n",
      "Epoch 456/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0821e-05 - val_loss: 3.2118e-05\n",
      "Epoch 457/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0585e-05 - val_loss: 3.2509e-05\n",
      "Epoch 458/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9989e-05 - val_loss: 3.1450e-05\n",
      "Epoch 459/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8789e-05 - val_loss: 3.1473e-05\n",
      "Epoch 460/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.9461e-05 - val_loss: 3.2547e-05\n",
      "Epoch 461/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8849e-05 - val_loss: 3.1700e-05\n",
      "Epoch 462/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8632e-05 - val_loss: 3.3461e-05\n",
      "Epoch 463/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8948e-05 - val_loss: 3.2051e-05\n",
      "Epoch 464/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8689e-05 - val_loss: 3.1453e-05\n",
      "Epoch 465/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9942e-05 - val_loss: 3.1665e-05\n",
      "Epoch 466/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9870e-05 - val_loss: 3.1454e-05\n",
      "Epoch 467/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8603e-05 - val_loss: 3.2273e-05\n",
      "Epoch 468/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9732e-05 - val_loss: 3.1502e-05\n",
      "Epoch 469/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9525e-05 - val_loss: 3.2504e-05\n",
      "Epoch 470/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9587e-05 - val_loss: 3.1729e-05\n",
      "Epoch 471/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0141e-05 - val_loss: 3.1464e-05\n",
      "Epoch 472/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 9.0459e-05 - val_loss: 3.2775e-05\n",
      "Epoch 473/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.1231e-05 - val_loss: 3.3041e-05\n",
      "Epoch 474/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9034e-05 - val_loss: 3.2177e-05\n",
      "Epoch 475/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8868e-05 - val_loss: 3.1458e-05\n",
      "Epoch 476/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8287e-05 - val_loss: 3.3046e-05\n",
      "Epoch 477/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8814e-05 - val_loss: 3.1649e-05\n",
      "Epoch 478/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8401e-05 - val_loss: 3.1733e-05\n",
      "Epoch 479/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8839e-05 - val_loss: 3.1714e-05\n",
      "Epoch 480/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8134e-05 - val_loss: 3.2649e-05\n",
      "Epoch 481/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9417e-05 - val_loss: 3.1996e-05\n",
      "Epoch 482/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0437e-05 - val_loss: 3.1684e-05\n",
      "Epoch 483/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.1205e-05 - val_loss: 3.1605e-05\n",
      "Epoch 484/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8127e-05 - val_loss: 3.1641e-05\n",
      "Epoch 485/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8234e-05 - val_loss: 3.1471e-05\n",
      "Epoch 486/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8520e-05 - val_loss: 3.3028e-05\n",
      "Epoch 487/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9199e-05 - val_loss: 3.1508e-05\n",
      "Epoch 488/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8943e-05 - val_loss: 3.2417e-05\n",
      "Epoch 489/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9474e-05 - val_loss: 3.2076e-05\n",
      "Epoch 490/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8562e-05 - val_loss: 3.1654e-05\n",
      "Epoch 491/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9790e-05 - val_loss: 3.1815e-05\n",
      "Epoch 492/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8478e-05 - val_loss: 3.1451e-05\n",
      "Epoch 493/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.1050e-05 - val_loss: 3.3281e-05\n",
      "Epoch 494/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8729e-05 - val_loss: 3.2079e-05\n",
      "Epoch 495/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8575e-05 - val_loss: 3.3503e-05\n",
      "Epoch 496/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.2730e-05 - val_loss: 3.2519e-05\n",
      "Epoch 497/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8648e-05 - val_loss: 3.1872e-05\n",
      "Epoch 498/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.9339e-05 - val_loss: 3.3159e-05\n",
      "Epoch 499/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.1208e-05 - val_loss: 3.1453e-05\n",
      "Epoch 500/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9005e-05 - val_loss: 3.3828e-05\n",
      "Epoch 501/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9287e-05 - val_loss: 3.1665e-05\n",
      "Epoch 502/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8279e-05 - val_loss: 3.2317e-05\n",
      "Epoch 503/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0107e-05 - val_loss: 3.1624e-05\n",
      "Epoch 504/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8732e-05 - val_loss: 3.1645e-05\n",
      "Epoch 505/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0052e-05 - val_loss: 3.6173e-05\n",
      "Epoch 506/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8710e-05 - val_loss: 3.1720e-05\n",
      "Epoch 507/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8475e-05 - val_loss: 3.5674e-05\n",
      "Epoch 508/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0121e-05 - val_loss: 3.3527e-05\n",
      "Epoch 509/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9017e-05 - val_loss: 3.5153e-05\n",
      "Epoch 510/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0682e-05 - val_loss: 3.2145e-05\n",
      "Epoch 511/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8541e-05 - val_loss: 3.4548e-05\n",
      "Epoch 512/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9197e-05 - val_loss: 3.1451e-05\n",
      "Epoch 513/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8965e-05 - val_loss: 3.1750e-05\n",
      "Epoch 514/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9081e-05 - val_loss: 3.1558e-05\n",
      "Epoch 515/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0539e-05 - val_loss: 3.4390e-05\n",
      "Epoch 516/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9320e-05 - val_loss: 3.4481e-05\n",
      "Epoch 517/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9102e-05 - val_loss: 3.2113e-05\n",
      "Epoch 518/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9254e-05 - val_loss: 3.2189e-05\n",
      "Epoch 519/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9079e-05 - val_loss: 3.1465e-05\n",
      "Epoch 520/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9063e-05 - val_loss: 3.1698e-05\n",
      "Epoch 521/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8921e-05 - val_loss: 3.2154e-05\n",
      "Epoch 522/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8589e-05 - val_loss: 3.2550e-05\n",
      "Epoch 523/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8530e-05 - val_loss: 3.2586e-05\n",
      "Epoch 524/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9985e-05 - val_loss: 3.3316e-05\n",
      "Epoch 525/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9078e-05 - val_loss: 3.2238e-05\n",
      "Epoch 526/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8967e-05 - val_loss: 3.1539e-05\n",
      "Epoch 527/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8476e-05 - val_loss: 3.1879e-05\n",
      "Epoch 528/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8958e-05 - val_loss: 3.1684e-05\n",
      "Epoch 529/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0420e-05 - val_loss: 3.2876e-05\n",
      "Epoch 530/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9246e-05 - val_loss: 3.1461e-05\n",
      "Epoch 531/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8376e-05 - val_loss: 3.2076e-05\n",
      "Epoch 532/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9656e-05 - val_loss: 3.3743e-05\n",
      "Epoch 533/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8474e-05 - val_loss: 3.2409e-05\n",
      "Epoch 534/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8389e-05 - val_loss: 3.1542e-05\n",
      "Epoch 535/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 8.8702e-05 - val_loss: 3.3675e-05\n",
      "Epoch 536/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9432e-05 - val_loss: 3.4613e-05\n",
      "Epoch 537/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9133e-05 - val_loss: 3.2785e-05\n",
      "Epoch 538/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9789e-05 - val_loss: 3.1641e-05\n",
      "Epoch 539/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9343e-05 - val_loss: 3.2557e-05\n",
      "Epoch 540/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8634e-05 - val_loss: 3.1479e-05\n",
      "Epoch 541/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8573e-05 - val_loss: 3.3427e-05\n",
      "Epoch 542/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9043e-05 - val_loss: 4.2158e-05\n",
      "Epoch 543/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0265e-05 - val_loss: 3.2684e-05\n",
      "Epoch 544/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8907e-05 - val_loss: 3.1600e-05\n",
      "Epoch 545/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8625e-05 - val_loss: 3.1955e-05\n",
      "Epoch 546/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9099e-05 - val_loss: 3.1843e-05\n",
      "Epoch 547/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.1517e-05 - val_loss: 4.3426e-05\n",
      "Epoch 548/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9987e-05 - val_loss: 3.1461e-05\n",
      "Epoch 549/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8286e-05 - val_loss: 3.1488e-05\n",
      "Epoch 550/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0208e-05 - val_loss: 3.1539e-05\n",
      "Epoch 551/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0933e-05 - val_loss: 3.1870e-05\n",
      "Epoch 552/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8600e-05 - val_loss: 3.1605e-05\n",
      "Epoch 553/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.1874e-05 - val_loss: 3.5922e-05\n",
      "Epoch 554/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.2168e-05 - val_loss: 3.3705e-05\n",
      "Epoch 555/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8510e-05 - val_loss: 3.3067e-05\n",
      "Epoch 556/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8873e-05 - val_loss: 3.4434e-05\n",
      "Epoch 557/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9077e-05 - val_loss: 3.3333e-05\n",
      "Epoch 558/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8156e-05 - val_loss: 3.2609e-05\n",
      "Epoch 559/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9348e-05 - val_loss: 3.4954e-05\n",
      "Epoch 560/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0757e-05 - val_loss: 3.1567e-05\n",
      "Epoch 561/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8603e-05 - val_loss: 3.4186e-05\n",
      "Epoch 562/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9236e-05 - val_loss: 3.2009e-05\n",
      "Epoch 563/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8699e-05 - val_loss: 3.2392e-05\n",
      "Epoch 564/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8641e-05 - val_loss: 3.1453e-05\n",
      "Epoch 565/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8455e-05 - val_loss: 3.1590e-05\n",
      "Epoch 566/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8493e-05 - val_loss: 3.1514e-05\n",
      "Epoch 567/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 9.0077e-05 - val_loss: 3.1684e-05\n",
      "Epoch 568/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9475e-05 - val_loss: 3.2185e-05\n",
      "Epoch 569/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0176e-05 - val_loss: 3.1512e-05\n",
      "Epoch 570/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.1420e-05 - val_loss: 3.3482e-05\n",
      "Epoch 571/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9041e-05 - val_loss: 3.1451e-05\n",
      "Epoch 572/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8663e-05 - val_loss: 3.1511e-05\n",
      "Epoch 573/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.9093e-05 - val_loss: 3.1459e-05\n",
      "Epoch 574/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8896e-05 - val_loss: 3.1862e-05\n",
      "Epoch 575/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.2439e-05 - val_loss: 3.1455e-05\n",
      "Epoch 576/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0062e-05 - val_loss: 3.1570e-05\n",
      "Epoch 577/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8629e-05 - val_loss: 3.5068e-05\n",
      "Epoch 578/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0428e-05 - val_loss: 3.1678e-05\n",
      "Epoch 579/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0269e-05 - val_loss: 3.1774e-05\n",
      "Epoch 580/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0873e-05 - val_loss: 3.3953e-05\n",
      "Epoch 581/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8481e-05 - val_loss: 3.3060e-05\n",
      "Epoch 582/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8721e-05 - val_loss: 3.1927e-05\n",
      "Epoch 583/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9932e-05 - val_loss: 3.1640e-05\n",
      "Epoch 584/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9014e-05 - val_loss: 3.7943e-05\n",
      "Epoch 585/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9652e-05 - val_loss: 3.1830e-05\n",
      "Epoch 586/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9809e-05 - val_loss: 3.1474e-05\n",
      "Epoch 587/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9642e-05 - val_loss: 3.1492e-05\n",
      "Epoch 588/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9198e-05 - val_loss: 3.1909e-05\n",
      "Epoch 589/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8839e-05 - val_loss: 3.1651e-05\n",
      "Epoch 590/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.2023e-05 - val_loss: 3.1467e-05\n",
      "Epoch 591/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8153e-05 - val_loss: 3.4048e-05\n",
      "Epoch 592/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8488e-05 - val_loss: 3.2240e-05\n",
      "Epoch 593/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8654e-05 - val_loss: 3.3226e-05\n",
      "Epoch 594/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9780e-05 - val_loss: 3.1763e-05\n",
      "Epoch 595/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0128e-05 - val_loss: 3.1894e-05\n",
      "Epoch 596/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8955e-05 - val_loss: 3.2458e-05\n",
      "Epoch 597/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8883e-05 - val_loss: 3.1562e-05\n",
      "Epoch 598/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8885e-05 - val_loss: 3.1936e-05\n",
      "Epoch 599/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0093e-05 - val_loss: 3.1568e-05\n",
      "Epoch 600/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8803e-05 - val_loss: 3.1917e-05\n",
      "Epoch 601/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9988e-05 - val_loss: 3.2192e-05\n",
      "Epoch 602/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.1690e-05 - val_loss: 3.8751e-05\n",
      "Epoch 603/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.1076e-05 - val_loss: 3.7854e-05\n",
      "Epoch 604/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9245e-05 - val_loss: 3.1595e-05\n",
      "Epoch 605/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8793e-05 - val_loss: 3.2304e-05\n",
      "Epoch 606/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9408e-05 - val_loss: 3.2963e-05\n",
      "Epoch 607/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8575e-05 - val_loss: 4.3409e-05\n",
      "Epoch 608/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.2673e-05 - val_loss: 3.3284e-05\n",
      "Epoch 609/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.9229e-05 - val_loss: 3.1476e-05\n",
      "Epoch 610/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8519e-05 - val_loss: 3.1716e-05\n",
      "Epoch 611/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8437e-05 - val_loss: 3.1546e-05\n",
      "Epoch 612/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8402e-05 - val_loss: 3.1664e-05\n",
      "Epoch 613/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8783e-05 - val_loss: 3.3613e-05\n",
      "Epoch 614/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9541e-05 - val_loss: 3.1817e-05\n",
      "Epoch 615/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8996e-05 - val_loss: 3.1711e-05\n",
      "Epoch 616/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0162e-05 - val_loss: 3.1651e-05\n",
      "Epoch 617/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9703e-05 - val_loss: 3.7107e-05\n",
      "Epoch 618/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9041e-05 - val_loss: 3.7725e-05\n",
      "Epoch 619/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0025e-05 - val_loss: 3.1473e-05\n",
      "Epoch 620/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8154e-05 - val_loss: 3.1748e-05\n",
      "Epoch 621/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8423e-05 - val_loss: 3.3627e-05\n",
      "Epoch 622/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8820e-05 - val_loss: 3.3213e-05\n",
      "Epoch 623/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8653e-05 - val_loss: 3.1651e-05\n",
      "Epoch 624/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8838e-05 - val_loss: 3.1561e-05\n",
      "Epoch 625/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9462e-05 - val_loss: 3.4328e-05\n",
      "Epoch 626/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 8.9581e-05 - val_loss: 3.2002e-05\n",
      "Epoch 627/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.9644e-05 - val_loss: 3.2653e-05\n",
      "Epoch 628/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9245e-05 - val_loss: 3.5410e-05\n",
      "Epoch 629/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8837e-05 - val_loss: 3.3951e-05\n",
      "Epoch 630/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8703e-05 - val_loss: 3.5398e-05\n",
      "Epoch 631/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8855e-05 - val_loss: 3.1479e-05\n",
      "Epoch 632/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8860e-05 - val_loss: 3.1453e-05\n",
      "Epoch 633/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8377e-05 - val_loss: 3.4951e-05\n",
      "Epoch 634/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9267e-05 - val_loss: 3.1675e-05\n",
      "Epoch 635/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8603e-05 - val_loss: 3.4460e-05\n",
      "Epoch 636/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9962e-05 - val_loss: 3.1666e-05\n",
      "Epoch 637/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9664e-05 - val_loss: 3.3539e-05\n",
      "Epoch 638/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8958e-05 - val_loss: 3.1559e-05\n",
      "Epoch 639/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8535e-05 - val_loss: 3.2428e-05\n",
      "Epoch 640/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.1669e-05 - val_loss: 3.1734e-05\n",
      "Epoch 641/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9660e-05 - val_loss: 3.1483e-05\n",
      "Epoch 642/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8354e-05 - val_loss: 3.1737e-05\n",
      "Epoch 643/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9490e-05 - val_loss: 3.1841e-05\n",
      "Epoch 644/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8528e-05 - val_loss: 3.2158e-05\n",
      "Epoch 645/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9805e-05 - val_loss: 3.1506e-05\n",
      "Epoch 646/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8683e-05 - val_loss: 3.1453e-05\n",
      "Epoch 647/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 8.9215e-05 - val_loss: 3.1454e-05\n",
      "Epoch 648/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9522e-05 - val_loss: 3.3597e-05\n",
      "Epoch 649/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0355e-05 - val_loss: 3.1949e-05\n",
      "Epoch 650/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8553e-05 - val_loss: 3.3184e-05\n",
      "Epoch 651/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8882e-05 - val_loss: 3.2099e-05\n",
      "Epoch 652/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8391e-05 - val_loss: 3.1452e-05\n",
      "Epoch 653/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8441e-05 - val_loss: 3.1941e-05\n",
      "Epoch 654/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9702e-05 - val_loss: 3.1485e-05\n",
      "Epoch 655/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8227e-05 - val_loss: 3.1642e-05\n",
      "Epoch 656/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8678e-05 - val_loss: 3.6377e-05\n",
      "Epoch 657/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8848e-05 - val_loss: 3.1709e-05\n",
      "Epoch 658/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8702e-05 - val_loss: 3.5669e-05\n",
      "Epoch 659/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 9.0486e-05 - val_loss: 3.5412e-05\n",
      "Epoch 660/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9002e-05 - val_loss: 3.4130e-05\n",
      "Epoch 661/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8523e-05 - val_loss: 3.1987e-05\n",
      "Epoch 662/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0146e-05 - val_loss: 3.1481e-05\n",
      "Epoch 663/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9117e-05 - val_loss: 3.3385e-05\n",
      "Epoch 664/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8387e-05 - val_loss: 3.1523e-05\n",
      "Epoch 665/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9017e-05 - val_loss: 3.7243e-05\n",
      "Epoch 666/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9057e-05 - val_loss: 3.1772e-05\n",
      "Epoch 667/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8732e-05 - val_loss: 3.2760e-05\n",
      "Epoch 668/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9132e-05 - val_loss: 3.1792e-05\n",
      "Epoch 669/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9223e-05 - val_loss: 3.1859e-05\n",
      "Epoch 670/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9386e-05 - val_loss: 3.3425e-05\n",
      "Epoch 671/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0005e-05 - val_loss: 3.2088e-05\n",
      "Epoch 672/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8156e-05 - val_loss: 3.6764e-05\n",
      "Epoch 673/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0369e-05 - val_loss: 3.1536e-05\n",
      "Epoch 674/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9208e-05 - val_loss: 3.2995e-05\n",
      "Epoch 675/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9675e-05 - val_loss: 3.5189e-05\n",
      "Epoch 676/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0514e-05 - val_loss: 3.2359e-05\n",
      "Epoch 677/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8958e-05 - val_loss: 3.1616e-05\n",
      "Epoch 678/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.1158e-05 - val_loss: 4.2145e-05\n",
      "Epoch 679/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.2607e-05 - val_loss: 3.2535e-05\n",
      "Epoch 680/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8718e-05 - val_loss: 3.5268e-05\n",
      "Epoch 681/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0460e-05 - val_loss: 3.2948e-05\n",
      "Epoch 682/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9024e-05 - val_loss: 3.6244e-05\n",
      "Epoch 683/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9810e-05 - val_loss: 3.1651e-05\n",
      "Epoch 684/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.9474e-05 - val_loss: 3.1521e-05\n",
      "Epoch 685/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 9.0181e-05 - val_loss: 3.2386e-05\n",
      "Epoch 686/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0867e-05 - val_loss: 3.7663e-05\n",
      "Epoch 687/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9904e-05 - val_loss: 3.2304e-05\n",
      "Epoch 688/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0441e-05 - val_loss: 3.1502e-05\n",
      "Epoch 689/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8949e-05 - val_loss: 3.1930e-05\n",
      "Epoch 690/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8894e-05 - val_loss: 3.1919e-05\n",
      "Epoch 691/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8526e-05 - val_loss: 3.2264e-05\n",
      "Epoch 692/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9879e-05 - val_loss: 3.3221e-05\n",
      "Epoch 693/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0274e-05 - val_loss: 3.3167e-05\n",
      "Epoch 694/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8705e-05 - val_loss: 3.1523e-05\n",
      "Epoch 695/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8434e-05 - val_loss: 3.1736e-05\n",
      "Epoch 696/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 8.8496e-05 - val_loss: 3.1670e-05\n",
      "Epoch 697/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8598e-05 - val_loss: 3.1773e-05\n",
      "Epoch 698/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8694e-05 - val_loss: 3.2448e-05\n",
      "Epoch 699/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8916e-05 - val_loss: 3.7527e-05\n",
      "Epoch 700/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0253e-05 - val_loss: 3.3326e-05\n",
      "Epoch 701/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0836e-05 - val_loss: 3.2537e-05\n",
      "Epoch 702/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0863e-05 - val_loss: 3.2452e-05\n",
      "Epoch 703/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8683e-05 - val_loss: 3.1666e-05\n",
      "Epoch 704/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8944e-05 - val_loss: 3.1955e-05\n",
      "Epoch 705/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8685e-05 - val_loss: 3.1826e-05\n",
      "Epoch 706/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8849e-05 - val_loss: 3.1948e-05\n",
      "Epoch 707/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8486e-05 - val_loss: 3.6785e-05\n",
      "Epoch 708/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0302e-05 - val_loss: 3.2150e-05\n",
      "Epoch 709/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9178e-05 - val_loss: 3.3139e-05\n",
      "Epoch 710/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9131e-05 - val_loss: 3.2490e-05\n",
      "Epoch 711/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9251e-05 - val_loss: 3.2755e-05\n",
      "Epoch 712/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8685e-05 - val_loss: 3.1686e-05\n",
      "Epoch 713/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8848e-05 - val_loss: 3.2371e-05\n",
      "Epoch 714/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9162e-05 - val_loss: 3.1487e-05\n",
      "Epoch 715/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8701e-05 - val_loss: 3.1961e-05\n",
      "Epoch 716/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8907e-05 - val_loss: 3.4981e-05\n",
      "Epoch 717/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9523e-05 - val_loss: 3.2725e-05\n",
      "Epoch 718/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8948e-05 - val_loss: 3.4790e-05\n",
      "Epoch 719/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9232e-05 - val_loss: 3.1754e-05\n",
      "Epoch 720/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.1322e-05 - val_loss: 3.2097e-05\n",
      "Epoch 721/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 8.8256e-05 - val_loss: 3.1572e-05\n",
      "Epoch 722/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.9542e-05 - val_loss: 3.5560e-05\n",
      "Epoch 723/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9005e-05 - val_loss: 3.4034e-05\n",
      "Epoch 724/2000\n",
      "21471/21471 [==============================] - ETA: 0s - loss: 9.6309e-0 - 0s 20us/step - loss: 8.9792e-05 - val_loss: 3.4984e-05\n",
      "Epoch 725/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.9225e-05 - val_loss: 3.1734e-05\n",
      "Epoch 726/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9023e-05 - val_loss: 3.1987e-05\n",
      "Epoch 727/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9306e-05 - val_loss: 3.4942e-05\n",
      "Epoch 728/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.9600e-05 - val_loss: 3.3852e-05\n",
      "Epoch 729/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8609e-05 - val_loss: 3.1986e-05\n",
      "Epoch 730/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9107e-05 - val_loss: 3.1946e-05\n",
      "Epoch 731/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0231e-05 - val_loss: 3.2805e-05\n",
      "Epoch 732/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9044e-05 - val_loss: 3.4050e-05\n",
      "Epoch 733/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8666e-05 - val_loss: 3.1487e-05\n",
      "Epoch 734/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9766e-05 - val_loss: 3.1575e-05\n",
      "Epoch 735/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8861e-05 - val_loss: 3.3772e-05\n",
      "Epoch 736/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9195e-05 - val_loss: 3.2611e-05\n",
      "Epoch 737/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9741e-05 - val_loss: 3.1680e-05\n",
      "Epoch 738/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9466e-05 - val_loss: 3.3414e-05\n",
      "Epoch 739/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8841e-05 - val_loss: 3.1893e-05\n",
      "Epoch 740/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9044e-05 - val_loss: 3.1634e-05\n",
      "Epoch 741/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9634e-05 - val_loss: 3.1836e-05\n",
      "Epoch 742/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8833e-05 - val_loss: 3.1519e-05\n",
      "Epoch 743/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8907e-05 - val_loss: 3.5092e-05\n",
      "Epoch 744/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9336e-05 - val_loss: 3.1453e-05\n",
      "Epoch 745/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9037e-05 - val_loss: 3.1671e-05\n",
      "Epoch 746/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8249e-05 - val_loss: 3.1455e-05\n",
      "Epoch 747/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8395e-05 - val_loss: 3.1960e-05\n",
      "Epoch 748/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.1073e-05 - val_loss: 3.6369e-05\n",
      "Epoch 749/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0306e-05 - val_loss: 3.2864e-05\n",
      "Epoch 750/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9017e-05 - val_loss: 3.1540e-05\n",
      "Epoch 751/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9411e-05 - val_loss: 3.3451e-05\n",
      "Epoch 752/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9273e-05 - val_loss: 3.1944e-05\n",
      "Epoch 753/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8610e-05 - val_loss: 3.2756e-05\n",
      "Epoch 754/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8315e-05 - val_loss: 3.2505e-05\n",
      "Epoch 755/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8540e-05 - val_loss: 3.1924e-05\n",
      "Epoch 756/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8976e-05 - val_loss: 3.1529e-05\n",
      "Epoch 757/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8685e-05 - val_loss: 3.3194e-05\n",
      "Epoch 758/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8425e-05 - val_loss: 4.9817e-05\n",
      "Epoch 759/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 9.1474e-05 - val_loss: 3.1793e-05\n",
      "Epoch 760/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8558e-05 - val_loss: 3.1520e-05\n",
      "Epoch 761/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8191e-05 - val_loss: 3.1523e-05\n",
      "Epoch 762/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8381e-05 - val_loss: 3.3211e-05\n",
      "Epoch 763/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8255e-05 - val_loss: 3.1936e-05\n",
      "Epoch 764/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9635e-05 - val_loss: 3.1591e-05\n",
      "Epoch 765/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.9263e-05 - val_loss: 3.4385e-05\n",
      "Epoch 766/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.9001e-05 - val_loss: 3.1521e-05\n",
      "Epoch 767/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8648e-05 - val_loss: 3.2312e-05\n",
      "Epoch 768/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8454e-05 - val_loss: 3.1494e-05\n",
      "Epoch 769/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9279e-05 - val_loss: 3.1536e-05\n",
      "Epoch 770/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9104e-05 - val_loss: 3.1491e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 771/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9217e-05 - val_loss: 3.1459e-05\n",
      "Epoch 772/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8787e-05 - val_loss: 3.3401e-05\n",
      "Epoch 773/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9022e-05 - val_loss: 3.3883e-05\n",
      "Epoch 774/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8573e-05 - val_loss: 3.3620e-05\n",
      "Epoch 775/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9578e-05 - val_loss: 3.1508e-05\n",
      "Epoch 776/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8954e-05 - val_loss: 3.1779e-05\n",
      "Epoch 777/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8178e-05 - val_loss: 3.1649e-05\n",
      "Epoch 778/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9043e-05 - val_loss: 3.1505e-05\n",
      "Epoch 779/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9197e-05 - val_loss: 3.6953e-05\n",
      "Epoch 780/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.1229e-05 - val_loss: 3.1464e-05\n",
      "Epoch 781/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9584e-05 - val_loss: 3.2659e-05\n",
      "Epoch 782/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9588e-05 - val_loss: 3.2116e-05\n",
      "Epoch 783/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8375e-05 - val_loss: 3.4008e-05\n",
      "Epoch 784/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.1319e-05 - val_loss: 3.8228e-05\n",
      "Epoch 785/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0091e-05 - val_loss: 3.1487e-05\n",
      "Epoch 786/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8171e-05 - val_loss: 3.1723e-05\n",
      "Epoch 787/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8723e-05 - val_loss: 3.7899e-05\n",
      "Epoch 788/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9512e-05 - val_loss: 3.2860e-05\n",
      "Epoch 789/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9452e-05 - val_loss: 3.3741e-05\n",
      "Epoch 790/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9079e-05 - val_loss: 3.2130e-05\n",
      "Epoch 791/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8953e-05 - val_loss: 3.3349e-05\n",
      "Epoch 792/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0630e-05 - val_loss: 3.1519e-05\n",
      "Epoch 793/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8828e-05 - val_loss: 3.1478e-05\n",
      "Epoch 794/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9234e-05 - val_loss: 3.3039e-05\n",
      "Epoch 795/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8318e-05 - val_loss: 3.1522e-05\n",
      "Epoch 796/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 8.8427e-05 - val_loss: 3.6488e-05\n",
      "Epoch 797/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8863e-05 - val_loss: 3.2361e-05\n",
      "Epoch 798/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8529e-05 - val_loss: 3.2005e-05\n",
      "Epoch 799/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8406e-05 - val_loss: 3.1631e-05\n",
      "Epoch 800/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8668e-05 - val_loss: 3.4403e-05\n",
      "Epoch 801/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.1609e-05 - val_loss: 3.8089e-05\n",
      "Epoch 802/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8242e-05 - val_loss: 3.1653e-05\n",
      "Epoch 803/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8555e-05 - val_loss: 3.1568e-05\n",
      "Epoch 804/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8631e-05 - val_loss: 3.1504e-05\n",
      "Epoch 805/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8552e-05 - val_loss: 3.1917e-05\n",
      "Epoch 806/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8812e-05 - val_loss: 3.3739e-05\n",
      "Epoch 807/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8452e-05 - val_loss: 3.1731e-05\n",
      "Epoch 808/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8973e-05 - val_loss: 3.1573e-05\n",
      "Epoch 809/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8771e-05 - val_loss: 3.2386e-05\n",
      "Epoch 810/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8932e-05 - val_loss: 3.5333e-05\n",
      "Epoch 811/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0446e-05 - val_loss: 3.4642e-05\n",
      "Epoch 812/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9616e-05 - val_loss: 3.1854e-05\n",
      "Epoch 813/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8629e-05 - val_loss: 3.2700e-05\n",
      "Epoch 814/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8964e-05 - val_loss: 3.3020e-05\n",
      "Epoch 815/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8437e-05 - val_loss: 3.2213e-05\n",
      "Epoch 816/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8826e-05 - val_loss: 3.2769e-05\n",
      "Epoch 817/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.9119e-05 - val_loss: 3.2037e-05\n",
      "Epoch 818/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8387e-05 - val_loss: 3.1657e-05\n",
      "Epoch 819/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 8.9786e-05 - val_loss: 3.2182e-05\n",
      "Epoch 820/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 8.8403e-05 - val_loss: 3.1776e-05\n",
      "Epoch 821/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9863e-05 - val_loss: 3.9831e-05\n",
      "Epoch 822/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9795e-05 - val_loss: 3.2696e-05\n",
      "Epoch 823/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8779e-05 - val_loss: 3.2933e-05\n",
      "Epoch 824/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8834e-05 - val_loss: 3.1684e-05\n",
      "Epoch 825/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8407e-05 - val_loss: 3.2431e-05\n",
      "Epoch 826/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8996e-05 - val_loss: 3.1461e-05\n",
      "Epoch 827/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8721e-05 - val_loss: 3.2903e-05\n",
      "Epoch 828/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8774e-05 - val_loss: 3.1755e-05\n",
      "Epoch 829/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8531e-05 - val_loss: 3.4468e-05\n",
      "Epoch 830/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8258e-05 - val_loss: 3.3964e-05\n",
      "Epoch 831/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9053e-05 - val_loss: 3.2778e-05\n",
      "Epoch 832/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.9268e-05 - val_loss: 3.1506e-05\n",
      "Epoch 833/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 8.8422e-05 - val_loss: 3.1812e-05\n",
      "Epoch 834/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8612e-05 - val_loss: 3.4911e-05\n",
      "Epoch 835/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 9.0359e-05 - val_loss: 3.1774e-05\n",
      "Epoch 836/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0694e-05 - val_loss: 3.1453e-05\n",
      "Epoch 837/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0075e-05 - val_loss: 3.3060e-05\n",
      "Epoch 838/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8941e-05 - val_loss: 3.1479e-05\n",
      "Epoch 839/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8876e-05 - val_loss: 3.3253e-05\n",
      "Epoch 840/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8688e-05 - val_loss: 3.9701e-05\n",
      "Epoch 841/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.1452e-05 - val_loss: 3.1679e-05\n",
      "Epoch 842/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8460e-05 - val_loss: 3.1674e-05\n",
      "Epoch 843/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8982e-05 - val_loss: 3.1515e-05\n",
      "Epoch 844/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8166e-05 - val_loss: 3.2427e-05\n",
      "Epoch 845/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8646e-05 - val_loss: 3.1457e-05\n",
      "Epoch 846/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0123e-05 - val_loss: 3.1557e-05\n",
      "Epoch 847/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 8.8089e-05 - val_loss: 3.1454e-05\n",
      "Epoch 848/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 8.9232e-05 - val_loss: 3.3004e-05\n",
      "Epoch 849/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.9278e-05 - val_loss: 3.1546e-05\n",
      "Epoch 850/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.9426e-05 - val_loss: 3.3302e-05\n",
      "Epoch 851/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 8.8502e-05 - val_loss: 3.1680e-05\n",
      "Epoch 852/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 9.0154e-05 - val_loss: 3.1503e-05\n",
      "Epoch 853/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8763e-05 - val_loss: 3.4923e-05\n",
      "Epoch 854/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9633e-05 - val_loss: 3.1675e-05\n",
      "Epoch 855/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9388e-05 - val_loss: 3.4569e-05\n",
      "Epoch 856/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9358e-05 - val_loss: 3.2939e-05\n",
      "Epoch 857/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8339e-05 - val_loss: 3.2181e-05\n",
      "Epoch 858/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8214e-05 - val_loss: 3.3046e-05\n",
      "Epoch 859/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8447e-05 - val_loss: 3.1455e-05\n",
      "Epoch 860/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0333e-05 - val_loss: 3.4612e-05\n",
      "Epoch 861/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8278e-05 - val_loss: 3.1884e-05\n",
      "Epoch 862/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8898e-05 - val_loss: 3.1851e-05\n",
      "Epoch 863/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8233e-05 - val_loss: 3.1508e-05\n",
      "Epoch 864/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8984e-05 - val_loss: 3.1509e-05\n",
      "Epoch 865/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9148e-05 - val_loss: 3.1465e-05\n",
      "Epoch 866/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9075e-05 - val_loss: 3.1515e-05\n",
      "Epoch 867/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9119e-05 - val_loss: 4.3189e-05\n",
      "Epoch 868/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9065e-05 - val_loss: 3.1458e-05\n",
      "Epoch 869/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8103e-05 - val_loss: 3.2173e-05\n",
      "Epoch 870/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8534e-05 - val_loss: 3.2756e-05\n",
      "Epoch 871/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 9.0296e-05 - val_loss: 3.2342e-05\n",
      "Epoch 872/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8574e-05 - val_loss: 3.2156e-05\n",
      "Epoch 873/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8270e-05 - val_loss: 3.1703e-05\n",
      "Epoch 874/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8932e-05 - val_loss: 3.4074e-05\n",
      "Epoch 875/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0159e-05 - val_loss: 3.2715e-05\n",
      "Epoch 876/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9178e-05 - val_loss: 3.1511e-05\n",
      "Epoch 877/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9271e-05 - val_loss: 3.1817e-05\n",
      "Epoch 878/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8837e-05 - val_loss: 3.1520e-05\n",
      "Epoch 879/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8754e-05 - val_loss: 3.1538e-05\n",
      "Epoch 880/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9018e-05 - val_loss: 3.1620e-05\n",
      "Epoch 881/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9966e-05 - val_loss: 3.2669e-05\n",
      "Epoch 882/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9846e-05 - val_loss: 3.3750e-05\n",
      "Epoch 883/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9875e-05 - val_loss: 3.4909e-05\n",
      "Epoch 884/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9265e-05 - val_loss: 3.2414e-05\n",
      "Epoch 885/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9218e-05 - val_loss: 3.1601e-05\n",
      "Epoch 886/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8742e-05 - val_loss: 3.1454e-05\n",
      "Epoch 887/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 9.0249e-05 - val_loss: 3.2721e-05\n",
      "Epoch 888/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9026e-05 - val_loss: 3.1535e-05\n",
      "Epoch 889/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9479e-05 - val_loss: 3.1859e-05\n",
      "Epoch 890/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0648e-05 - val_loss: 3.1485e-05\n",
      "Epoch 891/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8645e-05 - val_loss: 3.2216e-05\n",
      "Epoch 892/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8337e-05 - val_loss: 3.1856e-05\n",
      "Epoch 893/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8876e-05 - val_loss: 3.3392e-05\n",
      "Epoch 894/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8826e-05 - val_loss: 3.2208e-05\n",
      "Epoch 895/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0652e-05 - val_loss: 3.1967e-05\n",
      "Epoch 896/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0049e-05 - val_loss: 3.2241e-05\n",
      "Epoch 897/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8569e-05 - val_loss: 3.1988e-05\n",
      "Epoch 898/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.2163e-05 - val_loss: 3.1467e-05\n",
      "Epoch 899/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9270e-05 - val_loss: 3.2051e-05\n",
      "Epoch 900/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8028e-05 - val_loss: 3.4207e-05\n",
      "Epoch 901/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9271e-05 - val_loss: 3.1459e-05\n",
      "Epoch 902/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8962e-05 - val_loss: 3.1624e-05\n",
      "Epoch 903/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9290e-05 - val_loss: 3.1983e-05\n",
      "Epoch 904/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.9048e-05 - val_loss: 3.1468e-05\n",
      "Epoch 905/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 8.8675e-05 - val_loss: 3.4229e-05\n",
      "Epoch 906/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 9.0587e-05 - val_loss: 3.2481e-05\n",
      "Epoch 907/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 8.9071e-05 - val_loss: 3.1534e-05\n",
      "Epoch 908/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8611e-05 - val_loss: 3.1467e-05\n",
      "Epoch 909/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8654e-05 - val_loss: 3.4394e-05\n",
      "Epoch 910/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8692e-05 - val_loss: 3.1476e-05\n",
      "Epoch 911/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9365e-05 - val_loss: 3.2399e-05\n",
      "Epoch 912/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9334e-05 - val_loss: 3.1471e-05\n",
      "Epoch 913/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.9381e-05 - val_loss: 3.3974e-05\n",
      "Epoch 914/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8870e-05 - val_loss: 3.5829e-05\n",
      "Epoch 915/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0163e-05 - val_loss: 3.9708e-05\n",
      "Epoch 916/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9282e-05 - val_loss: 3.2815e-05\n",
      "Epoch 917/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 9.0103e-05 - val_loss: 3.1456e-05\n",
      "Epoch 918/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.9171e-05 - val_loss: 3.1775e-05\n",
      "Epoch 919/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8394e-05 - val_loss: 3.4850e-05\n",
      "Epoch 920/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9433e-05 - val_loss: 3.2575e-05\n",
      "Epoch 921/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 9.1909e-05 - val_loss: 3.1622e-05\n",
      "Epoch 922/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9228e-05 - val_loss: 3.2225e-05\n",
      "Epoch 923/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8296e-05 - val_loss: 3.4918e-05\n",
      "Epoch 924/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0358e-05 - val_loss: 3.2781e-05\n",
      "Epoch 925/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9539e-05 - val_loss: 3.4485e-05\n",
      "Epoch 926/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9599e-05 - val_loss: 3.5786e-05\n",
      "Epoch 927/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 9.0765e-05 - val_loss: 3.1950e-05\n",
      "Epoch 928/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8584e-05 - val_loss: 3.2668e-05\n",
      "Epoch 929/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0414e-05 - val_loss: 3.6100e-05\n",
      "Epoch 930/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8495e-05 - val_loss: 3.1514e-05\n",
      "Epoch 931/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8838e-05 - val_loss: 3.3128e-05\n",
      "Epoch 932/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9115e-05 - val_loss: 4.0490e-05\n",
      "Epoch 933/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 9.1794e-05 - val_loss: 3.3310e-05\n",
      "Epoch 934/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0400e-05 - val_loss: 4.0899e-05\n",
      "Epoch 935/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.9233e-05 - val_loss: 3.1483e-05\n",
      "Epoch 936/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9713e-05 - val_loss: 3.9454e-05\n",
      "Epoch 937/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0716e-05 - val_loss: 3.1613e-05\n",
      "Epoch 938/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8718e-05 - val_loss: 3.8514e-05\n",
      "Epoch 939/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0449e-05 - val_loss: 3.4682e-05\n",
      "Epoch 940/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8649e-05 - val_loss: 3.4369e-05\n",
      "Epoch 941/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9210e-05 - val_loss: 3.2969e-05\n",
      "Epoch 942/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9159e-05 - val_loss: 3.1989e-05\n",
      "Epoch 943/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 8.8934e-05 - val_loss: 3.2375e-05\n",
      "Epoch 944/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8968e-05 - val_loss: 3.2380e-05\n",
      "Epoch 945/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 9.0091e-05 - val_loss: 3.1456e-05\n",
      "Epoch 946/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0269e-05 - val_loss: 3.4677e-05\n",
      "Epoch 947/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0510e-05 - val_loss: 3.2116e-05\n",
      "Epoch 948/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9659e-05 - val_loss: 3.1564e-05\n",
      "Epoch 949/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8481e-05 - val_loss: 3.1949e-05\n",
      "Epoch 950/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8920e-05 - val_loss: 3.4223e-05\n",
      "Epoch 951/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8498e-05 - val_loss: 3.1470e-05\n",
      "Epoch 952/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8567e-05 - val_loss: 3.1521e-05\n",
      "Epoch 953/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8810e-05 - val_loss: 3.1455e-05\n",
      "Epoch 954/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8844e-05 - val_loss: 3.1581e-05\n",
      "Epoch 955/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0265e-05 - val_loss: 3.2369e-05\n",
      "Epoch 956/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 8.8153e-05 - val_loss: 3.3324e-05\n",
      "Epoch 957/2000\n",
      "21471/21471 [==============================] - 0s 23us/step - loss: 8.8538e-05 - val_loss: 3.1995e-05\n",
      "Epoch 958/2000\n",
      "21471/21471 [==============================] - 0s 23us/step - loss: 8.8370e-05 - val_loss: 3.3190e-05\n",
      "Epoch 959/2000\n",
      "21471/21471 [==============================] - 0s 23us/step - loss: 8.8980e-05 - val_loss: 3.3487e-05\n",
      "Epoch 960/2000\n",
      "21471/21471 [==============================] - 1s 23us/step - loss: 8.9466e-05 - val_loss: 3.2140e-05\n",
      "Epoch 961/2000\n",
      "21471/21471 [==============================] - 0s 23us/step - loss: 8.9718e-05 - val_loss: 3.1460e-05\n",
      "Epoch 962/2000\n",
      "21471/21471 [==============================] - 0s 23us/step - loss: 8.8809e-05 - val_loss: 3.1621e-05\n",
      "Epoch 963/2000\n",
      "21471/21471 [==============================] - 1s 23us/step - loss: 8.8635e-05 - val_loss: 3.1854e-05\n",
      "Epoch 964/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.9028e-05 - val_loss: 3.1457e-05\n",
      "Epoch 965/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8222e-05 - val_loss: 3.2303e-05\n",
      "Epoch 966/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9680e-05 - val_loss: 3.2349e-05\n",
      "Epoch 967/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.9512e-05 - val_loss: 3.1482e-05\n",
      "Epoch 968/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8728e-05 - val_loss: 3.3176e-05\n",
      "Epoch 969/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9366e-05 - val_loss: 3.2073e-05\n",
      "Epoch 970/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8428e-05 - val_loss: 3.3001e-05\n",
      "Epoch 971/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8850e-05 - val_loss: 4.0854e-05\n",
      "Epoch 972/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 9.0334e-05 - val_loss: 3.2805e-05\n",
      "Epoch 973/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8575e-05 - val_loss: 3.1468e-05\n",
      "Epoch 974/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9259e-05 - val_loss: 3.1597e-05\n",
      "Epoch 975/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9800e-05 - val_loss: 3.2290e-05\n",
      "Epoch 976/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8608e-05 - val_loss: 3.1454e-05\n",
      "Epoch 977/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8596e-05 - val_loss: 3.1470e-05\n",
      "Epoch 978/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 8.9743e-05 - val_loss: 3.1650e-05\n",
      "Epoch 979/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 8.8416e-05 - val_loss: 3.1620e-05\n",
      "Epoch 980/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8669e-05 - val_loss: 3.8299e-05\n",
      "Epoch 981/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9633e-05 - val_loss: 3.2722e-05\n",
      "Epoch 982/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8625e-05 - val_loss: 3.1596e-05\n",
      "Epoch 983/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9507e-05 - val_loss: 3.1861e-05\n",
      "Epoch 984/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8950e-05 - val_loss: 3.1821e-05\n",
      "Epoch 985/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0599e-05 - val_loss: 3.1483e-05\n",
      "Epoch 986/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9345e-05 - val_loss: 3.1900e-05\n",
      "Epoch 987/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9519e-05 - val_loss: 3.1462e-05\n",
      "Epoch 988/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9347e-05 - val_loss: 3.2853e-05\n",
      "Epoch 989/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9047e-05 - val_loss: 3.1454e-05\n",
      "Epoch 990/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9447e-05 - val_loss: 3.1460e-05\n",
      "Epoch 991/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 9.1442e-05 - val_loss: 3.1500e-05\n",
      "Epoch 992/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8496e-05 - val_loss: 3.1912e-05\n",
      "Epoch 993/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9524e-05 - val_loss: 3.3532e-05\n",
      "Epoch 994/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8816e-05 - val_loss: 3.1670e-05\n",
      "Epoch 995/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.9214e-05 - val_loss: 3.1753e-05\n",
      "Epoch 996/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.9328e-05 - val_loss: 3.1639e-05\n",
      "Epoch 997/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9007e-05 - val_loss: 3.1463e-05\n",
      "Epoch 998/2000\n",
      "21471/21471 [==============================] - 0s 23us/step - loss: 8.9243e-05 - val_loss: 3.2130e-05\n",
      "Epoch 999/2000\n",
      "21471/21471 [==============================] - 1s 24us/step - loss: 8.8464e-05 - val_loss: 3.9987e-05\n",
      "Epoch 1000/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.9590e-05 - val_loss: 3.1476e-05\n",
      "Epoch 1001/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8127e-05 - val_loss: 3.3358e-05\n",
      "Epoch 1002/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8675e-05 - val_loss: 3.3272e-05\n",
      "Epoch 1003/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9001e-05 - val_loss: 3.1701e-05\n",
      "Epoch 1004/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8117e-05 - val_loss: 3.1458e-05\n",
      "Epoch 1005/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8590e-05 - val_loss: 3.3418e-05\n",
      "Epoch 1006/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9273e-05 - val_loss: 3.3391e-05\n",
      "Epoch 1007/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9766e-05 - val_loss: 3.1457e-05\n",
      "Epoch 1008/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8567e-05 - val_loss: 3.1931e-05\n",
      "Epoch 1009/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8642e-05 - val_loss: 3.4204e-05\n",
      "Epoch 1010/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8907e-05 - val_loss: 3.1747e-05\n",
      "Epoch 1011/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9348e-05 - val_loss: 3.4310e-05\n",
      "Epoch 1012/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0009e-05 - val_loss: 3.4981e-05\n",
      "Epoch 1013/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8804e-05 - val_loss: 3.1540e-05\n",
      "Epoch 1014/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9096e-05 - val_loss: 3.2064e-05\n",
      "Epoch 1015/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 8.8199e-05 - val_loss: 3.3571e-05\n",
      "Epoch 1016/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8538e-05 - val_loss: 3.1783e-05\n",
      "Epoch 1017/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9027e-05 - val_loss: 3.1629e-05\n",
      "Epoch 1018/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9567e-05 - val_loss: 3.1543e-05\n",
      "Epoch 1019/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8276e-05 - val_loss: 3.2627e-05\n",
      "Epoch 1020/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8961e-05 - val_loss: 3.3252e-05\n",
      "Epoch 1021/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8593e-05 - val_loss: 3.5413e-05\n",
      "Epoch 1022/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0016e-05 - val_loss: 3.1464e-05\n",
      "Epoch 1023/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9064e-05 - val_loss: 3.1771e-05\n",
      "Epoch 1024/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0140e-05 - val_loss: 3.1988e-05\n",
      "Epoch 1025/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8564e-05 - val_loss: 3.2802e-05\n",
      "Epoch 1026/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9305e-05 - val_loss: 3.1605e-05\n",
      "Epoch 1027/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8589e-05 - val_loss: 3.1739e-05\n",
      "Epoch 1028/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8531e-05 - val_loss: 3.2227e-05\n",
      "Epoch 1029/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8503e-05 - val_loss: 3.2248e-05\n",
      "Epoch 1030/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8531e-05 - val_loss: 3.4184e-05\n",
      "Epoch 1031/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9536e-05 - val_loss: 3.1599e-05\n",
      "Epoch 1032/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8665e-05 - val_loss: 3.3284e-05\n",
      "Epoch 1033/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8730e-05 - val_loss: 3.1502e-05\n",
      "Epoch 1034/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9010e-05 - val_loss: 3.2877e-05\n",
      "Epoch 1035/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8347e-05 - val_loss: 3.1455e-05\n",
      "Epoch 1036/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9025e-05 - val_loss: 3.3652e-05\n",
      "Epoch 1037/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9129e-05 - val_loss: 3.1595e-05\n",
      "Epoch 1038/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8610e-05 - val_loss: 3.4112e-05\n",
      "Epoch 1039/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 8.9350e-05 - val_loss: 3.1474e-05\n",
      "Epoch 1040/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 8.8781e-05 - val_loss: 3.1740e-05\n",
      "Epoch 1041/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 8.8568e-05 - val_loss: 3.1457e-05\n",
      "Epoch 1042/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8273e-05 - val_loss: 3.1714e-05\n",
      "Epoch 1043/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9249e-05 - val_loss: 3.1565e-05\n",
      "Epoch 1044/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0986e-05 - val_loss: 3.2608e-05\n",
      "Epoch 1045/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8779e-05 - val_loss: 3.3574e-05\n",
      "Epoch 1046/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.9129e-05 - val_loss: 3.1512e-05\n",
      "Epoch 1047/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8963e-05 - val_loss: 3.1458e-05\n",
      "Epoch 1048/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8802e-05 - val_loss: 3.1723e-05\n",
      "Epoch 1049/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8833e-05 - val_loss: 3.2152e-05\n",
      "Epoch 1050/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8560e-05 - val_loss: 3.1795e-05\n",
      "Epoch 1051/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 8.9101e-05 - val_loss: 3.1501e-05\n",
      "Epoch 1052/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 8.8748e-05 - val_loss: 3.1601e-05\n",
      "Epoch 1053/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8927e-05 - val_loss: 3.1457e-05\n",
      "Epoch 1054/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8513e-05 - val_loss: 3.2756e-05\n",
      "Epoch 1055/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8510e-05 - val_loss: 3.1536e-05\n",
      "Epoch 1056/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9044e-05 - val_loss: 3.2180e-05\n",
      "Epoch 1057/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8848e-05 - val_loss: 3.4682e-05\n",
      "Epoch 1058/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9466e-05 - val_loss: 3.1476e-05\n",
      "Epoch 1059/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0012e-05 - val_loss: 3.2092e-05\n",
      "Epoch 1060/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8321e-05 - val_loss: 3.2155e-05\n",
      "Epoch 1061/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8915e-05 - val_loss: 3.1626e-05\n",
      "Epoch 1062/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8669e-05 - val_loss: 3.1890e-05\n",
      "Epoch 1063/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8667e-05 - val_loss: 3.1766e-05\n",
      "Epoch 1064/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8704e-05 - val_loss: 3.1850e-05\n",
      "Epoch 1065/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8369e-05 - val_loss: 3.1466e-05\n",
      "Epoch 1066/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8858e-05 - val_loss: 3.1682e-05\n",
      "Epoch 1067/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9026e-05 - val_loss: 3.1499e-05\n",
      "Epoch 1068/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9130e-05 - val_loss: 3.1515e-05\n",
      "Epoch 1069/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8528e-05 - val_loss: 4.0125e-05\n",
      "Epoch 1070/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0530e-05 - val_loss: 3.1677e-05\n",
      "Epoch 1071/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9798e-05 - val_loss: 3.1635e-05\n",
      "Epoch 1072/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8522e-05 - val_loss: 3.3404e-05\n",
      "Epoch 1073/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9561e-05 - val_loss: 3.2503e-05\n",
      "Epoch 1074/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8928e-05 - val_loss: 3.1835e-05\n",
      "Epoch 1075/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8164e-05 - val_loss: 3.1488e-05\n",
      "Epoch 1076/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8381e-05 - val_loss: 3.1462e-05\n",
      "Epoch 1077/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8899e-05 - val_loss: 3.3362e-05\n",
      "Epoch 1078/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8916e-05 - val_loss: 3.1561e-05\n",
      "Epoch 1079/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9192e-05 - val_loss: 3.8391e-05\n",
      "Epoch 1080/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.2686e-05 - val_loss: 3.4398e-05\n",
      "Epoch 1081/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9131e-05 - val_loss: 3.2906e-05\n",
      "Epoch 1082/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8814e-05 - val_loss: 3.1744e-05\n",
      "Epoch 1083/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8755e-05 - val_loss: 3.3149e-05\n",
      "Epoch 1084/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8920e-05 - val_loss: 3.1719e-05\n",
      "Epoch 1085/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8186e-05 - val_loss: 3.4277e-05\n",
      "Epoch 1086/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8988e-05 - val_loss: 3.2310e-05\n",
      "Epoch 1087/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8681e-05 - val_loss: 3.1609e-05\n",
      "Epoch 1088/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.9039e-05 - val_loss: 3.4298e-05\n",
      "Epoch 1089/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 8.8865e-05 - val_loss: 3.1475e-05\n",
      "Epoch 1090/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9029e-05 - val_loss: 3.1457e-05\n",
      "Epoch 1091/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9324e-05 - val_loss: 3.1580e-05\n",
      "Epoch 1092/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9770e-05 - val_loss: 3.4987e-05\n",
      "Epoch 1093/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9546e-05 - val_loss: 3.3963e-05\n",
      "Epoch 1094/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9015e-05 - val_loss: 3.2327e-05\n",
      "Epoch 1095/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9224e-05 - val_loss: 3.2653e-05\n",
      "Epoch 1096/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.1349e-05 - val_loss: 3.1595e-05\n",
      "Epoch 1097/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8847e-05 - val_loss: 3.1458e-05\n",
      "Epoch 1098/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8313e-05 - val_loss: 3.4133e-05\n",
      "Epoch 1099/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9162e-05 - val_loss: 3.7227e-05\n",
      "Epoch 1100/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.1577e-05 - val_loss: 3.1525e-05\n",
      "Epoch 1101/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8235e-05 - val_loss: 3.2115e-05\n",
      "Epoch 1102/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8987e-05 - val_loss: 3.1563e-05\n",
      "Epoch 1103/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8799e-05 - val_loss: 3.3396e-05\n",
      "Epoch 1104/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8646e-05 - val_loss: 3.1476e-05\n",
      "Epoch 1105/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8715e-05 - val_loss: 3.2234e-05\n",
      "Epoch 1106/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8935e-05 - val_loss: 3.3325e-05\n",
      "Epoch 1107/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0758e-05 - val_loss: 3.2255e-05\n",
      "Epoch 1108/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8589e-05 - val_loss: 3.3999e-05\n",
      "Epoch 1109/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8760e-05 - val_loss: 3.1606e-05\n",
      "Epoch 1110/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 8.8080e-05 - val_loss: 3.1698e-05\n",
      "Epoch 1111/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8361e-05 - val_loss: 3.1579e-05\n",
      "Epoch 1112/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8593e-05 - val_loss: 3.1777e-05\n",
      "Epoch 1113/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8393e-05 - val_loss: 3.1569e-05\n",
      "Epoch 1114/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8743e-05 - val_loss: 3.1456e-05\n",
      "Epoch 1115/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9319e-05 - val_loss: 3.1656e-05\n",
      "Epoch 1116/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8628e-05 - val_loss: 3.1455e-05\n",
      "Epoch 1117/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8405e-05 - val_loss: 3.2651e-05\n",
      "Epoch 1118/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9234e-05 - val_loss: 3.1758e-05\n",
      "Epoch 1119/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9155e-05 - val_loss: 3.1482e-05\n",
      "Epoch 1120/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8382e-05 - val_loss: 3.1560e-05\n",
      "Epoch 1121/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8412e-05 - val_loss: 3.1774e-05\n",
      "Epoch 1122/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8299e-05 - val_loss: 3.1573e-05\n",
      "Epoch 1123/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8440e-05 - val_loss: 3.2814e-05\n",
      "Epoch 1124/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8999e-05 - val_loss: 3.1699e-05\n",
      "Epoch 1125/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0182e-05 - val_loss: 3.1665e-05\n",
      "Epoch 1126/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 8.8880e-05 - val_loss: 3.1541e-05\n",
      "Epoch 1127/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.9314e-05 - val_loss: 3.2912e-05\n",
      "Epoch 1128/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9860e-05 - val_loss: 3.2117e-05\n",
      "Epoch 1129/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8853e-05 - val_loss: 3.1635e-05\n",
      "Epoch 1130/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9229e-05 - val_loss: 3.1865e-05\n",
      "Epoch 1131/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8842e-05 - val_loss: 3.1455e-05\n",
      "Epoch 1132/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8615e-05 - val_loss: 3.3423e-05\n",
      "Epoch 1133/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9378e-05 - val_loss: 3.3883e-05\n",
      "Epoch 1134/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8745e-05 - val_loss: 3.1455e-05\n",
      "Epoch 1135/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8636e-05 - val_loss: 3.1696e-05\n",
      "Epoch 1136/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8355e-05 - val_loss: 3.2243e-05\n",
      "Epoch 1137/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8143e-05 - val_loss: 3.4106e-05\n",
      "Epoch 1138/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9431e-05 - val_loss: 3.1538e-05\n",
      "Epoch 1139/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8776e-05 - val_loss: 3.1467e-05\n",
      "Epoch 1140/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8640e-05 - val_loss: 3.3267e-05\n",
      "Epoch 1141/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8323e-05 - val_loss: 3.1806e-05\n",
      "Epoch 1142/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8614e-05 - val_loss: 3.1474e-05\n",
      "Epoch 1143/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9578e-05 - val_loss: 3.3591e-05\n",
      "Epoch 1144/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8415e-05 - val_loss: 3.1538e-05\n",
      "Epoch 1145/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9778e-05 - val_loss: 3.1520e-05\n",
      "Epoch 1146/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9416e-05 - val_loss: 3.2556e-05\n",
      "Epoch 1147/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9184e-05 - val_loss: 3.1762e-05\n",
      "Epoch 1148/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9067e-05 - val_loss: 3.1613e-05\n",
      "Epoch 1149/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9477e-05 - val_loss: 3.5844e-05\n",
      "Epoch 1150/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.9454e-05 - val_loss: 3.2607e-05\n",
      "Epoch 1151/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9519e-05 - val_loss: 3.1719e-05\n",
      "Epoch 1152/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8911e-05 - val_loss: 3.1485e-05\n",
      "Epoch 1153/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8285e-05 - val_loss: 3.1847e-05\n",
      "Epoch 1154/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0198e-05 - val_loss: 3.1459e-05\n",
      "Epoch 1155/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8795e-05 - val_loss: 3.3677e-05\n",
      "Epoch 1156/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8464e-05 - val_loss: 3.1514e-05\n",
      "Epoch 1157/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8533e-05 - val_loss: 3.2125e-05\n",
      "Epoch 1158/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8472e-05 - val_loss: 3.1964e-05\n",
      "Epoch 1159/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9177e-05 - val_loss: 3.1713e-05\n",
      "Epoch 1160/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9132e-05 - val_loss: 3.2411e-05\n",
      "Epoch 1161/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8879e-05 - val_loss: 3.2539e-05\n",
      "Epoch 1162/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9233e-05 - val_loss: 3.2409e-05\n",
      "Epoch 1163/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 9.0300e-05 - val_loss: 3.1605e-05\n",
      "Epoch 1164/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8714e-05 - val_loss: 3.1958e-05\n",
      "Epoch 1165/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8690e-05 - val_loss: 3.3182e-05\n",
      "Epoch 1166/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0931e-05 - val_loss: 3.3975e-05\n",
      "Epoch 1167/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9565e-05 - val_loss: 3.7159e-05\n",
      "Epoch 1168/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9850e-05 - val_loss: 3.3147e-05\n",
      "Epoch 1169/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9200e-05 - val_loss: 3.1797e-05\n",
      "Epoch 1170/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8946e-05 - val_loss: 3.1590e-05\n",
      "Epoch 1171/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8352e-05 - val_loss: 3.1646e-05\n",
      "Epoch 1172/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8566e-05 - val_loss: 3.3460e-05\n",
      "Epoch 1173/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8795e-05 - val_loss: 3.2551e-05\n",
      "Epoch 1174/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8433e-05 - val_loss: 3.1929e-05\n",
      "Epoch 1175/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9106e-05 - val_loss: 3.1517e-05\n",
      "Epoch 1176/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8897e-05 - val_loss: 3.1742e-05\n",
      "Epoch 1177/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9344e-05 - val_loss: 3.1542e-05\n",
      "Epoch 1178/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9903e-05 - val_loss: 3.3596e-05\n",
      "Epoch 1179/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.9136e-05 - val_loss: 3.1979e-05\n",
      "Epoch 1180/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8644e-05 - val_loss: 3.1460e-05\n",
      "Epoch 1181/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8008e-05 - val_loss: 3.1540e-05\n",
      "Epoch 1182/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8125e-05 - val_loss: 3.1693e-05\n",
      "Epoch 1183/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8571e-05 - val_loss: 3.1901e-05\n",
      "Epoch 1184/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8923e-05 - val_loss: 3.5151e-05\n",
      "Epoch 1185/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9637e-05 - val_loss: 3.2027e-05\n",
      "Epoch 1186/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9003e-05 - val_loss: 3.2803e-05\n",
      "Epoch 1187/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0033e-05 - val_loss: 4.3657e-05\n",
      "Epoch 1188/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0825e-05 - val_loss: 3.1727e-05\n",
      "Epoch 1189/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8719e-05 - val_loss: 3.3043e-05\n",
      "Epoch 1190/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9650e-05 - val_loss: 3.1840e-05\n",
      "Epoch 1191/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8535e-05 - val_loss: 3.2708e-05\n",
      "Epoch 1192/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.1273e-05 - val_loss: 3.1560e-05\n",
      "Epoch 1193/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8674e-05 - val_loss: 3.1549e-05\n",
      "Epoch 1194/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8288e-05 - val_loss: 3.2525e-05\n",
      "Epoch 1195/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9780e-05 - val_loss: 3.1878e-05\n",
      "Epoch 1196/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8452e-05 - val_loss: 3.1538e-05\n",
      "Epoch 1197/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9440e-05 - val_loss: 3.1933e-05\n",
      "Epoch 1198/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9066e-05 - val_loss: 3.1843e-05\n",
      "Epoch 1199/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8805e-05 - val_loss: 3.7345e-05\n",
      "Epoch 1200/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.9119e-05 - val_loss: 3.2115e-05\n",
      "Epoch 1201/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8614e-05 - val_loss: 3.2265e-05\n",
      "Epoch 1202/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8912e-05 - val_loss: 3.2670e-05\n",
      "Epoch 1203/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8899e-05 - val_loss: 3.1921e-05\n",
      "Epoch 1204/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9425e-05 - val_loss: 3.1638e-05\n",
      "Epoch 1205/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9046e-05 - val_loss: 3.4935e-05\n",
      "Epoch 1206/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9379e-05 - val_loss: 3.1642e-05\n",
      "Epoch 1207/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0228e-05 - val_loss: 3.3339e-05\n",
      "Epoch 1208/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8639e-05 - val_loss: 3.1805e-05\n",
      "Epoch 1209/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0212e-05 - val_loss: 3.6459e-05\n",
      "Epoch 1210/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9631e-05 - val_loss: 3.1457e-05\n",
      "Epoch 1211/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8714e-05 - val_loss: 3.3612e-05\n",
      "Epoch 1212/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9474e-05 - val_loss: 3.5346e-05\n",
      "Epoch 1213/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8712e-05 - val_loss: 3.1461e-05\n",
      "Epoch 1214/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8112e-05 - val_loss: 3.1513e-05\n",
      "Epoch 1215/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8223e-05 - val_loss: 3.2966e-05\n",
      "Epoch 1216/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8555e-05 - val_loss: 3.1468e-05\n",
      "Epoch 1217/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8124e-05 - val_loss: 3.4101e-05\n",
      "Epoch 1218/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9664e-05 - val_loss: 4.1818e-05\n",
      "Epoch 1219/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0181e-05 - val_loss: 3.3180e-05\n",
      "Epoch 1220/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8289e-05 - val_loss: 3.3272e-05\n",
      "Epoch 1221/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9034e-05 - val_loss: 3.3058e-05\n",
      "Epoch 1222/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8577e-05 - val_loss: 3.1580e-05\n",
      "Epoch 1223/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8918e-05 - val_loss: 3.2226e-05\n",
      "Epoch 1224/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8264e-05 - val_loss: 3.1537e-05\n",
      "Epoch 1225/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9333e-05 - val_loss: 3.1545e-05\n",
      "Epoch 1226/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8473e-05 - val_loss: 3.3176e-05\n",
      "Epoch 1227/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9351e-05 - val_loss: 3.1479e-05\n",
      "Epoch 1228/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9019e-05 - val_loss: 3.4089e-05\n",
      "Epoch 1229/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0161e-05 - val_loss: 3.4231e-05\n",
      "Epoch 1230/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8975e-05 - val_loss: 3.1683e-05\n",
      "Epoch 1231/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8236e-05 - val_loss: 3.1514e-05\n",
      "Epoch 1232/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8818e-05 - val_loss: 3.1725e-05\n",
      "Epoch 1233/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8914e-05 - val_loss: 3.1511e-05\n",
      "Epoch 1234/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8979e-05 - val_loss: 3.2557e-05\n",
      "Epoch 1235/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8646e-05 - val_loss: 3.2203e-05\n",
      "Epoch 1236/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9219e-05 - val_loss: 3.1807e-05\n",
      "Epoch 1237/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 9.0350e-05 - val_loss: 3.1564e-05\n",
      "Epoch 1238/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 8.8720e-05 - val_loss: 3.1662e-05\n",
      "Epoch 1239/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8808e-05 - val_loss: 3.1620e-05\n",
      "Epoch 1240/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8895e-05 - val_loss: 3.1460e-05\n",
      "Epoch 1241/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8841e-05 - val_loss: 3.2525e-05\n",
      "Epoch 1242/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9645e-05 - val_loss: 3.2492e-05\n",
      "Epoch 1243/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8746e-05 - val_loss: 3.4257e-05\n",
      "Epoch 1244/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8347e-05 - val_loss: 3.1611e-05\n",
      "Epoch 1245/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8303e-05 - val_loss: 3.4790e-05\n",
      "Epoch 1246/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8875e-05 - val_loss: 4.1782e-05\n",
      "Epoch 1247/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 9.1281e-05 - val_loss: 3.1574e-05\n",
      "Epoch 1248/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8201e-05 - val_loss: 3.1485e-05\n",
      "Epoch 1249/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8381e-05 - val_loss: 3.1457e-05\n",
      "Epoch 1250/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8549e-05 - val_loss: 3.1601e-05\n",
      "Epoch 1251/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8743e-05 - val_loss: 3.1832e-05\n",
      "Epoch 1252/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8347e-05 - val_loss: 3.3386e-05\n",
      "Epoch 1253/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9225e-05 - val_loss: 3.5496e-05\n",
      "Epoch 1254/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8329e-05 - val_loss: 3.2142e-05\n",
      "Epoch 1255/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8351e-05 - val_loss: 3.1459e-05\n",
      "Epoch 1256/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.1309e-05 - val_loss: 3.3309e-05\n",
      "Epoch 1257/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8502e-05 - val_loss: 3.1787e-05\n",
      "Epoch 1258/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9285e-05 - val_loss: 3.2255e-05\n",
      "Epoch 1259/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9624e-05 - val_loss: 3.1847e-05\n",
      "Epoch 1260/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9346e-05 - val_loss: 3.4110e-05\n",
      "Epoch 1261/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9476e-05 - val_loss: 3.2821e-05\n",
      "Epoch 1262/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8764e-05 - val_loss: 3.3042e-05\n",
      "Epoch 1263/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8574e-05 - val_loss: 3.3540e-05\n",
      "Epoch 1264/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9032e-05 - val_loss: 3.2052e-05\n",
      "Epoch 1265/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8913e-05 - val_loss: 3.2192e-05\n",
      "Epoch 1266/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8480e-05 - val_loss: 3.1492e-05\n",
      "Epoch 1267/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8614e-05 - val_loss: 3.5535e-05\n",
      "Epoch 1268/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9342e-05 - val_loss: 3.2172e-05\n",
      "Epoch 1269/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8314e-05 - val_loss: 3.9300e-05\n",
      "Epoch 1270/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9702e-05 - val_loss: 3.2062e-05\n",
      "Epoch 1271/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9784e-05 - val_loss: 3.3916e-05\n",
      "Epoch 1272/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8993e-05 - val_loss: 3.2326e-05\n",
      "Epoch 1273/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8522e-05 - val_loss: 3.1531e-05\n",
      "Epoch 1274/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8210e-05 - val_loss: 3.3295e-05\n",
      "Epoch 1275/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 8.9312e-05 - val_loss: 3.1729e-05\n",
      "Epoch 1276/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8912e-05 - val_loss: 3.1560e-05\n",
      "Epoch 1277/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8889e-05 - val_loss: 3.2691e-05\n",
      "Epoch 1278/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8661e-05 - val_loss: 3.1553e-05\n",
      "Epoch 1279/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9248e-05 - val_loss: 3.1708e-05\n",
      "Epoch 1280/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8363e-05 - val_loss: 3.1487e-05\n",
      "Epoch 1281/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0224e-05 - val_loss: 3.1527e-05\n",
      "Epoch 1282/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9028e-05 - val_loss: 3.1756e-05\n",
      "Epoch 1283/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8551e-05 - val_loss: 3.4162e-05\n",
      "Epoch 1284/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8241e-05 - val_loss: 3.1881e-05\n",
      "Epoch 1285/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9181e-05 - val_loss: 3.1468e-05\n",
      "Epoch 1286/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8064e-05 - val_loss: 3.1550e-05\n",
      "Epoch 1287/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9610e-05 - val_loss: 3.2056e-05\n",
      "Epoch 1288/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9797e-05 - val_loss: 3.1594e-05\n",
      "Epoch 1289/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9711e-05 - val_loss: 3.5648e-05\n",
      "Epoch 1290/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9692e-05 - val_loss: 3.2871e-05\n",
      "Epoch 1291/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8269e-05 - val_loss: 3.1595e-05\n",
      "Epoch 1292/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9257e-05 - val_loss: 3.3947e-05\n",
      "Epoch 1293/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8663e-05 - val_loss: 3.1470e-05\n",
      "Epoch 1294/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8765e-05 - val_loss: 3.3793e-05\n",
      "Epoch 1295/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9270e-05 - val_loss: 3.2180e-05\n",
      "Epoch 1296/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8250e-05 - val_loss: 3.1466e-05\n",
      "Epoch 1297/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9235e-05 - val_loss: 3.3914e-05\n",
      "Epoch 1298/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0153e-05 - val_loss: 3.2003e-05\n",
      "Epoch 1299/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8650e-05 - val_loss: 3.1922e-05\n",
      "Epoch 1300/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8760e-05 - val_loss: 3.2773e-05\n",
      "Epoch 1301/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9105e-05 - val_loss: 3.1625e-05\n",
      "Epoch 1302/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8238e-05 - val_loss: 3.1456e-05\n",
      "Epoch 1303/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8590e-05 - val_loss: 3.1504e-05\n",
      "Epoch 1304/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9650e-05 - val_loss: 3.3168e-05\n",
      "Epoch 1305/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9840e-05 - val_loss: 3.3442e-05\n",
      "Epoch 1306/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8273e-05 - val_loss: 3.2367e-05\n",
      "Epoch 1307/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9113e-05 - val_loss: 3.2243e-05\n",
      "Epoch 1308/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8341e-05 - val_loss: 3.3644e-05\n",
      "Epoch 1309/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9258e-05 - val_loss: 3.1573e-05\n",
      "Epoch 1310/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9215e-05 - val_loss: 3.1485e-05\n",
      "Epoch 1311/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8556e-05 - val_loss: 3.2560e-05\n",
      "Epoch 1312/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 8.8329e-05 - val_loss: 3.1535e-05\n",
      "Epoch 1313/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8642e-05 - val_loss: 3.2051e-05\n",
      "Epoch 1314/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8616e-05 - val_loss: 3.2872e-05\n",
      "Epoch 1315/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8281e-05 - val_loss: 3.1524e-05\n",
      "Epoch 1316/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9059e-05 - val_loss: 3.1462e-05\n",
      "Epoch 1317/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9566e-05 - val_loss: 3.1830e-05\n",
      "Epoch 1318/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8337e-05 - val_loss: 3.1729e-05\n",
      "Epoch 1319/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 8.8816e-05 - val_loss: 3.2057e-05\n",
      "Epoch 1320/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8870e-05 - val_loss: 3.1554e-05\n",
      "Epoch 1321/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8882e-05 - val_loss: 3.1494e-05\n",
      "Epoch 1322/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8914e-05 - val_loss: 3.3922e-05\n",
      "Epoch 1323/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8904e-05 - val_loss: 3.2597e-05\n",
      "Epoch 1324/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9433e-05 - val_loss: 3.1841e-05\n",
      "Epoch 1325/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8852e-05 - val_loss: 3.2184e-05\n",
      "Epoch 1326/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8955e-05 - val_loss: 3.6879e-05\n",
      "Epoch 1327/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0073e-05 - val_loss: 3.2089e-05\n",
      "Epoch 1328/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8853e-05 - val_loss: 3.3259e-05\n",
      "Epoch 1329/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9111e-05 - val_loss: 3.1479e-05\n",
      "Epoch 1330/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9751e-05 - val_loss: 3.1517e-05\n",
      "Epoch 1331/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8497e-05 - val_loss: 3.2439e-05\n",
      "Epoch 1332/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0102e-05 - val_loss: 3.6362e-05\n",
      "Epoch 1333/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0515e-05 - val_loss: 3.1573e-05\n",
      "Epoch 1334/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8806e-05 - val_loss: 3.2483e-05\n",
      "Epoch 1335/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8694e-05 - val_loss: 3.1656e-05\n",
      "Epoch 1336/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0372e-05 - val_loss: 3.2078e-05\n",
      "Epoch 1337/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8753e-05 - val_loss: 3.1456e-05\n",
      "Epoch 1338/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9318e-05 - val_loss: 3.2830e-05\n",
      "Epoch 1339/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0684e-05 - val_loss: 3.4966e-05\n",
      "Epoch 1340/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9534e-05 - val_loss: 3.2054e-05\n",
      "Epoch 1341/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8849e-05 - val_loss: 3.1879e-05\n",
      "Epoch 1342/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0028e-05 - val_loss: 3.1676e-05\n",
      "Epoch 1343/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8293e-05 - val_loss: 3.1780e-05\n",
      "Epoch 1344/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8356e-05 - val_loss: 3.3151e-05\n",
      "Epoch 1345/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8372e-05 - val_loss: 3.1487e-05\n",
      "Epoch 1346/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8825e-05 - val_loss: 3.1477e-05\n",
      "Epoch 1347/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9600e-05 - val_loss: 3.1634e-05\n",
      "Epoch 1348/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8477e-05 - val_loss: 3.1946e-05\n",
      "Epoch 1349/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.9018e-05 - val_loss: 3.2462e-05\n",
      "Epoch 1350/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8382e-05 - val_loss: 3.2534e-05\n",
      "Epoch 1351/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8289e-05 - val_loss: 3.1653e-05\n",
      "Epoch 1352/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9254e-05 - val_loss: 3.6749e-05\n",
      "Epoch 1353/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0339e-05 - val_loss: 3.7312e-05\n",
      "Epoch 1354/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8979e-05 - val_loss: 3.1478e-05\n",
      "Epoch 1355/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8807e-05 - val_loss: 3.1459e-05\n",
      "Epoch 1356/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8523e-05 - val_loss: 3.2292e-05\n",
      "Epoch 1357/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8974e-05 - val_loss: 3.5275e-05\n",
      "Epoch 1358/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9813e-05 - val_loss: 3.2234e-05\n",
      "Epoch 1359/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9697e-05 - val_loss: 3.1681e-05\n",
      "Epoch 1360/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9264e-05 - val_loss: 3.1464e-05\n",
      "Epoch 1361/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9034e-05 - val_loss: 3.1790e-05\n",
      "Epoch 1362/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8731e-05 - val_loss: 3.2656e-05\n",
      "Epoch 1363/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9044e-05 - val_loss: 3.2496e-05\n",
      "Epoch 1364/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8504e-05 - val_loss: 3.1886e-05\n",
      "Epoch 1365/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8518e-05 - val_loss: 3.1873e-05\n",
      "Epoch 1366/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9097e-05 - val_loss: 3.1536e-05\n",
      "Epoch 1367/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9417e-05 - val_loss: 3.3838e-05\n",
      "Epoch 1368/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0764e-05 - val_loss: 3.1993e-05\n",
      "Epoch 1369/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8633e-05 - val_loss: 3.1497e-05\n",
      "Epoch 1370/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8659e-05 - val_loss: 3.2901e-05\n",
      "Epoch 1371/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8921e-05 - val_loss: 3.1648e-05\n",
      "Epoch 1372/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8179e-05 - val_loss: 3.1457e-05\n",
      "Epoch 1373/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9467e-05 - val_loss: 3.1627e-05\n",
      "Epoch 1374/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8758e-05 - val_loss: 3.2149e-05\n",
      "Epoch 1375/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9551e-05 - val_loss: 3.1465e-05\n",
      "Epoch 1376/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8422e-05 - val_loss: 3.1767e-05\n",
      "Epoch 1377/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8320e-05 - val_loss: 3.2391e-05\n",
      "Epoch 1378/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9222e-05 - val_loss: 3.6551e-05\n",
      "Epoch 1379/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0053e-05 - val_loss: 3.2408e-05\n",
      "Epoch 1380/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8929e-05 - val_loss: 3.1950e-05\n",
      "Epoch 1381/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8571e-05 - val_loss: 3.2912e-05\n",
      "Epoch 1382/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8780e-05 - val_loss: 3.1528e-05\n",
      "Epoch 1383/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8581e-05 - val_loss: 3.2523e-05\n",
      "Epoch 1384/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8678e-05 - val_loss: 3.1861e-05\n",
      "Epoch 1385/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9358e-05 - val_loss: 3.2152e-05\n",
      "Epoch 1386/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 8.9258e-05 - val_loss: 3.4449e-05\n",
      "Epoch 1387/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.9506e-05 - val_loss: 3.2379e-05\n",
      "Epoch 1388/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8741e-05 - val_loss: 3.4033e-05\n",
      "Epoch 1389/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8484e-05 - val_loss: 3.1513e-05\n",
      "Epoch 1390/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8562e-05 - val_loss: 3.1955e-05\n",
      "Epoch 1391/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9046e-05 - val_loss: 3.2261e-05\n",
      "Epoch 1392/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8888e-05 - val_loss: 3.2915e-05\n",
      "Epoch 1393/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9402e-05 - val_loss: 3.5961e-05\n",
      "Epoch 1394/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8514e-05 - val_loss: 3.1456e-05\n",
      "Epoch 1395/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8522e-05 - val_loss: 3.1479e-05\n",
      "Epoch 1396/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9350e-05 - val_loss: 3.2011e-05\n",
      "Epoch 1397/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9423e-05 - val_loss: 3.2854e-05\n",
      "Epoch 1398/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8765e-05 - val_loss: 3.2279e-05\n",
      "Epoch 1399/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8450e-05 - val_loss: 3.1524e-05\n",
      "Epoch 1400/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8484e-05 - val_loss: 3.4167e-05\n",
      "Epoch 1401/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0200e-05 - val_loss: 3.2466e-05\n",
      "Epoch 1402/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9897e-05 - val_loss: 3.1456e-05\n",
      "Epoch 1403/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8163e-05 - val_loss: 3.2088e-05\n",
      "Epoch 1404/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9044e-05 - val_loss: 3.1488e-05\n",
      "Epoch 1405/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9005e-05 - val_loss: 3.2697e-05\n",
      "Epoch 1406/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8472e-05 - val_loss: 3.4071e-05\n",
      "Epoch 1407/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9262e-05 - val_loss: 3.2122e-05\n",
      "Epoch 1408/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8280e-05 - val_loss: 3.1462e-05\n",
      "Epoch 1409/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8672e-05 - val_loss: 3.1485e-05\n",
      "Epoch 1410/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8367e-05 - val_loss: 3.1490e-05\n",
      "Epoch 1411/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9782e-05 - val_loss: 3.2390e-05\n",
      "Epoch 1412/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9705e-05 - val_loss: 3.1691e-05\n",
      "Epoch 1413/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8096e-05 - val_loss: 3.1472e-05\n",
      "Epoch 1414/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9746e-05 - val_loss: 3.2004e-05\n",
      "Epoch 1415/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9269e-05 - val_loss: 3.1456e-05\n",
      "Epoch 1416/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9543e-05 - val_loss: 3.2513e-05\n",
      "Epoch 1417/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8295e-05 - val_loss: 3.1717e-05\n",
      "Epoch 1418/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8501e-05 - val_loss: 3.2152e-05\n",
      "Epoch 1419/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8524e-05 - val_loss: 3.2007e-05\n",
      "Epoch 1420/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8718e-05 - val_loss: 3.1553e-05\n",
      "Epoch 1421/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9014e-05 - val_loss: 3.5140e-05\n",
      "Epoch 1422/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8914e-05 - val_loss: 3.1576e-05\n",
      "Epoch 1423/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8865e-05 - val_loss: 3.3339e-05\n",
      "Epoch 1424/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8817e-05 - val_loss: 3.6024e-05\n",
      "Epoch 1425/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9817e-05 - val_loss: 3.2425e-05\n",
      "Epoch 1426/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8346e-05 - val_loss: 3.2958e-05\n",
      "Epoch 1427/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8898e-05 - val_loss: 3.2322e-05\n",
      "Epoch 1428/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9492e-05 - val_loss: 3.3717e-05\n",
      "Epoch 1429/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9806e-05 - val_loss: 3.2230e-05\n",
      "Epoch 1430/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8739e-05 - val_loss: 3.1742e-05\n",
      "Epoch 1431/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9162e-05 - val_loss: 3.1714e-05\n",
      "Epoch 1432/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8948e-05 - val_loss: 3.1891e-05\n",
      "Epoch 1433/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9476e-05 - val_loss: 3.5622e-05\n",
      "Epoch 1434/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8915e-05 - val_loss: 3.1722e-05\n",
      "Epoch 1435/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8495e-05 - val_loss: 3.2810e-05\n",
      "Epoch 1436/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8988e-05 - val_loss: 3.2267e-05\n",
      "Epoch 1437/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8157e-05 - val_loss: 3.1775e-05\n",
      "Epoch 1438/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8518e-05 - val_loss: 3.1541e-05\n",
      "Epoch 1439/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8676e-05 - val_loss: 3.1566e-05\n",
      "Epoch 1440/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8465e-05 - val_loss: 3.1990e-05\n",
      "Epoch 1441/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8637e-05 - val_loss: 3.1745e-05\n",
      "Epoch 1442/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8289e-05 - val_loss: 3.4104e-05\n",
      "Epoch 1443/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8619e-05 - val_loss: 3.1455e-05\n",
      "Epoch 1444/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0641e-05 - val_loss: 3.3835e-05\n",
      "Epoch 1445/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9832e-05 - val_loss: 3.2721e-05\n",
      "Epoch 1446/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9510e-05 - val_loss: 3.2516e-05\n",
      "Epoch 1447/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8732e-05 - val_loss: 3.2168e-05\n",
      "Epoch 1448/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8867e-05 - val_loss: 3.1725e-05\n",
      "Epoch 1449/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9527e-05 - val_loss: 3.4788e-05\n",
      "Epoch 1450/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9101e-05 - val_loss: 3.4068e-05\n",
      "Epoch 1451/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9576e-05 - val_loss: 3.1461e-05\n",
      "Epoch 1452/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.7984e-05 - val_loss: 3.1735e-05\n",
      "Epoch 1453/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8743e-05 - val_loss: 3.3329e-05\n",
      "Epoch 1454/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9288e-05 - val_loss: 3.2186e-05\n",
      "Epoch 1455/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8822e-05 - val_loss: 3.2962e-05\n",
      "Epoch 1456/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8550e-05 - val_loss: 3.1902e-05\n",
      "Epoch 1457/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9180e-05 - val_loss: 3.1459e-05\n",
      "Epoch 1458/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.9222e-05 - val_loss: 3.6767e-05\n",
      "Epoch 1459/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 9.1639e-05 - val_loss: 3.2601e-05\n",
      "Epoch 1460/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8180e-05 - val_loss: 3.2748e-05\n",
      "Epoch 1461/2000\n",
      "21471/21471 [==============================] - ETA: 0s - loss: 9.2620e-0 - 0s 22us/step - loss: 8.8257e-05 - val_loss: 3.2022e-05\n",
      "Epoch 1462/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8339e-05 - val_loss: 3.1866e-05\n",
      "Epoch 1463/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8396e-05 - val_loss: 3.1460e-05\n",
      "Epoch 1464/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8772e-05 - val_loss: 3.1458e-05\n",
      "Epoch 1465/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8940e-05 - val_loss: 3.1520e-05\n",
      "Epoch 1466/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8666e-05 - val_loss: 3.1670e-05\n",
      "Epoch 1467/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0590e-05 - val_loss: 3.1768e-05\n",
      "Epoch 1468/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8736e-05 - val_loss: 3.1667e-05\n",
      "Epoch 1469/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8938e-05 - val_loss: 3.2114e-05\n",
      "Epoch 1470/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8631e-05 - val_loss: 3.2031e-05\n",
      "Epoch 1471/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9347e-05 - val_loss: 4.4155e-05\n",
      "Epoch 1472/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9437e-05 - val_loss: 3.1795e-05\n",
      "Epoch 1473/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9444e-05 - val_loss: 3.7243e-05\n",
      "Epoch 1474/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9012e-05 - val_loss: 3.1602e-05\n",
      "Epoch 1475/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9969e-05 - val_loss: 3.2520e-05\n",
      "Epoch 1476/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8754e-05 - val_loss: 3.1647e-05\n",
      "Epoch 1477/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8720e-05 - val_loss: 3.1457e-05\n",
      "Epoch 1478/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9141e-05 - val_loss: 3.6847e-05\n",
      "Epoch 1479/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8045e-05 - val_loss: 3.1975e-05\n",
      "Epoch 1480/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8786e-05 - val_loss: 3.1780e-05\n",
      "Epoch 1481/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8331e-05 - val_loss: 3.1714e-05\n",
      "Epoch 1482/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8066e-05 - val_loss: 3.1458e-05\n",
      "Epoch 1483/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9645e-05 - val_loss: 3.1459e-05\n",
      "Epoch 1484/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8860e-05 - val_loss: 3.1501e-05\n",
      "Epoch 1485/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8873e-05 - val_loss: 3.1536e-05\n",
      "Epoch 1486/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9149e-05 - val_loss: 3.3619e-05\n",
      "Epoch 1487/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9208e-05 - val_loss: 3.1960e-05\n",
      "Epoch 1488/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9088e-05 - val_loss: 3.2060e-05\n",
      "Epoch 1489/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8351e-05 - val_loss: 3.8871e-05\n",
      "Epoch 1490/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9290e-05 - val_loss: 3.3371e-05\n",
      "Epoch 1491/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8928e-05 - val_loss: 3.5968e-05\n",
      "Epoch 1492/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8671e-05 - val_loss: 3.1573e-05\n",
      "Epoch 1493/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9454e-05 - val_loss: 3.3312e-05\n",
      "Epoch 1494/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9136e-05 - val_loss: 3.2759e-05\n",
      "Epoch 1495/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8560e-05 - val_loss: 3.1659e-05\n",
      "Epoch 1496/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9113e-05 - val_loss: 3.3257e-05\n",
      "Epoch 1497/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9461e-05 - val_loss: 3.1807e-05\n",
      "Epoch 1498/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 8.8158e-05 - val_loss: 3.7553e-05\n",
      "Epoch 1499/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8856e-05 - val_loss: 3.1637e-05\n",
      "Epoch 1500/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9136e-05 - val_loss: 3.1498e-05\n",
      "Epoch 1501/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8426e-05 - val_loss: 3.1741e-05\n",
      "Epoch 1502/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0187e-05 - val_loss: 3.1558e-05\n",
      "Epoch 1503/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8782e-05 - val_loss: 3.6520e-05\n",
      "Epoch 1504/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9290e-05 - val_loss: 3.1455e-05\n",
      "Epoch 1505/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8375e-05 - val_loss: 3.2207e-05\n",
      "Epoch 1506/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9555e-05 - val_loss: 3.3294e-05\n",
      "Epoch 1507/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8628e-05 - val_loss: 3.1460e-05\n",
      "Epoch 1508/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.7939e-05 - val_loss: 3.5899e-05\n",
      "Epoch 1509/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9894e-05 - val_loss: 3.2555e-05\n",
      "Epoch 1510/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8925e-05 - val_loss: 3.1793e-05\n",
      "Epoch 1511/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9248e-05 - val_loss: 3.1884e-05\n",
      "Epoch 1512/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9064e-05 - val_loss: 3.7871e-05\n",
      "Epoch 1513/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8836e-05 - val_loss: 3.1457e-05\n",
      "Epoch 1514/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8275e-05 - val_loss: 3.1539e-05\n",
      "Epoch 1515/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8498e-05 - val_loss: 3.1534e-05\n",
      "Epoch 1516/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8321e-05 - val_loss: 3.3189e-05\n",
      "Epoch 1517/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9250e-05 - val_loss: 3.3429e-05\n",
      "Epoch 1518/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9638e-05 - val_loss: 3.1741e-05\n",
      "Epoch 1519/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8878e-05 - val_loss: 3.2511e-05\n",
      "Epoch 1520/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8837e-05 - val_loss: 3.1475e-05\n",
      "Epoch 1521/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8258e-05 - val_loss: 3.2448e-05\n",
      "Epoch 1522/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8188e-05 - val_loss: 3.1457e-05\n",
      "Epoch 1523/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9327e-05 - val_loss: 3.3509e-05\n",
      "Epoch 1524/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9697e-05 - val_loss: 3.1490e-05\n",
      "Epoch 1525/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9729e-05 - val_loss: 3.1467e-05\n",
      "Epoch 1526/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8830e-05 - val_loss: 3.1559e-05\n",
      "Epoch 1527/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9270e-05 - val_loss: 3.2117e-05\n",
      "Epoch 1528/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 8.8850e-05 - val_loss: 3.1546e-05\n",
      "Epoch 1529/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8540e-05 - val_loss: 3.2064e-05\n",
      "Epoch 1530/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8499e-05 - val_loss: 3.5223e-05\n",
      "Epoch 1531/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8943e-05 - val_loss: 3.1535e-05\n",
      "Epoch 1532/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8314e-05 - val_loss: 3.1898e-05\n",
      "Epoch 1533/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8860e-05 - val_loss: 3.1654e-05\n",
      "Epoch 1534/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8518e-05 - val_loss: 3.4124e-05\n",
      "Epoch 1535/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 8.8875e-05 - val_loss: 3.1731e-05\n",
      "Epoch 1536/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9263e-05 - val_loss: 3.2329e-05\n",
      "Epoch 1537/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9313e-05 - val_loss: 3.1463e-05\n",
      "Epoch 1538/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9081e-05 - val_loss: 3.1791e-05\n",
      "Epoch 1539/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8262e-05 - val_loss: 3.3365e-05\n",
      "Epoch 1540/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0336e-05 - val_loss: 3.2084e-05\n",
      "Epoch 1541/2000\n",
      "21471/21471 [==============================] - ETA: 0s - loss: 8.6911e-0 - 0s 20us/step - loss: 8.8423e-05 - val_loss: 3.3293e-05\n",
      "Epoch 1542/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0265e-05 - val_loss: 3.2057e-05\n",
      "Epoch 1543/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0628e-05 - val_loss: 3.6528e-05\n",
      "Epoch 1544/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0100e-05 - val_loss: 3.1459e-05\n",
      "Epoch 1545/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8124e-05 - val_loss: 3.1540e-05\n",
      "Epoch 1546/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9348e-05 - val_loss: 3.1583e-05\n",
      "Epoch 1547/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8485e-05 - val_loss: 3.2770e-05\n",
      "Epoch 1548/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.1447e-05 - val_loss: 3.1705e-05\n",
      "Epoch 1549/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9216e-05 - val_loss: 3.1534e-05\n",
      "Epoch 1550/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8389e-05 - val_loss: 3.4386e-05\n",
      "Epoch 1551/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8866e-05 - val_loss: 3.1703e-05\n",
      "Epoch 1552/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0019e-05 - val_loss: 3.3690e-05\n",
      "Epoch 1553/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8888e-05 - val_loss: 3.2554e-05\n",
      "Epoch 1554/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8302e-05 - val_loss: 3.5589e-05\n",
      "Epoch 1555/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0502e-05 - val_loss: 3.1510e-05\n",
      "Epoch 1556/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8733e-05 - val_loss: 3.1502e-05\n",
      "Epoch 1557/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8481e-05 - val_loss: 3.2476e-05\n",
      "Epoch 1558/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8652e-05 - val_loss: 3.1504e-05\n",
      "Epoch 1559/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8333e-05 - val_loss: 3.2417e-05\n",
      "Epoch 1560/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9082e-05 - val_loss: 3.2811e-05\n",
      "Epoch 1561/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9564e-05 - val_loss: 3.5808e-05\n",
      "Epoch 1562/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9226e-05 - val_loss: 3.2210e-05\n",
      "Epoch 1563/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9213e-05 - val_loss: 3.1515e-05\n",
      "Epoch 1564/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9305e-05 - val_loss: 3.4374e-05\n",
      "Epoch 1565/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9212e-05 - val_loss: 3.4517e-05\n",
      "Epoch 1566/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8817e-05 - val_loss: 3.2922e-05\n",
      "Epoch 1567/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8660e-05 - val_loss: 3.1792e-05\n",
      "Epoch 1568/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9035e-05 - val_loss: 3.1685e-05\n",
      "Epoch 1569/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9112e-05 - val_loss: 3.1990e-05\n",
      "Epoch 1570/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9584e-05 - val_loss: 3.3019e-05\n",
      "Epoch 1571/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8396e-05 - val_loss: 3.3865e-05\n",
      "Epoch 1572/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.9382e-05 - val_loss: 3.2301e-05\n",
      "Epoch 1573/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8700e-05 - val_loss: 3.1460e-05\n",
      "Epoch 1574/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9031e-05 - val_loss: 3.1606e-05\n",
      "Epoch 1575/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9008e-05 - val_loss: 3.1455e-05\n",
      "Epoch 1576/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9267e-05 - val_loss: 3.1671e-05\n",
      "Epoch 1577/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8756e-05 - val_loss: 3.1956e-05\n",
      "Epoch 1578/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9025e-05 - val_loss: 3.1550e-05\n",
      "Epoch 1579/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8067e-05 - val_loss: 3.2254e-05\n",
      "Epoch 1580/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9794e-05 - val_loss: 3.1503e-05\n",
      "Epoch 1581/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 9.0727e-05 - val_loss: 3.6410e-05\n",
      "Epoch 1582/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9894e-05 - val_loss: 3.1538e-05\n",
      "Epoch 1583/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8361e-05 - val_loss: 3.2276e-05\n",
      "Epoch 1584/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9380e-05 - val_loss: 3.2442e-05\n",
      "Epoch 1585/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8916e-05 - val_loss: 3.1704e-05\n",
      "Epoch 1586/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9464e-05 - val_loss: 3.1501e-05\n",
      "Epoch 1587/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9303e-05 - val_loss: 3.2075e-05\n",
      "Epoch 1588/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.9225e-05 - val_loss: 3.6036e-05\n",
      "Epoch 1589/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0058e-05 - val_loss: 3.1733e-05\n",
      "Epoch 1590/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8612e-05 - val_loss: 3.2599e-05\n",
      "Epoch 1591/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8736e-05 - val_loss: 3.2025e-05\n",
      "Epoch 1592/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8956e-05 - val_loss: 3.1455e-05\n",
      "Epoch 1593/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8899e-05 - val_loss: 3.5778e-05\n",
      "Epoch 1594/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9401e-05 - val_loss: 3.2341e-05\n",
      "Epoch 1595/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8600e-05 - val_loss: 3.1752e-05\n",
      "Epoch 1596/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8158e-05 - val_loss: 3.1477e-05\n",
      "Epoch 1597/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8654e-05 - val_loss: 3.1643e-05\n",
      "Epoch 1598/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8115e-05 - val_loss: 3.4217e-05\n",
      "Epoch 1599/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.9528e-05 - val_loss: 3.1455e-05\n",
      "Epoch 1600/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9738e-05 - val_loss: 3.1530e-05\n",
      "Epoch 1601/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8954e-05 - val_loss: 3.1734e-05\n",
      "Epoch 1602/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8918e-05 - val_loss: 3.1467e-05\n",
      "Epoch 1603/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8993e-05 - val_loss: 3.4981e-05\n",
      "Epoch 1604/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 9.0852e-05 - val_loss: 3.4383e-05\n",
      "Epoch 1605/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8398e-05 - val_loss: 3.1457e-05\n",
      "Epoch 1606/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9407e-05 - val_loss: 3.6708e-05\n",
      "Epoch 1607/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9470e-05 - val_loss: 3.1895e-05\n",
      "Epoch 1608/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 9.0476e-05 - val_loss: 3.1951e-05\n",
      "Epoch 1609/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8203e-05 - val_loss: 3.6813e-05\n",
      "Epoch 1610/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8617e-05 - val_loss: 3.3641e-05\n",
      "Epoch 1611/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9763e-05 - val_loss: 3.1854e-05\n",
      "Epoch 1612/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8242e-05 - val_loss: 3.1905e-05\n",
      "Epoch 1613/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8955e-05 - val_loss: 3.7198e-05\n",
      "Epoch 1614/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9717e-05 - val_loss: 3.1800e-05\n",
      "Epoch 1615/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9009e-05 - val_loss: 3.1456e-05\n",
      "Epoch 1616/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8220e-05 - val_loss: 3.7660e-05\n",
      "Epoch 1617/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9155e-05 - val_loss: 3.2118e-05\n",
      "Epoch 1618/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8281e-05 - val_loss: 3.3614e-05\n",
      "Epoch 1619/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9009e-05 - val_loss: 3.1806e-05\n",
      "Epoch 1620/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8376e-05 - val_loss: 3.1823e-05\n",
      "Epoch 1621/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8194e-05 - val_loss: 3.2015e-05\n",
      "Epoch 1622/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8434e-05 - val_loss: 3.1585e-05\n",
      "Epoch 1623/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8782e-05 - val_loss: 3.1474e-05\n",
      "Epoch 1624/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8433e-05 - val_loss: 3.2150e-05\n",
      "Epoch 1625/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9483e-05 - val_loss: 3.2493e-05\n",
      "Epoch 1626/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8284e-05 - val_loss: 3.1788e-05\n",
      "Epoch 1627/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9051e-05 - val_loss: 3.4414e-05\n",
      "Epoch 1628/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8937e-05 - val_loss: 3.1622e-05\n",
      "Epoch 1629/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9107e-05 - val_loss: 3.1612e-05\n",
      "Epoch 1630/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8685e-05 - val_loss: 3.1514e-05\n",
      "Epoch 1631/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8904e-05 - val_loss: 3.2020e-05\n",
      "Epoch 1632/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8908e-05 - val_loss: 3.2368e-05\n",
      "Epoch 1633/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8437e-05 - val_loss: 3.1896e-05\n",
      "Epoch 1634/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8811e-05 - val_loss: 3.5712e-05\n",
      "Epoch 1635/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8737e-05 - val_loss: 3.1529e-05\n",
      "Epoch 1636/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8270e-05 - val_loss: 3.1595e-05\n",
      "Epoch 1637/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8590e-05 - val_loss: 3.3148e-05\n",
      "Epoch 1638/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9511e-05 - val_loss: 3.2616e-05\n",
      "Epoch 1639/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8383e-05 - val_loss: 3.1468e-05\n",
      "Epoch 1640/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9621e-05 - val_loss: 3.2462e-05\n",
      "Epoch 1641/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8763e-05 - val_loss: 3.1455e-05\n",
      "Epoch 1642/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8313e-05 - val_loss: 3.1967e-05\n",
      "Epoch 1643/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8865e-05 - val_loss: 3.1528e-05\n",
      "Epoch 1644/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8946e-05 - val_loss: 3.5953e-05\n",
      "Epoch 1645/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9799e-05 - val_loss: 3.1455e-05\n",
      "Epoch 1646/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8630e-05 - val_loss: 3.1647e-05\n",
      "Epoch 1647/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8124e-05 - val_loss: 3.1487e-05\n",
      "Epoch 1648/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8576e-05 - val_loss: 3.1496e-05\n",
      "Epoch 1649/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9438e-05 - val_loss: 3.3473e-05\n",
      "Epoch 1650/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8071e-05 - val_loss: 3.3093e-05\n",
      "Epoch 1651/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9283e-05 - val_loss: 3.1548e-05\n",
      "Epoch 1652/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9244e-05 - val_loss: 3.1460e-05\n",
      "Epoch 1653/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8850e-05 - val_loss: 3.5312e-05\n",
      "Epoch 1654/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9411e-05 - val_loss: 3.1538e-05\n",
      "Epoch 1655/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8931e-05 - val_loss: 3.2507e-05\n",
      "Epoch 1656/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8210e-05 - val_loss: 3.8972e-05\n",
      "Epoch 1657/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9008e-05 - val_loss: 3.4121e-05\n",
      "Epoch 1658/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8747e-05 - val_loss: 3.3222e-05\n",
      "Epoch 1659/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8832e-05 - val_loss: 3.1507e-05\n",
      "Epoch 1660/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9146e-05 - val_loss: 3.2277e-05\n",
      "Epoch 1661/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9745e-05 - val_loss: 3.1798e-05\n",
      "Epoch 1662/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8352e-05 - val_loss: 3.1467e-05\n",
      "Epoch 1663/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8513e-05 - val_loss: 3.1587e-05\n",
      "Epoch 1664/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8464e-05 - val_loss: 3.1455e-05\n",
      "Epoch 1665/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9396e-05 - val_loss: 3.1519e-05\n",
      "Epoch 1666/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8318e-05 - val_loss: 3.1857e-05\n",
      "Epoch 1667/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8249e-05 - val_loss: 3.1585e-05\n",
      "Epoch 1668/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8897e-05 - val_loss: 3.2182e-05\n",
      "Epoch 1669/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.9175e-05 - val_loss: 3.3666e-05\n",
      "Epoch 1670/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.9416e-05 - val_loss: 3.1832e-05\n",
      "Epoch 1671/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9689e-05 - val_loss: 3.2490e-05\n",
      "Epoch 1672/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8065e-05 - val_loss: 3.1521e-05\n",
      "Epoch 1673/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 8.8090e-05 - val_loss: 3.1465e-05\n",
      "Epoch 1674/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8113e-05 - val_loss: 3.1811e-05\n",
      "Epoch 1675/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0492e-05 - val_loss: 3.1576e-05\n",
      "Epoch 1676/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.9200e-05 - val_loss: 3.1869e-05\n",
      "Epoch 1677/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8494e-05 - val_loss: 3.2082e-05\n",
      "Epoch 1678/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8292e-05 - val_loss: 3.1820e-05\n",
      "Epoch 1679/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8794e-05 - val_loss: 3.5916e-05\n",
      "Epoch 1680/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9546e-05 - val_loss: 3.2281e-05\n",
      "Epoch 1681/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8926e-05 - val_loss: 3.2645e-05\n",
      "Epoch 1682/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8540e-05 - val_loss: 3.5455e-05\n",
      "Epoch 1683/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8850e-05 - val_loss: 3.2872e-05\n",
      "Epoch 1684/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8801e-05 - val_loss: 3.2785e-05\n",
      "Epoch 1685/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8979e-05 - val_loss: 3.3128e-05\n",
      "Epoch 1686/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9262e-05 - val_loss: 3.6703e-05\n",
      "Epoch 1687/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0222e-05 - val_loss: 3.3031e-05\n",
      "Epoch 1688/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9140e-05 - val_loss: 3.1461e-05\n",
      "Epoch 1689/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8451e-05 - val_loss: 3.1730e-05\n",
      "Epoch 1690/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8958e-05 - val_loss: 3.1612e-05\n",
      "Epoch 1691/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8932e-05 - val_loss: 3.2481e-05\n",
      "Epoch 1692/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9858e-05 - val_loss: 3.1670e-05\n",
      "Epoch 1693/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8358e-05 - val_loss: 4.2788e-05\n",
      "Epoch 1694/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0722e-05 - val_loss: 3.1456e-05\n",
      "Epoch 1695/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9180e-05 - val_loss: 3.7235e-05\n",
      "Epoch 1696/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9115e-05 - val_loss: 3.2261e-05\n",
      "Epoch 1697/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8423e-05 - val_loss: 3.6981e-05\n",
      "Epoch 1698/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9975e-05 - val_loss: 3.1732e-05\n",
      "Epoch 1699/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8097e-05 - val_loss: 3.7660e-05\n",
      "Epoch 1700/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8402e-05 - val_loss: 3.1750e-05\n",
      "Epoch 1701/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8673e-05 - val_loss: 3.2312e-05\n",
      "Epoch 1702/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9835e-05 - val_loss: 3.1704e-05\n",
      "Epoch 1703/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8347e-05 - val_loss: 3.1520e-05\n",
      "Epoch 1704/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8434e-05 - val_loss: 3.1875e-05\n",
      "Epoch 1705/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8572e-05 - val_loss: 3.3053e-05\n",
      "Epoch 1706/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8363e-05 - val_loss: 3.1552e-05\n",
      "Epoch 1707/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9290e-05 - val_loss: 3.1867e-05\n",
      "Epoch 1708/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9364e-05 - val_loss: 3.1628e-05\n",
      "Epoch 1709/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8508e-05 - val_loss: 3.1619e-05\n",
      "Epoch 1710/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9321e-05 - val_loss: 3.2933e-05\n",
      "Epoch 1711/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8880e-05 - val_loss: 3.2353e-05\n",
      "Epoch 1712/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8426e-05 - val_loss: 3.1708e-05\n",
      "Epoch 1713/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9211e-05 - val_loss: 3.6793e-05\n",
      "Epoch 1714/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8873e-05 - val_loss: 3.8768e-05\n",
      "Epoch 1715/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9223e-05 - val_loss: 3.1605e-05\n",
      "Epoch 1716/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8500e-05 - val_loss: 3.1985e-05\n",
      "Epoch 1717/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8941e-05 - val_loss: 3.4966e-05\n",
      "Epoch 1718/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8426e-05 - val_loss: 3.1455e-05\n",
      "Epoch 1719/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8802e-05 - val_loss: 3.1668e-05\n",
      "Epoch 1720/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9601e-05 - val_loss: 3.2957e-05\n",
      "Epoch 1721/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8859e-05 - val_loss: 3.1482e-05\n",
      "Epoch 1722/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8876e-05 - val_loss: 3.1459e-05\n",
      "Epoch 1723/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 8.8673e-05 - val_loss: 3.1469e-05\n",
      "Epoch 1724/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8735e-05 - val_loss: 3.1493e-05\n",
      "Epoch 1725/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9278e-05 - val_loss: 3.2139e-05\n",
      "Epoch 1726/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8344e-05 - val_loss: 3.3785e-05\n",
      "Epoch 1727/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8477e-05 - val_loss: 3.1874e-05\n",
      "Epoch 1728/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8745e-05 - val_loss: 3.2201e-05\n",
      "Epoch 1729/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8902e-05 - val_loss: 3.4266e-05\n",
      "Epoch 1730/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9016e-05 - val_loss: 3.1902e-05\n",
      "Epoch 1731/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9827e-05 - val_loss: 3.1654e-05\n",
      "Epoch 1732/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8801e-05 - val_loss: 3.1691e-05\n",
      "Epoch 1733/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8755e-05 - val_loss: 3.2592e-05\n",
      "Epoch 1734/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 9.0310e-05 - val_loss: 3.1816e-05\n",
      "Epoch 1735/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8224e-05 - val_loss: 3.1959e-05\n",
      "Epoch 1736/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8358e-05 - val_loss: 3.1652e-05\n",
      "Epoch 1737/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8157e-05 - val_loss: 3.4606e-05\n",
      "Epoch 1738/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9679e-05 - val_loss: 3.2848e-05\n",
      "Epoch 1739/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.9136e-05 - val_loss: 3.1684e-05\n",
      "Epoch 1740/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8669e-05 - val_loss: 3.2064e-05\n",
      "Epoch 1741/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8192e-05 - val_loss: 3.1517e-05\n",
      "Epoch 1742/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8466e-05 - val_loss: 3.2146e-05\n",
      "Epoch 1743/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8890e-05 - val_loss: 3.1483e-05\n",
      "Epoch 1744/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8428e-05 - val_loss: 3.2473e-05\n",
      "Epoch 1745/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9412e-05 - val_loss: 3.6998e-05\n",
      "Epoch 1746/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9158e-05 - val_loss: 3.1602e-05\n",
      "Epoch 1747/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.7908e-05 - val_loss: 3.2663e-05\n",
      "Epoch 1748/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8605e-05 - val_loss: 3.1473e-05\n",
      "Epoch 1749/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8889e-05 - val_loss: 3.1487e-05\n",
      "Epoch 1750/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8866e-05 - val_loss: 3.1593e-05\n",
      "Epoch 1751/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8006e-05 - val_loss: 3.2901e-05\n",
      "Epoch 1752/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8603e-05 - val_loss: 3.3268e-05\n",
      "Epoch 1753/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8139e-05 - val_loss: 3.1495e-05\n",
      "Epoch 1754/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8300e-05 - val_loss: 3.4991e-05\n",
      "Epoch 1755/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8734e-05 - val_loss: 3.1455e-05\n",
      "Epoch 1756/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8525e-05 - val_loss: 3.3879e-05\n",
      "Epoch 1757/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8397e-05 - val_loss: 3.2055e-05\n",
      "Epoch 1758/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8360e-05 - val_loss: 3.1486e-05\n",
      "Epoch 1759/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9255e-05 - val_loss: 3.7441e-05\n",
      "Epoch 1760/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 9.0703e-05 - val_loss: 3.2407e-05\n",
      "Epoch 1761/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8407e-05 - val_loss: 3.9999e-05\n",
      "Epoch 1762/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.1007e-05 - val_loss: 3.1472e-05\n",
      "Epoch 1763/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9928e-05 - val_loss: 3.1466e-05\n",
      "Epoch 1764/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9043e-05 - val_loss: 3.1465e-05\n",
      "Epoch 1765/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8463e-05 - val_loss: 3.2204e-05\n",
      "Epoch 1766/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8984e-05 - val_loss: 3.3444e-05\n",
      "Epoch 1767/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8775e-05 - val_loss: 3.8432e-05\n",
      "Epoch 1768/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9792e-05 - val_loss: 3.4822e-05\n",
      "Epoch 1769/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0160e-05 - val_loss: 3.2748e-05\n",
      "Epoch 1770/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8694e-05 - val_loss: 3.1688e-05\n",
      "Epoch 1771/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8982e-05 - val_loss: 3.1923e-05\n",
      "Epoch 1772/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8934e-05 - val_loss: 3.2499e-05\n",
      "Epoch 1773/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8574e-05 - val_loss: 3.1861e-05\n",
      "Epoch 1774/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8576e-05 - val_loss: 3.2327e-05\n",
      "Epoch 1775/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8541e-05 - val_loss: 3.1455e-05\n",
      "Epoch 1776/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8455e-05 - val_loss: 3.3569e-05\n",
      "Epoch 1777/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8841e-05 - val_loss: 3.3622e-05\n",
      "Epoch 1778/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8387e-05 - val_loss: 3.2012e-05\n",
      "Epoch 1779/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8739e-05 - val_loss: 3.1470e-05\n",
      "Epoch 1780/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8600e-05 - val_loss: 3.1455e-05\n",
      "Epoch 1781/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8376e-05 - val_loss: 3.1758e-05\n",
      "Epoch 1782/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8827e-05 - val_loss: 3.2537e-05\n",
      "Epoch 1783/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9635e-05 - val_loss: 3.2135e-05\n",
      "Epoch 1784/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8424e-05 - val_loss: 3.1778e-05\n",
      "Epoch 1785/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8305e-05 - val_loss: 3.1766e-05\n",
      "Epoch 1786/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9370e-05 - val_loss: 3.1992e-05\n",
      "Epoch 1787/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8540e-05 - val_loss: 3.2489e-05\n",
      "Epoch 1788/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8755e-05 - val_loss: 3.1541e-05\n",
      "Epoch 1789/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8464e-05 - val_loss: 3.1606e-05\n",
      "Epoch 1790/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8385e-05 - val_loss: 3.1679e-05\n",
      "Epoch 1791/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8646e-05 - val_loss: 3.1764e-05\n",
      "Epoch 1792/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8555e-05 - val_loss: 3.1455e-05\n",
      "Epoch 1793/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9534e-05 - val_loss: 3.2654e-05\n",
      "Epoch 1794/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0759e-05 - val_loss: 3.2382e-05\n",
      "Epoch 1795/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9345e-05 - val_loss: 3.2164e-05\n",
      "Epoch 1796/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8483e-05 - val_loss: 3.1738e-05\n",
      "Epoch 1797/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8715e-05 - val_loss: 3.9476e-05\n",
      "Epoch 1798/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8605e-05 - val_loss: 3.1472e-05\n",
      "Epoch 1799/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8453e-05 - val_loss: 3.1455e-05\n",
      "Epoch 1800/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0634e-05 - val_loss: 3.2925e-05\n",
      "Epoch 1801/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8874e-05 - val_loss: 3.1610e-05\n",
      "Epoch 1802/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8653e-05 - val_loss: 3.1516e-05\n",
      "Epoch 1803/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8022e-05 - val_loss: 3.3518e-05\n",
      "Epoch 1804/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8664e-05 - val_loss: 3.3088e-05\n",
      "Epoch 1805/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8907e-05 - val_loss: 3.1492e-05\n",
      "Epoch 1806/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9579e-05 - val_loss: 3.2106e-05\n",
      "Epoch 1807/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9361e-05 - val_loss: 3.2276e-05\n",
      "Epoch 1808/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9358e-05 - val_loss: 3.1771e-05\n",
      "Epoch 1809/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8339e-05 - val_loss: 3.1909e-05\n",
      "Epoch 1810/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.9064e-05 - val_loss: 3.1463e-05\n",
      "Epoch 1811/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8297e-05 - val_loss: 3.1457e-05\n",
      "Epoch 1812/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8578e-05 - val_loss: 3.1647e-05\n",
      "Epoch 1813/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 9.0199e-05 - val_loss: 3.1716e-05\n",
      "Epoch 1814/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8897e-05 - val_loss: 3.1766e-05\n",
      "Epoch 1815/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8219e-05 - val_loss: 3.1523e-05\n",
      "Epoch 1816/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8601e-05 - val_loss: 3.1474e-05\n",
      "Epoch 1817/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9203e-05 - val_loss: 3.1509e-05\n",
      "Epoch 1818/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8425e-05 - val_loss: 3.2086e-05\n",
      "Epoch 1819/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8892e-05 - val_loss: 3.1743e-05\n",
      "Epoch 1820/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9537e-05 - val_loss: 3.1549e-05\n",
      "Epoch 1821/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9742e-05 - val_loss: 3.2107e-05\n",
      "Epoch 1822/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8466e-05 - val_loss: 3.2145e-05\n",
      "Epoch 1823/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 9.1390e-05 - val_loss: 3.2492e-05\n",
      "Epoch 1824/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8465e-05 - val_loss: 3.1520e-05\n",
      "Epoch 1825/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8782e-05 - val_loss: 3.3980e-05\n",
      "Epoch 1826/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8916e-05 - val_loss: 3.1455e-05\n",
      "Epoch 1827/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8427e-05 - val_loss: 3.2164e-05\n",
      "Epoch 1828/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8558e-05 - val_loss: 3.1472e-05\n",
      "Epoch 1829/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9084e-05 - val_loss: 3.1614e-05\n",
      "Epoch 1830/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8709e-05 - val_loss: 3.4816e-05\n",
      "Epoch 1831/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9276e-05 - val_loss: 3.1817e-05\n",
      "Epoch 1832/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8981e-05 - val_loss: 3.3350e-05\n",
      "Epoch 1833/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9175e-05 - val_loss: 3.1490e-05\n",
      "Epoch 1834/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8156e-05 - val_loss: 3.2656e-05\n",
      "Epoch 1835/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8554e-05 - val_loss: 3.2425e-05\n",
      "Epoch 1836/2000\n",
      "21471/21471 [==============================] - 0s 22us/step - loss: 8.8508e-05 - val_loss: 3.1529e-05\n",
      "Epoch 1837/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9978e-05 - val_loss: 3.2127e-05\n",
      "Epoch 1838/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8642e-05 - val_loss: 3.1508e-05\n",
      "Epoch 1839/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8607e-05 - val_loss: 3.1613e-05\n",
      "Epoch 1840/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9822e-05 - val_loss: 3.6175e-05\n",
      "Epoch 1841/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0195e-05 - val_loss: 3.1466e-05\n",
      "Epoch 1842/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8191e-05 - val_loss: 3.1810e-05\n",
      "Epoch 1843/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8641e-05 - val_loss: 3.1474e-05\n",
      "Epoch 1844/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8087e-05 - val_loss: 3.1639e-05\n",
      "Epoch 1845/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8756e-05 - val_loss: 3.3595e-05\n",
      "Epoch 1846/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9758e-05 - val_loss: 3.1713e-05\n",
      "Epoch 1847/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9432e-05 - val_loss: 3.1931e-05\n",
      "Epoch 1848/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8464e-05 - val_loss: 3.1624e-05\n",
      "Epoch 1849/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9277e-05 - val_loss: 3.3183e-05\n",
      "Epoch 1850/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8491e-05 - val_loss: 3.3351e-05\n",
      "Epoch 1851/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9725e-05 - val_loss: 3.1456e-05\n",
      "Epoch 1852/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8684e-05 - val_loss: 3.1752e-05\n",
      "Epoch 1853/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8937e-05 - val_loss: 3.2798e-05\n",
      "Epoch 1854/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8414e-05 - val_loss: 3.2146e-05\n",
      "Epoch 1855/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8900e-05 - val_loss: 3.2002e-05\n",
      "Epoch 1856/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8211e-05 - val_loss: 3.1915e-05\n",
      "Epoch 1857/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9631e-05 - val_loss: 3.4401e-05\n",
      "Epoch 1858/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0203e-05 - val_loss: 3.2239e-05\n",
      "Epoch 1859/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8406e-05 - val_loss: 3.1867e-05\n",
      "Epoch 1860/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8935e-05 - val_loss: 3.3096e-05\n",
      "Epoch 1861/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0262e-05 - val_loss: 3.1960e-05\n",
      "Epoch 1862/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8912e-05 - val_loss: 3.1479e-05\n",
      "Epoch 1863/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8591e-05 - val_loss: 3.1607e-05\n",
      "Epoch 1864/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9014e-05 - val_loss: 3.3974e-05\n",
      "Epoch 1865/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8193e-05 - val_loss: 3.1538e-05\n",
      "Epoch 1866/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9649e-05 - val_loss: 3.1476e-05\n",
      "Epoch 1867/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8172e-05 - val_loss: 3.2761e-05\n",
      "Epoch 1868/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8544e-05 - val_loss: 3.1503e-05\n",
      "Epoch 1869/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8081e-05 - val_loss: 3.3062e-05\n",
      "Epoch 1870/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9784e-05 - val_loss: 3.8524e-05\n",
      "Epoch 1871/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8275e-05 - val_loss: 3.1457e-05\n",
      "Epoch 1872/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8398e-05 - val_loss: 3.1486e-05\n",
      "Epoch 1873/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8972e-05 - val_loss: 3.2968e-05\n",
      "Epoch 1874/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.9523e-05 - val_loss: 3.5527e-05\n",
      "Epoch 1875/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0019e-05 - val_loss: 3.1456e-05\n",
      "Epoch 1876/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9763e-05 - val_loss: 3.1693e-05\n",
      "Epoch 1877/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8531e-05 - val_loss: 3.2456e-05\n",
      "Epoch 1878/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8823e-05 - val_loss: 3.1616e-05\n",
      "Epoch 1879/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8641e-05 - val_loss: 3.1931e-05\n",
      "Epoch 1880/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8821e-05 - val_loss: 3.1970e-05\n",
      "Epoch 1881/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8631e-05 - val_loss: 3.1465e-05\n",
      "Epoch 1882/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8539e-05 - val_loss: 3.3140e-05\n",
      "Epoch 1883/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8713e-05 - val_loss: 3.1455e-05\n",
      "Epoch 1884/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8833e-05 - val_loss: 3.3294e-05\n",
      "Epoch 1885/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8736e-05 - val_loss: 3.3108e-05\n",
      "Epoch 1886/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9286e-05 - val_loss: 3.1766e-05\n",
      "Epoch 1887/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9165e-05 - val_loss: 3.2884e-05\n",
      "Epoch 1888/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9433e-05 - val_loss: 3.3925e-05\n",
      "Epoch 1889/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9284e-05 - val_loss: 3.4751e-05\n",
      "Epoch 1890/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8965e-05 - val_loss: 3.1618e-05\n",
      "Epoch 1891/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8841e-05 - val_loss: 3.2266e-05\n",
      "Epoch 1892/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9174e-05 - val_loss: 3.7241e-05\n",
      "Epoch 1893/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9904e-05 - val_loss: 3.2567e-05\n",
      "Epoch 1894/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 9.0329e-05 - val_loss: 3.5550e-05\n",
      "Epoch 1895/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8977e-05 - val_loss: 3.2167e-05\n",
      "Epoch 1896/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8314e-05 - val_loss: 3.1664e-05\n",
      "Epoch 1897/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8799e-05 - val_loss: 3.2314e-05\n",
      "Epoch 1898/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8846e-05 - val_loss: 3.2070e-05\n",
      "Epoch 1899/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8663e-05 - val_loss: 3.3247e-05\n",
      "Epoch 1900/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9264e-05 - val_loss: 3.2490e-05\n",
      "Epoch 1901/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8766e-05 - val_loss: 3.1991e-05\n",
      "Epoch 1902/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8000e-05 - val_loss: 3.1564e-05\n",
      "Epoch 1903/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9317e-05 - val_loss: 3.2417e-05\n",
      "Epoch 1904/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9790e-05 - val_loss: 3.2131e-05\n",
      "Epoch 1905/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0114e-05 - val_loss: 3.4649e-05\n",
      "Epoch 1906/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8597e-05 - val_loss: 3.2429e-05\n",
      "Epoch 1907/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9091e-05 - val_loss: 3.1456e-05\n",
      "Epoch 1908/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 9.0588e-05 - val_loss: 3.5326e-05\n",
      "Epoch 1909/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9780e-05 - val_loss: 3.1799e-05\n",
      "Epoch 1910/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9246e-05 - val_loss: 3.2081e-05\n",
      "Epoch 1911/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8600e-05 - val_loss: 3.1528e-05\n",
      "Epoch 1912/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8776e-05 - val_loss: 3.2030e-05\n",
      "Epoch 1913/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9218e-05 - val_loss: 3.2392e-05\n",
      "Epoch 1914/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8540e-05 - val_loss: 3.2114e-05\n",
      "Epoch 1915/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8818e-05 - val_loss: 3.2243e-05\n",
      "Epoch 1916/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8256e-05 - val_loss: 3.2306e-05\n",
      "Epoch 1917/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9115e-05 - val_loss: 3.1915e-05\n",
      "Epoch 1918/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9090e-05 - val_loss: 3.1659e-05\n",
      "Epoch 1919/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8614e-05 - val_loss: 3.1992e-05\n",
      "Epoch 1920/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9007e-05 - val_loss: 3.2676e-05\n",
      "Epoch 1921/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8439e-05 - val_loss: 3.1997e-05\n",
      "Epoch 1922/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9099e-05 - val_loss: 3.1536e-05\n",
      "Epoch 1923/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8889e-05 - val_loss: 3.1668e-05\n",
      "Epoch 1924/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8687e-05 - val_loss: 3.6784e-05\n",
      "Epoch 1925/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9184e-05 - val_loss: 3.1656e-05\n",
      "Epoch 1926/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8572e-05 - val_loss: 3.1588e-05\n",
      "Epoch 1927/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8200e-05 - val_loss: 3.1512e-05\n",
      "Epoch 1928/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8513e-05 - val_loss: 3.2462e-05\n",
      "Epoch 1929/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8309e-05 - val_loss: 3.2796e-05\n",
      "Epoch 1930/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9503e-05 - val_loss: 3.1764e-05\n",
      "Epoch 1931/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9530e-05 - val_loss: 3.3109e-05\n",
      "Epoch 1932/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8971e-05 - val_loss: 3.2045e-05\n",
      "Epoch 1933/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9167e-05 - val_loss: 3.1968e-05\n",
      "Epoch 1934/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9174e-05 - val_loss: 3.1476e-05\n",
      "Epoch 1935/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8738e-05 - val_loss: 3.1479e-05\n",
      "Epoch 1936/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8432e-05 - val_loss: 3.2857e-05\n",
      "Epoch 1937/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9438e-05 - val_loss: 3.2265e-05\n",
      "Epoch 1938/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8322e-05 - val_loss: 3.2253e-05\n",
      "Epoch 1939/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8323e-05 - val_loss: 3.2060e-05\n",
      "Epoch 1940/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8982e-05 - val_loss: 3.2380e-05\n",
      "Epoch 1941/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8924e-05 - val_loss: 3.1459e-05\n",
      "Epoch 1942/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8473e-05 - val_loss: 3.1841e-05\n",
      "Epoch 1943/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8239e-05 - val_loss: 3.6769e-05\n",
      "Epoch 1944/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8817e-05 - val_loss: 3.8172e-05\n",
      "Epoch 1945/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9238e-05 - val_loss: 3.1591e-05\n",
      "Epoch 1946/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8592e-05 - val_loss: 3.3843e-05\n",
      "Epoch 1947/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8498e-05 - val_loss: 3.5396e-05\n",
      "Epoch 1948/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8753e-05 - val_loss: 3.1458e-05\n",
      "Epoch 1949/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8210e-05 - val_loss: 3.1506e-05\n",
      "Epoch 1950/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8567e-05 - val_loss: 3.2086e-05\n",
      "Epoch 1951/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8573e-05 - val_loss: 3.1636e-05\n",
      "Epoch 1952/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8764e-05 - val_loss: 3.1975e-05\n",
      "Epoch 1953/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9258e-05 - val_loss: 3.6459e-05\n",
      "Epoch 1954/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9343e-05 - val_loss: 3.3197e-05\n",
      "Epoch 1955/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8715e-05 - val_loss: 3.1456e-05\n",
      "Epoch 1956/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9262e-05 - val_loss: 3.1777e-05\n",
      "Epoch 1957/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8395e-05 - val_loss: 3.1478e-05\n",
      "Epoch 1958/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8631e-05 - val_loss: 3.1474e-05\n",
      "Epoch 1959/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9585e-05 - val_loss: 3.2089e-05\n",
      "Epoch 1960/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8638e-05 - val_loss: 3.1763e-05\n",
      "Epoch 1961/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8691e-05 - val_loss: 3.1836e-05\n",
      "Epoch 1962/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8897e-05 - val_loss: 3.1651e-05\n",
      "Epoch 1963/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8428e-05 - val_loss: 3.2735e-05\n",
      "Epoch 1964/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8851e-05 - val_loss: 3.2490e-05\n",
      "Epoch 1965/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9445e-05 - val_loss: 3.1594e-05\n",
      "Epoch 1966/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8359e-05 - val_loss: 3.2983e-05\n",
      "Epoch 1967/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9278e-05 - val_loss: 3.1635e-05\n",
      "Epoch 1968/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9231e-05 - val_loss: 3.1455e-05\n",
      "Epoch 1969/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9186e-05 - val_loss: 3.2768e-05\n",
      "Epoch 1970/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9564e-05 - val_loss: 3.1605e-05\n",
      "Epoch 1971/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8298e-05 - val_loss: 3.2580e-05\n",
      "Epoch 1972/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9384e-05 - val_loss: 3.1843e-05\n",
      "Epoch 1973/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8459e-05 - val_loss: 3.3452e-05\n",
      "Epoch 1974/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0277e-05 - val_loss: 3.2165e-05\n",
      "Epoch 1975/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9178e-05 - val_loss: 3.2438e-05\n",
      "Epoch 1976/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9206e-05 - val_loss: 3.1488e-05\n",
      "Epoch 1977/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8554e-05 - val_loss: 3.1514e-05\n",
      "Epoch 1978/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8453e-05 - val_loss: 3.1587e-05\n",
      "Epoch 1979/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8496e-05 - val_loss: 3.4122e-05\n",
      "Epoch 1980/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.8873e-05 - val_loss: 3.2563e-05\n",
      "Epoch 1981/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8281e-05 - val_loss: 3.5426e-05\n",
      "Epoch 1982/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8906e-05 - val_loss: 3.4719e-05\n",
      "Epoch 1983/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 9.0652e-05 - val_loss: 3.1634e-05\n",
      "Epoch 1984/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9315e-05 - val_loss: 3.2113e-05\n",
      "Epoch 1985/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8669e-05 - val_loss: 3.1666e-05\n",
      "Epoch 1986/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9667e-05 - val_loss: 3.1456e-05\n",
      "Epoch 1987/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8581e-05 - val_loss: 3.1653e-05\n",
      "Epoch 1988/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8571e-05 - val_loss: 3.1456e-05\n",
      "Epoch 1989/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8299e-05 - val_loss: 3.1680e-05\n",
      "Epoch 1990/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8646e-05 - val_loss: 4.1656e-05\n",
      "Epoch 1991/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9439e-05 - val_loss: 3.1534e-05\n",
      "Epoch 1992/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9296e-05 - val_loss: 3.2152e-05\n",
      "Epoch 1993/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8578e-05 - val_loss: 3.3266e-05\n",
      "Epoch 1994/2000\n",
      "21471/21471 [==============================] - 0s 19us/step - loss: 8.9070e-05 - val_loss: 3.2106e-05\n",
      "Epoch 1995/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8300e-05 - val_loss: 3.2072e-05\n",
      "Epoch 1996/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.8628e-05 - val_loss: 3.2105e-05\n",
      "Epoch 1997/2000\n",
      "21471/21471 [==============================] - 0s 20us/step - loss: 8.9678e-05 - val_loss: 3.1653e-05\n",
      "Epoch 1998/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8966e-05 - val_loss: 3.1517e-05\n",
      "Epoch 1999/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8092e-05 - val_loss: 3.1500e-05\n",
      "Epoch 2000/2000\n",
      "21471/21471 [==============================] - 0s 21us/step - loss: 8.8306e-05 - val_loss: 3.2002e-05\n"
     ]
    }
   ],
   "source": [
    "final_model = build_dense(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'sigmoid',\n",
       " 'optimizer': 'adamax',\n",
       " 'shuffle': True,\n",
       " 'density': 148,\n",
       " 'callbacks': [<keras.callbacks.callbacks.ModelCheckpoint at 0x2b0d9fd0c88>]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_182\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_923 (Dense)            (None, 148)               14652     \n",
      "_________________________________________________________________\n",
      "dense_924 (Dense)            (None, 74)                11026     \n",
      "_________________________________________________________________\n",
      "dense_925 (Dense)            (None, 37)                2775      \n",
      "_________________________________________________________________\n",
      "dense_926 (Dense)            (None, 18)                684       \n",
      "_________________________________________________________________\n",
      "dense_927 (Dense)            (None, 1)                 19        \n",
      "=================================================================\n",
      "Total params: 29,156\n",
      "Trainable params: 29,156\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model[0].load_weights('./checkpoints/fundamental.(best).hdf5')\n",
    "y_predicted = final_model[0].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y_test = y_normaliser.inverse_transform(y_predicted)\n",
    "true_y_test = y_normaliser.inverse_transform(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE is 87344.15\n",
      "Medium error is 35.87\n"
     ]
    }
   ],
   "source": [
    "loss = np.mean((true_y_test - predicted_y_test)**2)\n",
    "medium_error = np.mean(abs(true_y_test - predicted_y_test))\n",
    "print(f'MSE is {loss:.2f}\\nMedium error is {medium_error:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trend accuracy is: 52.05%\n"
     ]
    }
   ],
   "source": [
    "print(f'Trend accuracy is: {(sum(1 for r,p in zip(predicted_y_test,true_y_test) if (r > 0 and p > 0) or (r < 0 and p < 0))/len(Y_test))*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test growth trends:        Predicted growth trends:\n",
      "3110                       5892\n",
      "Test decreasing trends:    Predicted decreasing trends:\n",
      "2855                       73\n"
     ]
    }
   ],
   "source": [
    "print('Test growth trends:        Predicted growth trends:')\n",
    "print(sum(1 for v in true_y_test if v > 0),'                     ',sum(1 for v in predicted_y_test if v > 0))\n",
    "print('Test decreasing trends:    Predicted decreasing trends:')\n",
    "print(sum(1 for v in true_y_test if v < 0),'                     ',sum(1 for v in predicted_y_test if v < 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test mean: 13.814097446110715\n",
      "Predictions mean: 13.536017417907715\n"
     ]
    }
   ],
   "source": [
    "print(f'Test mean: {np.mean(true_y_test)}')\n",
    "print(f'Predictions mean: {np.mean(predicted_y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Results seem to be random around some tipical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test values:    Predicted values:\n",
      "    6.71           13.52\n",
      "    15.98           14.10\n",
      "    -24.16           14.20\n",
      "    -3.26           14.31\n",
      "    -37.74           14.32\n",
      "    19.17           12.33\n",
      "    -22.51           14.32\n",
      "    3.10           14.39\n",
      "    -32.61           14.39\n",
      "    -2.50           14.45\n",
      "    -35.70           14.40\n",
      "    5.68           -4.87\n",
      "    5.03           14.16\n",
      "    42.44           14.20\n",
      "    4.46            5.34\n",
      "    -29.52           14.30\n",
      "    7.42           14.35\n",
      "    -4.15           -1.40\n",
      "    -16.67           14.35\n",
      "    37.96           14.33\n",
      "    -21.83           14.27\n",
      "    -5.49           14.28\n",
      "    3.60           13.84\n",
      "    17.70           14.18\n",
      "    7.64           14.29\n",
      "    19.82           14.37\n",
      "    -11.20           14.00\n",
      "    4.49           14.34\n",
      "    6.44           14.34\n",
      "    -1.85           14.35\n",
      "    9.54           11.76\n",
      "    0.44           13.85\n",
      "    17.55           14.34\n",
      "    -31.37           14.30\n",
      "    10.42            9.33\n",
      "    -25.96           14.34\n",
      "    5.77           13.82\n",
      "    26.91           12.46\n",
      "    -6.28           14.11\n",
      "    139.19           14.39\n",
      "    -7.27           14.24\n",
      "    1.71           14.34\n",
      "    -29.57           14.38\n",
      "    4.49           14.14\n",
      "    -21.04           14.23\n",
      "    0.24           14.25\n",
      "    13.91           13.09\n",
      "    0.38           14.34\n",
      "    21.39           11.66\n",
      "    -4.89           14.31\n",
      "    5.54           13.07\n",
      "    -37.90           14.30\n",
      "    -11.39           14.11\n",
      "    10.34           13.59\n",
      "    19.00           14.32\n",
      "    167.94           14.35\n",
      "    -40.07           14.36\n",
      "    13.27           14.35\n",
      "    -11.11           14.27\n",
      "    7.57           14.23\n",
      "    -69.80           13.07\n",
      "    10.82           14.15\n",
      "    14.15           13.85\n",
      "    12.16           12.27\n",
      "    -41.29           14.38\n",
      "    -49.70           14.32\n",
      "    52.54           14.28\n",
      "    8.35           14.36\n",
      "    9.72           14.38\n",
      "    19.63           14.25\n",
      "    -13.96           14.38\n",
      "    -0.06           14.22\n",
      "    74.25           14.24\n",
      "    -1.06           14.30\n",
      "    4.84           14.38\n",
      "    9.15           14.07\n",
      "    7.57           14.28\n",
      "    14.52           14.30\n",
      "    11.17           14.22\n",
      "    -27.83           14.04\n",
      "    -16.00           14.32\n",
      "    -3.77           13.20\n",
      "    -31.60           14.18\n",
      "    -26.35           14.26\n",
      "    75.28           14.37\n",
      "    27.41           13.17\n",
      "    20.57           14.36\n",
      "    -63.28           14.40\n",
      "    1.35           13.80\n",
      "    36.81           14.35\n",
      "    -29.84           14.34\n",
      "    -48.32           12.64\n",
      "    -37.31           14.28\n",
      "    5.89           14.30\n",
      "    14.99           14.25\n",
      "    -13.61           14.39\n",
      "    1.11           13.78\n",
      "    21.34           14.35\n",
      "    -4.09           13.33\n",
      "    3.37           13.80\n",
      "    3.37           15.76\n",
      "    -18.91           12.26\n",
      "    40.97           14.25\n",
      "    -45.94           14.28\n",
      "    42.91           14.38\n",
      "    1.71           13.71\n",
      "    14.80           10.50\n",
      "    -8.69           14.33\n",
      "    -0.12           14.05\n",
      "    18.27           14.36\n",
      "    6.12           14.38\n",
      "    29.41           14.07\n",
      "    -10.26           14.29\n",
      "    44.68           14.30\n",
      "    14.46           14.22\n",
      "    6.38           14.14\n",
      "    15.62           14.32\n",
      "    3.55           14.08\n",
      "    39.83           14.38\n",
      "    530.45           14.38\n",
      "    2.00           14.38\n",
      "    -16.35           14.34\n",
      "    -33.54           14.02\n",
      "    2.76           14.33\n",
      "    7.41           14.29\n",
      "    -17.10           13.86\n",
      "    16.41           14.32\n",
      "    -1.88           13.79\n",
      "    0.87           14.28\n",
      "    15.75           14.33\n",
      "    46.66           14.16\n",
      "    -13.27           14.33\n",
      "    38.14           14.25\n",
      "    4.26           14.32\n",
      "    127.94           14.26\n",
      "    -3.42           13.97\n",
      "    -7.27           14.20\n",
      "    17.94           14.13\n",
      "    -2.00           14.10\n",
      "    -11.96           14.37\n",
      "    4.98           14.36\n",
      "    -0.45           -3.95\n",
      "    25.83           14.34\n",
      "    -26.92           14.36\n",
      "    21.04           14.34\n",
      "    0.73           14.34\n",
      "    -2.00           14.34\n",
      "    -25.66           14.26\n",
      "    -4.68           14.35\n",
      "    -2.59           14.34\n",
      "    21.80           13.79\n",
      "    -22.50           14.36\n",
      "    -39.94          -84.62\n",
      "    4.10           14.31\n",
      "    5.71           14.23\n",
      "    -13.11           14.32\n",
      "    -13.96           13.99\n",
      "    7.15           13.78\n",
      "    -84.00           14.39\n",
      "    -8.96           14.35\n",
      "    -17.92           14.24\n",
      "    -20.00           14.24\n",
      "    -36.97           14.28\n",
      "    -8.36           10.67\n",
      "    -2.29           14.07\n",
      "    0.33           12.41\n",
      "    7.65           14.21\n",
      "    11.02           13.33\n",
      "    22.33           14.39\n",
      "    -7.67           12.28\n",
      "    13.08           14.26\n",
      "    50.00           14.39\n",
      "    -61.11           14.28\n",
      "    -2.53           14.38\n",
      "    138.33           14.39\n",
      "    -15.07           14.39\n",
      "    -9.41           14.32\n",
      "    16.00           13.88\n",
      "    7.41           14.36\n",
      "    302.33           13.85\n",
      "    249.52           14.30\n",
      "    0.60           14.36\n",
      "    6.72           14.38\n",
      "    10.51           14.27\n",
      "    3.05           14.34\n",
      "    -16.71           14.28\n",
      "    31.55           14.36\n",
      "    -42.43           14.34\n",
      "    4.79           14.03\n",
      "    -8.76           13.91\n",
      "    12.92           14.22\n",
      "    -4.36           14.19\n",
      "    12.59           14.31\n",
      "    13.94           14.36\n",
      "    7.07            1.43\n",
      "    -24.55           14.37\n",
      "    21.58           14.15\n",
      "    -11.84           14.19\n",
      "    -7.54           14.37\n",
      "    -0.31           14.35\n",
      "    -21.02           13.50\n",
      "    -13.90           14.27\n",
      "    -0.32           14.10\n",
      "    -45.45           14.33\n",
      "    1.89           14.35\n",
      "    16.94           14.02\n",
      "    -16.67           14.04\n",
      "    42.86           14.12\n",
      "    21.29           13.96\n",
      "    5.38           13.51\n",
      "    -2.06           14.01\n",
      "    12.79           14.18\n",
      "    -37.37           14.34\n",
      "    11.21           14.24\n",
      "    29.03           13.22\n",
      "    3.88           14.27\n",
      "    23.16           14.39\n",
      "    -32.89           14.36\n",
      "    2.06           14.27\n",
      "    2.70           14.31\n",
      "    10.48           14.31\n",
      "    78.67           14.36\n",
      "    14.08           14.28\n",
      "    -10.13           13.88\n",
      "    -36.11           13.52\n",
      "    -61.04           14.19\n",
      "    16.29           14.00\n",
      "    32.50           13.81\n",
      "    24.85           13.66\n",
      "    8.84           14.04\n",
      "    -0.25           12.58\n",
      "    -2.88            6.26\n",
      "    90.53           14.33\n",
      "    1.97           14.38\n",
      "    63.06           14.27\n",
      "    7.48           14.25\n",
      "    -0.87           14.37\n",
      "    24.32           14.36\n",
      "    120.66           14.39\n",
      "    15.72            0.53\n",
      "    12.36           14.21\n",
      "    10.77           14.26\n",
      "    4.56           13.62\n",
      "    -1.04           14.32\n",
      "    -17.12           14.35\n",
      "    -2.20           14.38\n",
      "    0.20           13.81\n",
      "    21.92           13.94\n",
      "    15.48           14.37\n",
      "    41.31           14.29\n",
      "    -14.44           14.38\n",
      "    36.08           14.39\n",
      "    -31.49           14.38\n",
      "    -11.02           -0.79\n",
      "    -6.95           13.62\n",
      "    -12.70           14.16\n",
      "    37.57           14.35\n",
      "    -2.82           -1.03\n",
      "    3.89           14.39\n",
      "    -56.20           13.78\n",
      "    -71.25           14.34\n",
      "    9.50           14.19\n",
      "    -13.27           13.78\n",
      "    20.43           14.28\n",
      "    -28.42           14.34\n",
      "    55.07           10.32\n",
      "    6.48           14.21\n",
      "    -34.78           14.38\n",
      "    0.08            5.14\n",
      "    10.31           14.07\n",
      "    -8.99           14.34\n",
      "    -46.92           14.01\n",
      "    20.48           14.39\n",
      "    10.43           14.38\n",
      "    -19.08           14.33\n",
      "    -12.71           11.61\n",
      "    -0.05           14.39\n",
      "    -10.89           14.37\n",
      "    -39.12           14.00\n",
      "    -17.15           14.20\n",
      "    -0.05           14.35\n",
      "    -2.46           14.00\n",
      "    -1.29           14.38\n",
      "    8.78           14.04\n",
      "    -7.97           14.33\n",
      "    -24.65           13.89\n",
      "    -24.69           14.36\n",
      "    -2.23            9.52\n",
      "    -40.37           14.34\n",
      "    5.72           14.23\n",
      "    -26.41           14.29\n",
      "    -71.80           14.38\n",
      "    1.06           13.07\n",
      "    9.01           14.31\n",
      "    -11.80           11.07\n",
      "    7.09           14.27\n",
      "    3.61           14.33\n",
      "    -4.52           -3.13\n",
      "    33.33           14.38\n",
      "    4.28           13.50\n",
      "    -37.79           14.35\n",
      "    -12.25           14.19\n",
      "    -49.99           14.39\n",
      "    -15.59           14.39\n",
      "    23.22           14.01\n",
      "    -41.95           13.21\n",
      "    11.75           14.37\n",
      "    16.64           14.34\n",
      "    12.63           14.38\n",
      "    -31.35           13.65\n",
      "    10.63          -10.27\n",
      "    -28.48           14.39\n",
      "    4.05            6.75\n",
      "    -1.41            8.35\n",
      "    2.36           14.04\n",
      "    -41.23           14.27\n",
      "    -34.68           13.50\n",
      "    36.05           14.15\n",
      "    24.11           14.29\n",
      "    -75.09           14.32\n",
      "    14.73           10.10\n",
      "    -39.63           14.01\n",
      "    -11.22           14.25\n",
      "    23.88           14.36\n",
      "    14.52           14.34\n",
      "    -8.96           13.89\n",
      "    14.00           14.06\n",
      "    15.88           13.98\n",
      "    11.57            6.55\n",
      "    -2.49           14.40\n",
      "    -29.26           14.31\n",
      "    49.68           14.30\n",
      "    -1.13           13.83\n",
      "    129.44           14.37\n",
      "    -14.00           13.81\n",
      "    1.98           14.36\n",
      "    -16.67           13.86\n",
      "    18.17           14.11\n",
      "    9.65           14.35\n",
      "    -3.45           14.28\n",
      "    -1.13           14.18\n",
      "    -10.29           14.35\n",
      "    4.64           13.77\n",
      "    3.78           14.33\n",
      "    -25.13           14.35\n",
      "    3.32           14.29\n",
      "    2.15           14.26\n",
      "    13.23           13.47\n",
      "    -4.28           12.55\n",
      "    -71.43           14.38\n",
      "    2.62           14.37\n",
      "    2.05           14.38\n",
      "    -30.32           14.39\n",
      "    -68.91           14.31\n",
      "    23.06           14.21\n",
      "    7.07           14.27\n",
      "    -49.47           14.04\n",
      "    -0.92           -4.85\n",
      "    -15.25           14.33\n",
      "    -10.08           14.34\n",
      "    -4.02           14.30\n",
      "    11.56           10.47\n",
      "    -9.84           13.47\n",
      "    13.13           10.09\n",
      "    -6.89           14.11\n",
      "    8.42           14.19\n",
      "    -30.49           13.85\n",
      "    -7.62           14.31\n",
      "    43.59           14.36\n",
      "    -3.05           14.21\n",
      "    0.23           13.95\n",
      "    5.98           14.16\n",
      "    -8.21           14.22\n",
      "    -4.88           14.37\n",
      "    9.47           14.19\n",
      "    -7.09           14.31\n",
      "    19.97           14.35\n",
      "    41.82           14.22\n",
      "    -7.10           13.59\n",
      "    9.34           14.08\n",
      "    -29.66           13.97\n",
      "    89.17           14.33\n",
      "    -3.98           14.36\n",
      "    16.83           14.27\n",
      "    -24.45           14.36\n",
      "    3.17           14.35\n",
      "    0.11           13.24\n",
      "    -11.90           13.61\n",
      "    -12.84           14.24\n",
      "    15.83           14.17\n",
      "    -9.49           14.29\n",
      "    -8.24           12.80\n",
      "    27.85           14.34\n",
      "    5.01           13.45\n",
      "    6.88           13.84\n",
      "    17.95           14.39\n",
      "    10.45           14.07\n",
      "    5.11           14.38\n",
      "    31.55           12.04\n",
      "    12.05           14.27\n",
      "    -36.83           13.42\n",
      "    114.35           14.19\n",
      "    40.46           14.39\n",
      "    11.89           14.15\n",
      "    65.19           14.30\n",
      "    -0.70           14.19\n",
      "    19.36           14.32\n",
      "    -0.84           14.39\n",
      "    5.05           14.27\n",
      "    -12.04           14.13\n",
      "    -3.87           13.37\n",
      "    53.91           14.35\n",
      "    -28.57           14.35\n",
      "    -6.26           14.38\n",
      "    -7.01           14.29\n",
      "    -34.25           14.38\n",
      "    41.12           14.32\n",
      "    5.18           14.28\n",
      "    -16.53           14.09\n",
      "    2.34           14.32\n",
      "    -16.19           14.37\n",
      "    11.15           10.18\n",
      "    -7.93           13.82\n",
      "    -34.86           14.29\n",
      "    -11.29           14.33\n",
      "    -12.67           13.77\n",
      "    23.04           14.29\n",
      "    -6.09           14.35\n",
      "    -6.50           14.38\n",
      "    15.34           14.37\n",
      "    -33.77           14.38\n",
      "    -34.43           13.64\n",
      "    13.89           10.02\n",
      "    5.95           14.40\n",
      "    -48.15           14.30\n",
      "    -23.05           14.30\n",
      "    -17.79           14.32\n",
      "    -16.37           14.30\n",
      "    -7.20           14.37\n",
      "    16.52           14.28\n",
      "    -3.75           14.28\n",
      "    234.27           14.33\n",
      "    13.01           14.33\n",
      "    23.65           13.85\n",
      "    5.97           14.28\n",
      "    13.74           14.27\n",
      "    31.62           14.38\n",
      "    3.95           14.39\n",
      "    -5.95           13.44\n",
      "    14.03           14.24\n",
      "    -5.93           14.32\n",
      "    11.02           14.07\n",
      "    -12.12           14.39\n",
      "    11.52           13.81\n",
      "    21.50           14.27\n",
      "    24.74           12.38\n",
      "    -8.26           14.28\n",
      "    -3.21           14.32\n",
      "    12.85           13.63\n",
      "    3.36           14.36\n",
      "    26.34           14.25\n",
      "    -20.26           14.15\n",
      "    4.11           14.36\n",
      "    6.83           14.38\n",
      "    -53.15           14.31\n",
      "    -31.54           14.38\n",
      "    9.91           14.36\n",
      "    -47.24           13.82\n",
      "    81.62           14.38\n",
      "    -36.55           14.12\n",
      "    -54.92           14.36\n",
      "    22.82           13.71\n",
      "    -1.50           14.12\n",
      "    -1.31           14.37\n",
      "    -17.73           12.36\n",
      "    -2.77           13.93\n",
      "    -36.45           14.35\n",
      "    -35.38           14.36\n",
      "    0.20           14.39\n",
      "    23.50           -0.39\n",
      "    44.92           14.34\n",
      "    -11.13           14.13\n",
      "    -4.55           14.25\n",
      "    -24.33           14.24\n",
      "    17.25           14.36\n",
      "    -6.42           14.13\n",
      "    5.93           13.18\n",
      "    -0.80           14.39\n",
      "    -32.87           14.30\n",
      "    2.46           14.37\n",
      "    23.98           14.31\n",
      "    -23.68           14.37\n",
      "    594.44           14.38\n",
      "    -60.26            6.63\n",
      "    1.92           14.31\n",
      "    -25.43           14.38\n",
      "    37.01           14.35\n",
      "    -35.26           11.62\n",
      "    21.22           14.26\n",
      "    1.55           14.40\n",
      "    -5.28           14.08\n",
      "    -34.53           14.39\n",
      "    41.36           14.36\n",
      "    -21.35           14.28\n",
      "    -21.37           14.25\n",
      "    -37.32           14.38\n",
      "    13.24           14.26\n",
      "    -1.45           14.26\n",
      "    10.70           14.16\n",
      "    -7.13           14.35\n",
      "    6.91           14.31\n",
      "    7.86           14.27\n",
      "    2.26           13.41\n",
      "    1.97           14.32\n",
      "    37.87           14.19\n",
      "    -8.60           13.85\n",
      "    3.12           14.31\n",
      "    -13.33           14.26\n",
      "    0.27           14.30\n",
      "    40.74           14.21\n",
      "    -33.20           12.81\n",
      "    -33.33           14.31\n",
      "    25.61           14.29\n",
      "    -5.06           12.64\n",
      "    -10.81           14.33\n",
      "    -0.99           14.26\n",
      "    25.88           11.37\n",
      "    -4.40           14.34\n",
      "    -1.74           13.78\n",
      "    28.13           14.38\n",
      "    -30.59           14.35\n",
      "    -0.26           14.28\n",
      "    -3.96           14.35\n",
      "    -6.97           14.30\n",
      "    -23.84           14.38\n",
      "    13.25           14.25\n",
      "    0.84           14.16\n",
      "    -79.64           14.34\n",
      "    -27.54           14.28\n",
      "    -42.97           14.39\n",
      "    -2.09           14.21\n",
      "    -45.40           14.40\n",
      "    -34.70           14.29\n",
      "    -18.66           14.20\n",
      "    -9.38           14.40\n",
      "    -19.20           14.15\n",
      "    3.67           14.35\n",
      "    3.57           14.20\n",
      "    13.53           14.33\n",
      "    0.34           13.64\n",
      "    -51.56           14.31\n",
      "    -5.63           14.35\n",
      "    -5.25           14.17\n",
      "    -30.43           14.29\n",
      "    -2.60           14.38\n",
      "    -55.16           14.24\n",
      "    5.88           14.39\n",
      "    91.52           14.24\n",
      "    169.23           14.23\n",
      "    -44.12           14.35\n",
      "    -8.81           14.22\n",
      "    13.54           14.32\n",
      "    -30.00           14.39\n",
      "    -39.64           14.14\n",
      "    0.06           12.88\n",
      "    5.52           14.34\n",
      "    12.03           14.38\n",
      "    -7.27            8.21\n",
      "    -5.94           14.19\n",
      "    -4.33           14.35\n",
      "    -21.67           14.37\n",
      "    -19.07           14.27\n",
      "    1.05            8.35\n",
      "    -10.50           -5.73\n",
      "    3.60           14.31\n",
      "    -27.61           14.26\n",
      "    25.32           14.20\n",
      "    -8.07           14.29\n",
      "    5.63           14.10\n",
      "    29.59           14.33\n",
      "    13.50           14.39\n",
      "    -8.60           14.35\n",
      "    9.92           14.01\n",
      "    34.68           14.34\n",
      "    -13.03           14.36\n",
      "    28.79           14.16\n",
      "    13.28           11.80\n",
      "    1.03           14.27\n",
      "    26.63           14.26\n",
      "    -13.09           14.32\n",
      "    0.62           14.18\n",
      "    -35.41           14.05\n",
      "    6.85           14.01\n",
      "    40.57           14.04\n",
      "    -13.40           14.15\n",
      "    15.66           14.29\n",
      "    23.42           14.20\n",
      "    -19.48           13.09\n",
      "    -48.03           14.27\n",
      "    6.77           12.46\n",
      "    -8.00           12.79\n",
      "    -15.26           14.30\n",
      "    -74.76           14.37\n",
      "    24.50           14.12\n",
      "    -0.92            8.97\n",
      "    -35.59           14.19\n",
      "    23.78           13.30\n",
      "    36.66           14.25\n",
      "    -7.05           13.81\n",
      "    34.10           14.38\n",
      "    -19.09           14.39\n",
      "    -5.84           13.66\n",
      "    8.04           14.33\n",
      "    -3.68           14.00\n",
      "    8.23           14.22\n",
      "    -6.57           14.32\n",
      "    35.03           12.66\n",
      "    6.95           13.73\n",
      "    6.42           14.27\n",
      "    3.43           14.15\n",
      "    -6.86           14.45\n",
      "    1.43           14.28\n",
      "    -7.28           13.71\n",
      "    -40.21           14.31\n",
      "    3.96           12.14\n",
      "    -49.72           13.76\n",
      "    -50.00           14.08\n",
      "    35.08           14.11\n",
      "    6.36           14.25\n",
      "    48.91           13.96\n",
      "    -1.67           14.38\n",
      "    13.81           14.20\n",
      "    -30.00           14.39\n",
      "    9.77           13.50\n",
      "    33.47           14.25\n",
      "    -7.78           14.37\n",
      "    -56.67           14.37\n",
      "    -40.75           14.32\n",
      "    33.92           14.24\n",
      "    10.43           14.29\n",
      "    -59.21           13.93\n",
      "    -2.77           14.12\n",
      "    40.00           14.09\n",
      "    -57.50           -1.37\n",
      "    0.38           13.90\n",
      "    3.87           14.09\n",
      "    1.42           14.37\n",
      "    -60.78           14.39\n",
      "    21.60           14.17\n",
      "    44.43           14.33\n",
      "    8.45            5.70\n",
      "    -0.57           12.43\n",
      "    -7.41           14.25\n",
      "    -35.61           14.39\n",
      "    -58.70           14.35\n",
      "    4.29           14.22\n",
      "    18.57           14.26\n",
      "    -1.56           14.34\n",
      "    -21.14           14.12\n",
      "    -5.43           14.39\n",
      "    40.05           14.22\n",
      "    -77.12           14.35\n",
      "    -20.96           14.02\n",
      "    14.47           14.33\n",
      "    -2.78           14.37\n",
      "    18.53           15.02\n",
      "    22.07           14.37\n",
      "    -31.27           14.30\n",
      "    9.22           14.15\n",
      "    1.07           14.38\n",
      "    -15.46           13.91\n",
      "    29.27           14.33\n",
      "    -25.33           14.35\n",
      "    -2.01           13.79\n",
      "    2.25           11.85\n",
      "    15.11           14.05\n",
      "    0.12           14.38\n",
      "    -1.28           14.22\n",
      "    48.75           14.29\n",
      "    -14.02           14.34\n",
      "    40.96           14.23\n",
      "    13.21           12.43\n",
      "    -37.34           14.38\n",
      "    -21.02           14.30\n",
      "    -41.95           14.03\n",
      "    -13.33           14.23\n",
      "    -4.70           14.38\n",
      "    -4.62           14.32\n",
      "    13.39            8.45\n",
      "    -5.66           14.37\n",
      "    -22.73           14.06\n",
      "    17.82           14.31\n",
      "    -18.97           14.41\n",
      "    -17.33           14.38\n",
      "    0.69           14.32\n",
      "    23.09           14.26\n",
      "    -4.44           14.39\n",
      "    13.02           13.97\n",
      "    -27.22           14.33\n",
      "    29.31           14.16\n",
      "    -24.83           14.14\n",
      "    61.58           14.39\n",
      "    -33.03           14.24\n",
      "    -18.29           12.60\n",
      "    7.83           14.17\n",
      "    16.82           11.41\n",
      "    -26.77           14.30\n",
      "    10.48           14.01\n",
      "    -31.65           14.39\n",
      "    6.45           14.21\n",
      "    6.15           14.34\n",
      "    -1.01           13.65\n",
      "    1.05           13.95\n",
      "    -11.46           12.40\n",
      "    7.31            6.45\n",
      "    -37.92           14.35\n",
      "    -21.99           13.77\n",
      "    -52.17           14.34\n",
      "    -2.75           13.93\n",
      "    -18.57           14.38\n",
      "    125.66           14.37\n",
      "    7.20           14.23\n",
      "    343.95           14.24\n",
      "    54.18           14.36\n",
      "    36.95           14.38\n",
      "    -8.88           14.19\n",
      "    -10.03           14.34\n",
      "    7.00            5.19\n",
      "    97.62           14.23\n",
      "    -10.16           13.65\n",
      "    -0.32           13.22\n",
      "    17.39           14.38\n",
      "    52.60           14.33\n",
      "    -1.22           14.39\n",
      "    0.25           14.19\n",
      "    0.72           14.38\n",
      "    1.93           14.17\n",
      "    14.36           14.39\n",
      "    -2.30           14.31\n",
      "    -3.64           14.36\n",
      "    -1.86          -10.04\n",
      "    23.93           14.35\n",
      "    -10.64           13.51\n",
      "    13.67           14.33\n",
      "    71.80           14.05\n",
      "    19.11           13.84\n",
      "    -9.15           14.26\n",
      "    -34.72           14.39\n",
      "    64.62           14.25\n",
      "    -16.61           14.25\n",
      "    354.86           14.36\n",
      "    7.04           14.37\n",
      "    -21.62           14.27\n",
      "    -89.36           14.39\n",
      "    -37.43           14.13\n",
      "    -4.94           14.37\n",
      "    -20.42            8.72\n",
      "    -27.86           14.27\n",
      "    -47.56           13.10\n",
      "    14.79           14.38\n",
      "    -46.88           14.34\n",
      "    -16.14           14.35\n",
      "    -6.32           13.30\n",
      "    33.17           14.39\n",
      "    -18.03           14.27\n",
      "    -2.45           14.28\n",
      "    -5.60           14.34\n",
      "    -7.23           14.31\n",
      "    -10.26           14.36\n",
      "    1.75           13.35\n",
      "    -16.42           11.88\n",
      "    6.49           14.16\n",
      "    59.71           13.87\n",
      "    45.87           14.28\n",
      "    2.90           14.32\n",
      "    6.86           14.12\n",
      "    9.03           12.19\n",
      "    12.00           14.38\n",
      "    1.25           14.36\n",
      "    13.70           13.60\n",
      "    3.37           14.36\n",
      "    6.06           14.12\n",
      "    36.42           13.95\n",
      "    8.11           14.39\n",
      "    -5.33           14.37\n",
      "    38.73           14.28\n",
      "    16.57           12.91\n",
      "    -14.73           14.35\n",
      "    42.50           14.27\n",
      "    -9.79           14.36\n",
      "    1058.57           14.17\n",
      "    5.97           10.64\n",
      "    84.23           14.08\n",
      "    6.39           14.39\n",
      "    6.89           14.21\n",
      "    0.98           14.39\n",
      "    16.42            3.03\n",
      "    15.59           14.19\n",
      "    9.23           14.28\n",
      "    -10.62           14.17\n",
      "    11.54           14.26\n",
      "    -76.26           14.35\n",
      "    19.17           14.22\n",
      "    11.62           -1.52\n",
      "    22.77           13.73\n",
      "    19.96           14.29\n",
      "    24.46           14.32\n",
      "    -21.92           13.95\n",
      "    -7.36            9.88\n",
      "    3.73           14.27\n",
      "    3.07            7.48\n",
      "    -8.81           14.38\n",
      "    16.90           14.32\n",
      "    6.18           14.24\n",
      "    -0.57           14.37\n",
      "    21.22           -5.68\n",
      "    -49.22           14.11\n",
      "    6.35            9.67\n",
      "    -30.73           14.17\n",
      "    13.38           14.09\n",
      "    -28.63           13.15\n",
      "    6.96           14.21\n",
      "    22.27           13.70\n",
      "    -28.60           14.37\n",
      "    7.24           14.30\n",
      "    -27.13           14.29\n",
      "    7.90           13.54\n",
      "    137.03           14.35\n",
      "    25.36           14.14\n",
      "    1.60           11.08\n",
      "    10.36           14.21\n",
      "    3.45           14.14\n",
      "    -1.91           14.38\n",
      "    -16.76           13.53\n",
      "    -6.09           12.51\n",
      "    -25.47           10.22\n",
      "    37.18           14.36\n",
      "    13.46           14.05\n",
      "    -18.33           14.22\n",
      "    39.01           14.13\n",
      "    14.18           14.32\n",
      "    37.64           14.12\n",
      "    -4.87           -6.45\n",
      "    -46.67           14.40\n",
      "    -11.39           14.32\n",
      "    10.03          -15.58\n",
      "    132.51           14.27\n",
      "    -50.29           14.34\n",
      "    -81.18           14.38\n",
      "    -36.64           14.12\n",
      "    5.43           14.30\n",
      "    22.72           14.29\n",
      "    7.70           14.38\n",
      "    21.41          -14.66\n",
      "    5.94           14.29\n",
      "    -6.08           14.35\n",
      "    20.30           14.14\n",
      "    -15.21           14.23\n",
      "    23.61           14.33\n",
      "    47.83           13.89\n",
      "    80.73           14.31\n",
      "    4.04           14.33\n",
      "    16.28           14.08\n",
      "    -10.66           14.04\n",
      "    -3.46           14.25\n",
      "    -4.69           14.36\n",
      "    5.71           14.38\n",
      "    -0.31           13.50\n",
      "    21.17           14.24\n",
      "    -9.85           14.50\n",
      "    8.17           14.09\n",
      "    20.13           14.34\n",
      "    -2.42           11.73\n",
      "    3.21           14.32\n",
      "    -46.51           14.33\n",
      "    3.42           14.28\n",
      "    11.94           14.39\n",
      "    -7.40           14.29\n",
      "    -29.11           14.39\n",
      "    228.21           14.39\n",
      "    -17.28           14.24\n",
      "    4.62           14.30\n",
      "    -7.30           -4.27\n",
      "    21.03           14.29\n",
      "    -15.35           14.34\n",
      "    -20.89           14.30\n",
      "    -2.66           14.38\n",
      "    7.88           14.18\n",
      "    -33.88           14.31\n",
      "    3.75           14.36\n",
      "    -1.13           14.20\n",
      "    21.05           13.04\n",
      "    -8.30           14.03\n",
      "    24.60           14.05\n",
      "    33.33           14.30\n",
      "    -9.58           12.53\n",
      "    -11.77           13.21\n",
      "    27.23           13.74\n",
      "    11.95           14.07\n",
      "    27.43           14.28\n",
      "    -5.24           13.72\n",
      "    24.89           14.18\n",
      "    -2.16           14.18\n",
      "    12.79           14.11\n",
      "    -14.71           14.37\n",
      "    7.28           13.90\n",
      "    -5.62           14.28\n",
      "    -15.97           14.37\n",
      "    -19.92           13.83\n",
      "    7.79           14.05\n",
      "    -21.67           14.25\n",
      "    72.20           14.43\n",
      "    4.77            9.63\n",
      "    -10.64           13.49\n",
      "    -59.47           14.45\n",
      "    -8.53           14.37\n",
      "    6.98            7.82\n",
      "    4.83           14.27\n",
      "    10.13           14.01\n",
      "    -36.79           14.36\n",
      "    -29.38           14.36\n",
      "    2.67           14.34\n",
      "    -8.54           14.36\n",
      "    -25.83           13.95\n",
      "    -22.35           13.85\n",
      "    -74.20           14.07\n",
      "    21.48           14.12\n",
      "    -45.17           14.24\n",
      "    36.41           14.36\n",
      "    -5.99           14.28\n",
      "    -17.93           14.21\n",
      "    -16.20           14.20\n",
      "    21.84           14.25\n",
      "    0.94           14.38\n",
      "    -33.59           14.09\n",
      "    25.00           14.22\n",
      "    -21.82           13.62\n",
      "    31.83           12.92\n",
      "    -0.31           13.22\n",
      "    30.23           14.02\n",
      "    0.47           14.39\n",
      "    -14.29           14.36\n",
      "    11.52           12.68\n",
      "    -26.06           14.25\n",
      "    -16.51           14.25\n",
      "    -36.66           14.34\n",
      "    -0.08           12.39\n",
      "    -12.30           14.38\n",
      "    0.96           14.39\n",
      "    -3.55           13.38\n",
      "    -2.97           14.38\n",
      "    -8.38           14.34\n",
      "    -22.01           14.37\n",
      "    -12.41           14.05\n",
      "    1.85           14.38\n",
      "    -14.03           14.35\n",
      "    -1.11           14.30\n",
      "    -6.31           14.04\n",
      "    -32.16           14.32\n",
      "    151.62           14.39\n",
      "    7.07           14.38\n",
      "    -23.66           14.02\n",
      "    3.58           13.57\n",
      "    -20.58           14.39\n",
      "    -8.18           14.37\n",
      "    31.68           14.35\n",
      "    -9.09           14.38\n",
      "    -18.29           14.18\n",
      "    4.79            3.38\n",
      "    -33.60           14.32\n",
      "    151.43           14.36\n",
      "    95.10           14.36\n",
      "    -30.34           14.37\n",
      "    11.93           13.85\n",
      "    -44.23           14.34\n",
      "    -4.41           13.98\n",
      "    -58.02           14.32\n",
      "    29.71           11.99\n",
      "    1.09           14.37\n",
      "    -36.03           14.20\n",
      "    20.00           14.38\n",
      "    31.51           14.36\n",
      "    -21.64           14.30\n",
      "    217.76           14.38\n",
      "    2.65           14.32\n",
      "    -15.01           14.22\n",
      "    9.43           13.57\n",
      "    -24.85           14.15\n",
      "    -20.04           14.32\n",
      "    -32.17           14.28\n",
      "    -7.72           14.24\n",
      "    8.43           13.91\n",
      "    -26.83           14.30\n",
      "    -37.77           14.19\n",
      "    6.45            6.11\n",
      "    37.58           14.05\n",
      "    -51.10           14.07\n",
      "    -7.09           14.37\n",
      "    -8.41           14.18\n",
      "    13.02           14.25\n",
      "    6.40           12.21\n",
      "    1.45           14.25\n",
      "    -37.73           14.06\n",
      "    -4.82           13.74\n",
      "    1.22           14.39\n",
      "    0.11           14.16\n",
      "    -27.98           14.33\n",
      "    -24.59           14.25\n",
      "    -6.53           14.22\n",
      "    13.35           14.23\n",
      "    1.80           14.26\n",
      "    10.92           13.59\n",
      "    -7.71           14.31\n",
      "    -17.04           14.36\n",
      "    -11.23           14.34\n",
      "    -6.99           14.35\n",
      "    -14.64           14.30\n",
      "    -14.29            8.51\n",
      "    -6.85           14.31\n",
      "    -33.33           14.31\n",
      "    -1.19           14.36\n",
      "    10.14            8.88\n",
      "    -54.34           14.39\n",
      "    -3.50           11.89\n",
      "    27.53           10.10\n",
      "    23.58           14.39\n",
      "    -76.54           13.58\n",
      "    35.02           13.90\n",
      "    15.91           13.84\n",
      "    35.77           14.36\n",
      "    10.39           14.26\n",
      "    33.01           14.20\n",
      "    94.62           14.28\n",
      "    3.13           12.62\n",
      "    -24.64           14.32\n",
      "    17.84           14.32\n",
      "    7.83           14.37\n",
      "    1.82           13.40\n",
      "    50.88           14.20\n",
      "    -3.24           13.09\n",
      "    -22.42           14.36\n",
      "    -6.67           14.34\n",
      "    12.95            5.69\n",
      "    13.41           14.39\n",
      "    -3.45           14.33\n",
      "    -1.08           14.19\n",
      "    23.67           14.26\n",
      "    9.81           14.31\n",
      "    9.59           14.16\n",
      "    9.73           14.33\n",
      "    -0.53           14.24\n",
      "    -34.90           14.29\n",
      "    -21.59           12.76\n",
      "    82.22           14.29\n",
      "    8.57           13.14\n",
      "    1.37           14.32\n",
      "    35.87           14.35\n",
      "    14.48           14.05\n",
      "    37.91           14.29\n",
      "    -2.46           14.34\n",
      "    4.11           14.36\n",
      "    5.72           12.69\n",
      "    -8.84           14.22\n",
      "    -1.98           14.38\n",
      "    -10.67           14.26\n",
      "    13.86           14.30\n",
      "    17.79           14.36\n",
      "    36.47           12.63\n",
      "    -14.47           14.35\n",
      "    2.62           15.96\n",
      "    10.22           14.24\n",
      "    65.52           14.28\n",
      "    -9.78           14.38\n",
      "    19.34           14.33\n",
      "    -5.81           13.94\n",
      "    -10.29           14.10\n",
      "    43.37           14.30\n",
      "    -9.18           14.30\n",
      "    2.74           12.41\n",
      "    18.79           13.73\n",
      "    -17.35           14.14\n",
      "    -23.01           14.20\n",
      "    62.31           14.37\n",
      "    1.67           14.25\n",
      "    -13.16           14.33\n",
      "    -28.92           14.08\n",
      "    4.85           13.95\n",
      "    33.27           14.34\n",
      "    32.91           14.25\n",
      "    -19.49           14.24\n",
      "    -5.49           14.53\n",
      "    -0.97           13.89\n",
      "    -45.82           14.28\n",
      "    -22.73           14.35\n",
      "    13.95           14.37\n",
      "    -7.80           14.32\n",
      "    61.43           14.26\n",
      "    -3.04           14.16\n",
      "    -15.03           14.36\n",
      "    -7.78           14.36\n",
      "    -11.79           13.42\n",
      "    -6.86           14.35\n",
      "    10.00           14.07\n",
      "    22.94           13.87\n",
      "    -42.00           14.27\n",
      "    -0.76           -5.57\n",
      "    9.89           14.39\n",
      "    -2.39           13.62\n",
      "    -13.48           14.13\n",
      "    0.27            7.43\n",
      "    199.03           14.27\n",
      "    -33.82           14.32\n",
      "    -11.63           14.17\n",
      "    7.37           14.14\n",
      "    -17.61           14.33\n",
      "    23.61           14.33\n",
      "    37.59           14.29\n",
      "    2.89           14.11\n",
      "    0.24           14.37\n",
      "    -2.39           13.96\n",
      "    -5.07           14.35\n",
      "    -23.07           14.31\n",
      "    8.02           14.40\n",
      "    -0.42           14.04\n",
      "    9.30           14.27\n",
      "    0.72           14.39\n",
      "    -82.60           14.30\n",
      "    45.12           14.36\n",
      "    8.90           14.37\n",
      "    -21.58           14.25\n",
      "    -25.81           14.39\n",
      "    90.36           14.37\n",
      "    -5.93           14.14\n",
      "    0.91           13.44\n",
      "    -6.04           13.99\n",
      "    -14.32           14.22\n",
      "    -3.69           14.20\n",
      "    -5.81           14.17\n",
      "    -11.23           13.21\n",
      "    -61.58           14.35\n",
      "    7.05           14.36\n",
      "    -21.25           14.21\n",
      "    72.29           13.94\n",
      "    -48.23           14.00\n",
      "    46.37           12.78\n",
      "    -48.91           14.23\n",
      "    -28.86           14.26\n",
      "    -0.22           13.80\n",
      "    -11.44           14.38\n",
      "    -14.08           14.15\n",
      "    -76.43           14.38\n",
      "    -0.40           13.89\n",
      "    -1.91           14.13\n",
      "    5.66           14.35\n",
      "    -3.17           14.39\n",
      "    -33.33           13.62\n",
      "    -28.76           14.57\n",
      "    15.07           13.25\n",
      "    54.07           14.38\n",
      "    -11.33           14.26\n",
      "    -4.54           11.25\n",
      "    16.44           14.20\n",
      "    49.77           13.22\n",
      "    1.77           14.38\n",
      "    -18.46           14.32\n",
      "    114.29           14.35\n",
      "    -13.86            5.32\n",
      "    -1.83           13.38\n",
      "    52.10           14.27\n",
      "    -22.35           14.38\n",
      "    -30.47           13.86\n",
      "    22.22           14.29\n",
      "    11.03           12.50\n",
      "    -22.11           14.03\n",
      "    26.24           14.33\n",
      "    1.52           13.61\n",
      "    19.11           14.09\n",
      "    12.76           14.17\n",
      "    5.22           13.55\n",
      "    11.44           14.37\n",
      "    46.02           14.23\n",
      "    14.42           14.20\n",
      "    -2.04            3.66\n",
      "    5.26           10.82\n",
      "    -1.71           14.31\n",
      "    205.17           14.33\n",
      "    -4.42           14.02\n",
      "    11.93           14.24\n",
      "    -3.03           13.58\n",
      "    34.45           14.15\n",
      "    -22.30           14.37\n",
      "    -23.16           13.81\n",
      "    21.11           14.37\n",
      "    -4.23           14.08\n",
      "    21.29           14.34\n",
      "    -4.07           13.70\n",
      "    4.85           14.37\n",
      "    3.13           14.25\n",
      "    18.22           14.34\n",
      "    10.70           14.29\n",
      "    6.28           14.04\n",
      "    1.47           14.30\n",
      "    11.29           14.33\n",
      "    -5.26           14.36\n",
      "    8.99           14.09\n",
      "    33.50           13.81\n",
      "    11.60           14.08\n",
      "    -33.61           14.29\n",
      "    50.73           14.09\n",
      "    -26.47           14.00\n",
      "    3.25           -0.98\n",
      "    28.56           13.91\n",
      "    5.00           14.25\n",
      "    -10.32           14.28\n",
      "    -22.80           14.43\n",
      "    -7.39           14.14\n",
      "    -10.87           14.29\n",
      "    12.93           14.18\n",
      "    -17.57           13.93\n",
      "    12.67           14.32\n",
      "    -5.43           14.39\n",
      "    18.92           13.94\n",
      "    -29.48           14.30\n",
      "    -7.43           14.26\n",
      "    -9.97           11.29\n",
      "    127.92           14.38\n",
      "    21.93           14.10\n",
      "    41.42           13.57\n",
      "    8.33           12.96\n",
      "    -0.20           14.39\n",
      "    7.22            1.53\n",
      "    -0.16           11.56\n",
      "    17.06           13.84\n",
      "    133.80           14.31\n",
      "    -0.53           14.12\n",
      "    -4.47           13.80\n",
      "    4.76           14.21\n",
      "    -28.05           13.53\n",
      "    -2.89           13.13\n",
      "    7.60           14.35\n",
      "    19.20           14.35\n",
      "    22.77           14.37\n",
      "    -1.22           14.11\n",
      "    15.19           14.35\n",
      "    22.50           14.32\n",
      "    -0.12           14.25\n",
      "    -16.67           14.17\n",
      "    14.06           13.97\n",
      "    25.88           14.24\n",
      "    -3.57           14.19\n",
      "    40.43           14.15\n",
      "    -7.84           14.24\n",
      "    0.54           14.31\n",
      "    6.05           14.16\n",
      "    141.24           14.35\n",
      "    7.85           14.25\n",
      "    6.13           14.36\n",
      "    4.39           14.38\n",
      "    -11.40           14.22\n",
      "    27.33           14.37\n",
      "    45.56           13.28\n",
      "    10.26           13.97\n",
      "    83.62           14.25\n",
      "    -0.51           14.39\n",
      "    -11.16           14.38\n",
      "    -9.44           14.31\n",
      "    92.63           14.39\n",
      "    13.95           14.29\n",
      "    -7.88           14.15\n",
      "    10.87           14.34\n",
      "    6.61           11.13\n",
      "    -9.47           14.19\n",
      "    18.53           14.38\n",
      "    -27.37           14.29\n",
      "    1.24           14.39\n",
      "    19.45           14.01\n",
      "    10.50           14.38\n",
      "    60.85           14.28\n",
      "    1.97           14.20\n",
      "    31.72           14.31\n",
      "    -4.17           13.98\n",
      "    -23.33           14.15\n",
      "    -0.83           13.93\n",
      "    -10.19           12.34\n",
      "    3.29           13.88\n",
      "    -4.46           13.72\n",
      "    -10.64           14.24\n",
      "    0.67           14.28\n",
      "    -14.41           14.33\n",
      "    -53.11           14.35\n",
      "    -12.07           16.21\n",
      "    -23.33           14.15\n",
      "    3.49           14.38\n",
      "    -25.81           14.04\n",
      "    43.27           14.00\n",
      "    147.50           14.36\n",
      "    3.93           14.38\n",
      "    4.37           14.32\n",
      "    -22.25           14.39\n",
      "    17.86           13.85\n",
      "    -12.32           12.55\n",
      "    -2.48           14.33\n",
      "    -47.87           14.28\n",
      "    -34.19           14.34\n",
      "    10.90          -19.27\n",
      "    -20.69           14.38\n",
      "    -11.91           13.93\n",
      "    1.04            9.29\n",
      "    3.23           14.37\n",
      "    -36.51           14.39\n",
      "    -43.77           14.37\n",
      "    25.42           14.25\n",
      "    -23.47           13.49\n",
      "    18.24           14.14\n",
      "    41.59           14.34\n",
      "    -5.59           14.38\n",
      "    -0.88           14.24\n",
      "    22.22           14.39\n",
      "    6.66           14.11\n",
      "    -26.94            6.30\n",
      "    3.15           13.94\n",
      "    -9.86           14.29\n",
      "    -12.34           13.67\n",
      "    0.01           14.27\n",
      "    -65.95           14.38\n",
      "    1948.97           14.39\n",
      "    -7.03           14.16\n",
      "    1.91           14.22\n",
      "    -12.35           11.20\n",
      "    40.29           14.28\n",
      "    1.26           14.39\n",
      "    -15.73           14.30\n",
      "    -28.21           14.28\n",
      "    18.04           14.20\n",
      "    61.60           14.35\n",
      "    49.75           14.07\n",
      "    -1.97           12.69\n",
      "    12.82           14.24\n",
      "    15.29           14.37\n",
      "    3.69           14.29\n",
      "    4.90           14.28\n",
      "    33.54           14.35\n",
      "    6.62           14.35\n",
      "    -1.76           13.28\n",
      "    -60.00           14.35\n",
      "    -48.01           14.37\n",
      "    -12.22           14.38\n",
      "    13.06           14.35\n",
      "    -0.44           14.26\n",
      "    15.05           12.66\n",
      "    -11.11           14.18\n",
      "    -12.47           14.34\n",
      "    -35.59           14.17\n",
      "    9.47           14.17\n",
      "    -6.66           14.29\n",
      "    14.51           -3.15\n",
      "    -27.85           14.25\n",
      "    180.00           14.34\n",
      "    10.38           14.28\n",
      "    64.51           14.33\n",
      "    13.63           14.31\n",
      "    -17.58           14.26\n",
      "    -2.86           14.34\n",
      "    -1.59           13.72\n",
      "    -26.73           14.30\n",
      "    -7.47           13.36\n",
      "    38.16           14.17\n",
      "    23.88           14.08\n",
      "    17.86           14.30\n",
      "    -42.27           14.36\n",
      "    -34.40           14.17\n",
      "    -20.52           14.32\n",
      "    -25.93           14.39\n",
      "    -19.60           14.12\n",
      "    -15.39           13.98\n",
      "    -3.47           14.37\n",
      "    4.17           14.38\n",
      "    -12.20           14.25\n",
      "    880.76           14.35\n",
      "    1.25           13.03\n",
      "    9.93           14.27\n",
      "    57.84           14.38\n",
      "    97.19           14.36\n",
      "    15.18           12.92\n",
      "    -51.01           14.37\n",
      "    19.21            9.05\n",
      "    0.72           14.39\n",
      "    -13.75           14.37\n",
      "    -3.68           14.25\n",
      "    -3.74           12.88\n",
      "    -2.56           14.34\n",
      "    -4.68           14.22\n",
      "    24.50           14.31\n",
      "    33.72           14.31\n",
      "    -8.97           14.26\n",
      "    -0.92           14.31\n",
      "    101.81           14.33\n",
      "    -6.79            5.04\n",
      "    19.08           14.19\n",
      "    -38.24           14.38\n",
      "    59.93           13.85\n",
      "    37.63           14.38\n",
      "    -24.26           14.12\n",
      "    9.88           -5.07\n",
      "    -2.72           14.35\n",
      "    -19.31           14.24\n",
      "    5.73           13.86\n",
      "    0.89           14.33\n",
      "    14.70           13.83\n",
      "    4.06           14.33\n",
      "    6.43           13.97\n",
      "    1.69           14.33\n",
      "    -1.99           10.58\n",
      "    -16.99           14.26\n",
      "    -35.71           14.30\n",
      "    13.32           14.17\n",
      "    -30.91           13.63\n",
      "    6.01           14.11\n",
      "    -32.24           13.00\n",
      "    -19.49           13.84\n",
      "    -19.74           13.50\n",
      "    8.60           13.98\n",
      "    -46.42           14.27\n",
      "    0.93           14.03\n",
      "    7.66           14.18\n",
      "    -6.30           14.33\n",
      "    -8.73           14.27\n",
      "    30.07           14.28\n",
      "    13.97           13.65\n",
      "    5.00           14.35\n",
      "    17.44           14.09\n",
      "    -9.34           14.24\n",
      "    -13.77           14.16\n",
      "    6.67           14.29\n",
      "    4.45           14.22\n",
      "    24.67           14.01\n",
      "    9.21           14.27\n",
      "    -19.18           14.22\n",
      "    -13.79           14.18\n",
      "    18.71           13.09\n",
      "    7.17           14.32\n",
      "    -17.50           14.39\n",
      "    27.94           14.38\n",
      "    -0.99           14.33\n",
      "    26.58           14.15\n",
      "    -18.09           13.85\n",
      "    -1.05           14.33\n",
      "    -6.54           14.26\n",
      "    10.37           13.31\n",
      "    -3.63           14.83\n",
      "    -29.54           13.78\n",
      "    3.56           13.87\n",
      "    -27.13           14.17\n",
      "    8.52           14.33\n",
      "    9.13           14.19\n",
      "    -70.52           14.32\n",
      "    -55.58           14.28\n",
      "    19.12           13.05\n",
      "    -51.60           13.89\n",
      "    30.65           14.33\n",
      "    -4.00           14.38\n",
      "    46.73           14.14\n",
      "    41.99           14.38\n",
      "    -19.75           14.33\n",
      "    -13.87           14.37\n",
      "    -2.48           14.27\n",
      "    -10.04           14.24\n",
      "    -35.54           14.39\n",
      "    -14.54           14.16\n",
      "    1.53            8.19\n",
      "    -65.46           14.37\n",
      "    -30.82           13.55\n",
      "    -21.31           14.27\n",
      "    0.13           14.15\n",
      "    45.71           14.26\n",
      "    -2.56           14.37\n",
      "    -28.32           14.37\n",
      "    -13.33           14.38\n",
      "    -0.70           14.36\n",
      "    8.51           14.17\n",
      "    -5.23           13.98\n",
      "    -20.15           14.24\n",
      "    8.60           14.32\n",
      "    30.35           14.19\n",
      "    1.73           14.26\n",
      "    0.16           14.23\n",
      "    0.97           14.26\n",
      "    -40.51           14.34\n",
      "    -8.56           14.38\n",
      "    -21.43           14.38\n",
      "    -40.19           14.39\n",
      "    -15.28           14.35\n",
      "    -49.37           14.19\n",
      "    12.50           14.31\n",
      "    -8.83           14.32\n",
      "    -18.48           14.09\n",
      "    9.55            4.70\n",
      "    -43.34           14.37\n",
      "    -17.11           14.20\n",
      "    -32.38           14.34\n",
      "    7.46           11.68\n",
      "    33.33           14.32\n",
      "    38.42           14.39\n",
      "    38.33           14.31\n",
      "    -14.69           14.36\n",
      "    -40.17           14.34\n",
      "    -2.43           14.19\n",
      "    11.11           14.37\n",
      "    -56.91           14.24\n",
      "    1484.70           14.37\n",
      "    4.58           14.31\n",
      "    9.11           13.69\n",
      "    -24.15           14.37\n",
      "    7.15           13.84\n",
      "    12.19           14.32\n",
      "    -8.47           14.24\n",
      "    -15.15           14.29\n",
      "    47.22           14.30\n",
      "    12.45           14.27\n",
      "    11.82           14.20\n",
      "    -9.94           14.32\n",
      "    28.31           11.75\n",
      "    -23.61           14.30\n",
      "    -22.59           14.39\n",
      "    -26.59           13.89\n",
      "    -19.10           14.21\n",
      "    -29.50           14.15\n",
      "    8.62           13.46\n",
      "    39.37           13.04\n",
      "    -47.14           14.39\n",
      "    5.11           14.39\n",
      "    -6.19           14.25\n",
      "    57.77           14.30\n",
      "    -11.41           14.25\n",
      "    -20.14           12.91\n",
      "    1.76           12.98\n",
      "    27.36           14.36\n",
      "    20.16           14.32\n",
      "    38.24           11.53\n",
      "    5.51           13.12\n",
      "    28.38           14.34\n",
      "    10.26           14.02\n",
      "    -15.68           14.23\n",
      "    4.04           14.16\n",
      "    11.33           14.12\n",
      "    -64.25           14.38\n",
      "    -19.96           14.33\n",
      "    7.88           14.30\n",
      "    4.22           14.34\n",
      "    21.89           14.03\n",
      "    22.25           14.34\n",
      "    -25.72           14.33\n",
      "    0.14           14.25\n",
      "    545.83           14.31\n",
      "    1.43           14.26\n",
      "    18.96           14.35\n",
      "    6.37           14.16\n",
      "    -38.15           14.39\n",
      "    -14.38           14.24\n",
      "    -79.17           13.91\n",
      "    -8.17           14.33\n",
      "    32.50           14.39\n",
      "    55.00           14.39\n",
      "    30.66           14.27\n",
      "    20.95           14.39\n",
      "    2.44           14.24\n",
      "    11.05           14.28\n",
      "    2.86           14.28\n",
      "    12.22           14.38\n",
      "    -23.03           14.20\n",
      "    -31.70           14.35\n",
      "    61.07           14.35\n",
      "    36.26           13.92\n",
      "    16.85           14.05\n",
      "    11.39           12.77\n",
      "    -15.58           14.31\n",
      "    62.44           14.31\n",
      "    -0.81           14.06\n",
      "    18.57           14.89\n",
      "    -7.64           14.30\n",
      "    -73.11           13.92\n",
      "    -4.21           14.37\n",
      "    21.46           13.44\n",
      "    10.78           14.29\n",
      "    -4.13           14.01\n",
      "    522.22           14.36\n",
      "    58.97           14.36\n",
      "    6.18           14.38\n",
      "    -9.09           14.37\n",
      "    -8.23           14.31\n",
      "    4.20           14.39\n",
      "    0.90           14.36\n",
      "    2.55           14.36\n",
      "    -17.31           12.89\n",
      "    1.15           14.32\n",
      "    16.51            9.59\n",
      "    -28.40           14.37\n",
      "    77.69           14.34\n",
      "    6.77           14.34\n",
      "    -22.02           14.39\n",
      "    6.69           14.23\n",
      "    -11.14           14.37\n",
      "    -21.05           14.16\n",
      "    6.10           11.72\n",
      "    12.16           13.21\n",
      "    0.17           11.78\n",
      "    -15.30           14.26\n",
      "    -3.01           14.37\n",
      "    7.98           13.77\n",
      "    -4.33           14.30\n",
      "    3.66           14.32\n",
      "    0.42           12.15\n",
      "    18.78           14.29\n",
      "    -16.38           14.36\n",
      "    16.87           12.95\n",
      "    -11.49           14.30\n",
      "    -5.57           14.39\n",
      "    12.37           14.07\n",
      "    28.57           14.28\n",
      "    159.49           14.35\n",
      "    34.78           14.14\n",
      "    60.82           14.35\n",
      "    4.21           -0.88\n",
      "    -49.30           14.31\n",
      "    -5.29           13.86\n",
      "    7.66           14.01\n",
      "    -20.96           14.39\n",
      "    22.14           14.38\n",
      "    3.47           14.24\n",
      "    -3.05           13.87\n",
      "    -5.84           14.36\n",
      "    -13.07           14.35\n",
      "    20.91           14.35\n",
      "    23.63           14.34\n",
      "    -6.35           13.50\n",
      "    -33.09           14.35\n",
      "    4.30           13.51\n",
      "    19.11           14.19\n",
      "    -1.67           14.39\n",
      "    -16.22           14.26\n",
      "    25.13           13.80\n",
      "    65.71           14.27\n",
      "    -14.48           14.55\n",
      "    -9.59           14.34\n",
      "    23.78           14.32\n",
      "    40.76           14.17\n",
      "    -43.86           14.35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    3.75           14.39\n",
      "    18.90           14.39\n",
      "    -35.99           14.39\n",
      "    -5.51           14.21\n",
      "    23.41           13.65\n",
      "    22.84           13.51\n",
      "    -11.56           14.21\n",
      "    11.44           14.17\n",
      "    -1.49           13.61\n",
      "    12.62           14.32\n",
      "    60.49           14.35\n",
      "    18.75           14.35\n",
      "    -14.12           14.05\n",
      "    -2.21           14.21\n",
      "    33.50           14.33\n",
      "    -5.43           14.37\n",
      "    52.42           14.27\n",
      "    7.79           10.49\n",
      "    -38.97           14.03\n",
      "    14.42           14.33\n",
      "    19.32           14.14\n",
      "    -20.28           13.20\n",
      "    38.32           14.18\n",
      "    28.00           14.36\n",
      "    3.97           14.39\n",
      "    7.62           14.04\n",
      "    13.12           14.35\n",
      "    -70.48           14.29\n",
      "    42.77           14.34\n",
      "    18.53           14.32\n",
      "    -18.17           14.28\n",
      "    94.55           14.19\n",
      "    12.27           14.34\n",
      "    -15.63           14.39\n",
      "    35.45           14.38\n",
      "    -27.61           14.12\n",
      "    -7.09           14.35\n",
      "    -26.67           12.69\n",
      "    -2.70           13.75\n",
      "    7.89           13.63\n",
      "    17.42           13.92\n",
      "    6.89           14.25\n",
      "    -30.67           14.31\n",
      "    -6.67           14.33\n",
      "    5.23           13.61\n",
      "    56.11           14.15\n",
      "    -3.70           13.68\n",
      "    -16.70           14.38\n",
      "    -33.85           13.79\n",
      "    43.85           14.26\n",
      "    3.59           13.30\n",
      "    -5.66           13.80\n",
      "    -2.56           13.58\n",
      "    -3.17           11.09\n",
      "    -67.71           14.38\n",
      "    25.49           14.36\n",
      "    -19.94           14.36\n",
      "    66.13           14.28\n",
      "    11.77            9.72\n",
      "    1.17           14.38\n",
      "    -28.07           13.98\n",
      "    11.94           14.28\n",
      "    -37.65           14.29\n",
      "    0.79           12.70\n",
      "    177.62           14.33\n",
      "    -45.60           14.24\n",
      "    -27.13           12.33\n",
      "    2.81           14.39\n",
      "    1.95           14.39\n",
      "    4.92           14.21\n",
      "    -14.81           14.25\n",
      "    3.75           13.13\n",
      "    0.59           14.36\n",
      "    5.45           14.30\n",
      "    -6.81           14.38\n",
      "    39.05           14.19\n",
      "    0.51           14.31\n",
      "    17.28           14.24\n",
      "    47.65           14.39\n",
      "    3.17           14.17\n",
      "    -15.35           14.25\n",
      "    50.76           14.15\n",
      "    -15.20           13.18\n",
      "    17.56           14.38\n",
      "    16.66           14.32\n",
      "    -48.95           13.93\n",
      "    16.87           14.13\n",
      "    -27.29           14.30\n",
      "    33.07           14.38\n",
      "    12.66           14.35\n",
      "    -21.09           13.85\n",
      "    2.65           14.38\n",
      "    43.12           14.03\n",
      "    6.48           14.35\n",
      "    -3.06           14.39\n",
      "    16.45           14.29\n",
      "    13.58           14.31\n",
      "    -2.67           14.33\n",
      "    67.37           14.38\n",
      "    48.59           14.32\n",
      "    2.30           14.35\n",
      "    44.71           14.34\n",
      "    -47.93           14.39\n",
      "    34.14           14.21\n",
      "    3.50           14.35\n",
      "    12.77           14.35\n",
      "    1.78           11.91\n",
      "    10.86           14.02\n",
      "    5.16           13.15\n",
      "    207.77           14.37\n",
      "    -62.69           14.29\n",
      "    9.30           14.21\n",
      "    40.09           14.37\n",
      "    139.26           14.24\n",
      "    6.38           13.44\n",
      "    -39.85            7.76\n",
      "    7.58           14.30\n",
      "    -7.38           11.76\n",
      "    12.39           14.38\n",
      "    3.92           14.10\n",
      "    30.57           14.38\n",
      "    0.07           14.06\n",
      "    14.26           14.11\n",
      "    -16.67           14.34\n",
      "    -13.26           14.39\n",
      "    15.87           13.63\n",
      "    5.15           14.26\n",
      "    3.34           14.32\n",
      "    -7.69           14.39\n",
      "    -27.46           14.23\n",
      "    -4.90           14.29\n",
      "    2.81           14.26\n",
      "    -0.57           14.36\n",
      "    2.70           14.24\n",
      "    21.06           14.32\n",
      "    6.24           14.30\n",
      "    -39.50           14.24\n",
      "    -2.14           14.29\n",
      "    30.82           14.24\n",
      "    -4.49           14.33\n",
      "    -5.03           14.09\n",
      "    -20.04           14.34\n",
      "    8.81           14.31\n",
      "    -36.60           14.38\n",
      "    6.53           14.31\n",
      "    70.03           14.33\n",
      "    -1.67           14.31\n",
      "    -25.20           14.32\n",
      "    464.36           14.32\n",
      "    -0.22           13.76\n",
      "    -14.04           14.36\n",
      "    -0.14            7.25\n",
      "    -0.57           14.34\n",
      "    5.59            4.57\n",
      "    -23.13           14.13\n",
      "    61.07           14.35\n",
      "    7.51           13.93\n",
      "    -45.15           14.38\n",
      "    -11.84           14.37\n",
      "    -39.60           14.31\n",
      "    -32.73           14.37\n",
      "    19.88           14.24\n",
      "    -2.86           14.38\n",
      "    -25.60           14.29\n",
      "    -51.16           14.32\n",
      "    -13.34           14.26\n",
      "    -8.55           14.28\n",
      "    -1.96           14.26\n",
      "    3.13           13.50\n",
      "    13.58           14.25\n",
      "    -9.37           13.77\n",
      "    17.80           14.33\n",
      "    0.12           14.33\n",
      "    -7.27           14.38\n",
      "    -17.13           14.38\n",
      "    45.09           14.39\n",
      "    30.44           10.98\n",
      "    -11.23           14.26\n",
      "    3.38           -3.35\n",
      "    -6.73            9.84\n",
      "    -34.04           14.21\n",
      "    31.82           13.87\n",
      "    8.42           14.02\n",
      "    5.57           -0.63\n",
      "    -15.37           14.11\n",
      "    -2.47           14.38\n",
      "    36.38           14.31\n",
      "    -34.07           14.38\n",
      "    -2.03           14.37\n",
      "    5.24           12.16\n",
      "    3.33           14.39\n",
      "    -32.58           14.16\n",
      "    5.42            6.06\n",
      "    -14.29           14.11\n",
      "    -44.08           14.19\n",
      "    -29.78           14.35\n",
      "    -68.82           14.37\n",
      "    213.10           14.38\n",
      "    4.57           13.82\n",
      "    -3.32           14.03\n",
      "    3.72           14.33\n",
      "    26.05           14.20\n",
      "    -35.65           14.31\n",
      "    -9.01           13.70\n",
      "    25.50           14.05\n",
      "    32.40            8.00\n",
      "    -10.69           14.36\n",
      "    -7.17           14.23\n",
      "    17.91           13.91\n",
      "    13.91           14.31\n",
      "    -2.46           14.23\n",
      "    6.28           14.37\n",
      "    -28.13           14.38\n",
      "    -5.00           14.33\n",
      "    -9.41           14.07\n",
      "    5.59           13.82\n",
      "    -32.43           14.16\n",
      "    -23.87           14.33\n",
      "    -15.83           14.13\n",
      "    -15.00           14.36\n",
      "    -26.96           14.29\n",
      "    -15.93           14.35\n",
      "    -0.54           14.07\n",
      "    -18.73           14.37\n",
      "    -2.58           12.92\n",
      "    1.69           14.35\n",
      "    0.80           13.75\n",
      "    29.43           14.32\n",
      "    49.06           14.34\n",
      "    -41.67           14.32\n",
      "    28.32           14.26\n",
      "    41.94           13.28\n",
      "    -21.65           14.34\n",
      "    7.83           14.07\n",
      "    -5.84           14.15\n",
      "    -42.38           14.24\n",
      "    7.61           14.39\n",
      "    -22.40           14.13\n",
      "    -13.33           14.31\n",
      "    29.76           14.38\n",
      "    2.75           14.04\n",
      "    -41.39           13.95\n",
      "    25.86           14.26\n",
      "    -37.31           14.31\n",
      "    5.19           14.10\n",
      "    -49.98           14.35\n",
      "    -0.22           12.57\n",
      "    -33.21           14.39\n",
      "    -1.95            2.07\n",
      "    47.33           14.36\n",
      "    -16.15           14.15\n",
      "    13.91           12.98\n",
      "    23.08           14.46\n",
      "    -37.67           14.06\n",
      "    -0.16           14.20\n",
      "    7.15           11.71\n",
      "    42.62           14.26\n",
      "    -46.72           14.26\n",
      "    -1.41           14.69\n",
      "    -19.78           10.64\n",
      "    11.14           14.35\n",
      "    5.26           14.36\n",
      "    71.21           14.17\n",
      "    19.80           13.90\n",
      "    -0.81           14.27\n",
      "    -18.77           13.00\n",
      "    -35.17           14.38\n",
      "    37.10           14.18\n",
      "    -4.85           14.34\n",
      "    22.16           14.30\n",
      "    -18.83           14.31\n",
      "    8.30            8.07\n",
      "    5.11           14.30\n",
      "    389.30           14.36\n",
      "    -1.17           14.17\n",
      "    1.71           14.34\n",
      "    18.53           14.22\n",
      "    4.12           14.38\n",
      "    27.76           14.39\n",
      "    -36.34           14.35\n",
      "    10.55           14.32\n",
      "    -13.16           14.32\n",
      "    2.24           14.20\n",
      "    -6.68           14.39\n",
      "    2.11           14.33\n",
      "    -4.19           13.93\n",
      "    13.68           14.36\n",
      "    7.90           13.36\n",
      "    -23.17           14.38\n",
      "    -3.70           14.37\n",
      "    -0.95           14.24\n",
      "    15.00           14.39\n",
      "    -2.06           14.37\n",
      "    4.47           13.88\n",
      "    14.09           13.36\n",
      "    38.21           14.17\n",
      "    24.79           14.02\n",
      "    -55.66           14.33\n",
      "    22.76           14.17\n",
      "    4.19           14.36\n",
      "    -42.90           14.35\n",
      "    -8.15           13.63\n",
      "    16.85           14.33\n",
      "    33.95           13.10\n",
      "    -14.96           13.03\n",
      "    85.20           14.39\n",
      "    -25.06           13.99\n",
      "    -17.26           14.33\n",
      "    -41.03           14.35\n",
      "    -56.66           12.90\n",
      "    23.78           13.64\n",
      "    -30.82           14.18\n",
      "    -19.02           13.95\n",
      "    138.64           14.38\n",
      "    20.25           14.15\n",
      "    -2.50           14.38\n",
      "    6.54           14.28\n",
      "    19.45           13.96\n",
      "    -1.69           14.29\n",
      "    -38.15           14.19\n",
      "    -9.76           13.64\n",
      "    18.47           14.37\n",
      "    -41.18           14.33\n",
      "    33.33           14.37\n",
      "    -9.95           13.67\n",
      "    13.47           14.20\n",
      "    -60.59           14.36\n",
      "    -9.64           14.32\n",
      "    -60.78           14.35\n",
      "    -38.84           14.15\n",
      "    6.20           14.34\n",
      "    -31.76           14.32\n",
      "    19.81           13.86\n",
      "    23.47            0.83\n",
      "    10.49           14.37\n",
      "    16.18           14.25\n",
      "    5.11           14.06\n",
      "    11.44           14.34\n",
      "    -23.29           14.27\n",
      "    -33.81           14.38\n",
      "    -5.16           14.28\n",
      "    -2.46           14.33\n",
      "    -8.90           13.52\n",
      "    -12.98           14.29\n",
      "    12.84           14.28\n",
      "    2.60           14.50\n",
      "    -10.06           14.19\n",
      "    2.72           14.17\n",
      "    12.82           14.27\n",
      "    3.17           12.09\n",
      "    1.29           14.19\n",
      "    -3.00           12.99\n",
      "    2.54           14.35\n",
      "    25.49           13.41\n",
      "    -55.52           11.27\n",
      "    5.78           14.08\n",
      "    24.65           14.14\n",
      "    -10.79           13.74\n",
      "    -0.50           14.36\n",
      "    -39.93           14.54\n",
      "    -21.92           14.37\n",
      "    1.40           14.04\n",
      "    -2.75           14.31\n",
      "    -8.37           14.31\n",
      "    3.06           14.38\n",
      "    58.28           14.34\n",
      "    -1.16           14.28\n",
      "    -3.97           12.75\n",
      "    15.93           14.36\n",
      "    -10.94           14.25\n",
      "    46.57           13.94\n",
      "    -0.68           14.20\n",
      "    12.51           13.45\n",
      "    -18.95           14.36\n",
      "    14.49           14.02\n",
      "    6.02           14.02\n",
      "    12.62           14.28\n",
      "    13.34           14.35\n",
      "    -20.31           14.39\n",
      "    3.13           14.31\n",
      "    -27.78           14.39\n",
      "    17.22           14.34\n",
      "    5.85           11.53\n",
      "    0.13           13.16\n",
      "    -25.92           14.24\n",
      "    -13.04           14.19\n",
      "    3.24           13.99\n",
      "    88.74           14.31\n",
      "    7.98           11.91\n",
      "    1.08           14.33\n",
      "    7.89           14.34\n",
      "    -37.31           14.32\n",
      "    -19.82           14.39\n",
      "    10.87           14.32\n",
      "    17.85           14.32\n",
      "    38.66           14.18\n",
      "    -7.92           14.34\n",
      "    13.03           12.06\n",
      "    -59.44           14.15\n",
      "    14.67           14.27\n",
      "    16.15           13.29\n",
      "    3.80           14.34\n",
      "    -58.74           14.16\n",
      "    11.16           14.37\n",
      "    20.76           14.33\n",
      "    4.54           12.51\n",
      "    9.55           14.08\n",
      "    -4.42           14.17\n",
      "    7.06           13.61\n",
      "    -9.47           13.49\n",
      "    -5.93           13.96\n",
      "    17.27           13.61\n",
      "    25.70           14.27\n",
      "    6.79           14.28\n",
      "    10.54           14.33\n",
      "    -4.00           14.28\n",
      "    9.45           13.02\n",
      "    -12.35           14.32\n",
      "    -15.92           -1.08\n",
      "    -39.61           14.39\n",
      "    2.29           14.39\n",
      "    -54.51           13.88\n",
      "    -1.49           14.30\n",
      "    -28.89           14.39\n",
      "    54.30           14.30\n",
      "    61.01           14.38\n",
      "    39.46           14.33\n",
      "    16.73           13.66\n",
      "    -31.07           14.15\n",
      "    15.67           14.35\n",
      "    3.27           14.21\n",
      "    -9.67           13.44\n",
      "    -13.63           14.33\n",
      "    -21.35           14.39\n",
      "    -23.81           14.36\n",
      "    12.61           14.38\n",
      "    44.58           14.33\n",
      "    6.66           12.74\n",
      "    19.33           14.39\n",
      "    -11.08           13.96\n",
      "    -26.80           14.39\n",
      "    6.38           13.97\n",
      "    4.07           14.14\n",
      "    -11.91           13.86\n",
      "    -0.41           14.38\n",
      "    4.62           14.13\n",
      "    44.09           14.27\n",
      "    7.26           14.37\n",
      "    -9.86           14.20\n",
      "    -28.15           14.23\n",
      "    1.39           14.33\n",
      "    60.00           14.12\n",
      "    -23.35           12.55\n",
      "    14.89           14.08\n",
      "    -48.16           14.25\n",
      "    15.54           14.19\n",
      "    -19.31           10.91\n",
      "    8.60           14.15\n",
      "    -14.75           12.88\n",
      "    -1.52           14.36\n",
      "    -0.83           10.92\n",
      "    53.81           14.26\n",
      "    17.98            0.15\n",
      "    26.77           14.10\n",
      "    68.11           13.07\n",
      "    -9.17           14.35\n",
      "    3.08           14.32\n",
      "    0.68           13.90\n",
      "    2.11           14.35\n",
      "    -26.83           14.25\n",
      "    36.60           14.39\n",
      "    -0.36            7.30\n",
      "    15.38           11.49\n",
      "    -4.71            8.14\n",
      "    -10.02           13.50\n",
      "    -34.07           14.08\n",
      "    -13.01           14.33\n",
      "    -26.18           14.34\n",
      "    -3.59           14.25\n",
      "    29.49           14.39\n",
      "    -20.31           13.07\n",
      "    -31.03           14.32\n",
      "    -35.62           14.35\n",
      "    0.96           14.32\n",
      "    11.54           13.93\n",
      "    11.74           14.29\n",
      "    -20.85           13.97\n",
      "    117.58           14.39\n",
      "    5.30           11.51\n",
      "    -32.73           14.32\n",
      "    40.18           14.31\n",
      "    -12.05           14.34\n",
      "    24.04          -19.82\n",
      "    -24.49           14.21\n",
      "    -6.03           14.37\n",
      "    3.85           14.18\n",
      "    5.70           13.72\n",
      "    -9.88           11.40\n",
      "    -5.80           14.32\n",
      "    -8.16           14.34\n",
      "    -8.46           -6.99\n",
      "    -2.06           14.34\n",
      "    2.69           14.35\n",
      "    26.92           14.34\n",
      "    -19.24           14.35\n",
      "    -61.21           14.31\n",
      "    2.53           13.89\n",
      "    19.99           13.60\n",
      "    7.21           13.18\n",
      "    -11.58           14.37\n",
      "    -68.63           13.59\n",
      "    -1.74           14.36\n",
      "    -4.42           14.40\n",
      "    46.24           14.20\n",
      "    -24.24           14.25\n",
      "    -6.33           14.31\n",
      "    -15.55           12.67\n",
      "    5.07           13.55\n",
      "    16.53           14.23\n",
      "    9.80           14.17\n",
      "    3.41           14.39\n",
      "    3.02           14.25\n",
      "    -25.10           14.26\n",
      "    16.50            0.53\n",
      "    -23.20           13.62\n",
      "    -0.55           14.06\n",
      "    -26.41           14.37\n",
      "    -4.41           11.45\n",
      "    4.52           14.32\n",
      "    59.63           14.36\n",
      "    -53.73           14.41\n",
      "    -12.04            4.40\n",
      "    -4.89           13.94\n",
      "    -7.69           14.28\n",
      "    11.56           14.03\n",
      "    32.90           14.23\n",
      "    -62.22           14.37\n",
      "    6.68           14.18\n",
      "    -7.64           14.35\n",
      "    -18.90           14.27\n",
      "    -0.32           14.11\n",
      "    -7.27           14.31\n",
      "    53.60           14.31\n",
      "    -0.87           13.64\n",
      "    -50.84           14.24\n",
      "    -7.63           14.34\n",
      "    -16.00           14.39\n",
      "    13.53           14.31\n",
      "    10.24           14.31\n",
      "    -5.63           14.17\n",
      "    -4.98           14.23\n",
      "    18.81           13.87\n",
      "    -0.60           12.26\n",
      "    23.50           13.75\n",
      "    -5.02           14.38\n",
      "    -42.98           14.35\n",
      "    -23.81           14.32\n",
      "    -48.66           14.39\n",
      "    3.62           14.05\n",
      "    -45.05           14.10\n",
      "    44.00           14.35\n",
      "    12.11           13.38\n",
      "    -16.20           14.40\n",
      "    -28.57           14.30\n",
      "    16.52           14.26\n",
      "    -53.44           14.10\n",
      "    8.57           14.29\n",
      "    -10.47           14.34\n",
      "    -0.31           14.39\n",
      "    -5.87           13.84\n",
      "    -13.84           14.21\n",
      "    9.31           13.49\n",
      "    -44.39           14.24\n",
      "    -14.56           11.18\n",
      "    -11.30            8.66\n",
      "    19.51           14.34\n",
      "    158.59           14.34\n",
      "    -30.43           14.33\n",
      "    12.78           14.34\n",
      "    9.31           14.40\n",
      "    3.48           14.25\n",
      "    41.98           13.90\n",
      "    13.60           14.35\n",
      "    14.19           14.27\n",
      "    -0.45           14.38\n",
      "    -72.73           14.32\n",
      "    94.44           14.32\n",
      "    0.78           14.39\n",
      "    -2.59           13.59\n",
      "    19.58           14.28\n",
      "    -34.44           14.24\n",
      "    23.77           13.70\n",
      "    48.71           14.34\n",
      "    52.98           14.18\n",
      "    -1.61           13.15\n",
      "    3.46           14.20\n",
      "    -57.96           14.36\n",
      "    -3.93           14.31\n",
      "    -1.53           13.66\n",
      "    -31.45           14.35\n",
      "    21.03           13.65\n",
      "    -6.85           12.97\n",
      "    20.79           14.27\n",
      "    18.77           14.14\n",
      "    0.99           13.54\n",
      "    -0.88           14.16\n",
      "    -23.36           10.74\n",
      "    2.71           13.96\n",
      "    15.10           14.28\n",
      "    7.89           14.11\n",
      "    -13.84           14.37\n",
      "    -3.68           14.33\n",
      "    -77.01           14.24\n",
      "    2.17           13.96\n",
      "    -23.11           14.28\n",
      "    32.96           13.59\n",
      "    -18.35           13.98\n",
      "    1.60           14.24\n",
      "    -32.98           14.12\n",
      "    7.51           14.22\n",
      "    10.33          -11.99\n",
      "    34.62           14.22\n",
      "    -8.11           14.07\n",
      "    10.10           14.37\n",
      "    -8.76           14.17\n",
      "    51.68           14.34\n",
      "    11.24           14.27\n",
      "    -27.29           14.38\n",
      "    -29.72           14.33\n",
      "    -12.12            4.13\n",
      "    -3.75           14.20\n",
      "    36.33           14.26\n",
      "    31.96           14.04\n",
      "    22.44           12.32\n",
      "    -4.92           14.13\n",
      "    11.98           14.32\n",
      "    -1.89           14.13\n",
      "    -3.10           13.83\n",
      "    -21.40           14.34\n",
      "    24.55           13.30\n",
      "    -4.56           14.27\n",
      "    0.56           14.25\n",
      "    -0.21           14.38\n",
      "    -8.79           14.38\n",
      "    -20.36           14.12\n",
      "    5.00           14.36\n",
      "    16.72           14.22\n",
      "    15.35           13.32\n",
      "    81.33           14.32\n",
      "    -19.03           13.43\n",
      "    -4.38           14.36\n",
      "    4.56           13.84\n",
      "    -7.18           14.38\n",
      "    -6.79           14.20\n",
      "    17.24           14.14\n",
      "    -31.12           14.37\n",
      "    -4.49           13.94\n",
      "    0.26           14.28\n",
      "    1.38           14.39\n",
      "    13.55           14.38\n",
      "    -10.16           14.15\n",
      "    16.91           13.36\n",
      "    1.16           12.23\n",
      "    18.11           13.77\n",
      "    2.27           14.20\n",
      "    34.12           14.36\n",
      "    -65.16           14.35\n",
      "    -4.90           14.29\n",
      "    10.18           14.36\n",
      "    623.19           14.38\n",
      "    -67.65           13.21\n",
      "    82.03           14.18\n",
      "    22.21           13.85\n",
      "    -8.03           14.37\n",
      "    -8.30            6.25\n",
      "    -21.38           14.30\n",
      "    1.30           14.34\n",
      "    -0.90           13.11\n",
      "    -2.51           14.30\n",
      "    -17.65           14.26\n",
      "    34.65           14.09\n",
      "    -16.21           14.28\n",
      "    -25.51           14.33\n",
      "    -7.50           14.13\n",
      "    7.14           14.39\n",
      "    -8.55           14.31\n",
      "    -21.68           13.79\n",
      "    44.69           14.24\n",
      "    -5.97           13.98\n",
      "    4.05           13.79\n",
      "    -14.21           14.29\n",
      "    10.75           13.60\n",
      "    0.50           14.35\n",
      "    -49.75           14.36\n",
      "    20.22           14.35\n",
      "    68.28           14.24\n",
      "    4.08           14.32\n",
      "    0.53           14.40\n",
      "    2.25           14.38\n",
      "    -48.07           14.39\n",
      "    -45.46           14.36\n",
      "    -11.17           14.36\n",
      "    0.08           14.05\n",
      "    7.45           13.62\n",
      "    9.33           14.20\n",
      "    -30.23           14.31\n",
      "    92.48           14.31\n",
      "    42.72           14.37\n",
      "    -40.52           14.23\n",
      "    -12.38           14.34\n",
      "    -0.12           13.40\n",
      "    0.21           14.17\n",
      "    35.07           14.27\n",
      "    -8.99           14.37\n",
      "    -3.23           14.22\n",
      "    5.07           14.38\n",
      "    8.53           14.02\n",
      "    1568.83           14.30\n",
      "    18.61           14.06\n",
      "    0.33           14.04\n",
      "    1.96           14.35\n",
      "    37.04           14.16\n",
      "    -25.94           14.17\n",
      "    -14.23           14.16\n",
      "    2.32           13.99\n",
      "    8.62           14.22\n",
      "    20.18           14.11\n",
      "    -1.55           14.25\n",
      "    -37.50           14.34\n",
      "    31.14           14.34\n",
      "    -7.71           13.89\n",
      "    14.68           14.07\n",
      "    12.29           14.37\n",
      "    -13.45           14.32\n",
      "    3.77           10.69\n",
      "    7.63           14.34\n",
      "    16.10            4.81\n",
      "    12.60           14.09\n",
      "    -4.67           14.27\n",
      "    2.05           14.07\n",
      "    -3.81           14.23\n",
      "    15.08           14.27\n",
      "    151.27           14.14\n",
      "    8.54           13.74\n",
      "    57.79           14.38\n",
      "    -31.09           14.06\n",
      "    -1.02           14.14\n",
      "    37.65           14.36\n",
      "    -19.51           14.06\n",
      "    -10.04           13.14\n",
      "    -40.22           13.80\n",
      "    -22.29           14.28\n",
      "    -20.63           14.33\n",
      "    5.02           14.21\n",
      "    -18.53           14.37\n",
      "    -20.83           14.34\n",
      "    -15.32           14.36\n",
      "    13.03           14.27\n",
      "    0.03           14.34\n",
      "    -54.79           14.20\n",
      "    25.33           13.60\n",
      "    5.42           14.11\n",
      "    -10.15           14.35\n",
      "    -10.87           14.28\n",
      "    -29.46           14.30\n",
      "    25.82           11.52\n",
      "    3.06           11.76\n",
      "    -1.08           14.03\n",
      "    -0.18           13.60\n",
      "    -5.79           14.31\n",
      "    -35.03           14.33\n",
      "    1.03           14.23\n",
      "    -10.47           13.15\n",
      "    85.56           14.29\n",
      "    -38.96           14.04\n",
      "    -22.78           14.39\n",
      "    -6.47           14.20\n",
      "    44.11           14.36\n",
      "    15.98           13.82\n",
      "    46.29           14.10\n",
      "    1.81           14.10\n",
      "    6.40           12.82\n",
      "    1.49           14.28\n",
      "    -6.36           11.09\n",
      "    -2.91           -2.57\n",
      "    9.10           14.40\n",
      "    -7.43           14.35\n",
      "    14.60           13.96\n",
      "    14.84           14.36\n",
      "    -16.53           12.09\n",
      "    29.82           14.39\n",
      "    63.52           14.35\n",
      "    -12.17           14.16\n",
      "    -10.19           14.37\n",
      "    59.09           14.36\n",
      "    -7.57           14.29\n",
      "    7.61           14.19\n",
      "    -14.48           14.26\n",
      "    -1.03           14.17\n",
      "    13.49           14.31\n",
      "    -13.56           14.35\n",
      "    -6.38           12.77\n",
      "    5.99          -11.50\n",
      "    19.24           12.77\n",
      "    5.56           14.31\n",
      "    -8.76           14.32\n",
      "    -6.05           14.38\n",
      "    3.08           14.36\n",
      "    -2.45           14.12\n",
      "    93.65           14.35\n",
      "    57.54           13.52\n",
      "    23.79           14.15\n",
      "    4.94           14.39\n",
      "    3.60           14.26\n",
      "    13.13           12.04\n",
      "    -20.40           14.38\n",
      "    10.56           14.17\n",
      "    24.55           14.15\n",
      "    -32.73           14.30\n",
      "    -12.04           14.38\n",
      "    -7.08           14.21\n",
      "    -9.73           14.35\n",
      "    2.18           14.33\n",
      "    -22.29           14.24\n",
      "    -6.17           14.39\n",
      "    43.14           14.38\n",
      "    -49.16           14.27\n",
      "    -2.59           14.21\n",
      "    -8.60           14.19\n",
      "    11.45           14.21\n",
      "    1.69           14.42\n",
      "    -9.51           14.35\n",
      "    -21.72           11.70\n",
      "    -1.92           12.66\n",
      "    16.60           14.31\n",
      "    2.28           14.24\n",
      "    19.01           14.34\n",
      "    -46.45           14.37\n",
      "    77.81           14.33\n",
      "    2.27           14.27\n",
      "    -33.77           13.96\n",
      "    -0.53           12.54\n",
      "    -2.60           14.34\n",
      "    -18.33           14.25\n",
      "    -15.34           14.32\n",
      "    -47.74           13.57\n",
      "    5.37           14.29\n",
      "    -2.81           14.31\n",
      "    -21.99            9.08\n",
      "    5.97           14.22\n",
      "    -0.35           14.35\n",
      "    69.73           14.27\n",
      "    -28.38           14.27\n",
      "    283.57           14.38\n",
      "    -18.20           14.32\n",
      "    1.89           12.24\n",
      "    -44.59           14.05\n",
      "    -32.09           14.28\n",
      "    3.65           13.50\n",
      "    39.97           14.11\n",
      "    -6.47           14.34\n",
      "    -40.80           14.36\n",
      "    -25.96           13.77\n",
      "    -5.78           14.14\n",
      "    -18.29           14.26\n",
      "    37.14           14.32\n",
      "    -29.44           14.28\n",
      "    4.85           14.23\n",
      "    2.07           13.58\n",
      "    134.04           14.37\n",
      "    -6.78           14.39\n",
      "    31.13           14.22\n",
      "    -33.70           14.31\n",
      "    2.59           14.30\n",
      "    911.76           14.38\n",
      "    8.47           14.26\n",
      "    59.01           14.35\n",
      "    -0.14           15.64\n",
      "    9.91            7.78\n",
      "    -16.63           10.26\n",
      "    7.41           14.37\n",
      "    -38.53           14.28\n",
      "    -6.92           11.52\n",
      "    62.23           14.23\n",
      "    37.27           13.70\n",
      "    -29.37           12.38\n",
      "    48.18           14.24\n",
      "    -2.44           12.84\n",
      "    29.79           14.03\n",
      "    -13.77           14.35\n",
      "    -11.30           14.26\n",
      "    4.44           14.39\n",
      "    21.79           14.37\n",
      "    -13.61           14.27\n",
      "    5.79           14.38\n",
      "    20.21           13.65\n",
      "    -20.17           14.39\n",
      "    31.15           14.34\n",
      "    60.72           14.24\n",
      "    -6.65           14.26\n",
      "    10.77           14.02\n",
      "    -3.71           14.38\n",
      "    -1.17           13.78\n",
      "    72.22           14.42\n",
      "    -6.45            9.70\n",
      "    1.02           11.84\n",
      "    -2.71           13.94\n",
      "    -21.40           14.30\n",
      "    2.93           10.60\n",
      "    -11.07           12.79\n",
      "    9.25           13.88\n",
      "    -14.19           14.26\n",
      "    -23.00           14.33\n",
      "    2.39           14.24\n",
      "    27.69           14.34\n",
      "    -13.79           14.33\n",
      "    -43.79           13.94\n",
      "    -4.22           14.34\n",
      "    1.01           13.22\n",
      "    -20.39           14.35\n",
      "    -39.42           13.70\n",
      "    17.11            8.60\n",
      "    -3.21           14.20\n",
      "    -23.29           12.71\n",
      "    -20.47           14.38\n",
      "    14.99           13.85\n",
      "    -5.20           14.35\n",
      "    5.73           14.06\n",
      "    -45.35           14.07\n",
      "    0.78           13.37\n",
      "    -8.13           -0.70\n",
      "    10.09           14.26\n",
      "    13.96           14.31\n",
      "    38.37           14.13\n",
      "    13.53           14.32\n",
      "    17.26            1.32\n",
      "    50.00           14.31\n",
      "    7.01          -28.26\n",
      "    47.93           14.29\n",
      "    -26.03           14.29\n",
      "    8.80           13.63\n",
      "    -2.66           14.38\n",
      "    -35.96           14.39\n",
      "    -9.71           14.34\n",
      "    17.44           14.12\n",
      "    -17.75           14.29\n",
      "    36.77           14.23\n",
      "    1.14           14.36\n",
      "    -32.50           14.28\n",
      "    11.90           14.35\n",
      "    1.19           14.35\n",
      "    -35.71           14.38\n",
      "    -9.24           14.38\n",
      "    -14.61           14.24\n",
      "    -23.20           14.20\n",
      "    8.56           14.28\n",
      "    6.53           14.36\n",
      "    -9.41           13.59\n",
      "    18.11           14.43\n",
      "    -8.46           14.25\n",
      "    -30.97           14.26\n",
      "    27.04           13.85\n",
      "    27.36           14.15\n",
      "    13.82           16.38\n",
      "    9.03           14.35\n",
      "    -16.23           14.25\n",
      "    -26.25           14.37\n",
      "    -3.17           14.23\n",
      "    35.13           14.33\n",
      "    10.45           14.24\n",
      "    6.44           14.25\n",
      "    -24.51           14.33\n",
      "    -21.26           14.12\n",
      "    -1.19           14.38\n",
      "    9.76           14.34\n",
      "    16.44           14.23\n",
      "    -20.07           14.02\n",
      "    6.23           12.03\n",
      "    -26.73           14.26\n",
      "    1714.59           14.16\n",
      "    -36.43           14.21\n",
      "    22.12           14.26\n",
      "    15.63           14.38\n",
      "    15.09           14.34\n",
      "    -11.42           14.37\n",
      "    -7.60           14.27\n",
      "    -12.30           13.85\n",
      "    138.91           14.36\n",
      "    -17.02           14.22\n",
      "    7.18           13.68\n",
      "    -49.28           14.24\n",
      "    -26.58           14.32\n",
      "    3.32           13.07\n",
      "    -12.41           14.22\n",
      "    -10.36           14.23\n",
      "    9.00           14.34\n",
      "    -33.02           10.32\n",
      "    5.31           14.38\n",
      "    -0.19           14.23\n",
      "    -30.25           14.39\n",
      "    -27.19           14.18\n",
      "    -3.61           14.27\n",
      "    0.70           14.09\n",
      "    -35.43           14.39\n",
      "    -34.59           14.37\n",
      "    -8.48           14.18\n",
      "    6.59           12.13\n",
      "    -0.17           13.83\n",
      "    -22.44           14.12\n",
      "    -8.32           14.14\n",
      "    2.58           14.21\n",
      "    -16.85           14.02\n",
      "    -4.06           14.37\n",
      "    -36.02           13.92\n",
      "    75.90           14.34\n",
      "    -1.79           14.38\n",
      "    -40.71           13.17\n",
      "    57.59           14.21\n",
      "    0.72            5.95\n",
      "    40.20           14.34\n",
      "    11.96           14.26\n",
      "    4.61           14.25\n",
      "    -26.29           14.30\n",
      "    13.93           14.07\n",
      "    4.00           14.38\n",
      "    19.12           14.35\n",
      "    -14.47           14.06\n",
      "    -1.33           14.19\n",
      "    -2.53           14.32\n",
      "    17.95           14.37\n",
      "    -19.59           14.36\n",
      "    88.37           14.33\n",
      "    -9.72           14.27\n",
      "    -46.08           14.39\n",
      "    -29.63           14.37\n",
      "    2.05           14.38\n",
      "    17.29           14.01\n",
      "    -3.99           14.20\n",
      "    1.26           14.36\n",
      "    8.39           14.29\n",
      "    -46.91           14.33\n",
      "    17.56           14.26\n",
      "    -25.03           14.22\n",
      "    27.72           14.22\n",
      "    -13.68           14.38\n",
      "    4.29           14.06\n",
      "    0.04           13.58\n",
      "    -1.45           14.17\n",
      "    20.32           14.33\n",
      "    -0.31           14.38\n",
      "    -8.37           14.20\n",
      "    21150.00           14.34\n",
      "    1501.42           14.33\n",
      "    11.40           14.35\n",
      "    -9.18           14.23\n",
      "    -69.52           14.39\n",
      "    -15.08           14.13\n",
      "    4.96           13.92\n",
      "    -18.40           14.14\n",
      "    9.78           14.35\n",
      "    -33.49           14.43\n",
      "    20.86           14.06\n",
      "    -6.94           14.09\n",
      "    1.00           14.23\n",
      "    0.91           11.54\n",
      "    -1.98           14.01\n",
      "    -8.33           14.18\n",
      "    0.06           12.95\n",
      "    11.84           13.69\n",
      "    -3.38           14.20\n",
      "    -0.52           14.35\n",
      "    -18.68           14.36\n",
      "    27.90           13.93\n",
      "    31.67           14.37\n",
      "    49.05           14.35\n",
      "    33.60           13.13\n",
      "    4.87           -0.03\n",
      "    8.09           14.26\n",
      "    -37.47           12.55\n",
      "    27.87           -1.86\n",
      "    -8.86           14.24\n",
      "    -24.26           14.31\n",
      "    16.35           14.34\n",
      "    24.56           12.81\n",
      "    -23.85           13.44\n",
      "    13.73           13.44\n",
      "    -4.08           14.33\n",
      "    -36.84           14.30\n",
      "    -1.49           14.27\n",
      "    -8.81           14.32\n",
      "    11.54           13.70\n",
      "    12.11           14.34\n",
      "    -8.95            1.74\n",
      "    27.40           14.29\n",
      "    3.16           14.26\n",
      "    -24.11           14.20\n",
      "    0.14           12.81\n",
      "    9.25           13.84\n",
      "    657.92           14.34\n",
      "    5.23           14.31\n",
      "    133.28           14.34\n",
      "    -48.83           13.23\n",
      "    -26.20           14.38\n",
      "    91.14           14.39\n",
      "    1.40           14.31\n",
      "    -1.57           14.38\n",
      "    -18.67           13.35\n",
      "    4.68           12.13\n",
      "    -42.55           13.40\n",
      "    39.80           14.33\n",
      "    -48.09           14.33\n",
      "    -16.88           14.00\n",
      "    37.15           14.29\n",
      "    16.15           -5.73\n",
      "    2.36           14.07\n",
      "    -28.84           14.32\n",
      "    -21.89           14.13\n",
      "    20.42           14.09\n",
      "    53.72           14.20\n",
      "    27.72           12.95\n",
      "    294.69           14.35\n",
      "    -7.57           13.74\n",
      "    -5.84           14.33\n",
      "    -12.83           14.23\n",
      "    36.89           12.78\n",
      "    33.79           14.37\n",
      "    -35.96           14.37\n",
      "    2.54           13.96\n",
      "    -2.11           14.34\n",
      "    14.15           14.21\n",
      "    -9.89           14.06\n",
      "    65.94           14.36\n",
      "    -8.27           14.34\n",
      "    -14.48           14.37\n",
      "    7.05           14.36\n",
      "    -2.60           13.99\n",
      "    -18.58           12.56\n",
      "    2.17           12.08\n",
      "    38.79           14.32\n",
      "    30.85           13.74\n",
      "    -88.97           14.33\n",
      "    -13.69           14.27\n",
      "    -5.27           13.73\n",
      "    5.96           14.30\n",
      "    -29.58           14.30\n",
      "    0.65           14.37\n",
      "    14.80           14.04\n",
      "    -22.49           14.23\n",
      "    -4.39           14.38\n",
      "    -15.92           14.04\n",
      "    7.92           14.11\n",
      "    26.40           14.30\n",
      "    8.45           14.36\n",
      "    -8.30           14.28\n",
      "    10.97           14.11\n",
      "    -11.42           14.30\n",
      "    -19.84           13.74\n",
      "    -43.80           13.40\n",
      "    -7.62           14.35\n",
      "    16.38           14.30\n",
      "    1.86           14.38\n",
      "    4.49           13.66\n",
      "    687.13           14.38\n",
      "    6.02           14.27\n",
      "    -13.88           14.11\n",
      "    -7.81            5.33\n",
      "    2.99           14.36\n",
      "    -65.98           14.33\n",
      "    -13.27           14.39\n",
      "    29.74           14.13\n",
      "    26.70           13.36\n",
      "    8.00           13.73\n",
      "    52.93           14.20\n",
      "    -0.58           14.44\n",
      "    -0.94           14.40\n",
      "    -15.04           13.25\n",
      "    -15.03           14.34\n",
      "    10.27           12.44\n",
      "    -35.48            5.80\n",
      "    2.66           14.14\n",
      "    -9.46           14.24\n",
      "    -17.48           14.25\n",
      "    -1.97           13.71\n",
      "    -0.39           14.35\n",
      "    -8.74           14.04\n",
      "    -11.93           14.33\n",
      "    4.17           14.37\n",
      "    11.98           14.31\n",
      "    -5.15           14.39\n",
      "    -2.75           14.35\n",
      "    9.95           14.30\n",
      "    33.22           14.33\n",
      "    52.90           14.37\n",
      "    -2.05           14.19\n",
      "    15.13           14.37\n",
      "    9.98           12.71\n",
      "    69.35           13.56\n",
      "    -62.69           14.39\n",
      "    2.04           13.66\n",
      "    -15.07           13.36\n",
      "    -6.22           14.32\n",
      "    2.19           14.38\n",
      "    -15.33           14.40\n",
      "    14.46           13.81\n",
      "    1.09           14.36\n",
      "    24.80           14.29\n",
      "    -31.76           14.23\n",
      "    -19.03            9.38\n",
      "    5.45           13.97\n",
      "    8.53           14.24\n",
      "    27.02           13.56\n",
      "    23.10           14.33\n",
      "    -11.53           13.97\n",
      "    3.92           13.79\n",
      "    -17.49           14.13\n",
      "    7.04           12.14\n",
      "    9.32           14.23\n",
      "    13.85           14.24\n",
      "    -10.65           14.43\n",
      "    -14.91           14.06\n",
      "    -16.38           14.35\n",
      "    -42.42           14.38\n",
      "    -5.88           14.36\n",
      "    -9.63           14.10\n",
      "    -7.51           14.33\n",
      "    17.39           14.36\n",
      "    -3.68           14.29\n",
      "    1.19           14.17\n",
      "    -6.81           14.21\n",
      "    -4.47           14.29\n",
      "    1.18           14.21\n",
      "    34.11           14.38\n",
      "    -22.01           14.39\n",
      "    10.30           14.33\n",
      "    -12.33           14.32\n",
      "    -8.04           14.27\n",
      "    1.30           14.20\n",
      "    -20.21           14.34\n",
      "    6.17           14.39\n",
      "    -4.82           -1.71\n",
      "    78.34           14.34\n",
      "    -5.39           14.24\n",
      "    37.00           12.87\n",
      "    2.65           14.28\n",
      "    27.82           13.80\n",
      "    -2.34           14.21\n",
      "    -46.50           14.31\n",
      "    -2.00           14.20\n",
      "    30.03           14.24\n",
      "    -13.34           14.27\n",
      "    5.59           13.92\n",
      "    18.33           14.50\n",
      "    20.74           14.22\n",
      "    -17.98           14.20\n",
      "    -54.02           12.96\n",
      "    1.68           11.70\n",
      "    -9.63           13.44\n",
      "    99.00           14.28\n",
      "    -9.27           13.94\n",
      "    -59.21           14.39\n",
      "    1.52           14.35\n",
      "    -4.35           14.37\n",
      "    2.04           13.83\n",
      "    -32.65           14.24\n",
      "    -16.67           14.25\n",
      "    18.05           14.36\n",
      "    -8.24           14.23\n",
      "    -27.11            7.47\n",
      "    -22.49           14.27\n",
      "    9.71           14.33\n",
      "    -8.61           14.28\n",
      "    99.92           14.21\n",
      "    -13.87           14.30\n",
      "    37.23           10.12\n",
      "    4.57           14.31\n",
      "    8.28           14.20\n",
      "    7.90           12.91\n",
      "    3.41           13.62\n",
      "    9.14           14.22\n",
      "    -8.69           13.72\n",
      "    22.94           14.36\n",
      "    77.28           14.15\n",
      "    22.14           13.99\n",
      "    23.54           14.03\n",
      "    2.40           14.19\n",
      "    21.10           14.36\n",
      "    0.59           14.30\n",
      "    -1.17           14.06\n",
      "    -10.48           14.20\n",
      "    -16.88           14.29\n",
      "    -38.55           14.38\n",
      "    1.45           14.33\n",
      "    -12.94           14.19\n",
      "    -14.81           14.39\n",
      "    42.81           14.18\n",
      "    -10.04           14.17\n",
      "    -73.82           14.37\n",
      "    11.36           14.29\n",
      "    2.60           14.15\n",
      "    12.99           14.26\n",
      "    5.88           14.34\n",
      "    4.81           14.08\n",
      "    -52.50           14.26\n",
      "    30.12           14.33\n",
      "    32.94           14.36\n",
      "    -18.16           14.22\n",
      "    -39.39           14.39\n",
      "    2.50           13.66\n",
      "    2.20           14.38\n",
      "    8.06            6.12\n",
      "    4.77           14.02\n",
      "    -46.90           14.31\n",
      "    3.40           12.58\n",
      "    -4.62           13.65\n",
      "    25.45           13.70\n",
      "    -5.88           13.60\n",
      "    39.20           14.03\n",
      "    7.43           13.93\n",
      "    -59.31           14.26\n",
      "    17.92           14.36\n",
      "    -9.09           14.35\n",
      "    -11.07           12.78\n",
      "    53.29           14.31\n",
      "    1.53           14.15\n",
      "    2.02           14.37\n",
      "    9.89           13.13\n",
      "    23.88           14.18\n",
      "    -2.38            9.34\n",
      "    13.24           14.37\n",
      "    -51.88           14.34\n",
      "    3.71           14.01\n",
      "    7.58           14.27\n",
      "    15.90           14.38\n",
      "    -16.54           14.37\n",
      "    -32.17           14.38\n",
      "    -22.02           14.26\n",
      "    -36.95           14.09\n",
      "    -19.07           14.24\n",
      "    56.69           14.24\n",
      "    23.54           14.38\n",
      "    -6.91           14.21\n",
      "    -32.45           14.38\n",
      "    12.30           14.18\n",
      "    33.17           14.37\n",
      "    -13.83           13.75\n",
      "    3.41            6.53\n",
      "    -19.39           14.00\n",
      "    -0.26           -5.79\n",
      "    18.04           14.28\n",
      "    -15.02           14.31\n",
      "    -20.75           14.38\n",
      "    0.35           14.29\n",
      "    27.60           14.08\n",
      "    -39.50           14.33\n",
      "    -37.95           14.27\n",
      "    3.95           14.39\n",
      "    -0.38           13.99\n",
      "    -2.23           14.27\n",
      "    5.28           14.38\n",
      "    -7.77           14.38\n",
      "    20.67           14.13\n",
      "    18.63           14.18\n",
      "    18.87           14.33\n",
      "    766.67           14.33\n",
      "    -39.06           13.66\n",
      "    47.77           14.25\n",
      "    0.40           14.32\n",
      "    6.89           14.38\n",
      "    76.74           14.34\n",
      "    6.16           13.58\n",
      "    -23.27           14.31\n",
      "    -1.73           11.10\n",
      "    101.68           14.30\n",
      "    22.51           14.38\n",
      "    5.75            9.55\n",
      "    -34.20           14.27\n",
      "    -27.77           14.38\n",
      "    -0.52           14.35\n",
      "    4.12           14.26\n",
      "    -43.10           14.36\n",
      "    -28.05           14.26\n",
      "    23.61           14.22\n",
      "    -21.00           14.35\n",
      "    2.50           14.38\n",
      "    1.19           14.25\n",
      "    -19.46           14.10\n",
      "    14.12           14.27\n",
      "    -19.05           13.92\n",
      "    47.65           14.32\n",
      "    7.94           14.34\n",
      "    7.11           14.38\n",
      "    -13.46           14.24\n",
      "    -59.48           13.02\n",
      "    -3.50           14.38\n",
      "    10.42           14.05\n",
      "    28.67           14.36\n",
      "    3.05           14.34\n",
      "    20.57           14.07\n",
      "    19.52           14.38\n",
      "    -4.13           14.36\n",
      "    21.26           14.36\n",
      "    18.87           13.94\n",
      "    -42.11           13.53\n",
      "    -6.31           13.93\n",
      "    30.61           14.33\n",
      "    7.37           14.39\n",
      "    0.49           14.39\n",
      "    35.04           14.33\n",
      "    -3.49           14.39\n",
      "    5.65           13.58\n",
      "    21.61            8.62\n",
      "    26.53           14.07\n",
      "    16.62           13.35\n",
      "    12.14           14.02\n",
      "    -22.73           14.39\n",
      "    10.67           14.13\n",
      "    236.60           14.38\n",
      "    24.68           14.24\n",
      "    5.80           14.10\n",
      "    -46.36           14.32\n",
      "    10.38           14.19\n",
      "    -21.44           14.33\n",
      "    15.05           14.07\n",
      "    -3.28           14.32\n",
      "    17.55           14.37\n",
      "    12.02           14.12\n",
      "    4.61           14.21\n",
      "    11.61           14.37\n",
      "    -8.73           14.32\n",
      "    -9.46           14.06\n",
      "    30.38           14.39\n",
      "    -23.28           14.34\n",
      "    162.91           13.78\n",
      "    -44.25           14.32\n",
      "    -5.82           13.62\n",
      "    1.56           14.33\n",
      "    2.11           14.23\n",
      "    6.62            8.00\n",
      "    -17.27           14.27\n",
      "    1.22           14.20\n",
      "    0.71           14.36\n",
      "    4.62           14.24\n",
      "    -11.37           13.04\n",
      "    1.08           14.38\n",
      "    383.62           14.37\n",
      "    4.43           14.21\n",
      "    -11.27           14.37\n",
      "    -38.84           14.39\n",
      "    -10.99           10.31\n",
      "    2.50           14.38\n",
      "    6.60           14.37\n",
      "    -3.23           14.38\n",
      "    1.60           14.38\n",
      "    -14.66           14.14\n",
      "    -38.20           14.36\n",
      "    -1.51           11.84\n",
      "    7.04           14.25\n",
      "    2.58           13.92\n",
      "    -36.16           14.23\n",
      "    575.32           14.37\n",
      "    28.39           14.31\n",
      "    16.96           14.19\n",
      "    -49.10           14.34\n",
      "    13.17           14.36\n",
      "    10.73           13.29\n",
      "    -35.20           14.39\n",
      "    24.63           14.18\n",
      "    7.37           14.22\n",
      "    690.00           14.20\n",
      "    -4.94           12.93\n",
      "    -8.59           14.22\n",
      "    6.20           14.27\n",
      "    4.17           14.37\n",
      "    29.73           14.36\n",
      "    -44.62           12.89\n",
      "    13.11           14.23\n",
      "    -33.98           14.33\n",
      "    13.89           13.87\n",
      "    -16.90           14.22\n",
      "    -74.01           14.21\n",
      "    -24.69           13.92\n",
      "    -21.87           14.36\n",
      "    40.27           14.39\n",
      "    22.08           13.29\n",
      "    36.37           13.21\n",
      "    -19.38           14.32\n",
      "    -19.43           14.25\n",
      "    16.68           14.06\n",
      "    20.25           14.31\n",
      "    20.63           13.16\n",
      "    1753.33           14.39\n",
      "    -17.53           14.30\n",
      "    7.56           11.79\n",
      "    -0.59           14.19\n",
      "    -19.57           13.75\n",
      "    16.30           14.36\n",
      "    1831.24           14.36\n",
      "    -42.47           14.30\n",
      "    2.51           14.04\n",
      "    17.05           13.53\n",
      "    -8.82           14.31\n",
      "    0.64           12.17\n",
      "    -10.00           14.32\n",
      "    -29.20           14.22\n",
      "    -35.10           14.35\n",
      "    4.06           13.58\n",
      "    -15.16           14.38\n",
      "    -7.91           13.63\n",
      "    7.76           12.36\n",
      "    61.76           14.36\n",
      "    2.69           14.38\n",
      "    -32.61           14.37\n",
      "    17.15           13.98\n",
      "    -71.01           14.33\n",
      "    4.08           14.36\n",
      "    -23.12           14.31\n",
      "    -27.99           14.31\n",
      "    223.29           14.34\n",
      "    17.03           14.31\n",
      "    37.28           14.17\n",
      "    31.38           14.24\n",
      "    -19.35           14.38\n",
      "    -42.86           14.35\n",
      "    525.71           14.36\n",
      "    12.27           13.69\n",
      "    11.32           14.15\n",
      "    -15.69           14.37\n",
      "    -14.56           12.61\n",
      "    41.40           14.33\n",
      "    -5.71           14.38\n",
      "    -1.41           14.30\n",
      "    0.57           14.39\n",
      "    -25.08           14.33\n",
      "    2.99           14.34\n",
      "    -7.34           13.97\n",
      "    -2.16           14.09\n",
      "    4.71           13.69\n",
      "    99.21           14.39\n",
      "    8.57           14.22\n",
      "    3.74           13.55\n",
      "    13.98           14.03\n",
      "    11.52           12.74\n",
      "    38.77           14.38\n",
      "    1.53           12.82\n",
      "    24.58           14.12\n",
      "    5.20           14.37\n",
      "    8.96           13.83\n",
      "    -2.83           14.29\n",
      "    20.87           14.33\n",
      "    -29.54           14.15\n",
      "    -8.46           14.38\n",
      "    64.11           11.55\n",
      "    -29.47           14.11\n",
      "    -19.44           14.21\n",
      "    -23.90           14.33\n",
      "    11.26           14.34\n",
      "    -32.87           14.34\n",
      "    -17.48           14.15\n",
      "    1.52           14.30\n",
      "    0.01           14.38\n",
      "    2.75           14.13\n",
      "    4.44           14.33\n",
      "    43.98           13.85\n",
      "    -4.97           14.33\n",
      "    -2.95           14.38\n",
      "    -56.92           14.35\n",
      "    79.17           14.30\n",
      "    -17.98           14.22\n",
      "    -12.91           14.37\n",
      "    -30.30           14.24\n",
      "    9.09           14.36\n",
      "    33.33           14.39\n",
      "    -4.21           13.89\n",
      "    13.21           11.69\n",
      "    5.89           13.33\n",
      "    -23.82           14.39\n",
      "    1.48           14.39\n",
      "    13.12           14.19\n",
      "    -9.78           14.36\n",
      "    2.40           14.07\n",
      "    -6.71           14.33\n",
      "    -10.70           14.08\n",
      "    8.14            9.76\n",
      "    15.48           14.35\n",
      "    -34.07           14.29\n",
      "    23.10           10.69\n",
      "    -0.31           14.37\n",
      "    -36.83           14.35\n",
      "    -42.80           14.02\n",
      "    3.08           14.30\n",
      "    -5.49           14.33\n",
      "    -25.56           14.37\n",
      "    -3.00           14.08\n",
      "    11.06           13.77\n",
      "    -26.67           14.38\n",
      "    7.10           14.39\n",
      "    81.24           14.37\n",
      "    8.91           14.30\n",
      "    33.32           14.40\n",
      "    -23.97           14.26\n",
      "    -42.00           14.24\n",
      "    -29.27           14.11\n",
      "    5.33           14.14\n",
      "    -5.70           14.36\n",
      "    5.28           -2.86\n",
      "    -46.39           14.39\n",
      "    -54.14           14.27\n",
      "    -10.68           14.33\n",
      "    -4.17           14.37\n",
      "    1.87           14.25\n",
      "    24.77           14.07\n",
      "    -21.59           14.39\n",
      "    -2.72           14.16\n",
      "    490.17           14.28\n",
      "    577.98           14.38\n",
      "    -28.95           14.37\n",
      "    58.19           11.24\n",
      "    5.89           14.24\n",
      "    15.90           14.06\n",
      "    -56.72            7.26\n",
      "    -12.28           14.33\n",
      "    -40.57           14.03\n",
      "    5.00           14.29\n",
      "    -12.73           14.35\n",
      "    71.16           14.34\n",
      "    -3.15           11.83\n",
      "    -22.03           11.86\n",
      "    2.20           14.38\n",
      "    -5.02            6.20\n",
      "    14.94           13.10\n",
      "    6.48           13.03\n",
      "    1.83           14.39\n",
      "    52.69           14.38\n",
      "    -6.84           14.37\n",
      "    6.80           14.37\n",
      "    26.61           14.37\n",
      "    25.21           14.18\n",
      "    7.48           14.36\n",
      "    -48.94           14.37\n",
      "    2.12           14.19\n",
      "    -50.10           14.34\n",
      "    10.88           14.25\n",
      "    -22.23           14.44\n",
      "    636.00           14.38\n",
      "    -23.49           14.18\n",
      "    -8.61           14.25\n",
      "    -16.85           14.31\n",
      "    30.02           14.37\n",
      "    3.60           14.25\n",
      "    113.58           14.18\n",
      "    5.84           14.37\n",
      "    -3.40           14.38\n",
      "    0.08           11.71\n",
      "    23.15           14.33\n",
      "    16.45           14.21\n",
      "    7.11           14.36\n",
      "    46.97           14.19\n",
      "    -17.33           14.31\n",
      "    -40.16            6.22\n",
      "    6.36           13.50\n",
      "    19.01           14.26\n",
      "    29.38           14.35\n",
      "    32.70           14.33\n",
      "    -29.29           14.38\n",
      "    -19.03           14.39\n",
      "    40.09           14.12\n",
      "    -0.35           14.26\n",
      "    -60.00           14.39\n",
      "    -1.12           12.21\n",
      "    -5.03         -199.22\n",
      "    9.07           -6.02\n",
      "    50.35           14.33\n",
      "    0.20           14.39\n",
      "    -5.03           14.19\n",
      "    -3.17           14.12\n",
      "    102.37           13.83\n",
      "    -3.00           13.72\n",
      "    10.31           14.07\n",
      "    50.09           14.33\n",
      "    0.32           14.23\n",
      "    1.62           12.68\n",
      "    -9.15           13.69\n",
      "    -7.36           14.08\n",
      "    -8.56           13.87\n",
      "    7.35           14.04\n",
      "    10.18           12.86\n",
      "    -19.64           14.24\n",
      "    7.19           14.25\n",
      "    3.67           14.28\n",
      "    3.80           14.30\n",
      "    -3.75           14.33\n",
      "    1.40           14.32\n",
      "    -67.84           14.28\n",
      "    -4.36           14.24\n",
      "    -0.36           14.38\n",
      "    -10.59           14.31\n",
      "    -8.99           14.24\n",
      "    -7.95           14.27\n",
      "    1.76           14.28\n",
      "    4.08           13.97\n",
      "    12.26           13.78\n",
      "    5.17           14.35\n",
      "    43.38           14.26\n",
      "    -39.60           14.19\n",
      "    -1.05           14.28\n",
      "    9.47           14.35\n",
      "    14.69           14.25\n",
      "    96.00           14.37\n",
      "    -50.04           14.09\n",
      "    -35.25           13.07\n",
      "    -9.67           14.37\n",
      "    0.21           14.03\n",
      "    -10.31            0.54\n",
      "    9.77           14.15\n",
      "    31.76           14.31\n",
      "    12.15           13.84\n",
      "    6.95           13.56\n",
      "    25.97           12.80\n",
      "    52.12           14.28\n",
      "    -72.58           14.20\n",
      "    17.23           14.33\n",
      "    4.54           10.01\n",
      "    -0.55           14.39\n",
      "    1.51           14.39\n",
      "    0.53           14.37\n",
      "    20.20           14.38\n",
      "    216.90           14.33\n",
      "    9.83           17.23\n",
      "    11.35           14.26\n",
      "    43.71           13.12\n",
      "    3.66           14.22\n",
      "    16.43           14.18\n",
      "    1.89           13.84\n",
      "    -13.50           13.39\n",
      "    -2.66           13.74\n",
      "    7.76           14.39\n",
      "    22.57           14.18\n",
      "    -4.21           10.47\n",
      "    8.45           14.39\n",
      "    18.45           14.24\n",
      "    -79.62           14.39\n",
      "    9.46           14.27\n",
      "    -8.09           14.50\n",
      "    16.41           14.17\n",
      "    -36.00           13.32\n",
      "    2.75           14.25\n",
      "    -0.57           13.44\n",
      "    2.41           14.30\n",
      "    2.05           14.37\n",
      "    -20.60           14.00\n",
      "    4.85           14.37\n",
      "    5.42            6.72\n",
      "    50.23           14.25\n",
      "    1.16           12.07\n",
      "    9.74           14.17\n",
      "    -5.28           14.37\n",
      "    -10.43           14.14\n",
      "    30.28           14.31\n",
      "    -19.07           14.38\n",
      "    -30.26           14.05\n",
      "    16.35           14.33\n",
      "    5.85           14.38\n",
      "    2.91           14.39\n",
      "    3.28           14.32\n",
      "    21.56           14.11\n",
      "    -2.03           14.25\n",
      "    -10.26         -147.66\n",
      "    -41.43           14.39\n",
      "    6.05           14.24\n",
      "    -1.70           11.67\n",
      "    24.96           14.35\n",
      "    7.70           14.10\n",
      "    117.51           14.12\n",
      "    -17.53           14.02\n",
      "    -4.83           14.33\n",
      "    43.88           14.18\n",
      "    13.86           12.35\n",
      "    16.76           14.29\n",
      "    26.56           14.23\n",
      "    -2.36           14.30\n",
      "    -1.77           13.42\n",
      "    38.15           14.34\n",
      "    37.02           13.98\n",
      "    -4.40           14.30\n",
      "    -24.91           13.91\n",
      "    6.41           14.06\n",
      "    26.65           14.32\n",
      "    -37.28           14.04\n",
      "    38.96           14.25\n",
      "    32.44           14.36\n",
      "    7.13            5.51\n",
      "    -5.37           14.32\n",
      "    0.87           11.06\n",
      "    27.04           13.73\n",
      "    24.23           12.64\n",
      "    22.26           14.33\n",
      "    2.18           11.72\n",
      "    18.31           13.57\n",
      "    -0.86           14.38\n",
      "    -39.22           13.38\n",
      "    -8.99           14.34\n",
      "    -14.29           14.07\n",
      "    5.44           14.22\n",
      "    67.35           14.39\n",
      "    20.71           14.18\n",
      "    37.13           14.27\n",
      "    -9.69           13.38\n",
      "    7.38           14.25\n",
      "    0.48           14.34\n",
      "    1.59           13.68\n",
      "    -2.23           14.28\n",
      "    35.94           14.38\n",
      "    -30.91           14.17\n",
      "    41.46           14.39\n",
      "    11.31           14.36\n",
      "    6.99           13.99\n",
      "    -14.35           14.10\n",
      "    9.58           13.16\n",
      "    -13.94           14.37\n",
      "    -7.76           14.32\n",
      "    55.28           14.20\n",
      "    -4.97           13.52\n",
      "    -28.05           14.38\n",
      "    122.99           14.38\n",
      "    11.16           13.94\n",
      "    -44.42           14.32\n",
      "    -38.08           14.38\n",
      "    5.95           13.77\n",
      "    37.13           14.30\n",
      "    41.26           14.33\n",
      "    -39.42           14.39\n",
      "    -33.55           14.38\n",
      "    458.82           14.24\n",
      "    -84.14           14.24\n",
      "    -5.12           14.26\n",
      "    18.18           14.14\n",
      "    8.26           13.49\n",
      "    -11.59           14.38\n",
      "    -15.28           14.26\n",
      "    0.78           14.25\n",
      "    -13.71           13.85\n",
      "    -2.39           14.30\n",
      "    -4.89           12.11\n",
      "    -11.20           14.17\n",
      "    -41.02           14.42\n",
      "    -9.43           14.29\n",
      "    86.74           14.32\n",
      "    14.94           11.73\n",
      "    23.53           13.96\n",
      "    -6.53           14.46\n",
      "    39.95           14.23\n",
      "    -63.95           14.20\n",
      "    -7.78           14.26\n",
      "    8.64           14.18\n",
      "    7.95           14.26\n",
      "    -6.28           14.29\n",
      "    2.20            4.75\n",
      "    -28.18           13.89\n",
      "    -20.45           14.28\n",
      "    -20.00           14.39\n",
      "    -57.34           14.23\n",
      "    6.33           14.36\n",
      "    51.43           14.32\n",
      "    -1.85           14.21\n",
      "    -53.00           14.37\n",
      "    -43.63           14.38\n",
      "    7.85           14.09\n",
      "    17.54           14.28\n",
      "    -1.23           14.36\n",
      "    29.19           14.05\n",
      "    106.64           14.38\n",
      "    42.03           14.03\n",
      "    -2.14           14.38\n",
      "    0.29           14.08\n",
      "    -0.06           14.39\n",
      "    -3.34           13.24\n",
      "    13.71           14.32\n",
      "    31.26           14.34\n",
      "    -7.48           14.35\n",
      "    -63.79           14.08\n",
      "    -24.01           14.33\n",
      "    -3.13           14.28\n",
      "    -9.91           14.25\n",
      "    5.75           11.04\n",
      "    2.66           13.73\n",
      "    4.85           14.36\n",
      "    -47.16           14.37\n",
      "    -14.68           -1.84\n",
      "    17.17           13.96\n",
      "    -47.78           14.06\n",
      "    17.01           13.47\n",
      "    40.04           12.17\n",
      "    45.07           14.17\n",
      "    3.49           -6.25\n",
      "    26.89           14.25\n",
      "    21.01           14.32\n",
      "    -74.44           14.07\n",
      "    -4.91           14.29\n",
      "    2.20           14.31\n",
      "    -3.35           14.34\n",
      "    12.33           14.38\n",
      "    0.31           14.40\n",
      "    141.42            9.99\n",
      "    5.26           14.38\n",
      "    1.34           13.85\n",
      "    2.25           14.25\n",
      "    40.89           14.37\n",
      "    -10.82           14.28\n",
      "    27.39           14.21\n",
      "    3.26           11.54\n",
      "    -11.40           14.19\n",
      "    -3.67           12.34\n",
      "    -11.81           14.24\n",
      "    4.30           14.31\n",
      "    -11.01           11.81\n",
      "    0.83           14.20\n",
      "    1.10           14.39\n",
      "    2.65           14.36\n",
      "    10.57           14.23\n",
      "    -14.04           14.37\n",
      "    15.96           14.23\n",
      "    -0.91           14.29\n",
      "    660.00           14.38\n",
      "    41.41           14.36\n",
      "    1.89           14.30\n",
      "    -16.30           14.12\n",
      "    -18.83           14.37\n",
      "    6.33           13.90\n",
      "    19.01           14.24\n",
      "    -21.64           14.22\n",
      "    8.10           12.73\n",
      "    -2.39           14.25\n",
      "    3.06            7.38\n",
      "    3.81           13.09\n",
      "    14.09           14.28\n",
      "    32.64           14.05\n",
      "    1.87           11.67\n",
      "    6.27           14.23\n",
      "    9.60           13.41\n",
      "    8.27           14.13\n",
      "    0.24           14.33\n",
      "    -12.69           14.26\n",
      "    10.61           10.36\n",
      "    24.77           14.37\n",
      "    61.32           14.23\n",
      "    -15.55           13.50\n",
      "    2.35           14.34\n",
      "    -17.71           14.20\n",
      "    -78.85           14.39\n",
      "    -7.62           14.28\n",
      "    21.11           14.04\n",
      "    -7.67           14.23\n",
      "    9.54           14.39\n",
      "    20.65           14.54\n",
      "    23.89           14.33\n",
      "    0.16           14.30\n",
      "    53.85           14.32\n",
      "    12.42           14.38\n",
      "    -6.76           14.38\n",
      "    -13.64           14.37\n",
      "    16.36           14.30\n",
      "    -17.37           13.45\n",
      "    -32.92           14.32\n",
      "    -7.42           14.33\n",
      "    2.16           14.37\n",
      "    13.19           14.36\n",
      "    18.15           12.46\n",
      "    6.91            8.68\n",
      "    22.77           14.26\n",
      "    -35.58           14.22\n",
      "    1.94           14.32\n",
      "    4.52           14.24\n",
      "    22.40           14.30\n",
      "    -11.36           14.39\n",
      "    -39.15           13.86\n",
      "    -6.18           14.29\n",
      "    -75.10           14.38\n",
      "    -3.29           13.68\n",
      "    -16.59           14.34\n",
      "    0.69           14.33\n",
      "    -23.62           14.38\n",
      "    -4.45           13.92\n",
      "    -4.49           13.93\n",
      "    -24.48           14.32\n",
      "    -0.81           14.18\n",
      "    2.11           14.07\n",
      "    6.29           14.14\n",
      "    25.92           14.03\n",
      "    -1.27           14.37\n",
      "    -4.17           13.71\n",
      "    -5.82           13.81\n",
      "    46.45           13.92\n",
      "    33.94           14.18\n",
      "    17.89           14.29\n",
      "    5.40           13.42\n",
      "    -18.10           14.38\n",
      "    9.08           14.31\n",
      "    -15.87           14.30\n",
      "    1.01           10.93\n",
      "    -7.98           14.20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -24.92           14.35\n",
      "    -5.11           14.25\n",
      "    34.04           14.29\n",
      "    11.10           14.30\n",
      "    146.15           14.37\n",
      "    7.71           14.37\n",
      "    2.86           14.30\n",
      "    3.89           12.12\n",
      "    0.64            8.96\n",
      "    4.36           14.19\n",
      "    -28.45           14.26\n",
      "    -2.30           13.24\n",
      "    -6.84           14.23\n",
      "    6.19           14.11\n",
      "    7.48           13.97\n",
      "    -37.76           14.39\n",
      "    3.23           14.25\n",
      "    14.93           14.19\n",
      "    155.02           14.24\n",
      "    2.67           14.17\n",
      "    -1.98           14.34\n",
      "    13.67           12.15\n",
      "    -24.31           14.24\n",
      "    7.82           14.17\n",
      "    -76.00           14.38\n",
      "    31.70           14.34\n",
      "    -13.02           14.03\n",
      "    -2.37           14.27\n",
      "    8.29           13.77\n",
      "    -31.79           14.30\n",
      "    10.83           13.68\n",
      "    51.76           14.35\n",
      "    2.85           14.38\n",
      "    -11.01           14.38\n",
      "    -30.58           14.20\n",
      "    5.26           14.08\n",
      "    2.26           13.92\n",
      "    -13.77           14.35\n",
      "    6.19            9.81\n",
      "    -10.92           14.39\n",
      "    -16.76           14.33\n",
      "    5.69           14.37\n",
      "    13.24           14.33\n",
      "    46.26           14.10\n",
      "    -6.54           14.36\n",
      "    -6.72           14.30\n",
      "    1.37           13.26\n",
      "    10.54           14.17\n",
      "    9.68           12.67\n",
      "    -29.88           14.38\n",
      "    50.88           13.98\n",
      "    4.27           11.55\n",
      "    -14.18           14.32\n",
      "    13.89           13.80\n",
      "    0.25          -23.27\n",
      "    2.33           13.98\n",
      "    -2.26           14.19\n",
      "    1016.33           14.38\n",
      "    -7.77           14.34\n",
      "    4.47           14.12\n",
      "    -2.91           14.39\n",
      "    -56.17           14.39\n",
      "    -34.10           14.23\n",
      "    -1.08           13.99\n",
      "    -21.19           14.84\n",
      "    -23.09           14.24\n",
      "    15.15           14.33\n",
      "    6.83           14.21\n",
      "    28.79           14.30\n",
      "    -18.94           14.13\n",
      "    -30.61           14.25\n",
      "    -34.45           14.01\n",
      "    -35.73           14.15\n",
      "    19.62           13.77\n",
      "    3.60           14.18\n",
      "    -41.41           14.32\n",
      "    -11.40           14.15\n",
      "    -29.07           14.35\n",
      "    18.32           14.35\n",
      "    23.08           14.38\n",
      "    16.84           14.39\n",
      "    -13.98           14.30\n",
      "    -8.89           14.37\n",
      "    2.53           14.38\n",
      "    7.65           14.18\n",
      "    -17.54           14.13\n",
      "    -1.22           13.67\n",
      "    0.50           13.72\n",
      "    -84.14           14.39\n",
      "    412.59           14.38\n",
      "    81.95           14.34\n",
      "    40.00           14.34\n",
      "    15.11           11.30\n",
      "    -0.17           14.16\n",
      "    -7.71           14.39\n",
      "    -37.77           13.97\n",
      "    -58.28           14.38\n",
      "    -10.16           14.28\n",
      "    -5.39           13.14\n",
      "    17.47           13.96\n",
      "    12.86            9.25\n",
      "    -25.03           14.24\n",
      "    -4.62           13.93\n",
      "    -17.64           14.27\n",
      "    18.88           14.13\n",
      "    2.55           14.32\n",
      "    -13.53           14.24\n",
      "    0.77           14.39\n",
      "    -33.28           14.30\n",
      "    -37.28           13.41\n",
      "    0.59           10.76\n",
      "    26.87           14.37\n",
      "    18.44           13.47\n",
      "    -65.66           14.39\n",
      "    -55.64           14.23\n",
      "    -0.95           14.38\n",
      "    39.19           14.22\n",
      "    6.69           10.99\n",
      "    5.60           12.53\n",
      "    -10.89           14.35\n",
      "    11.98           14.28\n",
      "    34.57           14.19\n",
      "    5.14           13.68\n",
      "    -3.23           13.46\n",
      "    24.56           13.93\n",
      "    -13.11           14.18\n",
      "    1.66           14.28\n",
      "    -31.02           14.39\n",
      "    16.44            7.68\n",
      "    23.58           14.25\n",
      "    1.63           14.24\n",
      "    -24.86           14.29\n",
      "    -21.05           14.38\n",
      "    -61.07           14.27\n",
      "    9.14            5.85\n",
      "    58.12           14.37\n",
      "    -12.91           14.26\n",
      "    -11.92           14.39\n",
      "    8.24           13.96\n",
      "    -11.58           14.36\n",
      "    4.37           14.05\n",
      "    -4.53           14.36\n",
      "    -70.16           14.34\n",
      "    3.59           14.39\n",
      "    11.53           14.10\n",
      "    -3.45           13.59\n",
      "    -10.03           14.24\n",
      "    -25.70           14.28\n",
      "    22.44           14.04\n",
      "    -13.24            5.88\n",
      "    14.70           14.09\n",
      "    -16.21           14.38\n",
      "    19.84           14.25\n",
      "    116.35           14.30\n",
      "    48.77           14.39\n",
      "    29.93           14.19\n",
      "    -8.29           14.18\n",
      "    2.02           14.30\n",
      "    -17.49           14.23\n",
      "    -0.62           14.21\n",
      "    -20.13           14.34\n",
      "    26.28           14.30\n",
      "    -35.16           14.29\n",
      "    114.39           13.35\n",
      "    15.73           14.17\n",
      "    -5.19           12.22\n",
      "    100.69           14.27\n",
      "    -0.05           13.69\n",
      "    94.97           14.23\n",
      "    30.10           14.29\n",
      "    -1.15           13.85\n",
      "    6.27           14.38\n",
      "    -6.48           14.19\n",
      "    -8.94           14.37\n",
      "    14.99           14.21\n",
      "    -0.37           14.17\n",
      "    5.11           14.37\n",
      "    -16.94           14.36\n",
      "    13.44           14.35\n",
      "    6.53           14.36\n",
      "    -0.48            9.22\n",
      "    -10.64           14.32\n",
      "    20.23           14.32\n",
      "    0.23           12.08\n",
      "    2.23           13.71\n",
      "    16.80           14.26\n",
      "    3.76           14.34\n",
      "    -15.72           14.03\n",
      "    -17.77           14.20\n",
      "    -30.52           14.31\n",
      "    -18.00           14.38\n",
      "    -41.50           14.21\n",
      "    11.13           10.51\n",
      "    -17.13           14.19\n",
      "    -12.20           14.37\n",
      "    -16.38           14.25\n",
      "    5.69           14.19\n",
      "    -0.80           14.26\n",
      "    -62.07           14.22\n",
      "    0.40           14.11\n",
      "    -41.02            4.43\n",
      "    10.61           14.36\n",
      "    -6.02           14.27\n",
      "    0.70           14.20\n",
      "    24.09           14.30\n",
      "    0.06           14.16\n",
      "    -1.47           14.40\n",
      "    16.40           13.79\n",
      "    1.83            7.67\n",
      "    -29.26           14.35\n",
      "    3.17           14.28\n",
      "    -3.55           14.08\n",
      "    5.39           14.34\n",
      "    4.68           14.18\n",
      "    1.24           13.01\n",
      "    3.02           14.39\n",
      "    -0.17           14.39\n",
      "    -5.05           14.03\n",
      "    3.01           14.10\n",
      "    -11.95           14.22\n",
      "    -1.29           14.38\n",
      "    -4.90           14.16\n",
      "    -3.61           14.25\n",
      "    -19.70           14.37\n",
      "    -4.48           14.37\n",
      "    -0.50           13.95\n",
      "    -4.85           14.38\n",
      "    -2.63           14.26\n",
      "    -5.66           12.58\n",
      "    6.73           14.08\n",
      "    0.72           14.29\n",
      "    7.30           12.70\n",
      "    -19.10           14.05\n",
      "    7.45           14.23\n",
      "    -29.83           14.09\n",
      "    13.83           14.18\n",
      "    -2.64           14.28\n",
      "    -41.41           13.30\n",
      "    -29.07           14.11\n",
      "    -9.27           14.24\n",
      "    10.56           14.19\n",
      "    3.11           14.12\n",
      "    -5.19           14.45\n",
      "    -18.64           14.29\n",
      "    18.27           14.38\n",
      "    0.39           14.33\n",
      "    10.10           14.30\n",
      "    -26.85           14.08\n",
      "    -64.01           14.36\n",
      "    -9.46           14.38\n",
      "    74.60           14.38\n",
      "    3.11           14.09\n",
      "    -79.18           14.19\n",
      "    -19.53           14.07\n",
      "    -23.64           13.80\n",
      "    -9.52           14.30\n",
      "    -19.88           13.92\n",
      "    -39.92           14.22\n",
      "    -10.12           12.56\n",
      "    9.53           14.14\n",
      "    119.72           14.26\n",
      "    -16.33           14.36\n",
      "    -24.81           14.38\n",
      "    34.64           13.97\n",
      "    3.09           13.82\n",
      "    23.04           14.14\n",
      "    -5.45           14.37\n",
      "    6.51           10.83\n",
      "    -8.16           14.39\n",
      "    0.28            7.50\n",
      "    2.67           14.33\n",
      "    11.88           14.23\n",
      "    12.03           13.91\n",
      "    78.33           14.35\n",
      "    19.77           14.39\n",
      "    -19.24           14.38\n",
      "    98.18           14.26\n",
      "    -14.37           12.84\n",
      "    17.08           14.26\n",
      "    7.44           14.24\n",
      "    153.89           13.43\n",
      "    -15.62            8.53\n",
      "    -59.57           14.38\n",
      "    29.25           13.95\n",
      "    56.82           14.20\n",
      "    3.71           14.34\n",
      "    -44.33           14.33\n",
      "    28.94           14.29\n",
      "    60.00           14.03\n",
      "    -34.69           14.37\n",
      "    -61.98           14.26\n",
      "    4.74           14.39\n",
      "    10.22           13.93\n",
      "    -2.38           13.32\n",
      "    2.05           13.69\n",
      "    -6.22           14.18\n",
      "    27.86           14.32\n",
      "    0.63           14.36\n",
      "    11.37           13.90\n",
      "    6.50           13.57\n",
      "    13.30            8.68\n",
      "    -15.46           14.31\n",
      "    1.00           12.39\n",
      "    8.67           14.39\n",
      "    -5.33           14.19\n",
      "    22.16           14.33\n",
      "    14.79           13.31\n",
      "    -1.55           14.36\n",
      "    3.19           13.74\n",
      "    16.05           13.72\n",
      "    6.39           14.11\n",
      "    -22.65           14.32\n",
      "    40.27           14.27\n",
      "    14.71           14.33\n",
      "    5.70           14.39\n",
      "    23.05           14.21\n",
      "    10.34           14.39\n",
      "    55.86           14.23\n",
      "    60.56           14.38\n",
      "    10.75           13.42\n",
      "    3453.72           14.38\n",
      "    -9.83           14.25\n",
      "    -25.03           14.38\n",
      "    -34.69           14.02\n",
      "    -19.64           14.35\n",
      "    1.35            6.83\n",
      "    -0.66           14.39\n",
      "    71.45           14.35\n",
      "    -27.59           11.82\n",
      "    0.63           14.38\n",
      "    1.02           14.36\n",
      "    11.79           14.31\n",
      "    2.84           14.10\n",
      "    33.07           14.31\n",
      "    5.93           14.33\n",
      "    3.14           13.81\n",
      "    -7.76           14.39\n",
      "    17.24           14.11\n",
      "    21.97           14.25\n",
      "    -4.94           14.18\n",
      "    -0.89           14.81\n",
      "    -12.04           14.37\n",
      "    -5.02           14.25\n",
      "    -1.94           13.71\n",
      "    -17.15           14.19\n",
      "    -14.06           14.37\n",
      "    -72.22           14.39\n",
      "    16.81           14.37\n",
      "    -38.73           14.38\n",
      "    -13.35           13.80\n",
      "    53.59           14.22\n",
      "    2.71           14.29\n",
      "    -10.89           14.37\n",
      "    -8.66           14.27\n",
      "    -17.54            1.43\n",
      "    -1.39           14.27\n",
      "    500.00           13.61\n",
      "    4.65           -5.21\n",
      "    11.38           14.35\n",
      "    -14.86           14.38\n",
      "    5.81           14.23\n",
      "    -26.93           14.36\n",
      "    9.23           14.13\n",
      "    -2.28            9.66\n",
      "    25.78           12.64\n",
      "    5.41           14.10\n",
      "    54.51           14.40\n",
      "    15.20           13.01\n",
      "    16.32           -4.39\n",
      "    37.47           14.39\n",
      "    20.47           14.31\n",
      "    5.49           14.35\n",
      "    11.74           13.97\n",
      "    9.05           14.20\n",
      "    -32.39            9.95\n",
      "    -11.50           13.06\n",
      "    17.26           13.87\n",
      "    -15.84           14.29\n",
      "    -3.80           10.37\n",
      "    44.62           14.26\n",
      "    -12.66           14.27\n",
      "    28.65           14.32\n",
      "    -41.38           14.34\n",
      "    2.68           14.35\n",
      "    -45.07           14.35\n",
      "    -18.28           13.75\n",
      "    -33.33           14.39\n",
      "    9.78           13.25\n",
      "    -1.93           14.33\n",
      "    -33.79           13.59\n",
      "    23.37           14.07\n",
      "    -14.96           14.84\n",
      "    -12.89           14.35\n",
      "    -5.90           14.12\n",
      "    22.97           14.22\n",
      "    19.44           14.31\n",
      "    1.12           12.53\n",
      "    46.25           14.31\n",
      "    43.26           14.35\n",
      "    -33.41           14.30\n",
      "    -8.47           14.36\n",
      "    23.96           14.09\n",
      "    3.62           14.26\n",
      "    -17.32           14.30\n",
      "    -29.33           13.70\n",
      "    33.50           14.23\n",
      "    -5.77           14.38\n",
      "    12.54           14.07\n",
      "    3.31           11.58\n",
      "    -24.66           12.62\n",
      "    -6.60           14.21\n",
      "    3.68           12.19\n",
      "    -19.50           14.38\n",
      "    -5.09           14.13\n",
      "    2.61           14.17\n",
      "    -8.38           11.93\n",
      "    2.75           13.78\n",
      "    -38.67           13.17\n",
      "    -0.51           14.30\n",
      "    12.72           12.15\n",
      "    29.22           14.34\n",
      "    67.78           14.34\n",
      "    15.80           14.06\n",
      "    9.67           14.29\n",
      "    -47.01           14.38\n",
      "    7.51           14.41\n",
      "    9.55           14.38\n",
      "    8.14           13.92\n",
      "    -21.74           14.27\n",
      "    -38.02           12.99\n",
      "    -6.56           14.16\n",
      "    -9.91           14.13\n",
      "    -34.16           14.36\n",
      "    0.82            8.56\n",
      "    29.57           14.33\n",
      "    -16.43           14.33\n",
      "    -58.33           14.34\n",
      "    0.77           13.84\n",
      "    81.82           14.25\n",
      "    156.22           14.35\n",
      "    8.53           13.92\n",
      "    21.30           14.12\n",
      "    -5.15           14.30\n",
      "    -26.69           13.87\n",
      "    28.72           14.37\n",
      "    -1.27           14.38\n",
      "    18.67           13.71\n",
      "    -15.22           14.05\n",
      "    22.25            8.62\n",
      "    -3.02           14.37\n",
      "    10.45           14.32\n",
      "    -6.08           14.25\n",
      "    3.83           14.37\n",
      "    77.25           14.37\n",
      "    2.82           13.71\n",
      "    -23.23           14.31\n",
      "    14.36           13.74\n",
      "    5.72           11.66\n",
      "    143.24           14.37\n",
      "    62.70           14.29\n",
      "    -0.95           14.31\n",
      "    0.77           14.37\n",
      "    14.58           14.25\n",
      "    13.01           12.68\n",
      "    -30.66           14.28\n",
      "    -80.54           13.98\n",
      "    -12.72           14.35\n",
      "    -8.53           14.26\n",
      "    82.30           14.44\n",
      "    15.74           14.14\n",
      "    47.60           14.38\n",
      "    -29.80           12.81\n",
      "    10.29           14.35\n",
      "    -2.60           14.19\n",
      "    2.58           14.36\n",
      "    -61.94           14.14\n",
      "    -15.29           14.25\n",
      "    1.75           14.39\n",
      "    7.38           14.25\n",
      "    -1.79           14.25\n",
      "    4.27           14.38\n",
      "    -3.83           14.36\n",
      "    7.80           13.07\n",
      "    6.92           13.68\n",
      "    53.89           14.30\n",
      "    7.17           14.15\n",
      "    0.21           13.43\n",
      "    15.18           14.33\n",
      "    -22.48           14.37\n",
      "    -4.47           12.65\n",
      "    -43.65           12.88\n",
      "    19.84            6.16\n",
      "    -12.60           14.22\n",
      "    33.88           14.35\n",
      "    -39.27           11.30\n",
      "    -1.82           14.29\n",
      "    37.67           14.29\n",
      "    4.80           14.37\n",
      "    14.91           14.27\n",
      "    12.74           14.39\n",
      "    1.27            5.52\n",
      "    18.23            4.76\n",
      "    -34.31           13.94\n",
      "    -17.47          -42.03\n",
      "    2.84           11.85\n",
      "    -0.77           14.37\n",
      "    24.18           13.38\n",
      "    -58.00           14.39\n",
      "    -6.96            4.74\n",
      "    -15.75           14.31\n",
      "    -22.55           14.26\n",
      "    16.25           14.34\n",
      "    -7.47           14.37\n",
      "    13.85           14.37\n",
      "    -18.00           14.18\n",
      "    8.24           13.63\n",
      "    -12.10           14.30\n",
      "    20.92           14.34\n",
      "    -5.87           13.50\n",
      "    -1.96           14.21\n",
      "    7.82           14.23\n",
      "    -52.01           14.36\n",
      "    8.02           12.90\n",
      "    4.33           14.32\n",
      "    -9.01           14.39\n",
      "    -49.64           14.24\n",
      "    0.47           13.89\n",
      "    33.33           13.99\n",
      "    4.54           14.37\n",
      "    8.18           14.36\n",
      "    5.25           14.18\n",
      "    -0.73           14.00\n",
      "    -3.31           14.31\n",
      "    -57.55           14.38\n",
      "    2.77           -1.69\n",
      "    -39.81           14.20\n",
      "    32.00           12.79\n",
      "    10.13           14.35\n",
      "    22.74           14.33\n",
      "    0.60           14.32\n",
      "    -6.99           14.22\n",
      "    1.00           13.24\n",
      "    1.04           14.05\n",
      "    25.36           14.36\n",
      "    -11.02           13.55\n",
      "    -30.63           14.20\n",
      "    2.68           14.20\n",
      "    -8.70           14.36\n",
      "    -3.77           13.67\n",
      "    3.14            6.56\n",
      "    9.58           14.28\n",
      "    24.76            7.18\n",
      "    -18.93           14.33\n",
      "    -50.94           14.33\n",
      "    7.52           14.28\n",
      "    31.82           14.25\n",
      "    0.10           13.82\n",
      "    -22.36           13.94\n",
      "    20.83           13.41\n",
      "    -28.26           14.26\n",
      "    -10.75           14.14\n",
      "    -0.98            3.96\n",
      "    14.41           10.00\n",
      "    4.71           14.30\n",
      "    -30.27           14.36\n",
      "    -4.69           13.39\n",
      "    -23.66           14.34\n",
      "    1.94           12.23\n",
      "    -0.53           13.12\n",
      "    6.25           14.13\n",
      "    -39.94           14.32\n",
      "    -10.10           14.14\n",
      "    -44.78           14.35\n",
      "    37.76           14.29\n",
      "    5.78           12.44\n",
      "    -10.50           14.24\n",
      "    -7.84           14.03\n",
      "    -13.86           14.35\n",
      "    -17.04           14.30\n",
      "    -22.26           14.30\n",
      "    19.04           13.76\n",
      "    -15.94           14.17\n",
      "    13.03           14.08\n",
      "    162.07           14.36\n",
      "    -0.47           14.18\n",
      "    -23.89           14.38\n",
      "    -16.51           14.36\n",
      "    17.36           14.33\n",
      "    -54.28           14.23\n",
      "    -19.79           13.97\n",
      "    -33.77           14.00\n",
      "    -13.24           13.01\n",
      "    -2.94           14.32\n",
      "    40.45           13.94\n",
      "    16.80           14.38\n",
      "    89.62           14.34\n",
      "    40.39           14.31\n",
      "    -37.66           14.32\n",
      "    148.18           14.39\n",
      "    0.60           13.94\n",
      "    -8.77           14.29\n",
      "    17.57           14.21\n",
      "    -25.00           14.30\n",
      "    7.10           14.25\n",
      "    -5.99           14.23\n",
      "    8.99           14.37\n",
      "    -19.21           14.38\n",
      "    -30.37           14.23\n",
      "    8.37           14.21\n",
      "    17.30           13.07\n",
      "    32.80           14.28\n",
      "    6.38           14.38\n",
      "    -36.02           14.31\n",
      "    11.35           14.30\n",
      "    41.18           14.25\n",
      "    53.49           14.35\n",
      "    1.87           14.11\n",
      "    11.41           13.69\n",
      "    10.25           14.32\n",
      "    -11.82           14.32\n",
      "    0.41           14.03\n",
      "    73.03           14.32\n",
      "    -74.67           14.37\n",
      "    -1.85           14.25\n",
      "    12.20           14.11\n",
      "    22.14           14.16\n",
      "    -37.19           14.37\n",
      "    -56.50           14.31\n",
      "    -29.33           13.94\n",
      "    2.17           14.36\n",
      "    14.95           13.30\n",
      "    -2.75           10.88\n",
      "    -22.56           13.62\n",
      "    -5.02           13.27\n",
      "    14.03           14.37\n",
      "    -20.03           14.30\n",
      "    -41.32           14.39\n",
      "    -9.87           13.06\n",
      "    1.62           14.37\n",
      "    -11.32           14.38\n",
      "    -16.98           14.03\n",
      "    8.23           14.25\n",
      "    -8.76           14.37\n",
      "    -9.65           14.12\n",
      "    -10.37           11.07\n",
      "    -8.22           14.38\n",
      "    -23.64           14.27\n",
      "    8.77           13.60\n",
      "    -22.37           14.37\n",
      "    68.98           14.34\n",
      "    76.80           14.03\n",
      "    10.89           14.38\n",
      "    -42.07           14.27\n",
      "    3.62           14.35\n",
      "    -6.29            3.38\n",
      "    4.37           13.94\n",
      "    -1.49           14.34\n",
      "    10.25           14.25\n",
      "    -17.96           13.25\n",
      "    -2.05           13.39\n",
      "    -13.53           14.37\n",
      "    -9.75           14.05\n",
      "    17.50           14.37\n",
      "    2.09           14.28\n",
      "    -12.23           14.26\n",
      "    -1.79           14.32\n",
      "    18.13           14.03\n",
      "    -2.20           11.78\n",
      "    3.73           14.33\n",
      "    33.07           13.96\n",
      "    -55.00           14.25\n",
      "    -4.28           14.34\n",
      "    15.94           14.02\n",
      "    49.90           13.23\n",
      "    0.25           13.94\n",
      "    -5.71           14.33\n",
      "    60.91           14.21\n",
      "    -19.35           14.24\n",
      "    4.57           14.37\n",
      "    0.35           14.34\n",
      "    25.44           13.47\n",
      "    7.85           14.25\n",
      "    35.05           14.24\n",
      "    -18.35           14.38\n",
      "    3.83           14.28\n",
      "    -45.85           14.34\n",
      "    4.25           14.35\n",
      "    29.60           14.16\n",
      "    -16.81           13.31\n",
      "    -5.98           14.11\n",
      "    1.09           14.37\n",
      "    38.30           14.37\n",
      "    -7.72           14.06\n",
      "    -4.67           13.84\n",
      "    19.23           13.44\n",
      "    -61.56           14.37\n",
      "    6.03           13.47\n",
      "    2.12           14.24\n",
      "    31.84           14.28\n",
      "    -7.14           12.80\n",
      "    7.52           11.86\n",
      "    -21.48           14.38\n",
      "    6.40           14.29\n",
      "    17.85           13.59\n",
      "    80.35           12.12\n",
      "    195.31           14.41\n",
      "    110.54           14.14\n",
      "    -30.00           14.22\n",
      "    16.52            9.45\n",
      "    1.48           14.33\n",
      "    18.61           14.38\n",
      "    61.34           14.26\n",
      "    68.44           14.37\n",
      "    -11.54           14.38\n",
      "    12.34           14.08\n",
      "    51.16           14.25\n",
      "    -21.09           14.02\n",
      "    20.96           14.08\n",
      "    -5.61           14.37\n",
      "    -78.00           14.39\n",
      "    25.83           14.27\n",
      "    17.88           13.18\n",
      "    -1.70           14.34\n",
      "    56.00           14.39\n",
      "    42.12           12.10\n",
      "    270.72           14.38\n",
      "    13.22           14.28\n",
      "    -17.52           13.82\n",
      "    6.12           14.21\n",
      "    -44.44           14.29\n",
      "    -1.76           12.51\n",
      "    18.87           14.23\n",
      "    -39.22           14.39\n",
      "    12.39           13.90\n",
      "    19.60           13.90\n",
      "    39.28           14.37\n",
      "    -66.62            7.64\n",
      "    7.88           14.37\n",
      "    -3.88           14.33\n",
      "    -3.95           14.02\n",
      "    44.29           13.70\n",
      "    24.00           14.39\n",
      "    64.44           14.38\n",
      "    8.63           10.23\n",
      "    10.81           14.38\n",
      "    38.33           14.39\n",
      "    -4.94           14.36\n",
      "    58.86           14.37\n",
      "    -6.23           14.21\n",
      "    24.29           14.27\n",
      "    -44.12           14.26\n",
      "    -38.69           14.30\n",
      "    12.53            9.00\n",
      "    -4.76           14.39\n",
      "    13.53           14.29\n",
      "    -18.55           14.47\n",
      "    -1.91           14.06\n",
      "    122.42           14.36\n",
      "    -25.40           14.32\n",
      "    37.52           14.23\n",
      "    3.87           14.31\n",
      "    -8.85           14.24\n",
      "    0.15           14.22\n",
      "    2.94           14.38\n",
      "    3.32           13.97\n",
      "    -0.56           14.38\n",
      "    -8.53           14.27\n",
      "    -4.84           14.14\n",
      "    9.24           14.16\n",
      "    4.66           14.39\n",
      "    81.75           14.11\n",
      "    24.44           14.38\n",
      "    -0.97           14.34\n",
      "    -9.86           14.11\n",
      "    112.50           14.39\n",
      "    51.83           14.37\n",
      "    2.68           12.98\n",
      "    0.96           14.34\n",
      "    9.37           14.37\n",
      "    8.54           14.37\n",
      "    12.27           14.28\n",
      "    2.63           14.22\n",
      "    3.61           14.36\n",
      "    -52.07           14.34\n",
      "    2.36           14.33\n",
      "    67.34           14.37\n",
      "    -6.31           14.37\n",
      "    -15.52           14.32\n",
      "    12.87           13.89\n",
      "    1.03           14.38\n",
      "    16.95            5.07\n",
      "    -26.77           14.19\n",
      "    2.00           14.39\n",
      "    -10.43           14.34\n",
      "    124.36           14.35\n",
      "    -5.71           11.15\n",
      "    -7.44           14.37\n",
      "    -43.41           14.35\n",
      "    25.66           14.23\n",
      "    14.38           14.14\n",
      "    13.89           12.93\n",
      "    -31.24           14.24\n",
      "    -66.13           14.34\n",
      "    3.37           14.39\n",
      "    -27.27           14.25\n",
      "    15.14           13.35\n",
      "    -30.61           11.35\n",
      "    -15.33           14.16\n",
      "    7.78           14.38\n",
      "    -2.31           14.39\n",
      "    -17.59           14.22\n",
      "    -36.11           14.34\n",
      "    10.72           14.26\n",
      "    13.29           13.95\n",
      "    17.50           14.34\n",
      "    -20.42           14.37\n",
      "    -1.63           14.27\n",
      "    -17.46           14.20\n",
      "    21.55           14.18\n",
      "    -12.05           14.02\n",
      "    -1.11           14.37\n",
      "    -12.04           14.26\n",
      "    -10.40           14.30\n",
      "    -21.03           14.31\n",
      "    -0.33           14.36\n",
      "    -8.46           14.34\n",
      "    -2.37           14.28\n",
      "    -10.30           14.34\n",
      "    -18.71           14.37\n",
      "    -21.24           14.35\n",
      "    26.89           14.08\n",
      "    1.77           14.36\n",
      "    18.45           14.13\n",
      "    8.10           14.26\n",
      "    -11.38           14.37\n",
      "    -0.79           -0.37\n",
      "    -16.76           14.36\n",
      "    -5.16           14.20\n",
      "    -4.30           14.39\n",
      "    -18.91           14.38\n",
      "    -17.21           14.25\n",
      "    -54.99           14.38\n",
      "    8.70           10.31\n",
      "    9.84           14.33\n",
      "    -17.83           13.36\n",
      "    15.47           14.29\n",
      "    -5.98           13.86\n",
      "    -8.37           14.33\n",
      "    -36.29           14.05\n",
      "    -1.04           13.70\n",
      "    -31.48           14.35\n",
      "    -11.30           10.74\n",
      "    -7.85           14.25\n",
      "    2.03           10.76\n",
      "    11.34           14.30\n",
      "    10.67           14.10\n",
      "    -3.57           -1.35\n",
      "    6.34           14.16\n",
      "    -24.03           14.30\n",
      "    -47.75           14.39\n",
      "    2.55           14.34\n",
      "    -39.67           13.99\n",
      "    18.94           14.26\n",
      "    -3.14           14.34\n",
      "    0.20           13.04\n",
      "    -18.91           14.15\n",
      "    11.03           12.85\n",
      "    -2.02           14.24\n",
      "    -0.74           13.77\n",
      "    12.23           14.13\n",
      "    -17.50           14.29\n",
      "    -13.64           13.16\n",
      "    8.58           14.31\n",
      "    13.45           14.33\n",
      "    0.78           14.38\n",
      "    -3.63           14.25\n",
      "    2.71           12.97\n",
      "    25.89           14.10\n",
      "    13.74           14.28\n",
      "    -0.01           13.98\n",
      "    -3.87           12.58\n",
      "    -17.22           14.32\n",
      "    19.21           13.78\n",
      "    8.08           14.27\n",
      "    12.14           13.55\n",
      "    -0.89           14.37\n",
      "    -4.62           13.87\n",
      "    -18.29           14.37\n",
      "    -14.94           14.19\n",
      "    -9.56           14.18\n",
      "    16.43           14.37\n",
      "    18.68           13.89\n",
      "    -11.26           13.23\n",
      "    -15.01           14.34\n",
      "    -27.13           14.38\n",
      "    -22.50           14.39\n",
      "    13.96           13.15\n",
      "    -50.60           13.87\n",
      "    -0.73           13.72\n",
      "    9.45           14.03\n",
      "    -10.89           13.90\n",
      "    20.40           14.39\n",
      "    10.95           14.23\n",
      "    15.27           14.10\n",
      "    468.03           14.39\n",
      "    53.85           14.22\n",
      "    -3.19           13.51\n",
      "    -14.82           14.33\n",
      "    -5.28           14.35\n",
      "    -1.74           14.11\n",
      "    -9.96           14.26\n",
      "    39.15           13.53\n",
      "    -10.15            8.95\n",
      "    10.41           14.37\n",
      "    -13.96           14.07\n",
      "    20.88           14.21\n",
      "    -25.00           14.36\n",
      "    -83.14           14.29\n",
      "    -1.35           -1.41\n",
      "    -2.88           14.34\n",
      "    9.23           14.30\n",
      "    -14.14           12.99\n",
      "    -5.09           14.31\n",
      "    43.35           14.29\n",
      "    -27.37           14.38\n",
      "    -2.27           14.37\n",
      "    8.26           14.27\n",
      "    3.09           14.34\n",
      "    2.58           14.19\n",
      "    -50.35           14.33\n",
      "    27.51           14.34\n",
      "    -11.25           14.38\n",
      "    -2.03           13.61\n",
      "    -0.62           14.20\n",
      "    53.35           14.23\n",
      "    1.35           14.27\n",
      "    21.44           14.39\n",
      "    11.50            9.78\n",
      "    82.13           14.35\n",
      "    22.89           13.99\n",
      "    1.77           14.10\n",
      "    1.48           14.38\n",
      "    14.34           14.18\n",
      "    -18.56           14.36\n",
      "    16.34           14.06\n",
      "    -5.47           14.10\n",
      "    -41.37           13.90\n",
      "    -59.85           14.35\n",
      "    14.12           14.23\n",
      "    -37.50           14.16\n",
      "    -53.01           14.00\n",
      "    14.37           14.37\n",
      "    -72.73           14.36\n",
      "    0.69           13.91\n",
      "    10.29           14.34\n",
      "    19.34           14.34\n",
      "    57.78           14.38\n",
      "    -16.41           14.36\n",
      "    0.40           13.81\n",
      "    8.92           12.58\n",
      "    -34.62           14.27\n",
      "    7.35           12.60\n",
      "    16.32           14.37\n",
      "    8.87           13.86\n",
      "    18.01           14.31\n",
      "    56.49           14.18\n",
      "    5.52           14.36\n",
      "    47.58           14.30\n",
      "    3.16           14.34\n",
      "    4.11           14.34\n",
      "    2.43           14.17\n",
      "    23.55           14.25\n",
      "    -7.89           14.35\n",
      "    -4.55           13.33\n",
      "    6.64           14.38\n",
      "    10.49           13.85\n",
      "    31.51           14.22\n",
      "    -30.51           14.38\n",
      "    5.63           14.38\n",
      "    -14.94           14.31\n",
      "    3.22           14.15\n",
      "    -26.53           14.38\n",
      "    -1.55           13.92\n",
      "    -0.52           13.89\n",
      "    54.55           14.37\n",
      "    3.04           14.34\n",
      "    7.08           14.30\n",
      "    -4.07           14.32\n",
      "    5.07           14.24\n",
      "    35.94           14.39\n",
      "    5.22           14.36\n",
      "    6.55           14.17\n",
      "    -2.16            6.29\n",
      "    15.47           14.04\n",
      "    -45.68           14.24\n",
      "    11.15           14.19\n",
      "    -49.48           13.88\n",
      "    11.18            8.33\n",
      "    1053.85           14.38\n",
      "    -19.36            8.64\n",
      "    -15.48           13.58\n",
      "    8.85           14.30\n",
      "    54.72           14.38\n",
      "    -8.72           14.35\n",
      "    -3.69           11.88\n",
      "    35.01           14.37\n",
      "    39.76           14.28\n",
      "    2.58           13.99\n",
      "    23.70           14.38\n",
      "    -34.12           13.63\n",
      "    -13.22           14.30\n",
      "    -13.73           14.18\n",
      "    17.24           14.34\n",
      "    -7.70           14.26\n",
      "    0.79           14.36\n",
      "    -17.53           14.17\n",
      "    -45.38           14.35\n",
      "    5.31           14.38\n",
      "    -23.50           14.34\n",
      "    -6.90           14.38\n",
      "    -8.56           14.35\n",
      "    10.36           12.76\n",
      "    -63.53           14.35\n",
      "    -0.05           14.08\n",
      "    26.92           14.15\n",
      "    -17.77           14.27\n",
      "    -4.32           14.22\n",
      "    -38.99           14.09\n",
      "    6.25           14.20\n",
      "    39.92           14.10\n",
      "    -40.23           14.38\n",
      "    5.31           13.47\n",
      "    -8.37           14.23\n",
      "    -54.09           14.25\n",
      "    -69.15           14.12\n",
      "    6.47           11.47\n",
      "    35.56           14.02\n",
      "    39.68           12.51\n",
      "    1.47           13.98\n",
      "    -41.11           14.17\n",
      "    -25.00           14.22\n",
      "    49.53           14.35\n",
      "    -0.54           14.25\n",
      "    0.99           14.06\n",
      "    24.38           13.63\n",
      "    -46.47           13.94\n",
      "    -19.97           14.20\n",
      "    -27.73           13.92\n",
      "    -7.06           14.38\n",
      "    10.38           14.29\n",
      "    17.82           14.20\n",
      "    -30.17            8.63\n",
      "    -14.86           14.36\n",
      "    -50.57           14.37\n",
      "    -35.79           13.94\n",
      "    5.85           14.24\n",
      "    2.44           14.33\n",
      "    1.39           14.37\n",
      "    5.55           12.82\n",
      "    6.68           14.25\n",
      "    72.22           14.35\n",
      "    3.02           14.31\n",
      "    44.00           14.32\n",
      "    61.47           14.39\n",
      "    3.85           14.19\n",
      "    -6.24            5.17\n",
      "    0.26           14.24\n",
      "    -27.18           14.18\n",
      "    30.81           14.31\n",
      "    -17.66           14.17\n",
      "    -13.26           14.05\n",
      "    1.32           14.00\n",
      "    97.57           14.31\n",
      "    -6.00           14.29\n",
      "    -18.46           14.26\n",
      "    52.89           13.30\n",
      "    6.68           14.31\n",
      "    -5.66           14.31\n",
      "    -22.50           13.84\n",
      "    36.00           11.54\n",
      "    55.46           14.39\n",
      "    5.67           13.37\n",
      "    -4.71           14.39\n",
      "    -1.79           14.31\n",
      "    9.58            8.94\n",
      "    17.70           14.26\n",
      "    -25.43           14.36\n",
      "    3.74           14.32\n",
      "    -4.85           14.35\n",
      "    11.55           14.32\n",
      "    2.73           14.20\n",
      "    -14.83           14.17\n",
      "    1.60           14.39\n",
      "    -22.55           14.34\n",
      "    64.68           12.94\n",
      "    19.57           14.22\n",
      "    31.08           14.32\n",
      "    2.94           14.23\n",
      "    -44.93           14.33\n",
      "    -22.00           14.34\n",
      "    -15.19           14.20\n",
      "    10.05           14.02\n",
      "    291.01           14.39\n",
      "    -32.43           14.37\n",
      "    -13.75           14.11\n",
      "    -43.49           14.35\n",
      "    -0.25           14.31\n",
      "    3.00           13.76\n",
      "    105.93           14.34\n",
      "    0.77           14.22\n",
      "    2604.00           14.38\n",
      "    -3.70           14.27\n",
      "    23.20           13.10\n",
      "    33.33           14.32\n",
      "    12.14           13.57\n",
      "    1.53           14.37\n",
      "    127.09           14.29\n",
      "    -18.17           14.21\n",
      "    134.30           14.36\n",
      "    -6.89           10.70\n",
      "    596.31           14.34\n",
      "    -45.52           14.37\n",
      "    3.65           14.22\n",
      "    -4.94           14.29\n",
      "    8.31            6.17\n",
      "    17.19           14.18\n",
      "    278.26           14.39\n",
      "    13.44           10.00\n",
      "    1.15           14.18\n",
      "    6.65           14.03\n",
      "    1.59           14.38\n",
      "    43.79           14.14\n",
      "    -13.83           14.21\n",
      "    -1.09           14.10\n",
      "    -18.05           14.18\n",
      "    -35.88           14.25\n",
      "    -6.25           14.37\n",
      "    -3.48           14.26\n",
      "    -0.21            7.53\n",
      "    -13.27           14.37\n",
      "    0.93           13.50\n",
      "    -1.98           13.54\n",
      "    10.55           14.02\n",
      "    -44.24           14.36\n",
      "    -17.09           13.86\n",
      "    8.22           14.22\n",
      "    8.38           14.36\n",
      "    -48.99           14.24\n",
      "    -3.86           13.76\n",
      "    -13.86           14.23\n",
      "    3.33           14.21\n",
      "    112.50           14.33\n",
      "    0.26           14.31\n",
      "    28.00           14.28\n",
      "    -2.75           12.45\n",
      "    -43.09           14.31\n",
      "    27.98           13.80\n",
      "    -10.04           14.38\n",
      "    11.39           14.27\n",
      "    2.23           12.45\n",
      "    41.65           14.35\n",
      "    -3.04           13.56\n",
      "    34.96           14.13\n",
      "    4.17            5.31\n",
      "    -16.12           14.19\n",
      "    400.35           14.30\n",
      "    -20.05           14.25\n",
      "    -5.05           11.71\n",
      "    -5.24           13.46\n",
      "    -14.17           13.41\n",
      "    46.57           13.44\n",
      "    11.01           13.04\n",
      "    -22.99           14.31\n",
      "    5.45           14.19\n",
      "    11.11           14.36\n",
      "    24.95            8.20\n",
      "    0.29           14.28\n",
      "    -14.31           14.24\n",
      "    -7.09           14.24\n",
      "    17.35           14.37\n",
      "    7.15           13.16\n",
      "    28.52           14.34\n",
      "    -23.30           14.12\n",
      "    -7.84           13.18\n",
      "    -16.68           14.36\n",
      "    8.46           14.37\n",
      "    3.75           14.34\n",
      "    -4.99           14.35\n",
      "    17.84           14.16\n",
      "    34.99           14.10\n",
      "    0.72           14.36\n",
      "    5.38           14.36\n",
      "    49.51           14.27\n",
      "    -11.94           14.08\n",
      "    -9.11           14.31\n",
      "    149.25           14.29\n",
      "    4.96           13.88\n",
      "    -21.77           14.32\n",
      "    7.20           14.31\n",
      "    50.32           14.41\n",
      "    -20.01           14.26\n",
      "    3.72           14.20\n",
      "    3.12           14.35\n",
      "    1.09            5.17\n",
      "    88.12           14.00\n",
      "    41.48           14.30\n",
      "    -61.70           11.53\n",
      "    -4.48           14.11\n",
      "    -0.29           14.22\n",
      "    -22.41           14.35\n",
      "    16.77           13.91\n",
      "    17.85           13.85\n",
      "    -3.37           14.37\n",
      "    -18.80           14.37\n",
      "    25.00           13.62\n",
      "    -18.51           14.33\n",
      "    -17.32           14.32\n",
      "    -20.04           14.39\n",
      "    -54.43           14.07\n",
      "    2.72           13.96\n",
      "    21.14           14.34\n",
      "    0.28           14.05\n",
      "    26.64           14.38\n",
      "    3.98            9.42\n",
      "    8.50           14.22\n",
      "    -10.87           14.37\n",
      "    -21.14           14.25\n",
      "    69.04           13.25\n",
      "    -16.14           13.58\n",
      "    8.81           14.33\n",
      "    -21.60           14.33\n",
      "    8.39           14.32\n",
      "    -0.84           14.33\n",
      "    8.24            4.44\n",
      "    18.61           13.47\n",
      "    -43.02           -9.78\n",
      "    15.79           14.38\n",
      "    22.79           14.23\n",
      "    17.17           14.27\n",
      "    4.70           14.32\n",
      "    623.79           14.38\n",
      "    -12.55            4.40\n",
      "    -13.20           14.23\n",
      "    12.02           14.18\n",
      "    34.64           14.32\n",
      "    22.99           13.60\n",
      "    -7.58           14.36\n",
      "    -27.69           14.14\n",
      "    58.12           14.36\n",
      "    7.69           13.50\n",
      "    2.98           13.73\n",
      "    13.35           14.11\n",
      "    -6.40           14.21\n",
      "    4.78           14.13\n",
      "    -43.25           11.22\n",
      "    -48.11           14.35\n",
      "    3.98           14.37\n",
      "    10.46           14.17\n",
      "    -11.62           14.31\n",
      "    -43.73           12.76\n",
      "    -4.76           14.32\n",
      "    4.92           13.44\n",
      "    7.06           14.27\n",
      "    12.92           14.16\n",
      "    -20.39           14.35\n",
      "    23.79           14.13\n",
      "    34.42           14.12\n",
      "    25.99           14.32\n",
      "    24.45           14.32\n",
      "    2.90           13.44\n",
      "    -17.28           14.22\n",
      "    4.14           11.57\n",
      "    22.61           14.23\n",
      "    0.35           14.35\n",
      "    16.04           14.23\n",
      "    10.25           14.22\n",
      "    4.63           14.30\n",
      "    8.31           14.00\n",
      "    20.93           14.22\n",
      "    10.58            4.69\n",
      "    -20.71           13.44\n",
      "    11.76           13.71\n",
      "    -5.97           14.24\n",
      "    8.13           14.39\n",
      "    11.43           12.67\n",
      "    -31.56           13.00\n",
      "    -58.33           14.38\n",
      "    35.37           14.05\n",
      "    -6.35           14.28\n",
      "    4.61           14.30\n",
      "    -18.20           12.93\n",
      "    12.03           12.09\n",
      "    29.89           14.34\n",
      "    4.51           11.53\n",
      "    32.78           14.36\n",
      "    67.81           13.33\n",
      "    -25.17           14.38\n",
      "    -0.06           13.53\n",
      "    -51.57           14.37\n",
      "    4.79           14.35\n",
      "    61.52           14.31\n",
      "    7.35           11.58\n",
      "    2.44           13.61\n",
      "    7.64            5.88\n",
      "    2.79           14.36\n",
      "    66.92           13.79\n",
      "    6.11           14.17\n",
      "    9.59           13.98\n",
      "    -29.56           14.06\n",
      "    -19.38           14.12\n",
      "    7.61           14.38\n",
      "    6.27           14.25\n",
      "    -87.58           13.84\n",
      "    33.87           14.30\n",
      "    0.40           13.97\n",
      "    84.01           14.34\n",
      "    -54.56           13.83\n",
      "    4.51           14.33\n",
      "    -0.84           12.64\n",
      "    -9.73           14.37\n",
      "    23.81           14.35\n",
      "    -19.06           14.33\n",
      "    19.21           14.02\n",
      "    -2.82           15.96\n",
      "    11.85            9.63\n",
      "    0.89           14.20\n",
      "    -8.72           14.23\n",
      "    47.69           13.98\n",
      "    32.34           12.70\n",
      "    -30.12           14.25\n",
      "    25.00           14.27\n",
      "    -10.72           -0.70\n",
      "    0.49           14.22\n",
      "    -1.60           14.30\n",
      "    -14.33           14.33\n",
      "    -20.73           14.28\n",
      "    33.07           14.39\n",
      "    -14.34           14.18\n",
      "    12.69           14.33\n",
      "    1.77           14.20\n",
      "    0.69           13.75\n",
      "    22.44           13.24\n",
      "    -30.85           14.31\n",
      "    28.41           14.37\n",
      "    -21.34           14.33\n",
      "    63.07           14.32\n",
      "    1.15           14.25\n",
      "    -12.30           14.33\n",
      "    -0.32           14.22\n",
      "    6.80           14.34\n",
      "    -57.13           14.39\n",
      "    -0.81           14.36\n",
      "    -42.08           13.97\n",
      "    19.37           13.92\n",
      "    -8.83           14.33\n",
      "    25.80           14.20\n",
      "    0.24           14.39\n",
      "    27.61           14.24\n",
      "    -9.51           13.69\n",
      "    -20.90           14.43\n",
      "    17.30           14.31\n",
      "    34.06           14.08\n",
      "    20.38           16.39\n",
      "    -39.27           14.36\n",
      "    -3.96           14.35\n",
      "    -11.68           13.27\n",
      "    23.24           13.98\n",
      "    12.66           14.29\n",
      "    -3.16            4.64\n",
      "    -3.90           14.34\n",
      "    41.36           14.21\n",
      "    -83.64           14.39\n",
      "    -10.92           14.37\n",
      "    -10.91           12.75\n",
      "    -5.56           14.39\n",
      "    4.42           14.29\n",
      "    19.43           13.35\n",
      "    39.22           14.30\n",
      "    0.65           14.16\n",
      "    -1.17           14.37\n",
      "    -34.96           14.21\n",
      "    25.52           12.90\n",
      "    -20.77           14.24\n",
      "    61.92           14.37\n",
      "    5.10           14.40\n",
      "    3.77           14.30\n",
      "    -1.52           14.21\n",
      "    10.55           12.97\n",
      "    -50.27           14.39\n",
      "    -62.84           14.36\n",
      "    -10.11           14.20\n",
      "    -2.59           13.02\n",
      "    -12.07            6.78\n",
      "    6.01           14.07\n",
      "    95.33           14.36\n",
      "    -40.00           14.39\n",
      "    3.96           14.26\n",
      "    -9.12           14.16\n",
      "    20.00           14.24\n",
      "    3.49           14.41\n",
      "    -13.09           14.30\n",
      "    12.04           14.25\n",
      "    -3.11           14.36\n",
      "    -13.96           12.91\n",
      "    2.61           14.42\n",
      "    3.48           14.32\n",
      "    5.96           13.79\n",
      "    42.21           14.29\n",
      "    1037.50           14.37\n",
      "    -15.32           14.06\n",
      "    164.38           14.24\n",
      "    -15.06           14.25\n",
      "    -24.16            6.34\n",
      "    6.21           14.38\n",
      "    48.39           14.27\n",
      "    9.73           14.35\n",
      "    -6.38           14.35\n",
      "    -22.24           14.22\n",
      "    0.39           14.30\n",
      "    -6.76           14.36\n",
      "    11.80           14.02\n",
      "    12.18           14.24\n",
      "    6.71           13.71\n",
      "    25.84           14.26\n",
      "    41.26           14.36\n",
      "    -1.31           13.58\n",
      "    -2.78           14.27\n",
      "    1.09           14.32\n",
      "    3.47           14.15\n",
      "    0.92           14.53\n",
      "    -38.61           14.12\n",
      "    -6.87           14.25\n",
      "    -4.04           14.51\n",
      "    0.41           14.39\n",
      "    7.89           13.87\n",
      "    14.34           14.39\n",
      "    -16.24            6.11\n",
      "    -11.45           14.24\n",
      "    12.67           13.19\n",
      "    -3.17           14.06\n",
      "    -1.98           14.30\n",
      "    -0.97           14.33\n",
      "    -15.44           14.33\n",
      "    -16.05           14.34\n",
      "    42.78           14.30\n",
      "    3.34           14.00\n",
      "    -22.65           14.39\n",
      "    2.59           13.26\n",
      "    -10.00           14.34\n",
      "    11.95           14.23\n",
      "    -35.77           14.35\n",
      "    -6.70           14.29\n",
      "    89.08           14.20\n",
      "    36.10           14.33\n",
      "    2.52           13.21\n",
      "    -4.81           13.54\n",
      "    41.51           14.27\n",
      "    -3.71           13.97\n",
      "    -2.53           14.26\n",
      "    -17.07           14.32\n",
      "    5.62           14.30\n",
      "    18.73           14.29\n",
      "    -4.04           14.19\n",
      "    10.43           11.08\n",
      "    7.97           14.22\n",
      "    3.26           13.94\n",
      "    1.28            0.18\n",
      "    7.18           14.37\n",
      "    -25.83           14.21\n",
      "    48.44           14.38\n",
      "    -0.79           14.26\n",
      "    18.31            3.85\n",
      "    -4.08            9.63\n",
      "    9.37           14.29\n",
      "    -37.96           13.93\n",
      "    26.76           14.33\n",
      "    1.36           11.97\n",
      "    -10.31           14.12\n",
      "    15.09           -6.52\n",
      "    -11.76           14.39\n",
      "    0.73           14.14\n",
      "    6.11           14.06\n",
      "    -4.24           14.32\n",
      "    -49.61           14.35\n",
      "    -32.48           14.38\n",
      "    -27.37           14.40\n",
      "    -10.50           14.39\n",
      "    5.55           13.91\n",
      "    -8.89           14.23\n",
      "    -24.30           14.21\n",
      "    10.95           12.00\n",
      "    575.00           14.30\n",
      "    7.78           13.71\n",
      "    12.03           14.09\n",
      "    -16.03           14.26\n",
      "    -10.26           14.36\n",
      "    -8.73           13.72\n",
      "    -7.48           13.74\n",
      "    -44.19           14.29\n",
      "    0.24           14.20\n",
      "    -21.35           14.39\n",
      "    33.12           14.37\n",
      "    -17.82           14.28\n",
      "    13.10           14.13\n",
      "    -18.84           14.24\n",
      "    -1.56           13.88\n",
      "    -59.52           14.33\n",
      "    28.67           14.41\n",
      "    -0.19           14.04\n",
      "    -21.94           14.25\n",
      "    24.15           14.33\n",
      "    -31.95           14.04\n",
      "    20.96           13.45\n",
      "    -20.26           14.36\n",
      "    262.66           14.26\n",
      "    32.10           14.33\n",
      "    33.14           14.39\n",
      "    4.07           13.36\n",
      "    -12.36           13.96\n",
      "    -2.05           14.34\n",
      "    118.18           14.31\n",
      "    -28.39           14.23\n",
      "    -16.28           14.37\n",
      "    3.62           14.37\n",
      "    8.32           14.25\n",
      "    -29.76           14.38\n",
      "    0.87           14.39\n",
      "    -37.42           14.35\n",
      "    -9.31           14.34\n",
      "    16.14           13.40\n",
      "    1.44           13.70\n",
      "    3.60           11.54\n",
      "    -7.34           14.31\n",
      "    17.40           14.14\n",
      "    24.00           14.16\n",
      "    -18.63           14.39\n",
      "    1.99           14.22\n",
      "    -7.83           14.36\n",
      "    -42.35           14.26\n",
      "    17.80            9.16\n",
      "    1.33           14.26\n",
      "    -4.17           14.04\n",
      "    4.44           14.36\n",
      "    1.70           14.09\n",
      "    20.19           14.38\n",
      "    -13.39           14.10\n",
      "    797.93           14.21\n",
      "    -45.71           14.39\n",
      "    27.09           14.13\n",
      "    10.06           12.85\n",
      "    4.58           14.32\n",
      "    3.54          -15.99\n",
      "    1.88           14.32\n",
      "    -21.69           14.02\n",
      "    -51.30           14.27\n",
      "    -6.22           14.26\n",
      "    -2.58           14.32\n",
      "    32.51           14.28\n",
      "    -1.88           14.20\n",
      "    16.67           14.30\n",
      "    -2.80           14.33\n",
      "    -16.25           14.37\n",
      "    -15.22           13.86\n",
      "    12.61           14.34\n",
      "    129.91           14.32\n",
      "    1.15           14.28\n",
      "    4.26           14.26\n",
      "    8.18           -1.75\n",
      "    -2.94           12.53\n",
      "    462.50           14.34\n",
      "    -0.16           14.39\n",
      "    -3.64           14.32\n",
      "    2.09           13.77\n",
      "    67.24           14.23\n",
      "    -10.56           13.53\n",
      "    -4.75           14.39\n",
      "    0.37           14.36\n",
      "    10.53           15.49\n",
      "    -9.11           -1.13\n",
      "    -5.62           14.15\n",
      "    15.30           14.31\n",
      "    -5.31           14.27\n",
      "    13.70           14.25\n",
      "    0.58           13.96\n",
      "    -1.38           14.37\n",
      "    9.76           14.30\n",
      "    -12.07           14.36\n",
      "    -2.52           14.37\n",
      "    15.90           14.05\n",
      "    -13.40           14.12\n",
      "    12.57           -7.66\n",
      "    -4.00           13.39\n",
      "    9.42           14.02\n",
      "    -19.60           13.63\n",
      "    95.90           14.32\n",
      "    3.23           14.20\n",
      "    8.87           -0.46\n",
      "    1.08           12.21\n",
      "    334.78           14.38\n",
      "    -10.40           14.38\n",
      "    -49.22           14.27\n",
      "    -26.38           12.57\n",
      "    72.36           14.36\n",
      "    -28.28           14.39\n",
      "    21.06           14.17\n",
      "    -6.49           14.17\n",
      "    7.60           14.38\n",
      "    -0.84           11.49\n",
      "    12.97           14.11\n",
      "    23.60           14.37\n",
      "    1.61           14.38\n",
      "    59.48           14.35\n",
      "    -2.00           14.22\n",
      "    -59.50           14.33\n",
      "    17.41           14.34\n",
      "    5.32           13.94\n",
      "    -11.62           14.32\n",
      "    -1.50           13.99\n",
      "    6.62           14.23\n",
      "    -38.38           14.35\n",
      "    5.56           14.11\n",
      "    3.52           14.38\n",
      "    -15.09           14.36\n",
      "    8.21           12.50\n",
      "    -18.45           14.34\n",
      "    0.49           14.39\n",
      "    -34.96           14.39\n",
      "    -9.92           12.87\n",
      "    -11.66           14.22\n",
      "    -60.82           14.39\n",
      "    24.77           14.33\n",
      "    -0.53           12.63\n",
      "    15.80           14.07\n",
      "    -58.46           14.27\n",
      "    -19.71           14.25\n",
      "    -1.14           14.17\n",
      "    -0.86           14.30\n",
      "    -7.43           14.28\n",
      "    47.30           14.11\n",
      "    -37.69           14.34\n",
      "    -9.28           13.54\n",
      "    20.84           12.66\n",
      "    -35.09           14.38\n",
      "    -51.54           14.35\n",
      "    -8.44           14.17\n",
      "    50.20           14.35\n",
      "    -8.12           14.28\n",
      "    -35.66           14.38\n",
      "    0.90           14.22\n",
      "    29.77           14.36\n",
      "    -24.22           14.31\n",
      "    21.29           14.23\n",
      "    -0.53           13.74\n",
      "    -1.43           14.25\n",
      "    -38.75           14.21\n",
      "    13.46           14.25\n",
      "    -5.56           14.01\n",
      "    -8.26           13.21\n",
      "    58.16           14.38\n",
      "    5.37           14.33\n",
      "    -0.02           14.06\n",
      "    -34.82           14.32\n",
      "    31.16           14.30\n",
      "    9.78           14.08\n",
      "    10.68           12.63\n",
      "    -3.19           13.83\n",
      "    -31.62           14.20\n",
      "    -43.34           14.39\n",
      "    -3.13           14.33\n",
      "    -1.40            8.83\n",
      "    28.46           14.17\n",
      "    37.54           14.36\n",
      "    1748.60           14.15\n",
      "    -40.51           13.75\n",
      "    70.50           14.33\n",
      "    1.21           14.27\n",
      "    -16.95           14.14\n",
      "    21.28           14.39\n",
      "    11.75           13.91\n",
      "    -7.07           14.37\n",
      "    10.96           14.10\n",
      "    0.79           14.39\n",
      "    16.91           12.33\n",
      "    -27.36           13.52\n",
      "    -36.13           14.35\n",
      "    6.40           14.29\n",
      "    -22.19           14.28\n",
      "    17.10           14.36\n",
      "    3.54            5.19\n",
      "    33.94           14.32\n",
      "    7.34           14.18\n",
      "    7.36           14.32\n",
      "    -0.42           14.36\n",
      "    -27.99           14.37\n",
      "    -1.22           12.84\n",
      "    -42.75           14.35\n",
      "    2.11           13.78\n",
      "    -75.89           14.22\n",
      "    1.27           13.82\n",
      "    4.08           14.25\n",
      "    -5.99           13.97\n",
      "    31.72           14.26\n",
      "    -3.17           10.10\n",
      "    -21.44           13.73\n",
      "    24.83           14.10\n",
      "    33.57           14.23\n",
      "    -1.71           14.34\n",
      "    47.52           14.38\n",
      "    13.50           14.35\n",
      "    -14.64           14.30\n",
      "    -32.39           14.38\n",
      "    -6.27           14.07\n",
      "    -3.13           14.39\n",
      "    -12.17            6.14\n",
      "    -12.71           13.86\n",
      "    4.52           14.33\n",
      "    13.86           13.88\n",
      "    27.20           14.31\n",
      "    21.65           -3.29\n",
      "    6.29           -0.11\n",
      "    -2.07           13.98\n",
      "    28.74           14.29\n",
      "    10.70           14.02\n",
      "    20.60           14.28\n",
      "    -14.91           14.33\n",
      "    -3.03           14.27\n",
      "    9.24            4.50\n",
      "    4.89           14.37\n",
      "    0.35           13.77\n",
      "    -9.71           14.38\n",
      "    -37.71           13.61\n",
      "    -5.56           14.25\n",
      "    -0.79           14.23\n",
      "    37.03           14.26\n",
      "    -7.43           14.29\n",
      "    -30.19           14.19\n",
      "    -21.01           14.51\n",
      "    16.19           14.33\n",
      "    -36.86           14.36\n",
      "    13.13           14.08\n",
      "    -1.83           14.33\n",
      "    16.20           14.03\n",
      "    -6.91           14.36\n",
      "    -42.15           14.28\n",
      "    11.07           14.05\n",
      "    17.95           14.30\n",
      "    13.20           14.23\n",
      "    -18.38           14.22\n",
      "    -14.91           13.53\n",
      "    10.15           14.31\n",
      "    -15.52           -0.65\n",
      "    0.83           14.07\n",
      "    -2.50           14.34\n",
      "    -21.36           14.25\n",
      "    -11.43           14.36\n",
      "    -9.82           13.50\n",
      "    -3.15           13.89\n",
      "    -14.49            8.27\n",
      "    -19.27           14.38\n",
      "    -3.85           14.31\n",
      "    -19.85           11.34\n",
      "    -19.53           14.31\n",
      "    -31.75           14.27\n",
      "    10.49           14.18\n",
      "    24.69           14.33\n",
      "    -66.04           14.14\n",
      "    -0.62           13.56\n",
      "    -3.41           14.33\n",
      "    -3.24           -2.27\n",
      "    34.86           14.13\n",
      "    9.86           14.36\n",
      "    9.51           14.10\n",
      "    2.86           14.34\n",
      "    1.10           11.80\n",
      "    -30.00           14.22\n",
      "    6.68           14.18\n",
      "    -23.61           12.60\n",
      "    -39.82           14.12\n",
      "    0.55           13.62\n",
      "    -22.01           14.39\n",
      "    -2.56           14.12\n",
      "    -11.47           14.20\n",
      "    -4.83           14.14\n",
      "    -9.29           14.38\n",
      "    -23.08           14.39\n",
      "    -39.45           14.29\n",
      "    23.92           14.17\n",
      "    -67.26           14.26\n",
      "    -5.85           14.36\n",
      "    4.86           14.37\n",
      "    -6.67           14.34\n",
      "    -11.64           14.33\n",
      "    0.79           14.39\n",
      "    2.41           12.60\n",
      "    14.19           13.50\n",
      "    1.42           14.38\n",
      "    -33.96           14.25\n",
      "    -26.69           14.38\n",
      "    -13.83           14.14\n",
      "    -39.62           14.35\n",
      "    -17.17           14.06\n",
      "    -28.27           14.39\n",
      "    10.74           13.87\n",
      "    39.21           14.37\n",
      "    -12.18           14.00\n",
      "    -12.77           13.84\n",
      "    6.24           14.11\n",
      "    -0.37           12.11\n",
      "    0.77           14.29\n",
      "    37.81           13.15\n",
      "    -19.48           14.01\n",
      "    -43.48           13.24\n",
      "    -5.37           14.35\n",
      "    25.52           14.36\n",
      "    19.94           13.45\n",
      "    -46.08           14.19\n",
      "    -21.62           14.33\n",
      "    -12.32           13.22\n",
      "    -16.30           14.03\n",
      "    67.86           14.31\n",
      "    -10.73           14.29\n",
      "    34.33           14.17\n",
      "    -19.33           14.25\n",
      "    -25.79           14.43\n",
      "    -21.28           14.21\n",
      "    -21.52           14.38\n",
      "    -6.12            5.03\n",
      "    -40.74           14.39\n",
      "    11.34           13.63\n",
      "    4.52           14.29\n",
      "    12.27           14.24\n",
      "    -1.01           14.39\n",
      "    8.68           14.39\n",
      "    -21.98           14.37\n",
      "    0.79           14.34\n",
      "    3.58           14.23\n",
      "    -26.39           14.35\n",
      "    -2.87           14.39\n",
      "    34.36           14.38\n",
      "    171.79           14.10\n",
      "    24.69           14.28\n",
      "    0.31           14.18\n",
      "    -19.66           14.10\n",
      "    28.65           14.34\n",
      "    57.94           13.94\n",
      "    -19.07           14.36\n",
      "    5.29           14.22\n",
      "    8.72           14.30\n",
      "    -17.27           14.23\n",
      "    -23.82           14.25\n",
      "    2.85           14.26\n",
      "    29.21           14.33\n",
      "    -5.25           14.32\n",
      "    -3.98           14.18\n",
      "    -26.73           14.32\n",
      "    11.93           14.31\n",
      "    -12.68           14.34\n",
      "    25.48           14.23\n",
      "    -4.31           13.72\n",
      "    -26.21           14.19\n",
      "    10.75           13.96\n",
      "    -5.26           14.40\n",
      "    25.07           14.25\n",
      "    4.02           14.37\n",
      "    -3.72           13.62\n",
      "    1.76           13.77\n",
      "    -33.11           14.33\n",
      "    3.47           14.32\n",
      "    -19.01           14.18\n",
      "    -25.81           14.37\n",
      "    -13.81           12.67\n",
      "    -28.15           14.33\n",
      "    -30.14           14.34\n",
      "    24.76           14.29\n",
      "    45.06           14.08\n",
      "    9.63           13.87\n",
      "    -4.91           14.36\n",
      "    -6.04            3.75\n",
      "    -49.34           14.39\n",
      "    6.57           14.00\n",
      "    -30.70           14.27\n",
      "    15.48           14.10\n",
      "    60.09           13.77\n",
      "    -2.92           14.28\n",
      "    12.62           14.23\n",
      "    -30.43           14.38\n",
      "    62.42           14.14\n",
      "    -58.84           14.20\n",
      "    21.47           13.95\n",
      "    -33.40           14.33\n",
      "    11.10           14.18\n",
      "    7.26           13.06\n",
      "    24.71           14.19\n",
      "    23.08           14.29\n",
      "    -10.52           14.12\n",
      "    11.21           12.21\n",
      "    -1.36           14.34\n",
      "    -4.27          -22.26\n",
      "    -18.55           14.26\n",
      "    -1.25           13.77\n",
      "    -25.48           14.33\n",
      "    -5.32           14.16\n",
      "    -2.28           14.21\n",
      "    0.85           14.36\n",
      "    -0.66           13.01\n",
      "    3.09           11.85\n",
      "    -22.30           14.16\n",
      "    29.17           14.30\n",
      "    -25.36           14.24\n",
      "    -14.33           10.33\n",
      "    4.67           14.28\n",
      "    -27.46           14.32\n",
      "    -15.46           14.22\n",
      "    -65.32           14.24\n",
      "    18.34           13.95\n",
      "    -1.38           14.37\n",
      "    6.56           14.34\n",
      "    28.11           14.39\n",
      "    7.92           14.16\n",
      "    -25.98           14.37\n",
      "    -8.46           14.36\n",
      "    2.07           14.19\n",
      "    -52.87           13.87\n",
      "    1.71           14.29\n",
      "    -0.71           14.32\n",
      "    -7.43           14.36\n",
      "    -12.71           14.36\n",
      "    -38.08           14.32\n",
      "    4.51           14.35\n",
      "    9.99           14.27\n",
      "    5.89           10.50\n",
      "    7.80           14.11\n",
      "    -26.12           13.36\n",
      "    -24.36            3.34\n",
      "    -10.88           13.89\n",
      "    12.08           14.36\n",
      "    -55.08           13.72\n",
      "    7.73           12.62\n",
      "    66.84           14.33\n",
      "    14.29           14.33\n",
      "    17.62           14.25\n",
      "    -9.15           14.22\n",
      "    94.47           14.23\n",
      "    52.29           14.36\n",
      "    -8.13           14.14\n",
      "    21.28           14.39\n",
      "    18.83           14.18\n",
      "    8.35           14.32\n",
      "    9.45           14.30\n",
      "    7.49           14.19\n",
      "    19.73           14.37\n",
      "    31.36           14.16\n",
      "    -5.57           14.33\n",
      "    -5.10           14.20\n",
      "    -6.11           14.37\n",
      "    17.41           13.04\n",
      "    2414.81           14.38\n",
      "    1057.89           14.28\n",
      "    -0.51           14.39\n",
      "    -12.55           14.39\n",
      "    91.15           14.34\n",
      "    4.03           14.25\n",
      "    9.94           13.02\n",
      "    -13.25           10.15\n",
      "    -33.64           13.18\n",
      "    -11.27           14.34\n",
      "    -14.07           13.95\n",
      "    63.32           14.25\n",
      "    16.88           14.23\n",
      "    -26.55           14.31\n",
      "    -40.03           14.28\n",
      "    -51.69           -9.38\n",
      "    -30.90           14.25\n",
      "    -12.39           14.38\n",
      "    -28.00           14.24\n",
      "    -13.00           14.18\n",
      "    14.87           14.36\n",
      "    -0.65           14.24\n",
      "    -15.27           14.34\n",
      "    -58.29           13.56\n",
      "    -23.01           14.33\n",
      "    -34.61           14.35\n",
      "    -10.52           14.31\n",
      "    -8.02           14.33\n",
      "    -25.90           14.28\n",
      "    -20.67           14.37\n",
      "    -7.46           13.76\n",
      "    0.58           14.35\n",
      "    16.97           -8.07\n",
      "    17.62           -5.78\n",
      "    19.48           14.35\n",
      "    -0.57           14.36\n",
      "    -23.40           14.27\n",
      "    64.39           14.33\n",
      "    -40.01           13.93\n",
      "    -13.33           14.35\n",
      "    -9.78           13.35\n",
      "    -6.39           14.39\n",
      "    32.08           14.32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -26.81           14.40\n",
      "    2.45           13.56\n",
      "    11.78            8.17\n",
      "    5.70           14.35\n",
      "    -6.09           13.67\n",
      "    124.85           14.27\n",
      "    5.48           14.11\n",
      "    -33.55           14.11\n",
      "    -10.46           14.32\n",
      "    72.15           12.68\n",
      "    0.55           14.29\n",
      "    14.71           14.39\n",
      "    0.83           14.37\n",
      "    -11.17           14.28\n",
      "    -22.81           14.35\n",
      "    -31.71           14.36\n",
      "    27.08           14.42\n",
      "    40.89           14.34\n",
      "    0.25           14.36\n",
      "    40.85           14.03\n",
      "    -7.22            9.31\n",
      "    -29.44           14.25\n",
      "    17.25           14.27\n",
      "    -6.45           14.19\n",
      "    -32.84           14.27\n",
      "    2.78           10.60\n",
      "    -27.41           14.36\n",
      "    -15.00           14.36\n",
      "    -14.23           14.39\n",
      "    -16.48           13.31\n",
      "    -9.79           14.30\n",
      "    -1.34           14.32\n",
      "    -4.58           14.36\n",
      "    19.09           14.24\n",
      "    3.94           14.31\n",
      "    13.11           14.35\n",
      "    145.04           13.82\n",
      "    83.56           14.21\n",
      "    20.78           14.08\n",
      "    22.40           13.89\n",
      "    -0.37           14.32\n",
      "    -3.95           14.37\n",
      "    -3.74           14.20\n",
      "    -1.99           13.02\n",
      "    -5.91           14.33\n",
      "    -29.39           14.18\n",
      "    -1.30           14.15\n",
      "    -23.44           14.31\n",
      "    -6.77           14.38\n",
      "    -17.43           14.01\n",
      "    40.34           14.26\n",
      "    17.03           14.38\n",
      "    10.95           14.39\n",
      "    3.51           13.00\n",
      "    25.00           14.25\n",
      "    -8.11           14.35\n",
      "    -1.77           14.33\n",
      "    14.59           13.44\n",
      "    227.27           14.32\n",
      "    14.00           12.78\n",
      "    -1.85           14.30\n",
      "    -18.72           14.25\n",
      "    20.36           14.30\n",
      "    -13.13           14.31\n",
      "    -8.42           14.34\n",
      "    6.18           14.30\n",
      "    -19.36           14.19\n",
      "    10.52           13.62\n",
      "    5.36            8.53\n",
      "    -25.03           14.37\n",
      "    12.95           14.23\n",
      "    -12.06           -3.09\n",
      "    10.48           14.05\n",
      "    119.36           14.36\n",
      "    -18.77           14.29\n",
      "    -23.92           14.33\n",
      "    3.47           13.18\n",
      "    7.10           14.08\n",
      "    -28.71           14.36\n",
      "    4.96           14.26\n",
      "    30.91           14.18\n",
      "    2029.60           14.29\n",
      "    19.39           13.68\n",
      "    -24.91           14.38\n",
      "    3.19           14.39\n",
      "    -21.06           14.24\n",
      "    -5.75           13.56\n",
      "    29.25           14.06\n",
      "    26.80           14.24\n",
      "    -21.22           13.86\n",
      "    -1.13           12.29\n",
      "    19.00           14.10\n",
      "    -0.93           13.91\n",
      "    -39.55           14.10\n",
      "    8.43           14.33\n",
      "    13.25           14.39\n",
      "    -14.88           14.35\n",
      "    -18.60           14.40\n",
      "    -67.35           14.33\n",
      "    2.46           14.25\n",
      "    29.15           14.30\n",
      "    2.84           12.83\n",
      "    145.11           11.70\n",
      "    -53.09           14.39\n",
      "    10.38           12.85\n",
      "    -59.48           14.37\n",
      "    6.73           13.67\n",
      "    -23.69           14.30\n",
      "    112.57           14.32\n",
      "    1.89           14.26\n",
      "    84.36           14.36\n",
      "    42.42           14.34\n",
      "    30.85           14.29\n",
      "    10.65           14.23\n",
      "    55.92           14.23\n",
      "    9.62           14.40\n",
      "    1.46           12.58\n",
      "    3.84            6.69\n",
      "    19.85           13.86\n",
      "    34.56           14.24\n",
      "    -45.77           13.91\n",
      "    -14.66           13.94\n",
      "    6.21           14.37\n",
      "    -23.46           13.94\n",
      "    -15.27           14.21\n",
      "    83.48           14.40\n",
      "    3.27           14.39\n",
      "    -3.57           14.06\n",
      "    -4.92           14.20\n",
      "    -3.52           14.37\n",
      "    5.99           14.28\n",
      "    -8.24           14.33\n",
      "    13.04           14.30\n",
      "    4.25           14.18\n",
      "    -47.98           14.38\n",
      "    -1.07            7.05\n",
      "    11.50           14.35\n",
      "    -35.90           14.39\n",
      "    -2.12           13.31\n",
      "    -8.13           14.20\n",
      "    -23.69           14.31\n",
      "    -20.31           14.11\n",
      "    10.73           14.36\n",
      "    40.32           14.34\n",
      "    -29.96           11.67\n",
      "    43.21           13.64\n",
      "    11.92           14.30\n",
      "    -6.40           12.86\n",
      "    1.56           14.28\n",
      "    3.16           14.40\n",
      "    -5.11           14.07\n",
      "    -18.30           14.38\n",
      "    7.48           14.18\n",
      "    13.96           14.01\n",
      "    -22.52           13.79\n",
      "    -40.35           14.21\n",
      "    17.75           14.29\n",
      "    -10.00           14.21\n",
      "    -7.19           14.37\n",
      "    78.04           13.80\n",
      "    -46.83           14.32\n",
      "    13.78           13.54\n",
      "    6.68           13.82\n",
      "    1.33           14.26\n",
      "    72.27           14.29\n",
      "    12.73           14.33\n",
      "    -11.95           14.26\n",
      "    -7.67           14.34\n",
      "    -20.72           14.28\n",
      "    3.78          -16.75\n",
      "    1.16           14.30\n",
      "    -12.30           14.24\n",
      "    -20.63           14.29\n",
      "    5.82            6.61\n",
      "    3.48           14.39\n",
      "    8.80           14.39\n",
      "    -15.61           14.23\n",
      "    -2.99           14.33\n",
      "    27.06           14.23\n",
      "    3.01           14.37\n",
      "    -26.36           14.36\n",
      "    -5.97           12.58\n",
      "    -3.33           14.23\n",
      "    2.94           14.38\n",
      "    6.51           14.06\n",
      "    -1.88           14.02\n",
      "    -10.01           14.30\n",
      "    -0.60           14.36\n",
      "    -12.03           14.15\n",
      "    -1.34           13.97\n",
      "    14.08           10.19\n",
      "    17.43           12.46\n",
      "    17.80           14.24\n",
      "    -45.95           14.37\n",
      "    -30.84           13.52\n",
      "    -12.83           13.52\n",
      "    0.41           13.54\n",
      "    -10.53           14.30\n",
      "    -0.72           14.07\n",
      "    2.64           14.25\n",
      "    2.70           14.23\n",
      "    -5.46           14.28\n",
      "    -41.15           14.28\n",
      "    -14.73           14.30\n",
      "    24.15           14.32\n",
      "    -4.80           14.36\n",
      "    298.36           14.38\n",
      "    -31.90           14.12\n",
      "    -12.61           14.35\n",
      "    -28.92           14.15\n",
      "    -41.14           14.07\n",
      "    196.82           14.37\n",
      "    6.27           14.32\n",
      "    -19.44           13.98\n",
      "    26.67           14.38\n",
      "    -5.94           14.32\n",
      "    13.65           14.37\n",
      "    1.75           13.98\n",
      "    -0.85           14.35\n",
      "    55.31           14.32\n",
      "    -13.99           13.86\n",
      "    -4.37           14.39\n",
      "    -2.51           14.18\n",
      "    3.46           13.28\n",
      "    -42.37           14.36\n",
      "    9.19           14.34\n",
      "    7.92           14.33\n",
      "    3.24           14.20\n",
      "    9.27           14.24\n",
      "    3.10           14.37\n",
      "    1.11           14.07\n",
      "    -19.61           13.96\n",
      "    14.38           14.33\n",
      "    2.11           11.43\n",
      "    -73.08           14.11\n",
      "    11.17           14.32\n",
      "    416.83           14.38\n",
      "    -61.59           14.40\n",
      "    20.56           14.38\n",
      "    7.80           11.69\n",
      "    4.39           13.92\n",
      "    -42.64           14.12\n",
      "    1.35            6.45\n",
      "    -3.16           14.32\n",
      "    -14.24           14.01\n",
      "    92.27           14.37\n",
      "    -5.30           14.36\n",
      "    1.64           14.37\n",
      "    -7.93           12.59\n",
      "    -5.64           14.30\n",
      "    -5.98           14.28\n",
      "    0.78           14.39\n",
      "    27.34           14.39\n",
      "    4.18           14.01\n",
      "    14.23           14.11\n",
      "    15.90           14.38\n",
      "    16.57           14.30\n",
      "    -29.49           14.01\n",
      "    46.30           14.01\n",
      "    11.39           14.19\n",
      "    -40.00           14.24\n",
      "    90.59           14.37\n",
      "    2.30           14.28\n",
      "    -8.96           13.85\n",
      "    3.65           14.20\n",
      "    -22.58           14.32\n",
      "    -26.95           14.22\n",
      "    -27.56           14.36\n",
      "    -0.82           14.33\n",
      "    -19.15           14.37\n",
      "    -31.49           13.85\n",
      "    -9.78           14.34\n",
      "    -5.75           14.16\n",
      "    4.17           12.57\n",
      "    -14.85           12.39\n",
      "    -13.97           14.04\n",
      "    24.50           13.90\n",
      "    30.28           14.43\n",
      "    -11.36           14.38\n",
      "    13.19           14.29\n",
      "    9.45           14.34\n",
      "    -35.48           14.39\n",
      "    2.34           14.03\n",
      "    -3.82           14.38\n",
      "    16.31           13.13\n",
      "    1.45           13.73\n",
      "    -17.10           13.55\n",
      "    -13.41           14.22\n",
      "    72.14           14.38\n",
      "    -29.55           14.38\n",
      "    3.47           14.33\n",
      "    -28.02           14.31\n",
      "    27.27           14.04\n",
      "    -22.61           14.39\n",
      "    -7.56           14.13\n",
      "    -14.64           14.06\n",
      "    -16.52           14.32\n",
      "    -38.69           14.39\n",
      "    -17.07           14.39\n",
      "    30.45           14.27\n",
      "    -21.19           14.17\n",
      "    -3.40           14.19\n",
      "    30.71           14.17\n",
      "    39.76           14.19\n",
      "    -16.29           13.76\n",
      "    -0.93           14.38\n",
      "    -8.92           14.40\n",
      "    5.98           -0.60\n",
      "    -55.65           14.39\n",
      "    -27.67           14.25\n",
      "    -11.23           14.15\n",
      "    -30.65           14.41\n",
      "    -15.55           14.33\n",
      "    -31.84           14.18\n",
      "    12.94           14.30\n",
      "    -29.17           14.38\n",
      "    18.23           14.29\n",
      "    13.40           14.26\n",
      "    -17.25           14.10\n"
     ]
    }
   ],
   "source": [
    "print('Test values:    Predicted values:')\n",
    "for r,p in zip(true_y_test.flatten(),predicted_y_test.flatten()):\n",
    "    print(f'    {r:.2f}    {p:>12.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
