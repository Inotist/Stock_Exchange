{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este notebook y todos los que tienen un nombre similar a este son prácticamente iguales. Su contenido también es muy similar al del notebook \"IBM_MSE\", la principal diferencia es que en esta serie de notebooks, en lugar de utilizar una secuencia temporal diaria, utilizo una secuencia temporal en la que los días van de 2 en 2, de 3 en 3...\n",
    "\n",
    "El objetivo es tener diferentes modelos que puedan hacer predicciones en este orden (el de \"IBM_MSE\" hará las predicciones para hoy, el de 2 días las hará para mañana, el de 3 para pasado mañana, etc.)\n",
    "\n",
    "Veremos como según vamos aumentando el tamaño de los saltos en el tiempo, los modelos empiezan a ser cada vez más imprecisos. El objetivo no es conseguir predicciones exactas, ya que creo que se trata de una tarea imposible, sino que al final lo que busco con estos modelos es tener un conjunto de predicciones que me puedan, en cierto modo y de forma conjunta, \"asegurar\" que los valores van a seguir una cierta tendencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from joblib import load\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./datasets/IBM_daily.csv').sort_values(by='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>1. open</th>\n",
       "      <th>2. high</th>\n",
       "      <th>3. low</th>\n",
       "      <th>4. close</th>\n",
       "      <th>5. volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5217</th>\n",
       "      <td>1999-11-01</td>\n",
       "      <td>98.50</td>\n",
       "      <td>98.8100</td>\n",
       "      <td>96.37</td>\n",
       "      <td>96.75</td>\n",
       "      <td>9551800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5216</th>\n",
       "      <td>1999-11-02</td>\n",
       "      <td>96.75</td>\n",
       "      <td>96.8100</td>\n",
       "      <td>93.69</td>\n",
       "      <td>94.81</td>\n",
       "      <td>11105400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5215</th>\n",
       "      <td>1999-11-03</td>\n",
       "      <td>95.87</td>\n",
       "      <td>95.9400</td>\n",
       "      <td>93.50</td>\n",
       "      <td>94.37</td>\n",
       "      <td>10369100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5214</th>\n",
       "      <td>1999-11-04</td>\n",
       "      <td>94.44</td>\n",
       "      <td>94.4400</td>\n",
       "      <td>90.00</td>\n",
       "      <td>91.56</td>\n",
       "      <td>16697600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5213</th>\n",
       "      <td>1999-11-05</td>\n",
       "      <td>92.75</td>\n",
       "      <td>92.9400</td>\n",
       "      <td>90.19</td>\n",
       "      <td>90.25</td>\n",
       "      <td>13737600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-07-22</td>\n",
       "      <td>125.90</td>\n",
       "      <td>129.4700</td>\n",
       "      <td>125.80</td>\n",
       "      <td>128.67</td>\n",
       "      <td>8195366.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-07-23</td>\n",
       "      <td>129.10</td>\n",
       "      <td>129.3700</td>\n",
       "      <td>127.15</td>\n",
       "      <td>127.33</td>\n",
       "      <td>4220136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-07-24</td>\n",
       "      <td>126.48</td>\n",
       "      <td>127.6459</td>\n",
       "      <td>125.50</td>\n",
       "      <td>125.79</td>\n",
       "      <td>3531076.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-07-27</td>\n",
       "      <td>124.86</td>\n",
       "      <td>126.3200</td>\n",
       "      <td>124.71</td>\n",
       "      <td>126.21</td>\n",
       "      <td>3733547.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-28</td>\n",
       "      <td>125.82</td>\n",
       "      <td>126.3400</td>\n",
       "      <td>124.15</td>\n",
       "      <td>124.47</td>\n",
       "      <td>4157538.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5218 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  1. open   2. high  3. low  4. close   5. volume\n",
       "5217  1999-11-01    98.50   98.8100   96.37     96.75   9551800.0\n",
       "5216  1999-11-02    96.75   96.8100   93.69     94.81  11105400.0\n",
       "5215  1999-11-03    95.87   95.9400   93.50     94.37  10369100.0\n",
       "5214  1999-11-04    94.44   94.4400   90.00     91.56  16697600.0\n",
       "5213  1999-11-05    92.75   92.9400   90.19     90.25  13737600.0\n",
       "...          ...      ...       ...     ...       ...         ...\n",
       "4     2020-07-22   125.90  129.4700  125.80    128.67   8195366.0\n",
       "3     2020-07-23   129.10  129.3700  127.15    127.33   4220136.0\n",
       "2     2020-07-24   126.48  127.6459  125.50    125.79   3531076.0\n",
       "1     2020-07-27   124.86  126.3200  124.71    126.21   3733547.0\n",
       "0     2020-07-28   125.82  126.3400  124.15    124.47   4157538.0\n",
       "\n",
       "[5218 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1. open</th>\n",
       "      <th>2. high</th>\n",
       "      <th>3. low</th>\n",
       "      <th>4. close</th>\n",
       "      <th>5. volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5217</th>\n",
       "      <td>98.50</td>\n",
       "      <td>98.8100</td>\n",
       "      <td>96.37</td>\n",
       "      <td>96.75</td>\n",
       "      <td>9551800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5216</th>\n",
       "      <td>96.75</td>\n",
       "      <td>96.8100</td>\n",
       "      <td>93.69</td>\n",
       "      <td>94.81</td>\n",
       "      <td>11105400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5215</th>\n",
       "      <td>95.87</td>\n",
       "      <td>95.9400</td>\n",
       "      <td>93.50</td>\n",
       "      <td>94.37</td>\n",
       "      <td>10369100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5214</th>\n",
       "      <td>94.44</td>\n",
       "      <td>94.4400</td>\n",
       "      <td>90.00</td>\n",
       "      <td>91.56</td>\n",
       "      <td>16697600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5213</th>\n",
       "      <td>92.75</td>\n",
       "      <td>92.9400</td>\n",
       "      <td>90.19</td>\n",
       "      <td>90.25</td>\n",
       "      <td>13737600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>125.90</td>\n",
       "      <td>129.4700</td>\n",
       "      <td>125.80</td>\n",
       "      <td>128.67</td>\n",
       "      <td>8195366.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>129.10</td>\n",
       "      <td>129.3700</td>\n",
       "      <td>127.15</td>\n",
       "      <td>127.33</td>\n",
       "      <td>4220136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>126.48</td>\n",
       "      <td>127.6459</td>\n",
       "      <td>125.50</td>\n",
       "      <td>125.79</td>\n",
       "      <td>3531076.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>124.86</td>\n",
       "      <td>126.3200</td>\n",
       "      <td>124.71</td>\n",
       "      <td>126.21</td>\n",
       "      <td>3733547.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>125.82</td>\n",
       "      <td>126.3400</td>\n",
       "      <td>124.15</td>\n",
       "      <td>124.47</td>\n",
       "      <td>4157538.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5218 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      1. open   2. high  3. low  4. close   5. volume\n",
       "5217    98.50   98.8100   96.37     96.75   9551800.0\n",
       "5216    96.75   96.8100   93.69     94.81  11105400.0\n",
       "5215    95.87   95.9400   93.50     94.37  10369100.0\n",
       "5214    94.44   94.4400   90.00     91.56  16697600.0\n",
       "5213    92.75   92.9400   90.19     90.25  13737600.0\n",
       "...       ...       ...     ...       ...         ...\n",
       "4      125.90  129.4700  125.80    128.67   8195366.0\n",
       "3      129.10  129.3700  127.15    127.33   4220136.0\n",
       "2      126.48  127.6459  125.50    125.79   3531076.0\n",
       "1      124.86  126.3200  124.71    126.21   3733547.0\n",
       "0      125.82  126.3400  124.15    124.47   4157538.0\n",
       "\n",
       "[5218 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(columns='date')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequence for the LSTM network\n",
    "backlook = 92\n",
    "\n",
    "# Days to predict\n",
    "days = 4\n",
    "\n",
    "# Size of data split for testing\n",
    "train_size = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test split\n",
    "split = int(len(data) * train_size)\n",
    "\n",
    "train = data.to_numpy()[:split]\n",
    "test = data.to_numpy()[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load normalisers\n",
    "normaliser = load('./normalisers/x_normaliser.joblib')\n",
    "y_normaliser = load('./normalisers/y_normaliser.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise data\n",
    "train_norm = normaliser.transform(train)\n",
    "test_norm = normaliser.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now I get indexes for chunks from 4 in 4 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = []\n",
    "\n",
    "for i in range(days):\n",
    "    index.append(np.arange(i,len(train),days))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_index = []\n",
    "\n",
    "for i in range(len(index[0]) - backlook):\n",
    "    for e in range(days):\n",
    "        try: ordered_index.append(index[e][i:i+backlook])\n",
    "        except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalised train chunks\n",
    "X_train = np.array([train_norm[ix].copy() for ix in ordered_index])\n",
    "Y_train = np.array([train_norm[ordered_index[i+days][-1],3].copy() for i in range(len(ordered_index) - days)])\n",
    "Y_train = np.expand_dims(Y_train, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete those sequences that doesn't have a -th day in the results\n",
    "X_train = X_train[:Y_train.shape[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Same for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = []\n",
    "\n",
    "for i in range(days):\n",
    "    index.append(np.arange(i,len(test),days))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_index = []\n",
    "\n",
    "for i in range(len(index[0]) - backlook):\n",
    "    for e in range(days):\n",
    "        try: ordered_index.append(index[e][i:i+backlook])\n",
    "        except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalised test chunks\n",
    "X_test = np.array([test_norm[ix].copy() for ix in ordered_index])\n",
    "Y_test = np.array([test_norm[ordered_index[i+days][-1],3].copy() for i in range(len(ordered_index) - days)])\n",
    "Y_test = np.expand_dims(Y_test, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete those sequences that doesn't have a -th day in the results\n",
    "X_test = X_test[:Y_test.shape[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm(x, y, batch_size=512, epochs=24, **params):\n",
    "    \n",
    "    # List of parameters\n",
    "    if 'lstmsize' not in params: params['lstmsize'] = x.shape[1]\n",
    "    if 'density' not in params: params['density'] = int((params['lstmsize']//1.5)*2)\n",
    "    if 'activation' not in params: params['activation'] = 'relu'\n",
    "    if 'twice' not in params: params['twice'] = False\n",
    "    if 'optimizer' not in params: params['optimizer'] = 'adam'\n",
    "    if 'shuffle' not in params: params['shuffle'] = False\n",
    "    \n",
    "    # Model definition\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(params['lstmsize'], input_shape=x.shape[1:], return_sequences=params['twice']))\n",
    "    \n",
    "    if 'dropout' in params:\n",
    "        model.add(Dropout(params['dropout']))\n",
    "    \n",
    "    if params['twice']:\n",
    "        model.add(LSTM(params['lstmsize']))\n",
    "        \n",
    "        if 'dropout' in params:\n",
    "            model.add(Dropout(params['dropout']))\n",
    "            \n",
    "    model.add(Dense(params['density'], activation=params['activation']))\n",
    "    \n",
    "    if 'full_density' in params and params['full_density']:\n",
    "        density = params['density']//2\n",
    "        while density >= 12:\n",
    "            model.add(Dense(density, activation=params['activation']))\n",
    "            density //= 2\n",
    "            \n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    \n",
    "    model.compile(loss='mse', optimizer=params['optimizer'])\n",
    "    \n",
    "    if 'callbacks' in params:\n",
    "        callback = model.fit(x=x, y=y, validation_split=0.1, batch_size=batch_size, epochs=epochs, shuffle=params['shuffle'],\n",
    "                            callbacks=params['callbacks'])\n",
    "    else:\n",
    "        callback = model.fit(x=x, y=y, validation_split=0.1, batch_size=batch_size, epochs=epochs, shuffle=params['shuffle'])\n",
    "    \n",
    "    return [model, callback, params]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evolutive algorith to search for the most optimal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_genes(x, y, population_size, population=[]):\n",
    "    if population_size-len(population) < 0:\n",
    "        print('population size must be greater or equal than actual population')\n",
    "        return\n",
    "    \n",
    "    if len(population) > 0:\n",
    "        if len(population) < 3:\n",
    "            print('population should be empty or 3 at least')\n",
    "            return\n",
    "        \n",
    "        population[2] = breed_genes(x, y, population[0][2].copy())\n",
    "        population[1] = breed_genes(x, y, combine=(population[0][2], population[1][2]))\n",
    "        population = population[:3]\n",
    "    \n",
    "    for _ in range(population_size-len(population)):\n",
    "        subject = breed_genes(x, y)\n",
    "        population.append(subject)\n",
    "        \n",
    "    return population\n",
    "\n",
    "def breed_genes(x, y, genes={}, combine=None):\n",
    "    genes['x'] = x\n",
    "    genes['y'] = y\n",
    "    \n",
    "    if type(combine) is list or type(combine) is tuple:\n",
    "        genes['lstmsize'] = combine[np.random.randint(0,2)]['lstmsize']\n",
    "        genes['density'] = combine[np.random.randint(0,2)]['density']\n",
    "        genes['activation'] = combine[np.random.randint(0,2)]['activation']\n",
    "        genes['twice'] = combine[np.random.randint(0,2)]['twice']\n",
    "        genes['optimizer'] = combine[np.random.randint(0,2)]['optimizer']\n",
    "        genes['shuffle'] = combine[np.random.randint(0,2)]['shuffle']\n",
    "        \n",
    "        genes['dropout'] = combine[np.random.randint(0,2)].get('dropout')\n",
    "        if genes['dropout'] is None: del genes['dropout']\n",
    "        genes['full_density'] = combine[np.random.randint(0,2)].get('full_density')\n",
    "        if genes['full_density'] is None: del genes['full_density']\n",
    "            \n",
    "    else:\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['lstmsize'] = int((np.random.randint(x.shape[1],x.shape[1]*2)//2)*2)\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['density'] = int((np.random.randint(x.shape[1]//2,x.shape[1]*2.66)//2)*2)\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            activation = [\n",
    "                'relu',\n",
    "                'sigmoid',\n",
    "                'softplus',\n",
    "                'softsign',\n",
    "                'tanh',\n",
    "                'selu',\n",
    "                'elu',\n",
    "                'exponential'\n",
    "            ]\n",
    "            genes['activation'] = activation[np.random.randint(0,8)]\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['twice'] = True\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            optimizer = [\n",
    "                'sgd',\n",
    "                'rmsprop',\n",
    "                'adam',\n",
    "                'adadelta',\n",
    "                'adagrad',\n",
    "                'adamax',\n",
    "                'nadam'\n",
    "            ]\n",
    "            genes['optimizer'] = optimizer[np.random.randint(0,7)]\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['shuffle'] = True\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['dropout'] = np.random.randint(1,4)/10\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['full_density'] = True\n",
    "            \n",
    "    new_model = build_lstm(**genes)\n",
    "        \n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def breed_population(x, y, generations, population_size, population=[]):\n",
    "    \n",
    "    if generations > 1 and population_size < 3:\n",
    "        print('population size should be of a minimum of 3 for more than one generation')\n",
    "        return\n",
    "    \n",
    "    for g in range(generations):\n",
    "        print(f'\\nGENERATION {g}\\n')\n",
    "        population = set_genes(x, y, population_size, population)\n",
    "        population = sorted(population, key=lambda x: x[1].history['val_loss'][-1]+x[1].history['loss'][-1])\n",
    "        \n",
    "    return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GENERATION 0\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 1s 377us/step - loss: 0.1201 - val_loss: 0.0517\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 149us/step - loss: 0.0152 - val_loss: 0.0153\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 149us/step - loss: 0.0062 - val_loss: 0.0062\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 151us/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 152us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 153us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 153us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 153us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 152us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 150us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 151us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 150us/step - loss: 9.8636e-04 - val_loss: 9.6593e-04\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 150us/step - loss: 9.5174e-04 - val_loss: 9.2656e-04\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 152us/step - loss: 9.1356e-04 - val_loss: 9.0272e-04\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 149us/step - loss: 8.9223e-04 - val_loss: 9.7304e-04\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 150us/step - loss: 8.8853e-04 - val_loss: 9.9267e-04\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 154us/step - loss: 8.7639e-04 - val_loss: 8.5924e-04\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 158us/step - loss: 8.4083e-04 - val_loss: 8.3327e-04\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 155us/step - loss: 8.1367e-04 - val_loss: 8.5442e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 151us/step - loss: 7.9913e-04 - val_loss: 8.1092e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 153us/step - loss: 7.9179e-04 - val_loss: 8.3390e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 149us/step - loss: 8.0967e-04 - val_loss: 7.8265e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 150us/step - loss: 7.8067e-04 - val_loss: 7.9012e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 150us/step - loss: 7.6879e-04 - val_loss: 8.6612e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 2s 483us/step - loss: 0.1103 - val_loss: 0.0195\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 306us/step - loss: 0.0161 - val_loss: 0.0030\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 302us/step - loss: 0.0070 - val_loss: 0.0056\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 300us/step - loss: 0.0046 - val_loss: 0.0074\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 308us/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 307us/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 310us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 306us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 309us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 301us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 302us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 303us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 304us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 301us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 303us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 302us/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 302us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 301us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 300us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 305us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 307us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 302us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 305us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 301us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 2s 495us/step - loss: 0.0956 - val_loss: 0.0038\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 301us/step - loss: 0.0156 - val_loss: 0.0026\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 304us/step - loss: 0.0073 - val_loss: 0.0034\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 303us/step - loss: 0.0050 - val_loss: 0.0097\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 303us/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 301us/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 302us/step - loss: 0.0025 - val_loss: 0.0041\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 302us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 304us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 308us/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 302us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 301us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 302us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 302us/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 304us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 302us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 304us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 302us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 301us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 306us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 301us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 302us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 302us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 305us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 2s 543us/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 314us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 313us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 314us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 313us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 312us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 315us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 313us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 312us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 317us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 316us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 313us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 314us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 312us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 312us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 312us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 316us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 318us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 312us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 315us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 313us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 313us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 317us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 316us/step - loss: nan - val_loss: nan\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 2s 554us/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 315us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 314us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 314us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 313us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 314us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 313us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - ETA: 0s - loss: n - 1s 313us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 315us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 322us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 314us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 312us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 312us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 313us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 313us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 316us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 313us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 314us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 314us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 312us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 313us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 313us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 320us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 314us/step - loss: nan - val_loss: nan\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 2s 587us/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 315us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 314us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 316us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 313us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 318us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 317us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 319us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 316us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 320us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 318us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 314us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 314us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 319us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 316us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 314us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 317us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 315us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 316us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 315us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 316us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 315us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 318us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 316us/step - loss: nan - val_loss: nan\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 3s 744us/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 462us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 464us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 462us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 460us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 466us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 461us/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 464us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 462us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 463us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 462us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 460us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 462us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 461us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 465us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 461us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 462us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 462us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 461us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 461us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 460us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 462us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 460us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 464us/step - loss: nan - val_loss: nan\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 3s 770us/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 463us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 460us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 462us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 462us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 461us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 463us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 463us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 462us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 463us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 463us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 463us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 460us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 462us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 463us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 466us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 463us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 463us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 464us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 463us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 464us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 463us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 462us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 462us/step - loss: nan - val_loss: nan\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 3s 793us/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 463us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 463us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 462us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 462us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 467us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 463us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 464us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 465us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 463us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 462us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 461us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 463us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 463us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 462us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 467us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 466us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 462us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 463us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 464us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 462us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 462us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 465us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 463us/step - loss: nan - val_loss: nan\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 3s 805us/step - loss: 0.5590 - val_loss: 0.0359\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 464us/step - loss: 0.0725 - val_loss: 0.0379\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 463us/step - loss: 0.0623 - val_loss: 0.0201\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 463us/step - loss: 0.0483 - val_loss: 0.0200\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 463us/step - loss: 0.0260 - val_loss: 0.0041\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 465us/step - loss: 0.0284 - val_loss: 0.0434\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 464us/step - loss: 0.0303 - val_loss: 0.0142\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 465us/step - loss: 0.0218 - val_loss: 0.0084\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 462us/step - loss: 0.0270 - val_loss: 0.0169\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 466us/step - loss: 0.0275 - val_loss: 0.0075\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 462us/step - loss: 0.0191 - val_loss: 0.0075\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 464us/step - loss: 0.0160 - val_loss: 0.0076\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 464us/step - loss: 0.0176 - val_loss: 0.0118\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 462us/step - loss: 0.0274 - val_loss: 0.0127\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 461us/step - loss: 0.0227 - val_loss: 0.0055\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 463us/step - loss: 0.0181 - val_loss: 0.0044\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 464us/step - loss: 0.0152 - val_loss: 0.0051\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 462us/step - loss: 0.0164 - val_loss: 0.0069\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 464us/step - loss: 0.0203 - val_loss: 0.0051\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 463us/step - loss: 0.0158 - val_loss: 0.0060\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 463us/step - loss: 0.0160 - val_loss: 0.0046\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 464us/step - loss: 0.0133 - val_loss: 0.0044\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 463us/step - loss: 0.0170 - val_loss: 0.0109\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 463us/step - loss: 0.0233 - val_loss: 0.0058\n",
      "\n",
      "GENERATION 1\n",
      "\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 2s 640us/step - loss: 0.1126 - val_loss: 0.1126\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 301us/step - loss: 0.0585 - val_loss: 0.0143\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 300us/step - loss: 0.0197 - val_loss: 0.0500\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 302us/step - loss: 0.0110 - val_loss: 0.0132\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 305us/step - loss: 0.0060 - val_loss: 0.0035\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 302us/step - loss: 0.0047 - val_loss: 0.0033\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 303us/step - loss: 0.0036 - val_loss: 0.0051\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 303us/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 303us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 303us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 302us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 303us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 304us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 302us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 301us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 302us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 301us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 302us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - ETA: 0s - loss: 0.001 - 1s 301us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 301us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 303us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 304us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 306us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 302us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 3s 654us/step - loss: 0.1498 - val_loss: 0.0668\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 303us/step - loss: 0.0279 - val_loss: 0.0291\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 308us/step - loss: 0.0135 - val_loss: 0.0162\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 305us/step - loss: 0.0065 - val_loss: 0.0048\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 302us/step - loss: 0.0037 - val_loss: 0.0058\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 302us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 302us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 302us/step - loss: 0.0025 - val_loss: 0.0038\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 302us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 303us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 305us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 307us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 303us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 302us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 302us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 303us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 304us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 303us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 304us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 303us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 304us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 302us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 303us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 303us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 4s 912us/step - loss: 0.0633 - val_loss: 0.0152\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 525us/step - loss: 0.0104 - val_loss: 0.0026\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 526us/step - loss: 0.0064 - val_loss: 0.0056\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 528us/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 529us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 525us/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 527us/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 525us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 528us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 528us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 525us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 526us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 525us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 529us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 532us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 523us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 525us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 526us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 529us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 20/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 2s 529us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 525us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 530us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 525us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 529us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 4s 919us/step - loss: 0.0561 - val_loss: 0.0178\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 531us/step - loss: 0.0136 - val_loss: 0.0074\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 531us/step - loss: 0.0063 - val_loss: 0.0108\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 536us/step - loss: 0.0045 - val_loss: 0.0021\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 529us/step - loss: 0.0030 - val_loss: 0.0023\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 530us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 529us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 530us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 530us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 534us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 529us/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 532us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 533us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 530us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 532us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 529us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 530us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 534us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 529us/step - loss: 0.0014 - val_loss: 0.0022\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 530us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 531us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 529us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 531us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 532us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 4s 989us/step - loss: 0.0350 - val_loss: 0.0028\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 554us/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 555us/step - loss: 0.0041 - val_loss: 0.0085\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 553us/step - loss: 0.0069 - val_loss: 0.0170\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 553us/step - loss: 0.0067 - val_loss: 0.0079\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 561us/step - loss: 0.0052 - val_loss: 0.0122\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 554us/step - loss: 0.0064 - val_loss: 0.0137\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 557us/step - loss: 0.0065 - val_loss: 0.0083\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 561us/step - loss: 0.0045 - val_loss: 0.0074\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 557us/step - loss: 0.0042 - val_loss: 0.0102\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 556us/step - loss: 0.0067 - val_loss: 0.0110\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 557us/step - loss: 0.0066 - val_loss: 0.0119\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 557us/step - loss: 0.0056 - val_loss: 0.0060\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 557us/step - loss: 0.0036 - val_loss: 0.0051\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 554us/step - loss: 0.0032 - val_loss: 0.0047\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 556us/step - loss: 0.0033 - val_loss: 0.0068\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 558us/step - loss: 0.0063 - val_loss: 0.0157\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 555us/step - loss: 0.0081 - val_loss: 0.0095\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 554us/step - loss: 0.0048 - val_loss: 0.0082\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 556us/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 556us/step - loss: 0.0034 - val_loss: 0.0077\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 556us/step - loss: 0.0040 - val_loss: 0.0087\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 557us/step - loss: 0.0041 - val_loss: 0.0086\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 557us/step - loss: 0.0051 - val_loss: 0.0098\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 4s 1ms/step - loss: 0.0578 - val_loss: 0.0032\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 558us/step - loss: 0.0071 - val_loss: 0.0087\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 558us/step - loss: 0.0063 - val_loss: 0.0066\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 558us/step - loss: 0.0057 - val_loss: 0.0112\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 556us/step - loss: 0.0088 - val_loss: 0.0129\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 556us/step - loss: 0.0064 - val_loss: 0.0062\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 557us/step - loss: 0.0053 - val_loss: 0.0097\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 559us/step - loss: 0.0072 - val_loss: 0.0118\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 557us/step - loss: 0.0053 - val_loss: 0.0077\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 556us/step - loss: 0.0073 - val_loss: 0.0112\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 557us/step - loss: 0.0059 - val_loss: 0.0103\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 558us/step - loss: 0.0046 - val_loss: 0.0054\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 556us/step - loss: 0.0050 - val_loss: 0.0129\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 556us/step - loss: 0.0066 - val_loss: 0.0102\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 557us/step - loss: 0.0047 - val_loss: 0.0086\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 555us/step - loss: 0.0049 - val_loss: 0.0068\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 559us/step - loss: 0.0043 - val_loss: 0.0081\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 556us/step - loss: 0.0043 - val_loss: 0.0073\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 557us/step - loss: 0.0032 - val_loss: 0.0074\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 555us/step - loss: 0.0041 - val_loss: 0.0109\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 556us/step - loss: 0.0058 - val_loss: 0.0132\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 558us/step - loss: 0.0049 - val_loss: 0.0061\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 558us/step - loss: 0.0028 - val_loss: 0.0044\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 555us/step - loss: 0.0026 - val_loss: 0.0067\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 4s 1ms/step - loss: 0.1255 - val_loss: 0.0054\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 558us/step - loss: 0.0218 - val_loss: 0.0155\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 556us/step - loss: 0.0178 - val_loss: 0.0232\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 557us/step - loss: 0.0147 - val_loss: 0.0108\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 557us/step - loss: 0.0098 - val_loss: 0.0142\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 557us/step - loss: 0.0101 - val_loss: 0.0082\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 561us/step - loss: 0.0081 - val_loss: 0.0091\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 557us/step - loss: 0.0072 - val_loss: 0.0071\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 560us/step - loss: 0.0077 - val_loss: 0.0065\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 558us/step - loss: 0.0069 - val_loss: 0.0094\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 556us/step - loss: 0.0084 - val_loss: 0.0060\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 555us/step - loss: 0.0065 - val_loss: 0.0051\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 558us/step - loss: 0.0057 - val_loss: 0.0066\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 555us/step - loss: 0.0048 - val_loss: 0.0054\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 558us/step - loss: 0.0074 - val_loss: 0.0120\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 559us/step - loss: 0.0070 - val_loss: 0.0068\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 556us/step - loss: 0.0055 - val_loss: 0.0086\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 558us/step - loss: 0.0078 - val_loss: 0.0060\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 557us/step - loss: 0.0058 - val_loss: 0.0087\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 557us/step - loss: 0.0065 - val_loss: 0.0063\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 556us/step - loss: 0.0046 - val_loss: 0.0051\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 560us/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 559us/step - loss: 0.0046 - val_loss: 0.0032\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 557us/step - loss: 0.0049 - val_loss: 0.0053\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 4s 1ms/step - loss: 0.0653 - val_loss: 0.0113\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 555us/step - loss: 0.0076 - val_loss: 0.0038\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 557us/step - loss: 0.0042 - val_loss: 0.0026\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 556us/step - loss: 0.0034 - val_loss: 0.0026\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 556us/step - loss: 0.0040 - val_loss: 0.0066\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 557us/step - loss: 0.0053 - val_loss: 0.0040\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 555us/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 556us/step - loss: 0.0073 - val_loss: 0.0045\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 556us/step - loss: 0.0058 - val_loss: 0.0069\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 558us/step - loss: 0.0066 - val_loss: 0.0039\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 559us/step - loss: 0.0051 - val_loss: 0.0037\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 560us/step - loss: 0.0053 - val_loss: 0.0067\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 561us/step - loss: 0.0055 - val_loss: 0.0043\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 558us/step - loss: 0.0038 - val_loss: 0.0025\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 555us/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 554us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 554us/step - loss: 0.0049 - val_loss: 0.0060\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 559us/step - loss: 0.0057 - val_loss: 0.0057\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 559us/step - loss: 0.0045 - val_loss: 0.0030\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 554us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 558us/step - loss: 0.0049 - val_loss: 0.0071\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 558us/step - loss: 0.0055 - val_loss: 0.0039\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 554us/step - loss: 0.0050 - val_loss: 0.0029\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 556us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 4s 1ms/step - loss: 0.1033 - val_loss: 0.0031\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 481us/step - loss: 0.0067 - val_loss: 0.0060\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 484us/step - loss: 0.0209 - val_loss: 0.0307\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 482us/step - loss: 0.0160 - val_loss: 0.0092\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 481us/step - loss: 0.0103 - val_loss: 0.0158\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 483us/step - loss: 0.0111 - val_loss: 0.0110\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 484us/step - loss: 0.0075 - val_loss: 0.0060\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 481us/step - loss: 0.0063 - val_loss: 0.0073\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 481us/step - loss: 0.0063 - val_loss: 0.0041\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 482us/step - loss: 0.0053 - val_loss: 0.0054\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 481us/step - loss: 0.0071 - val_loss: 0.0063\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 482us/step - loss: 0.0061 - val_loss: 0.0052\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 486us/step - loss: 0.0051 - val_loss: 0.0059\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 483us/step - loss: 0.0056 - val_loss: 0.0105\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 483us/step - loss: 0.0073 - val_loss: 0.0039\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 484us/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 482us/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 481us/step - loss: 0.0075 - val_loss: 0.0054\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 482us/step - loss: 0.0053 - val_loss: 0.0048\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 483us/step - loss: 0.0042 - val_loss: 0.0030\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 483us/step - loss: 0.0037 - val_loss: 0.0033\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 481us/step - loss: 0.0050 - val_loss: 0.0091\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 483us/step - loss: 0.0069 - val_loss: 0.0090\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 488us/step - loss: 0.0060 - val_loss: 0.0052\n",
      "\n",
      "GENERATION 2\n",
      "\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 2s 605us/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 152us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 152us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 151us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 151us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 154us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 156us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 153us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 152us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 152us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 152us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 153us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 153us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 152us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 153us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 152us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 155us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 154us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 151us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 153us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 153us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 152us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 152us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 152us/step - loss: nan - val_loss: nan\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 4s 1ms/step - loss: 0.1225 - val_loss: 0.0125\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 527us/step - loss: 0.0122 - val_loss: 0.0074\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 530us/step - loss: 0.0050 - val_loss: 0.0066\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 527us/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 529us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 527us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 532us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 526us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 526us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 526us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 532us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 527us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 526us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 527us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 526us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 528us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 529us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 528us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 529us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 526us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 529us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 529us/step - loss: 0.0013 - val_loss: 0.0026\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 525us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 531us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 4s 1ms/step - loss: 0.1392 - val_loss: 0.0077\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 528us/step - loss: 0.0177 - val_loss: 0.0057\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 528us/step - loss: 0.0058 - val_loss: 0.0056\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 528us/step - loss: 0.0030 - val_loss: 0.0043\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 530us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 528us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 531us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 528us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 532us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 530us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 528us/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 527us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 530us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 528us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 546us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 524us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 526us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 525us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 523us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 524us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 524us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 523us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 528us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 531us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 4s 1ms/step - loss: 0.6454 - val_loss: 0.0046\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 529us/step - loss: 0.0091 - val_loss: 0.0131\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 526us/step - loss: 0.0087 - val_loss: 0.0131\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 527us/step - loss: 0.0099 - val_loss: 0.0195\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 525us/step - loss: 0.0123 - val_loss: 0.0206\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 526us/step - loss: 0.0137 - val_loss: 0.0306\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 523us/step - loss: 0.0142 - val_loss: 0.0292\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 526us/step - loss: 0.0168 - val_loss: 0.0172\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 524us/step - loss: 0.0152 - val_loss: 0.0247\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 526us/step - loss: 0.0122 - val_loss: 0.0302\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 529us/step - loss: 0.0219 - val_loss: 0.0120\n",
      "Epoch 12/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 2s 528us/step - loss: 0.0090 - val_loss: 0.0117\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 522us/step - loss: 0.0110 - val_loss: 0.0185\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 528us/step - loss: 0.0089 - val_loss: 0.0231\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 525us/step - loss: 0.0129 - val_loss: 0.0150\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 522us/step - loss: 0.0081 - val_loss: 0.0151\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 524us/step - loss: 0.0122 - val_loss: 0.0290\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 526us/step - loss: 0.0111 - val_loss: 0.0103\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 525us/step - loss: 0.0064 - val_loss: 0.0197\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 528us/step - loss: 0.0080 - val_loss: 0.0128\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 528us/step - loss: 0.0079 - val_loss: 0.0213\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 525us/step - loss: 0.0083 - val_loss: 0.0085\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 527us/step - loss: 0.0060 - val_loss: 0.0220\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 527us/step - loss: 0.0093 - val_loss: 0.0084\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 4s 989us/step - loss: 0.1409 - val_loss: 0.1271\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 396us/step - loss: 0.0212 - val_loss: 0.0201\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 394us/step - loss: 0.0107 - val_loss: 0.0194\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 392us/step - loss: 0.0126 - val_loss: 0.0132\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 391us/step - loss: 0.0117 - val_loss: 0.0185\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 392us/step - loss: 0.0140 - val_loss: 0.0240\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 393us/step - loss: 0.0120 - val_loss: 0.0221\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 391us/step - loss: 0.0107 - val_loss: 0.0268\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 392us/step - loss: 0.0124 - val_loss: 0.0204\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 395us/step - loss: 0.0094 - val_loss: 0.0134\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 393us/step - loss: 0.0102 - val_loss: 0.0155\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 392us/step - loss: 0.0080 - val_loss: 0.0190\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 393us/step - loss: 0.0101 - val_loss: 0.0120\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 392us/step - loss: 0.0083 - val_loss: 0.0137\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 393us/step - loss: 0.0066 - val_loss: 0.0139\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 392us/step - loss: 0.0083 - val_loss: 0.0106\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 393us/step - loss: 0.0067 - val_loss: 0.0196\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 396us/step - loss: 0.0067 - val_loss: 0.0154\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 394us/step - loss: 0.0070 - val_loss: 0.0146\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 393us/step - loss: 0.0055 - val_loss: 0.0144\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 398us/step - loss: 0.0066 - val_loss: 0.0144\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 396us/step - loss: 0.0065 - val_loss: 0.0111\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 393us/step - loss: 0.0056 - val_loss: 0.0203\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 393us/step - loss: 0.0059 - val_loss: 0.0081\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 4s 995us/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 392us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 397us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 393us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 392us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 392us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 391us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 392us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 395us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 393us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 391us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 391us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 393us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 394us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 392us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 392us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 391us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 393us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 392us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 392us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 393us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 390us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 392us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 394us/step - loss: nan - val_loss: nan\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 4s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 378us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 378us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 381us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 379us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 383us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 379us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 378us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 377us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 379us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 380us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 380us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 379us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 379us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 381us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 380us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 384us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 379us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 380us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 379us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 383us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 379us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 380us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 378us/step - loss: nan - val_loss: nan\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 4s 1ms/step - loss: 0.8161 - val_loss: 0.0177\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 373us/step - loss: 0.0473 - val_loss: 0.0067\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 372us/step - loss: 0.0243 - val_loss: 0.0023\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 374us/step - loss: 0.0098 - val_loss: 0.0078\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 373us/step - loss: 0.0069 - val_loss: 0.0023\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 372us/step - loss: 0.0070 - val_loss: 0.0020\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 373us/step - loss: 0.0056 - val_loss: 0.0041\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 374us/step - loss: 0.0054 - val_loss: 0.0025\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 374us/step - loss: 0.0052 - val_loss: 0.0024\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 378us/step - loss: 0.0052 - val_loss: 0.0030\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 373us/step - loss: 0.0051 - val_loss: 0.0027\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 377us/step - loss: 0.0050 - val_loss: 0.0024\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 373us/step - loss: 0.0050 - val_loss: 0.0025\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 373us/step - loss: 0.0046 - val_loss: 0.0025\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 375us/step - loss: 0.0046 - val_loss: 0.0024\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 374us/step - loss: 0.0047 - val_loss: 0.0023\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 374us/step - loss: 0.0047 - val_loss: 0.0023\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 373us/step - loss: 0.0044 - val_loss: 0.0023\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 375us/step - loss: 0.0043 - val_loss: 0.0021\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 373us/step - loss: 0.0043 - val_loss: 0.0021\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 377us/step - loss: 0.0044 - val_loss: 0.0021\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 373us/step - loss: 0.0042 - val_loss: 0.0019\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 374us/step - loss: 0.0042 - val_loss: 0.0020\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 376us/step - loss: 0.0041 - val_loss: 0.0019\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 4s 1ms/step - loss: 1.4210 - val_loss: 0.1139\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 369us/step - loss: 0.0745 - val_loss: 0.0693\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 374us/step - loss: 0.0248 - val_loss: 0.0315\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 375us/step - loss: 0.0142 - val_loss: 0.0033\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 370us/step - loss: 0.0108 - val_loss: 0.0055\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 372us/step - loss: 0.0085 - val_loss: 0.0032\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 370us/step - loss: 0.0070 - val_loss: 0.0022\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 374us/step - loss: 0.0064 - val_loss: 0.0033\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 372us/step - loss: 0.0062 - val_loss: 0.0022\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 369us/step - loss: 0.0060 - val_loss: 0.0024\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 368us/step - loss: 0.0058 - val_loss: 0.0025\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 370us/step - loss: 0.0054 - val_loss: 0.0022\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 371us/step - loss: 0.0054 - val_loss: 0.0023\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 372us/step - loss: 0.0055 - val_loss: 0.0021\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 372us/step - loss: 0.0052 - val_loss: 0.0022\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 380us/step - loss: 0.0053 - val_loss: 0.0021\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 371us/step - loss: 0.0048 - val_loss: 0.0021\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 369us/step - loss: 0.0049 - val_loss: 0.0021\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 371us/step - loss: 0.0048 - val_loss: 0.0021\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 372us/step - loss: 0.0048 - val_loss: 0.0021\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 372us/step - loss: 0.0046 - val_loss: 0.0021\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 370us/step - loss: 0.0047 - val_loss: 0.0021\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 369us/step - loss: 0.0045 - val_loss: 0.0021\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 372us/step - loss: 0.0045 - val_loss: 0.0021\n",
      "\n",
      "GENERATION 3\n",
      "\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 3s 807us/step - loss: 0.1352 - val_loss: 0.0632\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 152us/step - loss: 0.0209 - val_loss: 0.0199\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 155us/step - loss: 0.0081 - val_loss: 0.0061\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 154us/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 153us/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 152us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 153us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 153us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 154us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 154us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 154us/step - loss: 9.7959e-04 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 154us/step - loss: 9.3984e-04 - val_loss: 9.5152e-04\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 153us/step - loss: 8.9455e-04 - val_loss: 9.0882e-04\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 153us/step - loss: 8.6246e-04 - val_loss: 8.9718e-04\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 153us/step - loss: 8.3863e-04 - val_loss: 8.2535e-04\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 158us/step - loss: 8.2320e-04 - val_loss: 8.5878e-04\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 157us/step - loss: 8.0212e-04 - val_loss: 8.0483e-04\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 154us/step - loss: 7.8326e-04 - val_loss: 8.4999e-04\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 153us/step - loss: 7.8584e-04 - val_loss: 7.7911e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 153us/step - loss: 7.6707e-04 - val_loss: 7.7854e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 153us/step - loss: 7.5408e-04 - val_loss: 7.6184e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 154us/step - loss: 7.5415e-04 - val_loss: 8.5289e-04\n",
      "Epoch 23/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 1s 157us/step - loss: 7.6293e-04 - val_loss: 7.6668e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 153us/step - loss: 7.4560e-04 - val_loss: 8.8206e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 3s 816us/step - loss: 0.0823 - val_loss: 0.0113\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 153us/step - loss: 0.0094 - val_loss: 0.0023\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 156us/step - loss: 0.0035 - val_loss: 0.0014\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 156us/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 154us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 152us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 156us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 158us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 153us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 153us/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 153us/step - loss: 9.5468e-04 - val_loss: 0.0010\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 154us/step - loss: 9.1258e-04 - val_loss: 9.0715e-04\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 153us/step - loss: 8.5920e-04 - val_loss: 8.6471e-04\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 154us/step - loss: 8.1668e-04 - val_loss: 8.1544e-04\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 153us/step - loss: 7.9723e-04 - val_loss: 7.8705e-04\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 152us/step - loss: 7.7774e-04 - val_loss: 8.1483e-04\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 153us/step - loss: 7.5647e-04 - val_loss: 7.4985e-04\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 153us/step - loss: 7.3295e-04 - val_loss: 7.4210e-04\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 154us/step - loss: 7.2927e-04 - val_loss: 7.3462e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 154us/step - loss: 7.2478e-04 - val_loss: 7.3190e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 153us/step - loss: 7.1504e-04 - val_loss: 7.1874e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 154us/step - loss: 7.0544e-04 - val_loss: 7.1399e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 154us/step - loss: 6.9920e-04 - val_loss: 7.1409e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 155us/step - loss: 7.0834e-04 - val_loss: 7.1701e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 4s 1ms/step - loss: 0.0864 - val_loss: 0.0621\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 316us/step - loss: 0.0696 - val_loss: 0.0445\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 316us/step - loss: 0.0681 - val_loss: 0.0392\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 319us/step - loss: 0.0679 - val_loss: 0.0375\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 318us/step - loss: 0.0679 - val_loss: 0.0364\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 315us/step - loss: 0.0679 - val_loss: 0.0366\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 316us/step - loss: 0.0679 - val_loss: 0.0369\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 319us/step - loss: 0.0679 - val_loss: 0.0359\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 317us/step - loss: 0.0679 - val_loss: 0.0365\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 315us/step - loss: 0.0679 - val_loss: 0.0371\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 315us/step - loss: 0.0679 - val_loss: 0.0371\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 319us/step - loss: 0.0679 - val_loss: 0.0369\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 315us/step - loss: 0.0679 - val_loss: 0.0369\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 315us/step - loss: 0.0679 - val_loss: 0.0366\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 319us/step - loss: 0.0679 - val_loss: 0.0373\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 316us/step - loss: 0.0679 - val_loss: 0.0373\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 315us/step - loss: 0.0679 - val_loss: 0.0370\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 315us/step - loss: 0.0679 - val_loss: 0.0365\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 315us/step - loss: 0.0679 - val_loss: 0.0353\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 315us/step - loss: 0.0679 - val_loss: 0.0361\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 317us/step - loss: 0.0679 - val_loss: 0.0360\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 317us/step - loss: 0.0679 - val_loss: 0.0369\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 314us/step - loss: 0.0679 - val_loss: 0.0369\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 317us/step - loss: 0.0679 - val_loss: 0.0367\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 4s 1ms/step - loss: 0.7747 - val_loss: 0.2803\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 319us/step - loss: 0.1198 - val_loss: 0.0802\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 317us/step - loss: 0.0718 - val_loss: 0.0468\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 318us/step - loss: 0.0681 - val_loss: 0.0389\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 318us/step - loss: 0.0679 - val_loss: 0.0373\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 316us/step - loss: 0.0678 - val_loss: 0.0363\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 321us/step - loss: 0.0678 - val_loss: 0.0359\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 321us/step - loss: 0.0678 - val_loss: 0.0354\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 317us/step - loss: 0.0678 - val_loss: 0.0364\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 318us/step - loss: 0.0679 - val_loss: 0.0360\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 320us/step - loss: 0.0678 - val_loss: 0.0361\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 318us/step - loss: 0.0678 - val_loss: 0.0365\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 318us/step - loss: 0.0678 - val_loss: 0.0367\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 317us/step - loss: 0.0678 - val_loss: 0.0373\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 318us/step - loss: 0.0679 - val_loss: 0.0376\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 316us/step - loss: 0.0679 - val_loss: 0.0373\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 318us/step - loss: 0.0679 - val_loss: 0.0373\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 317us/step - loss: 0.0679 - val_loss: 0.0362\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 317us/step - loss: 0.0678 - val_loss: 0.0363\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 321us/step - loss: 0.0678 - val_loss: 0.0371\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 321us/step - loss: 0.0678 - val_loss: 0.0374\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 317us/step - loss: 0.0678 - val_loss: 0.0361\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 319us/step - loss: 0.0678 - val_loss: 0.0355\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 317us/step - loss: 0.0678 - val_loss: 0.0369\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 4s 1ms/step - loss: 0.2447 - val_loss: 0.0048\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 316us/step - loss: 0.0783 - val_loss: 0.0236\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 320us/step - loss: 0.0684 - val_loss: 0.0344\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 316us/step - loss: 0.0678 - val_loss: 0.0364\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 316us/step - loss: 0.0678 - val_loss: 0.0371\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 317us/step - loss: 0.0677 - val_loss: 0.0368\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 315us/step - loss: 0.0678 - val_loss: 0.0370\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 314us/step - loss: 0.0678 - val_loss: 0.0366\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 318us/step - loss: 0.0678 - val_loss: 0.0372\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 315us/step - loss: 0.0678 - val_loss: 0.0364\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 318us/step - loss: 0.0678 - val_loss: 0.0362\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 319us/step - loss: 0.0678 - val_loss: 0.0354\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 319us/step - loss: 0.0678 - val_loss: 0.0359\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 319us/step - loss: 0.0678 - val_loss: 0.0354\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 318us/step - loss: 0.0678 - val_loss: 0.0362\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 321us/step - loss: 0.0678 - val_loss: 0.0364\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 316us/step - loss: 0.0678 - val_loss: 0.0373\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 316us/step - loss: 0.0678 - val_loss: 0.0370\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 317us/step - loss: 0.0678 - val_loss: 0.0376\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 320us/step - loss: 0.0677 - val_loss: 0.0370\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 318us/step - loss: 0.0678 - val_loss: 0.0349\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 317us/step - loss: 0.0678 - val_loss: 0.0372\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 316us/step - loss: 0.0678 - val_loss: 0.0365\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - ETA: 0s - loss: 0.068 - 1s 316us/step - loss: 0.0677 - val_loss: 0.0356\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 4s 1ms/step - loss: 0.1663 - val_loss: 0.1441\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 316us/step - loss: 0.0897 - val_loss: 0.0776\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 315us/step - loss: 0.0726 - val_loss: 0.0541\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 317us/step - loss: 0.0689 - val_loss: 0.0446\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 316us/step - loss: 0.0680 - val_loss: 0.0396\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 316us/step - loss: 0.0678 - val_loss: 0.0375\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 315us/step - loss: 0.0678 - val_loss: 0.0373\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 316us/step - loss: 0.0678 - val_loss: 0.0367\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 315us/step - loss: 0.0678 - val_loss: 0.0366\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 315us/step - loss: 0.0678 - val_loss: 0.0364\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 319us/step - loss: 0.0678 - val_loss: 0.0362\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 315us/step - loss: 0.0678 - val_loss: 0.0366\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 315us/step - loss: 0.0678 - val_loss: 0.0361\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 319us/step - loss: 0.0678 - val_loss: 0.0361\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 317us/step - loss: 0.0678 - val_loss: 0.0366\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 315us/step - loss: 0.0678 - val_loss: 0.0367\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 317us/step - loss: 0.0678 - val_loss: 0.0367\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 314us/step - loss: 0.0678 - val_loss: 0.0365\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 317us/step - loss: 0.0678 - val_loss: 0.0365\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 316us/step - loss: 0.0678 - val_loss: 0.0369\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 314us/step - loss: 0.0678 - val_loss: 0.0374\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 314us/step - loss: 0.0678 - val_loss: 0.0369\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 315us/step - loss: 0.0678 - val_loss: 0.0363\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 318us/step - loss: 0.0678 - val_loss: 0.0359\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 5s 1ms/step - loss: 0.0860 - val_loss: 0.0367\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 410us/step - loss: 0.0643 - val_loss: 0.0125\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 411us/step - loss: 0.0577 - val_loss: 0.0140\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 411us/step - loss: 0.0449 - val_loss: 0.0103\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 413us/step - loss: 0.0629 - val_loss: 0.0352\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 415us/step - loss: 0.0675 - val_loss: 0.0283\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 411us/step - loss: 0.0675 - val_loss: 0.0218\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 410us/step - loss: 0.0661 - val_loss: 0.0498\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 411us/step - loss: 0.0644 - val_loss: 0.0919\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 409us/step - loss: 0.0632 - val_loss: 0.0160\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 411us/step - loss: 0.0358 - val_loss: 0.0042\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 413us/step - loss: 0.0160 - val_loss: 0.1184\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 409us/step - loss: 0.0205 - val_loss: 0.0094\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 410us/step - loss: 0.0123 - val_loss: 0.0136\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 412us/step - loss: 0.0107 - val_loss: 0.0148\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 411us/step - loss: 0.0103 - val_loss: 0.0161\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 411us/step - loss: 0.0094 - val_loss: 0.0185\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 410us/step - loss: 0.0089 - val_loss: 0.0175\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 408us/step - loss: 0.0090 - val_loss: 0.0190\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 411us/step - loss: 0.0082 - val_loss: 0.0184\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 411us/step - loss: 0.0080 - val_loss: 0.0190\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 410us/step - loss: 0.0084 - val_loss: 0.0189\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 413us/step - loss: 0.0077 - val_loss: 0.0177\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 414us/step - loss: 0.0073 - val_loss: 0.0169\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 5s 1ms/step - loss: 0.1343 - val_loss: 0.0570\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 354us/step - loss: 0.0699 - val_loss: 0.0086\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 354us/step - loss: 0.0729 - val_loss: 0.0173\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 355us/step - loss: 0.0587 - val_loss: 0.0312\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 358us/step - loss: 0.0513 - val_loss: 0.0257\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 354us/step - loss: 0.0432 - val_loss: 0.0107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 356us/step - loss: 0.0313 - val_loss: 0.0044\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 354us/step - loss: 0.0197 - val_loss: 0.0057\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 354us/step - loss: 0.0126 - val_loss: 0.0056\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 401us/step - loss: 0.0081 - val_loss: 0.0048\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 378us/step - loss: 0.0057 - val_loss: 0.0026\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 376us/step - loss: 0.0042 - val_loss: 0.0030\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 381us/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 379us/step - loss: 0.0029 - val_loss: 0.0024\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 374us/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 357us/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 360us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 356us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 355us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 356us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - -0s -98us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 355us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 356us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 355us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 5s 1ms/step - loss: 3.1780 - val_loss: 2.7456\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 357us/step - loss: 1.7566 - val_loss: 1.5233\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 358us/step - loss: 0.9009 - val_loss: 0.8137\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 358us/step - loss: 0.4434 - val_loss: 0.4211\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 360us/step - loss: 0.2172 - val_loss: 0.2127\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 358us/step - loss: 0.1167 - val_loss: 0.1081\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 358us/step - loss: 0.0787 - val_loss: 0.0594\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 359us/step - loss: 0.0690 - val_loss: 0.0380\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 361us/step - loss: 0.0679 - val_loss: 0.0298\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 356us/step - loss: 0.0683 - val_loss: 0.0279\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 356us/step - loss: 0.0684 - val_loss: 0.0288\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 358us/step - loss: 0.0682 - val_loss: 0.0311\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 358us/step - loss: 0.0679 - val_loss: 0.0336\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 356us/step - loss: 0.0678 - val_loss: 0.0357\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 355us/step - loss: 0.0678 - val_loss: 0.0366\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 357us/step - loss: 0.0678 - val_loss: 0.0368\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 356us/step - loss: 0.0678 - val_loss: 0.0373\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 357us/step - loss: 0.0678 - val_loss: 0.0375\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 357us/step - loss: 0.0678 - val_loss: 0.0371\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 360us/step - loss: 0.0678 - val_loss: 0.0366\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 356us/step - loss: 0.0678 - val_loss: 0.0365\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 357us/step - loss: 0.0678 - val_loss: 0.0367\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 357us/step - loss: 0.0678 - val_loss: 0.0369\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 356us/step - loss: 0.0678 - val_loss: 0.0368\n",
      "\n",
      "GENERATION 4\n",
      "\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 4s 1ms/step - loss: 0.0785 - val_loss: 0.0077\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 161us/step - loss: 0.0104 - val_loss: 0.0018\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 158us/step - loss: 0.0041 - val_loss: 0.0016\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 160us/step - loss: 0.0023 - val_loss: 0.0045\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 157us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 155us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 156us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 157us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 155us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 155us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 155us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 156us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 156us/step - loss: 9.3307e-04 - val_loss: 8.7188e-04\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 155us/step - loss: 8.5563e-04 - val_loss: 8.4958e-04\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 157us/step - loss: 7.9905e-04 - val_loss: 8.0653e-04\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 157us/step - loss: 7.6464e-04 - val_loss: 8.6769e-04\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 155us/step - loss: 7.5365e-04 - val_loss: 7.5156e-04\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 156us/step - loss: 7.2929e-04 - val_loss: 7.2292e-04\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 157us/step - loss: 7.1784e-04 - val_loss: 8.3168e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 157us/step - loss: 7.0386e-04 - val_loss: 6.8706e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 156us/step - loss: 7.0288e-04 - val_loss: 7.4224e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 154us/step - loss: 7.1628e-04 - val_loss: 7.9991e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 155us/step - loss: 7.1168e-04 - val_loss: 7.8801e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 156us/step - loss: 7.1279e-04 - val_loss: 8.3300e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 4s 1ms/step - loss: 0.0851 - val_loss: 0.0372\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 155us/step - loss: 0.0110 - val_loss: 0.0098\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 154us/step - loss: 0.0047 - val_loss: 0.0068\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 154us/step - loss: 0.0027 - val_loss: 0.0013\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 154us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 155us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 155us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 154us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 155us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 154us/step - loss: 0.0011 - val_loss: 0.0013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 155us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 155us/step - loss: 9.8914e-04 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 154us/step - loss: 8.9909e-04 - val_loss: 0.0010\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 156us/step - loss: 8.3606e-04 - val_loss: 8.5571e-04\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 161us/step - loss: 7.9894e-04 - val_loss: 7.9675e-04\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 154us/step - loss: 7.7501e-04 - val_loss: 9.4994e-04\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 155us/step - loss: 8.4704e-04 - val_loss: 7.7641e-04\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 156us/step - loss: 7.7723e-04 - val_loss: 8.2433e-04\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 153us/step - loss: 8.1000e-04 - val_loss: 8.2460e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 156us/step - loss: 7.8947e-04 - val_loss: 7.9217e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 154us/step - loss: 7.4039e-04 - val_loss: 9.5337e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 156us/step - loss: 7.6571e-04 - val_loss: 7.6616e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 155us/step - loss: 7.7155e-04 - val_loss: 8.6319e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 155us/step - loss: 7.6933e-04 - val_loss: 7.5063e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 5s 1ms/step - loss: 0.0581 - val_loss: 0.0285\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 306us/step - loss: 0.0106 - val_loss: 0.0040\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 304us/step - loss: 0.0046 - val_loss: 0.0026\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 305us/step - loss: 0.0028 - val_loss: 0.0017\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 311us/step - loss: 0.0024 - val_loss: 0.0049\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 306us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 307us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 305us/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 306us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 307us/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 305us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 306us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 306us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 311us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 306us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 307us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 307us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 307us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 307us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 306us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 306us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 307us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 307us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 306us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 5s 1ms/step - loss: 0.0450 - val_loss: 0.0174\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 320us/step - loss: 0.0096 - val_loss: 0.0027\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 321us/step - loss: 0.0062 - val_loss: 0.0080\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 320us/step - loss: 0.0043 - val_loss: 0.0050\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 321us/step - loss: 0.0036 - val_loss: 0.0023\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 320us/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 321us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 321us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 319us/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 320us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 318us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 321us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 320us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 318us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 320us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 319us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 320us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 318us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 321us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 323us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 320us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 323us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 320us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 321us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 5s 1ms/step - loss: 0.0748 - val_loss: 0.0081\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 321us/step - loss: 0.0168 - val_loss: 0.0139\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 321us/step - loss: 0.0079 - val_loss: 0.0068\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 321us/step - loss: 0.0050 - val_loss: 0.0023\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 321us/step - loss: 0.0041 - val_loss: 0.0060\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 320us/step - loss: 0.0032 - val_loss: 0.0049\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 321us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 320us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 318us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 321us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 320us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 320us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 329us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 322us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 15/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 1s 319us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 319us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 321us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 321us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 321us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 321us/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 320us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 320us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 320us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 321us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 6s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 326us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 324us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 329us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 325us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 327us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 326us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 324us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 324us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 324us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 324us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 325us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 324us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 324us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 327us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 325us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 326us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 328us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 328us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 326us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 323us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 325us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 325us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 323us/step - loss: nan - val_loss: nan\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 6s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 323us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 326us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 326us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 324us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 325us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 324us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 324us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 326us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 329us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 324us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 327us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 325us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 326us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 326us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 324us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 325us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 329us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 326us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 324us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 325us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 325us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 328us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 326us/step - loss: nan - val_loss: nan\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 6s 2ms/step - loss: 0.1288 - val_loss: 0.0101\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 402us/step - loss: 0.0363 - val_loss: 0.0079\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 401us/step - loss: 0.0234 - val_loss: 0.0047\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 397us/step - loss: 0.0171 - val_loss: 0.0035\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 398us/step - loss: 0.0128 - val_loss: 0.0029\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 399us/step - loss: 0.0099 - val_loss: 0.0028\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 401us/step - loss: 0.0086 - val_loss: 0.0029\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 400us/step - loss: 0.0076 - val_loss: 0.0030\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 398us/step - loss: 0.0074 - val_loss: 0.0032\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 398us/step - loss: 0.0070 - val_loss: 0.0029\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 399us/step - loss: 0.0069 - val_loss: 0.0033\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 400us/step - loss: 0.0065 - val_loss: 0.0031\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 398us/step - loss: 0.0062 - val_loss: 0.0034\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 399us/step - loss: 0.0062 - val_loss: 0.0033\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 399us/step - loss: 0.0064 - val_loss: 0.0035\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 401us/step - loss: 0.0064 - val_loss: 0.0034\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 400us/step - loss: 0.0059 - val_loss: 0.0036\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 399us/step - loss: 0.0061 - val_loss: 0.0033\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 398us/step - loss: 0.0064 - val_loss: 0.0039\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 401us/step - loss: 0.0058 - val_loss: 0.0034\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 399us/step - loss: 0.0057 - val_loss: 0.0035\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 400us/step - loss: 0.0056 - val_loss: 0.0035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 402us/step - loss: 0.0058 - val_loss: 0.0035\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 399us/step - loss: 0.0056 - val_loss: 0.0034\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 6s 2ms/step - loss: 0.0664 - val_loss: 0.0103\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 401us/step - loss: 0.0226 - val_loss: 0.0060\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 398us/step - loss: 0.0177 - val_loss: 0.0045\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 398us/step - loss: 0.0134 - val_loss: 0.0038\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 397us/step - loss: 0.0107 - val_loss: 0.0031\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 399us/step - loss: 0.0088 - val_loss: 0.0025\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 397us/step - loss: 0.0074 - val_loss: 0.0023\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 398us/step - loss: 0.0064 - val_loss: 0.0023\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 399us/step - loss: 0.0060 - val_loss: 0.0023\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 398us/step - loss: 0.0053 - val_loss: 0.0024\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 397us/step - loss: 0.0048 - val_loss: 0.0024\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 401us/step - loss: 0.0047 - val_loss: 0.0025\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 398us/step - loss: 0.0046 - val_loss: 0.0025\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 403us/step - loss: 0.0047 - val_loss: 0.0026\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 398us/step - loss: 0.0043 - val_loss: 0.0026\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 399us/step - loss: 0.0044 - val_loss: 0.0027\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 399us/step - loss: 0.0045 - val_loss: 0.0028\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 400us/step - loss: 0.0042 - val_loss: 0.0027\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 398us/step - loss: 0.0043 - val_loss: 0.0027\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 399us/step - loss: 0.0043 - val_loss: 0.0027\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 399us/step - loss: 0.0047 - val_loss: 0.0028\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 402us/step - loss: 0.0041 - val_loss: 0.0028\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 398us/step - loss: 0.0042 - val_loss: 0.0030\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 400us/step - loss: 0.0042 - val_loss: 0.0029\n",
      "\n",
      "GENERATION 5\n",
      "\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 6s 2ms/step - loss: 0.1487 - val_loss: 0.0607\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 312us/step - loss: 0.0287 - val_loss: 0.0198\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 307us/step - loss: 0.0112 - val_loss: 0.0093\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 307us/step - loss: 0.0050 - val_loss: 0.0024\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 307us/step - loss: 0.0031 - val_loss: 0.0025\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 310us/step - loss: 0.0027 - val_loss: 0.0051\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 308us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 309us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 309us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 307us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 309us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 308us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 309us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 311us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 307us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 308us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 311us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 308us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 308us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 308us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 307us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 306us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 309us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 307us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 5s 1ms/step - loss: 0.2115 - val_loss: 0.1117\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 157us/step - loss: 0.0325 - val_loss: 0.0031\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 157us/step - loss: 0.0113 - val_loss: 0.0053\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 156us/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 157us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 157us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 157us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 162us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 157us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 160us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 157us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 157us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 161us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 156us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 157us/step - loss: 9.7898e-04 - val_loss: 0.0010\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 158us/step - loss: 9.3922e-04 - val_loss: 9.7649e-04\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 158us/step - loss: 9.0946e-04 - val_loss: 9.3960e-04\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 158us/step - loss: 8.8138e-04 - val_loss: 9.1053e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 157us/step - loss: 8.6141e-04 - val_loss: 0.0010\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 156us/step - loss: 8.7280e-04 - val_loss: 9.6942e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 158us/step - loss: 8.5889e-04 - val_loss: 8.9163e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 158us/step - loss: 8.2168e-04 - val_loss: 8.3265e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 157us/step - loss: 8.1465e-04 - val_loss: 8.6709e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 5s 1ms/step - loss: 0.0920 - val_loss: 0.0121\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 156us/step - loss: 0.0251 - val_loss: 0.0192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 155us/step - loss: 0.0124 - val_loss: 0.0035\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 155us/step - loss: 0.0055 - val_loss: 0.0021\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 154us/step - loss: 0.0048 - val_loss: 0.0064\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 156us/step - loss: 0.0037 - val_loss: 0.0016\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 155us/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 155us/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 156us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 156us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 155us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 155us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 155us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 155us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 155us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 154us/step - loss: 9.9859e-04 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 156us/step - loss: 9.4190e-04 - val_loss: 0.0010\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 156us/step - loss: 9.0820e-04 - val_loss: 9.6975e-04\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 156us/step - loss: 8.8775e-04 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 156us/step - loss: 8.7092e-04 - val_loss: 0.0012\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 156us/step - loss: 8.6049e-04 - val_loss: 9.2115e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 157us/step - loss: 8.6898e-04 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 158us/step - loss: 8.4339e-04 - val_loss: 9.1629e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 156us/step - loss: 8.1432e-04 - val_loss: 9.8236e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 6s 1ms/step - loss: 0.0782 - val_loss: 0.0458\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 236us/step - loss: 0.0146 - val_loss: 0.0174\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 239us/step - loss: 0.0058 - val_loss: 0.0036\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 237us/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 236us/step - loss: 0.0020 - val_loss: 0.0010\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 236us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 236us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 236us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 236us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 236us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 235us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 237us/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 237us/step - loss: 9.9459e-04 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 236us/step - loss: 9.6713e-04 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 237us/step - loss: 9.4840e-04 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 235us/step - loss: 9.3189e-04 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 235us/step - loss: 9.1581e-04 - val_loss: 9.8855e-04\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 238us/step - loss: 9.0059e-04 - val_loss: 9.8810e-04\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 237us/step - loss: 8.8505e-04 - val_loss: 0.0010\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 237us/step - loss: 8.7338e-04 - val_loss: 8.9835e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 239us/step - loss: 8.5985e-04 - val_loss: 9.3701e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 237us/step - loss: 8.4448e-04 - val_loss: 9.4351e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 236us/step - loss: 8.3183e-04 - val_loss: 8.2100e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 235us/step - loss: 8.3507e-04 - val_loss: 8.7909e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 6s 1ms/step - loss: 0.1963 - val_loss: 0.0087\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 237us/step - loss: 0.0882 - val_loss: 0.0520\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 237us/step - loss: 0.0472 - val_loss: 0.0402\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 236us/step - loss: 0.0194 - val_loss: 0.0027\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 238us/step - loss: 0.0072 - val_loss: 0.0050\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 238us/step - loss: 0.0053 - val_loss: 0.0026\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 237us/step - loss: 0.0039 - val_loss: 0.0053\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 237us/step - loss: 0.0036 - val_loss: 0.0047\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 240us/step - loss: 0.0034 - val_loss: 0.0022\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 237us/step - loss: 0.0031 - val_loss: 0.0020\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 237us/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 237us/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 238us/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 236us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 238us/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 237us/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 236us/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 239us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 237us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 238us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 236us/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 237us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 237us/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 236us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 7s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 524us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 522us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 522us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 522us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 519us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 518us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 519us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 521us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 519us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 521us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 521us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 520us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 523us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 521us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 520us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 519us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 519us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 522us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 521us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 523us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 522us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 520us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 522us/step - loss: nan - val_loss: nan\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 7s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 520us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 520us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 520us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 520us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 520us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 523us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 520us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 520us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 519us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 518us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 518us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 521us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 520us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 521us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 522us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 524us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 520us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 520us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 519us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 519us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 520us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 525us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 517us/step - loss: nan - val_loss: nan\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 7s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 521us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 519us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 520us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 518us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 521us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 521us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 523us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 519us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 517us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 519us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 519us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 521us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 519us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 519us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 524us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 522us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 520us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 523us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 518us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 518us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 523us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 519us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 522us/step - loss: nan - val_loss: nan\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 8s 2ms/step - loss: 12.2869 - val_loss: 0.0119\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 518us/step - loss: 0.0110 - val_loss: 0.0045\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 519us/step - loss: 0.0081 - val_loss: 0.0035\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 518us/step - loss: 0.0078 - val_loss: 0.0027\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 523us/step - loss: 0.0076 - val_loss: 0.0039\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 522us/step - loss: 0.0076 - val_loss: 0.0029\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 520us/step - loss: 0.0067 - val_loss: 0.0032\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 524us/step - loss: 0.0065 - val_loss: 0.0031\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 522us/step - loss: 0.0066 - val_loss: 0.0037\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 524us/step - loss: 0.0061 - val_loss: 0.0021\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 521us/step - loss: 0.0061 - val_loss: 0.0034\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 521us/step - loss: 0.0058 - val_loss: 0.0031\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 521us/step - loss: 0.0054 - val_loss: 0.0028\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 519us/step - loss: 0.0056 - val_loss: 0.0032\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 521us/step - loss: 0.0054 - val_loss: 0.0025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 521us/step - loss: 0.0055 - val_loss: 0.0027\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 522us/step - loss: 0.0050 - val_loss: 0.0029\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 521us/step - loss: 0.0052 - val_loss: 0.0023\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 519us/step - loss: 0.0054 - val_loss: 0.0026\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 522us/step - loss: 0.0050 - val_loss: 0.0027\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 520us/step - loss: 0.0050 - val_loss: 0.0023\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 522us/step - loss: 0.0047 - val_loss: 0.0024\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 522us/step - loss: 0.0047 - val_loss: 0.0027\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 522us/step - loss: 0.0046 - val_loss: 0.0027\n",
      "\n",
      "GENERATION 6\n",
      "\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 7s 2ms/step - loss: 0.0758 - val_loss: 0.0233\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 309us/step - loss: 0.0148 - val_loss: 0.0073\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 308us/step - loss: 0.0064 - val_loss: 0.0136\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 309us/step - loss: 0.0047 - val_loss: 0.0025\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 311us/step - loss: 0.0034 - val_loss: 0.0020\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 312us/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 309us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 309us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 309us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 309us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 309us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 309us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 310us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 315us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 311us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 311us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 309us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 308us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 307us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 312us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 309us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 309us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 309us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 308us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 6s 2ms/step - loss: 0.0885 - val_loss: 0.0488\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: 0.0132 - val_loss: 0.0140\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: 0.0057 - val_loss: 0.0067\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: 0.0027 - val_loss: 0.0013\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 162us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 161us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 158us/step - loss: 9.8701e-04 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: 9.5666e-04 - val_loss: 0.0010\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: 9.3100e-04 - val_loss: 0.0010\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: 8.9533e-04 - val_loss: 9.3160e-04\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 160us/step - loss: 8.6501e-04 - val_loss: 8.3340e-04\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: 8.4052e-04 - val_loss: 8.4374e-04\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 160us/step - loss: 8.2387e-04 - val_loss: 8.0091e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 158us/step - loss: 8.2625e-04 - val_loss: 8.1009e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 158us/step - loss: 8.1361e-04 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: 8.1926e-04 - val_loss: 7.6230e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: 7.8990e-04 - val_loss: 7.4905e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 160us/step - loss: 7.6952e-04 - val_loss: 7.4040e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 6s 2ms/step - loss: 0.1736 - val_loss: 0.0075\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 158us/step - loss: 0.0223 - val_loss: 0.0129\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 158us/step - loss: 0.0138 - val_loss: 0.0017\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 157us/step - loss: 0.0064 - val_loss: 0.0015\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 158us/step - loss: 0.0045 - val_loss: 0.0016\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 157us/step - loss: 0.0033 - val_loss: 0.0013\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 158us/step - loss: 0.0027 - val_loss: 0.0013\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 157us/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 158us/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 157us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 160us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 162us/step - loss: 0.0019 - val_loss: 0.0031\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 156us/step - loss: 0.0019 - val_loss: 0.0034\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 158us/step - loss: 0.0018 - val_loss: 0.0033\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 155us/step - loss: 0.0017 - val_loss: 0.0026\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: 0.0017 - val_loss: 0.0032\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 157us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 158us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 20/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 1s 158us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 156us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 158us/step - loss: 0.0013 - val_loss: 0.0054\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 157us/step - loss: 0.0013 - val_loss: 0.0062\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 157us/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 8s 2ms/step - loss: 0.1473 - val_loss: 0.0032\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 324us/step - loss: 0.0181 - val_loss: 0.0132\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 321us/step - loss: 0.0127 - val_loss: 0.0176\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 322us/step - loss: 0.0074 - val_loss: 0.0040\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 325us/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 321us/step - loss: 0.0040 - val_loss: 0.0017\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 326us/step - loss: 0.0036 - val_loss: 0.0021\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 322us/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 323us/step - loss: 0.0033 - val_loss: 0.0018\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 323us/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 322us/step - loss: 0.0030 - val_loss: 0.0018\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 322us/step - loss: 0.0029 - val_loss: 0.0019\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 323us/step - loss: 0.0028 - val_loss: 0.0019\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 323us/step - loss: 0.0028 - val_loss: 0.0017\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 323us/step - loss: 0.0028 - val_loss: 0.0016\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 324us/step - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 324us/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 327us/step - loss: 0.0027 - val_loss: 0.0016\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 326us/step - loss: 0.0027 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 324us/step - loss: 0.0025 - val_loss: 0.0015\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 325us/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 324us/step - loss: 0.0025 - val_loss: 0.0015\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 325us/step - loss: 0.0024 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 325us/step - loss: 0.0024 - val_loss: 0.0015\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 8s 2ms/step - loss: 0.1270 - val_loss: 0.0301\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 322us/step - loss: 0.0161 - val_loss: 0.0020\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 323us/step - loss: 0.0077 - val_loss: 0.0058\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 329us/step - loss: 0.0048 - val_loss: 0.0019\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 324us/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 326us/step - loss: 0.0032 - val_loss: 0.0019\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 323us/step - loss: 0.0029 - val_loss: 0.0020\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 327us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 324us/step - loss: 0.0027 - val_loss: 0.0021\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 324us/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 322us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 324us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 326us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 324us/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 324us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 322us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 324us/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 324us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 322us/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 326us/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 327us/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 325us/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 325us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 323us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 8s 2ms/step - loss: 0.2739 - val_loss: 0.0460\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 326us/step - loss: 0.0260 - val_loss: 0.0018\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 324us/step - loss: 0.0141 - val_loss: 0.0034\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 323us/step - loss: 0.0075 - val_loss: 0.0017\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 323us/step - loss: 0.0053 - val_loss: 0.0036\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 321us/step - loss: 0.0041 - val_loss: 0.0018\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 324us/step - loss: 0.0033 - val_loss: 0.0029\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 327us/step - loss: 0.0031 - val_loss: 0.0017\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 325us/step - loss: 0.0029 - val_loss: 0.0027\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 324us/step - loss: 0.0029 - val_loss: 0.0018\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 323us/step - loss: 0.0026 - val_loss: 0.0021\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 324us/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 328us/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 327us/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 324us/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 324us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 322us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 324us/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 325us/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 323us/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 327us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 325us/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 326us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 325us/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 9s 2ms/step - loss: 0.2570 - val_loss: 0.0060\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 485us/step - loss: 0.0743 - val_loss: 0.0953\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 485us/step - loss: 0.0853 - val_loss: 0.0872\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 486us/step - loss: 0.0736 - val_loss: 0.0374\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 486us/step - loss: 0.0684 - val_loss: 0.0238\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 489us/step - loss: 0.0690 - val_loss: 0.0305\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 486us/step - loss: 0.0678 - val_loss: 0.0407\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 486us/step - loss: 0.0679 - val_loss: 0.0409\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 485us/step - loss: 0.0679 - val_loss: 0.0356\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 486us/step - loss: 0.0678 - val_loss: 0.0354\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 486us/step - loss: 0.0678 - val_loss: 0.0363\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 485us/step - loss: 0.0677 - val_loss: 0.0364\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 488us/step - loss: 0.0676 - val_loss: 0.0381\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 488us/step - loss: 0.0676 - val_loss: 0.0364\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 486us/step - loss: 0.0675 - val_loss: 0.0358\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 488us/step - loss: 0.0666 - val_loss: 0.0369\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 485us/step - loss: 0.0648 - val_loss: 0.0325\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 489us/step - loss: 0.0602 - val_loss: 0.0243\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 486us/step - loss: 0.0538 - val_loss: 0.0145\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 486us/step - loss: 0.0399 - val_loss: 0.0075\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 487us/step - loss: 0.0297 - val_loss: 0.0067\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 488us/step - loss: 0.0213 - val_loss: 0.0074\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 489us/step - loss: 0.0215 - val_loss: 0.0038\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 489us/step - loss: 0.0127 - val_loss: 0.0038\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 9s 2ms/step - loss: 0.0723 - val_loss: 0.0355\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 402us/step - loss: 0.0620 - val_loss: 0.0203\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 403us/step - loss: 0.0408 - val_loss: 0.0053\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 402us/step - loss: 0.0233 - val_loss: 0.0134\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 402us/step - loss: 0.0234 - val_loss: 0.0437\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 401us/step - loss: 0.0296 - val_loss: 0.0387\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 409us/step - loss: 0.0302 - val_loss: 0.0270\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 406us/step - loss: 0.0315 - val_loss: 0.0281\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 403us/step - loss: 0.0323 - val_loss: 0.0405\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 402us/step - loss: 0.0342 - val_loss: 0.0481\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 401us/step - loss: 0.0426 - val_loss: 0.0063\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 402us/step - loss: 0.0652 - val_loss: 0.0346\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 401us/step - loss: 0.0491 - val_loss: 0.0053\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 402us/step - loss: 0.0164 - val_loss: 0.0299\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 403us/step - loss: 0.0117 - val_loss: 0.0073\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 402us/step - loss: 0.0072 - val_loss: 0.0095\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 405us/step - loss: 0.0057 - val_loss: 0.0080\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 408us/step - loss: 0.0046 - val_loss: 0.0030\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 403us/step - loss: 0.0041 - val_loss: 0.0031\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 400us/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 404us/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 402us/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 402us/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 404us/step - loss: 0.0034 - val_loss: 0.0021\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 9s 2ms/step - loss: 0.0585 - val_loss: 0.0048\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 512us/step - loss: 0.0478 - val_loss: 0.0050\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 511us/step - loss: 0.0134 - val_loss: 0.0210\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 512us/step - loss: 0.0107 - val_loss: 0.0195\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 512us/step - loss: 0.0088 - val_loss: 0.0215\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 513us/step - loss: 0.0085 - val_loss: 0.0178\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 512us/step - loss: 0.0259 - val_loss: 0.0094\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 514us/step - loss: 0.0056 - val_loss: 0.0273\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 512us/step - loss: 0.0060 - val_loss: 0.0082\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 515us/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 512us/step - loss: 0.0038 - val_loss: 0.0266\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 512us/step - loss: 0.0061 - val_loss: 0.0119\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 514us/step - loss: 0.0038 - val_loss: 0.0070\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 514us/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 513us/step - loss: 0.0031 - val_loss: 0.0199\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 515us/step - loss: 0.0057 - val_loss: 0.0072\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 514us/step - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 516us/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 512us/step - loss: 0.0029 - val_loss: 0.0053\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 514us/step - loss: 0.0080 - val_loss: 0.0031\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 514us/step - loss: 0.0033 - val_loss: 0.0015\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 514us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 515us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 515us/step - loss: 0.0047 - val_loss: 0.0032\n",
      "\n",
      "GENERATION 7\n",
      "\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 8s 2ms/step - loss: 0.1359 - val_loss: 0.0348\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: 0.0198 - val_loss: 0.0177\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 163us/step - loss: 0.0088 - val_loss: 0.0077\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 162us/step - loss: 0.0047 - val_loss: 0.0031\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 160us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 6/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 1s 157us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 158us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: 9.5209e-04 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: 9.0173e-04 - val_loss: 9.6059e-04\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: 8.5042e-04 - val_loss: 9.1288e-04\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: 8.2232e-04 - val_loss: 9.0170e-04\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 161us/step - loss: 7.8738e-04 - val_loss: 8.3686e-04\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: 7.6685e-04 - val_loss: 8.5049e-04\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: 7.6838e-04 - val_loss: 8.1598e-04\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: 7.6951e-04 - val_loss: 8.7606e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: 7.7110e-04 - val_loss: 7.6920e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 160us/step - loss: 7.9180e-04 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - ETA: 0s - loss: 7.9126e-0 - 1s 159us/step - loss: 7.9816e-04 - val_loss: 7.4722e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 160us/step - loss: 7.8872e-04 - val_loss: 7.4656e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: 8.0344e-04 - val_loss: 9.1709e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 8s 2ms/step - loss: 0.2174 - val_loss: 0.1582\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: 0.0476 - val_loss: 0.0141\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 161us/step - loss: 0.0149 - val_loss: 0.0146\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 158us/step - loss: 0.0075 - val_loss: 0.0090\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 158us/step - loss: 0.0043 - val_loss: 0.0034\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 157us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 157us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 158us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 158us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 157us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 157us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 157us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 157us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 158us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 158us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 158us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 158us/step - loss: 9.9613e-04 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 157us/step - loss: 9.5987e-04 - val_loss: 9.7794e-04\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 158us/step - loss: 9.3693e-04 - val_loss: 0.0010\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: 9.3638e-04 - val_loss: 9.1706e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: 8.8845e-04 - val_loss: 8.8880e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 157us/step - loss: 8.5840e-04 - val_loss: 8.9859e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: 8.3778e-04 - val_loss: 8.5728e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: 8.2572e-04 - val_loss: 8.3563e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 8s 2ms/step - loss: 0.0665 - val_loss: 0.0021\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - ETA: 0s - loss: 0.011 - 1s 160us/step - loss: 0.0120 - val_loss: 0.0113\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 161us/step - loss: 0.0072 - val_loss: 0.0014\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 161us/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: 0.0038 - val_loss: 0.0024\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 160us/step - loss: 0.0032 - val_loss: 0.0027\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 160us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 160us/step - loss: 0.0024 - val_loss: 0.0036\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 160us/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 160us/step - loss: 0.0020 - val_loss: 0.0047\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 161us/step - loss: 0.0019 - val_loss: 0.0049\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: 0.0020 - val_loss: 0.0047\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: 0.0019 - val_loss: 0.0051\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 160us/step - loss: 0.0018 - val_loss: 0.0051\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 158us/step - loss: 0.0017 - val_loss: 0.0057\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 161us/step - loss: 0.0017 - val_loss: 0.0062\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 160us/step - loss: 0.0016 - val_loss: 0.0083\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 160us/step - loss: 0.0016 - val_loss: 0.0082\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 160us/step - loss: 0.0016 - val_loss: 0.0073\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 161us/step - loss: 0.0014 - val_loss: 0.0082\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: 0.0015 - val_loss: 0.0095\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 160us/step - loss: 0.0015 - val_loss: 0.0103\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 8s 2ms/step - loss: 0.1807 - val_loss: 0.0198\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: 0.0226 - val_loss: 0.0163\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 160us/step - loss: 0.0121 - val_loss: 0.0017\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 161us/step - loss: 0.0062 - val_loss: 0.0017\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 160us/step - loss: 0.0044 - val_loss: 0.0020\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 160us/step - loss: 0.0036 - val_loss: 0.0016\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 161us/step - loss: 0.0034 - val_loss: 0.0020\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: 0.0032 - val_loss: 0.0025\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 160us/step - loss: 0.0031 - val_loss: 0.0019\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 158us/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 158us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 160us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 158us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 158us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 160us/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 164us/step - loss: 0.0020 - val_loss: 0.0049\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 158us/step - loss: 0.0018 - val_loss: 0.0061\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 160us/step - loss: 0.0018 - val_loss: 0.0083\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 158us/step - loss: 0.0018 - val_loss: 0.0086\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 161us/step - loss: 0.0017 - val_loss: 0.0073\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: 0.0016 - val_loss: 0.0076\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 163us/step - loss: 0.0016 - val_loss: 0.0096\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 8s 2ms/step - loss: 0.0806 - val_loss: 0.0050\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 193us/step - loss: 0.0092 - val_loss: 0.0015\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 194us/step - loss: 0.0047 - val_loss: 0.0021\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 195us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 197us/step - loss: 0.0024 - val_loss: 0.0014\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 196us/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 196us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 195us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 195us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 193us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 194us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 195us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 194us/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 196us/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 196us/step - loss: 0.0013 - val_loss: 9.5313e-04\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 196us/step - loss: 0.0012 - val_loss: 9.4850e-04\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 197us/step - loss: 0.0012 - val_loss: 9.2703e-04\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 202us/step - loss: 0.0011 - val_loss: 9.8332e-04\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 196us/step - loss: 0.0011 - val_loss: 8.6892e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 198us/step - loss: 0.0011 - val_loss: 8.5216e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 194us/step - loss: 0.0011 - val_loss: 9.8214e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 195us/step - loss: 9.9932e-04 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 195us/step - loss: 0.0010 - val_loss: 9.8566e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 198us/step - loss: 9.8862e-04 - val_loss: 0.0012\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 8s 2ms/step - loss: 0.1333 - val_loss: 0.0052\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 195us/step - loss: 0.0073 - val_loss: 0.0030\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 195us/step - loss: 0.0050 - val_loss: 0.0033\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 195us/step - loss: 0.0086 - val_loss: 0.0041\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 195us/step - loss: 0.0092 - val_loss: 0.0073\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 196us/step - loss: 0.0095 - val_loss: 0.0054\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 194us/step - loss: 0.0093 - val_loss: 0.0042\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 197us/step - loss: 0.0076 - val_loss: 0.0028\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 198us/step - loss: 0.0080 - val_loss: 0.0046\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 194us/step - loss: 0.0062 - val_loss: 0.0023\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 196us/step - loss: 0.0063 - val_loss: 0.0049\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 198us/step - loss: 0.0063 - val_loss: 0.0035\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 195us/step - loss: 0.0063 - val_loss: 0.0031\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 195us/step - loss: 0.0047 - val_loss: 0.0025\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 194us/step - loss: 0.0062 - val_loss: 0.0027\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 194us/step - loss: 0.0048 - val_loss: 0.0015\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 195us/step - loss: 0.0049 - val_loss: 0.0013\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 194us/step - loss: 0.0047 - val_loss: 0.0032\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 196us/step - loss: 0.0037 - val_loss: 0.0013\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 196us/step - loss: 0.0052 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 196us/step - loss: 0.0032 - val_loss: 0.0023\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 196us/step - loss: 0.0037 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 194us/step - loss: 0.0044 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 196us/step - loss: 0.0040 - val_loss: 0.0021\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 9s 2ms/step - loss: 0.0615 - val_loss: 0.0038\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 252us/step - loss: 0.0111 - val_loss: 0.0048\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 253us/step - loss: 0.0091 - val_loss: 0.0057\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 256us/step - loss: 0.0101 - val_loss: 0.0065\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 256us/step - loss: 0.0082 - val_loss: 0.0019\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 254us/step - loss: 0.0081 - val_loss: 0.0088\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 252us/step - loss: 0.0069 - val_loss: 0.0017\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 253us/step - loss: 0.0065 - val_loss: 0.0165\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 254us/step - loss: 0.0097 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 252us/step - loss: 0.0033 - val_loss: 0.0021\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 253us/step - loss: 0.0061 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 254us/step - loss: 0.0054 - val_loss: 0.0013\n",
      "Epoch 13/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 1s 254us/step - loss: 0.0053 - val_loss: 0.0014\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 253us/step - loss: 0.0041 - val_loss: 0.0019\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 252us/step - loss: 0.0069 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 252us/step - loss: 0.0028 - val_loss: 0.0018\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 252us/step - loss: 0.0047 - val_loss: 0.0014\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 252us/step - loss: 0.0041 - val_loss: 0.0015\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 252us/step - loss: 0.0047 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 254us/step - loss: 0.0033 - val_loss: 0.0016\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 254us/step - loss: 0.0054 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 252us/step - loss: 0.0029 - val_loss: 9.2439e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 255us/step - loss: 0.0030 - val_loss: 0.0012\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 253us/step - loss: 0.0046 - val_loss: 0.0019\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 10s 3ms/step - loss: 0.1363 - val_loss: 0.0358\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 556us/step - loss: 0.0502 - val_loss: 0.0199\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 559us/step - loss: 0.0423 - val_loss: 0.0152\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 556us/step - loss: 0.0363 - val_loss: 0.0143\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 558us/step - loss: 0.0313 - val_loss: 0.0114\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 560us/step - loss: 0.0265 - val_loss: 0.0097\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 558us/step - loss: 0.0223 - val_loss: 0.0084\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 556us/step - loss: 0.0189 - val_loss: 0.0066\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 559us/step - loss: 0.0156 - val_loss: 0.0050\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 555us/step - loss: 0.0132 - val_loss: 0.0043\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 558us/step - loss: 0.0109 - val_loss: 0.0034\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 560us/step - loss: 0.0092 - val_loss: 0.0030\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 558us/step - loss: 0.0081 - val_loss: 0.0028\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 558us/step - loss: 0.0070 - val_loss: 0.0027\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 559us/step - loss: 0.0064 - val_loss: 0.0028\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 556us/step - loss: 0.0057 - val_loss: 0.0029\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 556us/step - loss: 0.0054 - val_loss: 0.0032\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 561us/step - loss: 0.0050 - val_loss: 0.0034\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 561us/step - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 557us/step - loss: 0.0047 - val_loss: 0.0038\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 560us/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 557us/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 560us/step - loss: 0.0045 - val_loss: 0.0042\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 561us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 10s 3ms/step - loss: 0.0959 - val_loss: 0.0025\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 555us/step - loss: 0.0259 - val_loss: 0.0027\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 554us/step - loss: 0.0071 - val_loss: 0.0187\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 558us/step - loss: 0.0172 - val_loss: 0.0156\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 557us/step - loss: 0.0074 - val_loss: 0.0231\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 554us/step - loss: 0.0181 - val_loss: 0.0128\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 556us/step - loss: 0.0152 - val_loss: 0.0054\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 554us/step - loss: 0.0036 - val_loss: 0.0026\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 555us/step - loss: 0.0166 - val_loss: 0.0043\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 555us/step - loss: 0.0043 - val_loss: 0.0031\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 556us/step - loss: 0.0077 - val_loss: 0.0265\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 553us/step - loss: 0.0115 - val_loss: 0.0026\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 554us/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 554us/step - loss: 0.0145 - val_loss: 0.0109\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 557us/step - loss: 0.0052 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 557us/step - loss: 0.0061 - val_loss: 0.0056\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 553us/step - loss: 0.0046 - val_loss: 0.0030\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 557us/step - loss: 0.0093 - val_loss: 0.0140\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 555us/step - loss: 0.0081 - val_loss: 0.0040\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 557us/step - loss: 0.0041 - val_loss: 0.0029\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 556us/step - loss: 0.0049 - val_loss: 0.0033\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 556us/step - loss: 0.0050 - val_loss: 0.0065\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 558us/step - loss: 0.0101 - val_loss: 0.0156\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 557us/step - loss: 0.0030 - val_loss: 0.0273\n",
      "\n",
      "GENERATION 8\n",
      "\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 9s 2ms/step - loss: 0.1082 - val_loss: 0.0317\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 309us/step - loss: 0.0132 - val_loss: 0.0027\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 309us/step - loss: 0.0057 - val_loss: 0.0034\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 309us/step - loss: 0.0038 - val_loss: 0.0070\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 315us/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 310us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 311us/step - loss: 0.0023 - val_loss: 0.0036\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 311us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 309us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 307us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 308us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 311us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 308us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 311us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 310us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 315us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 310us/step - loss: 0.0016 - val_loss: 0.0017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 315us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 308us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 309us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 310us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 309us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 309us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 309us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 9s 2ms/step - loss: 0.1224 - val_loss: 0.0521\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: 0.0213 - val_loss: 0.0185\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 160us/step - loss: 0.0100 - val_loss: 0.0053\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: 0.0044 - val_loss: 0.0022\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 164us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 162us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 161us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 160us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 160us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 160us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 161us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 160us/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 161us/step - loss: 9.6709e-04 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 160us/step - loss: 9.1639e-04 - val_loss: 9.2670e-04\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 161us/step - loss: 8.9140e-04 - val_loss: 9.0967e-04\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 160us/step - loss: 8.4456e-04 - val_loss: 0.0010\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: 8.3500e-04 - val_loss: 8.0379e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 160us/step - loss: 8.0867e-04 - val_loss: 8.5938e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 161us/step - loss: 7.8788e-04 - val_loss: 7.9411e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 160us/step - loss: 7.9008e-04 - val_loss: 8.4527e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 161us/step - loss: 7.7195e-04 - val_loss: 8.3767e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 9s 2ms/step - loss: 0.1586 - val_loss: 0.1178\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 156us/step - loss: 0.0628 - val_loss: 0.0480\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 156us/step - loss: 0.0372 - val_loss: 0.0236\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 156us/step - loss: 0.0285 - val_loss: 0.0150\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 158us/step - loss: 0.0241 - val_loss: 0.0109\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 157us/step - loss: 0.0211 - val_loss: 0.0088\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: 0.0187 - val_loss: 0.0072\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 158us/step - loss: 0.0165 - val_loss: 0.0064\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 157us/step - loss: 0.0146 - val_loss: 0.0055\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 156us/step - loss: 0.0128 - val_loss: 0.0047\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 157us/step - loss: 0.0113 - val_loss: 0.0040\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 156us/step - loss: 0.0099 - val_loss: 0.0033\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 157us/step - loss: 0.0087 - val_loss: 0.0029\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 156us/step - loss: 0.0076 - val_loss: 0.0026\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - ETA: 0s - loss: 0.006 - 1s 157us/step - loss: 0.0067 - val_loss: 0.0022\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 156us/step - loss: 0.0059 - val_loss: 0.0019\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 158us/step - loss: 0.0052 - val_loss: 0.0017\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 158us/step - loss: 0.0046 - val_loss: 0.0016\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: 0.0041 - val_loss: 0.0015\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 157us/step - loss: 0.0036 - val_loss: 0.0014\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 156us/step - loss: 0.0032 - val_loss: 0.0013\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 158us/step - loss: 0.0029 - val_loss: 0.0013\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 157us/step - loss: 0.0026 - val_loss: 0.0013\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 157us/step - loss: 0.0023 - val_loss: 0.0013\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 10s 3ms/step - loss: 0.0381 - val_loss: 0.0050\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 310us/step - loss: 0.0127 - val_loss: 0.0029\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 310us/step - loss: 0.0081 - val_loss: 0.0025\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 309us/step - loss: 0.0055 - val_loss: 0.0023\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 310us/step - loss: 0.0041 - val_loss: 0.0023\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 312us/step - loss: 0.0034 - val_loss: 0.0026\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 310us/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 311us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 311us/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 313us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 310us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 310us/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 309us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 311us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 314us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 310us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 311us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 308us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 313us/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 309us/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 310us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 309us/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 315us/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 311us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 11s 3ms/step - loss: 3.2951 - val_loss: 0.0039\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 490us/step - loss: 0.0048 - val_loss: 0.0039\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 488us/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 489us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 489us/step - loss: 0.0037 - val_loss: 0.0048\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 489us/step - loss: 0.0036 - val_loss: 0.0043\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 488us/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 487us/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 489us/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 488us/step - loss: 0.0033 - val_loss: 0.0039\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 491us/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 488us/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 489us/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 492us/step - loss: 0.0031 - val_loss: 0.0047\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 489us/step - loss: 0.0031 - val_loss: 0.0038\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 488us/step - loss: 0.0030 - val_loss: 0.0036\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 491us/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 489us/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 488us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 489us/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 489us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 490us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 489us/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 486us/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 11s 3ms/step - loss: 0.9494 - val_loss: 0.0284\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 421us/step - loss: 0.0205 - val_loss: 0.0110\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 421us/step - loss: 0.0086 - val_loss: 0.0097\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 421us/step - loss: 0.0056 - val_loss: 0.0021\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 420us/step - loss: 0.0029 - val_loss: 0.0018\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 422us/step - loss: 0.0027 - val_loss: 0.0020\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 421us/step - loss: 0.0028 - val_loss: 0.0020\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 421us/step - loss: 0.0030 - val_loss: 0.0025\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 418us/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 419us/step - loss: 0.0033 - val_loss: 0.0018\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 424us/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 421us/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 419us/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 421us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 419us/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 419us/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 419us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 420us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 419us/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 422us/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 421us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 422us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 424us/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 418us/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 11s 3ms/step - loss: 2.2633 - val_loss: 0.0334\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 360us/step - loss: 0.0612 - val_loss: 0.0130\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 360us/step - loss: 0.0397 - val_loss: 0.0045\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 362us/step - loss: 0.0140 - val_loss: 0.0186\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 366us/step - loss: 0.0191 - val_loss: 0.0188\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 360us/step - loss: 0.0088 - val_loss: 0.0111\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 360us/step - loss: 0.0078 - val_loss: 0.0260\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 362us/step - loss: 0.0101 - val_loss: 0.0180\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 360us/step - loss: 0.0066 - val_loss: 0.0081\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 362us/step - loss: 0.0063 - val_loss: 0.0332\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 364us/step - loss: 0.0082 - val_loss: 0.0107\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 362us/step - loss: 0.0054 - val_loss: 0.0073\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 361us/step - loss: 0.0062 - val_loss: 0.0089\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 361us/step - loss: 0.0067 - val_loss: 0.0166\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 361us/step - loss: 0.0061 - val_loss: 0.0083\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 365us/step - loss: 0.0046 - val_loss: 0.0033\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 361us/step - loss: 0.0053 - val_loss: 0.0054\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 361us/step - loss: 0.0057 - val_loss: 0.0037\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 362us/step - loss: 0.0056 - val_loss: 0.0032\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 363us/step - loss: 0.0044 - val_loss: 0.0032\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 361us/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 360us/step - loss: 0.0051 - val_loss: 0.0033\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 362us/step - loss: 0.0042 - val_loss: 0.0034\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 362us/step - loss: 0.0045 - val_loss: 0.0032\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 11s 3ms/step - loss: 0.3436 - val_loss: 0.0955\n",
      "Epoch 2/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 1s 361us/step - loss: 0.0753 - val_loss: 0.0758\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 361us/step - loss: 0.0570 - val_loss: 0.0508\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 362us/step - loss: 0.0494 - val_loss: 0.0519\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 363us/step - loss: 0.0400 - val_loss: 0.0403\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 361us/step - loss: 0.0373 - val_loss: 0.0562\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 363us/step - loss: 0.0307 - val_loss: 0.0649\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 363us/step - loss: 0.0377 - val_loss: 0.0352\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 364us/step - loss: 0.0319 - val_loss: 0.0521\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 364us/step - loss: 0.0196 - val_loss: 0.0857\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 363us/step - loss: 0.0303 - val_loss: 0.0585\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 360us/step - loss: 0.0279 - val_loss: 0.0427\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 365us/step - loss: 0.0217 - val_loss: 0.0467\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 361us/step - loss: 0.0204 - val_loss: 0.0571\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 361us/step - loss: 0.0221 - val_loss: 0.0505\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 362us/step - loss: 0.0218 - val_loss: 0.0417\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 363us/step - loss: 0.0177 - val_loss: 0.0367\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 362us/step - loss: 0.0184 - val_loss: 0.0432\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 361us/step - loss: 0.0168 - val_loss: 0.0362\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 363us/step - loss: 0.0160 - val_loss: 0.0465\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 364us/step - loss: 0.0145 - val_loss: 0.0313\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 364us/step - loss: 0.0128 - val_loss: 0.0487\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 360us/step - loss: 0.0163 - val_loss: 0.0400\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 364us/step - loss: 0.0111 - val_loss: 0.0375\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 11s 3ms/step - loss: 0.3772 - val_loss: 0.0046\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 362us/step - loss: 0.0639 - val_loss: 0.0225\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 365us/step - loss: 0.0558 - val_loss: 0.0165\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 362us/step - loss: 0.0521 - val_loss: 0.0365\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 363us/step - loss: 0.0331 - val_loss: 0.0751\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 364us/step - loss: 0.0424 - val_loss: 0.0320\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 361us/step - loss: 0.0384 - val_loss: 0.0476\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 361us/step - loss: 0.0225 - val_loss: 0.0751\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 363us/step - loss: 0.0363 - val_loss: 0.0403\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 362us/step - loss: 0.0246 - val_loss: 0.0638\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 362us/step - loss: 0.0219 - val_loss: 0.0606\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 362us/step - loss: 0.0240 - val_loss: 0.0561\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 361us/step - loss: 0.0200 - val_loss: 0.0456\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 366us/step - loss: 0.0229 - val_loss: 0.0353\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 368us/step - loss: 0.0178 - val_loss: 0.0466\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 361us/step - loss: 0.0176 - val_loss: 0.0379\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 363us/step - loss: 0.0151 - val_loss: 0.0375\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 360us/step - loss: 0.0129 - val_loss: 0.0365\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 361us/step - loss: 0.0153 - val_loss: 0.0266\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 361us/step - loss: 0.0127 - val_loss: 0.0433\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 362us/step - loss: 0.0117 - val_loss: 0.0468\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 362us/step - loss: 0.0122 - val_loss: 0.0365\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 362us/step - loss: 0.0119 - val_loss: 0.0257\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 360us/step - loss: 0.0091 - val_loss: 0.0285\n",
      "\n",
      "GENERATION 9\n",
      "\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 11s 3ms/step - loss: 0.1492 - val_loss: 0.0498\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 326us/step - loss: 0.0255 - val_loss: 0.0193\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 324us/step - loss: 0.0128 - val_loss: 0.0032\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 325us/step - loss: 0.0074 - val_loss: 0.0037\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 327us/step - loss: 0.0054 - val_loss: 0.0024\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 326us/step - loss: 0.0046 - val_loss: 0.0025\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 327us/step - loss: 0.0044 - val_loss: 0.0030\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 326us/step - loss: 0.0040 - val_loss: 0.0025\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 325us/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 327us/step - loss: 0.0039 - val_loss: 0.0030\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 329us/step - loss: 0.0037 - val_loss: 0.0033\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 325us/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 326us/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 324us/step - loss: 0.0034 - val_loss: 0.0041\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 328us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 324us/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 324us/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 330us/step - loss: 0.0031 - val_loss: 0.0049\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 326us/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 328us/step - loss: 0.0031 - val_loss: 0.0054\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 325us/step - loss: 0.0031 - val_loss: 0.0055\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 325us/step - loss: 0.0029 - val_loss: 0.0054\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 325us/step - loss: 0.0029 - val_loss: 0.0053\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 325us/step - loss: 0.0029 - val_loss: 0.0052\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 10s 3ms/step - loss: 0.1245 - val_loss: 0.0201\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 161us/step - loss: 0.0176 - val_loss: 0.0154\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 161us/step - loss: 0.0101 - val_loss: 0.0023\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 164us/step - loss: 0.0044 - val_loss: 0.0026\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 165us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 163us/step - loss: 0.0016 - val_loss: 0.0013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 161us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 161us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 160us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 162us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 161us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 161us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 161us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 160us/step - loss: 9.8695e-04 - val_loss: 0.0010\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 160us/step - loss: 9.2358e-04 - val_loss: 9.5912e-04\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 161us/step - loss: 8.7870e-04 - val_loss: 9.1319e-04\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 161us/step - loss: 8.6010e-04 - val_loss: 9.4075e-04\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 161us/step - loss: 8.3900e-04 - val_loss: 8.6198e-04\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 160us/step - loss: 8.0441e-04 - val_loss: 8.4950e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: 7.8505e-04 - val_loss: 8.3076e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 161us/step - loss: 7.7390e-04 - val_loss: 8.1556e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 161us/step - loss: 7.8492e-04 - val_loss: 8.3841e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 160us/step - loss: 7.6977e-04 - val_loss: 7.9097e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 161us/step - loss: 7.5490e-04 - val_loss: 8.0823e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 10s 3ms/step - loss: 0.0610 - val_loss: 0.0074\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 162us/step - loss: 0.0042 - val_loss: 0.0074\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 164us/step - loss: 0.0028 - val_loss: 0.0072\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 163us/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 163us/step - loss: 0.0022 - val_loss: 0.0062\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 163us/step - loss: 0.0035 - val_loss: 0.0052\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 164us/step - loss: 0.0025 - val_loss: 0.0043\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 163us/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 163us/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 165us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 163us/step - loss: 0.0020 - val_loss: 0.0030\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 163us/step - loss: 0.0017 - val_loss: 0.0056\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 163us/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 164us/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 164us/step - loss: 0.0017 - val_loss: 0.0038\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 164us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 164us/step - loss: 0.0024 - val_loss: 0.0043\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 169us/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 164us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 164us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 163us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 163us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 163us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 165us/step - loss: 0.0010 - val_loss: 0.0021\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 10s 3ms/step - loss: 0.2008 - val_loss: 0.0406\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 160us/step - loss: 0.0698 - val_loss: 0.0312\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: 0.0690 - val_loss: 0.0414\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 160us/step - loss: 0.0690 - val_loss: 0.0393\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 161us/step - loss: 0.0678 - val_loss: 0.0392\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 165us/step - loss: 0.0671 - val_loss: 0.0307\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 162us/step - loss: 0.0670 - val_loss: 0.0427\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 165us/step - loss: 0.0660 - val_loss: 0.0355\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 161us/step - loss: 0.0664 - val_loss: 0.0285\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 161us/step - loss: 0.0654 - val_loss: 0.0447\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 160us/step - loss: 0.0647 - val_loss: 0.0384\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: 0.0639 - val_loss: 0.0308\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 161us/step - loss: 0.0633 - val_loss: 0.0413\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 161us/step - loss: 0.0628 - val_loss: 0.0310\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 165us/step - loss: 0.0624 - val_loss: 0.0333\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 163us/step - loss: 0.0616 - val_loss: 0.0237\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 161us/step - loss: 0.0611 - val_loss: 0.0160\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 161us/step - loss: 0.0611 - val_loss: 0.0213\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 161us/step - loss: 0.0600 - val_loss: 0.0313\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 160us/step - loss: 0.0592 - val_loss: 0.0225\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 160us/step - loss: 0.0589 - val_loss: 0.0307\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 160us/step - loss: 0.0584 - val_loss: 0.0343\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 160us/step - loss: 0.0575 - val_loss: 0.0229\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 161us/step - loss: 0.0570 - val_loss: 0.0285\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 11s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 168us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 161us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 160us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 160us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 161us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 161us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 162us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 160us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 161us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 160us/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 158us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 160us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 163us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 162us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 160us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: nan - val_loss: nan\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 11s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 234us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: nan - val_loss: nan\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 13s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 495us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 499us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 495us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 495us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 497us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 497us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 498us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 498us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 498us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 498us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 494us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 496us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 494us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 499us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 493us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 498us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 497us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 499us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 497us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 496us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 495us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 495us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 498us/step - loss: nan - val_loss: nan\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 13s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 496us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 495us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 495us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 497us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 498us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 497us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 496us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 496us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 497us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 497us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 497us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 495us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 497us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 494us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 495us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 496us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 493us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 496us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 498us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 497us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 499us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 493us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 493us/step - loss: nan - val_loss: nan\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 13s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 501us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 495us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 495us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 496us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 496us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 494us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 495us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 497us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 496us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 494us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 495us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 493us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 496us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 498us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 496us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 498us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 500us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 495us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 495us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 495us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 498us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 495us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 495us/step - loss: nan - val_loss: nan\n",
      "\n",
      "GENERATION 10\n",
      "\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 13s 3ms/step - loss: 0.1331 - val_loss: 0.0037\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 479us/step - loss: 0.0185 - val_loss: 0.0094\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 482us/step - loss: 0.0100 - val_loss: 0.0091\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 479us/step - loss: 0.0067 - val_loss: 0.0068\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 481us/step - loss: 0.0044 - val_loss: 0.0024\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 479us/step - loss: 0.0038 - val_loss: 0.0024\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 477us/step - loss: 0.0035 - val_loss: 0.0027\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 480us/step - loss: 0.0032 - val_loss: 0.0023\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 480us/step - loss: 0.0031 - val_loss: 0.0023\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 481us/step - loss: 0.0029 - val_loss: 0.0025\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 480us/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 482us/step - loss: 0.0027 - val_loss: 0.0021\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 480us/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 479us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 479us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 481us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 480us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 478us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 480us/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 482us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 476us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 479us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 476us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 478us/step - loss: 0.0020 - val_loss: 0.0030\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 13s 3ms/step - loss: 0.1438 - val_loss: 0.0025\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 166us/step - loss: 0.0199 - val_loss: 0.0139\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 165us/step - loss: 0.0086 - val_loss: 0.0030\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 164us/step - loss: 0.0042 - val_loss: 0.0016\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 166us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 165us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 168us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 164us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 165us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 164us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 164us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 164us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 164us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 165us/step - loss: 9.4398e-04 - val_loss: 9.5096e-04\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 166us/step - loss: 9.1609e-04 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 165us/step - loss: 8.6791e-04 - val_loss: 9.4374e-04\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 169us/step - loss: 8.5522e-04 - val_loss: 8.5336e-04\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 167us/step - loss: 8.1830e-04 - val_loss: 9.7891e-04\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 165us/step - loss: 8.2449e-04 - val_loss: 8.0664e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 163us/step - loss: 8.1271e-04 - val_loss: 8.2842e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 164us/step - loss: 8.0659e-04 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 165us/step - loss: 8.1535e-04 - val_loss: 8.1955e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 165us/step - loss: 7.6752e-04 - val_loss: 7.8603e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 165us/step - loss: 7.6338e-04 - val_loss: 7.8625e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 12s 3ms/step - loss: 0.1164 - val_loss: 0.0137\n",
      "Epoch 2/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 1s 262us/step - loss: 0.0108 - val_loss: 0.0017\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 262us/step - loss: 0.0050 - val_loss: 0.0024\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 263us/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 263us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 262us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 262us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 262us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 260us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 263us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 263us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 263us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 260us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 263us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 265us/step - loss: 9.4800e-04 - val_loss: 9.8404e-04\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 263us/step - loss: 9.0513e-04 - val_loss: 9.3905e-04\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 261us/step - loss: 8.5912e-04 - val_loss: 8.6732e-04\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 262us/step - loss: 8.3197e-04 - val_loss: 8.2969e-04\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 262us/step - loss: 8.0147e-04 - val_loss: 8.0984e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 263us/step - loss: 7.8377e-04 - val_loss: 7.9399e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 263us/step - loss: 7.6592e-04 - val_loss: 7.7672e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 262us/step - loss: 7.5595e-04 - val_loss: 7.5058e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 260us/step - loss: 7.4936e-04 - val_loss: 7.6098e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 261us/step - loss: 7.3833e-04 - val_loss: 7.2698e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 13s 3ms/step - loss: 0.1246 - val_loss: 0.0105\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 263us/step - loss: 0.0122 - val_loss: 0.0065\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 264us/step - loss: 0.0068 - val_loss: 0.0024\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 262us/step - loss: 0.0049 - val_loss: 0.0017\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 264us/step - loss: 0.0033 - val_loss: 0.0027\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 265us/step - loss: 0.0027 - val_loss: 0.0012\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 264us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 264us/step - loss: 0.0023 - val_loss: 0.0013\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 265us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 266us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 265us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 265us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 264us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 263us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 264us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 264us/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 264us/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 263us/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 263us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 264us/step - loss: 0.0017 - val_loss: 0.0027\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 262us/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 262us/step - loss: 0.0016 - val_loss: 0.0026\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 263us/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 264us/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 14s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 577us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 573us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 576us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 575us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 573us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 573us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 577us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 577us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 579us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 574us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 576us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 576us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 574us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 577us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 576us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 577us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 576us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 573us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 573us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 576us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 574us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 576us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 576us/step - loss: nan - val_loss: nan\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 15s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 576us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 578us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 575us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 573us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 574us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 574us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 575us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 574us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 576us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 576us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 574us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 575us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 575us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 572us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 575us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 575us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 576us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 576us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 576us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 579us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 574us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 575us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 575us/step - loss: nan - val_loss: nan\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 15s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 545us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 546us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 546us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 546us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 550us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 548us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 546us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 548us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 547us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 548us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 546us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 547us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 547us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 544us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 548us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 547us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 544us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 545us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 551us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 545us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 550us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 545us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 546us/step - loss: nan - val_loss: nan\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 14s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 333us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 332us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 339us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 336us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 334us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 333us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 333us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 334us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 334us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 334us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 335us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 333us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 335us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 340us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 332us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 336us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 332us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 335us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 334us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 334us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 336us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 333us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 334us/step - loss: nan - val_loss: nan\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 15s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 337us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 336us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 346us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 335us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 337us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 342us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 336us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 335us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 336us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 338us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 338us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 338us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 336us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 337us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 335us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 1s 337us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 335us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 336us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 335us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 335us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 336us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 337us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 334us/step - loss: nan - val_loss: nan\n",
      "\n",
      "GENERATION 11\n",
      "\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 14s 4ms/step - loss: 0.1738 - val_loss: 0.0150\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 165us/step - loss: 0.0186 - val_loss: 0.0036\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 165us/step - loss: 0.0081 - val_loss: 0.0020\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 165us/step - loss: 0.0040 - val_loss: 0.0014\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 165us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 165us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 165us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 171us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 164us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 165us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 165us/step - loss: 9.9884e-04 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 165us/step - loss: 9.4487e-04 - val_loss: 9.3168e-04\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 164us/step - loss: 9.0434e-04 - val_loss: 9.0206e-04\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 164us/step - loss: 8.6479e-04 - val_loss: 8.2827e-04\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 165us/step - loss: 8.4309e-04 - val_loss: 8.2183e-04\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 167us/step - loss: 8.1475e-04 - val_loss: 8.1302e-04\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 168us/step - loss: 8.2588e-04 - val_loss: 7.8705e-04\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 164us/step - loss: 8.0020e-04 - val_loss: 8.0644e-04\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 166us/step - loss: 8.1030e-04 - val_loss: 7.6109e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 165us/step - loss: 7.9146e-04 - val_loss: 7.7395e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 165us/step - loss: 7.5290e-04 - val_loss: 8.2064e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 164us/step - loss: 7.5153e-04 - val_loss: 7.2937e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 165us/step - loss: 7.3793e-04 - val_loss: 7.2913e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 164us/step - loss: 7.6441e-04 - val_loss: 7.4578e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 14s 4ms/step - loss: 0.1019 - val_loss: 0.0029\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 263us/step - loss: 0.0141 - val_loss: 0.0019\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 262us/step - loss: 0.0065 - val_loss: 0.0029\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 264us/step - loss: 0.0040 - val_loss: 0.0025\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 266us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 262us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 262us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 264us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 264us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 264us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 263us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 263us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 263us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 265us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 263us/step - loss: 9.7628e-04 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 263us/step - loss: 9.1967e-04 - val_loss: 9.0527e-04\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 263us/step - loss: 8.7717e-04 - val_loss: 9.1023e-04\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 265us/step - loss: 8.5931e-04 - val_loss: 8.8879e-04\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 264us/step - loss: 8.3329e-04 - val_loss: 8.2033e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 266us/step - loss: 8.1075e-04 - val_loss: 8.0203e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 264us/step - loss: 7.9939e-04 - val_loss: 8.2139e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 267us/step - loss: 7.8978e-04 - val_loss: 7.8904e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 263us/step - loss: 7.7069e-04 - val_loss: 7.7089e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 263us/step - loss: 8.0739e-04 - val_loss: 0.0010\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 15s 4ms/step - loss: 0.3470 - val_loss: 0.0071\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 246us/step - loss: 0.0426 - val_loss: 0.0031\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 244us/step - loss: 0.0187 - val_loss: 0.0066\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 243us/step - loss: 0.0076 - val_loss: 0.0057\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 243us/step - loss: 0.0040 - val_loss: 0.0013\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 245us/step - loss: 0.0024 - val_loss: 0.0059\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 243us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 245us/step - loss: 0.0015 - val_loss: 0.0034\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 246us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 245us/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 249us/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 247us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 245us/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 247us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 246us/step - loss: 9.8082e-04 - val_loss: 0.0014\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 245us/step - loss: 9.5980e-04 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 244us/step - loss: 9.4042e-04 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 245us/step - loss: 9.2253e-04 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 247us/step - loss: 9.0838e-04 - val_loss: 0.0010\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 244us/step - loss: 8.9448e-04 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 244us/step - loss: 8.7774e-04 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 244us/step - loss: 8.6515e-04 - val_loss: 0.0010\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 244us/step - loss: 8.5178e-04 - val_loss: 9.2626e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 243us/step - loss: 8.4389e-04 - val_loss: 9.7594e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 15s 4ms/step - loss: 0.4448 - val_loss: 0.0635\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 248us/step - loss: 0.0441 - val_loss: 0.0037\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 247us/step - loss: 0.0197 - val_loss: 0.0110\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 245us/step - loss: 0.0107 - val_loss: 0.0012\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 244us/step - loss: 0.0062 - val_loss: 0.0025\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 247us/step - loss: 0.0040 - val_loss: 0.0021\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 245us/step - loss: 0.0031 - val_loss: 0.0012\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 245us/step - loss: 0.0027 - val_loss: 0.0020\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 247us/step - loss: 0.0025 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 244us/step - loss: 0.0024 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 247us/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 244us/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 245us/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 247us/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 247us/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 244us/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 245us/step - loss: 0.0019 - val_loss: 9.9913e-04\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 245us/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 250us/step - loss: 0.0019 - val_loss: 9.8262e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 246us/step - loss: 0.0018 - val_loss: 9.9317e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 246us/step - loss: 0.0018 - val_loss: 9.4224e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 246us/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 248us/step - loss: 0.0017 - val_loss: 9.2866e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 245us/step - loss: 0.0017 - val_loss: 9.2843e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 15s 4ms/step - loss: 0.5068 - val_loss: 0.0412\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 246us/step - loss: 0.0772 - val_loss: 0.0644\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 246us/step - loss: 0.0299 - val_loss: 0.0145\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 248us/step - loss: 0.0135 - val_loss: 0.0151\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 245us/step - loss: 0.0081 - val_loss: 0.0021\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 247us/step - loss: 0.0053 - val_loss: 0.0050\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 247us/step - loss: 0.0040 - val_loss: 0.0012\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 246us/step - loss: 0.0034 - val_loss: 0.0026\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 251us/step - loss: 0.0031 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 245us/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 244us/step - loss: 0.0026 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 247us/step - loss: 0.0025 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 246us/step - loss: 0.0023 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 248us/step - loss: 0.0023 - val_loss: 0.0010\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 248us/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 248us/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 246us/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 247us/step - loss: 0.0020 - val_loss: 9.8944e-04\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 247us/step - loss: 0.0020 - val_loss: 9.6902e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 247us/step - loss: 0.0019 - val_loss: 9.9458e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 246us/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 248us/step - loss: 0.0018 - val_loss: 9.4281e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 247us/step - loss: 0.0018 - val_loss: 9.5197e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 248us/step - loss: 0.0018 - val_loss: 9.9340e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 15s 4ms/step - loss: 0.1028 - val_loss: 0.0177\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 247us/step - loss: 0.0100 - val_loss: 0.0047\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 249us/step - loss: 0.0066 - val_loss: 0.0063\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 248us/step - loss: 0.0060 - val_loss: 0.0023\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 247us/step - loss: 0.0042 - val_loss: 0.0026\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 246us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 245us/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 249us/step - loss: 0.0040 - val_loss: 0.0022\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 247us/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 246us/step - loss: 0.0048 - val_loss: 0.0045\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 247us/step - loss: 0.0045 - val_loss: 0.0042\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 248us/step - loss: 0.0037 - val_loss: 0.0018\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 246us/step - loss: 0.0031 - val_loss: 0.0038\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 246us/step - loss: 0.0033 - val_loss: 0.0022\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 248us/step - loss: 0.0030 - val_loss: 0.0025\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 251us/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 246us/step - loss: 0.0044 - val_loss: 0.0026\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 247us/step - loss: 0.0034 - val_loss: 0.0048\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 248us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 249us/step - loss: 0.0039 - val_loss: 0.0048\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 247us/step - loss: 0.0036 - val_loss: 0.0025\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 247us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 247us/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 24/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 1s 246us/step - loss: 0.0033 - val_loss: 0.0039\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 16s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 378us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 385us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 377us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 377us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 379us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 378us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 377us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 380us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 376us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 377us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 376us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 376us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 382us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 378us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 380us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 381us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 376us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 377us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 378us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 377us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 378us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 381us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 376us/step - loss: nan - val_loss: nan\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 16s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 377us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 379us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 379us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 380us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 379us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 379us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 379us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 382us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 380us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 379us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 379us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 378us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 377us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 381us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 377us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 376us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 378us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 379us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 380us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 379us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 378us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 378us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 382us/step - loss: nan - val_loss: nan\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 17s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 381us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 382us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 379us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 381us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 378us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 384us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 379us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 379us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 380us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 379us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 378us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 381us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 381us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 380us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 379us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 379us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 378us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 380us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 380us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 379us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 377us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 380us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 378us/step - loss: nan - val_loss: nan\n",
      "\n",
      "GENERATION 12\n",
      "\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 16s 4ms/step - loss: 0.1377 - val_loss: 0.0136\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 166us/step - loss: 0.0170 - val_loss: 0.0170\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 166us/step - loss: 0.0093 - val_loss: 0.0059\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 164us/step - loss: 0.0047 - val_loss: 0.0028\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 166us/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 165us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 165us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 165us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 164us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 163us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 165us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 164us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 163us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 164us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 163us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 162us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 165us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 168us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 166us/step - loss: 9.9532e-04 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 165us/step - loss: 9.6472e-04 - val_loss: 9.9949e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 162us/step - loss: 9.3448e-04 - val_loss: 0.0010\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 164us/step - loss: 9.2650e-04 - val_loss: 9.5441e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 164us/step - loss: 8.8784e-04 - val_loss: 9.4139e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 166us/step - loss: 8.7733e-04 - val_loss: 9.5076e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 16s 4ms/step - loss: 0.1216 - val_loss: 0.0081\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 168us/step - loss: 0.0151 - val_loss: 0.0143\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 168us/step - loss: 0.0074 - val_loss: 0.0061\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 167us/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 166us/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 165us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 171us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 168us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 165us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 166us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 169us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 168us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 168us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 166us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 166us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 166us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 167us/step - loss: 9.6882e-04 - val_loss: 9.8253e-04\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 167us/step - loss: 9.3140e-04 - val_loss: 9.1612e-04\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 166us/step - loss: 8.9662e-04 - val_loss: 8.9121e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 167us/step - loss: 8.8598e-04 - val_loss: 9.7086e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 166us/step - loss: 9.0901e-04 - val_loss: 9.3240e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 167us/step - loss: 8.4129e-04 - val_loss: 8.3562e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 166us/step - loss: 8.1872e-04 - val_loss: 8.3836e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 165us/step - loss: 7.9537e-04 - val_loss: 8.1494e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 18s 5ms/step - loss: 0.0802 - val_loss: 0.0430\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 469us/step - loss: 0.0211 - val_loss: 0.0225\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 471us/step - loss: 0.0088 - val_loss: 0.0077\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 469us/step - loss: 0.0049 - val_loss: 0.0070\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 469us/step - loss: 0.0031 - val_loss: 0.0026\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 472us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 469us/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 470us/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 473us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 471us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 469us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 470us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 470us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 471us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 469us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 471us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 469us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 473us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 471us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 467us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 469us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 474us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 471us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 470us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 18s 5ms/step - loss: 0.1150 - val_loss: 0.0123\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 492us/step - loss: 0.0123 - val_loss: 0.0111\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 493us/step - loss: 0.0117 - val_loss: 0.0110\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 491us/step - loss: 0.0126 - val_loss: 0.0089\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 490us/step - loss: 0.0118 - val_loss: 0.0269\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 492us/step - loss: 0.0113 - val_loss: 0.0136\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 494us/step - loss: 0.0124 - val_loss: 0.0122\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 491us/step - loss: 0.0102 - val_loss: 0.0105\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 493us/step - loss: 0.0104 - val_loss: 0.0043\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 491us/step - loss: 0.0091 - val_loss: 0.0104\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 490us/step - loss: 0.0091 - val_loss: 0.0096\n",
      "Epoch 12/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 2s 490us/step - loss: 0.0088 - val_loss: 0.0120\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 492us/step - loss: 0.0072 - val_loss: 0.0077\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 493us/step - loss: 0.0099 - val_loss: 0.0048\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 494us/step - loss: 0.0054 - val_loss: 0.0098\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 493us/step - loss: 0.0077 - val_loss: 0.0090\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 494us/step - loss: 0.0071 - val_loss: 0.0113\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 493us/step - loss: 0.0067 - val_loss: 0.0047\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 492us/step - loss: 0.0067 - val_loss: 0.0107\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 494us/step - loss: 0.0067 - val_loss: 0.0068\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 495us/step - loss: 0.0054 - val_loss: 0.0062\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 492us/step - loss: 0.0071 - val_loss: 0.0062\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 493us/step - loss: 0.0059 - val_loss: 0.0083\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 496us/step - loss: 0.0051 - val_loss: 0.0092\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 18s 5ms/step - loss: 0.2157 - val_loss: 0.1502\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 493us/step - loss: 0.0513 - val_loss: 0.0068\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 493us/step - loss: 0.0154 - val_loss: 0.0256\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 495us/step - loss: 0.0145 - val_loss: 0.0174\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 492us/step - loss: 0.0136 - val_loss: 0.0275\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 495us/step - loss: 0.0134 - val_loss: 0.0135\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 492us/step - loss: 0.0119 - val_loss: 0.0235\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 494us/step - loss: 0.0090 - val_loss: 0.0296\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 495us/step - loss: 0.0117 - val_loss: 0.0247\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 495us/step - loss: 0.0087 - val_loss: 0.0129\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 496us/step - loss: 0.0090 - val_loss: 0.0152\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 495us/step - loss: 0.0084 - val_loss: 0.0147\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 491us/step - loss: 0.0076 - val_loss: 0.0164\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 493us/step - loss: 0.0094 - val_loss: 0.0173\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 495us/step - loss: 0.0065 - val_loss: 0.0180\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 492us/step - loss: 0.0078 - val_loss: 0.0171\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 495us/step - loss: 0.0063 - val_loss: 0.0155\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 495us/step - loss: 0.0085 - val_loss: 0.0234\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 493us/step - loss: 0.0053 - val_loss: 0.0169\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 496us/step - loss: 0.0054 - val_loss: 0.0238\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 496us/step - loss: 0.0073 - val_loss: 0.0161\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 494us/step - loss: 0.0053 - val_loss: 0.0143\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 494us/step - loss: 0.0068 - val_loss: 0.0131\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 495us/step - loss: 0.0045 - val_loss: 0.0122\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 19s 5ms/step - loss: 0.2589 - val_loss: 0.0045\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 495us/step - loss: 0.0049 - val_loss: 0.0033\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 490us/step - loss: 0.0082 - val_loss: 0.0039\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 491us/step - loss: 0.0101 - val_loss: 0.0053\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 492us/step - loss: 0.0104 - val_loss: 0.0169\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 495us/step - loss: 0.0125 - val_loss: 0.0125\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 494us/step - loss: 0.0124 - val_loss: 0.0260\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 491us/step - loss: 0.0134 - val_loss: 0.0156\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 494us/step - loss: 0.0135 - val_loss: 0.0259\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 491us/step - loss: 0.0116 - val_loss: 0.0066\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 493us/step - loss: 0.0103 - val_loss: 0.0211\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 492us/step - loss: 0.0091 - val_loss: 0.0166\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 495us/step - loss: 0.0110 - val_loss: 0.0161\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 492us/step - loss: 0.0079 - val_loss: 0.0089\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 492us/step - loss: 0.0102 - val_loss: 0.0087\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 494us/step - loss: 0.0065 - val_loss: 0.0078\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 494us/step - loss: 0.0099 - val_loss: 0.0115\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 494us/step - loss: 0.0053 - val_loss: 0.0183\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 490us/step - loss: 0.0078 - val_loss: 0.0082\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 491us/step - loss: 0.0070 - val_loss: 0.0083\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 492us/step - loss: 0.0068 - val_loss: 0.0046\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 491us/step - loss: 0.0048 - val_loss: 0.0154\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 494us/step - loss: 0.0076 - val_loss: 0.0020\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 492us/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 20s 5ms/step - loss: 0.0641 - val_loss: 0.0071\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 545us/step - loss: 0.0073 - val_loss: 0.0028\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 544us/step - loss: 0.0038 - val_loss: 0.0031\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 543us/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 544us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 542us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 543us/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 545us/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 541us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 545us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 546us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 546us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 544us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 544us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 543us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 546us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 17/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 2s 543us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 543us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 545us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 546us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 545us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 541us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 541us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 545us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 19s 5ms/step - loss: 0.9789 - val_loss: 0.0181\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 543us/step - loss: 0.0336 - val_loss: 0.0117\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 542us/step - loss: 0.0149 - val_loss: 0.0171\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 543us/step - loss: 0.0110 - val_loss: 0.0061\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 546us/step - loss: 0.0080 - val_loss: 0.0037\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 543us/step - loss: 0.0056 - val_loss: 0.0021\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 542us/step - loss: 0.0053 - val_loss: 0.0038\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 543us/step - loss: 0.0051 - val_loss: 0.0031\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 543us/step - loss: 0.0047 - val_loss: 0.0023\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 544us/step - loss: 0.0046 - val_loss: 0.0027\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 546us/step - loss: 0.0047 - val_loss: 0.0028\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 542us/step - loss: 0.0046 - val_loss: 0.0024\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 545us/step - loss: 0.0043 - val_loss: 0.0026\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 546us/step - loss: 0.0042 - val_loss: 0.0026\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 540us/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 544us/step - loss: 0.0041 - val_loss: 0.0026\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 542us/step - loss: 0.0042 - val_loss: 0.0027\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 541us/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 544us/step - loss: 0.0040 - val_loss: 0.0026\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 548us/step - loss: 0.0039 - val_loss: 0.0025\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 544us/step - loss: 0.0038 - val_loss: 0.0023\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 544us/step - loss: 0.0039 - val_loss: 0.0025\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 544us/step - loss: 0.0039 - val_loss: 0.0025\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 543us/step - loss: 0.0040 - val_loss: 0.0025\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 19s 5ms/step - loss: 0.0742 - val_loss: 0.0024\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 372us/step - loss: 0.0231 - val_loss: 0.0023\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 372us/step - loss: 0.0178 - val_loss: 0.0023\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 373us/step - loss: 0.0148 - val_loss: 0.0031\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 371us/step - loss: 0.0133 - val_loss: 0.0022\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 374us/step - loss: 0.0123 - val_loss: 0.0021\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 372us/step - loss: 0.0119 - val_loss: 0.0022\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 372us/step - loss: 0.0108 - val_loss: 0.0022\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 376us/step - loss: 0.0100 - val_loss: 0.0023\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 371us/step - loss: 0.0091 - val_loss: 0.0021\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 372us/step - loss: 0.0087 - val_loss: 0.0021\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 372us/step - loss: 0.0085 - val_loss: 0.0021\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 375us/step - loss: 0.0084 - val_loss: 0.0021\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 370us/step - loss: 0.0086 - val_loss: 0.0023\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 373us/step - loss: 0.0077 - val_loss: 0.0021\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 372us/step - loss: 0.0076 - val_loss: 0.0021\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 371us/step - loss: 0.0073 - val_loss: 0.0021\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 371us/step - loss: 0.0072 - val_loss: 0.0021\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 370us/step - loss: 0.0069 - val_loss: 0.0021\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 375us/step - loss: 0.0071 - val_loss: 0.0021\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 372us/step - loss: 0.0069 - val_loss: 0.0021\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 372us/step - loss: 0.0062 - val_loss: 0.0021\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 370us/step - loss: 0.0061 - val_loss: 0.0022\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 371us/step - loss: 0.0064 - val_loss: 0.0021\n",
      "\n",
      "GENERATION 13\n",
      "\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 19s 5ms/step - loss: 0.2552 - val_loss: 0.3091\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 334us/step - loss: 0.1881 - val_loss: 0.2369\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 329us/step - loss: 0.1465 - val_loss: 0.1823\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 329us/step - loss: 0.1181 - val_loss: 0.1426\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 330us/step - loss: 0.0996 - val_loss: 0.1143\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 330us/step - loss: 0.0873 - val_loss: 0.0944\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 331us/step - loss: 0.0793 - val_loss: 0.0798\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 331us/step - loss: 0.0741 - val_loss: 0.0690\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 330us/step - loss: 0.0708 - val_loss: 0.0607\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 331us/step - loss: 0.0684 - val_loss: 0.0544\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 330us/step - loss: 0.0669 - val_loss: 0.0496\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 337us/step - loss: 0.0656 - val_loss: 0.0459\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 329us/step - loss: 0.0650 - val_loss: 0.0431\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 330us/step - loss: 0.0643 - val_loss: 0.0409\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 330us/step - loss: 0.0638 - val_loss: 0.0392\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 331us/step - loss: 0.0634 - val_loss: 0.0380\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 332us/step - loss: 0.0631 - val_loss: 0.0368\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 330us/step - loss: 0.0627 - val_loss: 0.0359\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 330us/step - loss: 0.0624 - val_loss: 0.0351\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 331us/step - loss: 0.0621 - val_loss: 0.0343\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 330us/step - loss: 0.0617 - val_loss: 0.0339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 330us/step - loss: 0.0613 - val_loss: 0.0335\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 330us/step - loss: 0.0609 - val_loss: 0.0329\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 338us/step - loss: 0.0606 - val_loss: 0.0325\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 19s 5ms/step - loss: 0.1586 - val_loss: 0.0042\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 168us/step - loss: 0.0195 - val_loss: 0.0192\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 167us/step - loss: 0.0097 - val_loss: 0.0067\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 166us/step - loss: 0.0042 - val_loss: 0.0029\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 167us/step - loss: 0.0025 - val_loss: 0.0038\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 168us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 169us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 179us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 170us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 169us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 168us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 168us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 169us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 168us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 167us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 168us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 167us/step - loss: 9.7902e-04 - val_loss: 0.0010\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 168us/step - loss: 9.3280e-04 - val_loss: 9.4287e-04\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 167us/step - loss: 8.9846e-04 - val_loss: 9.2245e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 166us/step - loss: 8.7083e-04 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 170us/step - loss: 8.6916e-04 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 168us/step - loss: 8.5674e-04 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 166us/step - loss: 8.7238e-04 - val_loss: 8.6676e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 169us/step - loss: 8.8233e-04 - val_loss: 9.6113e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 19s 5ms/step - loss: 0.0522 - val_loss: 0.0014\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 0.0087 - val_loss: 0.0026\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 0.0055 - val_loss: 0.0081\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 0.0037 - val_loss: 0.0012\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 191us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 193us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 0.0015 - val_loss: 9.5057e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 191us/step - loss: 0.0014 - val_loss: 9.1729e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 0.0013 - val_loss: 8.0036e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 195us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 19s 5ms/step - loss: 0.0998 - val_loss: 0.0556\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 0.0223 - val_loss: 0.0263\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 0.0092 - val_loss: 0.0044\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 0.0060 - val_loss: 0.0080\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 0.0039 - val_loss: 0.0010\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 0.0027 - val_loss: 0.0013\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 191us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 194us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 0.0015 - val_loss: 9.9783e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 19s 5ms/step - loss: 0.0433 - val_loss: 0.0170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 0.0097 - val_loss: 0.0080\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 0.0060 - val_loss: 0.0012\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 0.0046 - val_loss: 0.0013\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 0.0041 - val_loss: 0.0033\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 0.0037 - val_loss: 0.0012\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 0.0032 - val_loss: 0.0017\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 0.0032 - val_loss: 0.0017\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 0.0030 - val_loss: 0.0017\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 0.0029 - val_loss: 0.0017\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 0.0028 - val_loss: 0.0016\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 0.0029 - val_loss: 0.0017\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 0.0027 - val_loss: 0.0016\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 195us/step - loss: 0.0024 - val_loss: 0.0014\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 0.0024 - val_loss: 0.0014\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 21s 5ms/step - loss: 0.0560 - val_loss: 0.0028\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 377us/step - loss: 0.0089 - val_loss: 0.0030\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 377us/step - loss: 0.0062 - val_loss: 0.0051\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 376us/step - loss: 0.0051 - val_loss: 0.0020\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 377us/step - loss: 0.0046 - val_loss: 0.0031\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 377us/step - loss: 0.0040 - val_loss: 0.0023\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 380us/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 378us/step - loss: 0.0038 - val_loss: 0.0024\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 378us/step - loss: 0.0039 - val_loss: 0.0024\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 381us/step - loss: 0.0036 - val_loss: 0.0026\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 379us/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 378us/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 376us/step - loss: 0.0036 - val_loss: 0.0024\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 379us/step - loss: 0.0035 - val_loss: 0.0023\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 376us/step - loss: 0.0035 - val_loss: 0.0023\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 377us/step - loss: 0.0032 - val_loss: 0.0025\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 378us/step - loss: 0.0035 - val_loss: 0.0021\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 377us/step - loss: 0.0033 - val_loss: 0.0023\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 377us/step - loss: 0.0033 - val_loss: 0.0022\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 381us/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 380us/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 378us/step - loss: 0.0030 - val_loss: 0.0024\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 378us/step - loss: 0.0031 - val_loss: 0.0022\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 377us/step - loss: 0.0030 - val_loss: 0.0022\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 21s 5ms/step - loss: 0.0884 - val_loss: 0.0057\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 496us/step - loss: 0.0100 - val_loss: 0.0055\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 496us/step - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 498us/step - loss: 0.0042 - val_loss: 0.0017\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 499us/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 498us/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 496us/step - loss: 0.0031 - val_loss: 0.0025\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 498us/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 498us/step - loss: 0.0029 - val_loss: 0.0023\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 495us/step - loss: 0.0029 - val_loss: 0.0027\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 496us/step - loss: 0.0030 - val_loss: 0.0023\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 497us/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 497us/step - loss: 0.0028 - val_loss: 0.0021\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 500us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 497us/step - loss: 0.0027 - val_loss: 0.0021\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 496us/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 497us/step - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 496us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 496us/step - loss: 0.0026 - val_loss: 0.0021\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 498us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 498us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 494us/step - loss: 0.0026 - val_loss: 0.0020\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 497us/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 499us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 22s 6ms/step - loss: 0.0588 - val_loss: 0.0093\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 496us/step - loss: 0.0097 - val_loss: 0.0058\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 495us/step - loss: 0.0050 - val_loss: 0.0088\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 497us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 496us/step - loss: 0.0030 - val_loss: 0.0046\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 495us/step - loss: 0.0027 - val_loss: 0.0019\n",
      "Epoch 7/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 2s 503us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 498us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 498us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 496us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 499us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 497us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 497us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 494us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 499us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 496us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 499us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 494us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 497us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 496us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 498us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 498us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 497us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 499us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 22s 6ms/step - loss: 0.1772 - val_loss: 0.0250\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 500us/step - loss: 0.0336 - val_loss: 0.2337\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 500us/step - loss: 0.0325 - val_loss: 0.0044\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 501us/step - loss: 0.0556 - val_loss: 0.0039\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 499us/step - loss: 0.0066 - val_loss: 0.0205\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 500us/step - loss: 0.0454 - val_loss: 0.0038\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 500us/step - loss: 0.0293 - val_loss: 0.0155\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 501us/step - loss: 0.0159 - val_loss: 0.0336\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 499us/step - loss: 0.0234 - val_loss: 0.0081\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 501us/step - loss: 0.0242 - val_loss: 0.0089\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 497us/step - loss: 0.0162 - val_loss: 0.0225\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 502us/step - loss: 0.0178 - val_loss: 0.0170\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 500us/step - loss: 0.0176 - val_loss: 0.0174\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 500us/step - loss: 0.0164 - val_loss: 0.0054\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 503us/step - loss: 0.0156 - val_loss: 0.0043\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 501us/step - loss: 0.0136 - val_loss: 0.0106\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 499us/step - loss: 0.0113 - val_loss: 0.0193\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 500us/step - loss: 0.0132 - val_loss: 0.0065\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 499us/step - loss: 0.0124 - val_loss: 0.0031\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 502us/step - loss: 0.0121 - val_loss: 0.0056\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 500us/step - loss: 0.0089 - val_loss: 0.0151\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 500us/step - loss: 0.0103 - val_loss: 0.0103\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 500us/step - loss: 0.0104 - val_loss: 0.0081\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 501us/step - loss: 0.0116 - val_loss: 0.0053\n",
      "\n",
      "GENERATION 14\n",
      "\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 21s 5ms/step - loss: 0.1301 - val_loss: 0.0488\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 168us/step - loss: 0.0192 - val_loss: 0.0202\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 170us/step - loss: 0.0086 - val_loss: 0.0075\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 174us/step - loss: 0.0045 - val_loss: 0.0026\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 168us/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 168us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 168us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 169us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 170us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 170us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 171us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 170us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 169us/step - loss: 9.7041e-04 - val_loss: 0.0010\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 169us/step - loss: 9.3681e-04 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 170us/step - loss: 8.8528e-04 - val_loss: 9.7079e-04\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 169us/step - loss: 8.4781e-04 - val_loss: 8.6012e-04\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 168us/step - loss: 8.2727e-04 - val_loss: 8.4181e-04\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 170us/step - loss: 8.0890e-04 - val_loss: 8.4264e-04\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 168us/step - loss: 8.0644e-04 - val_loss: 8.1097e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 169us/step - loss: 7.8861e-04 - val_loss: 8.0253e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 169us/step - loss: 7.7255e-04 - val_loss: 8.9134e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 170us/step - loss: 8.0967e-04 - val_loss: 8.5197e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 171us/step - loss: 7.9924e-04 - val_loss: 8.6691e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 170us/step - loss: 7.6359e-04 - val_loss: 7.6549e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 21s 5ms/step - loss: 0.0877 - val_loss: 0.0502\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 170us/step - loss: 0.0126 - val_loss: 0.0132\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 169us/step - loss: 0.0058 - val_loss: 0.0086\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 171us/step - loss: 0.0032 - val_loss: 0.0025\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 169us/step - loss: 0.0019 - val_loss: 0.0034\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 171us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 169us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 171us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 169us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 170us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 11/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 1s 169us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 169us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 169us/step - loss: 9.7916e-04 - val_loss: 0.0010\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 170us/step - loss: 9.0297e-04 - val_loss: 9.3985e-04\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 168us/step - loss: 8.4041e-04 - val_loss: 8.2552e-04\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 169us/step - loss: 7.9206e-04 - val_loss: 7.9471e-04\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 171us/step - loss: 7.6442e-04 - val_loss: 7.9525e-04\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 170us/step - loss: 7.5610e-04 - val_loss: 7.5296e-04\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 169us/step - loss: 7.3474e-04 - val_loss: 7.3867e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 169us/step - loss: 7.2105e-04 - val_loss: 7.3152e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 176us/step - loss: 7.2264e-04 - val_loss: 7.8690e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 171us/step - loss: 7.3820e-04 - val_loss: 6.9723e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 170us/step - loss: 7.1859e-04 - val_loss: 7.0015e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 170us/step - loss: 6.9127e-04 - val_loss: 7.1248e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 21s 6ms/step - loss: 0.1482 - val_loss: 0.0544\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 252us/step - loss: 0.0176 - val_loss: 0.0026\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 251us/step - loss: 0.0068 - val_loss: 0.0046\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 252us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 251us/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 252us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 252us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 251us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 251us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 253us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 252us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 250us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 253us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 254us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 252us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 252us/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 254us/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 251us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 252us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 251us/step - loss: 0.0012 - val_loss: 9.4414e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 252us/step - loss: 0.0012 - val_loss: 9.5790e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 252us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 255us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 252us/step - loss: 0.0011 - val_loss: 9.6525e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 21s 5ms/step - loss: 0.0371 - val_loss: 0.0165\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 0.0074 - val_loss: 0.0022\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 0.0035 - val_loss: 0.0021\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 233us/step - loss: 0.0025 - val_loss: 0.0010\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 0.0019 - val_loss: 0.0010\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 0.0014 - val_loss: 9.3572e-04\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 0.0014 - val_loss: 9.1628e-04\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 0.0013 - val_loss: 9.1465e-04\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 0.0013 - val_loss: 9.9459e-04\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 0.0012 - val_loss: 9.7042e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 0.0012 - val_loss: 9.7295e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 0.0012 - val_loss: 9.2012e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 234us/step - loss: 0.0012 - val_loss: 8.5384e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 0.0012 - val_loss: 7.8437e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 0.0012 - val_loss: 7.8697e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 22s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 232us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 232us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 233us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 232us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: nan - val_loss: nan\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 22s 6ms/step - loss: 0.0819 - val_loss: 0.0013\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 0.0028 - val_loss: 0.0012\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 234us/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 232us/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 0.0033 - val_loss: 0.0197\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 0.0196 - val_loss: 0.0189\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 0.0069 - val_loss: 0.0088\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 0.0045 - val_loss: 0.0090\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 0.0050 - val_loss: 0.0140\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 0.0098 - val_loss: 0.0249\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 0.0087 - val_loss: 0.0125\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 0.0049 - val_loss: 0.0052\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 0.0033 - val_loss: 0.0074\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 0.0056 - val_loss: 0.0142\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 0.0088 - val_loss: 0.0112\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 234us/step - loss: 0.0057 - val_loss: 0.0068\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 0.0031 - val_loss: 0.0062\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 0.0047 - val_loss: 0.0156\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 232us/step - loss: 0.0080 - val_loss: 0.0092\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 0.0049 - val_loss: 0.0093\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 235us/step - loss: 0.0057 - val_loss: 0.0093\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 0.0049 - val_loss: 0.0112\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 0.0052 - val_loss: 0.0083\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 0.0042 - val_loss: 0.0077\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 24s 6ms/step - loss: 0.1183 - val_loss: 0.0495\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 479us/step - loss: 0.0674 - val_loss: 0.0367\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 481us/step - loss: 0.0665 - val_loss: 0.0371\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 481us/step - loss: 0.0659 - val_loss: 0.0361\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 483us/step - loss: 0.0651 - val_loss: 0.0312\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 481us/step - loss: 0.0641 - val_loss: 0.0327\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 480us/step - loss: 0.0627 - val_loss: 0.0353\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 482us/step - loss: 0.0607 - val_loss: 0.0308\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 481us/step - loss: 0.0576 - val_loss: 0.0288\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 481us/step - loss: 0.0517 - val_loss: 0.0159\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 482us/step - loss: 0.0386 - val_loss: 0.0084\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 479us/step - loss: 0.0229 - val_loss: 0.0042\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 486us/step - loss: 0.0149 - val_loss: 0.0092\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 482us/step - loss: 0.0123 - val_loss: 0.0174\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 481us/step - loss: 0.0125 - val_loss: 0.0203\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 484us/step - loss: 0.0142 - val_loss: 0.0201\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 480us/step - loss: 0.0121 - val_loss: 0.0211\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 482us/step - loss: 0.0110 - val_loss: 0.0206\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 481us/step - loss: 0.0107 - val_loss: 0.0224\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 482us/step - loss: 0.0106 - val_loss: 0.0223\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 484us/step - loss: 0.0107 - val_loss: 0.0230\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 483us/step - loss: 0.0096 - val_loss: 0.0277\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 481us/step - loss: 0.0154 - val_loss: 0.0369\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 484us/step - loss: 0.0125 - val_loss: 0.0247\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 24s 6ms/step - loss: 1.9315 - val_loss: 0.0169\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 524us/step - loss: 0.0255 - val_loss: 0.0084\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 524us/step - loss: 0.0132 - val_loss: 0.0037\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 519us/step - loss: 0.0082 - val_loss: 0.0023\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 521us/step - loss: 0.0065 - val_loss: 0.0022\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 520us/step - loss: 0.0059 - val_loss: 0.0023\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 522us/step - loss: 0.0054 - val_loss: 0.0022\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 524us/step - loss: 0.0053 - val_loss: 0.0024\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 524us/step - loss: 0.0049 - val_loss: 0.0026\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 525us/step - loss: 0.0050 - val_loss: 0.0026\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 531us/step - loss: 0.0050 - val_loss: 0.0029\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 523us/step - loss: 0.0048 - val_loss: 0.0024\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 524us/step - loss: 0.0047 - val_loss: 0.0023\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 523us/step - loss: 0.0047 - val_loss: 0.0027\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 522us/step - loss: 0.0047 - val_loss: 0.0024\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 523us/step - loss: 0.0043 - val_loss: 0.0024\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 523us/step - loss: 0.0046 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 521us/step - loss: 0.0044 - val_loss: 0.0022\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 524us/step - loss: 0.0044 - val_loss: 0.0027\n",
      "Epoch 20/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 2s 523us/step - loss: 0.0043 - val_loss: 0.0023\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 523us/step - loss: 0.0042 - val_loss: 0.0023\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 523us/step - loss: 0.0041 - val_loss: 0.0022\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 523us/step - loss: 0.0042 - val_loss: 0.0023\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 521us/step - loss: 0.0041 - val_loss: 0.0023\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 25s 6ms/step - loss: 1.6166 - val_loss: 1.2330\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 522us/step - loss: 0.6451 - val_loss: 0.5061\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 523us/step - loss: 0.2355 - val_loss: 0.1825\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 525us/step - loss: 0.0957 - val_loss: 0.0575\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 524us/step - loss: 0.0686 - val_loss: 0.0212\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 523us/step - loss: 0.0722 - val_loss: 0.0142\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 525us/step - loss: 0.0738 - val_loss: 0.0169\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 521us/step - loss: 0.0711 - val_loss: 0.0243\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 522us/step - loss: 0.0685 - val_loss: 0.0327\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 522us/step - loss: 0.0679 - val_loss: 0.0388\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 520us/step - loss: 0.0679 - val_loss: 0.0406\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 522us/step - loss: 0.0679 - val_loss: 0.0393\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 523us/step - loss: 0.0678 - val_loss: 0.0377\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 522us/step - loss: 0.0678 - val_loss: 0.0365\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 526us/step - loss: 0.0678 - val_loss: 0.0358\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 523us/step - loss: 0.0678 - val_loss: 0.0361\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 522us/step - loss: 0.0678 - val_loss: 0.0357\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 522us/step - loss: 0.0678 - val_loss: 0.0368\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 528us/step - loss: 0.0678 - val_loss: 0.0370\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 522us/step - loss: 0.0678 - val_loss: 0.0373\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 525us/step - loss: 0.0678 - val_loss: 0.0373\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 523us/step - loss: 0.0678 - val_loss: 0.0365\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 527us/step - loss: 0.0678 - val_loss: 0.0364\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 522us/step - loss: 0.0678 - val_loss: 0.0366\n",
      "\n",
      "GENERATION 15\n",
      "\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 25s 6ms/step - loss: 0.1287 - val_loss: 0.0108\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 474us/step - loss: 0.0162 - val_loss: 0.0062\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 474us/step - loss: 0.0079 - val_loss: 0.0062\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 470us/step - loss: 0.0044 - val_loss: 0.0036\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 471us/step - loss: 0.0029 - val_loss: 0.0056\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 472us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 473us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 470us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 474us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 473us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 471us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 476us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 475us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 472us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 473us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 472us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 473us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 474us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 473us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 473us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 476us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 475us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 472us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 476us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 24s 6ms/step - loss: 0.1265 - val_loss: 0.0167\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 173us/step - loss: 0.0202 - val_loss: 0.0144\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 174us/step - loss: 0.0099 - val_loss: 0.0022\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 175us/step - loss: 0.0041 - val_loss: 0.0016\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 171us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 170us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 170us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 173us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 178us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 176us/step - loss: 9.9088e-04 - val_loss: 9.8553e-04\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 178us/step - loss: 9.2078e-04 - val_loss: 9.1988e-04\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 173us/step - loss: 8.6465e-04 - val_loss: 9.0472e-04\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 171us/step - loss: 8.2865e-04 - val_loss: 8.4205e-04\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 171us/step - loss: 8.0896e-04 - val_loss: 8.2555e-04\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 171us/step - loss: 8.6336e-04 - val_loss: 8.6005e-04\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 172us/step - loss: 8.8278e-04 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 172us/step - loss: 8.3563e-04 - val_loss: 8.3236e-04\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 170us/step - loss: 8.0322e-04 - val_loss: 9.1975e-04\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 171us/step - loss: 7.8798e-04 - val_loss: 7.7477e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 176us/step - loss: 7.9485e-04 - val_loss: 7.6346e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 176us/step - loss: 7.5259e-04 - val_loss: 7.6619e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 172us/step - loss: 7.3665e-04 - val_loss: 7.4831e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 174us/step - loss: 7.3878e-04 - val_loss: 8.4171e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 172us/step - loss: 7.4088e-04 - val_loss: 7.4498e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 24s 6ms/step - loss: 0.0768 - val_loss: 0.0266\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 172us/step - loss: 0.0104 - val_loss: 0.0062\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 176us/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 173us/step - loss: 0.0025 - val_loss: 0.0015\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 172us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 171us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 172us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 172us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 173us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 172us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 172us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 173us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 173us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 173us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 173us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 180us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 170us/step - loss: 9.9466e-04 - val_loss: 0.0010\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 172us/step - loss: 9.7509e-04 - val_loss: 9.9643e-04\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 173us/step - loss: 9.6003e-04 - val_loss: 9.7834e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 171us/step - loss: 8.9979e-04 - val_loss: 0.0010\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 173us/step - loss: 8.5981e-04 - val_loss: 9.0482e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 172us/step - loss: 8.3811e-04 - val_loss: 8.8509e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 172us/step - loss: 8.1571e-04 - val_loss: 8.4672e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 171us/step - loss: 7.8795e-04 - val_loss: 7.9709e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 25s 6ms/step - loss: 0.2017 - val_loss: 0.0034\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 336us/step - loss: 0.0310 - val_loss: 0.0345\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 336us/step - loss: 0.0178 - val_loss: 0.0128\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 336us/step - loss: 0.0094 - val_loss: 0.0066\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 337us/step - loss: 0.0058 - val_loss: 0.0032\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 338us/step - loss: 0.0044 - val_loss: 0.0032\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 340us/step - loss: 0.0040 - val_loss: 0.0033\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 334us/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 337us/step - loss: 0.0034 - val_loss: 0.0025\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 338us/step - loss: 0.0031 - val_loss: 0.0026\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 336us/step - loss: 0.0033 - val_loss: 0.0029\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 338us/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 340us/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 343us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 338us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 337us/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 338us/step - loss: 0.0025 - val_loss: 0.0042\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 338us/step - loss: 0.0026 - val_loss: 0.0040\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 339us/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 338us/step - loss: 0.0025 - val_loss: 0.0044\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 337us/step - loss: 0.0023 - val_loss: 0.0052\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 337us/step - loss: 0.0023 - val_loss: 0.0056\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 338us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 338us/step - loss: 0.0022 - val_loss: 0.0057\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 26s 7ms/step - loss: 0.2139 - val_loss: 0.0040\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 512us/step - loss: 0.0375 - val_loss: 0.0332\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 512us/step - loss: 0.0154 - val_loss: 0.0029\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 514us/step - loss: 0.0065 - val_loss: 0.0116\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 511us/step - loss: 0.0047 - val_loss: 0.0030\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 511us/step - loss: 0.0038 - val_loss: 0.0027\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 513us/step - loss: 0.0034 - val_loss: 0.0025\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 512us/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 513us/step - loss: 0.0031 - val_loss: 0.0025\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 512us/step - loss: 0.0029 - val_loss: 0.0024\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 513us/step - loss: 0.0030 - val_loss: 0.0023\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 514us/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 512us/step - loss: 0.0027 - val_loss: 0.0022\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 512us/step - loss: 0.0026 - val_loss: 0.0021\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 512us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 511us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 511us/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 512us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 514us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 514us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 515us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 513us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 515us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 516us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 27s 7ms/step - loss: 0.0947 - val_loss: 0.0283\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 512us/step - loss: 0.0148 - val_loss: 0.0114\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 509us/step - loss: 0.0075 - val_loss: 0.0024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 510us/step - loss: 0.0044 - val_loss: 0.0037\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 509us/step - loss: 0.0039 - val_loss: 0.0031\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 513us/step - loss: 0.0034 - val_loss: 0.0026\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 510us/step - loss: 0.0032 - val_loss: 0.0027\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 510us/step - loss: 0.0029 - val_loss: 0.0025\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 507us/step - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 508us/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 510us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 510us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 509us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 511us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 510us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 512us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 510us/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 512us/step - loss: 0.0021 - val_loss: 0.0036\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 508us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 508us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 509us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 512us/step - loss: 0.0020 - val_loss: 0.0034\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 510us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 510us/step - loss: 0.0021 - val_loss: 0.0035\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 27s 7ms/step - loss: 0.1055 - val_loss: 0.0044\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 377us/step - loss: 0.0146 - val_loss: 0.0028\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 378us/step - loss: 0.0068 - val_loss: 0.0031\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 377us/step - loss: 0.0042 - val_loss: 0.0054\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 378us/step - loss: 0.0035 - val_loss: 0.0023\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 375us/step - loss: 0.0031 - val_loss: 0.0026\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 377us/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 378us/step - loss: 0.0027 - val_loss: 0.0022\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 380us/step - loss: 0.0026 - val_loss: 0.0021\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 376us/step - loss: 0.0026 - val_loss: 0.0021\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 380us/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 379us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 378us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 376us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 376us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 377us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 377us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 376us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 376us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 379us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 378us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 379us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 375us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 375us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 27s 7ms/step - loss: 0.0875 - val_loss: 0.0300\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 381us/step - loss: 0.0179 - val_loss: 0.0131\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 380us/step - loss: 0.0088 - val_loss: 0.0050\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 380us/step - loss: 0.0053 - val_loss: 0.0071\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 383us/step - loss: 0.0043 - val_loss: 0.0019\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 379us/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 381us/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 380us/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 380us/step - loss: 0.0031 - val_loss: 0.0024\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 383us/step - loss: 0.0028 - val_loss: 0.0020\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 383us/step - loss: 0.0029 - val_loss: 0.0024\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 379us/step - loss: 0.0029 - val_loss: 0.0023\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 383us/step - loss: 0.0028 - val_loss: 0.0019\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 383us/step - loss: 0.0027 - val_loss: 0.0019\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 382us/step - loss: 0.0027 - val_loss: 0.0019\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 380us/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 380us/step - loss: 0.0026 - val_loss: 0.0020\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 381us/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 382us/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 380us/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 384us/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 387us/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 381us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 381us/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 28s 7ms/step - loss: 0.0510 - val_loss: 0.0076\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 524us/step - loss: 0.0074 - val_loss: 0.0021\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 525us/step - loss: 0.0048 - val_loss: 0.0097\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 523us/step - loss: 0.0038 - val_loss: 0.0017\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 522us/step - loss: 0.0032 - val_loss: 0.0025\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 521us/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 526us/step - loss: 0.0027 - val_loss: 0.0020\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 521us/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 9/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 2s 523us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 523us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 523us/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 523us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 521us/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 523us/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 525us/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 523us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 526us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 527us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 524us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 522us/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 521us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 526us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 524us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 527us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "\n",
      "GENERATION 16\n",
      "\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 27s 7ms/step - loss: 0.1011 - val_loss: 0.0030\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 177us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 178us/step - loss: 0.0067 - val_loss: 0.0016\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 178us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 0.0045 - val_loss: 0.0124\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 177us/step - loss: 0.0041 - val_loss: 0.0029\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 178us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 180us/step - loss: 0.0029 - val_loss: 0.0076\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 180us/step - loss: 0.0056 - val_loss: 0.0020\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 178us/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 177us/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 177us/step - loss: 0.0045 - val_loss: 0.0037\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 178us/step - loss: 0.0027 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 180us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 176us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 177us/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 180us/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 181us/step - loss: 0.0024 - val_loss: 0.0014\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 177us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 178us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 177us/step - loss: 0.0028 - val_loss: 0.0018\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 178us/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 178us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 177us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 26s 7ms/step - loss: 0.1451 - val_loss: 0.0025\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 173us/step - loss: 0.0200 - val_loss: 0.0081\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 174us/step - loss: 0.0118 - val_loss: 0.0022\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 175us/step - loss: 0.0047 - val_loss: 0.0023\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 174us/step - loss: 0.0027 - val_loss: 0.0015\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 174us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 176us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 176us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 172us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 174us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 175us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 174us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 174us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 176us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 174us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 173us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 175us/step - loss: 9.8588e-04 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 175us/step - loss: 9.3646e-04 - val_loss: 0.0010\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 175us/step - loss: 9.1206e-04 - val_loss: 8.9278e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 175us/step - loss: 8.6100e-04 - val_loss: 8.7653e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 181us/step - loss: 8.3436e-04 - val_loss: 8.4913e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 176us/step - loss: 8.0556e-04 - val_loss: 8.1392e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 174us/step - loss: 7.9889e-04 - val_loss: 8.4378e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 173us/step - loss: 7.9012e-04 - val_loss: 8.4036e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 28s 7ms/step - loss: 0.1394 - val_loss: 0.0411\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 331us/step - loss: 0.0307 - val_loss: 0.0237\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 329us/step - loss: 0.0134 - val_loss: 0.0100\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 329us/step - loss: 0.0058 - val_loss: 0.0028\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 328us/step - loss: 0.0034 - val_loss: 0.0028\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 328us/step - loss: 0.0030 - val_loss: 0.0054\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 326us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 328us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 328us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 329us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 331us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 328us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 328us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 329us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 328us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 328us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 328us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 328us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 327us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 328us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 332us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 327us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 335us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 327us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 27s 7ms/step - loss: 0.1184 - val_loss: 0.0219\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 328us/step - loss: 0.0188 - val_loss: 0.0029\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 329us/step - loss: 0.0074 - val_loss: 0.0050\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 328us/step - loss: 0.0049 - val_loss: 0.0080\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 327us/step - loss: 0.0033 - val_loss: 0.0055\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 328us/step - loss: 0.0029 - val_loss: 0.0026\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 329us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 330us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 326us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 326us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 327us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 334us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 327us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 329us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 330us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 330us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 329us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 332us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 327us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 327us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 329us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 327us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 328us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 335us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 29s 7ms/step - loss: 0.2195 - val_loss: 0.0729\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 330us/step - loss: 0.0469 - val_loss: 0.0330\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 329us/step - loss: 0.0225 - val_loss: 0.0156\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 328us/step - loss: 0.0066 - val_loss: 0.0033\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 329us/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 328us/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 329us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 329us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 329us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 329us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 333us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 334us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 329us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 328us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 328us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 329us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 329us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 329us/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 330us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 330us/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 332us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 330us/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 333us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 332us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 29s 8ms/step - loss: 0.1000 - val_loss: 0.0379\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 528us/step - loss: 0.0157 - val_loss: 0.0122\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 525us/step - loss: 0.0071 - val_loss: 0.0037\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 528us/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 525us/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 528us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 530us/step - loss: 0.0025 - val_loss: 0.0041\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 526us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 525us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 530us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 529us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 527us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 528us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 529us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 530us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 529us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 526us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 18/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 2s 525us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 532us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 525us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 526us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 529us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 524us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 526us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 30s 8ms/step - loss: 0.0853 - val_loss: 0.0175\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 528us/step - loss: 0.0093 - val_loss: 0.0073\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 528us/step - loss: 0.0052 - val_loss: 0.0060\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 529us/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 528us/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 530us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 529us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 529us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 529us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 528us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 527us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 531us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 527us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 527us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 526us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 526us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 529us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 528us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 524us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 529us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 528us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 527us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 527us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 525us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 29s 8ms/step - loss: 0.0733 - val_loss: 0.0139\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 405us/step - loss: 0.0069 - val_loss: 0.0031\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 399us/step - loss: 0.0031 - val_loss: 0.0025\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 398us/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 397us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 397us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 398us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 399us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 403us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 398us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 399us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 402us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 398us/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 397us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 398us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 398us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 397us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 397us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 397us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 398us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 398us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 398us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 401us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 400us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 30s 8ms/step - loss: 0.0557 - val_loss: 0.0029\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 397us/step - loss: 0.0047 - val_loss: 0.0173\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 395us/step - loss: 0.0100 - val_loss: 0.0158\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 397us/step - loss: 0.0100 - val_loss: 0.0101\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 400us/step - loss: 0.0083 - val_loss: 0.0074\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 400us/step - loss: 0.0086 - val_loss: 0.0082\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 398us/step - loss: 0.0062 - val_loss: 0.0091\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 395us/step - loss: 0.0074 - val_loss: 0.0053\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 398us/step - loss: 0.0049 - val_loss: 0.0088\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 398us/step - loss: 0.0076 - val_loss: 0.0050\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 397us/step - loss: 0.0052 - val_loss: 0.0050\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 397us/step - loss: 0.0057 - val_loss: 0.0059\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 399us/step - loss: 0.0061 - val_loss: 0.0046\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 397us/step - loss: 0.0039 - val_loss: 0.0069\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 398us/step - loss: 0.0061 - val_loss: 0.0056\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 400us/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 397us/step - loss: 0.0044 - val_loss: 0.0054\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 403us/step - loss: 0.0055 - val_loss: 0.0016\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 397us/step - loss: 0.0033 - val_loss: 0.0057\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 398us/step - loss: 0.0052 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 397us/step - loss: 0.0026 - val_loss: 0.0058\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 398us/step - loss: 0.0050 - val_loss: 0.0033\n",
      "Epoch 23/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 2s 396us/step - loss: 0.0030 - val_loss: 0.0038\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 397us/step - loss: 0.0046 - val_loss: 0.0015\n",
      "\n",
      "GENERATION 17\n",
      "\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 32s 8ms/step - loss: 0.1583 - val_loss: 0.0923\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 368us/step - loss: 0.0260 - val_loss: 0.0107\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 367us/step - loss: 0.0085 - val_loss: 0.0025\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 370us/step - loss: 0.0046 - val_loss: 0.0069\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 370us/step - loss: 0.0031 - val_loss: 0.0026\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 375us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 369us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 377us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 371us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 367us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 369us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 365us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 354us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 373us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 368us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 371us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 369us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 370us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 377us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 371us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 369us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 364us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 352us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 337us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 32s 8ms/step - loss: 0.2205 - val_loss: 0.0862\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 209us/step - loss: 0.0265 - val_loss: 0.0022\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 210us/step - loss: 0.0100 - val_loss: 0.0017\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 212us/step - loss: 0.0045 - val_loss: 0.0015\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 213us/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 203us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 200us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 199us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 194us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 212us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 212us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 214us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 212us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 208us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 209us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 206us/step - loss: 9.6579e-04 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 210us/step - loss: 9.4277e-04 - val_loss: 9.4056e-04\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 211us/step - loss: 9.0193e-04 - val_loss: 9.1191e-04\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 211us/step - loss: 8.5165e-04 - val_loss: 9.5359e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 210us/step - loss: 8.3604e-04 - val_loss: 8.4769e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 210us/step - loss: 8.2421e-04 - val_loss: 8.4335e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 210us/step - loss: 8.2699e-04 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 8.1710e-04 - val_loss: 8.3177e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 211us/step - loss: 8.1776e-04 - val_loss: 8.1921e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 34s 9ms/step - loss: 0.0646 - val_loss: 0.0258\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 383us/step - loss: 0.0156 - val_loss: 0.0065\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 381us/step - loss: 0.0078 - val_loss: 0.0083\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 381us/step - loss: 0.0054 - val_loss: 0.0057\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 380us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 384us/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 366us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 367us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 378us/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 381us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 384us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 379us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 357us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 362us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 382us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 384us/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 380us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 383us/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 388us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 383us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 382us/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 387us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 379us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 369us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 35s 9ms/step - loss: 0.0689 - val_loss: 0.0028\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 605us/step - loss: 0.0163 - val_loss: 0.0027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 597us/step - loss: 0.0067 - val_loss: 0.0259\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 598us/step - loss: 0.0112 - val_loss: 0.0038\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 602us/step - loss: 0.0093 - val_loss: 0.0047\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 603us/step - loss: 0.0145 - val_loss: 0.0075\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 586us/step - loss: 0.0050 - val_loss: 0.0028\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 584us/step - loss: 0.0084 - val_loss: 0.0110\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 599us/step - loss: 0.0087 - val_loss: 0.0022\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 596us/step - loss: 0.0043 - val_loss: 0.0068\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 601us/step - loss: 0.0095 - val_loss: 0.0020\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 604us/step - loss: 0.0041 - val_loss: 0.0021\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 596us/step - loss: 0.0107 - val_loss: 0.0029\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 583us/step - loss: 0.0032 - val_loss: 0.0040\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 580us/step - loss: 0.0038 - val_loss: 0.0552\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 601us/step - loss: 0.0096 - val_loss: 0.0047\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 597us/step - loss: 0.0024 - val_loss: 0.0177\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 592us/step - loss: 0.0064 - val_loss: 0.0110\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 599us/step - loss: 0.0051 - val_loss: 0.0084\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 602us/step - loss: 0.0048 - val_loss: 0.0204\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 600us/step - loss: 0.0057 - val_loss: 0.0047\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 591us/step - loss: 0.0031 - val_loss: 0.0193\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 602us/step - loss: 0.0058 - val_loss: 0.0095\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 600us/step - loss: 0.0030 - val_loss: 0.0152\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 33s 8ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 560us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 556us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 558us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 554us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 553us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 557us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 554us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 554us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 556us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 554us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 555us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 555us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 554us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 553us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 555us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 558us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 554us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 553us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 555us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 556us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 554us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 555us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 559us/step - loss: nan - val_loss: nan\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 33s 9ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 557us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 562us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 557us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 555us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 558us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 555us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 558us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 560us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 562us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 556us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 556us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 560us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 558us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 557us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 557us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 560us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 561us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 557us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 559us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 557us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 558us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 556us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 557us/step - loss: nan - val_loss: nan\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 34s 9ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 560us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 562us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 558us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 559us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 561us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 558us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 559us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 562us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 559us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 558us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 557us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 558us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 557us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 557us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 557us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 556us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 561us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 557us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 557us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 558us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 557us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 559us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 558us/step - loss: nan - val_loss: nan\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 34s 9ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 561us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 562us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 554us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 561us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 557us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 559us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 559us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 558us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 559us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 554us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 559us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 559us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 561us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 560us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 557us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 558us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 561us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 557us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 557us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 560us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 559us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 557us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 560us/step - loss: nan - val_loss: nan\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 34s 9ms/step - loss: 1.0551 - val_loss: 0.0042\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 560us/step - loss: 0.0592 - val_loss: 0.0041\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 559us/step - loss: 0.0295 - val_loss: 0.0083\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 555us/step - loss: 0.0087 - val_loss: 0.0073\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 555us/step - loss: 0.0061 - val_loss: 0.0035\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 558us/step - loss: 0.0116 - val_loss: 0.0034\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 556us/step - loss: 0.0060 - val_loss: 0.0060\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 557us/step - loss: 0.0049 - val_loss: 0.0064\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 556us/step - loss: 0.0045 - val_loss: 0.0063\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 558us/step - loss: 0.0046 - val_loss: 0.0087\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 556us/step - loss: 0.0044 - val_loss: 0.0057\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 555us/step - loss: 0.0041 - val_loss: 0.0090\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 558us/step - loss: 0.0046 - val_loss: 0.0154\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 554us/step - loss: 0.0062 - val_loss: 0.0102\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 557us/step - loss: 0.0041 - val_loss: 0.0049\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 556us/step - loss: 0.0036 - val_loss: 0.0043\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 557us/step - loss: 0.0037 - val_loss: 0.0043\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 556us/step - loss: 0.0036 - val_loss: 0.0061\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 557us/step - loss: 0.0034 - val_loss: 0.0057\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 559us/step - loss: 0.0037 - val_loss: 0.0076\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 554us/step - loss: 0.0038 - val_loss: 0.0066\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 561us/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 558us/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 556us/step - loss: 0.0031 - val_loss: 0.0037\n",
      "\n",
      "GENERATION 18\n",
      "\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 33s 9ms/step - loss: 0.0853 - val_loss: 0.0269\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 178us/step - loss: 0.0123 - val_loss: 0.0133\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 179us/step - loss: 0.0068 - val_loss: 0.0050\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 181us/step - loss: 0.0043 - val_loss: 0.0033\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 177us/step - loss: 0.0032 - val_loss: 0.0017\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 177us/step - loss: 0.0026 - val_loss: 0.0015\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 177us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 177us/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 176us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 178us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 178us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 177us/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 178us/step - loss: 0.0015 - val_loss: 0.0030\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 179us/step - loss: 0.0015 - val_loss: 0.0030\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 178us/step - loss: 0.0014 - val_loss: 0.0031\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 177us/step - loss: 0.0014 - val_loss: 0.0035\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 179us/step - loss: 0.0013 - val_loss: 0.0045\n",
      "Epoch 18/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 1s 179us/step - loss: 0.0013 - val_loss: 0.0054\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 178us/step - loss: 0.0012 - val_loss: 0.0057\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 178us/step - loss: 0.0012 - val_loss: 0.0056\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 177us/step - loss: 0.0012 - val_loss: 0.0065\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 179us/step - loss: 0.0011 - val_loss: 0.0049\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 178us/step - loss: 0.0012 - val_loss: 0.0078\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 178us/step - loss: 0.0011 - val_loss: 0.0065\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 33s 9ms/step - loss: 0.0799 - val_loss: 0.0465\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 180us/step - loss: 0.0126 - val_loss: 0.0159\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 179us/step - loss: 0.0066 - val_loss: 0.0070\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 180us/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 179us/step - loss: 0.0019 - val_loss: 0.0033\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 181us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 179us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 181us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 179us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 180us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 179us/step - loss: 9.8807e-04 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 179us/step - loss: 9.4159e-04 - val_loss: 0.0014\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 181us/step - loss: 9.6080e-04 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 179us/step - loss: 9.1087e-04 - val_loss: 8.8234e-04\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 181us/step - loss: 8.4606e-04 - val_loss: 8.0991e-04\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 179us/step - loss: 8.0304e-04 - val_loss: 8.1314e-04\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 179us/step - loss: 7.6429e-04 - val_loss: 7.7257e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 180us/step - loss: 7.4042e-04 - val_loss: 7.5184e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 180us/step - loss: 7.2269e-04 - val_loss: 7.2296e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 181us/step - loss: 7.1106e-04 - val_loss: 7.2647e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 180us/step - loss: 7.0845e-04 - val_loss: 7.0553e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 180us/step - loss: 7.0803e-04 - val_loss: 6.9165e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 34s 9ms/step - loss: 0.1693 - val_loss: 0.0363\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 279us/step - loss: 0.0203 - val_loss: 0.0066\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 277us/step - loss: 0.0062 - val_loss: 0.0027\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 276us/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 282us/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 276us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 277us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 277us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 277us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 277us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 276us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 283us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 278us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 278us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 277us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 277us/step - loss: 9.5913e-04 - val_loss: 9.8406e-04\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 277us/step - loss: 9.1859e-04 - val_loss: 9.5566e-04\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 280us/step - loss: 8.8012e-04 - val_loss: 9.2305e-04\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 279us/step - loss: 8.5605e-04 - val_loss: 9.0505e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 281us/step - loss: 8.3260e-04 - val_loss: 8.7496e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 276us/step - loss: 8.1011e-04 - val_loss: 8.4073e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 278us/step - loss: 8.0729e-04 - val_loss: 8.3973e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 278us/step - loss: 8.0125e-04 - val_loss: 8.2826e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 278us/step - loss: 8.0224e-04 - val_loss: 8.0800e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 34s 9ms/step - loss: 0.1388 - val_loss: 0.0690\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 0.0173 - val_loss: 0.0097\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 0.0063 - val_loss: 0.0024\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 0.0038 - val_loss: 0.0018\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 0.0027 - val_loss: 0.0016\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 222us/step - loss: 0.0014 - val_loss: 9.9980e-04\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 0.0014 - val_loss: 9.7793e-04\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 0.0012 - val_loss: 9.8691e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 0.0012 - val_loss: 9.3284e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 35s 9ms/step - loss: 0.2024 - val_loss: 0.0203\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 0.0246 - val_loss: 0.0173\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 0.0138 - val_loss: 0.0023\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 0.0038 - val_loss: 0.0016\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 222us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 0.0014 - val_loss: 9.9509e-04\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 0.0014 - val_loss: 9.7501e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 0.0013 - val_loss: 9.6644e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 0.0012 - val_loss: 9.1413e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 0.0012 - val_loss: 8.5495e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 36s 9ms/step - loss: 0.2510 - val_loss: 0.2636\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 440us/step - loss: 0.1067 - val_loss: 0.0075\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 443us/step - loss: 0.0709 - val_loss: 0.0380\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 440us/step - loss: 0.0561 - val_loss: 0.0165\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 441us/step - loss: 0.0259 - val_loss: 0.0178\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 441us/step - loss: 0.0330 - val_loss: 0.0046\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 441us/step - loss: 0.0179 - val_loss: 0.0105\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 442us/step - loss: 0.0079 - val_loss: 0.0111\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 442us/step - loss: 0.0059 - val_loss: 0.0089\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 443us/step - loss: 0.0043 - val_loss: 0.0036\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 442us/step - loss: 0.0035 - val_loss: 0.0027\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 442us/step - loss: 0.0031 - val_loss: 0.0027\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 442us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 442us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 441us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 444us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 442us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 441us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 441us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 444us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 442us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 442us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 443us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 442us/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 37s 9ms/step - loss: 0.1351 - val_loss: 0.0099\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 439us/step - loss: 0.0187 - val_loss: 0.0080\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 444us/step - loss: 0.0102 - val_loss: 0.0081\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 440us/step - loss: 0.0068 - val_loss: 0.0047\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 439us/step - loss: 0.0050 - val_loss: 0.0036\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 441us/step - loss: 0.0044 - val_loss: 0.0028\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 440us/step - loss: 0.0040 - val_loss: 0.0023\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 442us/step - loss: 0.0037 - val_loss: 0.0022\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 441us/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 441us/step - loss: 0.0034 - val_loss: 0.0022\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 439us/step - loss: 0.0032 - val_loss: 0.0025\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 440us/step - loss: 0.0031 - val_loss: 0.0025\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 441us/step - loss: 0.0030 - val_loss: 0.0026\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 440us/step - loss: 0.0029 - val_loss: 0.0025\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 439us/step - loss: 0.0029 - val_loss: 0.0025\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 439us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 440us/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 442us/step - loss: 0.0027 - val_loss: 0.0041\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 441us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 441us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 438us/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 442us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 440us/step - loss: 0.0024 - val_loss: 0.0062\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 442us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 38s 10ms/step - loss: 0.1150 - val_loss: 0.0217\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 525us/step - loss: 0.0209 - val_loss: 0.0221\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 521us/step - loss: 0.0109 - val_loss: 0.0037\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 525us/step - loss: 0.0058 - val_loss: 0.0032\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 525us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 525us/step - loss: 0.0042 - val_loss: 0.0024\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 524us/step - loss: 0.0036 - val_loss: 0.0032\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 522us/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 522us/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 526us/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 525us/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 526us/step - loss: 0.0030 - val_loss: 0.0044\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 525us/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 526us/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 521us/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 525us/step - loss: 0.0026 - val_loss: 0.0059\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 529us/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 526us/step - loss: 0.0024 - val_loss: 0.0036\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 526us/step - loss: 0.0024 - val_loss: 0.0074\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 526us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 522us/step - loss: 0.0023 - val_loss: 0.0078\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 525us/step - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 525us/step - loss: 0.0022 - val_loss: 0.0054\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 525us/step - loss: 0.0021 - val_loss: 0.0052\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 38s 10ms/step - loss: 0.0912 - val_loss: 0.0427\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 530us/step - loss: 0.0167 - val_loss: 0.0056\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 528us/step - loss: 0.0077 - val_loss: 0.0028\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 530us/step - loss: 0.0045 - val_loss: 0.0027\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 533us/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 529us/step - loss: 0.0032 - val_loss: 0.0026\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 528us/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 529us/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 525us/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 529us/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 528us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 529us/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 528us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 532us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 528us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 531us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 529us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 529us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 529us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 531us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 530us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 529us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 531us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 531us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "\n",
      "GENERATION 19\n",
      "\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 37s 9ms/step - loss: 0.0686 - val_loss: 0.0040\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 0.0051 - val_loss: 0.0065\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 0.0067 - val_loss: 0.0056\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 0.0036 - val_loss: 0.0026\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 0.0028 - val_loss: 0.0014\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 0.0027 - val_loss: 0.0045\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 0.0043 - val_loss: 0.0034\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 0.0033 - val_loss: 0.0049\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 0.0026 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 0.0040 - val_loss: 0.0019\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 0.0037 - val_loss: 0.0021\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 0.0031 - val_loss: 0.0016\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 37s 9ms/step - loss: 0.1561 - val_loss: 0.0079\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 180us/step - loss: 0.0212 - val_loss: 0.0041\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 180us/step - loss: 0.0114 - val_loss: 0.0052\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 0.0049 - val_loss: 0.0045\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 180us/step - loss: 0.0028 - val_loss: 0.0018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 179us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 180us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 180us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 180us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 179us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 178us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 180us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 179us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 179us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 179us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 180us/step - loss: 9.6569e-04 - val_loss: 9.9400e-04\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 181us/step - loss: 9.2494e-04 - val_loss: 8.9759e-04\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 181us/step - loss: 8.9754e-04 - val_loss: 8.6712e-04\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 180us/step - loss: 8.7832e-04 - val_loss: 9.6249e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 180us/step - loss: 8.5791e-04 - val_loss: 9.2072e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 179us/step - loss: 8.4962e-04 - val_loss: 8.1819e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 180us/step - loss: 8.2098e-04 - val_loss: 8.0453e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 180us/step - loss: 7.9601e-04 - val_loss: 9.1510e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 180us/step - loss: 7.9421e-04 - val_loss: 7.8808e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 37s 10ms/step - loss: 0.1352 - val_loss: 0.0221\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 0.0222 - val_loss: 0.0242\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 0.0127 - val_loss: 0.0015\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 0.0079 - val_loss: 0.0030\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 0.0054 - val_loss: 0.0024\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 0.0039 - val_loss: 0.0016\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 0.0034 - val_loss: 0.0022\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 181us/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 0.0025 - val_loss: 0.0043\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 0.0021 - val_loss: 0.0051\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 0.0020 - val_loss: 0.0054\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 0.0019 - val_loss: 0.0056\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 0.0019 - val_loss: 0.0060\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 0.0017 - val_loss: 0.0065\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 0.0018 - val_loss: 0.0074\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 0.0017 - val_loss: 0.0089\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 0.0016 - val_loss: 0.0101\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 0.0015 - val_loss: 0.0119\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 0.0015 - val_loss: 0.0122\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 39s 10ms/step - loss: 0.0960 - val_loss: 0.0248\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 348us/step - loss: 0.0200 - val_loss: 0.0066\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 344us/step - loss: 0.0101 - val_loss: 0.0058\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 343us/step - loss: 0.0071 - val_loss: 0.0029\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 343us/step - loss: 0.0055 - val_loss: 0.0029\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 345us/step - loss: 0.0047 - val_loss: 0.0027\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 346us/step - loss: 0.0044 - val_loss: 0.0033\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 346us/step - loss: 0.0042 - val_loss: 0.0028\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 348us/step - loss: 0.0041 - val_loss: 0.0035\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 348us/step - loss: 0.0039 - val_loss: 0.0033\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 345us/step - loss: 0.0039 - val_loss: 0.0034\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 347us/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 351us/step - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 347us/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 346us/step - loss: 0.0035 - val_loss: 0.0049\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 345us/step - loss: 0.0034 - val_loss: 0.0052\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 346us/step - loss: 0.0035 - val_loss: 0.0055\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 344us/step - loss: 0.0033 - val_loss: 0.0066\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 345us/step - loss: 0.0033 - val_loss: 0.0079\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 346us/step - loss: 0.0032 - val_loss: 0.0074\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 346us/step - loss: 0.0031 - val_loss: 0.0072\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 343us/step - loss: 0.0031 - val_loss: 0.0074\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 346us/step - loss: 0.0030 - val_loss: 0.0081\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 347us/step - loss: 0.0030 - val_loss: 0.0089\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 39s 10ms/step - loss: 0.0726 - val_loss: 0.0195\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 348us/step - loss: 0.0126 - val_loss: 0.0062\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 347us/step - loss: 0.0066 - val_loss: 0.0136\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 347us/step - loss: 0.0050 - val_loss: 0.0024\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 354us/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 347us/step - loss: 0.0035 - val_loss: 0.0053\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 349us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 350us/step - loss: 0.0030 - val_loss: 0.0038\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 349us/step - loss: 0.0030 - val_loss: 0.0035\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 346us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 347us/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 347us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 347us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 346us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 347us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 347us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 351us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 348us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 345us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 346us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 346us/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 347us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 347us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 346us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 40s 10ms/step - loss: 0.0745 - val_loss: 0.0170\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 349us/step - loss: 0.0116 - val_loss: 0.0078\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 349us/step - loss: 0.0059 - val_loss: 0.0074\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 347us/step - loss: 0.0051 - val_loss: 0.0035\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 353us/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 348us/step - loss: 0.0039 - val_loss: 0.0032\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 348us/step - loss: 0.0037 - val_loss: 0.0053\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 351us/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 351us/step - loss: 0.0032 - val_loss: 0.0040\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 346us/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 347us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 348us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 348us/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 350us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 350us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 348us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 348us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 347us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 354us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 354us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 348us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 350us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 349us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 349us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 41s 11ms/step - loss: 0.2457 - val_loss: 0.0314\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 494us/step - loss: 0.0773 - val_loss: 0.1062\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 495us/step - loss: 0.0817 - val_loss: 0.0655\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 494us/step - loss: 0.0692 - val_loss: 0.0322\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 496us/step - loss: 0.0684 - val_loss: 0.0255\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 496us/step - loss: 0.0687 - val_loss: 0.0300\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 495us/step - loss: 0.0679 - val_loss: 0.0371\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 496us/step - loss: 0.0678 - val_loss: 0.0399\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 494us/step - loss: 0.0678 - val_loss: 0.0389\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 494us/step - loss: 0.0676 - val_loss: 0.0360\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 494us/step - loss: 0.0675 - val_loss: 0.0348\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 498us/step - loss: 0.0672 - val_loss: 0.0354\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 499us/step - loss: 0.0665 - val_loss: 0.0349\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 494us/step - loss: 0.0654 - val_loss: 0.0348\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 493us/step - loss: 0.0632 - val_loss: 0.0293\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 496us/step - loss: 0.0591 - val_loss: 0.0247\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 497us/step - loss: 0.0552 - val_loss: 0.0173\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 494us/step - loss: 0.0481 - val_loss: 0.0123\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 494us/step - loss: 0.0383 - val_loss: 0.0079\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 494us/step - loss: 0.0391 - val_loss: 0.0137\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 495us/step - loss: 0.0269 - val_loss: 0.0044\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 494us/step - loss: 0.0314 - val_loss: 0.0494\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 496us/step - loss: 0.0284 - val_loss: 0.0074\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 497us/step - loss: 0.0233 - val_loss: 0.0075\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 42s 11ms/step - loss: 0.3027 - val_loss: 0.1126\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 547us/step - loss: 0.0922 - val_loss: 0.0648\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 544us/step - loss: 0.0652 - val_loss: 0.0073\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 550us/step - loss: 0.0546 - val_loss: 0.0052\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 545us/step - loss: 0.0205 - val_loss: 0.0294\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 544us/step - loss: 0.0134 - val_loss: 0.0113\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 546us/step - loss: 0.0118 - val_loss: 0.0050\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 549us/step - loss: 0.0074 - val_loss: 0.0050\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 546us/step - loss: 0.0067 - val_loss: 0.0069\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 547us/step - loss: 0.0057 - val_loss: 0.0071\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 548us/step - loss: 0.0053 - val_loss: 0.0036\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 547us/step - loss: 0.0049 - val_loss: 0.0032\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 548us/step - loss: 0.0046 - val_loss: 0.0036\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 548us/step - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 15/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 2s 557us/step - loss: 0.0042 - val_loss: 0.0034\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 567us/step - loss: 0.0039 - val_loss: 0.0028\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 557us/step - loss: 0.0037 - val_loss: 0.0032\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 550us/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 545us/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 546us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 547us/step - loss: 0.0033 - val_loss: 0.0039\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 549us/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 553us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 551us/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 45s 11ms/step - loss: 0.0848 - val_loss: 0.0175\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 552us/step - loss: 0.0347 - val_loss: 0.0081\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 552us/step - loss: 0.0113 - val_loss: 0.0044\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 551us/step - loss: 0.0066 - val_loss: 0.0066\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 549us/step - loss: 0.0052 - val_loss: 0.0042\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 552us/step - loss: 0.0045 - val_loss: 0.0029\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 551us/step - loss: 0.0039 - val_loss: 0.0033\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 552us/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 551us/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 552us/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 550us/step - loss: 0.0033 - val_loss: 0.0024\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 553us/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 552us/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 554us/step - loss: 0.0030 - val_loss: 0.0022\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 550us/step - loss: 0.0029 - val_loss: 0.0023\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 551us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 545us/step - loss: 0.0027 - val_loss: 0.0020\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 551us/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 560us/step - loss: 0.0026 - val_loss: 0.0020\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 577us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 556us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 562us/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 573us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 554us/step - loss: 0.0023 - val_loss: 0.0018\n"
     ]
    }
   ],
   "source": [
    "best_models = breed_population(X_train, Y_train, generations=20, population_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.046528443694114685,\n",
       " 0.015876784920692444,\n",
       " 0.0070190345868468285,\n",
       " 0.0024138118606060743,\n",
       " 0.003312045941129327,\n",
       " 0.0011173543753102422,\n",
       " 0.0014791690045967698,\n",
       " 0.001315784640610218,\n",
       " 0.0011454848572611809,\n",
       " 0.0013817568542435765,\n",
       " 0.0011358709307387471,\n",
       " 0.0010027687530964613,\n",
       " 0.0010786692146211863,\n",
       " 0.0013547553680837154,\n",
       " 0.0011292725102975965,\n",
       " 0.0008823425741866231,\n",
       " 0.0008099110564216971,\n",
       " 0.000813144026324153,\n",
       " 0.000772567989770323,\n",
       " 0.0007518439670093358,\n",
       " 0.000722959463018924,\n",
       " 0.0007264699670486152,\n",
       " 0.0007055338355712593,\n",
       " 0.0006916458951309323]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models[0][1].history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal parameters\n",
      "_______________________\n",
      "density: 138\n",
      "shuffle: True\n",
      "full_density: True\n",
      "twice: False\n",
      "activation: relu\n",
      "optimizer: adam\n",
      "lstmsize: 92\n"
     ]
    }
   ],
   "source": [
    "print('optimal parameters')\n",
    "print('_______________________')\n",
    "for key,val in best_models[0][2].items():\n",
    "    if key != 'x' and key != 'y': print(f'{key}: {val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_165\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_276 (LSTM)              (None, 92)                36064     \n",
      "_________________________________________________________________\n",
      "dense_831 (Dense)            (None, 138)               12834     \n",
      "_________________________________________________________________\n",
      "dense_832 (Dense)            (None, 69)                9591      \n",
      "_________________________________________________________________\n",
      "dense_833 (Dense)            (None, 34)                2380      \n",
      "_________________________________________________________________\n",
      "dense_834 (Dense)            (None, 17)                595       \n",
      "_________________________________________________________________\n",
      "dense_835 (Dense)            (None, 1)                 18        \n",
      "=================================================================\n",
      "Total params: 61,482\n",
      "Trainable params: 61,482\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_models[0][0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibm_checkpoint = ModelCheckpoint(\n",
    "    filepath='./checkpoints/IBM.{epoch}-{val_loss}.hdf5',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = best_models[0][2]\n",
    "params['x'] = X_train\n",
    "params['y'] = Y_train\n",
    "params['epochs'] = 2000\n",
    "params['callbacks'] = [ibm_checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/2000\n",
      "3891/3891 [==============================] - 40s 10ms/step - loss: 0.1634 - val_loss: 0.0058\n",
      "Epoch 2/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 0.0173 - val_loss: 0.0108\n",
      "Epoch 3/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 0.0095 - val_loss: 0.0029\n",
      "Epoch 4/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 0.0046 - val_loss: 0.0015\n",
      "Epoch 5/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 6/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 7/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 8/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 9/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 10/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 11/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 12/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 13/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 14/2000\n",
      "3891/3891 [==============================] - 1s 181us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 15/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 16/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 9.9157e-04 - val_loss: 0.0013\n",
      "Epoch 17/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 9.4648e-04 - val_loss: 9.6262e-04\n",
      "Epoch 18/2000\n",
      "3891/3891 [==============================] - 1s 181us/step - loss: 9.0416e-04 - val_loss: 8.1504e-04\n",
      "Epoch 19/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 8.5659e-04 - val_loss: 8.9010e-04\n",
      "Epoch 20/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 8.5869e-04 - val_loss: 8.1593e-04\n",
      "Epoch 21/2000\n",
      "3891/3891 [==============================] - 1s 191us/step - loss: 8.5327e-04 - val_loss: 8.6656e-04\n",
      "Epoch 22/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 8.2953e-04 - val_loss: 8.2977e-04\n",
      "Epoch 23/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 8.2677e-04 - val_loss: 9.5103e-04\n",
      "Epoch 24/2000\n",
      "3891/3891 [==============================] - 1s 191us/step - loss: 7.9309e-04 - val_loss: 7.5972e-04\n",
      "Epoch 25/2000\n",
      "3891/3891 [==============================] - 1s 200us/step - loss: 7.8578e-04 - val_loss: 7.5617e-04\n",
      "Epoch 26/2000\n",
      "3891/3891 [==============================] - 1s 196us/step - loss: 7.6992e-04 - val_loss: 7.9466e-04\n",
      "Epoch 27/2000\n",
      "3891/3891 [==============================] - 1s 192us/step - loss: 7.5228e-04 - val_loss: 8.4414e-04\n",
      "Epoch 28/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 7.8371e-04 - val_loss: 8.4997e-04\n",
      "Epoch 29/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 7.7483e-04 - val_loss: 7.4252e-04\n",
      "Epoch 30/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 7.5588e-04 - val_loss: 7.4806e-04\n",
      "Epoch 31/2000\n",
      "3891/3891 [==============================] - 1s 193us/step - loss: 7.3950e-04 - val_loss: 7.3284e-04\n",
      "Epoch 32/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 7.1927e-04 - val_loss: 7.3671e-04\n",
      "Epoch 33/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 7.1325e-04 - val_loss: 7.0640e-04\n",
      "Epoch 34/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 7.1228e-04 - val_loss: 7.4252e-04\n",
      "Epoch 35/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 7.1665e-04 - val_loss: 7.3354e-04\n",
      "Epoch 36/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 7.1035e-04 - val_loss: 7.1820e-04\n",
      "Epoch 37/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 7.0810e-04 - val_loss: 7.1754e-04\n",
      "Epoch 38/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 6.9605e-04 - val_loss: 7.2523e-04\n",
      "Epoch 39/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 6.9314e-04 - val_loss: 6.7250e-04\n",
      "Epoch 40/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 6.8025e-04 - val_loss: 6.7276e-04\n",
      "Epoch 41/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 6.8022e-04 - val_loss: 6.7636e-04\n",
      "Epoch 42/2000\n",
      "3891/3891 [==============================] - 1s 191us/step - loss: 6.9443e-04 - val_loss: 6.7363e-04\n",
      "Epoch 43/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 7.2887e-04 - val_loss: 8.8481e-04\n",
      "Epoch 44/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 6.9951e-04 - val_loss: 6.9477e-04\n",
      "Epoch 45/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 6.7229e-04 - val_loss: 6.4495e-04\n",
      "Epoch 46/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 6.7327e-04 - val_loss: 6.8371e-04\n",
      "Epoch 47/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 6.7356e-04 - val_loss: 6.4168e-04\n",
      "Epoch 48/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 6.5009e-04 - val_loss: 6.3221e-04\n",
      "Epoch 49/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 6.5374e-04 - val_loss: 6.3797e-04\n",
      "Epoch 50/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 6.5499e-04 - val_loss: 6.2691e-04\n",
      "Epoch 51/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 6.6196e-04 - val_loss: 7.3885e-04\n",
      "Epoch 52/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 7.0234e-04 - val_loss: 6.8600e-04\n",
      "Epoch 53/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 7.1261e-04 - val_loss: 8.0016e-04\n",
      "Epoch 54/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 7.1218e-04 - val_loss: 0.0010\n",
      "Epoch 55/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 6.8265e-04 - val_loss: 6.9167e-04\n",
      "Epoch 56/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 6.6358e-04 - val_loss: 6.1718e-04\n",
      "Epoch 57/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 6.3844e-04 - val_loss: 6.4531e-04\n",
      "Epoch 58/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 6.3710e-04 - val_loss: 6.8816e-04\n",
      "Epoch 59/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 6.3401e-04 - val_loss: 6.9431e-04\n",
      "Epoch 60/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 6.4829e-04 - val_loss: 6.3067e-04\n",
      "Epoch 61/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 6.1351e-04 - val_loss: 6.3325e-04\n",
      "Epoch 62/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 6.1524e-04 - val_loss: 6.2491e-04\n",
      "Epoch 63/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 6.2445e-04 - val_loss: 6.0300e-04\n",
      "Epoch 64/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 6.1484e-04 - val_loss: 5.9640e-04\n",
      "Epoch 65/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 6.1899e-04 - val_loss: 6.9189e-04\n",
      "Epoch 66/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 6.3028e-04 - val_loss: 6.7204e-04\n",
      "Epoch 67/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 6.2485e-04 - val_loss: 6.1561e-04\n",
      "Epoch 68/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 6.4098e-04 - val_loss: 6.8981e-04\n",
      "Epoch 69/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 6.2051e-04 - val_loss: 6.9678e-04\n",
      "Epoch 70/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 6.0996e-04 - val_loss: 8.5499e-04\n",
      "Epoch 71/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 6.3135e-04 - val_loss: 6.1658e-04\n",
      "Epoch 72/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 5.9621e-04 - val_loss: 6.5229e-04\n",
      "Epoch 73/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 1s 182us/step - loss: 5.9471e-04 - val_loss: 5.9186e-04\n",
      "Epoch 74/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 6.1660e-04 - val_loss: 6.3947e-04\n",
      "Epoch 75/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 5.8708e-04 - val_loss: 5.9734e-04\n",
      "Epoch 76/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 5.9116e-04 - val_loss: 5.8511e-04\n",
      "Epoch 77/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 5.9204e-04 - val_loss: 5.8669e-04\n",
      "Epoch 78/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 6.3255e-04 - val_loss: 7.9373e-04\n",
      "Epoch 79/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 6.1092e-04 - val_loss: 8.4884e-04\n",
      "Epoch 80/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 6.1470e-04 - val_loss: 6.9252e-04\n",
      "Epoch 81/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 6.4301e-04 - val_loss: 7.4420e-04\n",
      "Epoch 82/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 6.1487e-04 - val_loss: 6.7456e-04\n",
      "Epoch 83/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 5.9367e-04 - val_loss: 5.7873e-04\n",
      "Epoch 84/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 5.9721e-04 - val_loss: 5.9182e-04\n",
      "Epoch 85/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 6.3221e-04 - val_loss: 5.8136e-04\n",
      "Epoch 86/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 5.8601e-04 - val_loss: 5.8666e-04\n",
      "Epoch 87/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 6.1865e-04 - val_loss: 5.7808e-04\n",
      "Epoch 88/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 5.7348e-04 - val_loss: 5.8773e-04\n",
      "Epoch 89/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 5.6451e-04 - val_loss: 6.1617e-04\n",
      "Epoch 90/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 5.8196e-04 - val_loss: 9.5326e-04\n",
      "Epoch 91/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 6.2682e-04 - val_loss: 8.8572e-04\n",
      "Epoch 92/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 5.9096e-04 - val_loss: 5.8554e-04\n",
      "Epoch 93/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 5.6888e-04 - val_loss: 6.9287e-04\n",
      "Epoch 94/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 5.9811e-04 - val_loss: 6.3553e-04\n",
      "Epoch 95/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 5.9261e-04 - val_loss: 6.7308e-04\n",
      "Epoch 96/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 5.6980e-04 - val_loss: 5.7515e-04\n",
      "Epoch 97/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 5.7248e-04 - val_loss: 6.9801e-04\n",
      "Epoch 98/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 5.7962e-04 - val_loss: 7.1422e-04\n",
      "Epoch 99/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 5.7085e-04 - val_loss: 7.3341e-04\n",
      "Epoch 100/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 6.0178e-04 - val_loss: 5.7297e-04\n",
      "Epoch 101/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 5.9003e-04 - val_loss: 5.6480e-04\n",
      "Epoch 102/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 5.6557e-04 - val_loss: 6.1654e-04\n",
      "Epoch 103/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 5.5616e-04 - val_loss: 6.2296e-04\n",
      "Epoch 104/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 5.5966e-04 - val_loss: 5.7980e-04\n",
      "Epoch 105/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 5.6212e-04 - val_loss: 5.5907e-04\n",
      "Epoch 106/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 5.8175e-04 - val_loss: 9.4009e-04\n",
      "Epoch 107/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 6.1326e-04 - val_loss: 7.6406e-04\n",
      "Epoch 108/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 5.6379e-04 - val_loss: 6.2963e-04\n",
      "Epoch 109/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 5.4789e-04 - val_loss: 5.9366e-04\n",
      "Epoch 110/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 5.7144e-04 - val_loss: 7.9752e-04\n",
      "Epoch 111/2000\n",
      "3891/3891 [==============================] - 1s 191us/step - loss: 5.7143e-04 - val_loss: 5.5623e-04\n",
      "Epoch 112/2000\n",
      "3891/3891 [==============================] - 1s 196us/step - loss: 5.6445e-04 - val_loss: 5.5744e-04\n",
      "Epoch 113/2000\n",
      "3891/3891 [==============================] - 1s 192us/step - loss: 5.5485e-04 - val_loss: 5.7072e-04\n",
      "Epoch 114/2000\n",
      "3891/3891 [==============================] - 1s 191us/step - loss: 5.8626e-04 - val_loss: 8.6038e-04\n",
      "Epoch 115/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 6.0985e-04 - val_loss: 5.8646e-04\n",
      "Epoch 116/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 5.5691e-04 - val_loss: 5.5978e-04\n",
      "Epoch 117/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 5.4620e-04 - val_loss: 6.8529e-04\n",
      "Epoch 118/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 5.6931e-04 - val_loss: 5.8060e-04\n",
      "Epoch 119/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 5.5019e-04 - val_loss: 5.8034e-04\n",
      "Epoch 120/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 5.5475e-04 - val_loss: 5.7917e-04\n",
      "Epoch 121/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 5.3940e-04 - val_loss: 5.9000e-04\n",
      "Epoch 122/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 5.3966e-04 - val_loss: 7.0845e-04\n",
      "Epoch 123/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 5.5241e-04 - val_loss: 6.8557e-04\n",
      "Epoch 124/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 5.8951e-04 - val_loss: 5.5316e-04\n",
      "Epoch 125/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 5.5587e-04 - val_loss: 5.5896e-04\n",
      "Epoch 126/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 5.4933e-04 - val_loss: 5.6454e-04\n",
      "Epoch 127/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 5.7906e-04 - val_loss: 6.3332e-04\n",
      "Epoch 128/2000\n",
      "3891/3891 [==============================] - 1s 195us/step - loss: 5.9325e-04 - val_loss: 6.6515e-04\n",
      "Epoch 129/2000\n",
      "3891/3891 [==============================] - 1s 198us/step - loss: 5.6256e-04 - val_loss: 5.5544e-04\n",
      "Epoch 130/2000\n",
      "3891/3891 [==============================] - 1s 195us/step - loss: 5.3349e-04 - val_loss: 6.0219e-04\n",
      "Epoch 131/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 5.3336e-04 - val_loss: 5.7733e-04\n",
      "Epoch 132/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 5.3648e-04 - val_loss: 5.5776e-04\n",
      "Epoch 133/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 5.3126e-04 - val_loss: 5.4933e-04\n",
      "Epoch 134/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 5.3857e-04 - val_loss: 5.8539e-04\n",
      "Epoch 135/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 5.3883e-04 - val_loss: 5.9276e-04\n",
      "Epoch 136/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 5.3112e-04 - val_loss: 5.4880e-04\n",
      "Epoch 137/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 5.6490e-04 - val_loss: 6.6333e-04\n",
      "Epoch 138/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 5.9841e-04 - val_loss: 5.5660e-04\n",
      "Epoch 139/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 5.3877e-04 - val_loss: 5.5434e-04\n",
      "Epoch 140/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 5.6602e-04 - val_loss: 5.7946e-04\n",
      "Epoch 141/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 5.7280e-04 - val_loss: 5.4868e-04\n",
      "Epoch 142/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 5.6964e-04 - val_loss: 5.5064e-04\n",
      "Epoch 143/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 5.5929e-04 - val_loss: 5.5441e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 5.3464e-04 - val_loss: 5.5197e-04\n",
      "Epoch 145/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 5.2026e-04 - val_loss: 5.4941e-04\n",
      "Epoch 146/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 5.2765e-04 - val_loss: 6.3268e-04\n",
      "Epoch 147/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 5.3034e-04 - val_loss: 5.7313e-04\n",
      "Epoch 148/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 5.2472e-04 - val_loss: 6.0458e-04\n",
      "Epoch 149/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 5.3335e-04 - val_loss: 5.8975e-04\n",
      "Epoch 150/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 5.2176e-04 - val_loss: 5.9592e-04\n",
      "Epoch 151/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 5.3005e-04 - val_loss: 6.2311e-04\n",
      "Epoch 152/2000\n",
      "3891/3891 [==============================] - 1s 192us/step - loss: 5.3765e-04 - val_loss: 5.6569e-04\n",
      "Epoch 153/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 5.2981e-04 - val_loss: 6.6585e-04\n",
      "Epoch 154/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 5.4034e-04 - val_loss: 7.8539e-04\n",
      "Epoch 155/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 5.3621e-04 - val_loss: 5.9323e-04\n",
      "Epoch 156/2000\n",
      "3891/3891 [==============================] - 1s 191us/step - loss: 5.1340e-04 - val_loss: 5.9514e-04\n",
      "Epoch 157/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 5.1391e-04 - val_loss: 6.0444e-04\n",
      "Epoch 158/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 5.2313e-04 - val_loss: 5.9747e-04\n",
      "Epoch 159/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 5.0883e-04 - val_loss: 5.4569e-04\n",
      "Epoch 160/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 5.0494e-04 - val_loss: 6.3414e-04\n",
      "Epoch 161/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 5.3941e-04 - val_loss: 5.6180e-04\n",
      "Epoch 162/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 5.3539e-04 - val_loss: 5.4406e-04\n",
      "Epoch 163/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 5.1567e-04 - val_loss: 5.7758e-04\n",
      "Epoch 164/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 5.1626e-04 - val_loss: 5.5442e-04\n",
      "Epoch 165/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 5.1300e-04 - val_loss: 5.3826e-04\n",
      "Epoch 166/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 5.1919e-04 - val_loss: 6.3717e-04\n",
      "Epoch 167/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 5.1768e-04 - val_loss: 6.7266e-04\n",
      "Epoch 168/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 5.4360e-04 - val_loss: 6.7288e-04\n",
      "Epoch 169/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 5.5716e-04 - val_loss: 5.5903e-04\n",
      "Epoch 170/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 5.2479e-04 - val_loss: 5.3943e-04\n",
      "Epoch 171/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 5.0526e-04 - val_loss: 5.5243e-04\n",
      "Epoch 172/2000\n",
      "3891/3891 [==============================] - 1s 195us/step - loss: 5.1531e-04 - val_loss: 5.4382e-04\n",
      "Epoch 173/2000\n",
      "3891/3891 [==============================] - 1s 196us/step - loss: 5.1188e-04 - val_loss: 6.0550e-04\n",
      "Epoch 174/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 5.3017e-04 - val_loss: 5.4892e-04\n",
      "Epoch 175/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 5.0731e-04 - val_loss: 5.3882e-04\n",
      "Epoch 176/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 4.9900e-04 - val_loss: 5.8082e-04\n",
      "Epoch 177/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 5.1287e-04 - val_loss: 5.7916e-04\n",
      "Epoch 178/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 5.6288e-04 - val_loss: 5.4303e-04\n",
      "Epoch 179/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 5.1713e-04 - val_loss: 5.3403e-04\n",
      "Epoch 180/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 5.2214e-04 - val_loss: 6.2471e-04\n",
      "Epoch 181/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 5.4152e-04 - val_loss: 7.9349e-04\n",
      "Epoch 182/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 5.5979e-04 - val_loss: 0.0010\n",
      "Epoch 183/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 5.8933e-04 - val_loss: 8.5069e-04\n",
      "Epoch 184/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 5.2847e-04 - val_loss: 6.5172e-04\n",
      "Epoch 185/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 5.1606e-04 - val_loss: 6.0478e-04\n",
      "Epoch 186/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 5.2832e-04 - val_loss: 5.3753e-04\n",
      "Epoch 187/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 5.2546e-04 - val_loss: 5.7026e-04\n",
      "Epoch 188/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 5.4013e-04 - val_loss: 5.4680e-04\n",
      "Epoch 189/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 5.3932e-04 - val_loss: 6.2557e-04\n",
      "Epoch 190/2000\n",
      "3891/3891 [==============================] - 1s 196us/step - loss: 5.9362e-04 - val_loss: 5.9319e-04\n",
      "Epoch 191/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 5.2360e-04 - val_loss: 5.4571e-04\n",
      "Epoch 192/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 5.0956e-04 - val_loss: 5.8796e-04\n",
      "Epoch 193/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 5.1928e-04 - val_loss: 5.4786e-04\n",
      "Epoch 194/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 5.0460e-04 - val_loss: 7.5603e-04\n",
      "Epoch 195/2000\n",
      "3891/3891 [==============================] - 1s 191us/step - loss: 5.0958e-04 - val_loss: 5.3827e-04\n",
      "Epoch 196/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 4.9992e-04 - val_loss: 5.3115e-04\n",
      "Epoch 197/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 5.0771e-04 - val_loss: 5.3070e-04\n",
      "Epoch 198/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.9792e-04 - val_loss: 5.2912e-04\n",
      "Epoch 199/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 4.9916e-04 - val_loss: 5.4348e-04\n",
      "Epoch 200/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.9991e-04 - val_loss: 5.4791e-04\n",
      "Epoch 201/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 5.0208e-04 - val_loss: 5.7625e-04\n",
      "Epoch 202/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 5.0346e-04 - val_loss: 6.2032e-04\n",
      "Epoch 203/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 5.2648e-04 - val_loss: 5.3827e-04\n",
      "Epoch 204/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 5.4330e-04 - val_loss: 5.4800e-04\n",
      "Epoch 205/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 5.0783e-04 - val_loss: 6.8533e-04\n",
      "Epoch 206/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 4.9598e-04 - val_loss: 5.3969e-04\n",
      "Epoch 207/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 4.9596e-04 - val_loss: 5.3765e-04\n",
      "Epoch 208/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 5.0101e-04 - val_loss: 5.4863e-04\n",
      "Epoch 209/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 5.0697e-04 - val_loss: 5.3246e-04\n",
      "Epoch 210/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.8871e-04 - val_loss: 7.1982e-04\n",
      "Epoch 211/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 5.1989e-04 - val_loss: 7.3005e-04\n",
      "Epoch 212/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 5.1814e-04 - val_loss: 7.0374e-04\n",
      "Epoch 213/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 5.1148e-04 - val_loss: 5.6653e-04\n",
      "Epoch 214/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.9195e-04 - val_loss: 5.6814e-04\n",
      "Epoch 215/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 5.0379e-04 - val_loss: 5.5600e-04\n",
      "Epoch 216/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 4.9742e-04 - val_loss: 5.6435e-04\n",
      "Epoch 217/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 5.1624e-04 - val_loss: 5.3643e-04\n",
      "Epoch 218/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 5.0858e-04 - val_loss: 5.4058e-04\n",
      "Epoch 219/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 4.8924e-04 - val_loss: 5.6578e-04\n",
      "Epoch 220/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.8358e-04 - val_loss: 5.4124e-04\n",
      "Epoch 221/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 4.8328e-04 - val_loss: 5.5013e-04\n",
      "Epoch 222/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 4.8276e-04 - val_loss: 5.3333e-04\n",
      "Epoch 223/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 4.9034e-04 - val_loss: 5.3182e-04\n",
      "Epoch 224/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 4.9335e-04 - val_loss: 5.8241e-04\n",
      "Epoch 225/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 5.0769e-04 - val_loss: 8.0439e-04\n",
      "Epoch 226/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 5.5243e-04 - val_loss: 5.5851e-04\n",
      "Epoch 227/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 5.0929e-04 - val_loss: 5.6672e-04\n",
      "Epoch 228/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 5.1201e-04 - val_loss: 5.2570e-04\n",
      "Epoch 229/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 4.8518e-04 - val_loss: 5.6684e-04\n",
      "Epoch 230/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 4.8544e-04 - val_loss: 5.3196e-04\n",
      "Epoch 231/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.8281e-04 - val_loss: 5.2827e-04\n",
      "Epoch 232/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 4.9783e-04 - val_loss: 7.5655e-04\n",
      "Epoch 233/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 4.9930e-04 - val_loss: 6.5047e-04\n",
      "Epoch 234/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 5.0156e-04 - val_loss: 5.5321e-04\n",
      "Epoch 235/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 5.1073e-04 - val_loss: 5.2960e-04\n",
      "Epoch 236/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 5.2280e-04 - val_loss: 5.2786e-04\n",
      "Epoch 237/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 5.2785e-04 - val_loss: 5.2822e-04\n",
      "Epoch 238/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.8513e-04 - val_loss: 5.2954e-04\n",
      "Epoch 239/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 4.8906e-04 - val_loss: 5.4125e-04\n",
      "Epoch 240/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 4.8880e-04 - val_loss: 7.0179e-04\n",
      "Epoch 241/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 4.9325e-04 - val_loss: 5.3862e-04\n",
      "Epoch 242/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 4.9144e-04 - val_loss: 5.6493e-04\n",
      "Epoch 243/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.8746e-04 - val_loss: 5.5477e-04\n",
      "Epoch 244/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 4.9733e-04 - val_loss: 7.6119e-04\n",
      "Epoch 245/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 6.2292e-04 - val_loss: 6.6140e-04\n",
      "Epoch 246/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 5.3962e-04 - val_loss: 6.6356e-04\n",
      "Epoch 247/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 5.2268e-04 - val_loss: 5.4312e-04\n",
      "Epoch 248/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.9963e-04 - val_loss: 5.2171e-04\n",
      "Epoch 249/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.9576e-04 - val_loss: 5.3429e-04\n",
      "Epoch 250/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 4.8392e-04 - val_loss: 6.1924e-04\n",
      "Epoch 251/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 4.9049e-04 - val_loss: 5.4681e-04\n",
      "Epoch 252/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 4.8400e-04 - val_loss: 5.2914e-04\n",
      "Epoch 253/2000\n",
      "3891/3891 [==============================] - 1s 194us/step - loss: 4.8453e-04 - val_loss: 5.2868e-04\n",
      "Epoch 254/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 4.9911e-04 - val_loss: 5.2367e-04\n",
      "Epoch 255/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 4.8084e-04 - val_loss: 5.2392e-04\n",
      "Epoch 256/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 4.8503e-04 - val_loss: 5.3930e-04\n",
      "Epoch 257/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 4.8868e-04 - val_loss: 5.2442e-04\n",
      "Epoch 258/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 5.3284e-04 - val_loss: 5.4849e-04\n",
      "Epoch 259/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 5.0495e-04 - val_loss: 5.6837e-04\n",
      "Epoch 260/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 5.0718e-04 - val_loss: 5.3678e-04\n",
      "Epoch 261/2000\n",
      "3891/3891 [==============================] - 1s 191us/step - loss: 4.9180e-04 - val_loss: 5.2480e-04\n",
      "Epoch 262/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.8981e-04 - val_loss: 5.2526e-04\n",
      "Epoch 263/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 4.8706e-04 - val_loss: 5.9926e-04\n",
      "Epoch 264/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 4.9655e-04 - val_loss: 5.8853e-04\n",
      "Epoch 265/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 5.0893e-04 - val_loss: 5.2263e-04\n",
      "Epoch 266/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 4.8290e-04 - val_loss: 6.6863e-04\n",
      "Epoch 267/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 5.0858e-04 - val_loss: 6.6457e-04\n",
      "Epoch 268/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 5.1031e-04 - val_loss: 5.8725e-04\n",
      "Epoch 269/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 5.0647e-04 - val_loss: 9.7003e-04\n",
      "Epoch 270/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 5.5672e-04 - val_loss: 5.7697e-04\n",
      "Epoch 271/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.7606e-04 - val_loss: 5.2872e-04\n",
      "Epoch 272/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 4.7614e-04 - val_loss: 5.2358e-04\n",
      "Epoch 273/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 5.0187e-04 - val_loss: 5.3438e-04\n",
      "Epoch 274/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 5.1140e-04 - val_loss: 5.9419e-04\n",
      "Epoch 275/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 4.7494e-04 - val_loss: 5.7745e-04\n",
      "Epoch 276/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 4.8307e-04 - val_loss: 5.9445e-04\n",
      "Epoch 277/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.8424e-04 - val_loss: 5.3441e-04\n",
      "Epoch 278/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.7830e-04 - val_loss: 5.8429e-04\n",
      "Epoch 279/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 4.7998e-04 - val_loss: 5.8138e-04\n",
      "Epoch 280/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 4.9324e-04 - val_loss: 6.8635e-04\n",
      "Epoch 281/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 5.0245e-04 - val_loss: 8.1627e-04\n",
      "Epoch 282/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 5.1496e-04 - val_loss: 5.8884e-04\n",
      "Epoch 283/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 4.9865e-04 - val_loss: 6.5910e-04\n",
      "Epoch 284/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 5.0511e-04 - val_loss: 5.9877e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 285/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.8264e-04 - val_loss: 5.5469e-04\n",
      "Epoch 286/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 5.2224e-04 - val_loss: 7.1140e-04\n",
      "Epoch 287/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 5.4088e-04 - val_loss: 5.9529e-04\n",
      "Epoch 288/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 4.9064e-04 - val_loss: 5.7172e-04\n",
      "Epoch 289/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 4.8019e-04 - val_loss: 5.7314e-04\n",
      "Epoch 290/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.7227e-04 - val_loss: 6.2611e-04\n",
      "Epoch 291/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 4.7511e-04 - val_loss: 6.5313e-04\n",
      "Epoch 292/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 4.8439e-04 - val_loss: 5.2621e-04\n",
      "Epoch 293/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 4.7337e-04 - val_loss: 5.2156e-04\n",
      "Epoch 294/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 4.8528e-04 - val_loss: 5.2410e-04\n",
      "Epoch 295/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 4.8544e-04 - val_loss: 5.9551e-04\n",
      "Epoch 296/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.7882e-04 - val_loss: 6.2304e-04\n",
      "Epoch 297/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.9451e-04 - val_loss: 5.1962e-04\n",
      "Epoch 298/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 4.9263e-04 - val_loss: 5.5852e-04\n",
      "Epoch 299/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 4.9828e-04 - val_loss: 5.2222e-04\n",
      "Epoch 300/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 4.7602e-04 - val_loss: 5.2361e-04\n",
      "Epoch 301/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.7595e-04 - val_loss: 6.6747e-04\n",
      "Epoch 302/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 5.0902e-04 - val_loss: 6.1966e-04\n",
      "Epoch 303/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 5.0177e-04 - val_loss: 7.3395e-04\n",
      "Epoch 304/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 5.7585e-04 - val_loss: 0.0011\n",
      "Epoch 305/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 5.9877e-04 - val_loss: 6.4602e-04\n",
      "Epoch 306/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 5.6294e-04 - val_loss: 5.2288e-04\n",
      "Epoch 307/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 5.4436e-04 - val_loss: 5.7156e-04\n",
      "Epoch 308/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 5.0638e-04 - val_loss: 5.3663e-04\n",
      "Epoch 309/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 4.7055e-04 - val_loss: 5.2392e-04\n",
      "Epoch 310/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 4.9641e-04 - val_loss: 5.6642e-04\n",
      "Epoch 311/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 5.0799e-04 - val_loss: 5.2139e-04\n",
      "Epoch 312/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 5.0408e-04 - val_loss: 5.2581e-04\n",
      "Epoch 313/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.7732e-04 - val_loss: 6.5192e-04\n",
      "Epoch 314/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 4.8769e-04 - val_loss: 8.2767e-04\n",
      "Epoch 315/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 5.2209e-04 - val_loss: 5.4369e-04\n",
      "Epoch 316/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 4.9347e-04 - val_loss: 5.3329e-04\n",
      "Epoch 317/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.8792e-04 - val_loss: 5.3415e-04\n",
      "Epoch 318/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 4.6742e-04 - val_loss: 5.1947e-04\n",
      "Epoch 319/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 4.8621e-04 - val_loss: 5.4456e-04\n",
      "Epoch 320/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.7645e-04 - val_loss: 5.2513e-04\n",
      "Epoch 321/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.6768e-04 - val_loss: 5.2915e-04\n",
      "Epoch 322/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 4.7000e-04 - val_loss: 5.2203e-04\n",
      "Epoch 323/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.6974e-04 - val_loss: 5.4595e-04\n",
      "Epoch 324/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.6222e-04 - val_loss: 5.5185e-04\n",
      "Epoch 325/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 4.8901e-04 - val_loss: 5.8004e-04\n",
      "Epoch 326/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 5.4078e-04 - val_loss: 6.8266e-04\n",
      "Epoch 327/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 5.6640e-04 - val_loss: 6.0180e-04\n",
      "Epoch 328/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 5.8693e-04 - val_loss: 7.1077e-04\n",
      "Epoch 329/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 5.5399e-04 - val_loss: 7.6108e-04\n",
      "Epoch 330/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 5.3438e-04 - val_loss: 5.6351e-04\n",
      "Epoch 331/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 5.8827e-04 - val_loss: 5.2182e-04\n",
      "Epoch 332/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.9522e-04 - val_loss: 5.2186e-04\n",
      "Epoch 333/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.8864e-04 - val_loss: 5.2117e-04\n",
      "Epoch 334/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 4.7838e-04 - val_loss: 6.8908e-04\n",
      "Epoch 335/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.8241e-04 - val_loss: 5.2470e-04\n",
      "Epoch 336/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 4.7113e-04 - val_loss: 5.7650e-04\n",
      "Epoch 337/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.8224e-04 - val_loss: 5.2064e-04\n",
      "Epoch 338/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 4.7976e-04 - val_loss: 5.2728e-04\n",
      "Epoch 339/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.6903e-04 - val_loss: 5.3218e-04\n",
      "Epoch 340/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 4.6778e-04 - val_loss: 5.3350e-04\n",
      "Epoch 341/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 4.7636e-04 - val_loss: 5.2202e-04\n",
      "Epoch 342/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 4.7869e-04 - val_loss: 5.2398e-04\n",
      "Epoch 343/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 4.7139e-04 - val_loss: 5.4342e-04\n",
      "Epoch 344/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 4.9988e-04 - val_loss: 7.8798e-04\n",
      "Epoch 345/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.9143e-04 - val_loss: 5.6665e-04\n",
      "Epoch 346/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 4.6985e-04 - val_loss: 5.2274e-04\n",
      "Epoch 347/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.6286e-04 - val_loss: 5.3787e-04\n",
      "Epoch 348/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.6380e-04 - val_loss: 7.0875e-04\n",
      "Epoch 349/2000\n",
      "3891/3891 [==============================] - 1s 192us/step - loss: 5.0071e-04 - val_loss: 6.4182e-04\n",
      "Epoch 350/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.8020e-04 - val_loss: 5.4996e-04\n",
      "Epoch 351/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.6200e-04 - val_loss: 5.2255e-04\n",
      "Epoch 352/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 4.7090e-04 - val_loss: 5.2248e-04\n",
      "Epoch 353/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 4.6563e-04 - val_loss: 5.3521e-04\n",
      "Epoch 354/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 4.5683e-04 - val_loss: 5.2245e-04\n",
      "Epoch 355/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 4.8179e-04 - val_loss: 5.3445e-04\n",
      "Epoch 356/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.9945e-04 - val_loss: 5.5688e-04\n",
      "Epoch 357/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.7128e-04 - val_loss: 6.0510e-04\n",
      "Epoch 358/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 4.8476e-04 - val_loss: 5.6592e-04\n",
      "Epoch 359/2000\n",
      "3891/3891 [==============================] - 1s 181us/step - loss: 4.8999e-04 - val_loss: 5.6594e-04\n",
      "Epoch 360/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 4.8114e-04 - val_loss: 5.8019e-04\n",
      "Epoch 361/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 4.6374e-04 - val_loss: 5.7289e-04\n",
      "Epoch 362/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.6338e-04 - val_loss: 5.5281e-04\n",
      "Epoch 363/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 4.6420e-04 - val_loss: 5.3439e-04\n",
      "Epoch 364/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 4.5861e-04 - val_loss: 5.4214e-04\n",
      "Epoch 365/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 4.6213e-04 - val_loss: 5.1919e-04\n",
      "Epoch 366/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.8110e-04 - val_loss: 5.3009e-04\n",
      "Epoch 367/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 4.6649e-04 - val_loss: 5.1900e-04\n",
      "Epoch 368/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 4.6279e-04 - val_loss: 7.3082e-04\n",
      "Epoch 369/2000\n",
      "3891/3891 [==============================] - 1s 191us/step - loss: 5.1207e-04 - val_loss: 7.5341e-04\n",
      "Epoch 370/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 4.9185e-04 - val_loss: 5.6258e-04\n",
      "Epoch 371/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 4.6852e-04 - val_loss: 5.8377e-04\n",
      "Epoch 372/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 4.7357e-04 - val_loss: 5.5732e-04\n",
      "Epoch 373/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 4.6260e-04 - val_loss: 5.2141e-04\n",
      "Epoch 374/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.6934e-04 - val_loss: 5.2248e-04\n",
      "Epoch 375/2000\n",
      "3891/3891 [==============================] - 1s 191us/step - loss: 4.6290e-04 - val_loss: 5.2307e-04\n",
      "Epoch 376/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 4.5798e-04 - val_loss: 5.4251e-04\n",
      "Epoch 377/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 4.6488e-04 - val_loss: 5.4167e-04\n",
      "Epoch 378/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 4.8273e-04 - val_loss: 5.1928e-04\n",
      "Epoch 379/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.9734e-04 - val_loss: 5.3497e-04\n",
      "Epoch 380/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 4.8146e-04 - val_loss: 5.2485e-04\n",
      "Epoch 381/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 4.7146e-04 - val_loss: 5.2715e-04\n",
      "Epoch 382/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 4.7374e-04 - val_loss: 5.3167e-04\n",
      "Epoch 383/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 4.6957e-04 - val_loss: 5.2616e-04\n",
      "Epoch 384/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 4.5919e-04 - val_loss: 5.2405e-04\n",
      "Epoch 385/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 4.5602e-04 - val_loss: 5.8714e-04\n",
      "Epoch 386/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 4.5618e-04 - val_loss: 5.7326e-04\n",
      "Epoch 387/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 4.6021e-04 - val_loss: 5.2493e-04\n",
      "Epoch 388/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 4.5023e-04 - val_loss: 5.3739e-04\n",
      "Epoch 389/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 4.6686e-04 - val_loss: 5.2871e-04\n",
      "Epoch 390/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 4.5167e-04 - val_loss: 5.2740e-04\n",
      "Epoch 391/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 4.6222e-04 - val_loss: 5.2606e-04\n",
      "Epoch 392/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 4.7110e-04 - val_loss: 5.6556e-04\n",
      "Epoch 393/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 4.8539e-04 - val_loss: 5.4679e-04\n",
      "Epoch 394/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 4.9896e-04 - val_loss: 5.4003e-04\n",
      "Epoch 395/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 4.9129e-04 - val_loss: 5.4350e-04\n",
      "Epoch 396/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 4.5461e-04 - val_loss: 6.0825e-04\n",
      "Epoch 397/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.7655e-04 - val_loss: 5.5850e-04\n",
      "Epoch 398/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.7295e-04 - val_loss: 5.2746e-04\n",
      "Epoch 399/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 4.6197e-04 - val_loss: 5.2644e-04\n",
      "Epoch 400/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.5597e-04 - val_loss: 5.6653e-04\n",
      "Epoch 401/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.6572e-04 - val_loss: 5.9534e-04\n",
      "Epoch 402/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.7225e-04 - val_loss: 7.4329e-04\n",
      "Epoch 403/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 4.9000e-04 - val_loss: 7.8964e-04\n",
      "Epoch 404/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 4.9007e-04 - val_loss: 5.2383e-04\n",
      "Epoch 405/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.6702e-04 - val_loss: 5.4757e-04\n",
      "Epoch 406/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 4.6434e-04 - val_loss: 5.6325e-04\n",
      "Epoch 407/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.4842e-04 - val_loss: 5.2884e-04\n",
      "Epoch 408/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 4.5316e-04 - val_loss: 5.2401e-04\n",
      "Epoch 409/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 4.5466e-04 - val_loss: 5.2969e-04\n",
      "Epoch 410/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 4.5037e-04 - val_loss: 6.7681e-04\n",
      "Epoch 411/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 4.9305e-04 - val_loss: 5.8636e-04\n",
      "Epoch 412/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 4.5748e-04 - val_loss: 5.8020e-04\n",
      "Epoch 413/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 4.6275e-04 - val_loss: 6.7392e-04\n",
      "Epoch 414/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 4.8744e-04 - val_loss: 8.1466e-04\n",
      "Epoch 415/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 4.9401e-04 - val_loss: 6.0699e-04\n",
      "Epoch 416/2000\n",
      "3891/3891 [==============================] - 1s 191us/step - loss: 4.5728e-04 - val_loss: 5.7805e-04\n",
      "Epoch 417/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 4.5229e-04 - val_loss: 5.8044e-04\n",
      "Epoch 418/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 4.5567e-04 - val_loss: 5.4206e-04\n",
      "Epoch 419/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 4.5342e-04 - val_loss: 5.2507e-04\n",
      "Epoch 420/2000\n",
      "3891/3891 [==============================] - 1s 191us/step - loss: 4.5350e-04 - val_loss: 5.2817e-04\n",
      "Epoch 421/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 4.6784e-04 - val_loss: 6.5899e-04\n",
      "Epoch 422/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 4.9659e-04 - val_loss: 7.1734e-04\n",
      "Epoch 423/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 4.9217e-04 - val_loss: 5.9107e-04\n",
      "Epoch 424/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 4.7041e-04 - val_loss: 5.5796e-04\n",
      "Epoch 425/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.5223e-04 - val_loss: 6.2056e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 426/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 4.6423e-04 - val_loss: 6.7390e-04\n",
      "Epoch 427/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.6226e-04 - val_loss: 5.9552e-04\n",
      "Epoch 428/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 4.4807e-04 - val_loss: 6.2166e-04\n",
      "Epoch 429/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.5652e-04 - val_loss: 5.5268e-04\n",
      "Epoch 430/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 4.6053e-04 - val_loss: 5.3991e-04\n",
      "Epoch 431/2000\n",
      "3891/3891 [==============================] - 1s 197us/step - loss: 4.4566e-04 - val_loss: 5.2876e-04\n",
      "Epoch 432/2000\n",
      "3891/3891 [==============================] - 1s 193us/step - loss: 4.5860e-04 - val_loss: 5.3530e-04\n",
      "Epoch 433/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.5294e-04 - val_loss: 5.9183e-04\n",
      "Epoch 434/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 4.5471e-04 - val_loss: 5.6146e-04\n",
      "Epoch 435/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.6583e-04 - val_loss: 5.5433e-04\n",
      "Epoch 436/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 4.9458e-04 - val_loss: 6.1315e-04\n",
      "Epoch 437/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 4.6529e-04 - val_loss: 5.3710e-04\n",
      "Epoch 438/2000\n",
      "3891/3891 [==============================] - 1s 192us/step - loss: 4.4618e-04 - val_loss: 5.6745e-04\n",
      "Epoch 439/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 4.4262e-04 - val_loss: 5.3046e-04\n",
      "Epoch 440/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 4.4445e-04 - val_loss: 5.3840e-04\n",
      "Epoch 441/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.4265e-04 - val_loss: 5.6625e-04\n",
      "Epoch 442/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.4158e-04 - val_loss: 5.3020e-04\n",
      "Epoch 443/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.4936e-04 - val_loss: 5.2733e-04\n",
      "Epoch 444/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 4.5997e-04 - val_loss: 5.2883e-04\n",
      "Epoch 445/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 4.4645e-04 - val_loss: 5.4314e-04\n",
      "Epoch 446/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.7430e-04 - val_loss: 6.1317e-04\n",
      "Epoch 447/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 4.6529e-04 - val_loss: 5.8909e-04\n",
      "Epoch 448/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.4632e-04 - val_loss: 5.3217e-04\n",
      "Epoch 449/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.4590e-04 - val_loss: 5.2837e-04\n",
      "Epoch 450/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 4.6704e-04 - val_loss: 6.2376e-04\n",
      "Epoch 451/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.6873e-04 - val_loss: 5.9974e-04\n",
      "Epoch 452/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 4.5878e-04 - val_loss: 5.2774e-04\n",
      "Epoch 453/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 4.7920e-04 - val_loss: 5.5746e-04\n",
      "Epoch 454/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 4.6473e-04 - val_loss: 5.3632e-04\n",
      "Epoch 455/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 4.3617e-04 - val_loss: 5.8969e-04\n",
      "Epoch 456/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 4.4974e-04 - val_loss: 5.3241e-04\n",
      "Epoch 457/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 4.5127e-04 - val_loss: 5.3902e-04\n",
      "Epoch 458/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 4.8698e-04 - val_loss: 5.2535e-04\n",
      "Epoch 459/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 4.3955e-04 - val_loss: 5.3613e-04\n",
      "Epoch 460/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 4.5462e-04 - val_loss: 5.3551e-04\n",
      "Epoch 461/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 4.6336e-04 - val_loss: 5.3424e-04\n",
      "Epoch 462/2000\n",
      "3891/3891 [==============================] - 1s 191us/step - loss: 4.6129e-04 - val_loss: 5.4564e-04\n",
      "Epoch 463/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 5.0629e-04 - val_loss: 6.6071e-04\n",
      "Epoch 464/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 5.1671e-04 - val_loss: 5.4606e-04\n",
      "Epoch 465/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 4.4684e-04 - val_loss: 5.8080e-04\n",
      "Epoch 466/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.6165e-04 - val_loss: 5.3280e-04\n",
      "Epoch 467/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 4.5019e-04 - val_loss: 6.0800e-04\n",
      "Epoch 468/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.9527e-04 - val_loss: 6.2327e-04\n",
      "Epoch 469/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 4.8625e-04 - val_loss: 6.0867e-04\n",
      "Epoch 470/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 4.6098e-04 - val_loss: 5.3173e-04\n",
      "Epoch 471/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 4.6085e-04 - val_loss: 5.3534e-04\n",
      "Epoch 472/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 4.3620e-04 - val_loss: 5.3449e-04\n",
      "Epoch 473/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 4.3998e-04 - val_loss: 5.5286e-04\n",
      "Epoch 474/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 4.7282e-04 - val_loss: 5.5986e-04\n",
      "Epoch 475/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 5.2712e-04 - val_loss: 6.4973e-04\n",
      "Epoch 476/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 4.7482e-04 - val_loss: 5.9077e-04\n",
      "Epoch 477/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.5426e-04 - val_loss: 5.2363e-04\n",
      "Epoch 478/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 4.5083e-04 - val_loss: 5.4422e-04\n",
      "Epoch 479/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 4.4794e-04 - val_loss: 5.2746e-04\n",
      "Epoch 480/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 4.4086e-04 - val_loss: 5.4248e-04\n",
      "Epoch 481/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 4.3897e-04 - val_loss: 5.4070e-04\n",
      "Epoch 482/2000\n",
      "3891/3891 [==============================] - 1s 192us/step - loss: 4.3332e-04 - val_loss: 5.5331e-04\n",
      "Epoch 483/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 4.3426e-04 - val_loss: 5.7770e-04\n",
      "Epoch 484/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 4.3977e-04 - val_loss: 7.0524e-04\n",
      "Epoch 485/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 5.0473e-04 - val_loss: 7.5567e-04\n",
      "Epoch 486/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 5.0511e-04 - val_loss: 5.5313e-04\n",
      "Epoch 487/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 4.7261e-04 - val_loss: 5.4901e-04\n",
      "Epoch 488/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 5.1029e-04 - val_loss: 5.3764e-04\n",
      "Epoch 489/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 4.8864e-04 - val_loss: 5.8088e-04\n",
      "Epoch 490/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 4.6678e-04 - val_loss: 5.8060e-04\n",
      "Epoch 491/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.4114e-04 - val_loss: 5.5422e-04\n",
      "Epoch 492/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 4.3462e-04 - val_loss: 5.3808e-04\n",
      "Epoch 493/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 4.3929e-04 - val_loss: 5.8417e-04\n",
      "Epoch 494/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 4.5713e-04 - val_loss: 5.4758e-04\n",
      "Epoch 495/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 4.4215e-04 - val_loss: 5.4706e-04\n",
      "Epoch 496/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 4.4836e-04 - val_loss: 5.3836e-04\n",
      "Epoch 497/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 4.3855e-04 - val_loss: 5.3239e-04\n",
      "Epoch 498/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.4530e-04 - val_loss: 5.9262e-04\n",
      "Epoch 499/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 4.7502e-04 - val_loss: 5.3491e-04\n",
      "Epoch 500/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 4.3811e-04 - val_loss: 5.3640e-04\n",
      "Epoch 501/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 4.3108e-04 - val_loss: 5.3871e-04\n",
      "Epoch 502/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.5349e-04 - val_loss: 5.4123e-04\n",
      "Epoch 503/2000\n",
      "3891/3891 [==============================] - 1s 197us/step - loss: 4.8585e-04 - val_loss: 5.6904e-04\n",
      "Epoch 504/2000\n",
      "3891/3891 [==============================] - 1s 191us/step - loss: 4.5938e-04 - val_loss: 6.8192e-04\n",
      "Epoch 505/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 4.6769e-04 - val_loss: 6.2440e-04\n",
      "Epoch 506/2000\n",
      "3891/3891 [==============================] - 1s 191us/step - loss: 4.4216e-04 - val_loss: 5.4893e-04\n",
      "Epoch 507/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 4.3035e-04 - val_loss: 5.5957e-04\n",
      "Epoch 508/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 4.3965e-04 - val_loss: 5.7422e-04\n",
      "Epoch 509/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 4.5453e-04 - val_loss: 8.3592e-04\n",
      "Epoch 510/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.7495e-04 - val_loss: 5.6020e-04\n",
      "Epoch 511/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 5.0324e-04 - val_loss: 5.6186e-04\n",
      "Epoch 512/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 5.2723e-04 - val_loss: 5.6315e-04ETA: 0s - loss: 5.1708e\n",
      "Epoch 513/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 4.9764e-04 - val_loss: 5.9694e-04\n",
      "Epoch 514/2000\n",
      "3891/3891 [==============================] - 1s 192us/step - loss: 5.1259e-04 - val_loss: 7.4819e-04\n",
      "Epoch 515/2000\n",
      "3891/3891 [==============================] - 1s 192us/step - loss: 5.1437e-04 - val_loss: 5.7979e-04\n",
      "Epoch 516/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 5.0206e-04 - val_loss: 7.0677e-04\n",
      "Epoch 517/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 4.6676e-04 - val_loss: 6.2197e-04\n",
      "Epoch 518/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 4.4547e-04 - val_loss: 5.5655e-04\n",
      "Epoch 519/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.3005e-04 - val_loss: 5.4025e-04\n",
      "Epoch 520/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 4.2079e-04 - val_loss: 5.4795e-04\n",
      "Epoch 521/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 4.3135e-04 - val_loss: 5.8907e-04\n",
      "Epoch 522/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 4.5979e-04 - val_loss: 7.2673e-04\n",
      "Epoch 523/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 4.6310e-04 - val_loss: 5.3489e-04\n",
      "Epoch 524/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 4.3589e-04 - val_loss: 5.4472e-04\n",
      "Epoch 525/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 4.4274e-04 - val_loss: 6.1521e-04\n",
      "Epoch 526/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 4.2594e-04 - val_loss: 5.5407e-04\n",
      "Epoch 527/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 4.1547e-04 - val_loss: 5.4820e-04\n",
      "Epoch 528/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 4.1513e-04 - val_loss: 5.7257e-04\n",
      "Epoch 529/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 4.2688e-04 - val_loss: 5.5197e-04\n",
      "Epoch 530/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.3870e-04 - val_loss: 5.5851e-04\n",
      "Epoch 531/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 4.5124e-04 - val_loss: 5.6137e-04\n",
      "Epoch 532/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 4.3230e-04 - val_loss: 5.6271e-04\n",
      "Epoch 533/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 4.4608e-04 - val_loss: 5.5682e-04\n",
      "Epoch 534/2000\n",
      "3891/3891 [==============================] - 1s 192us/step - loss: 4.2463e-04 - val_loss: 5.5779e-04\n",
      "Epoch 535/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 4.2139e-04 - val_loss: 5.4082e-04\n",
      "Epoch 536/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 4.1968e-04 - val_loss: 5.4150e-04\n",
      "Epoch 537/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 4.1239e-04 - val_loss: 5.6529e-04\n",
      "Epoch 538/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 4.2370e-04 - val_loss: 6.4501e-04\n",
      "Epoch 539/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 4.5568e-04 - val_loss: 7.0663e-04\n",
      "Epoch 540/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 4.7254e-04 - val_loss: 6.0514e-04\n",
      "Epoch 541/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 4.3643e-04 - val_loss: 6.0100e-04\n",
      "Epoch 542/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 4.4502e-04 - val_loss: 6.2124e-04\n",
      "Epoch 543/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 4.5164e-04 - val_loss: 5.6931e-04\n",
      "Epoch 544/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 4.3916e-04 - val_loss: 5.8069e-04\n",
      "Epoch 545/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 4.1841e-04 - val_loss: 5.5835e-04\n",
      "Epoch 546/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 4.1948e-04 - val_loss: 5.7263e-04\n",
      "Epoch 547/2000\n",
      "3891/3891 [==============================] - 1s 192us/step - loss: 4.3029e-04 - val_loss: 5.4761e-04\n",
      "Epoch 548/2000\n",
      "3891/3891 [==============================] - 1s 199us/step - loss: 4.1602e-04 - val_loss: 5.5027e-04\n",
      "Epoch 549/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 4.3014e-04 - val_loss: 6.0698e-04\n",
      "Epoch 550/2000\n",
      "3891/3891 [==============================] - 1s 192us/step - loss: 4.1814e-04 - val_loss: 5.8285e-04\n",
      "Epoch 551/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 4.1699e-04 - val_loss: 5.5993e-04\n",
      "Epoch 552/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 4.0133e-04 - val_loss: 5.7229e-04\n",
      "Epoch 553/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 4.0516e-04 - val_loss: 5.5404e-04\n",
      "Epoch 554/2000\n",
      "3891/3891 [==============================] - 1s 193us/step - loss: 4.0922e-04 - val_loss: 5.6101e-04\n",
      "Epoch 555/2000\n",
      "3891/3891 [==============================] - 1s 193us/step - loss: 4.1125e-04 - val_loss: 5.7312e-04\n",
      "Epoch 556/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 4.0544e-04 - val_loss: 5.6527e-04\n",
      "Epoch 557/2000\n",
      "3891/3891 [==============================] - 1s 195us/step - loss: 4.0112e-04 - val_loss: 5.5096e-04\n",
      "Epoch 558/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 4.0679e-04 - val_loss: 5.6799e-04\n",
      "Epoch 559/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 4.1029e-04 - val_loss: 5.5307e-04\n",
      "Epoch 560/2000\n",
      "3891/3891 [==============================] - 1s 194us/step - loss: 4.1946e-04 - val_loss: 5.5888e-04\n",
      "Epoch 561/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 4.0699e-04 - val_loss: 5.4467e-04\n",
      "Epoch 562/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 4.0208e-04 - val_loss: 6.0040e-04\n",
      "Epoch 563/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.0482e-04 - val_loss: 5.7033e-04\n",
      "Epoch 564/2000\n",
      "3891/3891 [==============================] - 1s 192us/step - loss: 4.1809e-04 - val_loss: 6.2681e-04\n",
      "Epoch 565/2000\n",
      "3891/3891 [==============================] - 1s 215us/step - loss: 4.4218e-04 - val_loss: 5.8120e-04\n",
      "Epoch 566/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 1s 200us/step - loss: 4.2124e-04 - val_loss: 5.8001e-04\n",
      "Epoch 567/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 4.2805e-04 - val_loss: 5.4500e-04\n",
      "Epoch 568/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 4.4892e-04 - val_loss: 5.6385e-04\n",
      "Epoch 569/2000\n",
      "3891/3891 [==============================] - 1s 192us/step - loss: 4.3276e-04 - val_loss: 5.8529e-04\n",
      "Epoch 570/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 4.1200e-04 - val_loss: 6.0842e-04\n",
      "Epoch 571/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 4.1577e-04 - val_loss: 5.8588e-04\n",
      "Epoch 572/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 3.9888e-04 - val_loss: 5.6437e-04\n",
      "Epoch 573/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 3.9784e-04 - val_loss: 5.6232e-04\n",
      "Epoch 574/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 4.0670e-04 - val_loss: 5.8608e-04\n",
      "Epoch 575/2000\n",
      "3891/3891 [==============================] - 1s 181us/step - loss: 4.3491e-04 - val_loss: 5.6420e-04\n",
      "Epoch 576/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 3.9469e-04 - val_loss: 5.6987e-04\n",
      "Epoch 577/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 4.0242e-04 - val_loss: 6.0361e-04\n",
      "Epoch 578/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.1103e-04 - val_loss: 5.7748e-04\n",
      "Epoch 579/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 4.1079e-04 - val_loss: 5.7353e-04\n",
      "Epoch 580/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 4.3249e-04 - val_loss: 5.6650e-04\n",
      "Epoch 581/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 4.1740e-04 - val_loss: 7.2629e-04\n",
      "Epoch 582/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 4.6455e-04 - val_loss: 8.8750e-04\n",
      "Epoch 583/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 4.5107e-04 - val_loss: 7.6068e-04\n",
      "Epoch 584/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 4.2790e-04 - val_loss: 5.3981e-04\n",
      "Epoch 585/2000\n",
      "3891/3891 [==============================] - 1s 196us/step - loss: 4.1673e-04 - val_loss: 5.6969e-04\n",
      "Epoch 586/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 3.9623e-04 - val_loss: 5.7951e-04\n",
      "Epoch 587/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 3.9622e-04 - val_loss: 5.8511e-04\n",
      "Epoch 588/2000\n",
      "3891/3891 [==============================] - 1s 192us/step - loss: 3.8674e-04 - val_loss: 5.7779e-04\n",
      "Epoch 589/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 3.9518e-04 - val_loss: 5.6118e-04\n",
      "Epoch 590/2000\n",
      "3891/3891 [==============================] - 1s 193us/step - loss: 3.9076e-04 - val_loss: 5.8654e-04\n",
      "Epoch 591/2000\n",
      "3891/3891 [==============================] - 1s 197us/step - loss: 4.0163e-04 - val_loss: 7.0779e-04\n",
      "Epoch 592/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 4.2261e-04 - val_loss: 5.8487e-04\n",
      "Epoch 593/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 3.9444e-04 - val_loss: 5.7867e-04\n",
      "Epoch 594/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 3.9710e-04 - val_loss: 5.7368e-04\n",
      "Epoch 595/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 4.0704e-04 - val_loss: 6.9156e-04\n",
      "Epoch 596/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 4.2687e-04 - val_loss: 6.0492e-04\n",
      "Epoch 597/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 4.1855e-04 - val_loss: 5.8840e-04\n",
      "Epoch 598/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 4.0240e-04 - val_loss: 5.9349e-04\n",
      "Epoch 599/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 3.8966e-04 - val_loss: 6.8671e-04\n",
      "Epoch 600/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 4.1089e-04 - val_loss: 6.7378e-04\n",
      "Epoch 601/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 4.0253e-04 - val_loss: 6.2851e-04\n",
      "Epoch 602/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 4.2335e-04 - val_loss: 6.1400e-04\n",
      "Epoch 603/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 4.5717e-04 - val_loss: 6.5091e-04\n",
      "Epoch 604/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 4.3607e-04 - val_loss: 5.9501e-04\n",
      "Epoch 605/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 3.9119e-04 - val_loss: 5.5058e-04\n",
      "Epoch 606/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 3.9480e-04 - val_loss: 6.7886e-04\n",
      "Epoch 607/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 4.2258e-04 - val_loss: 6.7087e-04\n",
      "Epoch 608/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 3.9046e-04 - val_loss: 7.0417e-04\n",
      "Epoch 609/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 4.1332e-04 - val_loss: 6.3174e-04\n",
      "Epoch 610/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 3.9903e-04 - val_loss: 5.9271e-04\n",
      "Epoch 611/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 3.8006e-04 - val_loss: 6.0585e-04\n",
      "Epoch 612/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 3.8107e-04 - val_loss: 5.6347e-04\n",
      "Epoch 613/2000\n",
      "3891/3891 [==============================] - 1s 191us/step - loss: 3.8620e-04 - val_loss: 5.7042e-04\n",
      "Epoch 614/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 3.9028e-04 - val_loss: 5.8294e-04\n",
      "Epoch 615/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 3.8935e-04 - val_loss: 5.9543e-04\n",
      "Epoch 616/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 3.7616e-04 - val_loss: 6.0290e-04\n",
      "Epoch 617/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 3.8457e-04 - val_loss: 5.7603e-04\n",
      "Epoch 618/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 3.8961e-04 - val_loss: 7.0577e-04\n",
      "Epoch 619/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 3.8788e-04 - val_loss: 5.7341e-04\n",
      "Epoch 620/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 3.7946e-04 - val_loss: 6.4019e-04\n",
      "Epoch 621/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 3.7948e-04 - val_loss: 5.6641e-04\n",
      "Epoch 622/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 3.6798e-04 - val_loss: 5.9983e-04\n",
      "Epoch 623/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 3.9346e-04 - val_loss: 5.9335e-04\n",
      "Epoch 624/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 3.9256e-04 - val_loss: 6.0366e-04\n",
      "Epoch 625/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 3.8569e-04 - val_loss: 5.7384e-04\n",
      "Epoch 626/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 3.7726e-04 - val_loss: 5.7038e-04\n",
      "Epoch 627/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.0001e-04 - val_loss: 6.1368e-04\n",
      "Epoch 628/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 3.7815e-04 - val_loss: 6.1497e-04\n",
      "Epoch 629/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 4.2798e-04 - val_loss: 7.0076e-04\n",
      "Epoch 630/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.1051e-04 - val_loss: 6.0012e-04\n",
      "Epoch 631/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.1192e-04 - val_loss: 5.6807e-04\n",
      "Epoch 632/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.0529e-04 - val_loss: 5.5772e-04\n",
      "Epoch 633/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 3.8200e-04 - val_loss: 5.9119e-04\n",
      "Epoch 634/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 3.9317e-04 - val_loss: 5.7798e-04\n",
      "Epoch 635/2000\n",
      "3891/3891 [==============================] - 1s 194us/step - loss: 3.7991e-04 - val_loss: 7.8522e-04\n",
      "Epoch 636/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 4.0867e-04 - val_loss: 5.5986e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 637/2000\n",
      "3891/3891 [==============================] - 1s 194us/step - loss: 3.6975e-04 - val_loss: 8.2805e-04\n",
      "Epoch 638/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 4.2844e-04 - val_loss: 6.8158e-04\n",
      "Epoch 639/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 4.0311e-04 - val_loss: 7.0686e-04\n",
      "Epoch 640/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 3.9097e-04 - val_loss: 7.1658e-04\n",
      "Epoch 641/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 3.9356e-04 - val_loss: 5.7428e-04\n",
      "Epoch 642/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 3.7835e-04 - val_loss: 5.9447e-04\n",
      "Epoch 643/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 3.8113e-04 - val_loss: 5.9959e-04\n",
      "Epoch 644/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 4.0506e-04 - val_loss: 6.2385e-04\n",
      "Epoch 645/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 4.0266e-04 - val_loss: 6.2305e-04\n",
      "Epoch 646/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 3.9215e-04 - val_loss: 5.9030e-04\n",
      "Epoch 647/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 3.7143e-04 - val_loss: 6.0322e-04\n",
      "Epoch 648/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 3.8889e-04 - val_loss: 6.3727e-04\n",
      "Epoch 649/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 3.9343e-04 - val_loss: 5.5314e-04\n",
      "Epoch 650/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 3.6536e-04 - val_loss: 5.8486e-04\n",
      "Epoch 651/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 3.6321e-04 - val_loss: 5.3877e-04\n",
      "Epoch 652/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 3.6078e-04 - val_loss: 6.4577e-04\n",
      "Epoch 653/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 3.6108e-04 - val_loss: 5.8977e-04\n",
      "Epoch 654/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 3.7075e-04 - val_loss: 7.0043e-04\n",
      "Epoch 655/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 3.8713e-04 - val_loss: 6.0921e-04\n",
      "Epoch 656/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 3.7551e-04 - val_loss: 5.6418e-04\n",
      "Epoch 657/2000\n",
      "3891/3891 [==============================] - 1s 192us/step - loss: 3.7460e-04 - val_loss: 6.1885e-04\n",
      "Epoch 658/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 3.4719e-04 - val_loss: 5.8286e-04\n",
      "Epoch 659/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 3.4923e-04 - val_loss: 6.3102e-04\n",
      "Epoch 660/2000\n",
      "3891/3891 [==============================] - 1s 194us/step - loss: 3.4778e-04 - val_loss: 6.0850e-04\n",
      "Epoch 661/2000\n",
      "3891/3891 [==============================] - 1s 195us/step - loss: 3.4388e-04 - val_loss: 6.2013e-04\n",
      "Epoch 662/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 3.5208e-04 - val_loss: 6.1466e-04\n",
      "Epoch 663/2000\n",
      "3891/3891 [==============================] - 1s 201us/step - loss: 3.7202e-04 - val_loss: 5.6839e-04\n",
      "Epoch 664/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 3.7303e-04 - val_loss: 5.7495e-04\n",
      "Epoch 665/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 3.7783e-04 - val_loss: 6.6556e-04\n",
      "Epoch 666/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 3.5192e-04 - val_loss: 5.9647e-04\n",
      "Epoch 667/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 3.7398e-04 - val_loss: 7.0421e-04\n",
      "Epoch 668/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 3.4223e-04 - val_loss: 6.1891e-04\n",
      "Epoch 669/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 3.4414e-04 - val_loss: 6.0601e-04\n",
      "Epoch 670/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 3.3763e-04 - val_loss: 6.1252e-04\n",
      "Epoch 671/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 3.3299e-04 - val_loss: 6.7696e-04\n",
      "Epoch 672/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 3.5384e-04 - val_loss: 6.4192e-04\n",
      "Epoch 673/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 3.4104e-04 - val_loss: 6.6598e-04\n",
      "Epoch 674/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 3.5112e-04 - val_loss: 5.9827e-04\n",
      "Epoch 675/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 3.5551e-04 - val_loss: 7.1441e-04\n",
      "Epoch 676/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 3.3512e-04 - val_loss: 7.5315e-04\n",
      "Epoch 677/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 3.3099e-04 - val_loss: 6.2178e-04\n",
      "Epoch 678/2000\n",
      "3891/3891 [==============================] - 1s 194us/step - loss: 3.4482e-04 - val_loss: 6.4754e-04\n",
      "Epoch 679/2000\n",
      "3891/3891 [==============================] - 1s 192us/step - loss: 3.3873e-04 - val_loss: 6.5946e-04\n",
      "Epoch 680/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 3.4899e-04 - val_loss: 6.7532e-04\n",
      "Epoch 681/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 3.4716e-04 - val_loss: 6.3085e-04\n",
      "Epoch 682/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 3.3361e-04 - val_loss: 6.5682e-04\n",
      "Epoch 683/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 3.3407e-04 - val_loss: 6.5852e-04\n",
      "Epoch 684/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 3.7749e-04 - val_loss: 7.5047e-04\n",
      "Epoch 685/2000\n",
      "3891/3891 [==============================] - 1s 197us/step - loss: 3.5306e-04 - val_loss: 7.0199e-04\n",
      "Epoch 686/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 3.5946e-04 - val_loss: 7.3841e-04\n",
      "Epoch 687/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 3.5890e-04 - val_loss: 5.8499e-04\n",
      "Epoch 688/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 4.5705e-04 - val_loss: 7.9379e-04\n",
      "Epoch 689/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 4.1415e-04 - val_loss: 6.1713e-04\n",
      "Epoch 690/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 3.7063e-04 - val_loss: 7.9559e-04\n",
      "Epoch 691/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 3.4966e-04 - val_loss: 6.7534e-04\n",
      "Epoch 692/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 3.8628e-04 - val_loss: 0.0010\n",
      "Epoch 693/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 3.8774e-04 - val_loss: 7.7385e-04\n",
      "Epoch 694/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 4.0011e-04 - val_loss: 6.7781e-04\n",
      "Epoch 695/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 3.4583e-04 - val_loss: 7.9176e-04\n",
      "Epoch 696/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 3.4664e-04 - val_loss: 7.7470e-04\n",
      "Epoch 697/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 3.3816e-04 - val_loss: 5.9428e-04\n",
      "Epoch 698/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 3.4026e-04 - val_loss: 7.4105e-04\n",
      "Epoch 699/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 3.2919e-04 - val_loss: 6.6780e-04\n",
      "Epoch 700/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 3.2938e-04 - val_loss: 7.4478e-04\n",
      "Epoch 701/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 3.2586e-04 - val_loss: 7.1106e-04\n",
      "Epoch 702/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 3.1787e-04 - val_loss: 6.8280e-04\n",
      "Epoch 703/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 3.0824e-04 - val_loss: 7.3831e-04\n",
      "Epoch 704/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 3.1429e-04 - val_loss: 7.3267e-04\n",
      "Epoch 705/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 3.4656e-04 - val_loss: 6.9950e-04\n",
      "Epoch 706/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 3.5064e-04 - val_loss: 7.7245e-04\n",
      "Epoch 707/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 3.4229e-04 - val_loss: 7.0174e-04\n",
      "Epoch 708/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 3.1980e-04 - val_loss: 7.2008e-04\n",
      "Epoch 709/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 3.3529e-04 - val_loss: 6.9728e-04\n",
      "Epoch 710/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 3.2679e-04 - val_loss: 7.5586e-04\n",
      "Epoch 711/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 3.1066e-04 - val_loss: 7.2565e-04\n",
      "Epoch 712/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 3.1288e-04 - val_loss: 7.4831e-04\n",
      "Epoch 713/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 3.2622e-04 - val_loss: 9.3897e-04\n",
      "Epoch 714/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 3.5869e-04 - val_loss: 7.6380e-04\n",
      "Epoch 715/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 3.7838e-04 - val_loss: 9.6952e-04\n",
      "Epoch 716/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 4.0020e-04 - val_loss: 0.0010\n",
      "Epoch 717/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 3.9655e-04 - val_loss: 0.0012\n",
      "Epoch 718/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 4.0183e-04 - val_loss: 8.1687e-04\n",
      "Epoch 719/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 3.6496e-04 - val_loss: 7.8719e-04\n",
      "Epoch 720/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 3.3780e-04 - val_loss: 6.7906e-04\n",
      "Epoch 721/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 3.2527e-04 - val_loss: 6.9546e-04\n",
      "Epoch 722/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 3.1459e-04 - val_loss: 7.9911e-04\n",
      "Epoch 723/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 3.3267e-04 - val_loss: 6.8857e-04\n",
      "Epoch 724/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 2.9883e-04 - val_loss: 7.2813e-04\n",
      "Epoch 725/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 3.2354e-04 - val_loss: 7.4506e-04\n",
      "Epoch 726/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 3.3409e-04 - val_loss: 7.1766e-04\n",
      "Epoch 727/2000\n",
      "3891/3891 [==============================] - 1s 181us/step - loss: 3.3640e-04 - val_loss: 6.8281e-04\n",
      "Epoch 728/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 3.2684e-04 - val_loss: 8.7689e-04\n",
      "Epoch 729/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 3.1088e-04 - val_loss: 7.7485e-04\n",
      "Epoch 730/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 2.8673e-04 - val_loss: 7.7750e-04\n",
      "Epoch 731/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 2.9901e-04 - val_loss: 7.3966e-04\n",
      "Epoch 732/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 3.1637e-04 - val_loss: 7.7972e-04\n",
      "Epoch 733/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 2.9742e-04 - val_loss: 7.7244e-04\n",
      "Epoch 734/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 3.0828e-04 - val_loss: 7.4537e-04\n",
      "Epoch 735/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 2.9684e-04 - val_loss: 6.7628e-04\n",
      "Epoch 736/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 2.9174e-04 - val_loss: 7.3798e-04\n",
      "Epoch 737/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 2.8582e-04 - val_loss: 7.5990e-04\n",
      "Epoch 738/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 2.8731e-04 - val_loss: 8.1924e-04\n",
      "Epoch 739/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 2.8130e-04 - val_loss: 7.3866e-04\n",
      "Epoch 740/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 2.7942e-04 - val_loss: 7.4268e-04\n",
      "Epoch 741/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 2.7648e-04 - val_loss: 7.3132e-04\n",
      "Epoch 742/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 2.8745e-04 - val_loss: 7.4931e-04\n",
      "Epoch 743/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 2.8603e-04 - val_loss: 7.8462e-04\n",
      "Epoch 744/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 2.7528e-04 - val_loss: 9.4825e-04\n",
      "Epoch 745/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 2.8560e-04 - val_loss: 9.1922e-04\n",
      "Epoch 746/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 2.8900e-04 - val_loss: 7.7988e-04\n",
      "Epoch 747/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 2.7931e-04 - val_loss: 8.6198e-04\n",
      "Epoch 748/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 2.8848e-04 - val_loss: 8.7038e-04\n",
      "Epoch 749/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 2.7760e-04 - val_loss: 8.6863e-04\n",
      "Epoch 750/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 3.0823e-04 - val_loss: 0.0010\n",
      "Epoch 751/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 2.9441e-04 - val_loss: 9.4490e-04\n",
      "Epoch 752/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 2.7216e-04 - val_loss: 8.6383e-04\n",
      "Epoch 753/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 2.6623e-04 - val_loss: 0.0010\n",
      "Epoch 754/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 2.6977e-04 - val_loss: 8.8297e-04\n",
      "Epoch 755/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 2.6475e-04 - val_loss: 8.6225e-04\n",
      "Epoch 756/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 2.8593e-04 - val_loss: 8.8652e-04\n",
      "Epoch 757/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 2.7056e-04 - val_loss: 8.2809e-04\n",
      "Epoch 758/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 3.0380e-04 - val_loss: 9.3090e-04\n",
      "Epoch 759/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 2.9195e-04 - val_loss: 9.2853e-04\n",
      "Epoch 760/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 3.2110e-04 - val_loss: 8.3339e-04\n",
      "Epoch 761/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 3.0511e-04 - val_loss: 7.8904e-04\n",
      "Epoch 762/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 2.8704e-04 - val_loss: 8.4116e-04\n",
      "Epoch 763/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 2.7350e-04 - val_loss: 8.3167e-04\n",
      "Epoch 764/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 2.6569e-04 - val_loss: 9.0526e-04\n",
      "Epoch 765/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 2.6372e-04 - val_loss: 8.2576e-04\n",
      "Epoch 766/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 2.9529e-04 - val_loss: 8.8585e-04\n",
      "Epoch 767/2000\n",
      "3891/3891 [==============================] - 1s 200us/step - loss: 2.8762e-04 - val_loss: 8.5285e-04\n",
      "Epoch 768/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 2.7098e-04 - val_loss: 9.0064e-04\n",
      "Epoch 769/2000\n",
      "3891/3891 [==============================] - 1s 192us/step - loss: 2.7812e-04 - val_loss: 8.2213e-04\n",
      "Epoch 770/2000\n",
      "3891/3891 [==============================] - 1s 195us/step - loss: 2.8371e-04 - val_loss: 8.6210e-04\n",
      "Epoch 771/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 2.6825e-04 - val_loss: 9.4323e-04\n",
      "Epoch 772/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 2.5574e-04 - val_loss: 9.5503e-04\n",
      "Epoch 773/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 2.7042e-04 - val_loss: 9.8842e-04\n",
      "Epoch 774/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 2.8009e-04 - val_loss: 9.9235e-04\n",
      "Epoch 775/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 2.5637e-04 - val_loss: 9.7544e-04\n",
      "Epoch 776/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 2.5689e-04 - val_loss: 0.0012\n",
      "Epoch 777/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 3.0248e-04 - val_loss: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 778/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 2.5119e-04 - val_loss: 9.6443e-04\n",
      "Epoch 779/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 2.5194e-04 - val_loss: 9.2399e-04\n",
      "Epoch 780/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 2.8221e-04 - val_loss: 8.1000e-04\n",
      "Epoch 781/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 2.7442e-04 - val_loss: 9.8078e-04\n",
      "Epoch 782/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 2.5515e-04 - val_loss: 9.5538e-04\n",
      "Epoch 783/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 2.6148e-04 - val_loss: 9.3648e-04\n",
      "Epoch 784/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 2.6550e-04 - val_loss: 0.0010-\n",
      "Epoch 785/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 2.5920e-04 - val_loss: 0.0010\n",
      "Epoch 786/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 2.6217e-04 - val_loss: 0.0010\n",
      "Epoch 787/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 3.0604e-04 - val_loss: 9.9633e-04\n",
      "Epoch 788/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 2.8339e-04 - val_loss: 8.6932e-04\n",
      "Epoch 789/2000\n",
      "3891/3891 [==============================] - 1s 191us/step - loss: 2.7844e-04 - val_loss: 8.8182e-04\n",
      "Epoch 790/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 2.6453e-04 - val_loss: 0.0012\n",
      "Epoch 791/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 2.9074e-04 - val_loss: 0.0011\n",
      "Epoch 792/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 2.8760e-04 - val_loss: 0.0010\n",
      "Epoch 793/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 2.7672e-04 - val_loss: 0.0011\n",
      "Epoch 794/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 2.7547e-04 - val_loss: 8.7019e-04\n",
      "Epoch 795/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 2.6309e-04 - val_loss: 9.4422e-04\n",
      "Epoch 796/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 2.5686e-04 - val_loss: 9.5162e-04\n",
      "Epoch 797/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 2.5139e-04 - val_loss: 9.9330e-04\n",
      "Epoch 798/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 2.5059e-04 - val_loss: 0.0011\n",
      "Epoch 799/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 2.6693e-04 - val_loss: 0.0011\n",
      "Epoch 800/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 2.7469e-04 - val_loss: 0.0010\n",
      "Epoch 801/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 2.7007e-04 - val_loss: 9.8845e-04\n",
      "Epoch 802/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 2.7651e-04 - val_loss: 0.0010\n",
      "Epoch 803/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 2.5355e-04 - val_loss: 0.0010\n",
      "Epoch 804/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 2.4938e-04 - val_loss: 9.7761e-04\n",
      "Epoch 805/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 2.3559e-04 - val_loss: 9.8221e-04\n",
      "Epoch 806/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 2.4117e-04 - val_loss: 9.8903e-04\n",
      "Epoch 807/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 2.3464e-04 - val_loss: 9.8923e-04\n",
      "Epoch 808/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 2.3466e-04 - val_loss: 9.8501e-04\n",
      "Epoch 809/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 2.4604e-04 - val_loss: 0.0011\n",
      "Epoch 810/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 2.7471e-04 - val_loss: 0.0011\n",
      "Epoch 811/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 2.6241e-04 - val_loss: 0.0011\n",
      "Epoch 812/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 2.4399e-04 - val_loss: 9.1409e-04\n",
      "Epoch 813/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 2.4023e-04 - val_loss: 0.0010\n",
      "Epoch 814/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 2.4581e-04 - val_loss: 0.0010\n",
      "Epoch 815/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 2.4183e-04 - val_loss: 9.4613e-04\n",
      "Epoch 816/2000\n",
      "3891/3891 [==============================] - 1s 201us/step - loss: 2.4476e-04 - val_loss: 9.5896e-04\n",
      "Epoch 817/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 2.4494e-04 - val_loss: 0.0011\n",
      "Epoch 818/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 2.4743e-04 - val_loss: 9.0629e-04\n",
      "Epoch 819/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 2.5488e-04 - val_loss: 9.0482e-04\n",
      "Epoch 820/2000\n",
      "3891/3891 [==============================] - 1s 194us/step - loss: 2.4932e-04 - val_loss: 0.0012\n",
      "Epoch 821/2000\n",
      "3891/3891 [==============================] - 1s 198us/step - loss: 2.4628e-04 - val_loss: 0.0011\n",
      "Epoch 822/2000\n",
      "3891/3891 [==============================] - 1s 193us/step - loss: 2.3647e-04 - val_loss: 0.0011\n",
      "Epoch 823/2000\n",
      "3891/3891 [==============================] - 1s 206us/step - loss: 2.4005e-04 - val_loss: 0.0011\n",
      "Epoch 824/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 2.6227e-04 - val_loss: 0.0011\n",
      "Epoch 825/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 2.5585e-04 - val_loss: 0.0011\n",
      "Epoch 826/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 2.4375e-04 - val_loss: 0.0011\n",
      "Epoch 827/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 2.4773e-04 - val_loss: 0.0010\n",
      "Epoch 828/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 2.6797e-04 - val_loss: 0.0010\n",
      "Epoch 829/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 2.4407e-04 - val_loss: 9.8956e-04\n",
      "Epoch 830/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 2.7489e-04 - val_loss: 0.0012\n",
      "Epoch 831/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 2.9028e-04 - val_loss: 0.0011\n",
      "Epoch 832/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 2.9152e-04 - val_loss: 0.0010\n",
      "Epoch 833/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 2.6203e-04 - val_loss: 0.0010\n",
      "Epoch 834/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 2.4846e-04 - val_loss: 0.0011\n",
      "Epoch 835/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 2.5151e-04 - val_loss: 0.0011\n",
      "Epoch 836/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 2.3472e-04 - val_loss: 0.0011\n",
      "Epoch 837/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 2.3765e-04 - val_loss: 0.0011\n",
      "Epoch 838/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 2.3470e-04 - val_loss: 0.0011\n",
      "Epoch 839/2000\n",
      "3891/3891 [==============================] - 1s 191us/step - loss: 2.3964e-04 - val_loss: 0.0011\n",
      "Epoch 840/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 2.4866e-04 - val_loss: 0.0011\n",
      "Epoch 841/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 2.8254e-04 - val_loss: 0.0014\n",
      "Epoch 842/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 3.3333e-04 - val_loss: 0.0010\n",
      "Epoch 843/2000\n",
      "3891/3891 [==============================] - 1s 195us/step - loss: 3.1204e-04 - val_loss: 0.0010\n",
      "Epoch 844/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 2.8400e-04 - val_loss: 0.0012\n",
      "Epoch 845/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 2.7661e-04 - val_loss: 0.0012\n",
      "Epoch 846/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 2.3305e-04 - val_loss: 0.0012\n",
      "Epoch 847/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 2.3222e-04 - val_loss: 0.0012\n",
      "Epoch 848/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 2.5780e-04 - val_loss: 0.0011\n",
      "Epoch 849/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 2.4995e-04 - val_loss: 0.0012\n",
      "Epoch 850/2000\n",
      "3891/3891 [==============================] - 1s 191us/step - loss: 2.4707e-04 - val_loss: 0.0014\n",
      "Epoch 851/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 2.6741e-04 - val_loss: 0.0014\n",
      "Epoch 852/2000\n",
      "3891/3891 [==============================] - 1s 192us/step - loss: 2.5956e-04 - val_loss: 0.0012\n",
      "Epoch 853/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 2.4478e-04 - val_loss: 0.0013\n",
      "Epoch 854/2000\n",
      "3891/3891 [==============================] - 1s 194us/step - loss: 2.3609e-04 - val_loss: 0.0010\n",
      "Epoch 855/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 2.2209e-04 - val_loss: 0.0011\n",
      "Epoch 856/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 2.1712e-04 - val_loss: 0.0013\n",
      "Epoch 857/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 2.6004e-04 - val_loss: 0.0013\n",
      "Epoch 858/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 2.6753e-04 - val_loss: 0.0012\n",
      "Epoch 859/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 2.4200e-04 - val_loss: 0.0012\n",
      "Epoch 860/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 2.4623e-04 - val_loss: 0.0012\n",
      "Epoch 861/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 2.5951e-04 - val_loss: 0.0011\n",
      "Epoch 862/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 2.2168e-04 - val_loss: 0.0013\n",
      "Epoch 863/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 2.2363e-04 - val_loss: 0.0012\n",
      "Epoch 864/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 2.1847e-04 - val_loss: 0.0013\n",
      "Epoch 865/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 2.1500e-04 - val_loss: 0.0013\n",
      "Epoch 866/2000\n",
      "3891/3891 [==============================] - 1s 192us/step - loss: 2.2512e-04 - val_loss: 0.0013\n",
      "Epoch 867/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 2.2000e-04 - val_loss: 0.0012\n",
      "Epoch 868/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 2.1363e-04 - val_loss: 0.0013\n",
      "Epoch 869/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 2.2086e-04 - val_loss: 0.0013\n",
      "Epoch 870/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 2.2971e-04 - val_loss: 0.0013\n",
      "Epoch 871/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 2.3164e-04 - val_loss: 0.0013\n",
      "Epoch 872/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 2.2721e-04 - val_loss: 0.0013\n",
      "Epoch 873/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 2.2385e-04 - val_loss: 0.0013\n",
      "Epoch 874/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 2.4086e-04 - val_loss: 0.0013\n",
      "Epoch 875/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 2.3527e-04 - val_loss: 0.0013\n",
      "Epoch 876/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 2.2993e-04 - val_loss: 0.0014\n",
      "Epoch 877/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 2.3884e-04 - val_loss: 0.0015\n",
      "Epoch 878/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 2.2591e-04 - val_loss: 0.0013\n",
      "Epoch 879/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 2.1648e-04 - val_loss: 0.0012\n",
      "Epoch 880/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 2.2317e-04 - val_loss: 0.0013\n",
      "Epoch 881/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 2.1614e-04 - val_loss: 0.0012-\n",
      "Epoch 882/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 2.2760e-04 - val_loss: 0.0012\n",
      "Epoch 883/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 2.3312e-04 - val_loss: 0.0013\n",
      "Epoch 884/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 2.1541e-04 - val_loss: 0.0013\n",
      "Epoch 885/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 2.0401e-04 - val_loss: 0.0014\n",
      "Epoch 886/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 2.2898e-04 - val_loss: 0.0013\n",
      "Epoch 887/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 2.1213e-04 - val_loss: 0.0013\n",
      "Epoch 888/2000\n",
      "3891/3891 [==============================] - 1s 181us/step - loss: 2.2797e-04 - val_loss: 0.0014\n",
      "Epoch 889/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 2.1010e-04 - val_loss: 0.0014\n",
      "Epoch 890/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 2.0180e-04 - val_loss: 0.0014\n",
      "Epoch 891/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 2.1653e-04 - val_loss: 0.0014\n",
      "Epoch 892/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 2.1543e-04 - val_loss: 0.0014\n",
      "Epoch 893/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 2.1588e-04 - val_loss: 0.0014\n",
      "Epoch 894/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 2.1326e-04 - val_loss: 0.0014\n",
      "Epoch 895/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 2.0420e-04 - val_loss: 0.0014-0\n",
      "Epoch 896/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 2.0138e-04 - val_loss: 0.0014\n",
      "Epoch 897/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 2.0591e-04 - val_loss: 0.0014\n",
      "Epoch 898/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 2.0594e-04 - val_loss: 0.0015\n",
      "Epoch 899/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 2.0231e-04 - val_loss: 0.0016\n",
      "Epoch 900/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 2.2511e-04 - val_loss: 0.0014\n",
      "Epoch 901/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 2.1499e-04 - val_loss: 0.0014\n",
      "Epoch 902/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 2.0654e-04 - val_loss: 0.0014\n",
      "Epoch 903/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 2.0990e-04 - val_loss: 0.0014\n",
      "Epoch 904/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 2.0463e-04 - val_loss: 0.0014\n",
      "Epoch 905/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 2.6754e-04 - val_loss: 0.0015\n",
      "Epoch 906/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 2.5675e-04 - val_loss: 0.0014\n",
      "Epoch 907/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 2.4242e-04 - val_loss: 0.0015\n",
      "Epoch 908/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 2.1437e-04 - val_loss: 0.0014\n",
      "Epoch 909/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 2.1246e-04 - val_loss: 0.0014\n",
      "Epoch 910/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 2.1584e-04 - val_loss: 0.0014\n",
      "Epoch 911/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 2.0073e-04 - val_loss: 0.0015\n",
      "Epoch 912/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 2.2561e-04 - val_loss: 0.0014\n",
      "Epoch 913/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 2.1644e-04 - val_loss: 0.0013\n",
      "Epoch 914/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 2.0980e-04 - val_loss: 0.0015\n",
      "Epoch 915/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 2.0694e-04 - val_loss: 0.0014\n",
      "Epoch 916/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.9997e-04 - val_loss: 0.0015\n",
      "Epoch 917/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 1.8551e-04 - val_loss: 0.0015\n",
      "Epoch 918/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 1.8583e-04 - val_loss: 0.0016\n",
      "Epoch 919/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 1.9355e-04 - val_loss: 0.0016\n",
      "Epoch 920/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 2.1795e-04 - val_loss: 0.0016\n",
      "Epoch 921/2000\n",
      "3891/3891 [==============================] - 1s 191us/step - loss: 2.1640e-04 - val_loss: 0.0015\n",
      "Epoch 922/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 2.1606e-04 - val_loss: 0.0017\n",
      "Epoch 923/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 1s 182us/step - loss: 2.2183e-04 - val_loss: 0.0017\n",
      "Epoch 924/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 2.2294e-04 - val_loss: 0.0014\n",
      "Epoch 925/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 1.9829e-04 - val_loss: 0.0015\n",
      "Epoch 926/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 1.9533e-04 - val_loss: 0.0015\n",
      "Epoch 927/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 2.4262e-04 - val_loss: 0.0016\n",
      "Epoch 928/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 2.3606e-04 - val_loss: 0.0015\n",
      "Epoch 929/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 2.2958e-04 - val_loss: 0.0015\n",
      "Epoch 930/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 2.1297e-04 - val_loss: 0.0015\n",
      "Epoch 931/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 2.1003e-04 - val_loss: 0.0015\n",
      "Epoch 932/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.9849e-04 - val_loss: 0.0016\n",
      "Epoch 933/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.9002e-04 - val_loss: 0.0015\n",
      "Epoch 934/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 1.9093e-04 - val_loss: 0.0016\n",
      "Epoch 935/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.8300e-04 - val_loss: 0.0015\n",
      "Epoch 936/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.7764e-04 - val_loss: 0.0015\n",
      "Epoch 937/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.8108e-04 - val_loss: 0.0015\n",
      "Epoch 938/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.7468e-04 - val_loss: 0.0015\n",
      "Epoch 939/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.7824e-04 - val_loss: 0.0015\n",
      "Epoch 940/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 1.7932e-04 - val_loss: 0.0016\n",
      "Epoch 941/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 1.9201e-04 - val_loss: 0.0016\n",
      "Epoch 942/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.9225e-04 - val_loss: 0.0016\n",
      "Epoch 943/2000\n",
      "3891/3891 [==============================] - 1s 193us/step - loss: 2.0207e-04 - val_loss: 0.0017\n",
      "Epoch 944/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 2.0590e-04 - val_loss: 0.0016\n",
      "Epoch 945/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 1.9521e-04 - val_loss: 0.0016\n",
      "Epoch 946/2000\n",
      "3891/3891 [==============================] - 1s 194us/step - loss: 1.8498e-04 - val_loss: 0.0017\n",
      "Epoch 947/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.8160e-04 - val_loss: 0.0016\n",
      "Epoch 948/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 1.7753e-04 - val_loss: 0.0017\n",
      "Epoch 949/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 2.0095e-04 - val_loss: 0.0017\n",
      "Epoch 950/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 2.0924e-04 - val_loss: 0.0015\n",
      "Epoch 951/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.9142e-04 - val_loss: 0.0016\n",
      "Epoch 952/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.8698e-04 - val_loss: 0.0017\n",
      "Epoch 953/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.9989e-04 - val_loss: 0.0015\n",
      "Epoch 954/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 2.2054e-04 - val_loss: 0.0016\n",
      "Epoch 955/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.8888e-04 - val_loss: 0.0015\n",
      "Epoch 956/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.8357e-04 - val_loss: 0.0015\n",
      "Epoch 957/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.9385e-04 - val_loss: 0.0016\n",
      "Epoch 958/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 1.8279e-04 - val_loss: 0.0016\n",
      "Epoch 959/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.7559e-04 - val_loss: 0.0016\n",
      "Epoch 960/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.8530e-04 - val_loss: 0.0016\n",
      "Epoch 961/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.6916e-04 - val_loss: 0.0017\n",
      "Epoch 962/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 1.6402e-04 - val_loss: 0.0016\n",
      "Epoch 963/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 1.8331e-04 - val_loss: 0.0017\n",
      "Epoch 964/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.8110e-04 - val_loss: 0.0018\n",
      "Epoch 965/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 1.7982e-04 - val_loss: 0.0017\n",
      "Epoch 966/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 1.7725e-04 - val_loss: 0.0018\n",
      "Epoch 967/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 1.7122e-04 - val_loss: 0.0017\n",
      "Epoch 968/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.7174e-04 - val_loss: 0.0017\n",
      "Epoch 969/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 1.6950e-04 - val_loss: 0.0016\n",
      "Epoch 970/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 1.6610e-04 - val_loss: 0.0017\n",
      "Epoch 971/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.6648e-04 - val_loss: 0.0017\n",
      "Epoch 972/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.7325e-04 - val_loss: 0.0018\n",
      "Epoch 973/2000\n",
      "3891/3891 [==============================] - 1s 191us/step - loss: 1.8656e-04 - val_loss: 0.0018\n",
      "Epoch 974/2000\n",
      "3891/3891 [==============================] - 1s 199us/step - loss: 1.9391e-04 - val_loss: 0.0017\n",
      "Epoch 975/2000\n",
      "3891/3891 [==============================] - 1s 192us/step - loss: 1.9328e-04 - val_loss: 0.0018\n",
      "Epoch 976/2000\n",
      "3891/3891 [==============================] - 1s 192us/step - loss: 2.0314e-04 - val_loss: 0.0019\n",
      "Epoch 977/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 2.0894e-04 - val_loss: 0.0018\n",
      "Epoch 978/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 1.9813e-04 - val_loss: 0.0018\n",
      "Epoch 979/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.7494e-04 - val_loss: 0.0018\n",
      "Epoch 980/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.7654e-04 - val_loss: 0.0018\n",
      "Epoch 981/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 1.8235e-04 - val_loss: 0.0017\n",
      "Epoch 982/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 1.7802e-04 - val_loss: 0.0017\n",
      "Epoch 983/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 1.7534e-04 - val_loss: 0.0017\n",
      "Epoch 984/2000\n",
      "3891/3891 [==============================] - 1s 193us/step - loss: 1.7330e-04 - val_loss: 0.0017\n",
      "Epoch 985/2000\n",
      "3891/3891 [==============================] - 1s 194us/step - loss: 1.7318e-04 - val_loss: 0.0019\n",
      "Epoch 986/2000\n",
      "3891/3891 [==============================] - 1s 196us/step - loss: 1.7879e-04 - val_loss: 0.0018\n",
      "Epoch 987/2000\n",
      "3891/3891 [==============================] - 1s 191us/step - loss: 1.6795e-04 - val_loss: 0.0017\n",
      "Epoch 988/2000\n",
      "3891/3891 [==============================] - 1s 193us/step - loss: 1.6851e-04 - val_loss: 0.0017\n",
      "Epoch 989/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 1.6757e-04 - val_loss: 0.0019\n",
      "Epoch 990/2000\n",
      "3891/3891 [==============================] - 1s 197us/step - loss: 1.6245e-04 - val_loss: 0.0018\n",
      "Epoch 991/2000\n",
      "3891/3891 [==============================] - 1s 196us/step - loss: 1.7566e-04 - val_loss: 0.0018\n",
      "Epoch 992/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 1.8890e-04 - val_loss: 0.0019\n",
      "Epoch 993/2000\n",
      "3891/3891 [==============================] - 1s 191us/step - loss: 1.9219e-04 - val_loss: 0.0018\n",
      "Epoch 994/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 1.8594e-04 - val_loss: 0.0018\n",
      "Epoch 995/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 2.0251e-04 - val_loss: 0.0018\n",
      "Epoch 996/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 2.0059e-04 - val_loss: 0.0018\n",
      "Epoch 997/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 2.1090e-04 - val_loss: 0.0018\n",
      "Epoch 998/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.7723e-04 - val_loss: 0.0019\n",
      "Epoch 999/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.9923e-04 - val_loss: 0.0018\n",
      "Epoch 1000/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 2.0625e-04 - val_loss: 0.0016\n",
      "Epoch 1001/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 2.3999e-04 - val_loss: 0.0017\n",
      "Epoch 1002/2000\n",
      "3891/3891 [==============================] - 1s 194us/step - loss: 1.8820e-04 - val_loss: 0.0016\n",
      "Epoch 1003/2000\n",
      "3891/3891 [==============================] - 1s 196us/step - loss: 1.8105e-04 - val_loss: 0.0017\n",
      "Epoch 1004/2000\n",
      "3891/3891 [==============================] - 1s 207us/step - loss: 1.7787e-04 - val_loss: 0.0018\n",
      "Epoch 1005/2000\n",
      "3891/3891 [==============================] - 1s 193us/step - loss: 1.6392e-04 - val_loss: 0.0018\n",
      "Epoch 1006/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.7208e-04 - val_loss: 0.0017\n",
      "Epoch 1007/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 1.7301e-04 - val_loss: 0.0018\n",
      "Epoch 1008/2000\n",
      "3891/3891 [==============================] - 1s 204us/step - loss: 1.8412e-04 - val_loss: 0.0018\n",
      "Epoch 1009/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 1.8979e-04 - val_loss: 0.0017\n",
      "Epoch 1010/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.7615e-04 - val_loss: 0.0018\n",
      "Epoch 1011/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.8300e-04 - val_loss: 0.0018\n",
      "Epoch 1012/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.6633e-04 - val_loss: 0.0018\n",
      "Epoch 1013/2000\n",
      "3891/3891 [==============================] - 1s 195us/step - loss: 2.1723e-04 - val_loss: 0.0018\n",
      "Epoch 1014/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 2.1343e-04 - val_loss: 0.0018\n",
      "Epoch 1015/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.9517e-04 - val_loss: 0.0018\n",
      "Epoch 1016/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 1.7643e-04 - val_loss: 0.0018\n",
      "Epoch 1017/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.7210e-04 - val_loss: 0.0017\n",
      "Epoch 1018/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.6376e-04 - val_loss: 0.0018\n",
      "Epoch 1019/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 1.6593e-04 - val_loss: 0.0019\n",
      "Epoch 1020/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.7984e-04 - val_loss: 0.0019\n",
      "Epoch 1021/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.8644e-04 - val_loss: 0.0019\n",
      "Epoch 1022/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.9586e-04 - val_loss: 0.0019\n",
      "Epoch 1023/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 2.1840e-04 - val_loss: 0.0021\n",
      "Epoch 1024/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 2.4003e-04 - val_loss: 0.0018\n",
      "Epoch 1025/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 2.4713e-04 - val_loss: 0.0018\n",
      "Epoch 1026/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 2.0517e-04 - val_loss: 0.0017\n",
      "Epoch 1027/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.9768e-04 - val_loss: 0.0018\n",
      "Epoch 1028/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 1.8477e-04 - val_loss: 0.0017\n",
      "Epoch 1029/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 1.5766e-04 - val_loss: 0.0017\n",
      "Epoch 1030/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 1.8609e-04 - val_loss: 0.0019\n",
      "Epoch 1031/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 2.1461e-04 - val_loss: 0.0019\n",
      "Epoch 1032/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 2.1645e-04 - val_loss: 0.0018\n",
      "Epoch 1033/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.7724e-04 - val_loss: 0.0017\n",
      "Epoch 1034/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.6325e-04 - val_loss: 0.0017\n",
      "Epoch 1035/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 1.6449e-04 - val_loss: 0.0018\n",
      "Epoch 1036/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 1.6526e-04 - val_loss: 0.0018\n",
      "Epoch 1037/2000\n",
      "3891/3891 [==============================] - 1s 194us/step - loss: 1.8232e-04 - val_loss: 0.0019\n",
      "Epoch 1038/2000\n",
      "3891/3891 [==============================] - 1s 198us/step - loss: 1.6531e-04 - val_loss: 0.0017\n",
      "Epoch 1039/2000\n",
      "3891/3891 [==============================] - 1s 194us/step - loss: 1.6692e-04 - val_loss: 0.0019\n",
      "Epoch 1040/2000\n",
      "3891/3891 [==============================] - 1s 198us/step - loss: 1.5544e-04 - val_loss: 0.0018\n",
      "Epoch 1041/2000\n",
      "3891/3891 [==============================] - 1s 195us/step - loss: 1.5497e-04 - val_loss: 0.0017\n",
      "Epoch 1042/2000\n",
      "3891/3891 [==============================] - 1s 192us/step - loss: 1.6022e-04 - val_loss: 0.0019\n",
      "Epoch 1043/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.7537e-04 - val_loss: 0.0019\n",
      "Epoch 1044/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 2.1807e-04 - val_loss: 0.0019\n",
      "Epoch 1045/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.8437e-04 - val_loss: 0.0018\n",
      "Epoch 1046/2000\n",
      "3891/3891 [==============================] - 1s 194us/step - loss: 1.6801e-04 - val_loss: 0.0019\n",
      "Epoch 1047/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 1.6871e-04 - val_loss: 0.0019\n",
      "Epoch 1048/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 1.6164e-04 - val_loss: 0.0019\n",
      "Epoch 1049/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 1.5461e-04 - val_loss: 0.0019\n",
      "Epoch 1050/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.5820e-04 - val_loss: 0.0019\n",
      "Epoch 1051/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.6412e-04 - val_loss: 0.0019\n",
      "Epoch 1052/2000\n",
      "3891/3891 [==============================] - 1s 193us/step - loss: 1.5064e-04 - val_loss: 0.0019\n",
      "Epoch 1053/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.5200e-04 - val_loss: 0.0019\n",
      "Epoch 1054/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.4629e-04 - val_loss: 0.0019\n",
      "Epoch 1055/2000\n",
      "3891/3891 [==============================] - 1s 195us/step - loss: 1.5422e-04 - val_loss: 0.0020\n",
      "Epoch 1056/2000\n",
      "3891/3891 [==============================] - 1s 194us/step - loss: 1.5155e-04 - val_loss: 0.0019\n",
      "Epoch 1057/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 1.4872e-04 - val_loss: 0.0019\n",
      "Epoch 1058/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.5480e-04 - val_loss: 0.0020\n",
      "Epoch 1059/2000\n",
      "3891/3891 [==============================] - 1s 198us/step - loss: 1.4966e-04 - val_loss: 0.0020\n",
      "Epoch 1060/2000\n",
      "3891/3891 [==============================] - 1s 191us/step - loss: 1.5438e-04 - val_loss: 0.0020\n",
      "Epoch 1061/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.5665e-04 - val_loss: 0.0019\n",
      "Epoch 1062/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 1.7283e-04 - val_loss: 0.0019\n",
      "Epoch 1063/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.7658e-04 - val_loss: 0.0020\n",
      "Epoch 1064/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 1.7100e-04 - val_loss: 0.0019\n",
      "Epoch 1065/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.7268e-04 - val_loss: 0.0020\n",
      "Epoch 1066/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.6972e-04 - val_loss: 0.0020\n",
      "Epoch 1067/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 1.6475e-04 - val_loss: 0.0021\n",
      "Epoch 1068/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.4807e-04 - val_loss: 0.0020\n",
      "Epoch 1069/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.5853e-04 - val_loss: 0.0021\n",
      "Epoch 1070/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.5424e-04 - val_loss: 0.0018\n",
      "Epoch 1071/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.6188e-04 - val_loss: 0.0018\n",
      "Epoch 1072/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.7218e-04 - val_loss: 0.0019\n",
      "Epoch 1073/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 1.5822e-04 - val_loss: 0.0019\n",
      "Epoch 1074/2000\n",
      "3891/3891 [==============================] - 1s 194us/step - loss: 1.6018e-04 - val_loss: 0.0020\n",
      "Epoch 1075/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 1.5001e-04 - val_loss: 0.0019\n",
      "Epoch 1076/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 1.4614e-04 - val_loss: 0.0020\n",
      "Epoch 1077/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 1.5105e-04 - val_loss: 0.0020\n",
      "Epoch 1078/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 1.4638e-04 - val_loss: 0.0020\n",
      "Epoch 1079/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 1.6068e-04 - val_loss: 0.0020\n",
      "Epoch 1080/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 1.4891e-04 - val_loss: 0.0020\n",
      "Epoch 1081/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 1.4640e-04 - val_loss: 0.0019\n",
      "Epoch 1082/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 1.6052e-04 - val_loss: 0.0020\n",
      "Epoch 1083/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 1.6991e-04 - val_loss: 0.0021\n",
      "Epoch 1084/2000\n",
      "3891/3891 [==============================] - 1s 194us/step - loss: 1.5373e-04 - val_loss: 0.0021\n",
      "Epoch 1085/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 1.5087e-04 - val_loss: 0.0021\n",
      "Epoch 1086/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 1.5303e-04 - val_loss: 0.0020\n",
      "Epoch 1087/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 1.4534e-04 - val_loss: 0.0020\n",
      "Epoch 1088/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 1.4816e-04 - val_loss: 0.0019\n",
      "Epoch 1089/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 1.4953e-04 - val_loss: 0.0021\n",
      "Epoch 1090/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 1.5855e-04 - val_loss: 0.0020\n",
      "Epoch 1091/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 1.4891e-04 - val_loss: 0.0019\n",
      "Epoch 1092/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.5347e-04 - val_loss: 0.0019\n",
      "Epoch 1093/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 1.4134e-04 - val_loss: 0.0021\n",
      "Epoch 1094/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.3709e-04 - val_loss: 0.0020\n",
      "Epoch 1095/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.3846e-04 - val_loss: 0.0021\n",
      "Epoch 1096/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 1.4517e-04 - val_loss: 0.0021\n",
      "Epoch 1097/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.5088e-04 - val_loss: 0.0020\n",
      "Epoch 1098/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.4490e-04 - val_loss: 0.0020\n",
      "Epoch 1099/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 1.3575e-04 - val_loss: 0.0021\n",
      "Epoch 1100/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 1.3630e-04 - val_loss: 0.0021\n",
      "Epoch 1101/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.5003e-04 - val_loss: 0.0021\n",
      "Epoch 1102/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.4515e-04 - val_loss: 0.0021\n",
      "Epoch 1103/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 1.4638e-04 - val_loss: 0.0021\n",
      "Epoch 1104/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.5871e-04 - val_loss: 0.0021\n",
      "Epoch 1105/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.5420e-04 - val_loss: 0.0020\n",
      "Epoch 1106/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 1.7135e-04 - val_loss: 0.0020\n",
      "Epoch 1107/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.5745e-04 - val_loss: 0.0022\n",
      "Epoch 1108/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 1.5264e-04 - val_loss: 0.0021\n",
      "Epoch 1109/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.6449e-04 - val_loss: 0.0020\n",
      "Epoch 1110/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.4149e-04 - val_loss: 0.0022\n",
      "Epoch 1111/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 1.4511e-04 - val_loss: 0.0021\n",
      "Epoch 1112/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.4751e-04 - val_loss: 0.0021\n",
      "Epoch 1113/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.4340e-04 - val_loss: 0.0021\n",
      "Epoch 1114/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 1.4413e-04 - val_loss: 0.0025\n",
      "Epoch 1115/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 1.8848e-04 - val_loss: 0.0021\n",
      "Epoch 1116/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 1.7779e-04 - val_loss: 0.0020\n",
      "Epoch 1117/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.5090e-04 - val_loss: 0.0020\n",
      "Epoch 1118/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 1.4562e-04 - val_loss: 0.0022\n",
      "Epoch 1119/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 1.5499e-04 - val_loss: 0.0022\n",
      "Epoch 1120/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.4350e-04 - val_loss: 0.0022\n",
      "Epoch 1121/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.4887e-04 - val_loss: 0.0022\n",
      "Epoch 1122/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.5898e-04 - val_loss: 0.0021\n",
      "Epoch 1123/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 1.4706e-04 - val_loss: 0.0022\n",
      "Epoch 1124/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 1.5069e-04 - val_loss: 0.0022\n",
      "Epoch 1125/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.4891e-04 - val_loss: 0.0022\n",
      "Epoch 1126/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 1.5370e-04 - val_loss: 0.0022\n",
      "Epoch 1127/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.6481e-04 - val_loss: 0.0021\n",
      "Epoch 1128/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 1.5635e-04 - val_loss: 0.0023\n",
      "Epoch 1129/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.5478e-04 - val_loss: 0.0021\n",
      "Epoch 1130/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.5250e-04 - val_loss: 0.0022\n",
      "Epoch 1131/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 1.3976e-04 - val_loss: 0.0023\n",
      "Epoch 1132/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 1.4393e-04 - val_loss: 0.0021\n",
      "Epoch 1133/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 1.6340e-04 - val_loss: 0.0022\n",
      "Epoch 1134/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.4589e-04 - val_loss: 0.0021\n",
      "Epoch 1135/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 1.4576e-04 - val_loss: 0.0022\n",
      "Epoch 1136/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.4586e-04 - val_loss: 0.0023\n",
      "Epoch 1137/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 1.5546e-04 - val_loss: 0.0023\n",
      "Epoch 1138/2000\n",
      "3891/3891 [==============================] - 1s 181us/step - loss: 1.3959e-04 - val_loss: 0.0022\n",
      "Epoch 1139/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 1.3999e-04 - val_loss: 0.0021\n",
      "Epoch 1140/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.3950e-04 - val_loss: 0.0023\n",
      "Epoch 1141/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 1.5746e-04 - val_loss: 0.0024\n",
      "Epoch 1142/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.7989e-04 - val_loss: 0.0024\n",
      "Epoch 1143/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 1.6254e-04 - val_loss: 0.0024\n",
      "Epoch 1144/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.7821e-04 - val_loss: 0.0022\n",
      "Epoch 1145/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 1.4799e-04 - val_loss: 0.0022\n",
      "Epoch 1146/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.4030e-04 - val_loss: 0.0022\n",
      "Epoch 1147/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 1.5323e-04 - val_loss: 0.0023\n",
      "Epoch 1148/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.6232e-04 - val_loss: 0.0024\n",
      "Epoch 1149/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 1.8302e-04 - val_loss: 0.0024\n",
      "Epoch 1150/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.6933e-04 - val_loss: 0.0023\n",
      "Epoch 1151/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 1.5269e-04 - val_loss: 0.0022\n",
      "Epoch 1152/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 1.6438e-04 - val_loss: 0.0024\n",
      "Epoch 1153/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.5630e-04 - val_loss: 0.0024\n",
      "Epoch 1154/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.4456e-04 - val_loss: 0.0023\n",
      "Epoch 1155/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.6010e-04 - val_loss: 0.0023\n",
      "Epoch 1156/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.4466e-04 - val_loss: 0.0022\n",
      "Epoch 1157/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.7827e-04 - val_loss: 0.0023\n",
      "Epoch 1158/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 1.7338e-04 - val_loss: 0.0022\n",
      "Epoch 1159/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 1.6794e-04 - val_loss: 0.0022\n",
      "Epoch 1160/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.6082e-04 - val_loss: 0.0024\n",
      "Epoch 1161/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.7969e-04 - val_loss: 0.0024\n",
      "Epoch 1162/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 1.5429e-04 - val_loss: 0.0023\n",
      "Epoch 1163/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 1.4647e-04 - val_loss: 0.0022\n",
      "Epoch 1164/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 1.3334e-04 - val_loss: 0.0022-0\n",
      "Epoch 1165/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 1.3721e-04 - val_loss: 0.0023\n",
      "Epoch 1166/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 1.4284e-04 - val_loss: 0.0023\n",
      "Epoch 1167/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.4476e-04 - val_loss: 0.0023\n",
      "Epoch 1168/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.3553e-04 - val_loss: 0.0024\n",
      "Epoch 1169/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 1.2934e-04 - val_loss: 0.0023\n",
      "Epoch 1170/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.3161e-04 - val_loss: 0.0024\n",
      "Epoch 1171/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.3794e-04 - val_loss: 0.0023\n",
      "Epoch 1172/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 1.2988e-04 - val_loss: 0.0024\n",
      "Epoch 1173/2000\n",
      "3891/3891 [==============================] - 1s 194us/step - loss: 1.3996e-04 - val_loss: 0.0025\n",
      "Epoch 1174/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 1.4927e-04 - val_loss: 0.0024\n",
      "Epoch 1175/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 1.3990e-04 - val_loss: 0.0024\n",
      "Epoch 1176/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.3830e-04 - val_loss: 0.0024\n",
      "Epoch 1177/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.3835e-04 - val_loss: 0.0025\n",
      "Epoch 1178/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.5993e-04 - val_loss: 0.0024\n",
      "Epoch 1179/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.4376e-04 - val_loss: 0.0023\n",
      "Epoch 1180/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.3195e-04 - val_loss: 0.0024\n",
      "Epoch 1181/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.3963e-04 - val_loss: 0.0024\n",
      "Epoch 1182/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 1.4937e-04 - val_loss: 0.0023-0\n",
      "Epoch 1183/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.4121e-04 - val_loss: 0.0024\n",
      "Epoch 1184/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 1.4102e-04 - val_loss: 0.0022\n",
      "Epoch 1185/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 1.3378e-04 - val_loss: 0.0023\n",
      "Epoch 1186/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 1.3305e-04 - val_loss: 0.0023\n",
      "Epoch 1187/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 1.2854e-04 - val_loss: 0.0024\n",
      "Epoch 1188/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 1.2963e-04 - val_loss: 0.0024\n",
      "Epoch 1189/2000\n",
      "3891/3891 [==============================] - 1s 199us/step - loss: 1.4556e-04 - val_loss: 0.0024\n",
      "Epoch 1190/2000\n",
      "3891/3891 [==============================] - 1s 197us/step - loss: 1.5604e-04 - val_loss: 0.0028\n",
      "Epoch 1191/2000\n",
      "3891/3891 [==============================] - 1s 195us/step - loss: 1.7321e-04 - val_loss: 0.0024\n",
      "Epoch 1192/2000\n",
      "3891/3891 [==============================] - 1s 192us/step - loss: 1.5400e-04 - val_loss: 0.0022\n",
      "Epoch 1193/2000\n",
      "3891/3891 [==============================] - 1s 194us/step - loss: 1.3282e-04 - val_loss: 0.0024\n",
      "Epoch 1194/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 1.3183e-04 - val_loss: 0.0023\n",
      "Epoch 1195/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 1.3470e-04 - val_loss: 0.0023\n",
      "Epoch 1196/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 1.3138e-04 - val_loss: 0.0025\n",
      "Epoch 1197/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.3017e-04 - val_loss: 0.0024\n",
      "Epoch 1198/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 1.3407e-04 - val_loss: 0.0024\n",
      "Epoch 1199/2000\n",
      "3891/3891 [==============================] - 1s 192us/step - loss: 1.3595e-04 - val_loss: 0.0025\n",
      "Epoch 1200/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.2827e-04 - val_loss: 0.0024\n",
      "Epoch 1201/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 1.2271e-04 - val_loss: 0.0024\n",
      "Epoch 1202/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.2006e-04 - val_loss: 0.0025\n",
      "Epoch 1203/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.1479e-04 - val_loss: 0.0024\n",
      "Epoch 1204/2000\n",
      "3891/3891 [==============================] - 1s 196us/step - loss: 1.1806e-04 - val_loss: 0.0025\n",
      "Epoch 1205/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.1988e-04 - val_loss: 0.0024\n",
      "Epoch 1206/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 1.2220e-04 - val_loss: 0.0025\n",
      "Epoch 1207/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 1.2382e-04 - val_loss: 0.0024\n",
      "Epoch 1208/2000\n",
      "3891/3891 [==============================] - 1s 193us/step - loss: 1.2036e-04 - val_loss: 0.0025\n",
      "Epoch 1209/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.2249e-04 - val_loss: 0.0024\n",
      "Epoch 1210/2000\n",
      "3891/3891 [==============================] - 1s 193us/step - loss: 1.2899e-04 - val_loss: 0.0024\n",
      "Epoch 1211/2000\n",
      "3891/3891 [==============================] - 1s 193us/step - loss: 1.3491e-04 - val_loss: 0.0026\n",
      "Epoch 1212/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 1s 193us/step - loss: 1.3248e-04 - val_loss: 0.0024\n",
      "Epoch 1213/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.2318e-04 - val_loss: 0.0025\n",
      "Epoch 1214/2000\n",
      "3891/3891 [==============================] - 1s 198us/step - loss: 1.3103e-04 - val_loss: 0.0027\n",
      "Epoch 1215/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.1882e-04 - val_loss: 0.0024\n",
      "Epoch 1216/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.2280e-04 - val_loss: 0.0023\n",
      "Epoch 1217/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 1.2323e-04 - val_loss: 0.0026\n",
      "Epoch 1218/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.2089e-04 - val_loss: 0.0027\n",
      "Epoch 1219/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.1680e-04 - val_loss: 0.0026\n",
      "Epoch 1220/2000\n",
      "3891/3891 [==============================] - 1s 193us/step - loss: 1.1643e-04 - val_loss: 0.0025\n",
      "Epoch 1221/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 1.1797e-04 - val_loss: 0.0026\n",
      "Epoch 1222/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 1.2002e-04 - val_loss: 0.0025\n",
      "Epoch 1223/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 1.2041e-04 - val_loss: 0.0025\n",
      "Epoch 1224/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.2524e-04 - val_loss: 0.0025\n",
      "Epoch 1225/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.2627e-04 - val_loss: 0.0027\n",
      "Epoch 1226/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 1.3639e-04 - val_loss: 0.0027\n",
      "Epoch 1227/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.4608e-04 - val_loss: 0.0026\n",
      "Epoch 1228/2000\n",
      "3891/3891 [==============================] - 1s 194us/step - loss: 1.4682e-04 - val_loss: 0.0026\n",
      "Epoch 1229/2000\n",
      "3891/3891 [==============================] - 1s 196us/step - loss: 1.4472e-04 - val_loss: 0.0024\n",
      "Epoch 1230/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.3799e-04 - val_loss: 0.0027\n",
      "Epoch 1231/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 1.4234e-04 - val_loss: 0.0026\n",
      "Epoch 1232/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.3525e-04 - val_loss: 0.0025\n",
      "Epoch 1233/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.3122e-04 - val_loss: 0.0026\n",
      "Epoch 1234/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.2872e-04 - val_loss: 0.0025\n",
      "Epoch 1235/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.1672e-04 - val_loss: 0.0026\n",
      "Epoch 1236/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 1.3058e-04 - val_loss: 0.0025\n",
      "Epoch 1237/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.3982e-04 - val_loss: 0.0030\n",
      "Epoch 1238/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.7224e-04 - val_loss: 0.0026\n",
      "Epoch 1239/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 1.4428e-04 - val_loss: 0.0024\n",
      "Epoch 1240/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 1.3847e-04 - val_loss: 0.0026\n",
      "Epoch 1241/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 1.4258e-04 - val_loss: 0.0026\n",
      "Epoch 1242/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.5775e-04 - val_loss: 0.0026\n",
      "Epoch 1243/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 1.6455e-04 - val_loss: 0.0027\n",
      "Epoch 1244/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 1.3986e-04 - val_loss: 0.0025\n",
      "Epoch 1245/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 1.3950e-04 - val_loss: 0.0026\n",
      "Epoch 1246/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.5831e-04 - val_loss: 0.0026\n",
      "Epoch 1247/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 1.5293e-04 - val_loss: 0.0026\n",
      "Epoch 1248/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.8925e-04 - val_loss: 0.0026\n",
      "Epoch 1249/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.6020e-04 - val_loss: 0.0027\n",
      "Epoch 1250/2000\n",
      "3891/3891 [==============================] - 1s 191us/step - loss: 1.3386e-04 - val_loss: 0.0024\n",
      "Epoch 1251/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.3064e-04 - val_loss: 0.0024\n",
      "Epoch 1252/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.2406e-04 - val_loss: 0.0025\n",
      "Epoch 1253/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.2986e-04 - val_loss: 0.0026\n",
      "Epoch 1254/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.3183e-04 - val_loss: 0.0026\n",
      "Epoch 1255/2000\n",
      "3891/3891 [==============================] - 1s 191us/step - loss: 1.3006e-04 - val_loss: 0.0025\n",
      "Epoch 1256/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.2426e-04 - val_loss: 0.0025\n",
      "Epoch 1257/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 1.2833e-04 - val_loss: 0.0024\n",
      "Epoch 1258/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 1.3173e-04 - val_loss: 0.0024\n",
      "Epoch 1259/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 1.3582e-04 - val_loss: 0.0026\n",
      "Epoch 1260/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 1.3900e-04 - val_loss: 0.0026\n",
      "Epoch 1261/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 1.3676e-04 - val_loss: 0.0024\n",
      "Epoch 1262/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.2870e-04 - val_loss: 0.0024\n",
      "Epoch 1263/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.2119e-04 - val_loss: 0.0026\n",
      "Epoch 1264/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.2992e-04 - val_loss: 0.0025\n",
      "Epoch 1265/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 1.5472e-04 - val_loss: 0.0024\n",
      "Epoch 1266/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 1.4049e-04 - val_loss: 0.0023\n",
      "Epoch 1267/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 1.3159e-04 - val_loss: 0.0024\n",
      "Epoch 1268/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.3063e-04 - val_loss: 0.0024\n",
      "Epoch 1269/2000\n",
      "3891/3891 [==============================] - 1s 194us/step - loss: 1.2278e-04 - val_loss: 0.0026\n",
      "Epoch 1270/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.3058e-04 - val_loss: 0.0025\n",
      "Epoch 1271/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 1.3812e-04 - val_loss: 0.0027\n",
      "Epoch 1272/2000\n",
      "3891/3891 [==============================] - 1s 195us/step - loss: 1.4218e-04 - val_loss: 0.0024\n",
      "Epoch 1273/2000\n",
      "3891/3891 [==============================] - 1s 192us/step - loss: 1.3007e-04 - val_loss: 0.0025\n",
      "Epoch 1274/2000\n",
      "3891/3891 [==============================] - 1s 192us/step - loss: 1.2671e-04 - val_loss: 0.0026\n",
      "Epoch 1275/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 1.1527e-04 - val_loss: 0.0027-0\n",
      "Epoch 1276/2000\n",
      "3891/3891 [==============================] - 1s 194us/step - loss: 1.1906e-04 - val_loss: 0.0025\n",
      "Epoch 1277/2000\n",
      "3891/3891 [==============================] - 1s 194us/step - loss: 1.1632e-04 - val_loss: 0.0025\n",
      "Epoch 1278/2000\n",
      "3891/3891 [==============================] - 1s 191us/step - loss: 1.1077e-04 - val_loss: 0.0026\n",
      "Epoch 1279/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 1.2455e-04 - val_loss: 0.0028\n",
      "Epoch 1280/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 1.2990e-04 - val_loss: 0.0027\n",
      "Epoch 1281/2000\n",
      "3891/3891 [==============================] - 1s 191us/step - loss: 1.3802e-04 - val_loss: 0.0027\n",
      "Epoch 1282/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 1.2622e-04 - val_loss: 0.0027\n",
      "Epoch 1283/2000\n",
      "3891/3891 [==============================] - 1s 191us/step - loss: 1.3397e-04 - val_loss: 0.0026\n",
      "Epoch 1284/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 1.2336e-04 - val_loss: 0.0026\n",
      "Epoch 1285/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 1.1605e-04 - val_loss: 0.0025\n",
      "Epoch 1286/2000\n",
      "3891/3891 [==============================] - 1s 193us/step - loss: 1.2046e-04 - val_loss: 0.0027\n",
      "Epoch 1287/2000\n",
      "3891/3891 [==============================] - 1s 202us/step - loss: 1.1782e-04 - val_loss: 0.0027\n",
      "Epoch 1288/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.2414e-04 - val_loss: 0.0027\n",
      "Epoch 1289/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.2640e-04 - val_loss: 0.0026\n",
      "Epoch 1290/2000\n",
      "3891/3891 [==============================] - 1s 193us/step - loss: 1.2917e-04 - val_loss: 0.0027\n",
      "Epoch 1291/2000\n",
      "3891/3891 [==============================] - 1s 197us/step - loss: 1.1704e-04 - val_loss: 0.0026\n",
      "Epoch 1292/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.2215e-04 - val_loss: 0.0025\n",
      "Epoch 1293/2000\n",
      "3891/3891 [==============================] - 1s 193us/step - loss: 1.1622e-04 - val_loss: 0.0026\n",
      "Epoch 1294/2000\n",
      "3891/3891 [==============================] - 1s 198us/step - loss: 1.2128e-04 - val_loss: 0.0027\n",
      "Epoch 1295/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 1.1552e-04 - val_loss: 0.0028\n",
      "Epoch 1296/2000\n",
      "3891/3891 [==============================] - 1s 204us/step - loss: 1.2277e-04 - val_loss: 0.0026\n",
      "Epoch 1297/2000\n",
      "3891/3891 [==============================] - 1s 195us/step - loss: 1.2434e-04 - val_loss: 0.0026\n",
      "Epoch 1298/2000\n",
      "3891/3891 [==============================] - 1s 200us/step - loss: 1.2597e-04 - val_loss: 0.0028\n",
      "Epoch 1299/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 1.1078e-04 - val_loss: 0.0027\n",
      "Epoch 1300/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.0806e-04 - val_loss: 0.0027\n",
      "Epoch 1301/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 1.0436e-04 - val_loss: 0.0027\n",
      "Epoch 1302/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 1.0444e-04 - val_loss: 0.0026\n",
      "Epoch 1303/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 1.1884e-04 - val_loss: 0.0027\n",
      "Epoch 1304/2000\n",
      "3891/3891 [==============================] - 1s 199us/step - loss: 1.1768e-04 - val_loss: 0.0027\n",
      "Epoch 1305/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.2976e-04 - val_loss: 0.0027\n",
      "Epoch 1306/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 1.5643e-04 - val_loss: 0.0026\n",
      "Epoch 1307/2000\n",
      "3891/3891 [==============================] - 1s 203us/step - loss: 1.3914e-04 - val_loss: 0.0026\n",
      "Epoch 1308/2000\n",
      "3891/3891 [==============================] - 1s 197us/step - loss: 1.4051e-04 - val_loss: 0.0027\n",
      "Epoch 1309/2000\n",
      "3891/3891 [==============================] - 1s 199us/step - loss: 1.3328e-04 - val_loss: 0.0029\n",
      "Epoch 1310/2000\n",
      "3891/3891 [==============================] - 1s 191us/step - loss: 1.6751e-04 - val_loss: 0.0027\n",
      "Epoch 1311/2000\n",
      "3891/3891 [==============================] - 1s 191us/step - loss: 1.3238e-04 - val_loss: 0.0027\n",
      "Epoch 1312/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 1.2881e-04 - val_loss: 0.0029\n",
      "Epoch 1313/2000\n",
      "3891/3891 [==============================] - 1s 195us/step - loss: 1.4280e-04 - val_loss: 0.0027\n",
      "Epoch 1314/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 1.4056e-04 - val_loss: 0.0026\n",
      "Epoch 1315/2000\n",
      "3891/3891 [==============================] - 1s 191us/step - loss: 1.4228e-04 - val_loss: 0.0026\n",
      "Epoch 1316/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.2473e-04 - val_loss: 0.0029\n",
      "Epoch 1317/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.1684e-04 - val_loss: 0.0028\n",
      "Epoch 1318/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.2663e-04 - val_loss: 0.0027\n",
      "Epoch 1319/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.4007e-04 - val_loss: 0.0026\n",
      "Epoch 1320/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 1.3046e-04 - val_loss: 0.0026\n",
      "Epoch 1321/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 1.2096e-04 - val_loss: 0.0028\n",
      "Epoch 1322/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 1.1684e-04 - val_loss: 0.0027\n",
      "Epoch 1323/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 1.1262e-04 - val_loss: 0.0027\n",
      "Epoch 1324/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.2397e-04 - val_loss: 0.0028\n",
      "Epoch 1325/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.2549e-04 - val_loss: 0.0029\n",
      "Epoch 1326/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.1465e-04 - val_loss: 0.0026\n",
      "Epoch 1327/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.0738e-04 - val_loss: 0.0030\n",
      "Epoch 1328/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.0893e-04 - val_loss: 0.0029\n",
      "Epoch 1329/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 1.0903e-04 - val_loss: 0.0028\n",
      "Epoch 1330/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 1.0432e-04 - val_loss: 0.0029\n",
      "Epoch 1331/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.0702e-04 - val_loss: 0.0029\n",
      "Epoch 1332/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.0764e-04 - val_loss: 0.0028\n",
      "Epoch 1333/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.0333e-04 - val_loss: 0.0027\n",
      "Epoch 1334/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.0388e-04 - val_loss: 0.0029\n",
      "Epoch 1335/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 1.0912e-04 - val_loss: 0.0028\n",
      "Epoch 1336/2000\n",
      "3891/3891 [==============================] - 1s 193us/step - loss: 1.0829e-04 - val_loss: 0.0028\n",
      "Epoch 1337/2000\n",
      "3891/3891 [==============================] - 1s 191us/step - loss: 1.1244e-04 - val_loss: 0.0029\n",
      "Epoch 1338/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 1.1413e-04 - val_loss: 0.0027\n",
      "Epoch 1339/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 1.0842e-04 - val_loss: 0.0030\n",
      "Epoch 1340/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 9.9536e-05 - val_loss: 0.0029\n",
      "Epoch 1341/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.1240e-04 - val_loss: 0.0028\n",
      "Epoch 1342/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.0745e-04 - val_loss: 0.0028\n",
      "Epoch 1343/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 1.1692e-04 - val_loss: 0.0027\n",
      "Epoch 1344/2000\n",
      "3891/3891 [==============================] - 1s 201us/step - loss: 1.3180e-04 - val_loss: 0.0029\n",
      "Epoch 1345/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 1.1464e-04 - val_loss: 0.0028\n",
      "Epoch 1346/2000\n",
      "3891/3891 [==============================] - 1s 200us/step - loss: 1.1106e-04 - val_loss: 0.0027\n",
      "Epoch 1347/2000\n",
      "3891/3891 [==============================] - 1s 192us/step - loss: 1.0458e-04 - val_loss: 0.0028\n",
      "Epoch 1348/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.0185e-04 - val_loss: 0.0028\n",
      "Epoch 1349/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 1.1012e-04 - val_loss: 0.0029\n",
      "Epoch 1350/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.0312e-04 - val_loss: 0.0029\n",
      "Epoch 1351/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 1.0661e-04 - val_loss: 0.0029\n",
      "Epoch 1352/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 1.0627e-04 - val_loss: 0.0029\n",
      "Epoch 1353/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 1.1002e-04 - val_loss: 0.0029\n",
      "Epoch 1354/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 1.0500e-04 - val_loss: 0.0029\n",
      "Epoch 1355/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.0696e-04 - val_loss: 0.0029\n",
      "Epoch 1356/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.1252e-04 - val_loss: 0.0029\n",
      "Epoch 1357/2000\n",
      "3891/3891 [==============================] - 1s 195us/step - loss: 1.1964e-04 - val_loss: 0.0029\n",
      "Epoch 1358/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 1.1537e-04 - val_loss: 0.0029\n",
      "Epoch 1359/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 1.0613e-04 - val_loss: 0.0028\n",
      "Epoch 1360/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.0409e-04 - val_loss: 0.0029\n",
      "Epoch 1361/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.0603e-04 - val_loss: 0.0030\n",
      "Epoch 1362/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 1.0702e-04 - val_loss: 0.0029\n",
      "Epoch 1363/2000\n",
      "3891/3891 [==============================] - 1s 195us/step - loss: 1.1255e-04 - val_loss: 0.0029-\n",
      "Epoch 1364/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.0373e-04 - val_loss: 0.0030\n",
      "Epoch 1365/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.0482e-04 - val_loss: 0.0027\n",
      "Epoch 1366/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.1600e-04 - val_loss: 0.0029\n",
      "Epoch 1367/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.0924e-04 - val_loss: 0.0030\n",
      "Epoch 1368/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.1318e-04 - val_loss: 0.0030-0\n",
      "Epoch 1369/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 1.2676e-04 - val_loss: 0.0031\n",
      "Epoch 1370/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.1575e-04 - val_loss: 0.0028\n",
      "Epoch 1371/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.2020e-04 - val_loss: 0.0029\n",
      "Epoch 1372/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.1994e-04 - val_loss: 0.0032\n",
      "Epoch 1373/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.4623e-04 - val_loss: 0.0030\n",
      "Epoch 1374/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.3069e-04 - val_loss: 0.0031\n",
      "Epoch 1375/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.3420e-04 - val_loss: 0.0029\n",
      "Epoch 1376/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 1.3045e-04 - val_loss: 0.0029\n",
      "Epoch 1377/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 1.1475e-04 - val_loss: 0.0030\n",
      "Epoch 1378/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 1.0403e-04 - val_loss: 0.0029\n",
      "Epoch 1379/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 1.0939e-04 - val_loss: 0.0031-0\n",
      "Epoch 1380/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 1.1897e-04 - val_loss: 0.0029\n",
      "Epoch 1381/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 1.2397e-04 - val_loss: 0.0029\n",
      "Epoch 1382/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.2174e-04 - val_loss: 0.0030\n",
      "Epoch 1383/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.1281e-04 - val_loss: 0.0026\n",
      "Epoch 1384/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.2065e-04 - val_loss: 0.0030-0\n",
      "Epoch 1385/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.1309e-04 - val_loss: 0.0030\n",
      "Epoch 1386/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.1194e-04 - val_loss: 0.0030\n",
      "Epoch 1387/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 1.0027e-04 - val_loss: 0.0031\n",
      "Epoch 1388/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 1.0057e-04 - val_loss: 0.0030\n",
      "Epoch 1389/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 1.0867e-04 - val_loss: 0.0028\n",
      "Epoch 1390/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.0782e-04 - val_loss: 0.0030\n",
      "Epoch 1391/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 9.9910e-05 - val_loss: 0.0031\n",
      "Epoch 1392/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.0735e-04 - val_loss: 0.0030\n",
      "Epoch 1393/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 1.1739e-04 - val_loss: 0.0032\n",
      "Epoch 1394/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.2225e-04 - val_loss: 0.0030\n",
      "Epoch 1395/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 1.1588e-04 - val_loss: 0.0029\n",
      "Epoch 1396/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 1.3214e-04 - val_loss: 0.0030\n",
      "Epoch 1397/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 1.1787e-04 - val_loss: 0.0030\n",
      "Epoch 1398/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 1.0969e-04 - val_loss: 0.0029\n",
      "Epoch 1399/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 9.9879e-05 - val_loss: 0.0030\n",
      "Epoch 1400/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 9.7331e-05 - val_loss: 0.0030\n",
      "Epoch 1401/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 9.6423e-05 - val_loss: 0.0030\n",
      "Epoch 1402/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 1.0711e-04 - val_loss: 0.0030\n",
      "Epoch 1403/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 1.0365e-04 - val_loss: 0.0030\n",
      "Epoch 1404/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.0237e-04 - val_loss: 0.0032\n",
      "Epoch 1405/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 9.8019e-05 - val_loss: 0.0029\n",
      "Epoch 1406/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 9.5029e-05 - val_loss: 0.0031\n",
      "Epoch 1407/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 9.3184e-05 - val_loss: 0.0030\n",
      "Epoch 1408/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 9.8524e-05 - val_loss: 0.0032\n",
      "Epoch 1409/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.1197e-04 - val_loss: 0.0031\n",
      "Epoch 1410/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 1.1334e-04 - val_loss: 0.0030\n",
      "Epoch 1411/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.0096e-04 - val_loss: 0.0032\n",
      "Epoch 1412/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 1.1352e-04 - val_loss: 0.0031\n",
      "Epoch 1413/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 1.0778e-04 - val_loss: 0.0029\n",
      "Epoch 1414/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 1.0166e-04 - val_loss: 0.0030\n",
      "Epoch 1415/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 9.7864e-05 - val_loss: 0.0031\n",
      "Epoch 1416/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 1.0801e-04 - val_loss: 0.0030\n",
      "Epoch 1417/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 1.2525e-04 - val_loss: 0.0030\n",
      "Epoch 1418/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.4748e-04 - val_loss: 0.0036\n",
      "Epoch 1419/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 1.3357e-04 - val_loss: 0.0029\n",
      "Epoch 1420/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 1.1163e-04 - val_loss: 0.0030\n",
      "Epoch 1421/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 1.0323e-04 - val_loss: 0.0031\n",
      "Epoch 1422/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 9.9433e-05 - val_loss: 0.0030\n",
      "Epoch 1423/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 1.0168e-04 - val_loss: 0.0029\n",
      "Epoch 1424/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 1.0084e-04 - val_loss: 0.0032\n",
      "Epoch 1425/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 9.6860e-05 - val_loss: 0.0031\n",
      "Epoch 1426/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 9.9328e-05 - val_loss: 0.0032\n",
      "Epoch 1427/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.0825e-04 - val_loss: 0.0032\n",
      "Epoch 1428/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.1433e-04 - val_loss: 0.0034\n",
      "Epoch 1429/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 1.0586e-04 - val_loss: 0.0032\n",
      "Epoch 1430/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 9.5808e-05 - val_loss: 0.0031\n",
      "Epoch 1431/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 9.1712e-05 - val_loss: 0.0032\n",
      "Epoch 1432/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 9.9535e-05 - val_loss: 0.0031\n",
      "Epoch 1433/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.0291e-04 - val_loss: 0.0030\n",
      "Epoch 1434/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 1.1222e-04 - val_loss: 0.0032\n",
      "Epoch 1435/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.0549e-04 - val_loss: 0.0031\n",
      "Epoch 1436/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 9.9497e-05 - val_loss: 0.0031\n",
      "Epoch 1437/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 1.0456e-04 - val_loss: 0.0030\n",
      "Epoch 1438/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.0037e-04 - val_loss: 0.0032\n",
      "Epoch 1439/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.0142e-04 - val_loss: 0.0032\n",
      "Epoch 1440/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.0664e-04 - val_loss: 0.0031\n",
      "Epoch 1441/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.0934e-04 - val_loss: 0.0032\n",
      "Epoch 1442/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.0764e-04 - val_loss: 0.0032\n",
      "Epoch 1443/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.0062e-04 - val_loss: 0.0030\n",
      "Epoch 1444/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.0104e-04 - val_loss: 0.0031\n",
      "Epoch 1445/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 1.0367e-04 - val_loss: 0.0031\n",
      "Epoch 1446/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.1795e-04 - val_loss: 0.0030\n",
      "Epoch 1447/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 1.1473e-04 - val_loss: 0.0029\n",
      "Epoch 1448/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.2110e-04 - val_loss: 0.0031\n",
      "Epoch 1449/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 1.1507e-04 - val_loss: 0.0033\n",
      "Epoch 1450/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.2543e-04 - val_loss: 0.0029\n",
      "Epoch 1451/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 1.0996e-04 - val_loss: 0.0031\n",
      "Epoch 1452/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.0949e-04 - val_loss: 0.0032\n",
      "Epoch 1453/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 9.7067e-05 - val_loss: 0.0030\n",
      "Epoch 1454/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 9.4732e-05 - val_loss: 0.0031\n",
      "Epoch 1455/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 9.5958e-05 - val_loss: 0.0029-\n",
      "Epoch 1456/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.0565e-04 - val_loss: 0.0032\n",
      "Epoch 1457/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.3602e-04 - val_loss: 0.0030\n",
      "Epoch 1458/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 1.5153e-04 - val_loss: 0.0030\n",
      "Epoch 1459/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 1.3356e-04 - val_loss: 0.0032\n",
      "Epoch 1460/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 1.2648e-04 - val_loss: 0.0033\n",
      "Epoch 1461/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 1.2354e-04 - val_loss: 0.0031\n",
      "Epoch 1462/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 1.0626e-04 - val_loss: 0.0030\n",
      "Epoch 1463/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 9.8639e-05 - val_loss: 0.0032\n",
      "Epoch 1464/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 1.0378e-04 - val_loss: 0.0029\n",
      "Epoch 1465/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.0192e-04 - val_loss: 0.0030\n",
      "Epoch 1466/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 9.7602e-05 - val_loss: 0.0032\n",
      "Epoch 1467/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 1.1221e-04 - val_loss: 0.0031\n",
      "Epoch 1468/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.1359e-04 - val_loss: 0.0029\n",
      "Epoch 1469/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.2358e-04 - val_loss: 0.0030\n",
      "Epoch 1470/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 1.0599e-04 - val_loss: 0.0031\n",
      "Epoch 1471/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.1337e-04 - val_loss: 0.0031\n",
      "Epoch 1472/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 9.9020e-05 - val_loss: 0.0031\n",
      "Epoch 1473/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 9.6300e-05 - val_loss: 0.0032\n",
      "Epoch 1474/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 9.9064e-05 - val_loss: 0.0032\n",
      "Epoch 1475/2000\n",
      "3891/3891 [==============================] - 1s 191us/step - loss: 9.9316e-05 - val_loss: 0.0031\n",
      "Epoch 1476/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 1.1440e-04 - val_loss: 0.0033\n",
      "Epoch 1477/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.0821e-04 - val_loss: 0.0031\n",
      "Epoch 1478/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 1.0383e-04 - val_loss: 0.0030\n",
      "Epoch 1479/2000\n",
      "3891/3891 [==============================] - 1s 193us/step - loss: 9.9395e-05 - val_loss: 0.0030\n",
      "Epoch 1480/2000\n",
      "3891/3891 [==============================] - 1s 194us/step - loss: 9.8003e-05 - val_loss: 0.0030\n",
      "Epoch 1481/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 1.0974e-04 - val_loss: 0.0031\n",
      "Epoch 1482/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 1.0606e-04 - val_loss: 0.0028\n",
      "Epoch 1483/2000\n",
      "3891/3891 [==============================] - 1s 194us/step - loss: 1.0850e-04 - val_loss: 0.0029\n",
      "Epoch 1484/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 9.6458e-05 - val_loss: 0.0031\n",
      "Epoch 1485/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 9.9975e-05 - val_loss: 0.0032\n",
      "Epoch 1486/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 9.9917e-05 - val_loss: 0.0032\n",
      "Epoch 1487/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.0241e-04 - val_loss: 0.0033\n",
      "Epoch 1488/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 9.9973e-05 - val_loss: 0.0030\n",
      "Epoch 1489/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.0315e-04 - val_loss: 0.0031\n",
      "Epoch 1490/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 1.0359e-04 - val_loss: 0.0030\n",
      "Epoch 1491/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 9.8407e-05 - val_loss: 0.0031\n",
      "Epoch 1492/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 9.9441e-05 - val_loss: 0.0032\n",
      "Epoch 1493/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.0939e-04 - val_loss: 0.0034\n",
      "Epoch 1494/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 1.0101e-04 - val_loss: 0.0031\n",
      "Epoch 1495/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 9.2069e-05 - val_loss: 0.0030\n",
      "Epoch 1496/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 9.9457e-05 - val_loss: 0.0034\n",
      "Epoch 1497/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.1114e-04 - val_loss: 0.0030\n",
      "Epoch 1498/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.1549e-04 - val_loss: 0.0033\n",
      "Epoch 1499/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 1.0716e-04 - val_loss: 0.0033\n",
      "Epoch 1500/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 1s 184us/step - loss: 9.5035e-05 - val_loss: 0.0031\n",
      "Epoch 1501/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 9.3957e-05 - val_loss: 0.0030\n",
      "Epoch 1502/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 9.9324e-05 - val_loss: 0.0031\n",
      "Epoch 1503/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 9.6622e-05 - val_loss: 0.0031\n",
      "Epoch 1504/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 8.9247e-05 - val_loss: 0.0035\n",
      "Epoch 1505/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 1.2095e-04 - val_loss: 0.0031\n",
      "Epoch 1506/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.0824e-04 - val_loss: 0.0034\n",
      "Epoch 1507/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 9.9412e-05 - val_loss: 0.0032\n",
      "Epoch 1508/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 9.3729e-05 - val_loss: 0.0032\n",
      "Epoch 1509/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 9.3475e-05 - val_loss: 0.0033\n",
      "Epoch 1510/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 1.0296e-04 - val_loss: 0.0033\n",
      "Epoch 1511/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 9.7262e-05 - val_loss: 0.0032\n",
      "Epoch 1512/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.1059e-04 - val_loss: 0.0033\n",
      "Epoch 1513/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 9.5884e-05 - val_loss: 0.0031\n",
      "Epoch 1514/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 9.2118e-05 - val_loss: 0.0032\n",
      "Epoch 1515/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 1.0294e-04 - val_loss: 0.0034\n",
      "Epoch 1516/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 9.6693e-05 - val_loss: 0.0031\n",
      "Epoch 1517/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 9.0400e-05 - val_loss: 0.0032\n",
      "Epoch 1518/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 8.4688e-05 - val_loss: 0.0031\n",
      "Epoch 1519/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 9.4752e-05 - val_loss: 0.0034\n",
      "Epoch 1520/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 1.0171e-04 - val_loss: 0.0031\n",
      "Epoch 1521/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.4354e-04 - val_loss: 0.0034\n",
      "Epoch 1522/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.3261e-04 - val_loss: 0.0031\n",
      "Epoch 1523/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.1968e-04 - val_loss: 0.0032\n",
      "Epoch 1524/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 1.1200e-04 - val_loss: 0.0031\n",
      "Epoch 1525/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.0041e-04 - val_loss: 0.0031\n",
      "Epoch 1526/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 9.7802e-05 - val_loss: 0.0032\n",
      "Epoch 1527/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 9.1113e-05 - val_loss: 0.0031\n",
      "Epoch 1528/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 9.1701e-05 - val_loss: 0.0033\n",
      "Epoch 1529/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 9.2112e-05 - val_loss: 0.0033\n",
      "Epoch 1530/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 8.4062e-05 - val_loss: 0.0033\n",
      "Epoch 1531/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 9.2935e-05 - val_loss: 0.0030\n",
      "Epoch 1532/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 8.6259e-05 - val_loss: 0.0031\n",
      "Epoch 1533/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 8.5277e-05 - val_loss: 0.0032\n",
      "Epoch 1534/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 8.4174e-05 - val_loss: 0.0032\n",
      "Epoch 1535/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 8.7825e-05 - val_loss: 0.0032\n",
      "Epoch 1536/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 9.1081e-05 - val_loss: 0.0031\n",
      "Epoch 1537/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 7.8526e-05 - val_loss: 0.0034\n",
      "Epoch 1538/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 8.3824e-05 - val_loss: 0.0032\n",
      "Epoch 1539/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 8.5249e-05 - val_loss: 0.0033\n",
      "Epoch 1540/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 8.5787e-05 - val_loss: 0.0033\n",
      "Epoch 1541/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 8.9992e-05 - val_loss: 0.0033\n",
      "Epoch 1542/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 8.1349e-05 - val_loss: 0.0034\n",
      "Epoch 1543/2000\n",
      "3891/3891 [==============================] - 1s 195us/step - loss: 7.9322e-05 - val_loss: 0.0034\n",
      "Epoch 1544/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 9.0698e-05 - val_loss: 0.0033\n",
      "Epoch 1545/2000\n",
      "3891/3891 [==============================] - 1s 200us/step - loss: 9.6220e-05 - val_loss: 0.0033\n",
      "Epoch 1546/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.0367e-04 - val_loss: 0.0034\n",
      "Epoch 1547/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 9.8878e-05 - val_loss: 0.0033\n",
      "Epoch 1548/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.0373e-04 - val_loss: 0.0032\n",
      "Epoch 1549/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 9.6484e-05 - val_loss: 0.0034\n",
      "Epoch 1550/2000\n",
      "3891/3891 [==============================] - 1s 191us/step - loss: 9.9261e-05 - val_loss: 0.0034\n",
      "Epoch 1551/2000\n",
      "3891/3891 [==============================] - 1s 198us/step - loss: 1.0351e-04 - val_loss: 0.0031\n",
      "Epoch 1552/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 9.4899e-05 - val_loss: 0.0033\n",
      "Epoch 1553/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 9.3339e-05 - val_loss: 0.0032\n",
      "Epoch 1554/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 8.3922e-05 - val_loss: 0.0032\n",
      "Epoch 1555/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 8.4604e-05 - val_loss: 0.0034\n",
      "Epoch 1556/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 8.6035e-05 - val_loss: 0.0031\n",
      "Epoch 1557/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 8.8224e-05 - val_loss: 0.0035\n",
      "Epoch 1558/2000\n",
      "3891/3891 [==============================] - 1s 193us/step - loss: 1.0141e-04 - val_loss: 0.0031\n",
      "Epoch 1559/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 9.6699e-05 - val_loss: 0.0032\n",
      "Epoch 1560/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 9.1096e-05 - val_loss: 0.0034\n",
      "Epoch 1561/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 8.6820e-05 - val_loss: 0.0033\n",
      "Epoch 1562/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 9.4542e-05 - val_loss: 0.0032\n",
      "Epoch 1563/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 9.5839e-05 - val_loss: 0.0032\n",
      "Epoch 1564/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 9.2313e-05 - val_loss: 0.0035\n",
      "Epoch 1565/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 9.1466e-05 - val_loss: 0.0032\n",
      "Epoch 1566/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.1045e-04 - val_loss: 0.0035\n",
      "Epoch 1567/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 1.0107e-04 - val_loss: 0.0033\n",
      "Epoch 1568/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 8.9323e-05 - val_loss: 0.0035\n",
      "Epoch 1569/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 8.9775e-05 - val_loss: 0.0032\n",
      "Epoch 1570/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 8.7563e-05 - val_loss: 0.0034\n",
      "Epoch 1571/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.0649e-04 - val_loss: 0.0034-0\n",
      "Epoch 1572/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 9.7342e-05 - val_loss: 0.0033\n",
      "Epoch 1573/2000\n",
      "3891/3891 [==============================] - 1s 191us/step - loss: 1.2033e-04 - val_loss: 0.0036\n",
      "Epoch 1574/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 1.1861e-04 - val_loss: 0.0032\n",
      "Epoch 1575/2000\n",
      "3891/3891 [==============================] - 1s 194us/step - loss: 1.0093e-04 - val_loss: 0.0032\n",
      "Epoch 1576/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 9.9844e-05 - val_loss: 0.0034\n",
      "Epoch 1577/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 1.0093e-04 - val_loss: 0.0035\n",
      "Epoch 1578/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 8.9311e-05 - val_loss: 0.0033\n",
      "Epoch 1579/2000\n",
      "3891/3891 [==============================] - 1s 195us/step - loss: 8.5876e-05 - val_loss: 0.0033\n",
      "Epoch 1580/2000\n",
      "3891/3891 [==============================] - 1s 194us/step - loss: 8.2875e-05 - val_loss: 0.0034\n",
      "Epoch 1581/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 8.4657e-05 - val_loss: 0.0033\n",
      "Epoch 1582/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 8.8058e-05 - val_loss: 0.0034\n",
      "Epoch 1583/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 9.1278e-05 - val_loss: 0.0034\n",
      "Epoch 1584/2000\n",
      "3891/3891 [==============================] - 1s 193us/step - loss: 9.4808e-05 - val_loss: 0.0036-\n",
      "Epoch 1585/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 8.3787e-05 - val_loss: 0.0033\n",
      "Epoch 1586/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 8.3855e-05 - val_loss: 0.0032\n",
      "Epoch 1587/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 8.6761e-05 - val_loss: 0.0034\n",
      "Epoch 1588/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 8.5750e-05 - val_loss: 0.0034\n",
      "Epoch 1589/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 8.2237e-05 - val_loss: 0.0034\n",
      "Epoch 1590/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 8.8166e-05 - val_loss: 0.0036\n",
      "Epoch 1591/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 9.4667e-05 - val_loss: 0.0034\n",
      "Epoch 1592/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 9.4487e-05 - val_loss: 0.0035\n",
      "Epoch 1593/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 8.8442e-05 - val_loss: 0.0033\n",
      "Epoch 1594/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 1.0620e-04 - val_loss: 0.0034\n",
      "Epoch 1595/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 1.0444e-04 - val_loss: 0.0031\n",
      "Epoch 1596/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 9.7860e-05 - val_loss: 0.0030-\n",
      "Epoch 1597/2000\n",
      "3891/3891 [==============================] - 1s 192us/step - loss: 9.6856e-05 - val_loss: 0.0033\n",
      "Epoch 1598/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 8.6463e-05 - val_loss: 0.0035\n",
      "Epoch 1599/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 8.3024e-05 - val_loss: 0.0033\n",
      "Epoch 1600/2000\n",
      "3891/3891 [==============================] - 1s 191us/step - loss: 7.9846e-05 - val_loss: 0.0035\n",
      "Epoch 1601/2000\n",
      "3891/3891 [==============================] - 1s 192us/step - loss: 9.5237e-05 - val_loss: 0.0034\n",
      "Epoch 1602/2000\n",
      "3891/3891 [==============================] - 1s 192us/step - loss: 9.9753e-05 - val_loss: 0.0032\n",
      "Epoch 1603/2000\n",
      "3891/3891 [==============================] - 1s 191us/step - loss: 9.5013e-05 - val_loss: 0.0037\n",
      "Epoch 1604/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 1.1530e-04 - val_loss: 0.0033\n",
      "Epoch 1605/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 9.3819e-05 - val_loss: 0.0033\n",
      "Epoch 1606/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 8.2169e-05 - val_loss: 0.0035\n",
      "Epoch 1607/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 8.6697e-05 - val_loss: 0.0033\n",
      "Epoch 1608/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 9.0196e-05 - val_loss: 0.0034\n",
      "Epoch 1609/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 8.9348e-05 - val_loss: 0.0033\n",
      "Epoch 1610/2000\n",
      "3891/3891 [==============================] - 1s 195us/step - loss: 8.3785e-05 - val_loss: 0.0035\n",
      "Epoch 1611/2000\n",
      "3891/3891 [==============================] - 1s 194us/step - loss: 8.7292e-05 - val_loss: 0.0033\n",
      "Epoch 1612/2000\n",
      "3891/3891 [==============================] - 1s 192us/step - loss: 8.3752e-05 - val_loss: 0.0034\n",
      "Epoch 1613/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 8.4473e-05 - val_loss: 0.0035\n",
      "Epoch 1614/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 8.4511e-05 - val_loss: 0.0034\n",
      "Epoch 1615/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 8.7455e-05 - val_loss: 0.0034\n",
      "Epoch 1616/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 8.4170e-05 - val_loss: 0.0031\n",
      "Epoch 1617/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 8.7792e-05 - val_loss: 0.0033\n",
      "Epoch 1618/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 8.1940e-05 - val_loss: 0.0038\n",
      "Epoch 1619/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 8.4719e-05 - val_loss: 0.0035\n",
      "Epoch 1620/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 8.2174e-05 - val_loss: 0.0035-0\n",
      "Epoch 1621/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 8.4147e-05 - val_loss: 0.0036\n",
      "Epoch 1622/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 8.5662e-05 - val_loss: 0.0035\n",
      "Epoch 1623/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 8.7495e-05 - val_loss: 0.0034\n",
      "Epoch 1624/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 8.9428e-05 - val_loss: 0.0034\n",
      "Epoch 1625/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 9.0807e-05 - val_loss: 0.0034\n",
      "Epoch 1626/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 8.6814e-05 - val_loss: 0.0036\n",
      "Epoch 1627/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 9.7223e-05 - val_loss: 0.0033\n",
      "Epoch 1628/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.0034e-04 - val_loss: 0.0035\n",
      "Epoch 1629/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 8.6993e-05 - val_loss: 0.0034\n",
      "Epoch 1630/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 9.0708e-05 - val_loss: 0.0034\n",
      "Epoch 1631/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 9.1827e-05 - val_loss: 0.0034\n",
      "Epoch 1632/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 1.0653e-04 - val_loss: 0.0037\n",
      "Epoch 1633/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 8.9784e-05 - val_loss: 0.0034\n",
      "Epoch 1634/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 8.5204e-05 - val_loss: 0.0037\n",
      "Epoch 1635/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 8.5613e-05 - val_loss: 0.0035\n",
      "Epoch 1636/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 8.7440e-05 - val_loss: 0.0035\n",
      "Epoch 1637/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 8.3060e-05 - val_loss: 0.0036\n",
      "Epoch 1638/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.0110e-04 - val_loss: 0.0033\n",
      "Epoch 1639/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.1818e-04 - val_loss: 0.0036\n",
      "Epoch 1640/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 8.8122e-05 - val_loss: 0.0034\n",
      "Epoch 1641/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 9.8052e-05 - val_loss: 0.0036\n",
      "Epoch 1642/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.1898e-04 - val_loss: 0.0031\n",
      "Epoch 1643/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.1443e-04 - val_loss: 0.0034\n",
      "Epoch 1644/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.0299e-04 - val_loss: 0.0033\n",
      "Epoch 1645/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 9.6383e-05 - val_loss: 0.0033\n",
      "Epoch 1646/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 8.3083e-05 - val_loss: 0.0033\n",
      "Epoch 1647/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 8.1423e-05 - val_loss: 0.0034\n",
      "Epoch 1648/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 7.8860e-05 - val_loss: 0.0032\n",
      "Epoch 1649/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 8.5013e-05 - val_loss: 0.0036\n",
      "Epoch 1650/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 8.6820e-05 - val_loss: 0.0033\n",
      "Epoch 1651/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 8.2205e-05 - val_loss: 0.0034\n",
      "Epoch 1652/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 7.9274e-05 - val_loss: 0.0035\n",
      "Epoch 1653/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 8.3292e-05 - val_loss: 0.0035\n",
      "Epoch 1654/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 8.1376e-05 - val_loss: 0.0035\n",
      "Epoch 1655/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 7.7732e-05 - val_loss: 0.0035\n",
      "Epoch 1656/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 7.2431e-05 - val_loss: 0.0035\n",
      "Epoch 1657/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 7.5121e-05 - val_loss: 0.0036\n",
      "Epoch 1658/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 8.5316e-05 - val_loss: 0.0033\n",
      "Epoch 1659/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 9.0375e-05 - val_loss: 0.0034\n",
      "Epoch 1660/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 9.3866e-05 - val_loss: 0.0035\n",
      "Epoch 1661/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 8.7566e-05 - val_loss: 0.0036\n",
      "Epoch 1662/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 8.8418e-05 - val_loss: 0.0035\n",
      "Epoch 1663/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 9.6255e-05 - val_loss: 0.0038\n",
      "Epoch 1664/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 9.2913e-05 - val_loss: 0.0034\n",
      "Epoch 1665/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 9.8591e-05 - val_loss: 0.0034\n",
      "Epoch 1666/2000\n",
      "3891/3891 [==============================] - 1s 195us/step - loss: 8.4011e-05 - val_loss: 0.0035\n",
      "Epoch 1667/2000\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 7.8597e-05 - val_loss: 0.0034\n",
      "Epoch 1668/2000\n",
      "3891/3891 [==============================] - 1s 195us/step - loss: 7.9835e-05 - val_loss: 0.0036\n",
      "Epoch 1669/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 7.9461e-05 - val_loss: 0.0035\n",
      "Epoch 1670/2000\n",
      "3891/3891 [==============================] - 1s 196us/step - loss: 9.5462e-05 - val_loss: 0.0034\n",
      "Epoch 1671/2000\n",
      "3891/3891 [==============================] - 1s 200us/step - loss: 8.7253e-05 - val_loss: 0.0035\n",
      "Epoch 1672/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 7.7961e-05 - val_loss: 0.0035\n",
      "Epoch 1673/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 8.0565e-05 - val_loss: 0.0037\n",
      "Epoch 1674/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 8.1004e-05 - val_loss: 0.0035\n",
      "Epoch 1675/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 9.7352e-05 - val_loss: 0.0037\n",
      "Epoch 1676/2000\n",
      "3891/3891 [==============================] - 1s 192us/step - loss: 9.1766e-05 - val_loss: 0.0034\n",
      "Epoch 1677/2000\n",
      "3891/3891 [==============================] - 1s 196us/step - loss: 8.1513e-05 - val_loss: 0.0036\n",
      "Epoch 1678/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 8.0173e-05 - val_loss: 0.0036\n",
      "Epoch 1679/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 7.2246e-05 - val_loss: 0.0035\n",
      "Epoch 1680/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 8.1189e-05 - val_loss: 0.0035\n",
      "Epoch 1681/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 7.7334e-05 - val_loss: 0.0033\n",
      "Epoch 1682/2000\n",
      "3891/3891 [==============================] - 1s 194us/step - loss: 7.9955e-05 - val_loss: 0.0036\n",
      "Epoch 1683/2000\n",
      "3891/3891 [==============================] - 1s 207us/step - loss: 9.4942e-05 - val_loss: 0.0033\n",
      "Epoch 1684/2000\n",
      "3891/3891 [==============================] - 1s 201us/step - loss: 9.5327e-05 - val_loss: 0.0038\n",
      "Epoch 1685/2000\n",
      "3891/3891 [==============================] - 1s 197us/step - loss: 8.9848e-05 - val_loss: 0.0036\n",
      "Epoch 1686/2000\n",
      "3891/3891 [==============================] - 1s 193us/step - loss: 9.2257e-05 - val_loss: 0.0035\n",
      "Epoch 1687/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 9.8113e-05 - val_loss: 0.0036\n",
      "Epoch 1688/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 9.4437e-05 - val_loss: 0.0036\n",
      "Epoch 1689/2000\n",
      "3891/3891 [==============================] - 1s 235us/step - loss: 1.3319e-04 - val_loss: 0.0037\n",
      "Epoch 1690/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 1.3916e-04 - val_loss: 0.0032\n",
      "Epoch 1691/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 1.0433e-04 - val_loss: 0.0031\n",
      "Epoch 1692/2000\n",
      "3891/3891 [==============================] - 1s 194us/step - loss: 1.0453e-04 - val_loss: 0.0034\n",
      "Epoch 1693/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 9.3320e-05 - val_loss: 0.0032\n",
      "Epoch 1694/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 9.4262e-05 - val_loss: 0.0034\n",
      "Epoch 1695/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 1.0189e-04 - val_loss: 0.0035\n",
      "Epoch 1696/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 9.3142e-05 - val_loss: 0.0033\n",
      "Epoch 1697/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 8.4008e-05 - val_loss: 0.0036\n",
      "Epoch 1698/2000\n",
      "3891/3891 [==============================] - 1s 192us/step - loss: 8.8152e-05 - val_loss: 0.0035\n",
      "Epoch 1699/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 8.3888e-05 - val_loss: 0.0034\n",
      "Epoch 1700/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 8.0658e-05 - val_loss: 0.0034\n",
      "Epoch 1701/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 7.8905e-05 - val_loss: 0.0034\n",
      "Epoch 1702/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 7.4650e-05 - val_loss: 0.0035\n",
      "Epoch 1703/2000\n",
      "3891/3891 [==============================] - 1s 196us/step - loss: 6.9748e-05 - val_loss: 0.0036\n",
      "Epoch 1704/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 6.6720e-05 - val_loss: 0.0035-\n",
      "Epoch 1705/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 7.8013e-05 - val_loss: 0.0036\n",
      "Epoch 1706/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 7.0416e-05 - val_loss: 0.0034\n",
      "Epoch 1707/2000\n",
      "3891/3891 [==============================] - 1s 196us/step - loss: 7.6890e-05 - val_loss: 0.0036\n",
      "Epoch 1708/2000\n",
      "3891/3891 [==============================] - 1s 195us/step - loss: 7.6160e-05 - val_loss: 0.0034\n",
      "Epoch 1709/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 7.7184e-05 - val_loss: 0.0036\n",
      "Epoch 1710/2000\n",
      "3891/3891 [==============================] - 1s 192us/step - loss: 7.8862e-05 - val_loss: 0.0035\n",
      "Epoch 1711/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 7.9831e-05 - val_loss: 0.0036\n",
      "Epoch 1712/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 1.0092e-04 - val_loss: 0.0033\n",
      "Epoch 1713/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 9.6088e-05 - val_loss: 0.0037\n",
      "Epoch 1714/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 8.6399e-05 - val_loss: 0.0035\n",
      "Epoch 1715/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 8.9654e-05 - val_loss: 0.0036\n",
      "Epoch 1716/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 8.7377e-05 - val_loss: 0.0034\n",
      "Epoch 1717/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 8.4163e-05 - val_loss: 0.0037\n",
      "Epoch 1718/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 8.7706e-05 - val_loss: 0.0033\n",
      "Epoch 1719/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 8.2018e-05 - val_loss: 0.0037\n",
      "Epoch 1720/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 8.8266e-05 - val_loss: 0.0034\n",
      "Epoch 1721/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 9.0422e-05 - val_loss: 0.0035\n",
      "Epoch 1722/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 8.4854e-05 - val_loss: 0.0035\n",
      "Epoch 1723/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 8.1756e-05 - val_loss: 0.0035\n",
      "Epoch 1724/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 8.6400e-05 - val_loss: 0.0033\n",
      "Epoch 1725/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 8.5427e-05 - val_loss: 0.0038\n",
      "Epoch 1726/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 9.8478e-05 - val_loss: 0.0033\n",
      "Epoch 1727/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 9.0399e-05 - val_loss: 0.0034\n",
      "Epoch 1728/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 8.2675e-05 - val_loss: 0.0035\n",
      "Epoch 1729/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 8.6587e-05 - val_loss: 0.0035\n",
      "Epoch 1730/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 8.8676e-05 - val_loss: 0.0031\n",
      "Epoch 1731/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 9.1076e-05 - val_loss: 0.0037\n",
      "Epoch 1732/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 9.4759e-05 - val_loss: 0.0034\n",
      "Epoch 1733/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 7.8016e-05 - val_loss: 0.0035\n",
      "Epoch 1734/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 8.8180e-05 - val_loss: 0.0033\n",
      "Epoch 1735/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 9.0564e-05 - val_loss: 0.0035\n",
      "Epoch 1736/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 9.0607e-05 - val_loss: 0.0032\n",
      "Epoch 1737/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 8.5994e-05 - val_loss: 0.0034\n",
      "Epoch 1738/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 7.8917e-05 - val_loss: 0.0033\n",
      "Epoch 1739/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 7.8679e-05 - val_loss: 0.0034\n",
      "Epoch 1740/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 7.4493e-05 - val_loss: 0.0032\n",
      "Epoch 1741/2000\n",
      "3891/3891 [==============================] - 1s 193us/step - loss: 7.0282e-05 - val_loss: 0.0035\n",
      "Epoch 1742/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 6.9414e-05 - val_loss: 0.0036\n",
      "Epoch 1743/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 7.2831e-05 - val_loss: 0.0038\n",
      "Epoch 1744/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 7.1847e-05 - val_loss: 0.0035\n",
      "Epoch 1745/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 6.9725e-05 - val_loss: 0.0034\n",
      "Epoch 1746/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 7.3577e-05 - val_loss: 0.0038\n",
      "Epoch 1747/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 7.6016e-05 - val_loss: 0.0034\n",
      "Epoch 1748/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 1.1541e-04 - val_loss: 0.0038\n",
      "Epoch 1749/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.2135e-04 - val_loss: 0.0033\n",
      "Epoch 1750/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 9.9723e-05 - val_loss: 0.0039\n",
      "Epoch 1751/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 1.0420e-04 - val_loss: 0.0032\n",
      "Epoch 1752/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 9.7285e-05 - val_loss: 0.0034\n",
      "Epoch 1753/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 8.8066e-05 - val_loss: 0.0034\n",
      "Epoch 1754/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 8.3226e-05 - val_loss: 0.0035\n",
      "Epoch 1755/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 7.9030e-05 - val_loss: 0.0034\n",
      "Epoch 1756/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 7.7474e-05 - val_loss: 0.0032\n",
      "Epoch 1757/2000\n",
      "3891/3891 [==============================] - 1s 191us/step - loss: 8.2331e-05 - val_loss: 0.0035\n",
      "Epoch 1758/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 7.8996e-05 - val_loss: 0.0033\n",
      "Epoch 1759/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 7.6075e-05 - val_loss: 0.0033\n",
      "Epoch 1760/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 7.4048e-05 - val_loss: 0.0035\n",
      "Epoch 1761/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 6.9092e-05 - val_loss: 0.0034\n",
      "Epoch 1762/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 7.6144e-05 - val_loss: 0.0037\n",
      "Epoch 1763/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 8.2824e-05 - val_loss: 0.0034\n",
      "Epoch 1764/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 7.0928e-05 - val_loss: 0.0036\n",
      "Epoch 1765/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 7.2904e-05 - val_loss: 0.0034\n",
      "Epoch 1766/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 7.6510e-05 - val_loss: 0.0034\n",
      "Epoch 1767/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 9.1608e-05 - val_loss: 0.0037\n",
      "Epoch 1768/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 9.3471e-05 - val_loss: 0.0034\n",
      "Epoch 1769/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 9.8938e-05 - val_loss: 0.0035\n",
      "Epoch 1770/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 8.0989e-05 - val_loss: 0.0035\n",
      "Epoch 1771/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 8.0797e-05 - val_loss: 0.0036\n",
      "Epoch 1772/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 7.9396e-05 - val_loss: 0.0036\n",
      "Epoch 1773/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 7.7678e-05 - val_loss: 0.0033\n",
      "Epoch 1774/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 7.4865e-05 - val_loss: 0.0036\n",
      "Epoch 1775/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 8.6018e-05 - val_loss: 0.0035\n",
      "Epoch 1776/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 8.1847e-05 - val_loss: 0.0033\n",
      "Epoch 1777/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 9.0984e-05 - val_loss: 0.0035\n",
      "Epoch 1778/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 8.3497e-05 - val_loss: 0.0034\n",
      "Epoch 1779/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 8.6949e-05 - val_loss: 0.0036\n",
      "Epoch 1780/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 9.9583e-05 - val_loss: 0.0032\n",
      "Epoch 1781/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 8.5445e-05 - val_loss: 0.0033\n",
      "Epoch 1782/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 7.2192e-05 - val_loss: 0.0034\n",
      "Epoch 1783/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 8.2093e-05 - val_loss: 0.0034\n",
      "Epoch 1784/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 8.0717e-05 - val_loss: 0.0034\n",
      "Epoch 1785/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 7.2861e-05 - val_loss: 0.0036\n",
      "Epoch 1786/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 6.9686e-05 - val_loss: 0.0035\n",
      "Epoch 1787/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 7.8868e-05 - val_loss: 0.0034\n",
      "Epoch 1788/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 1s 189us/step - loss: 6.9700e-05 - val_loss: 0.0035\n",
      "Epoch 1789/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 7.4637e-05 - val_loss: 0.0032\n",
      "Epoch 1790/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 7.6013e-05 - val_loss: 0.0036\n",
      "Epoch 1791/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 8.7687e-05 - val_loss: 0.0033\n",
      "Epoch 1792/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 8.0895e-05 - val_loss: 0.0038\n",
      "Epoch 1793/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 9.4092e-05 - val_loss: 0.0034\n",
      "Epoch 1794/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 9.1585e-05 - val_loss: 0.0034\n",
      "Epoch 1795/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 9.5182e-05 - val_loss: 0.0036\n",
      "Epoch 1796/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 8.2386e-05 - val_loss: 0.0033\n",
      "Epoch 1797/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 7.1919e-05 - val_loss: 0.0034\n",
      "Epoch 1798/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 6.6411e-05 - val_loss: 0.0036\n",
      "Epoch 1799/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 6.1911e-05 - val_loss: 0.0033\n",
      "Epoch 1800/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 7.0526e-05 - val_loss: 0.0038\n",
      "Epoch 1801/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 7.3309e-05 - val_loss: 0.0035\n",
      "Epoch 1802/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 6.9244e-05 - val_loss: 0.0035\n",
      "Epoch 1803/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 6.4016e-05 - val_loss: 0.0034\n",
      "Epoch 1804/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 6.4245e-05 - val_loss: 0.0034\n",
      "Epoch 1805/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 7.2397e-05 - val_loss: 0.0038\n",
      "Epoch 1806/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 7.0713e-05 - val_loss: 0.0036\n",
      "Epoch 1807/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 6.7753e-05 - val_loss: 0.0033\n",
      "Epoch 1808/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 7.5024e-05 - val_loss: 0.0035\n",
      "Epoch 1809/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 6.9536e-05 - val_loss: 0.0036\n",
      "Epoch 1810/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 7.1557e-05 - val_loss: 0.0032\n",
      "Epoch 1811/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 8.2467e-05 - val_loss: 0.0039\n",
      "Epoch 1812/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 8.9499e-05 - val_loss: 0.0034\n",
      "Epoch 1813/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 7.1984e-05 - val_loss: 0.0036\n",
      "Epoch 1814/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 6.9734e-05 - val_loss: 0.0035\n",
      "Epoch 1815/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 6.9632e-05 - val_loss: 0.0035\n",
      "Epoch 1816/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 6.3288e-05 - val_loss: 0.0036\n",
      "Epoch 1817/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 6.4643e-05 - val_loss: 0.0035\n",
      "Epoch 1818/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 6.6071e-05 - val_loss: 0.0036\n",
      "Epoch 1819/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 6.9611e-05 - val_loss: 0.0034\n",
      "Epoch 1820/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 8.5629e-05 - val_loss: 0.0035\n",
      "Epoch 1821/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 7.2822e-05 - val_loss: 0.0036\n",
      "Epoch 1822/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 7.7078e-05 - val_loss: 0.0033\n",
      "Epoch 1823/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 7.7836e-05 - val_loss: 0.0036\n",
      "Epoch 1824/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 7.3624e-05 - val_loss: 0.0035\n",
      "Epoch 1825/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 7.6464e-05 - val_loss: 0.0034\n",
      "Epoch 1826/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 7.2002e-05 - val_loss: 0.0034\n",
      "Epoch 1827/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 6.9621e-05 - val_loss: 0.0034\n",
      "Epoch 1828/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 6.3593e-05 - val_loss: 0.0034\n",
      "Epoch 1829/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 6.9199e-05 - val_loss: 0.0034\n",
      "Epoch 1830/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 6.8566e-05 - val_loss: 0.0035\n",
      "Epoch 1831/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 6.3222e-05 - val_loss: 0.0037\n",
      "Epoch 1832/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 6.6867e-05 - val_loss: 0.0035\n",
      "Epoch 1833/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 6.5142e-05 - val_loss: 0.0035\n",
      "Epoch 1834/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 5.8681e-05 - val_loss: 0.0035\n",
      "Epoch 1835/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 6.0311e-05 - val_loss: 0.0035\n",
      "Epoch 1836/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 6.4745e-05 - val_loss: 0.0037\n",
      "Epoch 1837/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 6.4860e-05 - val_loss: 0.0038\n",
      "Epoch 1838/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 6.5477e-05 - val_loss: 0.0036\n",
      "Epoch 1839/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 6.1095e-05 - val_loss: 0.0035\n",
      "Epoch 1840/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 6.6766e-05 - val_loss: 0.0035\n",
      "Epoch 1841/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 6.7044e-05 - val_loss: 0.0036\n",
      "Epoch 1842/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 7.6825e-05 - val_loss: 0.0034\n",
      "Epoch 1843/2000\n",
      "3891/3891 [==============================] - 1s 197us/step - loss: 7.1064e-05 - val_loss: 0.0037\n",
      "Epoch 1844/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 6.2149e-05 - val_loss: 0.0037\n",
      "Epoch 1845/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 5.8859e-05 - val_loss: 0.0035\n",
      "Epoch 1846/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 5.7446e-05 - val_loss: 0.0037\n",
      "Epoch 1847/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 6.2590e-05 - val_loss: 0.0034\n",
      "Epoch 1848/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 6.9796e-05 - val_loss: 0.0035\n",
      "Epoch 1849/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 6.5738e-05 - val_loss: 0.0037\n",
      "Epoch 1850/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 6.5056e-05 - val_loss: 0.0037\n",
      "Epoch 1851/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 6.9697e-05 - val_loss: 0.0036\n",
      "Epoch 1852/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 6.7199e-05 - val_loss: 0.0036\n",
      "Epoch 1853/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 6.4916e-05 - val_loss: 0.0036\n",
      "Epoch 1854/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 7.3977e-05 - val_loss: 0.0036\n",
      "Epoch 1855/2000\n",
      "3891/3891 [==============================] - 1s 194us/step - loss: 8.5374e-05 - val_loss: 0.0038\n",
      "Epoch 1856/2000\n",
      "3891/3891 [==============================] - 1s 192us/step - loss: 9.5481e-05 - val_loss: 0.0035\n",
      "Epoch 1857/2000\n",
      "3891/3891 [==============================] - 1s 197us/step - loss: 8.2405e-05 - val_loss: 0.0039\n",
      "Epoch 1858/2000\n",
      "3891/3891 [==============================] - 1s 192us/step - loss: 8.5793e-05 - val_loss: 0.0035\n",
      "Epoch 1859/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 8.6873e-05 - val_loss: 0.0038\n",
      "Epoch 1860/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 8.7439e-05 - val_loss: 0.0034\n",
      "Epoch 1861/2000\n",
      "3891/3891 [==============================] - 1s 193us/step - loss: 7.6491e-05 - val_loss: 0.0037\n",
      "Epoch 1862/2000\n",
      "3891/3891 [==============================] - 1s 197us/step - loss: 7.7565e-05 - val_loss: 0.0034\n",
      "Epoch 1863/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 8.7709e-05 - val_loss: 0.0037\n",
      "Epoch 1864/2000\n",
      "3891/3891 [==============================] - 1s 210us/step - loss: 7.8647e-05 - val_loss: 0.0034\n",
      "Epoch 1865/2000\n",
      "3891/3891 [==============================] - 1s 198us/step - loss: 9.3195e-05 - val_loss: 0.0037\n",
      "Epoch 1866/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 1.4428e-04 - val_loss: 0.0033\n",
      "Epoch 1867/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 9.8867e-05 - val_loss: 0.0035\n",
      "Epoch 1868/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 8.7532e-05 - val_loss: 0.0033\n",
      "Epoch 1869/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 7.9112e-05 - val_loss: 0.0035\n",
      "Epoch 1870/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 8.5127e-05 - val_loss: 0.0034\n",
      "Epoch 1871/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 9.4254e-05 - val_loss: 0.0038\n",
      "Epoch 1872/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 8.8176e-05 - val_loss: 0.0032\n",
      "Epoch 1873/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 9.0728e-05 - val_loss: 0.0036\n",
      "Epoch 1874/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 7.3253e-05 - val_loss: 0.0034\n",
      "Epoch 1875/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 7.0174e-05 - val_loss: 0.0032\n",
      "Epoch 1876/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 6.6045e-05 - val_loss: 0.0034\n",
      "Epoch 1877/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 6.1588e-05 - val_loss: 0.0035\n",
      "Epoch 1878/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 6.0621e-05 - val_loss: 0.0034\n",
      "Epoch 1879/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 6.5417e-05 - val_loss: 0.0034\n",
      "Epoch 1880/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 6.5484e-05 - val_loss: 0.0033\n",
      "Epoch 1881/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 7.2555e-05 - val_loss: 0.0034\n",
      "Epoch 1882/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 6.6818e-05 - val_loss: 0.0033\n",
      "Epoch 1883/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 6.2340e-05 - val_loss: 0.0033\n",
      "Epoch 1884/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 7.0580e-05 - val_loss: 0.0036\n",
      "Epoch 1885/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 6.2758e-05 - val_loss: 0.0036\n",
      "Epoch 1886/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 6.1758e-05 - val_loss: 0.0036\n",
      "Epoch 1887/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 6.8502e-05 - val_loss: 0.0038\n",
      "Epoch 1888/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 6.7519e-05 - val_loss: 0.0035\n",
      "Epoch 1889/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 6.7632e-05 - val_loss: 0.0034\n",
      "Epoch 1890/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 6.1970e-05 - val_loss: 0.0035\n",
      "Epoch 1891/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 7.6673e-05 - val_loss: 0.0035\n",
      "Epoch 1892/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 8.1267e-05 - val_loss: 0.0035\n",
      "Epoch 1893/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 7.9373e-05 - val_loss: 0.0032\n",
      "Epoch 1894/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 7.7781e-05 - val_loss: 0.0034\n",
      "Epoch 1895/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 7.8321e-05 - val_loss: 0.0035\n",
      "Epoch 1896/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 7.5193e-05 - val_loss: 0.0037\n",
      "Epoch 1897/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 7.4595e-05 - val_loss: 0.0033\n",
      "Epoch 1898/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 6.7605e-05 - val_loss: 0.0034\n",
      "Epoch 1899/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 6.4458e-05 - val_loss: 0.0034\n",
      "Epoch 1900/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 6.2524e-05 - val_loss: 0.0032\n",
      "Epoch 1901/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 7.0123e-05 - val_loss: 0.0035\n",
      "Epoch 1902/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 7.4355e-05 - val_loss: 0.0037\n",
      "Epoch 1903/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 6.8969e-05 - val_loss: 0.0034\n",
      "Epoch 1904/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 6.8341e-05 - val_loss: 0.0036\n",
      "Epoch 1905/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 6.6753e-05 - val_loss: 0.0036\n",
      "Epoch 1906/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 6.1844e-05 - val_loss: 0.0033\n",
      "Epoch 1907/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 6.4978e-05 - val_loss: 0.0036\n",
      "Epoch 1908/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 5.9895e-05 - val_loss: 0.0035\n",
      "Epoch 1909/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 6.4559e-05 - val_loss: 0.0036\n",
      "Epoch 1910/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 6.6288e-05 - val_loss: 0.0036\n",
      "Epoch 1911/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 7.2954e-05 - val_loss: 0.0035\n",
      "Epoch 1912/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 8.6415e-05 - val_loss: 0.0036\n",
      "Epoch 1913/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 7.9558e-05 - val_loss: 0.0034\n",
      "Epoch 1914/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 6.3440e-05 - val_loss: 0.0037\n",
      "Epoch 1915/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 6.3423e-05 - val_loss: 0.0034\n",
      "Epoch 1916/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 6.8358e-05 - val_loss: 0.0038\n",
      "Epoch 1917/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 7.1599e-05 - val_loss: 0.0033\n",
      "Epoch 1918/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 6.4550e-05 - val_loss: 0.0036\n",
      "Epoch 1919/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 6.6159e-05 - val_loss: 0.0033\n",
      "Epoch 1920/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 6.5933e-05 - val_loss: 0.0036\n",
      "Epoch 1921/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 6.1929e-05 - val_loss: 0.0034\n",
      "Epoch 1922/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 6.2937e-05 - val_loss: 0.0035\n",
      "Epoch 1923/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 6.4476e-05 - val_loss: 0.0036\n",
      "Epoch 1924/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 6.1777e-05 - val_loss: 0.0036\n",
      "Epoch 1925/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 6.4619e-05 - val_loss: 0.0036\n",
      "Epoch 1926/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 6.3433e-05 - val_loss: 0.0034\n",
      "Epoch 1927/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 6.1162e-05 - val_loss: 0.0036\n",
      "Epoch 1928/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 6.0953e-05 - val_loss: 0.0035\n",
      "Epoch 1929/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 6.1590e-05 - val_loss: 0.0037\n",
      "Epoch 1930/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 6.1824e-05 - val_loss: 0.0037\n",
      "Epoch 1931/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 5.6672e-05 - val_loss: 0.0035\n",
      "Epoch 1932/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 1s 189us/step - loss: 6.1637e-05 - val_loss: 0.0034\n",
      "Epoch 1933/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 6.3255e-05 - val_loss: 0.0037\n",
      "Epoch 1934/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 6.7756e-05 - val_loss: 0.0035\n",
      "Epoch 1935/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 7.2482e-05 - val_loss: 0.0038\n",
      "Epoch 1936/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 7.5123e-05 - val_loss: 0.0033\n",
      "Epoch 1937/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 7.6288e-05 - val_loss: 0.0038\n",
      "Epoch 1938/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 7.3384e-05 - val_loss: 0.0036\n",
      "Epoch 1939/2000\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 7.6726e-05 - val_loss: 0.0038-\n",
      "Epoch 1940/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 7.0757e-05 - val_loss: 0.0036\n",
      "Epoch 1941/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 7.3327e-05 - val_loss: 0.0033\n",
      "Epoch 1942/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 7.2611e-05 - val_loss: 0.0038\n",
      "Epoch 1943/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 8.1317e-05 - val_loss: 0.0034\n",
      "Epoch 1944/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 6.6362e-05 - val_loss: 0.0033\n",
      "Epoch 1945/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 7.3078e-05 - val_loss: 0.0036\n",
      "Epoch 1946/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 8.5050e-05 - val_loss: 0.0035\n",
      "Epoch 1947/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 7.8366e-05 - val_loss: 0.0038\n",
      "Epoch 1948/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 8.3797e-05 - val_loss: 0.0033\n",
      "Epoch 1949/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 8.1355e-05 - val_loss: 0.0035\n",
      "Epoch 1950/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 8.6537e-05 - val_loss: 0.0033\n",
      "Epoch 1951/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 8.5751e-05 - val_loss: 0.0036\n",
      "Epoch 1952/2000\n",
      "3891/3891 [==============================] - 1s 191us/step - loss: 7.9325e-05 - val_loss: 0.0034\n",
      "Epoch 1953/2000\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 7.7978e-05 - val_loss: 0.0033\n",
      "Epoch 1954/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 8.9936e-05 - val_loss: 0.0036\n",
      "Epoch 1955/2000\n",
      "3891/3891 [==============================] - 1s 192us/step - loss: 9.0779e-05 - val_loss: 0.0035\n",
      "Epoch 1956/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 8.2625e-05 - val_loss: 0.0031\n",
      "Epoch 1957/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 8.3631e-05 - val_loss: 0.0035\n",
      "Epoch 1958/2000\n",
      "3891/3891 [==============================] - 1s 191us/step - loss: 9.1466e-05 - val_loss: 0.0032\n",
      "Epoch 1959/2000\n",
      "3891/3891 [==============================] - 1s 194us/step - loss: 9.7731e-05 - val_loss: 0.0036\n",
      "Epoch 1960/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 8.2050e-05 - val_loss: 0.0034\n",
      "Epoch 1961/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 7.3731e-05 - val_loss: 0.0033\n",
      "Epoch 1962/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 6.6542e-05 - val_loss: 0.0035\n",
      "Epoch 1963/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 6.8083e-05 - val_loss: 0.0032\n",
      "Epoch 1964/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 6.2757e-05 - val_loss: 0.0036\n",
      "Epoch 1965/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 6.8181e-05 - val_loss: 0.0034\n",
      "Epoch 1966/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 6.5899e-05 - val_loss: 0.0035\n",
      "Epoch 1967/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 6.1845e-05 - val_loss: 0.0035\n",
      "Epoch 1968/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 6.1286e-05 - val_loss: 0.0036\n",
      "Epoch 1969/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 6.3229e-05 - val_loss: 0.0035\n",
      "Epoch 1970/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 5.8859e-05 - val_loss: 0.0034\n",
      "Epoch 1971/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 6.1063e-05 - val_loss: 0.0036\n",
      "Epoch 1972/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 5.8835e-05 - val_loss: 0.0036\n",
      "Epoch 1973/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 6.5156e-05 - val_loss: 0.0035\n",
      "Epoch 1974/2000\n",
      "3891/3891 [==============================] - 1s 191us/step - loss: 6.8749e-05 - val_loss: 0.0037\n",
      "Epoch 1975/2000\n",
      "3891/3891 [==============================] - 1s 194us/step - loss: 6.6031e-05 - val_loss: 0.0035\n",
      "Epoch 1976/2000\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 6.5203e-05 - val_loss: 0.0035\n",
      "Epoch 1977/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 6.0166e-05 - val_loss: 0.0037\n",
      "Epoch 1978/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 6.5752e-05 - val_loss: 0.0033\n",
      "Epoch 1979/2000\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 5.7164e-05 - val_loss: 0.0034\n",
      "Epoch 1980/2000\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 6.1409e-05 - val_loss: 0.0034\n",
      "Epoch 1981/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 5.9099e-05 - val_loss: 0.0034\n",
      "Epoch 1982/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 5.5867e-05 - val_loss: 0.0036\n",
      "Epoch 1983/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 5.7807e-05 - val_loss: 0.0035\n",
      "Epoch 1984/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 5.7660e-05 - val_loss: 0.0036\n",
      "Epoch 1985/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 6.1075e-05 - val_loss: 0.0033\n",
      "Epoch 1986/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 6.1406e-05 - val_loss: 0.0035\n",
      "Epoch 1987/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 5.7331e-05 - val_loss: 0.0036\n",
      "Epoch 1988/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 5.7674e-05 - val_loss: 0.0037\n",
      "Epoch 1989/2000\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 5.9823e-05 - val_loss: 0.0036\n",
      "Epoch 1990/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 7.0004e-05 - val_loss: 0.0035\n",
      "Epoch 1991/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 7.1516e-05 - val_loss: 0.0036\n",
      "Epoch 1992/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 6.8141e-05 - val_loss: 0.0037\n",
      "Epoch 1993/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 6.0099e-05 - val_loss: 0.0037\n",
      "Epoch 1994/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 5.8752e-05 - val_loss: 0.0034\n",
      "Epoch 1995/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 5.9610e-05 - val_loss: 0.0036\n",
      "Epoch 1996/2000\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 5.1502e-05 - val_loss: 0.0037\n",
      "Epoch 1997/2000\n",
      "3891/3891 [==============================] - 1s 191us/step - loss: 4.8803e-05 - val_loss: 0.0035\n",
      "Epoch 1998/2000\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 5.1885e-05 - val_loss: 0.0037\n",
      "Epoch 1999/2000\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 5.5088e-05 - val_loss: 0.0037- - ETA: 0s - loss: 5.5077\n",
      "Epoch 2000/2000\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 6.2484e-05 - val_loss: 0.0036\n"
     ]
    }
   ],
   "source": [
    "final_model = build_lstm(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'density': 138,\n",
       " 'shuffle': True,\n",
       " 'full_density': True,\n",
       " 'twice': False,\n",
       " 'activation': 'relu',\n",
       " 'optimizer': 'adam',\n",
       " 'lstmsize': 92,\n",
       " 'callbacks': [<keras.callbacks.callbacks.ModelCheckpoint at 0x1a8de54d488>]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_182\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_303 (LSTM)              (None, 92)                36064     \n",
      "_________________________________________________________________\n",
      "dense_919 (Dense)            (None, 138)               12834     \n",
      "_________________________________________________________________\n",
      "dense_920 (Dense)            (None, 69)                9591      \n",
      "_________________________________________________________________\n",
      "dense_921 (Dense)            (None, 34)                2380      \n",
      "_________________________________________________________________\n",
      "dense_922 (Dense)            (None, 17)                595       \n",
      "_________________________________________________________________\n",
      "dense_923 (Dense)            (None, 1)                 18        \n",
      "=================================================================\n",
      "Total params: 61,482\n",
      "Trainable params: 61,482\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model[0].load_weights('./checkpoints/IBM_4days/IBM.(best).hdf5')\n",
    "y_predicted = final_model[0].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y_test = y_normaliser.inverse_transform(y_predicted)\n",
    "true_y_test = y_normaliser.inverse_transform(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE is 51.07\n",
      "Medium error is 5.30\n"
     ]
    }
   ],
   "source": [
    "loss = np.mean((true_y_test - predicted_y_test)**2)\n",
    "medium_error = np.mean(abs(true_y_test - predicted_y_test))\n",
    "print(f'MSE is {loss:.2f}\\nMedium error is {medium_error:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_down_test = []\n",
    "up_down_predicted = []\n",
    "\n",
    "for y,x in zip(Y_test,X_test):\n",
    "    if y[0] > x[-1][0]: up_down_test.append(1)\n",
    "    elif y[0] < x[-1][0]: up_down_test.append(-1)\n",
    "    else: up_down_test.append(0)\n",
    "        \n",
    "for y,x in zip(y_predicted,X_test):\n",
    "    if y[0] > x[-1][0]: up_down_predicted.append(1)\n",
    "    elif y[0] < x[-1][0]: up_down_predicted.append(-1)\n",
    "    else: up_down_predicted.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trend accuracy is: 53.29%\n"
     ]
    }
   ],
   "source": [
    "print(f'Trend accuracy is: {(sum(1 for r,p in zip(up_down_test,up_down_predicted) if r == p)/len(up_down_test))*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for upward trend is: 18.42%\n",
      "Accuracy for downward trend is: 88.16%\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy for upward trend is: {(sum(1 for r,p in zip(up_down_test,up_down_predicted) if r == 1 and p == 1)/sum(1 for v in up_down_test if v == 1))*100:.2f}%')\n",
    "print(f'Accuracy for downward trend is: {(sum(1 for r,p in zip(up_down_test,up_down_predicted) if r == -1 and p == -1)/sum(1 for v in up_down_test if v == -1))*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predictions over the last 92 days in test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 3200x2400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "figure(num=None, figsize=(40, 30), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "plt.plot(range(92), true_y_test[-92:])\n",
    "plt.plot(range(92), predicted_y_test[-92:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Last 16 days + prediction of last 8 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 3200x2400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure(num=None, figsize=(40, 30), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "plt.plot(range(16), true_y_test[-16:])\n",
    "plt.plot(range(16), np.append(true_y_test[-16:-8], predicted_y_test[-8:]))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
