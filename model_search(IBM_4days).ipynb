{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./datasets/IBM_daily.csv').sort_values(by='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>1. open</th>\n",
       "      <th>2. high</th>\n",
       "      <th>3. low</th>\n",
       "      <th>4. close</th>\n",
       "      <th>5. volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5217</th>\n",
       "      <td>1999-11-01</td>\n",
       "      <td>98.50</td>\n",
       "      <td>98.8100</td>\n",
       "      <td>96.37</td>\n",
       "      <td>96.75</td>\n",
       "      <td>9551800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5216</th>\n",
       "      <td>1999-11-02</td>\n",
       "      <td>96.75</td>\n",
       "      <td>96.8100</td>\n",
       "      <td>93.69</td>\n",
       "      <td>94.81</td>\n",
       "      <td>11105400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5215</th>\n",
       "      <td>1999-11-03</td>\n",
       "      <td>95.87</td>\n",
       "      <td>95.9400</td>\n",
       "      <td>93.50</td>\n",
       "      <td>94.37</td>\n",
       "      <td>10369100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5214</th>\n",
       "      <td>1999-11-04</td>\n",
       "      <td>94.44</td>\n",
       "      <td>94.4400</td>\n",
       "      <td>90.00</td>\n",
       "      <td>91.56</td>\n",
       "      <td>16697600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5213</th>\n",
       "      <td>1999-11-05</td>\n",
       "      <td>92.75</td>\n",
       "      <td>92.9400</td>\n",
       "      <td>90.19</td>\n",
       "      <td>90.25</td>\n",
       "      <td>13737600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-07-22</td>\n",
       "      <td>125.90</td>\n",
       "      <td>129.4700</td>\n",
       "      <td>125.80</td>\n",
       "      <td>128.67</td>\n",
       "      <td>8195366.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-07-23</td>\n",
       "      <td>129.10</td>\n",
       "      <td>129.3700</td>\n",
       "      <td>127.15</td>\n",
       "      <td>127.33</td>\n",
       "      <td>4220136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-07-24</td>\n",
       "      <td>126.48</td>\n",
       "      <td>127.6459</td>\n",
       "      <td>125.50</td>\n",
       "      <td>125.79</td>\n",
       "      <td>3531076.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-07-27</td>\n",
       "      <td>124.86</td>\n",
       "      <td>126.3200</td>\n",
       "      <td>124.71</td>\n",
       "      <td>126.21</td>\n",
       "      <td>3733547.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-28</td>\n",
       "      <td>125.82</td>\n",
       "      <td>126.3400</td>\n",
       "      <td>124.15</td>\n",
       "      <td>124.47</td>\n",
       "      <td>4157538.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5218 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  1. open   2. high  3. low  4. close   5. volume\n",
       "5217  1999-11-01    98.50   98.8100   96.37     96.75   9551800.0\n",
       "5216  1999-11-02    96.75   96.8100   93.69     94.81  11105400.0\n",
       "5215  1999-11-03    95.87   95.9400   93.50     94.37  10369100.0\n",
       "5214  1999-11-04    94.44   94.4400   90.00     91.56  16697600.0\n",
       "5213  1999-11-05    92.75   92.9400   90.19     90.25  13737600.0\n",
       "...          ...      ...       ...     ...       ...         ...\n",
       "4     2020-07-22   125.90  129.4700  125.80    128.67   8195366.0\n",
       "3     2020-07-23   129.10  129.3700  127.15    127.33   4220136.0\n",
       "2     2020-07-24   126.48  127.6459  125.50    125.79   3531076.0\n",
       "1     2020-07-27   124.86  126.3200  124.71    126.21   3733547.0\n",
       "0     2020-07-28   125.82  126.3400  124.15    124.47   4157538.0\n",
       "\n",
       "[5218 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1. open</th>\n",
       "      <th>2. high</th>\n",
       "      <th>3. low</th>\n",
       "      <th>4. close</th>\n",
       "      <th>5. volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5217</th>\n",
       "      <td>98.50</td>\n",
       "      <td>98.8100</td>\n",
       "      <td>96.37</td>\n",
       "      <td>96.75</td>\n",
       "      <td>9551800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5216</th>\n",
       "      <td>96.75</td>\n",
       "      <td>96.8100</td>\n",
       "      <td>93.69</td>\n",
       "      <td>94.81</td>\n",
       "      <td>11105400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5215</th>\n",
       "      <td>95.87</td>\n",
       "      <td>95.9400</td>\n",
       "      <td>93.50</td>\n",
       "      <td>94.37</td>\n",
       "      <td>10369100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5214</th>\n",
       "      <td>94.44</td>\n",
       "      <td>94.4400</td>\n",
       "      <td>90.00</td>\n",
       "      <td>91.56</td>\n",
       "      <td>16697600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5213</th>\n",
       "      <td>92.75</td>\n",
       "      <td>92.9400</td>\n",
       "      <td>90.19</td>\n",
       "      <td>90.25</td>\n",
       "      <td>13737600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>125.90</td>\n",
       "      <td>129.4700</td>\n",
       "      <td>125.80</td>\n",
       "      <td>128.67</td>\n",
       "      <td>8195366.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>129.10</td>\n",
       "      <td>129.3700</td>\n",
       "      <td>127.15</td>\n",
       "      <td>127.33</td>\n",
       "      <td>4220136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>126.48</td>\n",
       "      <td>127.6459</td>\n",
       "      <td>125.50</td>\n",
       "      <td>125.79</td>\n",
       "      <td>3531076.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>124.86</td>\n",
       "      <td>126.3200</td>\n",
       "      <td>124.71</td>\n",
       "      <td>126.21</td>\n",
       "      <td>3733547.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>125.82</td>\n",
       "      <td>126.3400</td>\n",
       "      <td>124.15</td>\n",
       "      <td>124.47</td>\n",
       "      <td>4157538.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5218 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      1. open   2. high  3. low  4. close   5. volume\n",
       "5217    98.50   98.8100   96.37     96.75   9551800.0\n",
       "5216    96.75   96.8100   93.69     94.81  11105400.0\n",
       "5215    95.87   95.9400   93.50     94.37  10369100.0\n",
       "5214    94.44   94.4400   90.00     91.56  16697600.0\n",
       "5213    92.75   92.9400   90.19     90.25  13737600.0\n",
       "...       ...       ...     ...       ...         ...\n",
       "4      125.90  129.4700  125.80    128.67   8195366.0\n",
       "3      129.10  129.3700  127.15    127.33   4220136.0\n",
       "2      126.48  127.6459  125.50    125.79   3531076.0\n",
       "1      124.86  126.3200  124.71    126.21   3733547.0\n",
       "0      125.82  126.3400  124.15    124.47   4157538.0\n",
       "\n",
       "[5218 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(columns='date')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequence for the LSTM network\n",
    "backlook = 92\n",
    "\n",
    "# Days to predict\n",
    "days = 4\n",
    "\n",
    "# Size of data split for testing\n",
    "train_size = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = []\n",
    "\n",
    "for i in range(days):\n",
    "    index.append(np.arange(i,len(data),days))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_index = []\n",
    "\n",
    "for i in range(len(index[0]) - backlook):\n",
    "    for e in range(len(index)):\n",
    "        try: ordered_index.append(index[e][i:i+backlook])\n",
    "        except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise data\n",
    "normaliser = preprocessing.MinMaxScaler()\n",
    "data_norm = normaliser.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalised chunks\n",
    "historical_sequences_norm = np.array([data_norm[ix].copy() for ix in ordered_index])\n",
    "next_day_open_values_norm = np.array([data_norm[ordered_index[i+days][-1],0].copy() for i in range(len(ordered_index) - days)])\n",
    "next_day_open_values_norm = np.expand_dims(next_day_open_values_norm, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete those sequences that doesn't have a -th day in the results\n",
    "historical_sequences_norm = historical_sequences_norm[:next_day_open_values_norm.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4848, 92, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "historical_sequences_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4848, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_day_open_values_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.30081503],\n",
       "       [0.35680956],\n",
       "       [0.37143035],\n",
       "       ...,\n",
       "       [0.44328999],\n",
       "       [0.46319915],\n",
       "       [0.44689853]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Y raw data\n",
    "next_day_open_values = np.array([data.to_numpy()[ordered_index[i+days][-1],0] for i in range(len(ordered_index) - days)])\n",
    "next_day_open_values = np.expand_dims(next_day_open_values, -1)\n",
    "\n",
    "# Y normaliser\n",
    "y_normaliser = preprocessing.MinMaxScaler()\n",
    "y_normaliser.fit_transform(next_day_open_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test split\n",
    "split = int(historical_sequences_norm.shape[0] * train_size)\n",
    "\n",
    "X_train = historical_sequences_norm[:split]\n",
    "Y_train = next_day_open_values_norm[:split]\n",
    "\n",
    "X_test = historical_sequences_norm[split:]\n",
    "Y_test = next_day_open_values_norm[split:]\n",
    "unscaled_y_test = next_day_open_values[split:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm(x, y, batch_size=512, epochs=24, **params):\n",
    "    \n",
    "    # List of parameters\n",
    "    if 'lstmsize' not in params: params['lstmsize'] = x.shape[1]\n",
    "    if 'density' not in params: params['density'] = int((params['lstmsize']//1.5)*2)\n",
    "    if 'activation' not in params: params['activation'] = 'relu'\n",
    "    if 'twice' not in params: params['twice'] = False\n",
    "    if 'optimizer' not in params: params['optimizer'] = 'adam'\n",
    "    if 'shuffle' not in params: params['shuffle'] = False\n",
    "    \n",
    "    # Model definition\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(params['lstmsize'], input_shape=x.shape[1:], return_sequences=params['twice']))\n",
    "    \n",
    "    if 'dropout' in params:\n",
    "        model.add(Dropout(params['dropout']))\n",
    "    \n",
    "    if params['twice']:\n",
    "        model.add(LSTM(params['lstmsize']))\n",
    "        \n",
    "        if 'dropout' in params:\n",
    "            model.add(Dropout(params['dropout']))\n",
    "            \n",
    "    model.add(Dense(params['density'], activation=params['activation']))\n",
    "    \n",
    "    if 'full_density' in params and params['full_density']:\n",
    "        density = params['density']//2\n",
    "        while density >= 12:\n",
    "            model.add(Dense(density, activation=params['activation']))\n",
    "            density //= 2\n",
    "            \n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    \n",
    "    model.compile(loss='mse', optimizer=params['optimizer'])\n",
    "    \n",
    "    if 'callbacks' in params:\n",
    "        callback = model.fit(x=x, y=y, validation_split=0.1, batch_size=batch_size, epochs=epochs, shuffle=params['shuffle'],\n",
    "                            callbacks=params['callbacks'])\n",
    "    else:\n",
    "        callback = model.fit(x=x, y=y, validation_split=0.1, batch_size=batch_size, epochs=epochs, shuffle=params['shuffle'])\n",
    "    \n",
    "    return [model, callback, params]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evolutive algorith to search for the most optimal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_genes(x, y, population_size, population=[]):\n",
    "    if population_size-len(population) < 0:\n",
    "        print('population size must be greater or equal than actual population')\n",
    "        return\n",
    "    \n",
    "    if len(population) > 0:\n",
    "        if len(population) < 3:\n",
    "            print('population should be empty or 3 at least')\n",
    "            return\n",
    "        \n",
    "        population[2] = breed_genes(x, y, population[0][2].copy())\n",
    "        population[1] = breed_genes(x, y, combine=(population[0][2], population[1][2]))\n",
    "        population = population[:3]\n",
    "    \n",
    "    for _ in range(population_size-len(population)):\n",
    "        subject = breed_genes(x, y)\n",
    "        population.append(subject)\n",
    "        \n",
    "    return population\n",
    "\n",
    "def breed_genes(x, y, genes={}, combine=None):\n",
    "    genes['x'] = x\n",
    "    genes['y'] = y\n",
    "    \n",
    "    if type(combine) is list or type(combine) is tuple:\n",
    "        genes['lstmsize'] = combine[np.random.randint(0,2)]['lstmsize']\n",
    "        genes['density'] = combine[np.random.randint(0,2)]['density']\n",
    "        genes['activation'] = combine[np.random.randint(0,2)]['activation']\n",
    "        genes['twice'] = combine[np.random.randint(0,2)]['twice']\n",
    "        genes['optimizer'] = combine[np.random.randint(0,2)]['optimizer']\n",
    "        genes['shuffle'] = combine[np.random.randint(0,2)]['shuffle']\n",
    "        \n",
    "        genes['dropout'] = combine[np.random.randint(0,2)].get('dropout')\n",
    "        if genes['dropout'] is None: del genes['dropout']\n",
    "        genes['full_density'] = combine[np.random.randint(0,2)].get('full_density')\n",
    "        if genes['full_density'] is None: del genes['full_density']\n",
    "            \n",
    "    else:\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['lstmsize'] = int((np.random.randint(x.shape[1],x.shape[1]*2)//2)*2)\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['density'] = int((np.random.randint(x.shape[1]//2,x.shape[1]*2.66)//2)*2)\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            activation = [\n",
    "                'relu',\n",
    "                'sigmoid',\n",
    "                'softplus',\n",
    "                'softsign',\n",
    "                'tanh',\n",
    "                'selu',\n",
    "                'elu',\n",
    "                'exponential'\n",
    "            ]\n",
    "            genes['activation'] = activation[np.random.randint(0,8)]\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['twice'] = True\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            optimizer = [\n",
    "                'sgd',\n",
    "                'rmsprop',\n",
    "                'adam',\n",
    "                'adadelta',\n",
    "                'adagrad',\n",
    "                'adamax',\n",
    "                'nadam'\n",
    "            ]\n",
    "            genes['optimizer'] = optimizer[np.random.randint(0,7)]\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['shuffle'] = True\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['dropout'] = np.random.randint(1,4)/10\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['full_density'] = True\n",
    "            \n",
    "    new_model = build_lstm(**genes)\n",
    "        \n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def breed_population(x, y, generations, population_size, population=[]):\n",
    "    \n",
    "    if generations > 1 and population_size < 3:\n",
    "        print('population size should be of a minimum of 3 for more than one generation')\n",
    "        return\n",
    "    \n",
    "    for g in range(generations):\n",
    "        print(f'\\nGENERATION {g}\\n')\n",
    "        population = set_genes(x, y, population_size, population)\n",
    "        population = sorted(population, key=lambda x: x[1].history['val_loss'][-1]+x[1].history['loss'][-1])\n",
    "        \n",
    "    return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GENERATION 0\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 1s 290us/step - loss: 0.0283 - val_loss: 0.0289\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 151us/step - loss: 0.0151 - val_loss: 0.0040\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 151us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 151us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 149us/step - loss: 0.0027 - val_loss: 0.0013\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 150us/step - loss: 0.0045 - val_loss: 0.0013\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 153us/step - loss: 0.0094 - val_loss: 0.0037\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 150us/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 150us/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 153us/step - loss: 9.6633e-04 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 151us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 153us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 156us/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 151us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 150us/step - loss: 8.9690e-04 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 150us/step - loss: 9.0318e-04 - val_loss: 0.0010\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 150us/step - loss: 8.4782e-04 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 151us/step - loss: 8.7008e-04 - val_loss: 0.0010\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 154us/step - loss: 8.3262e-04 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 159us/step - loss: 8.5603e-04 - val_loss: 0.0010\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 158us/step - loss: 8.1974e-04 - val_loss: 0.0010\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 156us/step - loss: 8.6085e-04 - val_loss: 0.0010\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 156us/step - loss: 8.2207e-04 - val_loss: 0.0010\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 154us/step - loss: 9.2565e-04 - val_loss: 9.9721e-04\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 2s 474us/step - loss: 0.1272 - val_loss: 0.0086\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 303us/step - loss: 0.0944 - val_loss: 0.0080\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 297us/step - loss: 0.0911 - val_loss: 0.0078\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 295us/step - loss: 0.0891 - val_loss: 0.0077\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 297us/step - loss: 0.0871 - val_loss: 0.0076\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 297us/step - loss: 0.0852 - val_loss: 0.0075\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 297us/step - loss: 0.0832 - val_loss: 0.0075\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 296us/step - loss: 0.0813 - val_loss: 0.0074\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 295us/step - loss: 0.0795 - val_loss: 0.0073\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 296us/step - loss: 0.0776 - val_loss: 0.0072\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 297us/step - loss: 0.0758 - val_loss: 0.0071\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 299us/step - loss: 0.0739 - val_loss: 0.0071\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 297us/step - loss: 0.0721 - val_loss: 0.0070\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 297us/step - loss: 0.0703 - val_loss: 0.0069\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 296us/step - loss: 0.0685 - val_loss: 0.0069\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 297us/step - loss: 0.0668 - val_loss: 0.0068\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 297us/step - loss: 0.0650 - val_loss: 0.0067\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 297us/step - loss: 0.0632 - val_loss: 0.0067\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 296us/step - loss: 0.0615 - val_loss: 0.0066\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 295us/step - loss: 0.0598 - val_loss: 0.0066\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 299us/step - loss: 0.0580 - val_loss: 0.0065\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 299us/step - loss: 0.0563 - val_loss: 0.0065\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 297us/step - loss: 0.0546 - val_loss: 0.0064\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 296us/step - loss: 0.0529 - val_loss: 0.0064\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 2s 496us/step - loss: 0.0824 - val_loss: 0.0104\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 313us/step - loss: 0.0297 - val_loss: 0.0112\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 311us/step - loss: 0.0301 - val_loss: 0.0053\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 311us/step - loss: 0.0217 - val_loss: 0.0074\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 310us/step - loss: 0.0165 - val_loss: 0.0108\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 311us/step - loss: 0.0157 - val_loss: 0.0090\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 311us/step - loss: 0.0167 - val_loss: 0.0097\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 311us/step - loss: 0.0158 - val_loss: 0.0057\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 311us/step - loss: 0.0164 - val_loss: 0.0069\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 312us/step - loss: 0.0156 - val_loss: 0.0051\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 310us/step - loss: 0.0152 - val_loss: 0.0044\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 310us/step - loss: 0.0146 - val_loss: 0.0048\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 311us/step - loss: 0.0138 - val_loss: 0.0039\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 310us/step - loss: 0.0135 - val_loss: 0.0038\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 309us/step - loss: 0.0125 - val_loss: 0.0034\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 315us/step - loss: 0.0125 - val_loss: 0.0034\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 309us/step - loss: 0.0116 - val_loss: 0.0033\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 310us/step - loss: 0.0117 - val_loss: 0.0031\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 310us/step - loss: 0.0113 - val_loss: 0.0030\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 311us/step - loss: 0.0115 - val_loss: 0.0031\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 310us/step - loss: 0.0110 - val_loss: 0.0029\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 311us/step - loss: 0.0108 - val_loss: 0.0028\n",
      "Epoch 23/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3490/3490 [==============================] - 1s 315us/step - loss: 0.0108 - val_loss: 0.0028\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 313us/step - loss: 0.0109 - val_loss: 0.0028\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 2s 508us/step - loss: 0.0860 - val_loss: 0.0565\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 310us/step - loss: 0.0565 - val_loss: 0.0054\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 310us/step - loss: 0.0068 - val_loss: 0.0086\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 311us/step - loss: 0.0058 - val_loss: 0.0110\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 314us/step - loss: 0.0159 - val_loss: 0.0187\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 311us/step - loss: 0.0088 - val_loss: 0.0227\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 310us/step - loss: 0.0124 - val_loss: 0.0053\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 311us/step - loss: 0.0105 - val_loss: 0.0402\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 310us/step - loss: 0.0115 - val_loss: 0.0047\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 310us/step - loss: 0.0099 - val_loss: 0.0332\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 310us/step - loss: 0.0097 - val_loss: 0.0050\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 310us/step - loss: 0.0092 - val_loss: 0.0213\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 312us/step - loss: 0.0084 - val_loss: 0.0097\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 311us/step - loss: 0.0090 - val_loss: 0.0208\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 311us/step - loss: 0.0089 - val_loss: 0.0037\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 309us/step - loss: 0.0086 - val_loss: 0.0150\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 311us/step - loss: 0.0073 - val_loss: 0.0090\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 313us/step - loss: 0.0082 - val_loss: 0.0136\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 310us/step - loss: 0.0058 - val_loss: 0.0118\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 313us/step - loss: 0.0089 - val_loss: 0.0160\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 310us/step - loss: 0.0061 - val_loss: 0.0120\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 311us/step - loss: 0.0078 - val_loss: 0.0146\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 310us/step - loss: 0.0065 - val_loss: 0.0057\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 309us/step - loss: 0.0064 - val_loss: 0.0130\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 2s 527us/step - loss: 0.0851 - val_loss: 0.0034\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 312us/step - loss: 0.0055 - val_loss: 0.0032\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 309us/step - loss: 0.0201 - val_loss: 0.0030\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 310us/step - loss: 0.0049 - val_loss: 0.0163\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 311us/step - loss: 0.0152 - val_loss: 0.0043\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 309us/step - loss: 0.0111 - val_loss: 0.0110\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 311us/step - loss: 0.0077 - val_loss: 0.0122\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 313us/step - loss: 0.0088 - val_loss: 0.0084\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 313us/step - loss: 0.0088 - val_loss: 0.0119\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 312us/step - loss: 0.0096 - val_loss: 0.0100\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 312us/step - loss: 0.0089 - val_loss: 0.0071\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 311us/step - loss: 0.0063 - val_loss: 0.0062\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 311us/step - loss: 0.0083 - val_loss: 0.0094\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 311us/step - loss: 0.0069 - val_loss: 0.0065\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 310us/step - loss: 0.0067 - val_loss: 0.0063\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 310us/step - loss: 0.0068 - val_loss: 0.0083\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 310us/step - loss: 0.0058 - val_loss: 0.0027\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 313us/step - loss: 0.0061 - val_loss: 0.0130\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 312us/step - loss: 0.0072 - val_loss: 0.0020\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 310us/step - loss: 0.0037 - val_loss: 0.0156\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 309us/step - loss: 0.0073 - val_loss: 0.0018\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 310us/step - loss: 0.0043 - val_loss: 0.0077\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 315us/step - loss: 0.0065 - val_loss: 0.0022\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 311us/step - loss: 0.0041 - val_loss: 0.0093\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 2s 553us/step - loss: 0.1155 - val_loss: 0.0027\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 310us/step - loss: 0.0058 - val_loss: 0.0031\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 310us/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 311us/step - loss: 0.0113 - val_loss: 0.0074\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 312us/step - loss: 0.0077 - val_loss: 0.0261\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 312us/step - loss: 0.0123 - val_loss: 0.0030\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 310us/step - loss: 0.0109 - val_loss: 0.0091\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 311us/step - loss: 0.0062 - val_loss: 0.0128\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 314us/step - loss: 0.0100 - val_loss: 0.0131\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 311us/step - loss: 0.0080 - val_loss: 0.0116\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 315us/step - loss: 0.0090 - val_loss: 0.0056\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 315us/step - loss: 0.0073 - val_loss: 0.0104\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 311us/step - loss: 0.0071 - val_loss: 0.0085\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 313us/step - loss: 0.0070 - val_loss: 0.0059\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 312us/step - loss: 0.0067 - val_loss: 0.0083\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 313us/step - loss: 0.0064 - val_loss: 0.0036\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 310us/step - loss: 0.0054 - val_loss: 0.0141\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 310us/step - loss: 0.0074 - val_loss: 0.0019\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 311us/step - loss: 0.0032 - val_loss: 0.0117\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 311us/step - loss: 0.0080 - val_loss: 0.0023\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 311us/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 311us/step - loss: 0.0057 - val_loss: 0.0072\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 310us/step - loss: 0.0054 - val_loss: 0.0038\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 311us/step - loss: 0.0048 - val_loss: 0.0053\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 3s 840us/step - loss: 0.0911 - val_loss: 0.0076\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 548us/step - loss: 0.0105 - val_loss: 0.0047\n",
      "Epoch 3/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3490/3490 [==============================] - 2s 548us/step - loss: 0.0078 - val_loss: 0.0114\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 548us/step - loss: 0.0052 - val_loss: 0.0026\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 549us/step - loss: 0.0039 - val_loss: 0.0064\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 547us/step - loss: 0.0033 - val_loss: 0.0023\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 547us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 550us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 548us/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 547us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 549us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 549us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 547us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 547us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 549us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 556us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 552us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 547us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 547us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 548us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 549us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 547us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 548us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 552us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 3s 854us/step - loss: 0.0569 - val_loss: 0.0031\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 548us/step - loss: 0.0081 - val_loss: 0.0073\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 550us/step - loss: 0.0057 - val_loss: 0.0022\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 548us/step - loss: 0.0039 - val_loss: 0.0064\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 549us/step - loss: 0.0033 - val_loss: 0.0019\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 551us/step - loss: 0.0027 - val_loss: 0.0020\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 552us/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 552us/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 548us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 548us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 547us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 548us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 546us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 548us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 547us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 550us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 547us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 549us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 547us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 546us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 545us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 553us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 548us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 551us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 3s 729us/step - loss: 0.0713 - val_loss: 0.0146\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 399us/step - loss: 0.0107 - val_loss: 0.0030\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 398us/step - loss: 0.0065 - val_loss: 0.0034\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 396us/step - loss: 0.0045 - val_loss: 0.0021\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 398us/step - loss: 0.0040 - val_loss: 0.0048\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 399us/step - loss: 0.0035 - val_loss: 0.0020\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 399us/step - loss: 0.0030 - val_loss: 0.0043\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 398us/step - loss: 0.0028 - val_loss: 0.0020\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 401us/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 398us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 398us/step - loss: 0.0026 - val_loss: 0.0021\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 398us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 403us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 398us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 400us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 401us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 398us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 399us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 398us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 400us/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 399us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 400us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 397us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 400us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 3s 727us/step - loss: 0.0650 - val_loss: 0.0337\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 389us/step - loss: 0.0123 - val_loss: 0.0077\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 388us/step - loss: 0.0057 - val_loss: 0.0026\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 389us/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 388us/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 391us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 388us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 8/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3490/3490 [==============================] - 1s 387us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 389us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 388us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 394us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 388us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 388us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 389us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 390us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 389us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 392us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 391us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 389us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 388us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 388us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 390us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 390us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 389us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "\n",
      "GENERATION 1\n",
      "\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 2s 714us/step - loss: 0.0682 - val_loss: 0.0153\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 387us/step - loss: 0.0120 - val_loss: 0.0196\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 391us/step - loss: 0.0058 - val_loss: 0.0049\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 387us/step - loss: 0.0036 - val_loss: 0.0065\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 386us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 386us/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 391us/step - loss: 0.0019 - val_loss: 0.0032\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 386us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 386us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 386us/step - loss: 0.0017 - val_loss: 0.0026\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 388us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 385us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 388us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 388us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 388us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 386us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 386us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 388us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 386us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 387us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 386us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 390us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 386us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 387us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 2s 694us/step - loss: 0.0919 - val_loss: 0.0079\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 316us/step - loss: 0.0188 - val_loss: 0.0063\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 319us/step - loss: 0.0082 - val_loss: 0.0025\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 314us/step - loss: 0.0051 - val_loss: 0.0036\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 314us/step - loss: 0.0037 - val_loss: 0.0049\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 315us/step - loss: 0.0032 - val_loss: 0.0028\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 315us/step - loss: 0.0027 - val_loss: 0.0042\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 313us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 314us/step - loss: 0.0024 - val_loss: 0.0036\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 315us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 315us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 314us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 315us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 319us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 316us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 315us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 313us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 314us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 314us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 314us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 315us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 316us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 315us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 313us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 3s 870us/step - loss: 0.0842 - val_loss: 0.0555\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 458us/step - loss: 0.0214 - val_loss: 0.0206\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 456us/step - loss: 0.0095 - val_loss: 0.0053\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 456us/step - loss: 0.0062 - val_loss: 0.0076\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 459us/step - loss: 0.0041 - val_loss: 0.0022\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 458us/step - loss: 0.0035 - val_loss: 0.0034\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 459us/step - loss: 0.0031 - val_loss: 0.0025\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 456us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 456us/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 459us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 458us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 456us/step - loss: 0.0025 - val_loss: 0.0025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 456us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 459us/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 458us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 458us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 457us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 457us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 457us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 462us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 460us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 456us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 456us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 458us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 3s 755us/step - loss: 0.0828 - val_loss: 0.0171\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 325us/step - loss: 0.0162 - val_loss: 0.0034\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 320us/step - loss: 0.0090 - val_loss: 0.0084\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 320us/step - loss: 0.0069 - val_loss: 0.0026\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 323us/step - loss: 0.0050 - val_loss: 0.0045\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 321us/step - loss: 0.0043 - val_loss: 0.0025\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 321us/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 320us/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 321us/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 321us/step - loss: 0.0034 - val_loss: 0.0025\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 320us/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 321us/step - loss: 0.0030 - val_loss: 0.0024\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 319us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 320us/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 321us/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 320us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 324us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 320us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 322us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 321us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 320us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 319us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 321us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 319us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 3s 751us/step - loss: 0.4489 - val_loss: 0.0129\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 320us/step - loss: 0.0261 - val_loss: 0.0029\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 319us/step - loss: 0.0140 - val_loss: 0.0027\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 322us/step - loss: 0.0095 - val_loss: 0.0039\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 328us/step - loss: 0.0077 - val_loss: 0.0052\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 324us/step - loss: 0.0075 - val_loss: 0.0052\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 320us/step - loss: 0.0067 - val_loss: 0.0048\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 319us/step - loss: 0.0068 - val_loss: 0.0052\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 318us/step - loss: 0.0066 - val_loss: 0.0053\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 318us/step - loss: 0.0064 - val_loss: 0.0046\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 318us/step - loss: 0.0063 - val_loss: 0.0046\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 319us/step - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 320us/step - loss: 0.0058 - val_loss: 0.0047\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 318us/step - loss: 0.0058 - val_loss: 0.0045\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 319us/step - loss: 0.0055 - val_loss: 0.0045\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 323us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 322us/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 319us/step - loss: 0.0053 - val_loss: 0.0048\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 319us/step - loss: 0.0052 - val_loss: 0.0048\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 324us/step - loss: 0.0051 - val_loss: 0.0044\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 319us/step - loss: 0.0052 - val_loss: 0.0042\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 318us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 321us/step - loss: 0.0049 - val_loss: 0.0043\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 319us/step - loss: 0.0050 - val_loss: 0.0041\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 3s 748us/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 319us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 321us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 318us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 317us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 320us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 319us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 318us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 318us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 318us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 318us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 317us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 318us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 319us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 319us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 322us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 319us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 318us/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 318us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 317us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 323us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 318us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 319us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 318us/step - loss: nan - val_loss: nan\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 3s 774us/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 319us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 320us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 319us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 318us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 318us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 320us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 320us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 318us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 317us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 318us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 319us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 320us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 323us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 322us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 319us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 319us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 319us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 319us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 318us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 320us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 322us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 319us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 318us/step - loss: nan - val_loss: nan\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 3s 791us/step - loss: 0.1094 - val_loss: 0.0160\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 321us/step - loss: 0.0462 - val_loss: 0.0108\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 319us/step - loss: 0.0322 - val_loss: 0.0078\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 317us/step - loss: 0.0239 - val_loss: 0.0053\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 321us/step - loss: 0.0173 - val_loss: 0.0041\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 320us/step - loss: 0.0131 - val_loss: 0.0033\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 318us/step - loss: 0.0106 - val_loss: 0.0031\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 323us/step - loss: 0.0086 - val_loss: 0.0032\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 319us/step - loss: 0.0078 - val_loss: 0.0035\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 319us/step - loss: 0.0068 - val_loss: 0.0037\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 318us/step - loss: 0.0068 - val_loss: 0.0037\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 317us/step - loss: 0.0065 - val_loss: 0.0041\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 322us/step - loss: 0.0062 - val_loss: 0.0043\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 321us/step - loss: 0.0060 - val_loss: 0.0041\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 319us/step - loss: 0.0061 - val_loss: 0.0043\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 318us/step - loss: 0.0058 - val_loss: 0.0045\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 319us/step - loss: 0.0060 - val_loss: 0.0051\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 319us/step - loss: 0.0058 - val_loss: 0.0045\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 319us/step - loss: 0.0056 - val_loss: 0.0041\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 319us/step - loss: 0.0055 - val_loss: 0.0041\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 319us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 321us/step - loss: 0.0056 - val_loss: 0.0042\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 320us/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 319us/step - loss: 0.0055 - val_loss: 0.0044\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 3s 814us/step - loss: 0.0675 - val_loss: 0.0139\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 319us/step - loss: 0.0290 - val_loss: 0.0094\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 320us/step - loss: 0.0235 - val_loss: 0.0071\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 319us/step - loss: 0.0187 - val_loss: 0.0059\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 318us/step - loss: 0.0149 - val_loss: 0.0044\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 318us/step - loss: 0.0116 - val_loss: 0.0038\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 320us/step - loss: 0.0096 - val_loss: 0.0032\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 327us/step - loss: 0.0077 - val_loss: 0.0029\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 321us/step - loss: 0.0064 - val_loss: 0.0027\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 319us/step - loss: 0.0056 - val_loss: 0.0027\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 320us/step - loss: 0.0049 - val_loss: 0.0027\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 324us/step - loss: 0.0045 - val_loss: 0.0027\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 319us/step - loss: 0.0040 - val_loss: 0.0028\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 318us/step - loss: 0.0039 - val_loss: 0.0029\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 320us/step - loss: 0.0037 - val_loss: 0.0030\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 319us/step - loss: 0.0036 - val_loss: 0.0031\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 319us/step - loss: 0.0036 - val_loss: 0.0032\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 321us/step - loss: 0.0035 - val_loss: 0.0033\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 320us/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 321us/step - loss: 0.0035 - val_loss: 0.0033\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 319us/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 319us/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 321us/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 319us/step - loss: 0.0034 - val_loss: 0.0035\n",
      "\n",
      "GENERATION 2\n",
      "\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3490/3490 [==============================] - 3s 829us/step - loss: 0.0197 - val_loss: 0.0146\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 313us/step - loss: 0.0333 - val_loss: 0.0032\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 313us/step - loss: 0.0212 - val_loss: 0.0051\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 314us/step - loss: 0.0518 - val_loss: 0.0259\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 315us/step - loss: 0.0073 - val_loss: 0.0072\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 313us/step - loss: 0.0137 - val_loss: 0.0039\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 313us/step - loss: 0.0068 - val_loss: 0.0052\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 315us/step - loss: 0.0094 - val_loss: 0.0037\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 316us/step - loss: 0.0046 - val_loss: 0.0059\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 316us/step - loss: 0.0048 - val_loss: 0.0026\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 318us/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 313us/step - loss: 0.0029 - val_loss: 0.0023\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 314us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 313us/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 315us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 313us/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 313us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 313us/step - loss: 0.0032 - val_loss: 0.0023\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 313us/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 314us/step - loss: 0.0063 - val_loss: 0.0021\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 314us/step - loss: 0.0067 - val_loss: 0.0021\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 314us/step - loss: 0.0169 - val_loss: 0.0060\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 315us/step - loss: 0.0086 - val_loss: 0.0046\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 313us/step - loss: 0.0144 - val_loss: 0.0077\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 3s 821us/step - loss: 0.0866 - val_loss: 0.0050\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 300us/step - loss: 0.0127 - val_loss: 0.0041\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 301us/step - loss: 0.0060 - val_loss: 0.0036\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 301us/step - loss: 0.0041 - val_loss: 0.0066\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 302us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 301us/step - loss: 0.0025 - val_loss: 0.0046\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 301us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 302us/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 307us/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 309us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 300us/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 302us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 302us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 301us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 300us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 301us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 299us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 301us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 302us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 299us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 299us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 301us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 300us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 300us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 4s 1ms/step - loss: 0.0844 - val_loss: 0.0541\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 526us/step - loss: 0.0196 - val_loss: 0.0194\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 524us/step - loss: 0.0086 - val_loss: 0.0082\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 524us/step - loss: 0.0054 - val_loss: 0.0060\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 530us/step - loss: 0.0040 - val_loss: 0.0025\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 526us/step - loss: 0.0033 - val_loss: 0.0027\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 527us/step - loss: 0.0031 - val_loss: 0.0023\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 526us/step - loss: 0.0027 - val_loss: 0.0022\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 525us/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 524us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 526us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 528us/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 525us/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 527us/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 526us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 528us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 525us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 529us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 526us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 524us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 525us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 530us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 528us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 528us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 3s 959us/step - loss: 0.2370 - val_loss: 0.0428\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 322us/step - loss: 0.0392 - val_loss: 0.0241\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 323us/step - loss: 0.0182 - val_loss: 0.0076\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 322us/step - loss: 0.0066 - val_loss: 0.0062\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 323us/step - loss: 0.0073 - val_loss: 0.0148\n",
      "Epoch 6/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3490/3490 [==============================] - 1s 322us/step - loss: 0.0091 - val_loss: 0.0104\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 321us/step - loss: 0.0077 - val_loss: 0.0105\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 326us/step - loss: 0.0064 - val_loss: 0.0045\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 322us/step - loss: 0.0058 - val_loss: 0.0106\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 323us/step - loss: 0.0070 - val_loss: 0.0043\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 322us/step - loss: 0.0050 - val_loss: 0.0178\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 322us/step - loss: 0.0083 - val_loss: 0.0042\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 321us/step - loss: 0.0036 - val_loss: 0.0041\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 322us/step - loss: 0.0062 - val_loss: 0.0065\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 322us/step - loss: 0.0066 - val_loss: 0.0067\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 323us/step - loss: 0.0046 - val_loss: 0.0033\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 328us/step - loss: 0.0038 - val_loss: 0.0131\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 323us/step - loss: 0.0058 - val_loss: 0.0034\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 322us/step - loss: 0.0055 - val_loss: 0.0081\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 322us/step - loss: 0.0045 - val_loss: 0.0026\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 322us/step - loss: 0.0045 - val_loss: 0.0078\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 325us/step - loss: 0.0036 - val_loss: 0.0022\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 323us/step - loss: 0.0030 - val_loss: 0.0078\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 322us/step - loss: 0.0044 - val_loss: 0.0033\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 3s 905us/step - loss: 0.1569 - val_loss: 0.1278\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 319us/step - loss: 0.0920 - val_loss: 0.0707\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 320us/step - loss: 0.0767 - val_loss: 0.0498\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 319us/step - loss: 0.0731 - val_loss: 0.0410\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 320us/step - loss: 0.0722 - val_loss: 0.0367\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 320us/step - loss: 0.0721 - val_loss: 0.0350\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 323us/step - loss: 0.0720 - val_loss: 0.0342\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 324us/step - loss: 0.0720 - val_loss: 0.0342\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 321us/step - loss: 0.0720 - val_loss: 0.0337\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 321us/step - loss: 0.0720 - val_loss: 0.0336\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 320us/step - loss: 0.0720 - val_loss: 0.0335\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 319us/step - loss: 0.0720 - val_loss: 0.0334\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 319us/step - loss: 0.0720 - val_loss: 0.0334\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 322us/step - loss: 0.0720 - val_loss: 0.0334\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 323us/step - loss: 0.0720 - val_loss: 0.0340\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 321us/step - loss: 0.0720 - val_loss: 0.0334\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 319us/step - loss: 0.0720 - val_loss: 0.0335\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 321us/step - loss: 0.0720 - val_loss: 0.0336\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 320us/step - loss: 0.0720 - val_loss: 0.0335\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 319us/step - loss: 0.0720 - val_loss: 0.0334\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 321us/step - loss: 0.0720 - val_loss: 0.0334\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 324us/step - loss: 0.0720 - val_loss: 0.0334\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 321us/step - loss: 0.0720 - val_loss: 0.0334\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 321us/step - loss: 0.0720 - val_loss: 0.0335\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 3s 943us/step - loss: 0.3305 - val_loss: 0.1870\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 321us/step - loss: 0.1058 - val_loss: 0.0730\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 320us/step - loss: 0.0763 - val_loss: 0.0455\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 320us/step - loss: 0.0725 - val_loss: 0.0377\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 320us/step - loss: 0.0720 - val_loss: 0.0346\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 323us/step - loss: 0.0720 - val_loss: 0.0335\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 325us/step - loss: 0.0720 - val_loss: 0.0337\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 319us/step - loss: 0.0720 - val_loss: 0.0340\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 320us/step - loss: 0.0720 - val_loss: 0.0338\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 319us/step - loss: 0.0720 - val_loss: 0.0334\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 323us/step - loss: 0.0720 - val_loss: 0.0332\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 324us/step - loss: 0.0720 - val_loss: 0.0334\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 321us/step - loss: 0.0720 - val_loss: 0.0337\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 320us/step - loss: 0.0720 - val_loss: 0.0337\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 321us/step - loss: 0.0720 - val_loss: 0.0334\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 319us/step - loss: 0.0720 - val_loss: 0.0333\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 319us/step - loss: 0.0720 - val_loss: 0.0331\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 320us/step - loss: 0.0720 - val_loss: 0.0333\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 321us/step - loss: 0.0720 - val_loss: 0.0332\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 321us/step - loss: 0.0720 - val_loss: 0.0333\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 325us/step - loss: 0.0720 - val_loss: 0.0337\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 320us/step - loss: 0.0720 - val_loss: 0.0338\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 320us/step - loss: 0.0720 - val_loss: 0.0332\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 321us/step - loss: 0.0720 - val_loss: 0.0338\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 3s 951us/step - loss: 0.3874 - val_loss: 0.1860\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 323us/step - loss: 0.1033 - val_loss: 0.0672\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 323us/step - loss: 0.0752 - val_loss: 0.0427\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 322us/step - loss: 0.0723 - val_loss: 0.0363\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 321us/step - loss: 0.0721 - val_loss: 0.0342\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 327us/step - loss: 0.0720 - val_loss: 0.0333\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 322us/step - loss: 0.0720 - val_loss: 0.0334\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 323us/step - loss: 0.0720 - val_loss: 0.0333\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 329us/step - loss: 0.0720 - val_loss: 0.0335\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 326us/step - loss: 0.0720 - val_loss: 0.0336\n",
      "Epoch 11/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3490/3490 [==============================] - 1s 322us/step - loss: 0.0720 - val_loss: 0.0335\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 321us/step - loss: 0.0720 - val_loss: 0.0328\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 323us/step - loss: 0.0721 - val_loss: 0.0338\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 321us/step - loss: 0.0720 - val_loss: 0.0337\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 322us/step - loss: 0.0720 - val_loss: 0.0335\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 323us/step - loss: 0.0720 - val_loss: 0.0339\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 321us/step - loss: 0.0720 - val_loss: 0.0338\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 322us/step - loss: 0.0720 - val_loss: 0.0330\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 322us/step - loss: 0.0720 - val_loss: 0.0337\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 327us/step - loss: 0.0720 - val_loss: 0.0332\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 324us/step - loss: 0.0720 - val_loss: 0.0334\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 322us/step - loss: 0.0721 - val_loss: 0.0336\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 322us/step - loss: 0.0720 - val_loss: 0.0332\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 322us/step - loss: 0.0720 - val_loss: 0.0333\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 4s 1ms/step - loss: 0.7903 - val_loss: 0.3091\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 547us/step - loss: 0.1409 - val_loss: 0.0876\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 552us/step - loss: 0.0786 - val_loss: 0.0474\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 551us/step - loss: 0.0726 - val_loss: 0.0378\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 548us/step - loss: 0.0719 - val_loss: 0.0345\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 550us/step - loss: 0.0719 - val_loss: 0.0338\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 551us/step - loss: 0.0719 - val_loss: 0.0340\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 548us/step - loss: 0.0719 - val_loss: 0.0333\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 550us/step - loss: 0.0719 - val_loss: 0.0332\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 549us/step - loss: 0.0719 - val_loss: 0.0341\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 548us/step - loss: 0.0719 - val_loss: 0.0336\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 549us/step - loss: 0.0719 - val_loss: 0.0336\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 548us/step - loss: 0.0719 - val_loss: 0.0333\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 548us/step - loss: 0.0719 - val_loss: 0.0333\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 548us/step - loss: 0.0719 - val_loss: 0.0336\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 550us/step - loss: 0.0719 - val_loss: 0.0339\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 552us/step - loss: 0.0719 - val_loss: 0.0327\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 550us/step - loss: 0.0719 - val_loss: 0.0337\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 547us/step - loss: 0.0719 - val_loss: 0.0337\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 558us/step - loss: 0.0719 - val_loss: 0.0340\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 548us/step - loss: 0.0718 - val_loss: 0.0335\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 550us/step - loss: 0.0719 - val_loss: 0.0331\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 552us/step - loss: 0.0718 - val_loss: 0.0333\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 551us/step - loss: 0.0719 - val_loss: 0.0331\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 4s 1ms/step - loss: 2.5333 - val_loss: 0.0062\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 548us/step - loss: 0.0110 - val_loss: 0.0060\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 547us/step - loss: 0.0090 - val_loss: 0.0058\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 546us/step - loss: 0.0082 - val_loss: 0.0059\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 548us/step - loss: 0.0075 - val_loss: 0.0059\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 548us/step - loss: 0.0071 - val_loss: 0.0056\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 547us/step - loss: 0.0070 - val_loss: 0.0056\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 549us/step - loss: 0.0066 - val_loss: 0.0052\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 549us/step - loss: 0.0061 - val_loss: 0.0053\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 549us/step - loss: 0.0059 - val_loss: 0.0051\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 548us/step - loss: 0.0058 - val_loss: 0.0048\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 548us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 549us/step - loss: 0.0056 - val_loss: 0.0045\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 547us/step - loss: 0.0054 - val_loss: 0.0049\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 546us/step - loss: 0.0053 - val_loss: 0.0044\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 549us/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 550us/step - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 549us/step - loss: 0.0049 - val_loss: 0.0044\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 548us/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 544us/step - loss: 0.0046 - val_loss: 0.0041\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 548us/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 548us/step - loss: 0.0045 - val_loss: 0.0038\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 547us/step - loss: 0.0044 - val_loss: 0.0039\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 550us/step - loss: 0.0044 - val_loss: 0.0038\n",
      "\n",
      "GENERATION 3\n",
      "\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 4s 1ms/step - loss: 0.0858 - val_loss: 0.0060\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 388us/step - loss: 0.0120 - val_loss: 0.0118\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 386us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 386us/step - loss: 0.0033 - val_loss: 0.0068\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 390us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 388us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 386us/step - loss: 0.0019 - val_loss: 0.0031\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 386us/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 390us/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 386us/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 386us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 386us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 386us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 386us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 387us/step - loss: 0.0014 - val_loss: 0.0018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 390us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 388us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 388us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 387us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 386us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 401us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 386us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 388us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 389us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 3s 796us/step - loss: 0.1037 - val_loss: 0.0467\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 150us/step - loss: 0.0139 - val_loss: 0.0112\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 151us/step - loss: 0.0071 - val_loss: 0.0014\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 151us/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 149us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 151us/step - loss: 0.0012 - val_loss: 0.0024\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 150us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 150us/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 152us/step - loss: 9.1325e-04 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 154us/step - loss: 8.8450e-04 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 150us/step - loss: 8.6175e-04 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 150us/step - loss: 8.4591e-04 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 151us/step - loss: 8.3371e-04 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 150us/step - loss: 8.2165e-04 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 151us/step - loss: 8.0702e-04 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 151us/step - loss: 7.9097e-04 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 151us/step - loss: 7.8462e-04 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 151us/step - loss: 7.6483e-04 - val_loss: 0.0010\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 151us/step - loss: 7.4974e-04 - val_loss: 9.9631e-04\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 149us/step - loss: 7.3534e-04 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 150us/step - loss: 7.2177e-04 - val_loss: 0.0010\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 150us/step - loss: 7.0626e-04 - val_loss: 9.2918e-04\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 150us/step - loss: 6.8568e-04 - val_loss: 9.4468e-04\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 153us/step - loss: 6.7647e-04 - val_loss: 8.4121e-04\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 3s 819us/step - loss: 0.3643 - val_loss: 0.0708\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 151us/step - loss: 0.0875 - val_loss: 0.0062\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 150us/step - loss: 0.0291 - val_loss: 0.0387\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 153us/step - loss: 0.0337 - val_loss: 0.0140\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 152us/step - loss: 0.0200 - val_loss: 0.0024\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 152us/step - loss: 0.0133 - val_loss: 0.0018\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 151us/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 150us/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 149us/step - loss: 0.0029 - val_loss: 0.0025\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 150us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 151us/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 150us/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 152us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 149us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 150us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 151us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 151us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 150us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 149us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 151us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 149us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 152us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 152us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 150us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 5s 1ms/step - loss: 0.1481 - val_loss: 0.0924\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 534us/step - loss: 0.0763 - val_loss: 0.0219\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 529us/step - loss: 0.0770 - val_loss: 0.0124\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 532us/step - loss: 0.0773 - val_loss: 0.0203\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 530us/step - loss: 0.0724 - val_loss: 0.0361\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 532us/step - loss: 0.0717 - val_loss: 0.0424\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 531us/step - loss: 0.0706 - val_loss: 0.0378\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 533us/step - loss: 0.0674 - val_loss: 0.0282\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 532us/step - loss: 0.0640 - val_loss: 0.0208\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 530us/step - loss: 0.0603 - val_loss: 0.0151\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 531us/step - loss: 0.0559 - val_loss: 0.0117\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 529us/step - loss: 0.0518 - val_loss: 0.0080\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 532us/step - loss: 0.0475 - val_loss: 0.0114\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 532us/step - loss: 0.0439 - val_loss: 0.0189\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 530us/step - loss: 0.0426 - val_loss: 0.0325\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 534us/step - loss: 0.0414 - val_loss: 0.0415\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 532us/step - loss: 0.0405 - val_loss: 0.0500\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 534us/step - loss: 0.0401 - val_loss: 0.0569\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 532us/step - loss: 0.0400 - val_loss: 0.0614\n",
      "Epoch 20/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3490/3490 [==============================] - 2s 533us/step - loss: 0.0400 - val_loss: 0.0642\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 533us/step - loss: 0.0401 - val_loss: 0.0655\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 531us/step - loss: 0.0400 - val_loss: 0.0654\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 532us/step - loss: 0.0401 - val_loss: 0.0652\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 530us/step - loss: 0.0400 - val_loss: 0.0649\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 5s 1ms/step - loss: 0.2071 - val_loss: 0.0069\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 531us/step - loss: 0.0837 - val_loss: 0.0447\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 529us/step - loss: 0.0781 - val_loss: 0.0791\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 530us/step - loss: 0.0810 - val_loss: 0.0601\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 533us/step - loss: 0.0740 - val_loss: 0.0338\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 533us/step - loss: 0.0721 - val_loss: 0.0245\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 532us/step - loss: 0.0729 - val_loss: 0.0265\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 531us/step - loss: 0.0721 - val_loss: 0.0325\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 530us/step - loss: 0.0721 - val_loss: 0.0380\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 532us/step - loss: 0.0721 - val_loss: 0.0355\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 531us/step - loss: 0.0719 - val_loss: 0.0326\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 529us/step - loss: 0.0718 - val_loss: 0.0320\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 530us/step - loss: 0.0715 - val_loss: 0.0322\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 532us/step - loss: 0.0716 - val_loss: 0.0352\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 532us/step - loss: 0.0720 - val_loss: 0.0334\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 534us/step - loss: 0.0719 - val_loss: 0.0324\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 535us/step - loss: 0.0712 - val_loss: 0.0346\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 532us/step - loss: 0.0694 - val_loss: 0.0271\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 532us/step - loss: 0.0660 - val_loss: 0.0245\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 532us/step - loss: 0.0597 - val_loss: 0.0165\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 532us/step - loss: 0.0557 - val_loss: 0.0113\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 541us/step - loss: 0.0718 - val_loss: 0.0171\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 534us/step - loss: 0.0720 - val_loss: 0.0480\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 534us/step - loss: 0.0710 - val_loss: 0.0407\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 5s 1ms/step - loss: 0.7797 - val_loss: 0.1965\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 532us/step - loss: 0.2956 - val_loss: 0.0229\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 536us/step - loss: 0.1159 - val_loss: 0.0124\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 531us/step - loss: 0.0735 - val_loss: 0.0456\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 534us/step - loss: 0.0754 - val_loss: 0.0679\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 532us/step - loss: 0.0795 - val_loss: 0.0680\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 530us/step - loss: 0.0774 - val_loss: 0.0548\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 533us/step - loss: 0.0737 - val_loss: 0.0412\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 530us/step - loss: 0.0722 - val_loss: 0.0322\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 532us/step - loss: 0.0722 - val_loss: 0.0286\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 534us/step - loss: 0.0722 - val_loss: 0.0291\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 532us/step - loss: 0.0721 - val_loss: 0.0313\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 532us/step - loss: 0.0720 - val_loss: 0.0335\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 533us/step - loss: 0.0720 - val_loss: 0.0346\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 531us/step - loss: 0.0720 - val_loss: 0.0344\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 532us/step - loss: 0.0720 - val_loss: 0.0342\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 532us/step - loss: 0.0720 - val_loss: 0.0337\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 531us/step - loss: 0.0720 - val_loss: 0.0332\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 532us/step - loss: 0.0720 - val_loss: 0.0331\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 533us/step - loss: 0.0720 - val_loss: 0.0334\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 534us/step - loss: 0.0720 - val_loss: 0.0335\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 532us/step - loss: 0.0720 - val_loss: 0.0337\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 532us/step - loss: 0.0720 - val_loss: 0.0334\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 532us/step - loss: 0.0720 - val_loss: 0.0334\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 5s 1ms/step - loss: 0.0740 - val_loss: 0.0160\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 530us/step - loss: 0.0194 - val_loss: 0.0062\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 532us/step - loss: 0.0090 - val_loss: 0.0039\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 530us/step - loss: 0.0066 - val_loss: 0.0056\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 530us/step - loss: 0.0051 - val_loss: 0.0087\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 530us/step - loss: 0.0042 - val_loss: 0.0051\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 530us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 531us/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 531us/step - loss: 0.0033 - val_loss: 0.0027\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 530us/step - loss: 0.0031 - val_loss: 0.0027\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 531us/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 530us/step - loss: 0.0029 - val_loss: 0.0024\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 531us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 534us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 530us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 532us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 530us/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 530us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 530us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 532us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 533us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 530us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 530us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 531us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3490/3490 [==============================] - 5s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 533us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 533us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 530us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 534us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 534us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 533us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 532us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 531us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 532us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 533us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 534us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 535us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 532us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 532us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 531us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 535us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 531us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 530us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 533us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 532us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 533us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 537us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 534us/step - loss: nan - val_loss: nan\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 5s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 571us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 565us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 570us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 566us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 566us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 568us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 567us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 567us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 571us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 568us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 568us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 568us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 567us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 567us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 568us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 568us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 573us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 574us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 567us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 570us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 569us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 570us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 567us/step - loss: nan - val_loss: nan\n",
      "\n",
      "GENERATION 4\n",
      "\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 5s 1ms/step - loss: 0.0679 - val_loss: 0.0038\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 315us/step - loss: 0.0152 - val_loss: 0.0039\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 314us/step - loss: 0.0080 - val_loss: 0.0042\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 316us/step - loss: 0.0061 - val_loss: 0.0030\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 317us/step - loss: 0.0044 - val_loss: 0.0027\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 317us/step - loss: 0.0038 - val_loss: 0.0027\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 316us/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 316us/step - loss: 0.0032 - val_loss: 0.0023\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 316us/step - loss: 0.0030 - val_loss: 0.0026\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 327us/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 317us/step - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 316us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 316us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 315us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 315us/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 315us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 316us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 315us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 316us/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 316us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 315us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 316us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 316us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 319us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 4s 1ms/step - loss: 0.0156 - val_loss: 0.0021\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 151us/step - loss: 0.0393 - val_loss: 0.0058\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 151us/step - loss: 0.0103 - val_loss: 0.0031\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 151us/step - loss: 0.0161 - val_loss: 0.0046\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 151us/step - loss: 0.0038 - val_loss: 0.0053\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 151us/step - loss: 0.0033 - val_loss: 0.0015\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 151us/step - loss: 0.0011 - val_loss: 0.0022\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 150us/step - loss: 9.5089e-04 - val_loss: 0.0011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 151us/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 152us/step - loss: 9.2045e-04 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 155us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 151us/step - loss: 9.9967e-04 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 151us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 152us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 155us/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 150us/step - loss: 0.0024 - val_loss: 0.0013\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 151us/step - loss: 0.0043 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 151us/step - loss: 0.0041 - val_loss: 0.0020\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 151us/step - loss: 0.0063 - val_loss: 0.0022\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 151us/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 151us/step - loss: 0.0028 - val_loss: 0.0015\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 150us/step - loss: 0.0010 - val_loss: 0.0021\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 151us/step - loss: 9.1323e-04 - val_loss: 9.8429e-04\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 152us/step - loss: 8.5492e-04 - val_loss: 0.0011\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 5s 1ms/step - loss: 0.0292 - val_loss: 0.0189\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 321us/step - loss: 0.0208 - val_loss: 0.0094\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 317us/step - loss: 0.0188 - val_loss: 0.0037\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 317us/step - loss: 0.0198 - val_loss: 0.0062\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 317us/step - loss: 0.0189 - val_loss: 0.0205\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 318us/step - loss: 0.0055 - val_loss: 0.0027\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 316us/step - loss: 0.0071 - val_loss: 0.0059\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 317us/step - loss: 0.0051 - val_loss: 0.0035\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 316us/step - loss: 0.0034 - val_loss: 0.0022\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 317us/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 318us/step - loss: 0.0029 - val_loss: 0.0023\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 318us/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 322us/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 316us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 317us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 321us/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 318us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 317us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 316us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 316us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 317us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 317us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 316us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 317us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 5s 2ms/step - loss: 0.0735 - val_loss: 0.0312\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 489us/step - loss: 0.0157 - val_loss: 0.0195\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 490us/step - loss: 0.0079 - val_loss: 0.0048\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 488us/step - loss: 0.0050 - val_loss: 0.0069\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 491us/step - loss: 0.0038 - val_loss: 0.0023\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 489us/step - loss: 0.0035 - val_loss: 0.0031\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 488us/step - loss: 0.0031 - val_loss: 0.0024\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 492us/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 490us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 490us/step - loss: 0.0028 - val_loss: 0.0021\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 488us/step - loss: 0.0027 - val_loss: 0.0021\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 487us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 489us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 490us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 489us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 490us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 489us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 490us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 490us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 490us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 490us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 493us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 490us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 488us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 5s 2ms/step - loss: 0.0730 - val_loss: 0.0488\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 489us/step - loss: 0.0179 - val_loss: 0.0149\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 490us/step - loss: 0.0082 - val_loss: 0.0072\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 489us/step - loss: 0.0055 - val_loss: 0.0054\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 490us/step - loss: 0.0041 - val_loss: 0.0029\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 487us/step - loss: 0.0034 - val_loss: 0.0026\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 493us/step - loss: 0.0030 - val_loss: 0.0023\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 490us/step - loss: 0.0028 - val_loss: 0.0023\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 490us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 491us/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 490us/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 490us/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 490us/step - loss: 0.0024 - val_loss: 0.0022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 491us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 491us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 493us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 492us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 490us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 488us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 489us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 492us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 490us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 487us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 490us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 6s 2ms/step - loss: 0.0739 - val_loss: 0.0416\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 491us/step - loss: 0.0196 - val_loss: 0.0196\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 490us/step - loss: 0.0098 - val_loss: 0.0074\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 492us/step - loss: 0.0063 - val_loss: 0.0073\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 491us/step - loss: 0.0044 - val_loss: 0.0033\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 488us/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 488us/step - loss: 0.0036 - val_loss: 0.0024\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 490us/step - loss: 0.0033 - val_loss: 0.0028\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 493us/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 489us/step - loss: 0.0030 - val_loss: 0.0023\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 489us/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 491us/step - loss: 0.0027 - val_loss: 0.0021\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 490us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 492us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 492us/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 489us/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 490us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 491us/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 489us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 490us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 489us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 491us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 491us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 489us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 6s 2ms/step - loss: 0.1025 - val_loss: 0.0029\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 487us/step - loss: 0.0130 - val_loss: 0.0082\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 488us/step - loss: 0.0073 - val_loss: 0.0053\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 483us/step - loss: 0.0051 - val_loss: 0.0060\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 483us/step - loss: 0.0041 - val_loss: 0.0028\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 482us/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 481us/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 482us/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 482us/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 481us/step - loss: 0.0028 - val_loss: 0.0021\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 482us/step - loss: 0.0028 - val_loss: 0.0021\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 485us/step - loss: 0.0026 - val_loss: 0.0020\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 483us/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 483us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 483us/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 482us/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 483us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 481us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 483us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 486us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 484us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 483us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 482us/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 483us/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 6s 2ms/step - loss: 0.0894 - val_loss: 0.0436\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 483us/step - loss: 0.0166 - val_loss: 0.0174\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 484us/step - loss: 0.0078 - val_loss: 0.0066\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 484us/step - loss: 0.0052 - val_loss: 0.0047\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 482us/step - loss: 0.0040 - val_loss: 0.0022\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 482us/step - loss: 0.0034 - val_loss: 0.0026\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 480us/step - loss: 0.0031 - val_loss: 0.0020\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 487us/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 482us/step - loss: 0.0027 - val_loss: 0.0019\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 483us/step - loss: 0.0027 - val_loss: 0.0022\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 482us/step - loss: 0.0028 - val_loss: 0.0019\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 482us/step - loss: 0.0026 - val_loss: 0.0020\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 484us/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 482us/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 482us/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 482us/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 480us/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 481us/step - loss: 0.0023 - val_loss: 0.0018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 484us/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 484us/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 483us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 483us/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 484us/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 482us/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 6s 2ms/step - loss: 0.0588 - val_loss: 0.0145\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 375us/step - loss: 0.0150 - val_loss: 0.0088\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 375us/step - loss: 0.0072 - val_loss: 0.0023\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 375us/step - loss: 0.0051 - val_loss: 0.0036\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 375us/step - loss: 0.0038 - val_loss: 0.0032\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 373us/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 375us/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 376us/step - loss: 0.0031 - val_loss: 0.0025\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 376us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 378us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 374us/step - loss: 0.0029 - val_loss: 0.0023\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 376us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 375us/step - loss: 0.0027 - val_loss: 0.0021\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 375us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 373us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 379us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 375us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 373us/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 374us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 376us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 373us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 377us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 377us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 376us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "\n",
      "GENERATION 5\n",
      "\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 5s 1ms/step - loss: 0.1655 - val_loss: 0.0076\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 155us/step - loss: 0.0226 - val_loss: 0.0128\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 156us/step - loss: 0.0124 - val_loss: 0.0034\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 155us/step - loss: 0.0053 - val_loss: 0.0022\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 158us/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 157us/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 155us/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 155us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 155us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 155us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 155us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 155us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 155us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 155us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 155us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 158us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 156us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 156us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 156us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 154us/step - loss: 0.0010 - val_loss: 0.0018\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 155us/step - loss: 9.8732e-04 - val_loss: 0.0013\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 154us/step - loss: 9.8450e-04 - val_loss: 0.0015\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 154us/step - loss: 9.0881e-04 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 155us/step - loss: 9.5917e-04 - val_loss: 0.0019\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 5s 1ms/step - loss: 0.0752 - val_loss: 0.0355\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 153us/step - loss: 0.0100 - val_loss: 0.0111\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 153us/step - loss: 0.0044 - val_loss: 0.0067\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 154us/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 154us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 153us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 154us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 153us/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 153us/step - loss: 9.8285e-04 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 153us/step - loss: 9.5150e-04 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 154us/step - loss: 9.3700e-04 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 154us/step - loss: 9.1989e-04 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 154us/step - loss: 9.0668e-04 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 154us/step - loss: 8.8955e-04 - val_loss: 0.0013\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 153us/step - loss: 8.7283e-04 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 152us/step - loss: 8.5454e-04 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 153us/step - loss: 8.4020e-04 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 154us/step - loss: 8.3116e-04 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 154us/step - loss: 8.1262e-04 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 157us/step - loss: 7.9511e-04 - val_loss: 0.0010\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 153us/step - loss: 7.7633e-04 - val_loss: 9.7178e-04\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 153us/step - loss: 7.4540e-04 - val_loss: 9.1865e-04\n",
      "Epoch 23/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3490/3490 [==============================] - 1s 154us/step - loss: 7.2787e-04 - val_loss: 9.1591e-04\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 153us/step - loss: 7.1493e-04 - val_loss: 9.3478e-04\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 5s 1ms/step - loss: 0.1630 - val_loss: 0.0029\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 155us/step - loss: 0.0217 - val_loss: 0.0184\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 155us/step - loss: 0.0125 - val_loss: 0.0050\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 157us/step - loss: 0.0054 - val_loss: 0.0024\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 157us/step - loss: 0.0032 - val_loss: 0.0026\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 155us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 155us/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 155us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 157us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 157us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 156us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 156us/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 155us/step - loss: 9.8514e-04 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 155us/step - loss: 9.1848e-04 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 156us/step - loss: 8.3744e-04 - val_loss: 0.0010\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 156us/step - loss: 8.0188e-04 - val_loss: 9.6681e-04\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 155us/step - loss: 8.0820e-04 - val_loss: 8.7396e-04\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 155us/step - loss: 7.6354e-04 - val_loss: 9.2969e-04\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 155us/step - loss: 7.6157e-04 - val_loss: 8.3437e-04\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 156us/step - loss: 7.0523e-04 - val_loss: 9.2588e-04\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 156us/step - loss: 6.8600e-04 - val_loss: 8.1594e-04\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 155us/step - loss: 6.7098e-04 - val_loss: 8.7521e-04\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 156us/step - loss: 6.5460e-04 - val_loss: 7.9302e-04\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 155us/step - loss: 6.4956e-04 - val_loss: 9.5646e-04\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 6s 2ms/step - loss: 0.1744 - val_loss: 0.0416\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 397us/step - loss: 0.0287 - val_loss: 0.0220\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 396us/step - loss: 0.0119 - val_loss: 0.0102\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 396us/step - loss: 0.0054 - val_loss: 0.0034\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 396us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 397us/step - loss: 0.0029 - val_loss: 0.0060\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 398us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 398us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 396us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 397us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 397us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 394us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 397us/step - loss: 0.0019 - val_loss: 0.0030\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 396us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 397us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 397us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 398us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 406us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 397us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 395us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 397us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 397us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 395us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 396us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 6s 2ms/step - loss: 0.0934 - val_loss: 0.0288\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 414us/step - loss: 0.0245 - val_loss: 0.0081\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 414us/step - loss: 0.0113 - val_loss: 0.0125\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 414us/step - loss: 0.0070 - val_loss: 0.0064\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 414us/step - loss: 0.0049 - val_loss: 0.0056\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 417us/step - loss: 0.0044 - val_loss: 0.0027\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 415us/step - loss: 0.0038 - val_loss: 0.0027\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 415us/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 414us/step - loss: 0.0033 - val_loss: 0.0025\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 413us/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 415us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 415us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 415us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 415us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 415us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 415us/step - loss: 0.0026 - val_loss: 0.0039\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 413us/step - loss: 0.0025 - val_loss: 0.0053\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 415us/step - loss: 0.0025 - val_loss: 0.0053\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 416us/step - loss: 0.0024 - val_loss: 0.0046\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 413us/step - loss: 0.0023 - val_loss: 0.0046\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 415us/step - loss: 0.0023 - val_loss: 0.0058\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 415us/step - loss: 0.0024 - val_loss: 0.0070\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 415us/step - loss: 0.0023 - val_loss: 0.0084\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 414us/step - loss: 0.0025 - val_loss: 0.0082\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 7s 2ms/step - loss: 0.2154 - val_loss: 0.0683\n",
      "Epoch 2/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3490/3490 [==============================] - 1s 415us/step - loss: 0.0471 - val_loss: 0.0341\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 414us/step - loss: 0.0183 - val_loss: 0.0178\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 416us/step - loss: 0.0055 - val_loss: 0.0094\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 414us/step - loss: 0.0044 - val_loss: 0.0035\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 416us/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 418us/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 415us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 417us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 417us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 416us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 414us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 416us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 422us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 417us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 414us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 416us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 417us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 417us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 414us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 417us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 416us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 415us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 414us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 7s 2ms/step - loss: 0.1523 - val_loss: 0.1026\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 376us/step - loss: 0.0294 - val_loss: 0.0252\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 374us/step - loss: 0.0137 - val_loss: 0.0120\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 375us/step - loss: 0.0064 - val_loss: 0.0045\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 376us/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 376us/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 375us/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 376us/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 376us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 376us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 374us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 376us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 377us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 374us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 374us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 374us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 376us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 376us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 375us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 379us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 375us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 374us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 374us/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 377us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 7s 2ms/step - loss: 0.0749 - val_loss: 0.0650\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 535us/step - loss: 0.0227 - val_loss: 0.0065\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 538us/step - loss: 0.0098 - val_loss: 0.0027\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 541us/step - loss: 0.0056 - val_loss: 0.0056\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 538us/step - loss: 0.0045 - val_loss: 0.0032\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 539us/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 538us/step - loss: 0.0030 - val_loss: 0.0026\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 538us/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 544us/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 537us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 537us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 536us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 538us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 538us/step - loss: 0.0023 - val_loss: 0.0036\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 541us/step - loss: 0.0022 - val_loss: 0.0033\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 535us/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 540us/step - loss: 0.0021 - val_loss: 0.0035\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 538us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 538us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 537us/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 538us/step - loss: 0.0021 - val_loss: 0.0049\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 538us/step - loss: 0.0019 - val_loss: 0.0058\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 539us/step - loss: 0.0019 - val_loss: 0.0054\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 540us/step - loss: 0.0018 - val_loss: 0.0057\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 8s 2ms/step - loss: 0.1616 - val_loss: 0.0552\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 538us/step - loss: 0.0311 - val_loss: 0.0127\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 538us/step - loss: 0.0130 - val_loss: 0.0033\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 538us/step - loss: 0.0086 - val_loss: 0.0032\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 538us/step - loss: 0.0055 - val_loss: 0.0041\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 539us/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 7/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3490/3490 [==============================] - 2s 542us/step - loss: 0.0038 - val_loss: 0.0033\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 537us/step - loss: 0.0035 - val_loss: 0.0028\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 548us/step - loss: 0.0032 - val_loss: 0.0027\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 541us/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 540us/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 539us/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 539us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 540us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 537us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 538us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 541us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 542us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 537us/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 538us/step - loss: 0.0023 - val_loss: 0.0036\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 541us/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 538us/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 537us/step - loss: 0.0021 - val_loss: 0.0039\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 536us/step - loss: 0.0022 - val_loss: 0.0039\n",
      "\n",
      "GENERATION 6\n",
      "\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 6s 2ms/step - loss: 0.0769 - val_loss: 0.0356\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 156us/step - loss: 0.0114 - val_loss: 0.0141\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 155us/step - loss: 0.0085 - val_loss: 0.0029\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 155us/step - loss: 0.0052 - val_loss: 0.0015\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 154us/step - loss: 0.0036 - val_loss: 0.0021\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 155us/step - loss: 0.0028 - val_loss: 0.0020\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 154us/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 156us/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 155us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 156us/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 158us/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 156us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 155us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 156us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 155us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 154us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 155us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 155us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 155us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 155us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 155us/step - loss: 0.0014 - val_loss: 0.0022\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 155us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 154us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 155us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 6s 2ms/step - loss: 0.0572 - val_loss: 0.0159\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 156us/step - loss: 0.0073 - val_loss: 0.0078\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 155us/step - loss: 0.0034 - val_loss: 0.0061\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 154us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 153us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 154us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 154us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 155us/step - loss: 9.5720e-04 - val_loss: 0.0012\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 155us/step - loss: 9.1729e-04 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 155us/step - loss: 8.8929e-04 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 154us/step - loss: 8.7268e-04 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 155us/step - loss: 8.5849e-04 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 155us/step - loss: 8.4162e-04 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 155us/step - loss: 8.2461e-04 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 156us/step - loss: 8.0428e-04 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 155us/step - loss: 7.7947e-04 - val_loss: 9.5854e-04\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 155us/step - loss: 7.6114e-04 - val_loss: 9.5057e-04\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 155us/step - loss: 7.4933e-04 - val_loss: 9.7875e-04\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 155us/step - loss: 7.2637e-04 - val_loss: 9.3166e-04\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 155us/step - loss: 7.0590e-04 - val_loss: 8.9259e-04\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 159us/step - loss: 6.8842e-04 - val_loss: 8.6875e-04\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 155us/step - loss: 6.6874e-04 - val_loss: 8.3544e-04\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 155us/step - loss: 6.5621e-04 - val_loss: 8.1607e-04\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 154us/step - loss: 6.4562e-04 - val_loss: 8.3279e-04\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 6s 2ms/step - loss: 0.0846 - val_loss: 0.0149\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 156us/step - loss: 0.0132 - val_loss: 0.0159\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 158us/step - loss: 0.0078 - val_loss: 0.0030\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 159us/step - loss: 0.0052 - val_loss: 0.0073\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 157us/step - loss: 0.0038 - val_loss: 0.0016\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 158us/step - loss: 0.0029 - val_loss: 0.0049\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 157us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 157us/step - loss: 0.0024 - val_loss: 0.0043\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 157us/step - loss: 0.0022 - val_loss: 0.0064\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 157us/step - loss: 0.0021 - val_loss: 0.0052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 157us/step - loss: 0.0020 - val_loss: 0.0059\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 157us/step - loss: 0.0019 - val_loss: 0.0068\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 157us/step - loss: 0.0018 - val_loss: 0.0068\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 156us/step - loss: 0.0018 - val_loss: 0.0077\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 156us/step - loss: 0.0017 - val_loss: 0.0089\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 157us/step - loss: 0.0016 - val_loss: 0.0089\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 157us/step - loss: 0.0015 - val_loss: 0.0098\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 157us/step - loss: 0.0015 - val_loss: 0.0113\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 158us/step - loss: 0.0015 - val_loss: 0.0118\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 158us/step - loss: 0.0015 - val_loss: 0.0120\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 158us/step - loss: 0.0014 - val_loss: 0.0126\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - ETA: 0s - loss: 0.001 - 1s 157us/step - loss: 0.0014 - val_loss: 0.0138\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 156us/step - loss: 0.0013 - val_loss: 0.0145\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 157us/step - loss: 0.0013 - val_loss: 0.0137\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 7s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 322us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 328us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 321us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 321us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 322us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 321us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 322us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 322us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 321us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 324us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 322us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 321us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 323us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 321us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 320us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 325us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 322us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 320us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 323us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 322us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 323us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 323us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 322us/step - loss: nan - val_loss: nan\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 7s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 325us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 322us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 321us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 323us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 323us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 326us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 322us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 321us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 328us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 323us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 322us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 321us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 322us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 321us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 322us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 320us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 322us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 323us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 322us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 325us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 321us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 323us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 323us/step - loss: nan - val_loss: nan\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 8s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 320us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 323us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 322us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 323us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 322us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 322us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 323us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 321us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 322us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 328us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 321us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 322us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 323us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 321us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 323us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 322us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 323us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3490/3490 [==============================] - 1s 322us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 322us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 321us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 322us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 322us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 323us/step - loss: nan - val_loss: nan\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 8s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 474us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 476us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 471us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 473us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 473us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 473us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 473us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 477us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 478us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 472us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 474us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 473us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 475us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 474us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 474us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 475us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 475us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 475us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 478us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 474us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 476us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 474us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 474us/step - loss: nan - val_loss: nan\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 9s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 576us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 574us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 578us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 576us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 576us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 577us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 575us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 580us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 578us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 575us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 577us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 578us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 577us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 576us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 575us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 576us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 575us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 580us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 579us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 577us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 576us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 576us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 582us/step - loss: nan - val_loss: nan\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 9s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 574us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 574us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 575us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 576us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 577us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 576us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 572us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 573us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 570us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 573us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 576us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 575us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 573us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 571us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 574us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 572us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 573us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 577us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 575us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 576us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 574us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 572us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 573us/step - loss: nan - val_loss: nan\n",
      "\n",
      "GENERATION 7\n",
      "\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 8s 2ms/step - loss: 0.0870 - val_loss: 0.0035\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 258us/step - loss: 0.0091 - val_loss: 0.0018\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 257us/step - loss: 0.0043 - val_loss: 0.0015\n",
      "Epoch 4/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3490/3490 [==============================] - 1s 258us/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 258us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 260us/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 260us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 260us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 261us/step - loss: 9.8957e-04 - val_loss: 0.0013\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 257us/step - loss: 9.6366e-04 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 258us/step - loss: 9.1857e-04 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 258us/step - loss: 8.5633e-04 - val_loss: 0.0010\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 257us/step - loss: 8.0886e-04 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 258us/step - loss: 7.5455e-04 - val_loss: 9.0641e-04\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 257us/step - loss: 7.0780e-04 - val_loss: 8.3706e-04\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 257us/step - loss: 6.9033e-04 - val_loss: 8.5915e-04\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 258us/step - loss: 6.7445e-04 - val_loss: 7.7545e-04\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 257us/step - loss: 6.5776e-04 - val_loss: 7.6302e-04\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 259us/step - loss: 6.3683e-04 - val_loss: 7.3802e-04\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 257us/step - loss: 6.2105e-04 - val_loss: 7.3039e-04\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 257us/step - loss: 6.2667e-04 - val_loss: 7.1464e-04\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 258us/step - loss: 6.2873e-04 - val_loss: 7.0908e-04\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 257us/step - loss: 6.0057e-04 - val_loss: 8.1995e-04\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 261us/step - loss: 6.0829e-04 - val_loss: 6.8898e-04\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 7s 2ms/step - loss: 0.1139 - val_loss: 0.0632\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 157us/step - loss: 0.0161 - val_loss: 0.0150\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 156us/step - loss: 0.0083 - val_loss: 0.0019\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 157us/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 156us/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 156us/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 157us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 157us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 156us/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 157us/step - loss: 9.8693e-04 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 156us/step - loss: 9.4091e-04 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 157us/step - loss: 9.2169e-04 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 156us/step - loss: 9.0763e-04 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 156us/step - loss: 8.7966e-04 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 156us/step - loss: 8.5550e-04 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 157us/step - loss: 8.3704e-04 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 157us/step - loss: 8.0903e-04 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 157us/step - loss: 7.7791e-04 - val_loss: 0.0010\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 157us/step - loss: 7.5049e-04 - val_loss: 9.2853e-04\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 157us/step - loss: 7.2590e-04 - val_loss: 9.2338e-04\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 157us/step - loss: 7.0370e-04 - val_loss: 8.7076e-04\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 156us/step - loss: 6.9428e-04 - val_loss: 8.4788e-04\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 155us/step - loss: 6.7145e-04 - val_loss: 8.4630e-04\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 156us/step - loss: 6.5604e-04 - val_loss: 8.7300e-04\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 8s 2ms/step - loss: 0.0881 - val_loss: 0.0068\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 309us/step - loss: 0.0102 - val_loss: 0.0032\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 308us/step - loss: 0.0051 - val_loss: 0.0043\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 309us/step - loss: 0.0036 - val_loss: 0.0059\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 309us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 310us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 308us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 310us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 309us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 307us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 309us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 310us/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 309us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 309us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 314us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 310us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 308us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 310us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 309us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 307us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 309us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 313us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 309us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 309us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 9s 2ms/step - loss: 0.1182 - val_loss: 0.0200\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 324us/step - loss: 0.0213 - val_loss: 0.0107\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 328us/step - loss: 0.0111 - val_loss: 0.0032\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 323us/step - loss: 0.0076 - val_loss: 0.0036\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 324us/step - loss: 0.0055 - val_loss: 0.0035\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 324us/step - loss: 0.0045 - val_loss: 0.0030\n",
      "Epoch 7/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3490/3490 [==============================] - 1s 325us/step - loss: 0.0039 - val_loss: 0.0048\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 325us/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 323us/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 324us/step - loss: 0.0033 - val_loss: 0.0048\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 323us/step - loss: 0.0032 - val_loss: 0.0059\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 327us/step - loss: 0.0032 - val_loss: 0.0060\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 325us/step - loss: 0.0029 - val_loss: 0.0067\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 323us/step - loss: 0.0028 - val_loss: 0.0070\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 325us/step - loss: 0.0028 - val_loss: 0.0077\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 325us/step - loss: 0.0027 - val_loss: 0.0077\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 327us/step - loss: 0.0026 - val_loss: 0.0084\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 326us/step - loss: 0.0025 - val_loss: 0.0093\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 323us/step - loss: 0.0025 - val_loss: 0.0097\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 325us/step - loss: 0.0026 - val_loss: 0.0100\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 323us/step - loss: 0.0025 - val_loss: 0.0110\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 323us/step - loss: 0.0024 - val_loss: 0.0108\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 325us/step - loss: 0.0023 - val_loss: 0.0101\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 323us/step - loss: 0.0023 - val_loss: 0.0100\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 10s 3ms/step - loss: 0.2317 - val_loss: 0.2670\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 554us/step - loss: 0.1708 - val_loss: 0.1957\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 559us/step - loss: 0.1311 - val_loss: 0.1452\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 556us/step - loss: 0.1046 - val_loss: 0.1086\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 559us/step - loss: 0.0870 - val_loss: 0.0824\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 560us/step - loss: 0.0753 - val_loss: 0.0637\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 557us/step - loss: 0.0673 - val_loss: 0.0504\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 558us/step - loss: 0.0619 - val_loss: 0.0410\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 556us/step - loss: 0.0587 - val_loss: 0.0343\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 558us/step - loss: 0.0559 - val_loss: 0.0292\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 558us/step - loss: 0.0535 - val_loss: 0.0255\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 559us/step - loss: 0.0522 - val_loss: 0.0228\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 558us/step - loss: 0.0498 - val_loss: 0.0206\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 558us/step - loss: 0.0486 - val_loss: 0.0189\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 556us/step - loss: 0.0472 - val_loss: 0.0174\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 554us/step - loss: 0.0455 - val_loss: 0.0162\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 557us/step - loss: 0.0443 - val_loss: 0.0153\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 556us/step - loss: 0.0426 - val_loss: 0.0145\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 558us/step - loss: 0.0412 - val_loss: 0.0136\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 557us/step - loss: 0.0398 - val_loss: 0.0127\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 555us/step - loss: 0.0386 - val_loss: 0.0120\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 557us/step - loss: 0.0366 - val_loss: 0.0113\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 556us/step - loss: 0.0356 - val_loss: 0.0107\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 557us/step - loss: 0.0336 - val_loss: 0.0100\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 10s 3ms/step - loss: 0.0943 - val_loss: 0.0129\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 560us/step - loss: 0.0141 - val_loss: 0.0255\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 555us/step - loss: 0.0149 - val_loss: 0.0073\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 556us/step - loss: 0.0086 - val_loss: 0.0120\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 556us/step - loss: 0.0080 - val_loss: 0.0041\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 559us/step - loss: 0.0070 - val_loss: 0.0146\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 559us/step - loss: 0.0086 - val_loss: 0.0061\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 557us/step - loss: 0.0057 - val_loss: 0.0115\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 558us/step - loss: 0.0072 - val_loss: 0.0084\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 562us/step - loss: 0.0072 - val_loss: 0.0150\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 561us/step - loss: 0.0072 - val_loss: 0.0033\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 557us/step - loss: 0.0032 - val_loss: 0.0068\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 557us/step - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 562us/step - loss: 0.0059 - val_loss: 0.0103\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 559us/step - loss: 0.0075 - val_loss: 0.0097\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 559us/step - loss: 0.0067 - val_loss: 0.0099\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 557us/step - loss: 0.0067 - val_loss: 0.0056\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 563us/step - loss: 0.0050 - val_loss: 0.0106\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 560us/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 557us/step - loss: 0.0065 - val_loss: 0.0095\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 560us/step - loss: 0.0062 - val_loss: 0.0064\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 563us/step - loss: 0.0053 - val_loss: 0.0070\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 558us/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 562us/step - loss: 0.0052 - val_loss: 0.0089\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 9s 3ms/step - loss: 0.2085 - val_loss: 0.2070\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 323us/step - loss: 0.1292 - val_loss: 0.1254\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 322us/step - loss: 0.0911 - val_loss: 0.0810\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 322us/step - loss: 0.0733 - val_loss: 0.0567\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 322us/step - loss: 0.0648 - val_loss: 0.0430\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 322us/step - loss: 0.0604 - val_loss: 0.0348\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 323us/step - loss: 0.0578 - val_loss: 0.0298\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 321us/step - loss: 0.0558 - val_loss: 0.0265\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 322us/step - loss: 0.0544 - val_loss: 0.0242\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 322us/step - loss: 0.0528 - val_loss: 0.0224\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 322us/step - loss: 0.0515 - val_loss: 0.0210\n",
      "Epoch 12/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3490/3490 [==============================] - 1s 321us/step - loss: 0.0501 - val_loss: 0.0198\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 327us/step - loss: 0.0488 - val_loss: 0.0188\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 322us/step - loss: 0.0474 - val_loss: 0.0179\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 326us/step - loss: 0.0458 - val_loss: 0.0168\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 323us/step - loss: 0.0441 - val_loss: 0.0161\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 320us/step - loss: 0.0426 - val_loss: 0.0151\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 321us/step - loss: 0.0409 - val_loss: 0.0144\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 322us/step - loss: 0.0393 - val_loss: 0.0133\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 321us/step - loss: 0.0377 - val_loss: 0.0125\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 323us/step - loss: 0.0360 - val_loss: 0.0118\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 321us/step - loss: 0.0343 - val_loss: 0.0108\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 322us/step - loss: 0.0324 - val_loss: 0.0100\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 322us/step - loss: 0.0306 - val_loss: 0.0092\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 9s 3ms/step - loss: 0.2338 - val_loss: 0.2573\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 377us/step - loss: 0.1644 - val_loss: 0.1809\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 374us/step - loss: 0.1227 - val_loss: 0.1300\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 374us/step - loss: 0.0971 - val_loss: 0.0960\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 373us/step - loss: 0.0814 - val_loss: 0.0726\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 373us/step - loss: 0.0717 - val_loss: 0.0570\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 372us/step - loss: 0.0660 - val_loss: 0.0464\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 375us/step - loss: 0.0623 - val_loss: 0.0390\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 374us/step - loss: 0.0597 - val_loss: 0.0338\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 372us/step - loss: 0.0581 - val_loss: 0.0300\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 371us/step - loss: 0.0566 - val_loss: 0.0272\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 373us/step - loss: 0.0556 - val_loss: 0.0251\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 373us/step - loss: 0.0544 - val_loss: 0.0236\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 379us/step - loss: 0.0536 - val_loss: 0.0223\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 374us/step - loss: 0.0526 - val_loss: 0.0215\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 374us/step - loss: 0.0515 - val_loss: 0.0205\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 373us/step - loss: 0.0504 - val_loss: 0.0198\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 375us/step - loss: 0.0491 - val_loss: 0.0191\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 372us/step - loss: 0.0474 - val_loss: 0.0183\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 373us/step - loss: 0.0460 - val_loss: 0.0175\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 373us/step - loss: 0.0444 - val_loss: 0.0167\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 376us/step - loss: 0.0430 - val_loss: 0.0159\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 372us/step - loss: 0.0416 - val_loss: 0.0151\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 371us/step - loss: 0.0403 - val_loss: 0.0145\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 9s 3ms/step - loss: 0.1849 - val_loss: 0.1489\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 370us/step - loss: 0.0907 - val_loss: 0.0646\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 370us/step - loss: 0.0593 - val_loss: 0.0332\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 370us/step - loss: 0.0478 - val_loss: 0.0204\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 378us/step - loss: 0.0422 - val_loss: 0.0145\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 371us/step - loss: 0.0385 - val_loss: 0.0119\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 371us/step - loss: 0.0353 - val_loss: 0.0106\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 373us/step - loss: 0.0326 - val_loss: 0.0092\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 370us/step - loss: 0.0299 - val_loss: 0.0084\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 372us/step - loss: 0.0275 - val_loss: 0.0076\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 372us/step - loss: 0.0252 - val_loss: 0.0067\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 373us/step - loss: 0.0227 - val_loss: 0.0060\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 372us/step - loss: 0.0210 - val_loss: 0.0052\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 371us/step - loss: 0.0185 - val_loss: 0.0048\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 371us/step - loss: 0.0166 - val_loss: 0.0043\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 371us/step - loss: 0.0148 - val_loss: 0.0040\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 370us/step - loss: 0.0134 - val_loss: 0.0037\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 371us/step - loss: 0.0118 - val_loss: 0.0035\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 371us/step - loss: 0.0107 - val_loss: 0.0034\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 370us/step - loss: 0.0094 - val_loss: 0.0034\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 369us/step - loss: 0.0084 - val_loss: 0.0034\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 371us/step - loss: 0.0076 - val_loss: 0.0035\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 372us/step - loss: 0.0068 - val_loss: 0.0036\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 375us/step - loss: 0.0063 - val_loss: 0.0038\n",
      "\n",
      "GENERATION 8\n",
      "\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 9s 3ms/step - loss: 0.0773 - val_loss: 0.0023\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 258us/step - loss: 0.0081 - val_loss: 0.0060\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 259us/step - loss: 0.0035 - val_loss: 0.0013\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 260us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 259us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 259us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 260us/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 260us/step - loss: 9.7051e-04 - val_loss: 0.0013\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 260us/step - loss: 9.2969e-04 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 258us/step - loss: 8.9431e-04 - val_loss: 0.0010\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 259us/step - loss: 8.7074e-04 - val_loss: 0.0010\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 260us/step - loss: 8.4640e-04 - val_loss: 9.6607e-04\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 263us/step - loss: 8.0338e-04 - val_loss: 9.3625e-04\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 260us/step - loss: 7.6072e-04 - val_loss: 8.7384e-04\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 258us/step - loss: 7.3673e-04 - val_loss: 9.8325e-04\n",
      "Epoch 16/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3490/3490 [==============================] - 1s 259us/step - loss: 7.6095e-04 - val_loss: 8.1611e-04\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 265us/step - loss: 6.8222e-04 - val_loss: 8.0299e-04\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 259us/step - loss: 6.5923e-04 - val_loss: 7.7249e-04\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 259us/step - loss: 6.6459e-04 - val_loss: 8.7388e-04\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 261us/step - loss: 6.5014e-04 - val_loss: 7.6498e-04\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 259us/step - loss: 6.3348e-04 - val_loss: 7.5408e-04\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 259us/step - loss: 6.2965e-04 - val_loss: 7.2716e-04\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 259us/step - loss: 6.3331e-04 - val_loss: 7.7195e-04\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 258us/step - loss: 6.4844e-04 - val_loss: 7.0516e-04\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 9s 3ms/step - loss: 0.1625 - val_loss: 0.0185\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 161us/step - loss: 0.0238 - val_loss: 0.0024\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 165us/step - loss: 0.0114 - val_loss: 0.0072\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 163us/step - loss: 0.0049 - val_loss: 0.0103\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 159us/step - loss: 0.0032 - val_loss: 0.0025\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 160us/step - loss: 0.0019 - val_loss: 0.0030\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 160us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 160us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 161us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 160us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - ETA: 0s - loss: 0.001 - 1s 160us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 160us/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 160us/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 160us/step - loss: 9.7361e-04 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 160us/step - loss: 8.8452e-04 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 160us/step - loss: 8.1819e-04 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 161us/step - loss: 7.7543e-04 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 160us/step - loss: 7.6682e-04 - val_loss: 9.6871e-04\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 160us/step - loss: 7.4195e-04 - val_loss: 0.0010\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 161us/step - loss: 7.2257e-04 - val_loss: 9.4236e-04\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 159us/step - loss: 7.3787e-04 - val_loss: 9.0505e-04\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 160us/step - loss: 6.9809e-04 - val_loss: 0.0013\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 159us/step - loss: 7.2607e-04 - val_loss: 8.9955e-04\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 160us/step - loss: 6.7746e-04 - val_loss: 9.1266e-04\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 10s 3ms/step - loss: 0.1519 - val_loss: 0.0147\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 312us/step - loss: 0.0293 - val_loss: 0.0240\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 312us/step - loss: 0.0143 - val_loss: 0.0166\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 314us/step - loss: 0.0067 - val_loss: 0.0046\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 310us/step - loss: 0.0039 - val_loss: 0.0100\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 313us/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 311us/step - loss: 0.0026 - val_loss: 0.0056\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 311us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 311us/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 314us/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 313us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 316us/step - loss: 0.0020 - val_loss: 0.0033\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 311us/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 311us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 313us/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 312us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 313us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 311us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 312us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 312us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 311us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 312us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 311us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 313us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 10s 3ms/step - loss: 0.1178 - val_loss: 0.0133\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 326us/step - loss: 0.0173 - val_loss: 0.0036\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 327us/step - loss: 0.0083 - val_loss: 0.0051\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 326us/step - loss: 0.0060 - val_loss: 0.0091\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 327us/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 325us/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 331us/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 327us/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 326us/step - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 326us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 329us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 325us/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 326us/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 328us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 330us/step - loss: 0.0024 - val_loss: 0.0038\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 327us/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 327us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 326us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 19/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3490/3490 [==============================] - 1s 326us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 325us/step - loss: 0.0023 - val_loss: 0.0036\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 326us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 326us/step - loss: 0.0022 - val_loss: 0.0053\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 324us/step - loss: 0.0020 - val_loss: 0.0047\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 328us/step - loss: 0.0019 - val_loss: 0.0049\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 10s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 327us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 330us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 324us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 324us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 324us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 332us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 327us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 328us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 325us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 324us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 325us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 324us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 329us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 325us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 332us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 326us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 327us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 324us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 326us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 326us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 326us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 328us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 324us/step - loss: nan - val_loss: nan\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 11s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 327us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 325us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 325us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 326us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 327us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 330us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 326us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 325us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 327us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 325us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 325us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 326us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 325us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 325us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 325us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 324us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 326us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 325us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 326us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 328us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 325us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 325us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 329us/step - loss: nan - val_loss: nan\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 11s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 475us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 474us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 477us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 472us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 475us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 474us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 474us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 473us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 474us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 473us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 474us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 476us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 472us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 474us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 472us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 474us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 474us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 474us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 474us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 476us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 480us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 476us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 473us/step - loss: nan - val_loss: nan\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 11s 3ms/step - loss: 0.1430 - val_loss: 0.0201\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 474us/step - loss: 0.0230 - val_loss: 0.0042\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 477us/step - loss: 0.0096 - val_loss: 0.0034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 474us/step - loss: 0.0056 - val_loss: 0.0038\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 472us/step - loss: 0.0044 - val_loss: 0.0037\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 473us/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 471us/step - loss: 0.0035 - val_loss: 0.0031\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 474us/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 472us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 472us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 474us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 473us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 475us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 476us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 473us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 473us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 476us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 473us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 474us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 476us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 473us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 474us/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 475us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 474us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 11s 3ms/step - loss: 0.1066 - val_loss: 0.0617\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 472us/step - loss: 0.0407 - val_loss: 0.0039\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 474us/step - loss: 0.0149 - val_loss: 0.0035\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 472us/step - loss: 0.0096 - val_loss: 0.0071\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 472us/step - loss: 0.0060 - val_loss: 0.0068\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 471us/step - loss: 0.0051 - val_loss: 0.0041\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 473us/step - loss: 0.0046 - val_loss: 0.0034\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 474us/step - loss: 0.0043 - val_loss: 0.0034\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 472us/step - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 472us/step - loss: 0.0040 - val_loss: 0.0033\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 474us/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 475us/step - loss: 0.0037 - val_loss: 0.0033\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 474us/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 473us/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 475us/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 471us/step - loss: 0.0034 - val_loss: 0.0040\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 472us/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 477us/step - loss: 0.0032 - val_loss: 0.0039\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 474us/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 474us/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 473us/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 472us/step - loss: 0.0031 - val_loss: 0.0041\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 476us/step - loss: 0.0030 - val_loss: 0.0036\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 475us/step - loss: 0.0030 - val_loss: 0.0040\n",
      "\n",
      "GENERATION 9\n",
      "\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 12s 3ms/step - loss: 1.1877 - val_loss: 0.0079\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 501us/step - loss: 0.0189 - val_loss: 0.0044\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 502us/step - loss: 0.0105 - val_loss: 0.0031\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 500us/step - loss: 0.0061 - val_loss: 0.0030\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 501us/step - loss: 0.0039 - val_loss: 0.0032\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 499us/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 501us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 501us/step - loss: 0.0024 - val_loss: 0.0038\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 501us/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 498us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 502us/step - loss: 0.0024 - val_loss: 0.0038\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 502us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 500us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 503us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 500us/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 500us/step - loss: 0.0023 - val_loss: 0.0036\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 500us/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 501us/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 500us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 502us/step - loss: 0.0023 - val_loss: 0.0036\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 506us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 501us/step - loss: 0.0023 - val_loss: 0.0036\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 502us/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 502us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 11s 3ms/step - loss: 0.1183 - val_loss: 0.0520\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 265us/step - loss: 0.0177 - val_loss: 0.0124\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 262us/step - loss: 0.0075 - val_loss: 0.0055\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 262us/step - loss: 0.0041 - val_loss: 0.0031\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 263us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 262us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 263us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 262us/step - loss: 0.0012 - val_loss: 0.0014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 262us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 263us/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 263us/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 261us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 262us/step - loss: 9.4862e-04 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 262us/step - loss: 8.7947e-04 - val_loss: 9.8724e-04\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 261us/step - loss: 8.0205e-04 - val_loss: 8.9343e-04\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 263us/step - loss: 7.5874e-04 - val_loss: 8.9226e-04\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 261us/step - loss: 7.0900e-04 - val_loss: 7.9867e-04\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 263us/step - loss: 6.7662e-04 - val_loss: 8.3846e-04\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 274us/step - loss: 6.6646e-04 - val_loss: 7.7001e-04\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 262us/step - loss: 6.5667e-04 - val_loss: 8.0973e-04\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 262us/step - loss: 6.4841e-04 - val_loss: 7.3070e-04\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 262us/step - loss: 6.5771e-04 - val_loss: 7.2488e-04\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 261us/step - loss: 6.2298e-04 - val_loss: 7.2676e-04\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 263us/step - loss: 6.0740e-04 - val_loss: 7.0581e-04\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 11s 3ms/step - loss: 0.1552 - val_loss: 0.0664\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 260us/step - loss: 0.0238 - val_loss: 0.0099\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 264us/step - loss: 0.0063 - val_loss: 0.0024\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 260us/step - loss: 0.0033 - val_loss: 0.0022\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 260us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 259us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 261us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 260us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 259us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 261us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 262us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 260us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 260us/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 262us/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 260us/step - loss: 9.7584e-04 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 262us/step - loss: 9.4771e-04 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 259us/step - loss: 9.2404e-04 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 260us/step - loss: 8.8933e-04 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 259us/step - loss: 8.9422e-04 - val_loss: 9.8345e-04\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 262us/step - loss: 8.5672e-04 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 261us/step - loss: 8.3509e-04 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 260us/step - loss: 8.3551e-04 - val_loss: 9.5733e-04\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 261us/step - loss: 7.7986e-04 - val_loss: 9.9000e-04\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 260us/step - loss: 7.6088e-04 - val_loss: 8.9007e-04\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 11s 3ms/step - loss: 0.1142 - val_loss: 0.0463\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 175us/step - loss: 0.0215 - val_loss: 0.0256\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 176us/step - loss: 0.0132 - val_loss: 0.0016\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 177us/step - loss: 0.0065 - val_loss: 0.0016\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 179us/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 179us/step - loss: 0.0030 - val_loss: 0.0015\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 178us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 177us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 176us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 175us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 176us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 176us/step - loss: 0.0017 - val_loss: 0.0033\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 176us/step - loss: 0.0017 - val_loss: 0.0033\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 176us/step - loss: 0.0015 - val_loss: 0.0033\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 179us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 176us/step - loss: 0.0015 - val_loss: 0.0034\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 176us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 177us/step - loss: 0.0013 - val_loss: 0.0048\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 175us/step - loss: 0.0013 - val_loss: 0.0048\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 176us/step - loss: 0.0012 - val_loss: 0.0045\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 179us/step - loss: 0.0011 - val_loss: 0.0046\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 179us/step - loss: 0.0011 - val_loss: 0.0050\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 176us/step - loss: 0.0012 - val_loss: 0.0057\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 176us/step - loss: 0.0011 - val_loss: 0.0071\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 13s 4ms/step - loss: 0.0713 - val_loss: 0.0509\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 573us/step - loss: 0.0181 - val_loss: 0.0065\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 575us/step - loss: 0.0106 - val_loss: 0.0195\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 573us/step - loss: 0.0188 - val_loss: 0.0181\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 576us/step - loss: 0.0096 - val_loss: 0.0065\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 576us/step - loss: 0.0084 - val_loss: 0.0123\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 574us/step - loss: 0.0090 - val_loss: 0.0083\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 575us/step - loss: 0.0071 - val_loss: 0.0083\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 576us/step - loss: 0.0062 - val_loss: 0.0065\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 575us/step - loss: 0.0050 - val_loss: 0.0081\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 574us/step - loss: 0.0064 - val_loss: 0.0067\n",
      "Epoch 12/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3490/3490 [==============================] - 2s 577us/step - loss: 0.0073 - val_loss: 0.0110\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 578us/step - loss: 0.0071 - val_loss: 0.0098\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 575us/step - loss: 0.0075 - val_loss: 0.0087\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 574us/step - loss: 0.0063 - val_loss: 0.0047\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 579us/step - loss: 0.0055 - val_loss: 0.0077\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 577us/step - loss: 0.0066 - val_loss: 0.0109\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 574us/step - loss: 0.0062 - val_loss: 0.0066\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 574us/step - loss: 0.0068 - val_loss: 0.0090\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 576us/step - loss: 0.0072 - val_loss: 0.0066\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 582us/step - loss: 0.0055 - val_loss: 0.0061\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 577us/step - loss: 0.0056 - val_loss: 0.0046\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 576us/step - loss: 0.0050 - val_loss: 0.0059\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 579us/step - loss: 0.0046 - val_loss: 0.0063\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 13s 4ms/step - loss: 0.1253 - val_loss: 0.0150\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 577us/step - loss: 0.0269 - val_loss: 0.0802\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 576us/step - loss: 0.0992 - val_loss: 0.0186\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 574us/step - loss: 0.0294 - val_loss: 0.0901\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 579us/step - loss: 0.0587 - val_loss: 0.0425\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 577us/step - loss: 0.0285 - val_loss: 0.0246\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 574us/step - loss: 0.0232 - val_loss: 0.0465\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 580us/step - loss: 0.0250 - val_loss: 0.0157\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 577us/step - loss: 0.0189 - val_loss: 0.0459\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 577us/step - loss: 0.0204 - val_loss: 0.0208\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 574us/step - loss: 0.0213 - val_loss: 0.0347\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 576us/step - loss: 0.0186 - val_loss: 0.0216\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 576us/step - loss: 0.0251 - val_loss: 0.0380\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 575us/step - loss: 0.0168 - val_loss: 0.0124\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 577us/step - loss: 0.0195 - val_loss: 0.0429\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 576us/step - loss: 0.0181 - val_loss: 0.0129\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 577us/step - loss: 0.0186 - val_loss: 0.0412\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 576us/step - loss: 0.0179 - val_loss: 0.0118\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 577us/step - loss: 0.0177 - val_loss: 0.0382\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 578us/step - loss: 0.0132 - val_loss: 0.0076\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 579us/step - loss: 0.0175 - val_loss: 0.0377\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 578us/step - loss: 0.0177 - val_loss: 0.0098\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 582us/step - loss: 0.0188 - val_loss: 0.0362\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 576us/step - loss: 0.0161 - val_loss: 0.0084\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 13s 4ms/step - loss: 0.0999 - val_loss: 0.0427\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 366us/step - loss: 0.0635 - val_loss: 0.0053\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 366us/step - loss: 0.0801 - val_loss: 0.1057\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 365us/step - loss: 0.0680 - val_loss: 0.0263\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 366us/step - loss: 0.0571 - val_loss: 0.0597\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 365us/step - loss: 0.0384 - val_loss: 0.0483\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 366us/step - loss: 0.0236 - val_loss: 0.0098\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 365us/step - loss: 0.0160 - val_loss: 0.0389\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 365us/step - loss: 0.0101 - val_loss: 0.0061\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 365us/step - loss: 0.0089 - val_loss: 0.0439\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 364us/step - loss: 0.0123 - val_loss: 0.0075\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 365us/step - loss: 0.0139 - val_loss: 0.0458\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 365us/step - loss: 0.0144 - val_loss: 0.0060\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 369us/step - loss: 0.0115 - val_loss: 0.0394\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 367us/step - loss: 0.0107 - val_loss: 0.0057\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 371us/step - loss: 0.0110 - val_loss: 0.0368\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 367us/step - loss: 0.0088 - val_loss: 0.0057\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 367us/step - loss: 0.0137 - val_loss: 0.0511\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 366us/step - loss: 0.0159 - val_loss: 0.0064\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 367us/step - loss: 0.0114 - val_loss: 0.0357\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 365us/step - loss: 0.0113 - val_loss: 0.0057\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 365us/step - loss: 0.0095 - val_loss: 0.0335\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 371us/step - loss: 0.0100 - val_loss: 0.0060\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 365us/step - loss: 0.0140 - val_loss: 0.0459\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 13s 4ms/step - loss: 0.0985 - val_loss: 0.0338\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 364us/step - loss: 0.0228 - val_loss: 0.0171\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 365us/step - loss: 0.0164 - val_loss: 0.0164\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 364us/step - loss: 0.0140 - val_loss: 0.0205\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 367us/step - loss: 0.0137 - val_loss: 0.0080\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 367us/step - loss: 0.0094 - val_loss: 0.0111\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 365us/step - loss: 0.0094 - val_loss: 0.0071\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 365us/step - loss: 0.0088 - val_loss: 0.0079\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 364us/step - loss: 0.0083 - val_loss: 0.0071\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 365us/step - loss: 0.0065 - val_loss: 0.0047\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 364us/step - loss: 0.0066 - val_loss: 0.0124\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 366us/step - loss: 0.0082 - val_loss: 0.0055\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 366us/step - loss: 0.0060 - val_loss: 0.0077\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 366us/step - loss: 0.0058 - val_loss: 0.0033\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 364us/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 366us/step - loss: 0.0044 - val_loss: 0.0037\n",
      "Epoch 17/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3490/3490 [==============================] - 1s 365us/step - loss: 0.0069 - val_loss: 0.0046\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 371us/step - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 365us/step - loss: 0.0062 - val_loss: 0.0116\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 365us/step - loss: 0.0075 - val_loss: 0.0041\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 365us/step - loss: 0.0060 - val_loss: 0.0081\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 363us/step - loss: 0.0072 - val_loss: 0.0039\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 366us/step - loss: 0.0058 - val_loss: 0.0074\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 371us/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 13s 4ms/step - loss: 0.1229 - val_loss: 0.0115\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 365us/step - loss: 0.0238 - val_loss: 0.0128\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 366us/step - loss: 0.0177 - val_loss: 0.0167\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 367us/step - loss: 0.0150 - val_loss: 0.0121\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 367us/step - loss: 0.0112 - val_loss: 0.0080\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 365us/step - loss: 0.0103 - val_loss: 0.0069\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 365us/step - loss: 0.0083 - val_loss: 0.0090\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 364us/step - loss: 0.0083 - val_loss: 0.0122\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 368us/step - loss: 0.0078 - val_loss: 0.0076\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 365us/step - loss: 0.0081 - val_loss: 0.0118\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 363us/step - loss: 0.0083 - val_loss: 0.0080\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 364us/step - loss: 0.0074 - val_loss: 0.0154\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 364us/step - loss: 0.0065 - val_loss: 0.0045\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 365us/step - loss: 0.0052 - val_loss: 0.0041\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 363us/step - loss: 0.0053 - val_loss: 0.0074\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 364us/step - loss: 0.0075 - val_loss: 0.0078\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 365us/step - loss: 0.0076 - val_loss: 0.0059\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 366us/step - loss: 0.0062 - val_loss: 0.0116\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 365us/step - loss: 0.0070 - val_loss: 0.0039\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 366us/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 369us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 365us/step - loss: 0.0062 - val_loss: 0.0086\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 364us/step - loss: 0.0067 - val_loss: 0.0061\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 369us/step - loss: 0.0069 - val_loss: 0.0146\n",
      "\n",
      "GENERATION 10\n",
      "\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 14s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 550us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 551us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 551us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 551us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 550us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 554us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 551us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 550us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 550us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 550us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 550us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 551us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 550us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 559us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 552us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 552us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 551us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 551us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 551us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 550us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 551us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 552us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 553us/step - loss: nan - val_loss: nan\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 13s 4ms/step - loss: 0.1749 - val_loss: 0.0030\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 265us/step - loss: 0.0241 - val_loss: 0.0295\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 267us/step - loss: 0.0116 - val_loss: 0.0101\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 267us/step - loss: 0.0058 - val_loss: 0.0056\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 262us/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 265us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 264us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 264us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 264us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 265us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 264us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 264us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 265us/step - loss: 9.7690e-04 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 267us/step - loss: 9.3031e-04 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 267us/step - loss: 8.8447e-04 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 265us/step - loss: 8.4205e-04 - val_loss: 9.9351e-04\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 263us/step - loss: 7.8928e-04 - val_loss: 9.0405e-04\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 265us/step - loss: 7.4839e-04 - val_loss: 8.4952e-04\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 266us/step - loss: 7.1296e-04 - val_loss: 8.9292e-04\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 265us/step - loss: 7.0255e-04 - val_loss: 8.1809e-04\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 264us/step - loss: 6.8237e-04 - val_loss: 8.2120e-04\n",
      "Epoch 22/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3490/3490 [==============================] - 1s 264us/step - loss: 6.6428e-04 - val_loss: 7.8914e-04\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 265us/step - loss: 6.5567e-04 - val_loss: 7.9733e-04\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 263us/step - loss: 6.4214e-04 - val_loss: 7.8297e-04\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 15s 4ms/step - loss: 0.0778 - val_loss: 0.0204\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 552us/step - loss: 0.0086 - val_loss: 0.0055\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 551us/step - loss: 0.0046 - val_loss: 0.0027\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 552us/step - loss: 0.0028 - val_loss: 0.0040\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 553us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 552us/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 551us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 552us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 550us/step - loss: 0.0016 - val_loss: 0.0025\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 553us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 556us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 552us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 552us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 551us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 552us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 550us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 549us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 552us/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 554us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 551us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 553us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 549us/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 554us/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 553us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 15s 4ms/step - loss: 0.2783 - val_loss: 0.3497\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 580us/step - loss: 0.2124 - val_loss: 0.1115\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 580us/step - loss: 0.0673 - val_loss: 0.0605\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 580us/step - loss: 0.0307 - val_loss: 0.0075\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 580us/step - loss: 0.0060 - val_loss: 0.0061\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 580us/step - loss: 0.0058 - val_loss: 0.0036\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 582us/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 581us/step - loss: 0.0037 - val_loss: 0.0031\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 581us/step - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 581us/step - loss: 0.0030 - val_loss: 0.0026\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 578us/step - loss: 0.0029 - val_loss: 0.0025\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 580us/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 578us/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 579us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 583us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 583us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 579us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 579us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 581us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 577us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 582us/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 579us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 580us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 581us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 15s 4ms/step - loss: 0.0759 - val_loss: 0.0253\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 580us/step - loss: 0.0119 - val_loss: 0.0031\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 582us/step - loss: 0.0063 - val_loss: 0.0066\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 582us/step - loss: 0.0049 - val_loss: 0.0043\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 581us/step - loss: 0.0038 - val_loss: 0.0047\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 583us/step - loss: 0.0037 - val_loss: 0.0027\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 581us/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 579us/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 581us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 579us/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 578us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 582us/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 578us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 581us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 582us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 580us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 579us/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 581us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 581us/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 580us/step - loss: 0.0019 - val_loss: 0.0032\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 581us/step - loss: 0.0020 - val_loss: 0.0033\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 580us/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 577us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 577us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 15s 4ms/step - loss: 0.1747 - val_loss: 0.0630\n",
      "Epoch 2/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3490/3490 [==============================] - 2s 466us/step - loss: 0.0307 - val_loss: 0.0267\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 469us/step - loss: 0.0141 - val_loss: 0.0141\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 465us/step - loss: 0.0079 - val_loss: 0.0065\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 465us/step - loss: 0.0058 - val_loss: 0.0034\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 466us/step - loss: 0.0046 - val_loss: 0.0030\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 467us/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 467us/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 466us/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 466us/step - loss: 0.0033 - val_loss: 0.0045\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 468us/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 469us/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 468us/step - loss: 0.0029 - val_loss: 0.0044\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 467us/step - loss: 0.0029 - val_loss: 0.0043\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 464us/step - loss: 0.0029 - val_loss: 0.0055\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 468us/step - loss: 0.0027 - val_loss: 0.0050\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 469us/step - loss: 0.0027 - val_loss: 0.0065\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 468us/step - loss: 0.0026 - val_loss: 0.0062\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 465us/step - loss: 0.0026 - val_loss: 0.0066\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 468us/step - loss: 0.0025 - val_loss: 0.0082\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 466us/step - loss: 0.0024 - val_loss: 0.0091\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 469us/step - loss: 0.0024 - val_loss: 0.0084\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 467us/step - loss: 0.0024 - val_loss: 0.0073\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 467us/step - loss: 0.0022 - val_loss: 0.0074\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 16s 5ms/step - loss: 0.1907 - val_loss: 0.0303\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 522us/step - loss: 0.0166 - val_loss: 0.0475\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 484us/step - loss: 0.0198 - val_loss: 0.0199\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 497us/step - loss: 0.0136 - val_loss: 0.0188\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 490us/step - loss: 0.0165 - val_loss: 0.0175\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 497us/step - loss: 0.0158 - val_loss: 0.0138\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 496us/step - loss: 0.0136 - val_loss: 0.0125\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 486us/step - loss: 0.0131 - val_loss: 0.0109\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 484us/step - loss: 0.0117 - val_loss: 0.0280\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 477us/step - loss: 0.0103 - val_loss: 0.0149\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 479us/step - loss: 0.0108 - val_loss: 0.0158\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 484us/step - loss: 0.0111 - val_loss: 0.0146\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 490us/step - loss: 0.0092 - val_loss: 0.0218\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 496us/step - loss: 0.0106 - val_loss: 0.0064\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 479us/step - loss: 0.0080 - val_loss: 0.0155\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 472us/step - loss: 0.0091 - val_loss: 0.0078\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 474us/step - loss: 0.0076 - val_loss: 0.0152\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 502us/step - loss: 0.0082 - val_loss: 0.0057\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 477us/step - loss: 0.0079 - val_loss: 0.0068\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 494us/step - loss: 0.0063 - val_loss: 0.0175\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 487us/step - loss: 0.0084 - val_loss: 0.0125\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 500us/step - loss: 0.0067 - val_loss: 0.0077\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 474us/step - loss: 0.0071 - val_loss: 0.0102\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 473us/step - loss: 0.0057 - val_loss: 0.0156\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 17s 5ms/step - loss: 0.1673 - val_loss: 0.0067\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 510us/step - loss: 0.0091 - val_loss: 0.0046\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 482us/step - loss: 0.0073 - val_loss: 0.0361\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 514us/step - loss: 0.0167 - val_loss: 0.0124\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 519us/step - loss: 0.0121 - val_loss: 0.0332\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 502us/step - loss: 0.0147 - val_loss: 0.0109\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 498us/step - loss: 0.0098 - val_loss: 0.0169\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 483us/step - loss: 0.0124 - val_loss: 0.0129\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 483us/step - loss: 0.0091 - val_loss: 0.0160\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 518us/step - loss: 0.0103 - val_loss: 0.0090\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 494us/step - loss: 0.0112 - val_loss: 0.0118\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 498us/step - loss: 0.0066 - val_loss: 0.0134\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 481us/step - loss: 0.0093 - val_loss: 0.0111\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 523us/step - loss: 0.0078 - val_loss: 0.0113\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 487us/step - loss: 0.0069 - val_loss: 0.0062\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 483us/step - loss: 0.0087 - val_loss: 0.0047\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 473us/step - loss: 0.0062 - val_loss: 0.0101\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 484us/step - loss: 0.0075 - val_loss: 0.0051\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 477us/step - loss: 0.0057 - val_loss: 0.0109\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 505us/step - loss: 0.0076 - val_loss: 0.0057\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 483us/step - loss: 0.0046 - val_loss: 0.0069\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 491us/step - loss: 0.0065 - val_loss: 0.0096\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 488us/step - loss: 0.0051 - val_loss: 0.0046\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 482us/step - loss: 0.0065 - val_loss: 0.0071\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 17s 5ms/step - loss: 0.1025 - val_loss: 0.0729\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 482us/step - loss: 0.0199 - val_loss: 0.0102\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 481us/step - loss: 0.0111 - val_loss: 0.0091\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 481us/step - loss: 0.0078 - val_loss: 0.0101\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 472us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 469us/step - loss: 0.0068 - val_loss: 0.0109\n",
      "Epoch 7/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3490/3490 [==============================] - 2s 471us/step - loss: 0.0064 - val_loss: 0.0044\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 483us/step - loss: 0.0072 - val_loss: 0.0100\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 470us/step - loss: 0.0049 - val_loss: 0.0074\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 478us/step - loss: 0.0063 - val_loss: 0.0081\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 468us/step - loss: 0.0045 - val_loss: 0.0029\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 470us/step - loss: 0.0050 - val_loss: 0.0091\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 473us/step - loss: 0.0061 - val_loss: 0.0041\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 468us/step - loss: 0.0042 - val_loss: 0.0058\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 485us/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 469us/step - loss: 0.0058 - val_loss: 0.0087\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 472us/step - loss: 0.0047 - val_loss: 0.0024\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 472us/step - loss: 0.0046 - val_loss: 0.0070\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 476us/step - loss: 0.0049 - val_loss: 0.0023\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 477us/step - loss: 0.0034 - val_loss: 0.0053\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 468us/step - loss: 0.0039 - val_loss: 0.0033\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 468us/step - loss: 0.0034 - val_loss: 0.0050\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 485us/step - loss: 0.0036 - val_loss: 0.0031\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 487us/step - loss: 0.0031 - val_loss: 0.0040\n",
      "\n",
      "GENERATION 11\n",
      "\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 17s 5ms/step - loss: 0.0580 - val_loss: 0.0062\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 597us/step - loss: 0.0087 - val_loss: 0.0055\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 594us/step - loss: 0.0052 - val_loss: 0.0042\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 611us/step - loss: 0.0037 - val_loss: 0.0059\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 616us/step - loss: 0.0031 - val_loss: 0.0019\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 666us/step - loss: 0.0027 - val_loss: 0.0041\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 667us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 664us/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 657us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 666us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 662us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 669us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 660us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 662us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 622us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 605us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 594us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 623us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 615us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 616us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 586us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 598us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 605us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 600us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 16s 5ms/step - loss: 0.1493 - val_loss: 0.1018\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 274us/step - loss: 0.0218 - val_loss: 0.0120\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 269us/step - loss: 0.0076 - val_loss: 0.0047\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 268us/step - loss: 0.0040 - val_loss: 0.0028\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 268us/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 267us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 270us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 271us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 268us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 268us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 268us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 268us/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 267us/step - loss: 9.9603e-04 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 269us/step - loss: 9.5163e-04 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 268us/step - loss: 9.1529e-04 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 271us/step - loss: 8.7390e-04 - val_loss: 0.0010\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 274us/step - loss: 8.4124e-04 - val_loss: 9.5324e-04\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 268us/step - loss: 8.2871e-04 - val_loss: 9.2787e-04\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 269us/step - loss: 7.9675e-04 - val_loss: 8.9897e-04\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 266us/step - loss: 7.5539e-04 - val_loss: 8.8459e-04\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 267us/step - loss: 7.5272e-04 - val_loss: 9.5742e-04\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 271us/step - loss: 7.6459e-04 - val_loss: 8.6884e-04\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 272us/step - loss: 7.4407e-04 - val_loss: 8.4751e-04\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 293us/step - loss: 7.1023e-04 - val_loss: 8.5252e-04\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 18s 5ms/step - loss: 0.1769 - val_loss: 0.0112\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 467us/step - loss: 0.0303 - val_loss: 0.0264\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 456us/step - loss: 0.0139 - val_loss: 0.0081\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 452us/step - loss: 0.0059 - val_loss: 0.0039\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 456us/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 456us/step - loss: 0.0031 - val_loss: 0.0060\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 458us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 480us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 501us/step - loss: 0.0022 - val_loss: 0.0036\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 477us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 11/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3490/3490 [==============================] - 2s 468us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 471us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 491us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 471us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 463us/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 468us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 462us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 457us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 453us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 452us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 454us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 457us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 459us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 454us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 17s 5ms/step - loss: 0.1007 - val_loss: 0.0031\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 482us/step - loss: 0.0163 - val_loss: 0.0065\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 478us/step - loss: 0.0081 - val_loss: 0.0071\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 476us/step - loss: 0.0053 - val_loss: 0.0077\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 473us/step - loss: 0.0035 - val_loss: 0.0027\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 476us/step - loss: 0.0029 - val_loss: 0.0025\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 474us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 476us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 476us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 474us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 473us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 476us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 475us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 477us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 476us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 478us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 474us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 475us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 475us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 474us/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 476us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 475us/step - loss: 0.0015 - val_loss: 0.0024\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 477us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 478us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 18s 5ms/step - loss: 0.1003 - val_loss: 0.0382\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 472us/step - loss: 0.0779 - val_loss: 0.0734\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 471us/step - loss: 0.0759 - val_loss: 0.0354\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 475us/step - loss: 0.0710 - val_loss: 0.0196\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 481us/step - loss: 0.0667 - val_loss: 0.0202\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 474us/step - loss: 0.0578 - val_loss: 0.0206\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 474us/step - loss: 0.0537 - val_loss: 0.0088\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 476us/step - loss: 0.0511 - val_loss: 0.0236\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 476us/step - loss: 0.0525 - val_loss: 0.0393\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 479us/step - loss: 0.0516 - val_loss: 0.0601\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 475us/step - loss: 0.0518 - val_loss: 0.0701\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 473us/step - loss: 0.0522 - val_loss: 0.0726\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 476us/step - loss: 0.0524 - val_loss: 0.0753\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 476us/step - loss: 0.0525 - val_loss: 0.0756\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 475us/step - loss: 0.0523 - val_loss: 0.0743\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 477us/step - loss: 0.0517 - val_loss: 0.0737\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 474us/step - loss: 0.0512 - val_loss: 0.0692\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 476us/step - loss: 0.0506 - val_loss: 0.0590\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 475us/step - loss: 0.0500 - val_loss: 0.0533\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 473us/step - loss: 0.0473 - val_loss: 0.0469\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 474us/step - loss: 0.0356 - val_loss: 0.0348\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 479us/step - loss: 0.0191 - val_loss: 0.0504\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 481us/step - loss: 0.0106 - val_loss: 0.0529\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 479us/step - loss: 0.0074 - val_loss: 0.0535\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 19s 6ms/step - loss: 0.0741 - val_loss: 0.0262\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 531us/step - loss: 0.0166 - val_loss: 0.0045\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 501us/step - loss: 0.0099 - val_loss: 0.0145\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 486us/step - loss: 0.0061 - val_loss: 0.0084\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 478us/step - loss: 0.0044 - val_loss: 0.0037\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 487us/step - loss: 0.0033 - val_loss: 0.0043\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 486us/step - loss: 0.0028 - val_loss: 0.0045\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 522us/step - loss: 0.0026 - val_loss: 0.0056\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 500us/step - loss: 0.0025 - val_loss: 0.0058\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 490us/step - loss: 0.0024 - val_loss: 0.0053\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 509us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 503us/step - loss: 0.0022 - val_loss: 0.0034\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 508us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 486us/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 486us/step - loss: 0.0020 - val_loss: 0.0033\n",
      "Epoch 16/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3490/3490 [==============================] - 2s 478us/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 471us/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 471us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 471us/step - loss: 0.0019 - val_loss: 0.0033\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 470us/step - loss: 0.0019 - val_loss: 0.0030\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 469us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 471us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 476us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 472us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 18s 5ms/step - loss: 0.1343 - val_loss: 0.1087\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 483us/step - loss: 0.0715 - val_loss: 0.0238\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 485us/step - loss: 0.0370 - val_loss: 0.0069\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 474us/step - loss: 0.0103 - val_loss: 0.0164\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 479us/step - loss: 0.0090 - val_loss: 0.0385\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 478us/step - loss: 0.0063 - val_loss: 0.0179\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 474us/step - loss: 0.0056 - val_loss: 0.0091\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 479us/step - loss: 0.0049 - val_loss: 0.0184\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 476us/step - loss: 0.0044 - val_loss: 0.0162\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 473us/step - loss: 0.0041 - val_loss: 0.0079\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 476us/step - loss: 0.0036 - val_loss: 0.0056\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 476us/step - loss: 0.0034 - val_loss: 0.0065\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 475us/step - loss: 0.0032 - val_loss: 0.0049\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 481us/step - loss: 0.0030 - val_loss: 0.0036\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 476us/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 476us/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 476us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 475us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 473us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 474us/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 474us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 478us/step - loss: 0.0023 - val_loss: 0.0042\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 484us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 476us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 19s 5ms/step - loss: 0.4361 - val_loss: 0.2188\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 474us/step - loss: 0.1119 - val_loss: 0.0276\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 474us/step - loss: 0.0691 - val_loss: 0.0232\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 475us/step - loss: 0.0577 - val_loss: 0.0140\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 484us/step - loss: 0.0336 - val_loss: 0.0139\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 480us/step - loss: 0.0097 - val_loss: 0.0486\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 480us/step - loss: 0.0072 - val_loss: 0.0059\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 478us/step - loss: 0.0056 - val_loss: 0.0188\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 477us/step - loss: 0.0042 - val_loss: 0.0172\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 485us/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 493us/step - loss: 0.0033 - val_loss: 0.0046\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 483us/step - loss: 0.0031 - val_loss: 0.0047\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 472us/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 478us/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 484us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 505us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 491us/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 480us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 479us/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 483us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 480us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 472us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 472us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 476us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 19s 5ms/step - loss: 0.8279 - val_loss: 0.0067\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 480us/step - loss: 0.1282 - val_loss: 0.0160\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 476us/step - loss: 0.0770 - val_loss: 0.0790\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 476us/step - loss: 0.0761 - val_loss: 0.0364\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 485us/step - loss: 0.0697 - val_loss: 0.0209\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 482us/step - loss: 0.0627 - val_loss: 0.0184\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 476us/step - loss: 0.0513 - val_loss: 0.0188\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 483us/step - loss: 0.0676 - val_loss: 0.0395\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 479us/step - loss: 0.0688 - val_loss: 0.0216\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 472us/step - loss: 0.0623 - val_loss: 0.0260\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 472us/step - loss: 0.0370 - val_loss: 0.0093\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 473us/step - loss: 0.0089 - val_loss: 0.0128\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 480us/step - loss: 0.0071 - val_loss: 0.0170\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 478us/step - loss: 0.0061 - val_loss: 0.0080\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 473us/step - loss: 0.0055 - val_loss: 0.0165\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 476us/step - loss: 0.0052 - val_loss: 0.0068\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 482us/step - loss: 0.0055 - val_loss: 0.0091\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 485us/step - loss: 0.0049 - val_loss: 0.0070\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 486us/step - loss: 0.0043 - val_loss: 0.0054\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 482us/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 21/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3490/3490 [==============================] - 2s 473us/step - loss: 0.0040 - val_loss: 0.0052\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 480us/step - loss: 0.0039 - val_loss: 0.0041\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 488us/step - loss: 0.0036 - val_loss: 0.0032\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 474us/step - loss: 0.0035 - val_loss: 0.0032\n",
      "\n",
      "GENERATION 12\n",
      "\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 18s 5ms/step - loss: 0.1782 - val_loss: 0.0041\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 269us/step - loss: 0.0293 - val_loss: 0.0370\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 269us/step - loss: 0.0141 - val_loss: 0.0168\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 267us/step - loss: 0.0064 - val_loss: 0.0061\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 267us/step - loss: 0.0037 - val_loss: 0.0052\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 268us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 269us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 268us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 267us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 267us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 273us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 269us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 271us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 273us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 274us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 270us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 271us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 9.8027e-04 - val_loss: 0.0013\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 9.2065e-04 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 273us/step - loss: 8.7779e-04 - val_loss: 0.0010\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 268us/step - loss: 8.2804e-04 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 274us/step - loss: 8.1216e-04 - val_loss: 9.4406e-04\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 277us/step - loss: 7.8503e-04 - val_loss: 9.2339e-04\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 270us/step - loss: 7.7393e-04 - val_loss: 9.0190e-04\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 19s 5ms/step - loss: 0.1458 - val_loss: 0.0905\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 268us/step - loss: 0.0210 - val_loss: 0.0149\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 271us/step - loss: 0.0081 - val_loss: 0.0044\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 268us/step - loss: 0.0044 - val_loss: 0.0023\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 267us/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 268us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 267us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 266us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 268us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 268us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 269us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 268us/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 275us/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 274us/step - loss: 9.8151e-04 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 269us/step - loss: 9.3906e-04 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 270us/step - loss: 8.9954e-04 - val_loss: 0.0010\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 269us/step - loss: 8.5650e-04 - val_loss: 0.0010\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 266us/step - loss: 8.0557e-04 - val_loss: 9.3033e-04\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 269us/step - loss: 7.6595e-04 - val_loss: 8.7671e-04\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 269us/step - loss: 7.3158e-04 - val_loss: 8.3927e-04\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 266us/step - loss: 7.1008e-04 - val_loss: 8.2616e-04\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 268us/step - loss: 6.9924e-04 - val_loss: 8.4302e-04\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 270us/step - loss: 7.0292e-04 - val_loss: 8.9635e-04\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 269us/step - loss: 6.8892e-04 - val_loss: 8.0480e-04\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 19s 5ms/step - loss: 0.0688 - val_loss: 0.0300\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 229us/step - loss: 0.0184 - val_loss: 0.0125\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 229us/step - loss: 0.0076 - val_loss: 0.0015\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 228us/step - loss: 0.0046 - val_loss: 0.0022\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 228us/step - loss: 0.0028 - val_loss: 0.0059\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 229us/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 229us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 231us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 233us/step - loss: 0.0013 - val_loss: 0.0028\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 227us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 229us/step - loss: 0.0010 - val_loss: 0.0018\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 228us/step - loss: 9.6037e-04 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 228us/step - loss: 8.9405e-04 - val_loss: 0.0015\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 231us/step - loss: 8.4536e-04 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 228us/step - loss: 8.0958e-04 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 228us/step - loss: 7.9107e-04 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 229us/step - loss: 7.7516e-04 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 230us/step - loss: 7.6492e-04 - val_loss: 9.3050e-04\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 235us/step - loss: 7.3295e-04 - val_loss: 8.7428e-04\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 230us/step - loss: 7.2169e-04 - val_loss: 9.7961e-04\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 230us/step - loss: 7.1135e-04 - val_loss: 9.6230e-04\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 229us/step - loss: 7.0162e-04 - val_loss: 8.7296e-04\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 230us/step - loss: 6.8739e-04 - val_loss: 8.2212e-04\n",
      "Epoch 24/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3490/3490 [==============================] - 1s 229us/step - loss: 6.7902e-04 - val_loss: 8.0758e-04\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 20s 6ms/step - loss: 0.0706 - val_loss: 0.0222\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 470us/step - loss: 0.0160 - val_loss: 0.0125\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 488us/step - loss: 0.0088 - val_loss: 0.0061\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 468us/step - loss: 0.0050 - val_loss: 0.0066\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 468us/step - loss: 0.0029 - val_loss: 0.0047\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 471us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 487us/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 476us/step - loss: 0.0017 - val_loss: 0.0027\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 477us/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 481us/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 480us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 475us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 482us/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 471us/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 480us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 472us/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 469us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 468us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 473us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 470us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 470us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 468us/step - loss: 0.0012 - val_loss: 0.0035\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 469us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 467us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 20s 6ms/step - loss: 0.0533 - val_loss: 0.0105\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 469us/step - loss: 0.0093 - val_loss: 0.0028\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 471us/step - loss: 0.0063 - val_loss: 0.0029\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 481us/step - loss: 0.0037 - val_loss: 0.0067\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 484us/step - loss: 0.0023 - val_loss: 0.0057\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 475us/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 470us/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 470us/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 470us/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 470us/step - loss: 0.0014 - val_loss: 0.0022\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 483us/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 492us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 471us/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 469us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 471us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 475us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 471us/step - loss: 0.0011 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 473us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 472us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 474us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 472us/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 483us/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 467us/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 469us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 21s 6ms/step - loss: 0.0670 - val_loss: 0.0150\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 470us/step - loss: 0.0178 - val_loss: 0.0156\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 470us/step - loss: 0.0094 - val_loss: 0.0104\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 469us/step - loss: 0.0063 - val_loss: 0.0025\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 468us/step - loss: 0.0042 - val_loss: 0.0079\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 472us/step - loss: 0.0029 - val_loss: 0.0062\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 472us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 470us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 476us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 470us/step - loss: 0.0020 - val_loss: 0.0030\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 468us/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 474us/step - loss: 0.0019 - val_loss: 0.0033\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 471us/step - loss: 0.0019 - val_loss: 0.0031\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 470us/step - loss: 0.0019 - val_loss: 0.0034\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 470us/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 472us/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 472us/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 468us/step - loss: 0.0017 - val_loss: 0.0026\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 472us/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 468us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 470us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 470us/step - loss: 0.0017 - val_loss: 0.0032\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 469us/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 470us/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 21s 6ms/step - loss: 0.0522 - val_loss: 0.0035\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 469us/step - loss: 0.0083 - val_loss: 0.0054\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 471us/step - loss: 0.0064 - val_loss: 0.0025\n",
      "Epoch 4/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3490/3490 [==============================] - 2s 474us/step - loss: 0.0049 - val_loss: 0.0061\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 472us/step - loss: 0.0036 - val_loss: 0.0079\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 474us/step - loss: 0.0029 - val_loss: 0.0048\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 470us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 470us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 476us/step - loss: 0.0022 - val_loss: 0.0034\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 474us/step - loss: 0.0021 - val_loss: 0.0034\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 472us/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 472us/step - loss: 0.0019 - val_loss: 0.0036\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 472us/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 469us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 476us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 472us/step - loss: 0.0018 - val_loss: 0.0036\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 473us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 474us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 476us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 472us/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 476us/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 469us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 470us/step - loss: 0.0016 - val_loss: 0.0031\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 473us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 21s 6ms/step - loss: 0.0498 - val_loss: 0.0071\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 473us/step - loss: 0.0101 - val_loss: 0.0026\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 472us/step - loss: 0.0079 - val_loss: 0.0081\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 472us/step - loss: 0.0051 - val_loss: 0.0070\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 472us/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 471us/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 473us/step - loss: 0.0025 - val_loss: 0.0045\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 471us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 472us/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 470us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 480us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 474us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 472us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 473us/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 474us/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 475us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 474us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 472us/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 473us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 475us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 476us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 473us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 476us/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 474us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 22s 6ms/step - loss: 0.0894 - val_loss: 0.0183\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 472us/step - loss: 0.0156 - val_loss: 0.0160\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 474us/step - loss: 0.0086 - val_loss: 0.0107\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 472us/step - loss: 0.0063 - val_loss: 0.0048\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 472us/step - loss: 0.0037 - val_loss: 0.0049\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 477us/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 473us/step - loss: 0.0027 - val_loss: 0.0052\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 484us/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 492us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 484us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 473us/step - loss: 0.0021 - val_loss: 0.0036\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 490us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 524us/step - loss: 0.0020 - val_loss: 0.0032\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 500us/step - loss: 0.0019 - val_loss: 0.0032\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 510us/step - loss: 0.0019 - val_loss: 0.0037\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 476us/step - loss: 0.0019 - val_loss: 0.0035\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 477us/step - loss: 0.0018 - val_loss: 0.0034\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 480us/step - loss: 0.0018 - val_loss: 0.0033\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 476us/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 474us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 493us/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 499us/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 515us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 528us/step - loss: 0.0016 - val_loss: 0.0028\n",
      "\n",
      "GENERATION 13\n",
      "\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 21s 6ms/step - loss: 0.9271 - val_loss: 0.4697\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 200us/step - loss: 0.1165 - val_loss: 0.1013\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 200us/step - loss: 0.0569 - val_loss: 0.0095\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 200us/step - loss: 0.0201 - val_loss: 0.0029\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 208us/step - loss: 0.0085 - val_loss: 0.0266\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 200us/step - loss: 0.0090 - val_loss: 0.0105\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 199us/step - loss: 0.0038 - val_loss: 0.0014\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 199us/step - loss: 0.0037 - val_loss: 0.0059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 199us/step - loss: 0.0026 - val_loss: 0.0085\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 198us/step - loss: 0.0021 - val_loss: 0.0039\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 200us/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 204us/step - loss: 0.0016 - val_loss: 0.0053\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 198us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 200us/step - loss: 0.0014 - val_loss: 0.0035\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 200us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 200us/step - loss: 0.0012 - val_loss: 0.0037\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 199us/step - loss: 0.0012 - val_loss: 0.0034\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 200us/step - loss: 0.0011 - val_loss: 0.0034\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 201us/step - loss: 0.0011 - val_loss: 0.0033\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 204us/step - loss: 0.0010 - val_loss: 0.0032\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 219us/step - loss: 0.0010 - val_loss: 0.0031\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 220us/step - loss: 9.9727e-04 - val_loss: 0.0030\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 249us/step - loss: 9.7901e-04 - val_loss: 0.0030\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 235us/step - loss: 9.6402e-04 - val_loss: 0.0029\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 23s 7ms/step - loss: 0.0644 - val_loss: 0.0319\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 278us/step - loss: 0.0148 - val_loss: 0.0183\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 263us/step - loss: 0.0058 - val_loss: 0.0022\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 261us/step - loss: 0.0036 - val_loss: 0.0074\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 260us/step - loss: 0.0025 - val_loss: 0.0011\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 255us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 252us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 260us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 269us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 254us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 255us/step - loss: 9.9323e-04 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 253us/step - loss: 9.3210e-04 - val_loss: 0.0016\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 255us/step - loss: 8.9053e-04 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 260us/step - loss: 8.4626e-04 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 258us/step - loss: 8.1021e-04 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 260us/step - loss: 7.8304e-04 - val_loss: 9.4622e-04\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 271us/step - loss: 7.5359e-04 - val_loss: 9.9785e-04\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 254us/step - loss: 7.2872e-04 - val_loss: 9.7980e-04\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 256us/step - loss: 7.1027e-04 - val_loss: 8.2868e-04\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 254us/step - loss: 6.9490e-04 - val_loss: 8.0496e-04\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 253us/step - loss: 6.7836e-04 - val_loss: 7.7255e-04\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 253us/step - loss: 6.7501e-04 - val_loss: 7.5644e-04\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 253us/step - loss: 6.6329e-04 - val_loss: 7.8631e-04\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 252us/step - loss: 6.5350e-04 - val_loss: 7.6904e-04\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 23s 7ms/step - loss: 0.1047 - val_loss: 0.0499\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 256us/step - loss: 0.0155 - val_loss: 0.0144\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 275us/step - loss: 0.0063 - val_loss: 0.0013\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 266us/step - loss: 0.0038 - val_loss: 0.0017\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 274us/step - loss: 0.0020 - val_loss: 0.0062\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 257us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 253us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 252us/step - loss: 0.0014 - val_loss: 0.0027\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 248us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 258us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 261us/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 257us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 306us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 291us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 257us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 278us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 262us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 260us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 254us/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 248us/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 249us/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 249us/step - loss: 9.8838e-04 - val_loss: 0.0014\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 260us/step - loss: 9.7411e-04 - val_loss: 0.0014\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 23s 7ms/step - loss: 0.1383 - val_loss: 0.0808\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 211us/step - loss: 0.0212 - val_loss: 0.0196\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 211us/step - loss: 0.0105 - val_loss: 0.0016\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 208us/step - loss: 0.0039 - val_loss: 0.0031\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 210us/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 212us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 211us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 221us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 227us/step - loss: 0.0012 - val_loss: 0.0026\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 218us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 207us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 218us/step - loss: 0.0011 - val_loss: 0.0019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 220us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 226us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 213us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 214us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 209us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 209us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 219us/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 210us/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 210us/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 222us/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 211us/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 218us/step - loss: 9.9933e-04 - val_loss: 0.0015\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 23s 7ms/step - loss: 0.1040 - val_loss: 0.0018\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 226us/step - loss: 0.0031 - val_loss: 0.0024\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 222us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 225us/step - loss: 0.0027 - val_loss: 0.0098\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 220us/step - loss: 0.0046 - val_loss: 0.0017\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 231us/step - loss: 0.0027 - val_loss: 0.0043\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 222us/step - loss: 0.0021 - val_loss: 0.0010\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 213us/step - loss: 0.0023 - val_loss: 0.0048\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 222us/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 231us/step - loss: 0.0044 - val_loss: 0.0064\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 214us/step - loss: 0.0023 - val_loss: 9.3942e-04\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 212us/step - loss: 0.0016 - val_loss: 0.0031\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 214us/step - loss: 0.0016 - val_loss: 9.1215e-04\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 230us/step - loss: 0.0019 - val_loss: 0.0048\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 225us/step - loss: 0.0038 - val_loss: 0.0054\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 220us/step - loss: 0.0060 - val_loss: 0.0107\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 213us/step - loss: 0.0044 - val_loss: 0.0015\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 217us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 212us/step - loss: 0.0014 - val_loss: 8.7892e-04\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 216us/step - loss: 0.0014 - val_loss: 0.0032\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 218us/step - loss: 0.0013 - val_loss: 9.3126e-04\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 212us/step - loss: 0.0022 - val_loss: 0.0036\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 216us/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 217us/step - loss: 0.0050 - val_loss: 0.0090\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 25s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 257us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 256us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 257us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 257us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 258us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 264us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 267us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 280us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 262us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 256us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 272us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 270us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 273us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 276us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 272us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 268us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 270us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 264us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 270us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 273us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 274us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 268us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 258us/step - loss: nan - val_loss: nan\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 26s 8ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 551us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 544us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 546us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 561us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 571us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 567us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 557us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 559us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 554us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 558us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 555us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 570us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 563us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 559us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 554us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 547us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 563us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 532us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3490/3490 [==============================] - 2s 538us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 536us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 536us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 543us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 533us/step - loss: nan - val_loss: nan\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 27s 8ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 552us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 547us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 566us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 536us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 541us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 550us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 545us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 541us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 535us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 550us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 535us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 537us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 533us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 535us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 537us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 539us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 540us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 534us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 541us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 537us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 544us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 537us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 538us/step - loss: nan - val_loss: nan\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 27s 8ms/step - loss: 0.0893 - val_loss: 0.0025\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 552us/step - loss: 0.0044 - val_loss: 0.0039\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 557us/step - loss: 0.0071 - val_loss: 0.0311\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 555us/step - loss: 0.0064 - val_loss: 0.0032\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 551us/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 510us/step - loss: 0.0031 - val_loss: 0.0020\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 502us/step - loss: 0.0050 - val_loss: 0.0083\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 526us/step - loss: 0.0043 - val_loss: 0.0034\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 521us/step - loss: 0.0068 - val_loss: 0.0090\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 505us/step - loss: 0.0043 - val_loss: 0.0023\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 515us/step - loss: 0.0044 - val_loss: 0.0071\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 544us/step - loss: 0.0033 - val_loss: 0.0018\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 550us/step - loss: 0.0029 - val_loss: 0.0058\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 548us/step - loss: 0.0053 - val_loss: 0.0074\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 506us/step - loss: 0.0076 - val_loss: 0.0045\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 546us/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 549us/step - loss: 0.0029 - val_loss: 0.0058\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 556us/step - loss: 0.0045 - val_loss: 0.0026\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 551us/step - loss: 0.0040 - val_loss: 0.0081\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 538us/step - loss: 0.0032 - val_loss: 0.0016\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 528us/step - loss: 0.0030 - val_loss: 0.0073\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 522us/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 508us/step - loss: 0.0030 - val_loss: 0.0094\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 519us/step - loss: 0.0056 - val_loss: 0.0056\n",
      "\n",
      "GENERATION 14\n",
      "\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 25s 7ms/step - loss: 0.1528 - val_loss: 0.0021\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 289us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 279us/step - loss: 0.0209 - val_loss: 0.0011\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 0.0016 - val_loss: 0.0030\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 0.0106 - val_loss: 0.0617\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 0.0120 - val_loss: 0.0115\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 0.0080 - val_loss: 0.0148\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 310us/step - loss: 0.0095 - val_loss: 0.0154\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 306us/step - loss: 0.0081 - val_loss: 0.0157\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 302us/step - loss: 0.0132 - val_loss: 0.0104\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 297us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 310us/step - loss: 0.0099 - val_loss: 0.0204\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 279us/step - loss: 0.0086 - val_loss: 9.0315e-04\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 0.0019 - val_loss: 0.0136\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 280us/step - loss: 0.0100 - val_loss: 0.0201\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 307us/step - loss: 0.0082 - val_loss: 0.0038\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 300us/step - loss: 0.0022 - val_loss: 0.0095\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 0.0081 - val_loss: 0.0187\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 0.0063 - val_loss: 9.2288e-04\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 0.0018 - val_loss: 0.0117\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 0.0094 - val_loss: 0.0171\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 279us/step - loss: 0.0054 - val_loss: 0.0019\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 279us/step - loss: 9.3341e-04 - val_loss: 0.0012\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 25s 7ms/step - loss: 0.0870 - val_loss: 0.0027\n",
      "Epoch 2/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3490/3490 [==============================] - 1s 277us/step - loss: 0.0086 - val_loss: 0.0024\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 278us/step - loss: 0.0042 - val_loss: 0.0026\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 277us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 278us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 278us/step - loss: 0.0014 - val_loss: 0.0022\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 279us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - ETA: 0s - loss: 0.001 - 1s 281us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 9.6843e-04 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 279us/step - loss: 9.1471e-04 - val_loss: 0.0010\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 279us/step - loss: 8.5148e-04 - val_loss: 9.9155e-04\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 7.9690e-04 - val_loss: 9.2207e-04\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 7.4827e-04 - val_loss: 8.6918e-04\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 7.1406e-04 - val_loss: 8.2978e-04\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 280us/step - loss: 6.9357e-04 - val_loss: 8.4085e-04\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 279us/step - loss: 6.9931e-04 - val_loss: 8.8489e-04\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 278us/step - loss: 6.9308e-04 - val_loss: 8.2982e-04\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 278us/step - loss: 6.7885e-04 - val_loss: 8.0327e-04\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 6.6201e-04 - val_loss: 7.6951e-04\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 304us/step - loss: 6.8540e-04 - val_loss: 7.5459e-04\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 308us/step - loss: 6.5218e-04 - val_loss: 9.4188e-04\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 6.7103e-04 - val_loss: 7.4610e-04\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 25s 7ms/step - loss: 0.7796 - val_loss: 0.2112\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 278us/step - loss: 0.1001 - val_loss: 0.0522\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 280us/step - loss: 0.0212 - val_loss: 0.0106\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 278us/step - loss: 0.0139 - val_loss: 0.0181\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 0.0086 - val_loss: 0.0046\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 0.0066 - val_loss: 0.0116\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 0.0049 - val_loss: 0.0012\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 280us/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 0.0035 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 0.0033 - val_loss: 0.0019\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 0.0031 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 280us/step - loss: 0.0027 - val_loss: 0.0015\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 288us/step - loss: 0.0027 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 299us/step - loss: 0.0026 - val_loss: 0.0014\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 294us/step - loss: 0.0025 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 279us/step - loss: 0.0024 - val_loss: 0.0015\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 0.0023 - val_loss: 0.0013\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 287us/step - loss: 0.0024 - val_loss: 0.0014\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 289us/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 295us/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 27s 8ms/step - loss: 6.1157 - val_loss: 0.6288\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 300us/step - loss: 0.4263 - val_loss: 0.0853\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 300us/step - loss: 0.1428 - val_loss: 0.2785\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 299us/step - loss: 0.1300 - val_loss: 0.0196\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 299us/step - loss: 0.0945 - val_loss: 0.0077\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 310us/step - loss: 0.0761 - val_loss: 0.0740\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 301us/step - loss: 0.0772 - val_loss: 0.0426\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 322us/step - loss: 0.0709 - val_loss: 0.0181\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 306us/step - loss: 0.0686 - val_loss: 0.0408\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 299us/step - loss: 0.0666 - val_loss: 0.0354\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 298us/step - loss: 0.0637 - val_loss: 0.0247\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 299us/step - loss: 0.0569 - val_loss: 0.0285\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 302us/step - loss: 0.0381 - val_loss: 0.0053\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 307us/step - loss: 0.0231 - val_loss: 0.0225\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 310us/step - loss: 0.0235 - val_loss: 0.0197\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 317us/step - loss: 0.0137 - val_loss: 0.0210\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 318us/step - loss: 0.0111 - val_loss: 0.0233\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 321us/step - loss: 0.0095 - val_loss: 0.0142\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 314us/step - loss: 0.0073 - val_loss: 0.0128\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 320us/step - loss: 0.0061 - val_loss: 0.0234\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 314us/step - loss: 0.0058 - val_loss: 0.0195\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 312us/step - loss: 0.0055 - val_loss: 0.0137\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 314us/step - loss: 0.0054 - val_loss: 0.0162\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 297us/step - loss: 0.0050 - val_loss: 0.0138\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 29s 8ms/step - loss: 1.7284 - val_loss: 0.3212\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 635us/step - loss: 0.1580 - val_loss: 0.0457\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 638us/step - loss: 0.0853 - val_loss: 0.0847\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 640us/step - loss: 0.0742 - val_loss: 0.0240\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 642us/step - loss: 0.0647 - val_loss: 0.0094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 643us/step - loss: 0.0488 - val_loss: 0.0048\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 650us/step - loss: 0.0160 - val_loss: 0.0088\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 641us/step - loss: 0.0092 - val_loss: 0.0203\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 638us/step - loss: 0.0084 - val_loss: 0.0110\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 642us/step - loss: 0.0058 - val_loss: 0.0071\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 669us/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 652us/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 644us/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 642us/step - loss: 0.0042 - val_loss: 0.0052\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 639us/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 653us/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 682us/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 643us/step - loss: 0.0038 - val_loss: 0.0031\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 653us/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 648us/step - loss: 0.0037 - val_loss: 0.0032\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 645us/step - loss: 0.0035 - val_loss: 0.0033\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 663us/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 682us/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 653us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 29s 8ms/step - loss: 0.0610 - val_loss: 0.0023\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 640us/step - loss: 0.0087 - val_loss: 0.0060\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 643us/step - loss: 0.0061 - val_loss: 0.0027\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 639us/step - loss: 0.0042 - val_loss: 0.0068\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 637us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 636us/step - loss: 0.0030 - val_loss: 0.0025\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 637us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 637us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 638us/step - loss: 0.0026 - val_loss: 0.0020\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 635us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 647us/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 643us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 638us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 636us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 655us/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 652us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 664us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 601us/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 627us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 647us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 640us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 639us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 641us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 637us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 30s 9ms/step - loss: 0.0687 - val_loss: 0.0682\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 650us/step - loss: 0.0158 - val_loss: 0.0161\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 640us/step - loss: 0.0120 - val_loss: 0.0154\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 633us/step - loss: 0.0116 - val_loss: 0.0129\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 642us/step - loss: 0.0066 - val_loss: 0.0029\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 608us/step - loss: 0.0059 - val_loss: 0.0144\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 616us/step - loss: 0.0090 - val_loss: 0.0084\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 635us/step - loss: 0.0080 - val_loss: 0.0125\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 631us/step - loss: 0.0077 - val_loss: 0.0055\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 658us/step - loss: 0.0092 - val_loss: 0.0125\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 652us/step - loss: 0.0077 - val_loss: 0.0051\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 656us/step - loss: 0.0081 - val_loss: 0.0094\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 651us/step - loss: 0.0064 - val_loss: 0.0081\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 644us/step - loss: 0.0095 - val_loss: 0.0103\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 637us/step - loss: 0.0072 - val_loss: 0.0051\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 640us/step - loss: 0.0059 - val_loss: 0.0092\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 635us/step - loss: 0.0053 - val_loss: 0.0034\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 661us/step - loss: 0.0062 - val_loss: 0.0098\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 630us/step - loss: 0.0059 - val_loss: 0.0052\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 644us/step - loss: 0.0075 - val_loss: 0.0150\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 638us/step - loss: 0.0071 - val_loss: 0.0077\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 639us/step - loss: 0.0079 - val_loss: 0.0078\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 637us/step - loss: 0.0042 - val_loss: 0.0029\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 639us/step - loss: 0.0055 - val_loss: 0.0102\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 31s 9ms/step - loss: 0.0623 - val_loss: 0.0055\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 622us/step - loss: 0.0052 - val_loss: 0.0059\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 643us/step - loss: 0.0089 - val_loss: 0.0184\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 608us/step - loss: 0.0104 - val_loss: 0.0042\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 620us/step - loss: 0.0053 - val_loss: 0.0123\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 659us/step - loss: 0.0060 - val_loss: 0.0051\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 639us/step - loss: 0.0069 - val_loss: 0.0176\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 620us/step - loss: 0.0089 - val_loss: 0.0065\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 612us/step - loss: 0.0071 - val_loss: 0.0090\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 632us/step - loss: 0.0056 - val_loss: 0.0061\n",
      "Epoch 11/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3490/3490 [==============================] - 2s 619us/step - loss: 0.0061 - val_loss: 0.0153\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 621us/step - loss: 0.0081 - val_loss: 0.0092\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 610us/step - loss: 0.0081 - val_loss: 0.0116\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 605us/step - loss: 0.0079 - val_loss: 0.0046\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 600us/step - loss: 0.0062 - val_loss: 0.0113\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 615us/step - loss: 0.0078 - val_loss: 0.0054\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 592us/step - loss: 0.0055 - val_loss: 0.0123\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 600us/step - loss: 0.0058 - val_loss: 0.0054\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 596us/step - loss: 0.0063 - val_loss: 0.0087\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 594us/step - loss: 0.0041 - val_loss: 0.0022\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 601us/step - loss: 0.0059 - val_loss: 0.0112\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 617us/step - loss: 0.0070 - val_loss: 0.0062\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 627us/step - loss: 0.0059 - val_loss: 0.0129\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 620us/step - loss: 0.0064 - val_loss: 0.0067\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 30s 9ms/step - loss: 0.1060 - val_loss: 0.0024\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 609us/step - loss: 0.0033 - val_loss: 0.0025\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 597us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 598us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 594us/step - loss: 0.0026 - val_loss: 0.0039\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 596us/step - loss: 0.0054 - val_loss: 0.0222\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 597us/step - loss: 0.0149 - val_loss: 0.0098\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 595us/step - loss: 0.0058 - val_loss: 0.0076\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 601us/step - loss: 0.0098 - val_loss: 0.0147\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 595us/step - loss: 0.0109 - val_loss: 0.0092\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 597us/step - loss: 0.0074 - val_loss: 0.0122\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 597us/step - loss: 0.0072 - val_loss: 0.0060\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 598us/step - loss: 0.0084 - val_loss: 0.0138\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 594us/step - loss: 0.0082 - val_loss: 0.0079\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 596us/step - loss: 0.0072 - val_loss: 0.0114\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 600us/step - loss: 0.0071 - val_loss: 0.0087\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 598us/step - loss: 0.0070 - val_loss: 0.0125\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 609us/step - loss: 0.0086 - val_loss: 0.0093\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 626us/step - loss: 0.0058 - val_loss: 0.0102\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 597us/step - loss: 0.0068 - val_loss: 0.0118\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 598us/step - loss: 0.0078 - val_loss: 0.0127\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 601us/step - loss: 0.0080 - val_loss: 0.0066\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 606us/step - loss: 0.0069 - val_loss: 0.0105\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 624us/step - loss: 0.0070 - val_loss: 0.0051\n",
      "\n",
      "GENERATION 15\n",
      "\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 27s 8ms/step - loss: 6.1519 - val_loss: 0.5001\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 0.3253 - val_loss: 0.5063\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 0.1824 - val_loss: 0.0064\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 0.1188 - val_loss: 0.0072\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 0.0775 - val_loss: 0.0769\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 278us/step - loss: 0.0824 - val_loss: 0.0541\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 277us/step - loss: 0.0732 - val_loss: 0.0194\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 277us/step - loss: 0.0740 - val_loss: 0.0259\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 276us/step - loss: 0.0718 - val_loss: 0.0411\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 277us/step - loss: 0.0719 - val_loss: 0.0365\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 276us/step - loss: 0.0714 - val_loss: 0.0293\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 276us/step - loss: 0.0713 - val_loss: 0.0331\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 279us/step - loss: 0.0710 - val_loss: 0.0349\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 279us/step - loss: 0.0707 - val_loss: 0.0324\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 0.0702 - val_loss: 0.0324\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 290us/step - loss: 0.0689 - val_loss: 0.0310\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 0.0655 - val_loss: 0.0262\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 275us/step - loss: 0.0617 - val_loss: 0.0218\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 0.0565 - val_loss: 0.0258\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 0.0525 - val_loss: 0.0081\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 280us/step - loss: 0.0486 - val_loss: 0.0062\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 276us/step - loss: 0.0800 - val_loss: 0.0589\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 277us/step - loss: 0.0763 - val_loss: 0.0405\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 277us/step - loss: 0.0705 - val_loss: 0.0184\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 27s 8ms/step - loss: 0.1236 - val_loss: 0.0443\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 272us/step - loss: 0.0147 - val_loss: 0.0129\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 275us/step - loss: 0.0064 - val_loss: 0.0068\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 275us/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 273us/step - loss: 0.0021 - val_loss: 0.0031\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 272us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 273us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 276us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 278us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 273us/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 275us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 273us/step - loss: 9.7108e-04 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 273us/step - loss: 9.3369e-04 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 272us/step - loss: 8.9450e-04 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 273us/step - loss: 8.5227e-04 - val_loss: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 272us/step - loss: 8.1376e-04 - val_loss: 9.9781e-04\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 273us/step - loss: 7.9125e-04 - val_loss: 9.0351e-04\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 273us/step - loss: 7.6088e-04 - val_loss: 8.6025e-04\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 273us/step - loss: 7.3744e-04 - val_loss: 8.2820e-04\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 273us/step - loss: 6.9591e-04 - val_loss: 7.9952e-04\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 273us/step - loss: 6.7906e-04 - val_loss: 7.7580e-04\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 275us/step - loss: 6.5559e-04 - val_loss: 7.7944e-04\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 274us/step - loss: 6.4595e-04 - val_loss: 7.3846e-04\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 6.3213e-04 - val_loss: 7.5172e-04\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 28s 8ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 490us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 488us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 487us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 489us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 488us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 493us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 491us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 488us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 488us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 489us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 492us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 490us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 491us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 489us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 489us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 491us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 490us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 490us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 491us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 490us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 489us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 488us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 492us/step - loss: nan - val_loss: nan\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 29s 8ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 582us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 579us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 578us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 582us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 597us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 579us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 578us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 593us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 591us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 585us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 606us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 610us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 582us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 580us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 580us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 580us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 588us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 579us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 578us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 589us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 591us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 578us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 581us/step - loss: nan - val_loss: nan\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 30s 8ms/step - loss: 0.0796 - val_loss: 0.0049\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 542us/step - loss: 0.0112 - val_loss: 0.0060\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 541us/step - loss: 0.0080 - val_loss: 0.0099\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 549us/step - loss: 0.0049 - val_loss: 0.0030\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 568us/step - loss: 0.0039 - val_loss: 0.0061\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 548us/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 541us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 540us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 539us/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 542us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 539us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 539us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 542us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 544us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 540us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 541us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 553us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 569us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 544us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 540us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 539us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 556us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 23/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3490/3490 [==============================] - 2s 541us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 549us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 29s 8ms/step - loss: 0.0600 - val_loss: 0.0089\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 546us/step - loss: 0.0101 - val_loss: 0.0051\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 539us/step - loss: 0.0065 - val_loss: 0.0144\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 537us/step - loss: 0.0047 - val_loss: 0.0024\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 537us/step - loss: 0.0035 - val_loss: 0.0047\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 538us/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 541us/step - loss: 0.0027 - val_loss: 0.0020\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 541us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 540us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 546us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 547us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 546us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 563us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 540us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 546us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 542us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 552us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 578us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 562us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 553us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 538us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 539us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 540us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 542us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 30s 9ms/step - loss: 0.0577 - val_loss: 0.0029\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 544us/step - loss: 0.0088 - val_loss: 0.0084\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 540us/step - loss: 0.0061 - val_loss: 0.0099\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 539us/step - loss: 0.0041 - val_loss: 0.0020\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 548us/step - loss: 0.0031 - val_loss: 0.0023\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 566us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 553us/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 556us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 544us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 545us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 541us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 549us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 539us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 539us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 540us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 539us/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 541us/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 538us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 538us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 538us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 548us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 540us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 538us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 538us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 29s 8ms/step - loss: 0.0677 - val_loss: 0.0391\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 382us/step - loss: 0.0156 - val_loss: 0.0091\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 380us/step - loss: 0.0073 - val_loss: 0.0021\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 382us/step - loss: 0.0049 - val_loss: 0.0022\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 384us/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 384us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 381us/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 384us/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 382us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 382us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 386us/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 383us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 388us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 383us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 383us/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 382us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 381us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 382us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 382us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 382us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 385us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 385us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 388us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 383us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 31s 9ms/step - loss: 0.9426 - val_loss: 0.0042\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 384us/step - loss: 0.0140 - val_loss: 0.0033\n",
      "Epoch 3/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3490/3490 [==============================] - 1s 385us/step - loss: 0.0061 - val_loss: 0.0036\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 392us/step - loss: 0.0053 - val_loss: 0.0042\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 402us/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 396us/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 396us/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 393us/step - loss: 0.0044 - val_loss: 0.0051\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 392us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 394us/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 398us/step - loss: 0.0043 - val_loss: 0.0041\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 387us/step - loss: 0.0041 - val_loss: 0.0048\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 384us/step - loss: 0.0039 - val_loss: 0.0034\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 384us/step - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 383us/step - loss: 0.0040 - val_loss: 0.0036\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 384us/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 385us/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 388us/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 386us/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 388us/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 384us/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 382us/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 386us/step - loss: 0.0034 - val_loss: 0.0040\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 385us/step - loss: 0.0035 - val_loss: 0.0041\n",
      "\n",
      "GENERATION 16\n",
      "\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 31s 9ms/step - loss: 0.1536 - val_loss: 0.0245\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 565us/step - loss: 0.0241 - val_loss: 0.0103\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 566us/step - loss: 0.0198 - val_loss: 0.0086\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 565us/step - loss: 0.0121 - val_loss: 0.0161\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 568us/step - loss: 0.0108 - val_loss: 0.0180\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 566us/step - loss: 0.0123 - val_loss: 0.0168\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 567us/step - loss: 0.0070 - val_loss: 0.0065\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 564us/step - loss: 0.0069 - val_loss: 0.0137\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 566us/step - loss: 0.0069 - val_loss: 0.0072\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 568us/step - loss: 0.0071 - val_loss: 0.0153\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 566us/step - loss: 0.0081 - val_loss: 0.0038\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 571us/step - loss: 0.0059 - val_loss: 0.0096\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 564us/step - loss: 0.0047 - val_loss: 0.0052\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 564us/step - loss: 0.0046 - val_loss: 0.0082\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 565us/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 566us/step - loss: 0.0054 - val_loss: 0.0121\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 566us/step - loss: 0.0066 - val_loss: 0.0096\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 573us/step - loss: 0.0065 - val_loss: 0.0110\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 565us/step - loss: 0.0071 - val_loss: 0.0093\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 564us/step - loss: 0.0062 - val_loss: 0.0116\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 565us/step - loss: 0.0048 - val_loss: 0.0034\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 569us/step - loss: 0.0043 - val_loss: 0.0112\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 569us/step - loss: 0.0064 - val_loss: 0.0052\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 566us/step - loss: 0.0046 - val_loss: 0.0115\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 31s 9ms/step - loss: 0.0778 - val_loss: 0.0026\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 276us/step - loss: 0.0068 - val_loss: 0.0055\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 278us/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 277us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 277us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 276us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 278us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 278us/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 276us/step - loss: 9.7905e-04 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 277us/step - loss: 9.3787e-04 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 277us/step - loss: 9.0123e-04 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 275us/step - loss: 8.4814e-04 - val_loss: 0.0010\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 277us/step - loss: 8.1015e-04 - val_loss: 9.8808e-04\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 280us/step - loss: 7.7874e-04 - val_loss: 9.0669e-04\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 278us/step - loss: 7.5079e-04 - val_loss: 8.6845e-04\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 277us/step - loss: 7.6642e-04 - val_loss: 8.5224e-04\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 277us/step - loss: 7.1894e-04 - val_loss: 9.1809e-04\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 278us/step - loss: 6.9425e-04 - val_loss: 8.3890e-04\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 280us/step - loss: 6.6636e-04 - val_loss: 7.8388e-04\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 277us/step - loss: 6.4014e-04 - val_loss: 7.9294e-04\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 277us/step - loss: 6.3482e-04 - val_loss: 7.5817e-04\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 277us/step - loss: 6.2024e-04 - val_loss: 7.3236e-04\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 279us/step - loss: 6.4116e-04 - val_loss: 8.1894e-04\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 277us/step - loss: 6.1835e-04 - val_loss: 7.6097e-04\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 30s 9ms/step - loss: 0.1601 - val_loss: 0.0051\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 239us/step - loss: 0.0184 - val_loss: 0.0177\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 238us/step - loss: 0.0100 - val_loss: 0.0052\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 238us/step - loss: 0.0052 - val_loss: 0.0029\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 238us/step - loss: 0.0029 - val_loss: 0.0019\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 238us/step - loss: 0.0016 - val_loss: 0.0016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 239us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 238us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 239us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 239us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 240us/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 238us/step - loss: 9.7000e-04 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 238us/step - loss: 9.2446e-04 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 239us/step - loss: 8.6168e-04 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 239us/step - loss: 8.0357e-04 - val_loss: 9.3907e-04\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 239us/step - loss: 7.4884e-04 - val_loss: 8.8502e-04\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 237us/step - loss: 7.1204e-04 - val_loss: 8.1442e-04\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 239us/step - loss: 7.1416e-04 - val_loss: 8.1575e-04\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 243us/step - loss: 6.7612e-04 - val_loss: 8.0511e-04\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 240us/step - loss: 6.6244e-04 - val_loss: 8.5681e-04\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 239us/step - loss: 6.5564e-04 - val_loss: 7.7647e-04\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 240us/step - loss: 6.3484e-04 - val_loss: 7.6018e-04\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 238us/step - loss: 6.3901e-04 - val_loss: 7.4785e-04\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 239us/step - loss: 6.1674e-04 - val_loss: 7.4733e-04\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 30s 9ms/step - loss: 0.1855 - val_loss: 0.1655\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 237us/step - loss: 0.1015 - val_loss: 0.0908\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 239us/step - loss: 0.0693 - val_loss: 0.0555\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 237us/step - loss: 0.0559 - val_loss: 0.0376\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 238us/step - loss: 0.0499 - val_loss: 0.0281\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 238us/step - loss: 0.0466 - val_loss: 0.0228\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 238us/step - loss: 0.0443 - val_loss: 0.0197\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 237us/step - loss: 0.0424 - val_loss: 0.0177\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 238us/step - loss: 0.0405 - val_loss: 0.0160\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 237us/step - loss: 0.0385 - val_loss: 0.0145\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 237us/step - loss: 0.0360 - val_loss: 0.0135\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 237us/step - loss: 0.0338 - val_loss: 0.0124\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 238us/step - loss: 0.0317 - val_loss: 0.0115\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 237us/step - loss: 0.0296 - val_loss: 0.0104\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 239us/step - loss: 0.0276 - val_loss: 0.0096\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 239us/step - loss: 0.0248 - val_loss: 0.0086\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 238us/step - loss: 0.0215 - val_loss: 0.0073\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 238us/step - loss: 0.0188 - val_loss: 0.0065\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 237us/step - loss: 0.0165 - val_loss: 0.0052\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 238us/step - loss: 0.0143 - val_loss: 0.0045\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 236us/step - loss: 0.0122 - val_loss: 0.0038\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 237us/step - loss: 0.0104 - val_loss: 0.0031\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 236us/step - loss: 0.0088 - val_loss: 0.0027\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 238us/step - loss: 0.0075 - val_loss: 0.0023\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 30s 9ms/step - loss: 0.2162 - val_loss: 0.2328\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 175us/step - loss: 0.1469 - val_loss: 0.1605\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 175us/step - loss: 0.1083 - val_loss: 0.1142\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 175us/step - loss: 0.0851 - val_loss: 0.0836\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 175us/step - loss: 0.0713 - val_loss: 0.0633\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 173us/step - loss: 0.0630 - val_loss: 0.0497\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 175us/step - loss: 0.0576 - val_loss: 0.0403\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 176us/step - loss: 0.0538 - val_loss: 0.0336\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 175us/step - loss: 0.0509 - val_loss: 0.0292\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 176us/step - loss: 0.0488 - val_loss: 0.0258\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 175us/step - loss: 0.0472 - val_loss: 0.0232\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 174us/step - loss: 0.0458 - val_loss: 0.0212\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 179us/step - loss: 0.0444 - val_loss: 0.0196\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 176us/step - loss: 0.0432 - val_loss: 0.0184\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 174us/step - loss: 0.0419 - val_loss: 0.0173\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 177us/step - loss: 0.0407 - val_loss: 0.0164\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 179us/step - loss: 0.0394 - val_loss: 0.0157\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 176us/step - loss: 0.0382 - val_loss: 0.0148\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 176us/step - loss: 0.0370 - val_loss: 0.0140\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 175us/step - loss: 0.0357 - val_loss: 0.0133\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 175us/step - loss: 0.0344 - val_loss: 0.0127\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 175us/step - loss: 0.0331 - val_loss: 0.0120\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 177us/step - loss: 0.0318 - val_loss: 0.0114\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 177us/step - loss: 0.0305 - val_loss: 0.0107\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 32s 9ms/step - loss: 0.2268 - val_loss: 0.2515\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 331us/step - loss: 0.1604 - val_loss: 0.1818\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 328us/step - loss: 0.1222 - val_loss: 0.1331\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 326us/step - loss: 0.0985 - val_loss: 0.1006\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 327us/step - loss: 0.0842 - val_loss: 0.0785\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 329us/step - loss: 0.0756 - val_loss: 0.0636\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 329us/step - loss: 0.0705 - val_loss: 0.0533\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 328us/step - loss: 0.0674 - val_loss: 0.0459\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 328us/step - loss: 0.0655 - val_loss: 0.0407\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 329us/step - loss: 0.0641 - val_loss: 0.0371\n",
      "Epoch 11/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3490/3490 [==============================] - 1s 328us/step - loss: 0.0632 - val_loss: 0.0343\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 328us/step - loss: 0.0624 - val_loss: 0.0324\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 328us/step - loss: 0.0617 - val_loss: 0.0309\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 327us/step - loss: 0.0612 - val_loss: 0.0297\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 325us/step - loss: 0.0606 - val_loss: 0.0287\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 329us/step - loss: 0.0601 - val_loss: 0.0281\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 329us/step - loss: 0.0595 - val_loss: 0.0275\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 329us/step - loss: 0.0589 - val_loss: 0.0269\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 330us/step - loss: 0.0583 - val_loss: 0.0263\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 334us/step - loss: 0.0578 - val_loss: 0.0259\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 326us/step - loss: 0.0572 - val_loss: 0.0254\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 326us/step - loss: 0.0566 - val_loss: 0.0252\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 326us/step - loss: 0.0560 - val_loss: 0.0248\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 326us/step - loss: 0.0553 - val_loss: 0.0244\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 32s 9ms/step - loss: 0.1404 - val_loss: 0.0060\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 341us/step - loss: 0.0075 - val_loss: 0.0039\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 332us/step - loss: 0.0048 - val_loss: 0.0302\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 330us/step - loss: 0.0107 - val_loss: 0.0111\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 330us/step - loss: 0.0099 - val_loss: 0.0208\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 330us/step - loss: 0.0108 - val_loss: 0.0108\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 331us/step - loss: 0.0114 - val_loss: 0.0166\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 332us/step - loss: 0.0078 - val_loss: 0.0098\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 337us/step - loss: 0.0094 - val_loss: 0.0162\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 329us/step - loss: 0.0091 - val_loss: 0.0092\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 339us/step - loss: 0.0085 - val_loss: 0.0148\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 331us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 329us/step - loss: 0.0065 - val_loss: 0.0138\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 330us/step - loss: 0.0071 - val_loss: 0.0053\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 330us/step - loss: 0.0075 - val_loss: 0.0139\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 331us/step - loss: 0.0052 - val_loss: 0.0061\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 345us/step - loss: 0.0066 - val_loss: 0.0136\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 352us/step - loss: 0.0071 - val_loss: 0.0039\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 348us/step - loss: 0.0043 - val_loss: 0.0231\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 342us/step - loss: 0.0055 - val_loss: 0.0052\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 335us/step - loss: 0.0052 - val_loss: 0.0160\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 336us/step - loss: 0.0064 - val_loss: 0.0029\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 335us/step - loss: 0.0038 - val_loss: 0.0127\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 345us/step - loss: 0.0052 - val_loss: 0.0076\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 33s 9ms/step - loss: 0.1657 - val_loss: 0.0183\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 344us/step - loss: 0.0135 - val_loss: 0.0059\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 331us/step - loss: 0.0077 - val_loss: 0.0151\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 334us/step - loss: 0.0135 - val_loss: 0.0284\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 332us/step - loss: 0.0122 - val_loss: 0.0113\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 333us/step - loss: 0.0118 - val_loss: 0.0262\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 329us/step - loss: 0.0162 - val_loss: 0.0054\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 332us/step - loss: 0.0081 - val_loss: 0.0196\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 333us/step - loss: 0.0109 - val_loss: 0.0075\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 334us/step - loss: 0.0092 - val_loss: 0.0239\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 336us/step - loss: 0.0103 - val_loss: 0.0092\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 331us/step - loss: 0.0065 - val_loss: 0.0183\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 333us/step - loss: 0.0091 - val_loss: 0.0052\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 331us/step - loss: 0.0067 - val_loss: 0.0171\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 331us/step - loss: 0.0078 - val_loss: 0.0124\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 335us/step - loss: 0.0068 - val_loss: 0.0192\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 340us/step - loss: 0.0064 - val_loss: 0.0040\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 340us/step - loss: 0.0070 - val_loss: 0.0162\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 335us/step - loss: 0.0059 - val_loss: 0.0043\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 335us/step - loss: 0.0059 - val_loss: 0.0199\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 339us/step - loss: 0.0057 - val_loss: 0.0050\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 344us/step - loss: 0.0054 - val_loss: 0.0161\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 344us/step - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 339us/step - loss: 0.0052 - val_loss: 0.0196\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 33s 9ms/step - loss: 0.1154 - val_loss: 0.0171\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 331us/step - loss: 0.0145 - val_loss: 0.0178\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 329us/step - loss: 0.0136 - val_loss: 0.0190\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 330us/step - loss: 0.0113 - val_loss: 0.0313\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 329us/step - loss: 0.0118 - val_loss: 0.0254\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 328us/step - loss: 0.0118 - val_loss: 0.0077\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 328us/step - loss: 0.0105 - val_loss: 0.0189\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 333us/step - loss: 0.0100 - val_loss: 0.0052\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 343us/step - loss: 0.0078 - val_loss: 0.0210\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 359us/step - loss: 0.0104 - val_loss: 0.0088\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 334us/step - loss: 0.0069 - val_loss: 0.0220\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 331us/step - loss: 0.0083 - val_loss: 0.0123\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 341us/step - loss: 0.0076 - val_loss: 0.0177\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 339us/step - loss: 0.0073 - val_loss: 0.0061\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 334us/step - loss: 0.0069 - val_loss: 0.0140\n",
      "Epoch 16/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3490/3490 [==============================] - 1s 335us/step - loss: 0.0063 - val_loss: 0.0040\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 339us/step - loss: 0.0058 - val_loss: 0.0199\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 330us/step - loss: 0.0064 - val_loss: 0.0031\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 335us/step - loss: 0.0064 - val_loss: 0.0203\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 344us/step - loss: 0.0058 - val_loss: 0.0025\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 351us/step - loss: 0.0038 - val_loss: 0.0242\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 334us/step - loss: 0.0065 - val_loss: 0.0035\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 331us/step - loss: 0.0051 - val_loss: 0.0144\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 351us/step - loss: 0.0053 - val_loss: 0.0037\n",
      "\n",
      "GENERATION 17\n",
      "\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 33s 9ms/step - loss: 0.0515 - val_loss: 0.0354\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 292us/step - loss: 0.0113 - val_loss: 0.0161\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 296us/step - loss: 0.0046 - val_loss: 0.0037\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 299us/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 287us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 287us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 287us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 9.3923e-04 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 9.2971e-04 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 9.0409e-04 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 8.9263e-04 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 8.8067e-04 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 8.7403e-04 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 8.5692e-04 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 288us/step - loss: 8.4406e-04 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 8.3358e-04 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 8.2185e-04 - val_loss: 0.0010\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 8.1648e-04 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 279us/step - loss: 8.0204e-04 - val_loss: 9.9395e-04\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 278us/step - loss: 7.8960e-04 - val_loss: 9.8971e-04\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 7.8024e-04 - val_loss: 9.6120e-04\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 277us/step - loss: 7.7019e-04 - val_loss: 9.7416e-04\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 278us/step - loss: 7.6075e-04 - val_loss: 9.4334e-04\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 33s 9ms/step - loss: 0.1900 - val_loss: 0.0154\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 278us/step - loss: 0.0213 - val_loss: 0.0121\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 279us/step - loss: 0.0064 - val_loss: 0.0042\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 279us/step - loss: 0.0034 - val_loss: 0.0020\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 276us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 280us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 278us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 277us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 276us/step - loss: 9.7377e-04 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 277us/step - loss: 9.2686e-04 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 278us/step - loss: 8.7596e-04 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 279us/step - loss: 8.5850e-04 - val_loss: 0.0010\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 279us/step - loss: 8.2679e-04 - val_loss: 9.4794e-04\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 278us/step - loss: 7.9450e-04 - val_loss: 9.0148e-04\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 279us/step - loss: 7.7604e-04 - val_loss: 9.9608e-04\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 32s 9ms/step - loss: 0.0450 - val_loss: 0.0255\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 278us/step - loss: 0.0102 - val_loss: 0.0120\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 279us/step - loss: 0.0040 - val_loss: 0.0014\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 0.0024 - val_loss: 0.0057\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 279us/step - loss: 0.0014 - val_loss: 0.0029\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 279us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 277us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 280us/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 9.6728e-04 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 277us/step - loss: 9.2218e-04 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 280us/step - loss: 8.7996e-04 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 280us/step - loss: 8.4687e-04 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 279us/step - loss: 8.1459e-04 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 277us/step - loss: 7.8875e-04 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 277us/step - loss: 7.6427e-04 - val_loss: 9.7937e-04\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 289us/step - loss: 7.4831e-04 - val_loss: 8.5959e-04\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 277us/step - loss: 7.3010e-04 - val_loss: 7.7767e-04\n",
      "Epoch 19/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3490/3490 [==============================] - 1s 278us/step - loss: 7.1015e-04 - val_loss: 8.5588e-04\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 278us/step - loss: 6.8765e-04 - val_loss: 7.9425e-04\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 279us/step - loss: 6.7181e-04 - val_loss: 8.0759e-04\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 277us/step - loss: 6.5941e-04 - val_loss: 8.1237e-04\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 279us/step - loss: 6.5995e-04 - val_loss: 8.1443e-04\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 278us/step - loss: 6.5074e-04 - val_loss: 7.4738e-04\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 33s 9ms/step - loss: 0.1080 - val_loss: 0.0205\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 279us/step - loss: 0.0318 - val_loss: 0.0087\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 278us/step - loss: 0.0240 - val_loss: 0.0060\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 278us/step - loss: 0.0183 - val_loss: 0.0045\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 277us/step - loss: 0.0139 - val_loss: 0.0036\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 280us/step - loss: 0.0105 - val_loss: 0.0027\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 278us/step - loss: 0.0079 - val_loss: 0.0023\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 277us/step - loss: 0.0060 - val_loss: 0.0020\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 278us/step - loss: 0.0047 - val_loss: 0.0019\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 278us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 278us/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 277us/step - loss: 0.0026 - val_loss: 0.0020\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 277us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 276us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 277us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 276us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 279us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 277us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 278us/step - loss: 0.0017 - val_loss: 0.0026\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 278us/step - loss: 0.0017 - val_loss: 0.0027\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 279us/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 279us/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 278us/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 277us/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 35s 10ms/step - loss: 0.3373 - val_loss: 0.1341\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 277us/step - loss: 0.0314 - val_loss: 0.0314\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 278us/step - loss: 0.0158 - val_loss: 0.0020\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 277us/step - loss: 0.0062 - val_loss: 0.0038\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 276us/step - loss: 0.0048 - val_loss: 0.0036\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 0.0035 - val_loss: 0.0074\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 299us/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 302us/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 287us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 289us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 278us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 293us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 287us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 280us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 279us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 279us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 278us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 278us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 278us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 279us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 279us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 35s 10ms/step - loss: 0.0801 - val_loss: 0.0194\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 291us/step - loss: 0.0096 - val_loss: 0.0020\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 0.0073 - val_loss: 0.0117\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 290us/step - loss: 0.0072 - val_loss: 0.0019\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 0.0040 - val_loss: 0.0034\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 291us/step - loss: 0.0035 - val_loss: 0.0028\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 0.0031 - val_loss: 0.0020\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 277us/step - loss: 0.0076 - val_loss: 0.0442\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 276us/step - loss: 0.0170 - val_loss: 0.0021\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 0.0040 - val_loss: 0.0050\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 279us/step - loss: 0.0037 - val_loss: 0.0018\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 289us/step - loss: 0.0044 - val_loss: 0.0096\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 293us/step - loss: 0.0075 - val_loss: 0.0073\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 279us/step - loss: 0.0065 - val_loss: 0.0099\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 0.0047 - val_loss: 0.0025\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 280us/step - loss: 0.0049 - val_loss: 0.0094\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 280us/step - loss: 0.0051 - val_loss: 0.0029\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 278us/step - loss: 0.0040 - val_loss: 0.0070\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 278us/step - loss: 0.0045 - val_loss: 0.0037\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 293us/step - loss: 0.0051 - val_loss: 0.0067\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 311us/step - loss: 0.0052 - val_loss: 0.0032\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 303us/step - loss: 0.0040 - val_loss: 0.0052\n",
      "Epoch 23/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3490/3490 [==============================] - 1s 293us/step - loss: 0.0040 - val_loss: 0.0028\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 295us/step - loss: 0.0041 - val_loss: 0.0070\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 37s 11ms/step - loss: 0.0606 - val_loss: 0.0221\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 610us/step - loss: 0.0136 - val_loss: 0.0163\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 666us/step - loss: 0.0092 - val_loss: 0.0122\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 663us/step - loss: 0.0091 - val_loss: 0.0131\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 664us/step - loss: 0.0087 - val_loss: 0.0085\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 617us/step - loss: 0.0063 - val_loss: 0.0065\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 622us/step - loss: 0.0039 - val_loss: 0.0030\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 606us/step - loss: 0.0064 - val_loss: 0.0159\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 596us/step - loss: 0.0076 - val_loss: 0.0059\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 595us/step - loss: 0.0060 - val_loss: 0.0124\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 593us/step - loss: 0.0076 - val_loss: 0.0092\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 598us/step - loss: 0.0082 - val_loss: 0.0141\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 597us/step - loss: 0.0069 - val_loss: 0.0028\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 598us/step - loss: 0.0045 - val_loss: 0.0109\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 597us/step - loss: 0.0060 - val_loss: 0.0053\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 598us/step - loss: 0.0068 - val_loss: 0.0120\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 594us/step - loss: 0.0047 - val_loss: 0.0035\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 597us/step - loss: 0.0068 - val_loss: 0.0158\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 599us/step - loss: 0.0060 - val_loss: 0.0021\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 602us/step - loss: 0.0036 - val_loss: 0.0057\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 595us/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 598us/step - loss: 0.0054 - val_loss: 0.0099\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 610us/step - loss: 0.0056 - val_loss: 0.0053\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 598us/step - loss: 0.0061 - val_loss: 0.0104\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 38s 11ms/step - loss: 0.2170 - val_loss: 0.0065\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 606us/step - loss: 0.0232 - val_loss: 0.0121\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 602us/step - loss: 0.0219 - val_loss: 0.0361\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 600us/step - loss: 0.0232 - val_loss: 0.0199\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 596us/step - loss: 0.0154 - val_loss: 0.0231\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 593us/step - loss: 0.0158 - val_loss: 0.0107\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 597us/step - loss: 0.0120 - val_loss: 0.0161\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 596us/step - loss: 0.0073 - val_loss: 0.0103\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 604us/step - loss: 0.0078 - val_loss: 0.0176\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 594us/step - loss: 0.0089 - val_loss: 0.0136\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 596us/step - loss: 0.0086 - val_loss: 0.0107\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 593us/step - loss: 0.0058 - val_loss: 0.0064\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 596us/step - loss: 0.0061 - val_loss: 0.0110\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 597us/step - loss: 0.0072 - val_loss: 0.0117\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 596us/step - loss: 0.0082 - val_loss: 0.0102\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 594us/step - loss: 0.0074 - val_loss: 0.0085\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 592us/step - loss: 0.0063 - val_loss: 0.0084\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 601us/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 612us/step - loss: 0.0061 - val_loss: 0.0129\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 603us/step - loss: 0.0081 - val_loss: 0.0073\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 646us/step - loss: 0.0057 - val_loss: 0.0109\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 652us/step - loss: 0.0060 - val_loss: 0.0056\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 626us/step - loss: 0.0059 - val_loss: 0.0088\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 604us/step - loss: 0.0059 - val_loss: 0.0074\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 37s 11ms/step - loss: 0.0855 - val_loss: 0.0443\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 540us/step - loss: 0.0240 - val_loss: 0.0038\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 538us/step - loss: 0.0170 - val_loss: 0.0183\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 574us/step - loss: 0.0146 - val_loss: 0.0168\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 606us/step - loss: 0.0123 - val_loss: 0.0126\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 600us/step - loss: 0.0091 - val_loss: 0.0092\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 563us/step - loss: 0.0097 - val_loss: 0.0139\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 622us/step - loss: 0.0077 - val_loss: 0.0047\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 582us/step - loss: 0.0061 - val_loss: 0.0060\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 554us/step - loss: 0.0054 - val_loss: 0.0073\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 577us/step - loss: 0.0057 - val_loss: 0.0117\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 632us/step - loss: 0.0073 - val_loss: 0.0053\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 589us/step - loss: 0.0056 - val_loss: 0.0109\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 600us/step - loss: 0.0081 - val_loss: 0.0108\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 571us/step - loss: 0.0062 - val_loss: 0.0086\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 547us/step - loss: 0.0062 - val_loss: 0.0156\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 538us/step - loss: 0.0073 - val_loss: 0.0089\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 541us/step - loss: 0.0080 - val_loss: 0.0072\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 545us/step - loss: 0.0074 - val_loss: 0.0064\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 539us/step - loss: 0.0047 - val_loss: 0.0062\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 541us/step - loss: 0.0049 - val_loss: 0.0062\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 539us/step - loss: 0.0048 - val_loss: 0.0095\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 540us/step - loss: 0.0063 - val_loss: 0.0082\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 541us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "\n",
      "GENERATION 18\n",
      "\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 36s 10ms/step - loss: 0.0993 - val_loss: 0.0143\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 287us/step - loss: 0.0098 - val_loss: 0.0026\n",
      "Epoch 3/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3490/3490 [==============================] - 1s 279us/step - loss: 0.0046 - val_loss: 0.0015\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 280us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 278us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 279us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 279us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 279us/step - loss: 9.6726e-04 - val_loss: 0.0013\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 278us/step - loss: 9.4841e-04 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 280us/step - loss: 9.2475e-04 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 280us/step - loss: 8.8746e-04 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 8.6188e-04 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 278us/step - loss: 8.4259e-04 - val_loss: 9.9778e-04\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 278us/step - loss: 8.1602e-04 - val_loss: 0.0010\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 279us/step - loss: 7.9147e-04 - val_loss: 9.7176e-04\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 280us/step - loss: 7.6729e-04 - val_loss: 9.1347e-04\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 278us/step - loss: 7.4666e-04 - val_loss: 8.8930e-04\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 278us/step - loss: 7.2261e-04 - val_loss: 9.2190e-04\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 7.1223e-04 - val_loss: 8.4181e-04\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 278us/step - loss: 6.9641e-04 - val_loss: 8.0861e-04\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 280us/step - loss: 6.8422e-04 - val_loss: 8.4378e-04\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 6.7131e-04 - val_loss: 7.6770e-04\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 288us/step - loss: 6.4578e-04 - val_loss: 7.5785e-04\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 36s 10ms/step - loss: 0.1177 - val_loss: 0.0648\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 278us/step - loss: 0.0148 - val_loss: 0.0111\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 278us/step - loss: 0.0056 - val_loss: 0.0067\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 279us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 279us/step - loss: 0.0020 - val_loss: 0.0030\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 278us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 279us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 277us/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 277us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 280us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 9.9053e-04 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 280us/step - loss: 9.5725e-04 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 9.1287e-04 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 8.7288e-04 - val_loss: 0.0010\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 279us/step - loss: 8.5910e-04 - val_loss: 9.7643e-04\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 280us/step - loss: 8.0093e-04 - val_loss: 9.6682e-04\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 279us/step - loss: 7.7777e-04 - val_loss: 8.8655e-04\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 279us/step - loss: 7.3337e-04 - val_loss: 8.9905e-04\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 279us/step - loss: 7.1307e-04 - val_loss: 9.4235e-04\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 280us/step - loss: 6.8283e-04 - val_loss: 8.2593e-04\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 278us/step - loss: 6.4880e-04 - val_loss: 8.0598e-04\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 280us/step - loss: 6.4253e-04 - val_loss: 7.6954e-04\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 6.3967e-04 - val_loss: 7.6846e-04\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 6.4155e-04 - val_loss: 7.4991e-04\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 37s 11ms/step - loss: 0.0945 - val_loss: 0.0371\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 566us/step - loss: 0.0234 - val_loss: 0.0236\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 564us/step - loss: 0.0098 - val_loss: 0.0050\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 569us/step - loss: 0.0039 - val_loss: 0.0025\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 568us/step - loss: 0.0026 - val_loss: 0.0054\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 566us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 568us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 569us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 571us/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 567us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 568us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 568us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 567us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 567us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 568us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 567us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 571us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 568us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 566us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 566us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 568us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 566us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 566us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 569us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 38s 11ms/step - loss: 0.0885 - val_loss: 0.0238\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 565us/step - loss: 0.0102 - val_loss: 0.0122\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 565us/step - loss: 0.0082 - val_loss: 0.0067\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 568us/step - loss: 0.0061 - val_loss: 0.0134\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 570us/step - loss: 0.0093 - val_loss: 0.0059\n",
      "Epoch 6/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3490/3490 [==============================] - 2s 564us/step - loss: 0.0051 - val_loss: 0.0088\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 564us/step - loss: 0.0051 - val_loss: 0.0055\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 566us/step - loss: 0.0067 - val_loss: 0.0112\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 567us/step - loss: 0.0069 - val_loss: 0.0113\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 567us/step - loss: 0.0086 - val_loss: 0.0121\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 566us/step - loss: 0.0063 - val_loss: 0.0106\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 567us/step - loss: 0.0078 - val_loss: 0.0104\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 568us/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 565us/step - loss: 0.0046 - val_loss: 0.0091\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 565us/step - loss: 0.0075 - val_loss: 0.0057\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 565us/step - loss: 0.0049 - val_loss: 0.0087\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 564us/step - loss: 0.0056 - val_loss: 0.0057\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 563us/step - loss: 0.0039 - val_loss: 0.0063\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 570us/step - loss: 0.0046 - val_loss: 0.0092\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 565us/step - loss: 0.0082 - val_loss: 0.0095\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 570us/step - loss: 0.0061 - val_loss: 0.0072\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 566us/step - loss: 0.0048 - val_loss: 0.0113\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 566us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 566us/step - loss: 0.0050 - val_loss: 0.0076\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 39s 11ms/step - loss: 0.1907 - val_loss: 0.0436\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 594us/step - loss: 0.0715 - val_loss: 0.0318\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 592us/step - loss: 0.0714 - val_loss: 0.0280\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 593us/step - loss: 0.0713 - val_loss: 0.0310\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 590us/step - loss: 0.0719 - val_loss: 0.0274\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 592us/step - loss: 0.0713 - val_loss: 0.0282\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 587us/step - loss: 0.0715 - val_loss: 0.0259\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 591us/step - loss: 0.0708 - val_loss: 0.0354\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 591us/step - loss: 0.0706 - val_loss: 0.0339\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 589us/step - loss: 0.0707 - val_loss: 0.0270\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 594us/step - loss: 0.0705 - val_loss: 0.0338\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 591us/step - loss: 0.0707 - val_loss: 0.0347\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 592us/step - loss: 0.0704 - val_loss: 0.0345\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 589us/step - loss: 0.0707 - val_loss: 0.0438\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 592us/step - loss: 0.0699 - val_loss: 0.0314\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 592us/step - loss: 0.0697 - val_loss: 0.0213\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 594us/step - loss: 0.0700 - val_loss: 0.0288\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 592us/step - loss: 0.0700 - val_loss: 0.0278\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 591us/step - loss: 0.0694 - val_loss: 0.0300\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 591us/step - loss: 0.0702 - val_loss: 0.0315\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 593us/step - loss: 0.0694 - val_loss: 0.0346\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 591us/step - loss: 0.0692 - val_loss: 0.0372\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 594us/step - loss: 0.0690 - val_loss: 0.0305\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 594us/step - loss: 0.0688 - val_loss: 0.0274\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 39s 11ms/step - loss: 0.7929 - val_loss: 0.0304\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 595us/step - loss: 0.0974 - val_loss: 0.0389\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 601us/step - loss: 0.0502 - val_loss: 0.0110\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 594us/step - loss: 0.0773 - val_loss: 0.0057\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 600us/step - loss: 0.0095 - val_loss: 0.0265\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 595us/step - loss: 0.0581 - val_loss: 0.0046\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 598us/step - loss: 0.0058 - val_loss: 0.0756\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 597us/step - loss: 0.0541 - val_loss: 0.0078\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 596us/step - loss: 0.0046 - val_loss: 0.0236\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 604us/step - loss: 0.0444 - val_loss: 0.0051\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 610us/step - loss: 0.0068 - val_loss: 0.0347\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 597us/step - loss: 0.0311 - val_loss: 0.0133\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 596us/step - loss: 0.0053 - val_loss: 0.0895\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 598us/step - loss: 0.0203 - val_loss: 0.0219\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 604us/step - loss: 0.0149 - val_loss: 0.0801\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 603us/step - loss: 0.0108 - val_loss: 0.0163\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 604us/step - loss: 0.0142 - val_loss: 0.0748\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 599us/step - loss: 0.0098 - val_loss: 0.0181\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 597us/step - loss: 0.0115 - val_loss: 0.0709\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 599us/step - loss: 0.0091 - val_loss: 0.0171\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 594us/step - loss: 0.0092 - val_loss: 0.0858\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 597us/step - loss: 0.0101 - val_loss: 0.0269\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 596us/step - loss: 0.0071 - val_loss: 0.0712\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 597us/step - loss: 0.0093 - val_loss: 0.0250\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 39s 11ms/step - loss: 0.2874 - val_loss: 0.0320\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 492us/step - loss: 0.0737 - val_loss: 0.0317\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 493us/step - loss: 0.0736 - val_loss: 0.0406\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 494us/step - loss: 0.0735 - val_loss: 0.0232\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 495us/step - loss: 0.0737 - val_loss: 0.0359\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 495us/step - loss: 0.0731 - val_loss: 0.0360\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 495us/step - loss: 0.0730 - val_loss: 0.0314\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 492us/step - loss: 0.0729 - val_loss: 0.0377\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 498us/step - loss: 0.0728 - val_loss: 0.0341\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 495us/step - loss: 0.0729 - val_loss: 0.0350\n",
      "Epoch 11/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3490/3490 [==============================] - 2s 494us/step - loss: 0.0728 - val_loss: 0.0320\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 493us/step - loss: 0.0726 - val_loss: 0.0299\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 493us/step - loss: 0.0724 - val_loss: 0.0330\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 494us/step - loss: 0.0723 - val_loss: 0.0311\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 495us/step - loss: 0.0722 - val_loss: 0.0293\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 492us/step - loss: 0.0722 - val_loss: 0.0307\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 494us/step - loss: 0.0725 - val_loss: 0.0279\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 498us/step - loss: 0.0720 - val_loss: 0.0310\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 495us/step - loss: 0.0718 - val_loss: 0.0304\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 498us/step - loss: 0.0719 - val_loss: 0.0373\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 494us/step - loss: 0.0718 - val_loss: 0.0371\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 497us/step - loss: 0.0720 - val_loss: 0.0297\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 496us/step - loss: 0.0719 - val_loss: 0.0277\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 494us/step - loss: 0.0714 - val_loss: 0.0305\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 39s 11ms/step - loss: 0.0946 - val_loss: 0.0343\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 345us/step - loss: 0.0680 - val_loss: 0.0338\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 345us/step - loss: 0.0671 - val_loss: 0.0316\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 344us/step - loss: 0.0666 - val_loss: 0.0296\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 347us/step - loss: 0.0659 - val_loss: 0.0309\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 344us/step - loss: 0.0650 - val_loss: 0.0302\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 343us/step - loss: 0.0643 - val_loss: 0.0259\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 344us/step - loss: 0.0636 - val_loss: 0.0319\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 343us/step - loss: 0.0628 - val_loss: 0.0297\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 348us/step - loss: 0.0621 - val_loss: 0.0290\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 344us/step - loss: 0.0615 - val_loss: 0.0291\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 345us/step - loss: 0.0610 - val_loss: 0.0267\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 344us/step - loss: 0.0602 - val_loss: 0.0254\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 347us/step - loss: 0.0594 - val_loss: 0.0254\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 343us/step - loss: 0.0585 - val_loss: 0.0268\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 345us/step - loss: 0.0580 - val_loss: 0.0267\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 345us/step - loss: 0.0570 - val_loss: 0.0261\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 343us/step - loss: 0.0563 - val_loss: 0.0278\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 345us/step - loss: 0.0555 - val_loss: 0.0241\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 344us/step - loss: 0.0547 - val_loss: 0.0238\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 344us/step - loss: 0.0536 - val_loss: 0.0227\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 344us/step - loss: 0.0532 - val_loss: 0.0241\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 344us/step - loss: 0.0522 - val_loss: 0.0233\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 347us/step - loss: 0.0514 - val_loss: 0.0231\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 39s 11ms/step - loss: 0.9696 - val_loss: 0.0848\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 352us/step - loss: 0.0722 - val_loss: 0.0358\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 353us/step - loss: 0.0672 - val_loss: 0.0302\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 362us/step - loss: 0.0667 - val_loss: 0.0304\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 351us/step - loss: 0.0663 - val_loss: 0.0289\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 356us/step - loss: 0.0659 - val_loss: 0.0282\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 353us/step - loss: 0.0655 - val_loss: 0.0284\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 351us/step - loss: 0.0651 - val_loss: 0.0282\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 353us/step - loss: 0.0644 - val_loss: 0.0291\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 350us/step - loss: 0.0641 - val_loss: 0.0277\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 353us/step - loss: 0.0635 - val_loss: 0.0291\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 353us/step - loss: 0.0633 - val_loss: 0.0280\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 353us/step - loss: 0.0627 - val_loss: 0.0255\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 352us/step - loss: 0.0622 - val_loss: 0.0275\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 352us/step - loss: 0.0619 - val_loss: 0.0257\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 351us/step - loss: 0.0612 - val_loss: 0.0266\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 352us/step - loss: 0.0607 - val_loss: 0.0268\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 353us/step - loss: 0.0603 - val_loss: 0.0274\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 353us/step - loss: 0.0597 - val_loss: 0.0262\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 356us/step - loss: 0.0591 - val_loss: 0.0258\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 353us/step - loss: 0.0586 - val_loss: 0.0248\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 352us/step - loss: 0.0582 - val_loss: 0.0245\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 351us/step - loss: 0.0572 - val_loss: 0.0254\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 353us/step - loss: 0.0568 - val_loss: 0.0258\n",
      "\n",
      "GENERATION 19\n",
      "\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 40s 11ms/step - loss: 2.2787 - val_loss: 1.9099\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 491us/step - loss: 1.1942 - val_loss: 1.0319\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 494us/step - loss: 0.6017 - val_loss: 0.5341\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 494us/step - loss: 0.2913 - val_loss: 0.2612\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 492us/step - loss: 0.1458 - val_loss: 0.1238\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 493us/step - loss: 0.0897 - val_loss: 0.0605\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 494us/step - loss: 0.0740 - val_loss: 0.0339\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 491us/step - loss: 0.0723 - val_loss: 0.0240\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 493us/step - loss: 0.0733 - val_loss: 0.0214\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 500us/step - loss: 0.0737 - val_loss: 0.0220\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 492us/step - loss: 0.0732 - val_loss: 0.0245\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 491us/step - loss: 0.0726 - val_loss: 0.0278\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 492us/step - loss: 0.0722 - val_loss: 0.0309\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 492us/step - loss: 0.0720 - val_loss: 0.0332\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 492us/step - loss: 0.0720 - val_loss: 0.0344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 493us/step - loss: 0.0720 - val_loss: 0.0347\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 492us/step - loss: 0.0720 - val_loss: 0.0344\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 490us/step - loss: 0.0720 - val_loss: 0.0340\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 492us/step - loss: 0.0720 - val_loss: 0.0337\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 493us/step - loss: 0.0720 - val_loss: 0.0338\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 498us/step - loss: 0.0720 - val_loss: 0.0334\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 495us/step - loss: 0.0720 - val_loss: 0.0332\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 490us/step - loss: 0.0720 - val_loss: 0.0334\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 492us/step - loss: 0.0720 - val_loss: 0.0337\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 39s 11ms/step - loss: 0.2064 - val_loss: 0.0597\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 0.0292 - val_loss: 0.0266\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 0.0118 - val_loss: 0.0144\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 0.0052 - val_loss: 0.0057\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 0.0031 - val_loss: 0.0046\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 287us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 9.2656e-04 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 9.0538e-04 - val_loss: 0.0010\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 8.6182e-04 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 8.2420e-04 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 7.9174e-04 - val_loss: 9.6564e-04\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 7.7077e-04 - val_loss: 9.3580e-04\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 7.4541e-04 - val_loss: 9.3272e-04\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 291us/step - loss: 7.3300e-04 - val_loss: 9.1693e-04\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 7.1243e-04 - val_loss: 9.2041e-04\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 40s 11ms/step - loss: 0.8904 - val_loss: 0.0029\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 0.1186 - val_loss: 0.0027\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 0.0468 - val_loss: 0.0085\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 0.0174 - val_loss: 0.0117\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 0.0092 - val_loss: 0.0013\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 0.0051 - val_loss: 0.0151\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 0.0034 - val_loss: 0.0013\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 0.0025 - val_loss: 0.0078\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 1s 280us/step - loss: 0.0011 - val_loss: 0.0030\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 9.3832e-04 - val_loss: 0.0023\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 8.9058e-04 - val_loss: 0.0018\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 8.5204e-04 - val_loss: 0.0019\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 8.3101e-04 - val_loss: 0.0016\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 8.1460e-04 - val_loss: 0.0017\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 7.9841e-04 - val_loss: 0.0015\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 1s 287us/step - loss: 7.8781e-04 - val_loss: 0.0016\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 7.7884e-04 - val_loss: 0.0015\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 7.6550e-04 - val_loss: 0.0014\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 7.5835e-04 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 7.4783e-04 - val_loss: 0.0015\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 42s 12ms/step - loss: 0.5193 - val_loss: 0.0247\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 601us/step - loss: 0.0390 - val_loss: 0.0092\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 599us/step - loss: 0.0214 - val_loss: 0.0138\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 598us/step - loss: 0.0116 - val_loss: 0.0020\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 602us/step - loss: 0.0076 - val_loss: 0.0023\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 601us/step - loss: 0.0052 - val_loss: 0.0068\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 604us/step - loss: 0.0040 - val_loss: 0.0019\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 600us/step - loss: 0.0036 - val_loss: 0.0048\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 603us/step - loss: 0.0033 - val_loss: 0.0019\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 601us/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 599us/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 601us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 598us/step - loss: 0.0029 - val_loss: 0.0023\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 607us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 600us/step - loss: 0.0026 - val_loss: 0.0021\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 600us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 608us/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 599us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 601us/step - loss: 0.0025 - val_loss: 0.0025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 601us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 599us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 602us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 597us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 598us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 43s 12ms/step - loss: 0.2293 - val_loss: 0.0041\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 607us/step - loss: 0.0236 - val_loss: 0.0191\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 602us/step - loss: 0.0161 - val_loss: 0.0191\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 601us/step - loss: 0.0075 - val_loss: 0.0036\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 603us/step - loss: 0.0057 - val_loss: 0.0090\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 600us/step - loss: 0.0044 - val_loss: 0.0023\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 602us/step - loss: 0.0037 - val_loss: 0.0053\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 600us/step - loss: 0.0034 - val_loss: 0.0022\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 598us/step - loss: 0.0031 - val_loss: 0.0045\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 604us/step - loss: 0.0030 - val_loss: 0.0024\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 604us/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 601us/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 605us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 600us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 602us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 602us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 601us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 603us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 604us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 602us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 609us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 602us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 602us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 607us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 45s 13ms/step - loss: 0.4235 - val_loss: 0.0197\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 606us/step - loss: 0.0272 - val_loss: 0.0296\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 605us/step - loss: 0.0181 - val_loss: 0.0288\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 606us/step - loss: 0.0093 - val_loss: 0.0043\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 606us/step - loss: 0.0065 - val_loss: 0.0134\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 607us/step - loss: 0.0051 - val_loss: 0.0020\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 606us/step - loss: 0.0041 - val_loss: 0.0057\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 604us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 604us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 608us/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 607us/step - loss: 0.0029 - val_loss: 0.0024\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 612us/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 606us/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 607us/step - loss: 0.0028 - val_loss: 0.0020\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 606us/step - loss: 0.0027 - val_loss: 0.0022\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 605us/step - loss: 0.0027 - val_loss: 0.0019\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 608us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 610us/step - loss: 0.0026 - val_loss: 0.0021\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 606us/step - loss: 0.0026 - val_loss: 0.0020\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 605us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 609us/step - loss: 0.0026 - val_loss: 0.0020\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 611us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 604us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 608us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 42s 12ms/step - loss: 0.8117 - val_loss: 0.3442\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 606us/step - loss: 0.1560 - val_loss: 0.0998\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 603us/step - loss: 0.0816 - val_loss: 0.0518\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 602us/step - loss: 0.0731 - val_loss: 0.0391\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 612us/step - loss: 0.0721 - val_loss: 0.0353\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 603us/step - loss: 0.0720 - val_loss: 0.0345\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 600us/step - loss: 0.0720 - val_loss: 0.0345\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 601us/step - loss: 0.0720 - val_loss: 0.0339\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 600us/step - loss: 0.0720 - val_loss: 0.0337\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 600us/step - loss: 0.0720 - val_loss: 0.0341\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 603us/step - loss: 0.0720 - val_loss: 0.0337\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 601us/step - loss: 0.0720 - val_loss: 0.0340\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 603us/step - loss: 0.0720 - val_loss: 0.0334\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 607us/step - loss: 0.0720 - val_loss: 0.0328\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 600us/step - loss: 0.0720 - val_loss: 0.0332\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 603us/step - loss: 0.0720 - val_loss: 0.0333\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 603us/step - loss: 0.0720 - val_loss: 0.0332\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 604us/step - loss: 0.0720 - val_loss: 0.0335\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 603us/step - loss: 0.0720 - val_loss: 0.0332\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 602us/step - loss: 0.0719 - val_loss: 0.0338\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 601us/step - loss: 0.0720 - val_loss: 0.0333\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 604us/step - loss: 0.0720 - val_loss: 0.0333\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 602us/step - loss: 0.0720 - val_loss: 0.0337\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 602us/step - loss: 0.0720 - val_loss: 0.0332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 43s 12ms/step - loss: 0.0744 - val_loss: 0.0418\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 598us/step - loss: 0.0722 - val_loss: 0.0357\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 601us/step - loss: 0.0720 - val_loss: 0.0347\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 599us/step - loss: 0.0720 - val_loss: 0.0334\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 598us/step - loss: 0.0720 - val_loss: 0.0340\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 599us/step - loss: 0.0720 - val_loss: 0.0331\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 596us/step - loss: 0.0720 - val_loss: 0.0332\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 597us/step - loss: 0.0720 - val_loss: 0.0333\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 596us/step - loss: 0.0720 - val_loss: 0.0338\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 599us/step - loss: 0.0720 - val_loss: 0.0342\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 596us/step - loss: 0.0720 - val_loss: 0.0336\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 600us/step - loss: 0.0720 - val_loss: 0.0330\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 596us/step - loss: 0.0720 - val_loss: 0.0329\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 602us/step - loss: 0.0720 - val_loss: 0.0327\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 599us/step - loss: 0.0720 - val_loss: 0.0332\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 596us/step - loss: 0.0720 - val_loss: 0.0339\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 600us/step - loss: 0.0720 - val_loss: 0.0335\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 598us/step - loss: 0.0720 - val_loss: 0.0331\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 595us/step - loss: 0.0720 - val_loss: 0.0329\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 596us/step - loss: 0.0720 - val_loss: 0.0338\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 595us/step - loss: 0.0720 - val_loss: 0.0334\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 596us/step - loss: 0.0720 - val_loss: 0.0330\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 599us/step - loss: 0.0720 - val_loss: 0.0333\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 600us/step - loss: 0.0720 - val_loss: 0.0334\n",
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/24\n",
      "3490/3490 [==============================] - 43s 12ms/step - loss: 0.1143 - val_loss: 0.0368\n",
      "Epoch 2/24\n",
      "3490/3490 [==============================] - 2s 606us/step - loss: 0.0638 - val_loss: 0.0157\n",
      "Epoch 3/24\n",
      "3490/3490 [==============================] - 2s 604us/step - loss: 0.0400 - val_loss: 0.1040\n",
      "Epoch 4/24\n",
      "3490/3490 [==============================] - 2s 605us/step - loss: 0.0745 - val_loss: 0.0289\n",
      "Epoch 5/24\n",
      "3490/3490 [==============================] - 2s 604us/step - loss: 0.0711 - val_loss: 0.0473\n",
      "Epoch 6/24\n",
      "3490/3490 [==============================] - 2s 606us/step - loss: 0.0603 - val_loss: 0.0348\n",
      "Epoch 7/24\n",
      "3490/3490 [==============================] - 2s 606us/step - loss: 0.0805 - val_loss: 0.0465\n",
      "Epoch 8/24\n",
      "3490/3490 [==============================] - 2s 610us/step - loss: 0.0733 - val_loss: 0.0292\n",
      "Epoch 9/24\n",
      "3490/3490 [==============================] - 2s 608us/step - loss: 0.0633 - val_loss: 0.0123\n",
      "Epoch 10/24\n",
      "3490/3490 [==============================] - 2s 604us/step - loss: 0.0290 - val_loss: 0.0337\n",
      "Epoch 11/24\n",
      "3490/3490 [==============================] - 2s 604us/step - loss: 0.0480 - val_loss: 0.0398\n",
      "Epoch 12/24\n",
      "3490/3490 [==============================] - 2s 603us/step - loss: 0.0267 - val_loss: 0.0497\n",
      "Epoch 13/24\n",
      "3490/3490 [==============================] - 2s 605us/step - loss: 0.0250 - val_loss: 0.0574\n",
      "Epoch 14/24\n",
      "3490/3490 [==============================] - 2s 604us/step - loss: 0.0238 - val_loss: 0.0639\n",
      "Epoch 15/24\n",
      "3490/3490 [==============================] - 2s 607us/step - loss: 0.0222 - val_loss: 0.0573\n",
      "Epoch 16/24\n",
      "3490/3490 [==============================] - 2s 606us/step - loss: 0.0171 - val_loss: 0.0598\n",
      "Epoch 17/24\n",
      "3490/3490 [==============================] - 2s 615us/step - loss: 0.0142 - val_loss: 0.0564\n",
      "Epoch 18/24\n",
      "3490/3490 [==============================] - 2s 605us/step - loss: 0.0114 - val_loss: 0.0302\n",
      "Epoch 19/24\n",
      "3490/3490 [==============================] - 2s 606us/step - loss: 0.0172 - val_loss: 0.0350\n",
      "Epoch 20/24\n",
      "3490/3490 [==============================] - 2s 607us/step - loss: 0.0159 - val_loss: 0.0181\n",
      "Epoch 21/24\n",
      "3490/3490 [==============================] - 2s 605us/step - loss: 0.0227 - val_loss: 0.0286\n",
      "Epoch 22/24\n",
      "3490/3490 [==============================] - 2s 608us/step - loss: 0.0063 - val_loss: 0.0535\n",
      "Epoch 23/24\n",
      "3490/3490 [==============================] - 2s 607us/step - loss: 0.0060 - val_loss: 0.0446\n",
      "Epoch 24/24\n",
      "3490/3490 [==============================] - 2s 608us/step - loss: 0.0073 - val_loss: 0.0519\n"
     ]
    }
   ],
   "source": [
    "best_models = breed_population(X_train, Y_train, generations=20, population_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0034677558578550816,\n",
       " 0.0017870757728815079,\n",
       " 0.0014964372385293245,\n",
       " 0.0023654005490243435,\n",
       " 0.0015972476685419679,\n",
       " 0.002243621274828911,\n",
       " 0.0012327985605224967,\n",
       " 0.0012157507007941604,\n",
       " 0.0013378700241446495,\n",
       " 0.0011703632771968842,\n",
       " 0.0011268395464867353,\n",
       " 0.001026210025884211,\n",
       " 0.0010529073188081384,\n",
       " 0.0009064124315045774,\n",
       " 0.0008370602154172957,\n",
       " 0.0008591523510403931,\n",
       " 0.0007754461839795113,\n",
       " 0.0007630169275216758,\n",
       " 0.00073802046244964,\n",
       " 0.0007303858874365687,\n",
       " 0.0007146400166675448,\n",
       " 0.000709084328263998,\n",
       " 0.0008199548465199769,\n",
       " 0.00068897899473086]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models[0][1].history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal parameters\n",
      "_______________________\n",
      "density: 166\n",
      "activation: relu\n",
      "twice: False\n",
      "optimizer: adam\n",
      "shuffle: True\n",
      "lstmsize: 180\n",
      "full_density: True\n"
     ]
    }
   ],
   "source": [
    "print('optimal parameters')\n",
    "print('_______________________')\n",
    "for key,val in best_models[0][2].items():\n",
    "    if key != 'x' and key != 'y': print(f'{key}: {val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_65\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_119 (LSTM)              (None, 180)               133920    \n",
      "_________________________________________________________________\n",
      "dense_265 (Dense)            (None, 166)               30046     \n",
      "_________________________________________________________________\n",
      "dense_266 (Dense)            (None, 83)                13861     \n",
      "_________________________________________________________________\n",
      "dense_267 (Dense)            (None, 41)                3444      \n",
      "_________________________________________________________________\n",
      "dense_268 (Dense)            (None, 20)                840       \n",
      "_________________________________________________________________\n",
      "dense_269 (Dense)            (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 182,132\n",
      "Trainable params: 182,132\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_models[0][0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibm_checkpoint = ModelCheckpoint(\n",
    "    filepath='./checkpoints/IBM.{epoch}-{val_loss}.hdf5',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = best_models[0][2]\n",
    "params['x'] = X_train\n",
    "params['y'] = Y_train\n",
    "params['epochs'] = 2000\n",
    "params['callbacks'] = [ibm_checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3490 samples, validate on 388 samples\n",
      "Epoch 1/2000\n",
      "3490/3490 [==============================] - 43s 12ms/step - loss: 0.2083 - val_loss: 0.0790\n",
      "Epoch 2/2000\n",
      "3490/3490 [==============================] - 1s 288us/step - loss: 0.0257 - val_loss: 0.0100\n",
      "Epoch 3/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 0.0090 - val_loss: 0.0057\n",
      "Epoch 4/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 0.0044 - val_loss: 0.0036\n",
      "Epoch 5/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 6/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 7/2000\n",
      "3490/3490 [==============================] - 1s 292us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 8/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 9/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 10/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 11/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 12/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 13/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 9.9444e-04 - val_loss: 0.0012\n",
      "Epoch 14/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 9.5617e-04 - val_loss: 0.0012\n",
      "Epoch 15/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 9.1607e-04 - val_loss: 0.0011\n",
      "Epoch 16/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 8.7768e-04 - val_loss: 0.0011\n",
      "Epoch 17/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 8.3806e-04 - val_loss: 0.0010\n",
      "Epoch 18/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 8.5527e-04 - val_loss: 9.5512e-04\n",
      "Epoch 19/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 8.0175e-04 - val_loss: 9.4318e-04\n",
      "Epoch 20/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 7.5859e-04 - val_loss: 9.0397e-04\n",
      "Epoch 21/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 7.4306e-04 - val_loss: 8.9962e-04\n",
      "Epoch 22/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 7.1362e-04 - val_loss: 8.6810e-04\n",
      "Epoch 23/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 6.9611e-04 - val_loss: 8.5597e-04\n",
      "Epoch 24/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 6.7910e-04 - val_loss: 8.5635e-04\n",
      "Epoch 25/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 6.6961e-04 - val_loss: 8.2399e-04\n",
      "Epoch 26/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 6.6966e-04 - val_loss: 8.2534e-04\n",
      "Epoch 27/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 6.4495e-04 - val_loss: 7.8973e-04\n",
      "Epoch 28/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 6.3069e-04 - val_loss: 8.1296e-04\n",
      "Epoch 29/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 6.2488e-04 - val_loss: 7.7233e-04\n",
      "Epoch 30/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 6.1514e-04 - val_loss: 7.8852e-04\n",
      "Epoch 31/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 6.3833e-04 - val_loss: 8.6333e-04\n",
      "Epoch 32/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 5.9594e-04 - val_loss: 7.3016e-04\n",
      "Epoch 33/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 5.8793e-04 - val_loss: 7.9314e-04\n",
      "Epoch 34/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.8250e-04 - val_loss: 7.0975e-04\n",
      "Epoch 35/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.6848e-04 - val_loss: 6.9161e-04\n",
      "Epoch 36/2000\n",
      "3490/3490 [==============================] - 1s 289us/step - loss: 5.7974e-04 - val_loss: 6.8433e-04\n",
      "Epoch 37/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.5720e-04 - val_loss: 6.9360e-04\n",
      "Epoch 38/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 5.6300e-04 - val_loss: 7.1515e-04\n",
      "Epoch 39/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 6.8958e-04 - val_loss: 6.8745e-04\n",
      "Epoch 40/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 5.9830e-04 - val_loss: 6.7944e-04\n",
      "Epoch 41/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.5575e-04 - val_loss: 6.7412e-04\n",
      "Epoch 42/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 5.4840e-04 - val_loss: 6.9768e-04\n",
      "Epoch 43/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 6.1589e-04 - val_loss: 7.4737e-04\n",
      "Epoch 44/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 5.6221e-04 - val_loss: 8.9419e-04\n",
      "Epoch 45/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.5402e-04 - val_loss: 7.3853e-04\n",
      "Epoch 46/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.2285e-04 - val_loss: 6.5115e-04\n",
      "Epoch 47/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 5.3694e-04 - val_loss: 6.3376e-04\n",
      "Epoch 48/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.3246e-04 - val_loss: 7.5086e-04\n",
      "Epoch 49/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 5.2304e-04 - val_loss: 6.9235e-04\n",
      "Epoch 50/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 6.2290e-04 - val_loss: 6.8467e-04\n",
      "Epoch 51/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 5.4504e-04 - val_loss: 6.7629e-04\n",
      "Epoch 52/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 6.0396e-04 - val_loss: 6.3470e-04\n",
      "Epoch 53/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 5.4963e-04 - val_loss: 6.4905e-04\n",
      "Epoch 54/2000\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 5.4847e-04 - val_loss: 6.7333e-04\n",
      "Epoch 55/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.6837e-04 - val_loss: 6.2767e-04\n",
      "Epoch 56/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 5.3805e-04 - val_loss: 6.3052e-04\n",
      "Epoch 57/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.4514e-04 - val_loss: 6.5273e-04\n",
      "Epoch 58/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.2867e-04 - val_loss: 6.1802e-04\n",
      "Epoch 59/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 4.9932e-04 - val_loss: 6.1652e-04\n",
      "Epoch 60/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 5.5459e-04 - val_loss: 7.7367e-04\n",
      "Epoch 61/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 5.1784e-04 - val_loss: 9.2964e-04\n",
      "Epoch 62/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 5.4897e-04 - val_loss: 6.9167e-04\n",
      "Epoch 63/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 5.4284e-04 - val_loss: 6.8885e-04\n",
      "Epoch 64/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 5.0142e-04 - val_loss: 5.9931e-04\n",
      "Epoch 65/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 5.1836e-04 - val_loss: 7.6640e-04\n",
      "Epoch 66/2000\n",
      "3490/3490 [==============================] - 1s 287us/step - loss: 5.1160e-04 - val_loss: 6.0959e-04\n",
      "Epoch 67/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.4493e-04 - val_loss: 6.1158e-04\n",
      "Epoch 68/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.4602e-04 - val_loss: 6.0509e-04\n",
      "Epoch 69/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 5.1314e-04 - val_loss: 5.9846e-04\n",
      "Epoch 70/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 5.2832e-04 - val_loss: 6.1210e-04\n",
      "Epoch 71/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.1723e-04 - val_loss: 6.0632e-04\n",
      "Epoch 72/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.3257e-04 - val_loss: 6.2673e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.4069e-04 - val_loss: 5.9742e-04\n",
      "Epoch 74/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.0738e-04 - val_loss: 6.7461e-04\n",
      "Epoch 75/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.3104e-04 - val_loss: 6.7476e-04\n",
      "Epoch 76/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.0204e-04 - val_loss: 6.4638e-04\n",
      "Epoch 77/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.8289e-04 - val_loss: 5.8173e-04\n",
      "Epoch 78/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.1612e-04 - val_loss: 6.0954e-04\n",
      "Epoch 79/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.8706e-04 - val_loss: 5.8536e-04\n",
      "Epoch 80/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 4.7954e-04 - val_loss: 5.7350e-04\n",
      "Epoch 81/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 4.8169e-04 - val_loss: 6.7502e-04\n",
      "Epoch 82/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.7781e-04 - val_loss: 7.5911e-04\n",
      "Epoch 83/2000\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 4.7557e-04 - val_loss: 8.4882e-04\n",
      "Epoch 84/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.8797e-04 - val_loss: 9.4475e-04\n",
      "Epoch 85/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.0617e-04 - val_loss: 7.3566e-04\n",
      "Epoch 86/2000\n",
      "3490/3490 [==============================] - 1s 288us/step - loss: 4.7811e-04 - val_loss: 7.1076e-04\n",
      "Epoch 87/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 4.5935e-04 - val_loss: 6.9494e-04\n",
      "Epoch 88/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 4.8809e-04 - val_loss: 5.5284e-04\n",
      "Epoch 89/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.8197e-04 - val_loss: 6.0568e-04\n",
      "Epoch 90/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.7122e-04 - val_loss: 6.3778e-04\n",
      "Epoch 91/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.6036e-04 - val_loss: 6.2766e-04\n",
      "Epoch 92/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.7373e-04 - val_loss: 5.9092e-04\n",
      "Epoch 93/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 4.5253e-04 - val_loss: 7.2838e-04\n",
      "Epoch 94/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.8948e-04 - val_loss: 7.0844e-04\n",
      "Epoch 95/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 5.1238e-04 - val_loss: 5.9572e-04\n",
      "Epoch 96/2000\n",
      "3490/3490 [==============================] - 1s 287us/step - loss: 4.4779e-04 - val_loss: 6.0138e-04\n",
      "Epoch 97/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 4.5347e-04 - val_loss: 5.4317e-04\n",
      "Epoch 98/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.6335e-04 - val_loss: 7.3320e-04\n",
      "Epoch 99/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.4359e-04 - val_loss: 5.4625e-04\n",
      "Epoch 100/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 4.4257e-04 - val_loss: 5.4121e-04\n",
      "Epoch 101/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.3552e-04 - val_loss: 0.0011\n",
      "Epoch 102/2000\n",
      "3490/3490 [==============================] - 1s 288us/step - loss: 5.5081e-04 - val_loss: 8.9772e-04\n",
      "Epoch 103/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.7427e-04 - val_loss: 6.8660e-04\n",
      "Epoch 104/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 4.6535e-04 - val_loss: 5.7835e-04\n",
      "Epoch 105/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 4.7204e-04 - val_loss: 5.3186e-04\n",
      "Epoch 106/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 4.8372e-04 - val_loss: 5.2657e-04\n",
      "Epoch 107/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 4.8327e-04 - val_loss: 7.4705e-04\n",
      "Epoch 108/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 5.0226e-04 - val_loss: 7.7896e-04\n",
      "Epoch 109/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 4.5444e-04 - val_loss: 6.9870e-04\n",
      "Epoch 110/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.6883e-04 - val_loss: 6.8049e-04\n",
      "Epoch 111/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 4.5551e-04 - val_loss: 5.5518e-04\n",
      "Epoch 112/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.3965e-04 - val_loss: 5.4000e-04\n",
      "Epoch 113/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.4225e-04 - val_loss: 5.1979e-04\n",
      "Epoch 114/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 4.2662e-04 - val_loss: 5.1187e-04\n",
      "Epoch 115/2000\n",
      "3490/3490 [==============================] - 1s 280us/step - loss: 4.3821e-04 - val_loss: 5.3639e-04\n",
      "Epoch 116/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 4.5165e-04 - val_loss: 8.2012e-04\n",
      "Epoch 117/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 4.8003e-04 - val_loss: 6.4302e-04\n",
      "Epoch 118/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 4.4418e-04 - val_loss: 5.1482e-04\n",
      "Epoch 119/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.6500e-04 - val_loss: 5.9302e-04\n",
      "Epoch 120/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 4.8064e-04 - val_loss: 5.5281e-04\n",
      "Epoch 121/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.7151e-04 - val_loss: 5.1074e-04\n",
      "Epoch 122/2000\n",
      "3490/3490 [==============================] - 1s 291us/step - loss: 4.5840e-04 - val_loss: 5.4897e-04\n",
      "Epoch 123/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.3981e-04 - val_loss: 5.2689e-04\n",
      "Epoch 124/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 4.5527e-04 - val_loss: 5.7119e-04\n",
      "Epoch 125/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 4.8973e-04 - val_loss: 0.0011\n",
      "Epoch 126/2000\n",
      "3490/3490 [==============================] - 1s 288us/step - loss: 5.0756e-04 - val_loss: 5.9858e-04\n",
      "Epoch 127/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 4.6282e-04 - val_loss: 5.3671e-04\n",
      "Epoch 128/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.9763e-04 - val_loss: 5.2328e-04\n",
      "Epoch 129/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 4.5536e-04 - val_loss: 5.2874e-04\n",
      "Epoch 130/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 4.1840e-04 - val_loss: 5.2670e-04\n",
      "Epoch 131/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 4.1108e-04 - val_loss: 5.5548e-04\n",
      "Epoch 132/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 4.3231e-04 - val_loss: 6.1293e-04\n",
      "Epoch 133/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 4.2199e-04 - val_loss: 5.1267e-04\n",
      "Epoch 134/2000\n",
      "3490/3490 [==============================] - 1s 287us/step - loss: 4.2592e-04 - val_loss: 5.1669e-04\n",
      "Epoch 135/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 4.2957e-04 - val_loss: 5.1275e-04\n",
      "Epoch 136/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 4.1518e-04 - val_loss: 4.9997e-04\n",
      "Epoch 137/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 4.1512e-04 - val_loss: 5.0196e-04\n",
      "Epoch 138/2000\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 4.2822e-04 - val_loss: 5.4010e-04\n",
      "Epoch 139/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.1378e-04 - val_loss: 5.8315e-04\n",
      "Epoch 140/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 4.2127e-04 - val_loss: 5.5092e-04\n",
      "Epoch 141/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 4.2857e-04 - val_loss: 5.0190e-04\n",
      "Epoch 142/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 4.1932e-04 - val_loss: 5.5367e-04\n",
      "Epoch 143/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 4.1284e-04 - val_loss: 4.9569e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 4.1926e-04 - val_loss: 5.3484e-04\n",
      "Epoch 145/2000\n",
      "3490/3490 [==============================] - 1s 280us/step - loss: 4.4235e-04 - val_loss: 4.9534e-04\n",
      "Epoch 146/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 4.5459e-04 - val_loss: 5.8992e-04\n",
      "Epoch 147/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 4.4153e-04 - val_loss: 5.0130e-04\n",
      "Epoch 148/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 4.2887e-04 - val_loss: 5.5516e-04\n",
      "Epoch 149/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 4.2598e-04 - val_loss: 8.9649e-04\n",
      "Epoch 150/2000\n",
      "3490/3490 [==============================] - 1s 287us/step - loss: 4.5663e-04 - val_loss: 9.3394e-04\n",
      "Epoch 151/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 4.4830e-04 - val_loss: 6.7265e-04\n",
      "Epoch 152/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 4.0543e-04 - val_loss: 5.0348e-04\n",
      "Epoch 153/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.9735e-04 - val_loss: 4.9823e-04\n",
      "Epoch 154/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 4.1042e-04 - val_loss: 5.0252e-04\n",
      "Epoch 155/2000\n",
      "3490/3490 [==============================] - 1s 287us/step - loss: 4.4807e-04 - val_loss: 6.2631e-04\n",
      "Epoch 156/2000\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 4.0645e-04 - val_loss: 5.7361e-04\n",
      "Epoch 157/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 4.0432e-04 - val_loss: 6.1836e-04\n",
      "Epoch 158/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 4.2629e-04 - val_loss: 5.5562e-04\n",
      "Epoch 159/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 4.0364e-04 - val_loss: 4.8997e-04\n",
      "Epoch 160/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 4.0874e-04 - val_loss: 5.5209e-04\n",
      "Epoch 161/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 4.4408e-04 - val_loss: 4.9795e-04\n",
      "Epoch 162/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.0351e-04 - val_loss: 4.9213e-04\n",
      "Epoch 163/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.9472e-04 - val_loss: 6.0392e-04\n",
      "Epoch 164/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 4.1306e-04 - val_loss: 6.6669e-04\n",
      "Epoch 165/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 4.1799e-04 - val_loss: 5.2810e-04\n",
      "Epoch 166/2000\n",
      "3490/3490 [==============================] - 1s 288us/step - loss: 4.0963e-04 - val_loss: 4.8935e-04\n",
      "Epoch 167/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.9928e-04 - val_loss: 5.7955e-04\n",
      "Epoch 168/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.1888e-04 - val_loss: 4.9175e-04\n",
      "Epoch 169/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 4.0260e-04 - val_loss: 4.9788e-04\n",
      "Epoch 170/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 4.0812e-04 - val_loss: 5.5330e-04\n",
      "Epoch 171/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 4.2387e-04 - val_loss: 5.0172e-04\n",
      "Epoch 172/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 4.6506e-04 - val_loss: 5.7474e-04\n",
      "Epoch 173/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 4.7124e-04 - val_loss: 4.9827e-04\n",
      "Epoch 174/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 4.5440e-04 - val_loss: 5.0099e-04\n",
      "Epoch 175/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.6400e-04 - val_loss: 5.9479e-04\n",
      "Epoch 176/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 4.1012e-04 - val_loss: 5.0244e-04\n",
      "Epoch 177/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.9533e-04 - val_loss: 5.6279e-04\n",
      "Epoch 178/2000\n",
      "3490/3490 [==============================] - 1s 288us/step - loss: 4.0453e-04 - val_loss: 4.9862e-04\n",
      "Epoch 179/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 4.1226e-04 - val_loss: 4.8641e-04\n",
      "Epoch 180/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 4.1096e-04 - val_loss: 5.5946e-04\n",
      "Epoch 181/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.2876e-04 - val_loss: 6.5107e-04\n",
      "Epoch 182/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 4.3876e-04 - val_loss: 6.3117e-04\n",
      "Epoch 183/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 4.5512e-04 - val_loss: 6.6697e-04\n",
      "Epoch 184/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.3064e-04 - val_loss: 4.9086e-04\n",
      "Epoch 185/2000\n",
      "3490/3490 [==============================] - 1s 288us/step - loss: 3.9864e-04 - val_loss: 5.1009e-04\n",
      "Epoch 186/2000\n",
      "3490/3490 [==============================] - 1s 291us/step - loss: 3.8951e-04 - val_loss: 6.2936e-04\n",
      "Epoch 187/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.1600e-04 - val_loss: 5.0875e-04\n",
      "Epoch 188/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.8297e-04 - val_loss: 4.9151e-04\n",
      "Epoch 189/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.8953e-04 - val_loss: 4.8857e-04\n",
      "Epoch 190/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.9596e-04 - val_loss: 5.1904e-04\n",
      "Epoch 191/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.1308e-04 - val_loss: 5.6781e-04\n",
      "Epoch 192/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.0253e-04 - val_loss: 5.0589e-04\n",
      "Epoch 193/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.9139e-04 - val_loss: 5.6668e-04\n",
      "Epoch 194/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 3.9359e-04 - val_loss: 5.3485e-04\n",
      "Epoch 195/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 3.8687e-04 - val_loss: 4.8334e-04\n",
      "Epoch 196/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.9329e-04 - val_loss: 4.8784e-04\n",
      "Epoch 197/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 4.1262e-04 - val_loss: 4.8799e-04\n",
      "Epoch 198/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 4.1404e-04 - val_loss: 4.9422e-04\n",
      "Epoch 199/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.6276e-04 - val_loss: 5.2738e-04\n",
      "Epoch 200/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.1442e-04 - val_loss: 5.3656e-04\n",
      "Epoch 201/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.5746e-04 - val_loss: 4.9735e-04\n",
      "Epoch 202/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.9615e-04 - val_loss: 4.8898e-04\n",
      "Epoch 203/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.8662e-04 - val_loss: 4.9110e-04\n",
      "Epoch 204/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.8654e-04 - val_loss: 5.3027e-04\n",
      "Epoch 205/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.8705e-04 - val_loss: 5.7814e-04\n",
      "Epoch 206/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 3.9532e-04 - val_loss: 5.6823e-04\n",
      "Epoch 207/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.8321e-04 - val_loss: 5.0801e-04\n",
      "Epoch 208/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.8124e-04 - val_loss: 5.4061e-04\n",
      "Epoch 209/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.8898e-04 - val_loss: 5.4263e-04\n",
      "Epoch 210/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 4.2429e-04 - val_loss: 4.8957e-04\n",
      "Epoch 211/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.7934e-04 - val_loss: 4.9015e-04\n",
      "Epoch 212/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.8698e-04 - val_loss: 4.9402e-04\n",
      "Epoch 213/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.1363e-04 - val_loss: 5.0067e-04\n",
      "Epoch 214/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3490/3490 [==============================] - 1s 288us/step - loss: 4.1041e-04 - val_loss: 4.9596e-04\n",
      "Epoch 215/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.9155e-04 - val_loss: 5.7031e-04\n",
      "Epoch 216/2000\n",
      "3490/3490 [==============================] - 1s 289us/step - loss: 3.8686e-04 - val_loss: 4.9618e-04\n",
      "Epoch 217/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.8070e-04 - val_loss: 4.9608e-04\n",
      "Epoch 218/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 3.9938e-04 - val_loss: 6.0967e-04\n",
      "Epoch 219/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 4.5132e-04 - val_loss: 5.0900e-04\n",
      "Epoch 220/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.0569e-04 - val_loss: 0.0011\n",
      "Epoch 221/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.8313e-04 - val_loss: 7.7433e-04\n",
      "Epoch 222/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 4.9340e-04 - val_loss: 4.9768e-04\n",
      "Epoch 223/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.3917e-04 - val_loss: 5.6220e-04\n",
      "Epoch 224/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.3507e-04 - val_loss: 4.9581e-04\n",
      "Epoch 225/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.0838e-04 - val_loss: 5.3755e-04\n",
      "Epoch 226/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.1338e-04 - val_loss: 6.4685e-04\n",
      "Epoch 227/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 4.1330e-04 - val_loss: 7.8504e-04\n",
      "Epoch 228/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.2460e-04 - val_loss: 5.1817e-04\n",
      "Epoch 229/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.9290e-04 - val_loss: 4.8451e-04\n",
      "Epoch 230/2000\n",
      "3490/3490 [==============================] - 1s 288us/step - loss: 3.9581e-04 - val_loss: 5.2342e-04\n",
      "Epoch 231/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.5573e-04 - val_loss: 5.2526e-04\n",
      "Epoch 232/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 4.3742e-04 - val_loss: 5.1412e-04\n",
      "Epoch 233/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 4.0928e-04 - val_loss: 7.0069e-04\n",
      "Epoch 234/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 4.2782e-04 - val_loss: 5.1968e-04\n",
      "Epoch 235/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.5134e-04 - val_loss: 4.9722e-04\n",
      "Epoch 236/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 4.5242e-04 - val_loss: 5.2576e-04\n",
      "Epoch 237/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.2098e-04 - val_loss: 5.3779e-04\n",
      "Epoch 238/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 3.9133e-04 - val_loss: 5.3578e-04\n",
      "Epoch 239/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.8437e-04 - val_loss: 4.8835e-04\n",
      "Epoch 240/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.7772e-04 - val_loss: 5.2695e-04\n",
      "Epoch 241/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.9639e-04 - val_loss: 5.6559e-04\n",
      "Epoch 242/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.7936e-04 - val_loss: 4.8385e-04\n",
      "Epoch 243/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.8525e-04 - val_loss: 4.8817e-04\n",
      "Epoch 244/2000\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 3.8385e-04 - val_loss: 5.0827e-04\n",
      "Epoch 245/2000\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 3.7547e-04 - val_loss: 4.8942e-04\n",
      "Epoch 246/2000\n",
      "3490/3490 [==============================] - 1s 294us/step - loss: 3.8288e-04 - val_loss: 6.3574e-04\n",
      "Epoch 247/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.8460e-04 - val_loss: 4.9112e-04\n",
      "Epoch 248/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.9216e-04 - val_loss: 4.8517e-04\n",
      "Epoch 249/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.9309e-04 - val_loss: 4.9501e-04\n",
      "Epoch 250/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.8978e-04 - val_loss: 4.8466e-04\n",
      "Epoch 251/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.0220e-04 - val_loss: 4.8672e-04\n",
      "Epoch 252/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.8532e-04 - val_loss: 5.0994e-04\n",
      "Epoch 253/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.7869e-04 - val_loss: 4.9504e-04\n",
      "Epoch 254/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.0107e-04 - val_loss: 4.8622e-04\n",
      "Epoch 255/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.8149e-04 - val_loss: 6.0799e-04\n",
      "Epoch 256/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.8916e-04 - val_loss: 5.4135e-04\n",
      "Epoch 257/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.8210e-04 - val_loss: 5.6555e-04\n",
      "Epoch 258/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 4.0932e-04 - val_loss: 6.5408e-04\n",
      "Epoch 259/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 4.2454e-04 - val_loss: 6.9261e-04\n",
      "Epoch 260/2000\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 4.2769e-04 - val_loss: 6.8650e-04\n",
      "Epoch 261/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 4.2337e-04 - val_loss: 6.7263e-04\n",
      "Epoch 262/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 3.8625e-04 - val_loss: 4.8784e-04\n",
      "Epoch 263/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 3.9505e-04 - val_loss: 5.8969e-04\n",
      "Epoch 264/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 4.5121e-04 - val_loss: 5.5498e-04\n",
      "Epoch 265/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 4.1782e-04 - val_loss: 6.5171e-04\n",
      "Epoch 266/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.0042e-04 - val_loss: 6.1030e-04\n",
      "Epoch 267/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 4.1478e-04 - val_loss: 5.2740e-04\n",
      "Epoch 268/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.1088e-04 - val_loss: 4.8656e-04\n",
      "Epoch 269/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.3662e-04 - val_loss: 5.3798e-04\n",
      "Epoch 270/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.3486e-04 - val_loss: 5.2469e-04\n",
      "Epoch 271/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.8783e-04 - val_loss: 5.9283e-04\n",
      "Epoch 272/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.9088e-04 - val_loss: 5.6478e-04\n",
      "Epoch 273/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 3.7968e-04 - val_loss: 5.1296e-04\n",
      "Epoch 274/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 3.7613e-04 - val_loss: 4.8518e-04\n",
      "Epoch 275/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.8360e-04 - val_loss: 4.8587e-04\n",
      "Epoch 276/2000\n",
      "3490/3490 [==============================] - 1s 289us/step - loss: 3.9969e-04 - val_loss: 5.8552e-04\n",
      "Epoch 277/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.0008e-04 - val_loss: 5.9284e-04\n",
      "Epoch 278/2000\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 4.0377e-04 - val_loss: 7.0388e-04\n",
      "Epoch 279/2000\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 4.3050e-04 - val_loss: 5.1019e-04\n",
      "Epoch 280/2000\n",
      "3490/3490 [==============================] - 1s 295us/step - loss: 4.1181e-04 - val_loss: 5.1478e-04\n",
      "Epoch 281/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.1329e-04 - val_loss: 4.9816e-04\n",
      "Epoch 282/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 4.1263e-04 - val_loss: 5.7540e-04\n",
      "Epoch 283/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 3.8072e-04 - val_loss: 5.3061e-04\n",
      "Epoch 284/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.8425e-04 - val_loss: 4.8420e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 285/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.8170e-04 - val_loss: 4.8591e-04\n",
      "Epoch 286/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.7709e-04 - val_loss: 4.8453e-04\n",
      "Epoch 287/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.9787e-04 - val_loss: 4.8593e-04\n",
      "Epoch 288/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.7959e-04 - val_loss: 4.8507e-04\n",
      "Epoch 289/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 4.1395e-04 - val_loss: 4.8491e-04\n",
      "Epoch 290/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.9174e-04 - val_loss: 6.2577e-04\n",
      "Epoch 291/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.2839e-04 - val_loss: 6.9788e-04\n",
      "Epoch 292/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 4.0402e-04 - val_loss: 6.1499e-04\n",
      "Epoch 293/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 3.9325e-04 - val_loss: 4.8457e-04\n",
      "Epoch 294/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 4.1861e-04 - val_loss: 4.8382e-04\n",
      "Epoch 295/2000\n",
      "3490/3490 [==============================] - ETA: 0s - loss: 3.9067e-0 - 1s 286us/step - loss: 3.8585e-04 - val_loss: 4.8724e-04\n",
      "Epoch 296/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.8085e-04 - val_loss: 6.3018e-04\n",
      "Epoch 297/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.0667e-04 - val_loss: 5.8482e-04\n",
      "Epoch 298/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.9706e-04 - val_loss: 4.9010e-04\n",
      "Epoch 299/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 4.0729e-04 - val_loss: 4.9055e-04\n",
      "Epoch 300/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 4.0799e-04 - val_loss: 5.8362e-04\n",
      "Epoch 301/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 4.2157e-04 - val_loss: 4.8987e-04\n",
      "Epoch 302/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 4.0625e-04 - val_loss: 5.8327e-04\n",
      "Epoch 303/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.9257e-04 - val_loss: 5.5619e-04\n",
      "Epoch 304/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.7624e-04 - val_loss: 5.2472e-04\n",
      "Epoch 305/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.8036e-04 - val_loss: 6.2761e-04\n",
      "Epoch 306/2000\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 3.9552e-04 - val_loss: 4.8195e-04\n",
      "Epoch 307/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 3.9935e-04 - val_loss: 5.0719e-04\n",
      "Epoch 308/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 4.3236e-04 - val_loss: 4.8943e-04\n",
      "Epoch 309/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.4310e-04 - val_loss: 7.5853e-04\n",
      "Epoch 310/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 4.0204e-04 - val_loss: 4.9017e-04\n",
      "Epoch 311/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 3.7589e-04 - val_loss: 4.8186e-04\n",
      "Epoch 312/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.8000e-04 - val_loss: 4.8704e-04\n",
      "Epoch 313/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 3.7416e-04 - val_loss: 5.0270e-04\n",
      "Epoch 314/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.7362e-04 - val_loss: 5.7233e-04\n",
      "Epoch 315/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.7665e-04 - val_loss: 4.8757e-04\n",
      "Epoch 316/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 3.6812e-04 - val_loss: 5.0267e-04\n",
      "Epoch 317/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.7939e-04 - val_loss: 4.7846e-04\n",
      "Epoch 318/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.7671e-04 - val_loss: 4.7868e-04\n",
      "Epoch 319/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.7608e-04 - val_loss: 4.9288e-04\n",
      "Epoch 320/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.8309e-04 - val_loss: 4.8427e-04\n",
      "Epoch 321/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.8264e-04 - val_loss: 5.2543e-04\n",
      "Epoch 322/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.7024e-04 - val_loss: 4.8234e-04\n",
      "Epoch 323/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.8406e-04 - val_loss: 4.8136e-04\n",
      "Epoch 324/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 3.7762e-04 - val_loss: 4.9105e-04\n",
      "Epoch 325/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.9377e-04 - val_loss: 5.1631e-04\n",
      "Epoch 326/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.0520e-04 - val_loss: 6.6341e-04\n",
      "Epoch 327/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.8269e-04 - val_loss: 5.0472e-04\n",
      "Epoch 328/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.7231e-04 - val_loss: 5.0547e-04\n",
      "Epoch 329/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.6749e-04 - val_loss: 5.5978e-04\n",
      "Epoch 330/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 3.8121e-04 - val_loss: 5.7437e-04\n",
      "Epoch 331/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 3.7796e-04 - val_loss: 5.1279e-04\n",
      "Epoch 332/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.7802e-04 - val_loss: 4.9181e-04\n",
      "Epoch 333/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.7153e-04 - val_loss: 5.2051e-04\n",
      "Epoch 334/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.7195e-04 - val_loss: 5.5995e-04\n",
      "Epoch 335/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.9006e-04 - val_loss: 6.3265e-04\n",
      "Epoch 336/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 3.9569e-04 - val_loss: 5.6265e-04\n",
      "Epoch 337/2000\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 3.9766e-04 - val_loss: 4.8248e-04\n",
      "Epoch 338/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.8461e-04 - val_loss: 4.8591e-04\n",
      "Epoch 339/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.8552e-04 - val_loss: 5.3053e-04\n",
      "Epoch 340/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.7950e-04 - val_loss: 4.9143e-04\n",
      "Epoch 341/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 3.7746e-04 - val_loss: 5.5313e-04\n",
      "Epoch 342/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.7120e-04 - val_loss: 4.7842e-04\n",
      "Epoch 343/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 3.7195e-04 - val_loss: 5.0232e-04\n",
      "Epoch 344/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.6997e-04 - val_loss: 5.1277e-04\n",
      "Epoch 345/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.7824e-04 - val_loss: 5.7540e-04\n",
      "Epoch 346/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.8639e-04 - val_loss: 5.4677e-04\n",
      "Epoch 347/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.7489e-04 - val_loss: 6.0424e-04\n",
      "Epoch 348/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.9276e-04 - val_loss: 6.0620e-04\n",
      "Epoch 349/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.8102e-04 - val_loss: 6.9126e-04\n",
      "Epoch 350/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.0448e-04 - val_loss: 6.9600e-04\n",
      "Epoch 351/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 4.0390e-04 - val_loss: 4.8292e-04\n",
      "Epoch 352/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.8870e-04 - val_loss: 5.3669e-04\n",
      "Epoch 353/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.6589e-04 - val_loss: 4.8164e-04\n",
      "Epoch 354/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.7026e-04 - val_loss: 4.8132e-04\n",
      "Epoch 355/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.9422e-04 - val_loss: 5.4196e-04\n",
      "Epoch 356/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 4.1567e-04 - val_loss: 4.7871e-04\n",
      "Epoch 357/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 3.8797e-04 - val_loss: 5.1075e-04\n",
      "Epoch 358/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.8776e-04 - val_loss: 6.3426e-04\n",
      "Epoch 359/2000\n",
      "3490/3490 [==============================] - 1s 288us/step - loss: 3.9338e-04 - val_loss: 5.6056e-04\n",
      "Epoch 360/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.9380e-04 - val_loss: 4.9155e-04\n",
      "Epoch 361/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.7400e-04 - val_loss: 5.9470e-04\n",
      "Epoch 362/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 3.8364e-04 - val_loss: 5.0328e-04\n",
      "Epoch 363/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.8908e-04 - val_loss: 5.8226e-04\n",
      "Epoch 364/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.5685e-04 - val_loss: 8.3027e-04\n",
      "Epoch 365/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 4.1816e-04 - val_loss: 5.1292e-04\n",
      "Epoch 366/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.7792e-04 - val_loss: 4.8529e-04\n",
      "Epoch 367/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 3.8005e-04 - val_loss: 4.8414e-04\n",
      "Epoch 368/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.7215e-04 - val_loss: 5.3081e-04\n",
      "Epoch 369/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.9417e-04 - val_loss: 6.2984e-04\n",
      "Epoch 370/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 3.9281e-04 - val_loss: 5.9207e-04\n",
      "Epoch 371/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 3.6759e-04 - val_loss: 5.1086e-04\n",
      "Epoch 372/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.6888e-04 - val_loss: 5.1767e-04\n",
      "Epoch 373/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.6713e-04 - val_loss: 5.7238e-04\n",
      "Epoch 374/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.7694e-04 - val_loss: 5.9278e-04\n",
      "Epoch 375/2000\n",
      "3490/3490 [==============================] - 1s 288us/step - loss: 3.7644e-04 - val_loss: 6.7898e-04\n",
      "Epoch 376/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.8178e-04 - val_loss: 5.1832e-04\n",
      "Epoch 377/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.6517e-04 - val_loss: 6.1036e-04\n",
      "Epoch 378/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.7533e-04 - val_loss: 4.9545e-04\n",
      "Epoch 379/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.7918e-04 - val_loss: 4.8903e-04\n",
      "Epoch 380/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 3.8085e-04 - val_loss: 5.2892e-04\n",
      "Epoch 381/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.6758e-04 - val_loss: 5.2791e-04\n",
      "Epoch 382/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 3.6389e-04 - val_loss: 4.8276e-04\n",
      "Epoch 383/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.6639e-04 - val_loss: 5.0067e-04\n",
      "Epoch 384/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.8092e-04 - val_loss: 4.8732e-04\n",
      "Epoch 385/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.8170e-04 - val_loss: 4.7991e-04\n",
      "Epoch 386/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.6622e-04 - val_loss: 6.1193e-04\n",
      "Epoch 387/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.8567e-04 - val_loss: 6.3958e-04\n",
      "Epoch 388/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.7899e-04 - val_loss: 5.7176e-04\n",
      "Epoch 389/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.9060e-04 - val_loss: 5.9981e-04\n",
      "Epoch 390/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.9884e-04 - val_loss: 4.8437e-04\n",
      "Epoch 391/2000\n",
      "3490/3490 [==============================] - 1s 287us/step - loss: 3.8799e-04 - val_loss: 4.8610e-04\n",
      "Epoch 392/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.7359e-04 - val_loss: 5.1299e-04\n",
      "Epoch 393/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.6038e-04 - val_loss: 5.2205e-04\n",
      "Epoch 394/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.7233e-04 - val_loss: 6.1439e-04\n",
      "Epoch 395/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.7287e-04 - val_loss: 4.9894e-04\n",
      "Epoch 396/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.7013e-04 - val_loss: 4.8669e-04\n",
      "Epoch 397/2000\n",
      "3490/3490 [==============================] - 1s 288us/step - loss: 3.7884e-04 - val_loss: 4.8601e-04\n",
      "Epoch 398/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.8319e-04 - val_loss: 5.3713e-04\n",
      "Epoch 399/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.7156e-04 - val_loss: 5.3416e-04\n",
      "Epoch 400/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.7831e-04 - val_loss: 5.8039e-04\n",
      "Epoch 401/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.4030e-04 - val_loss: 8.1121e-04\n",
      "Epoch 402/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.9121e-04 - val_loss: 5.0491e-04\n",
      "Epoch 403/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 3.7822e-04 - val_loss: 4.8686e-04\n",
      "Epoch 404/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.1084e-04 - val_loss: 5.6532e-04\n",
      "Epoch 405/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 4.5832e-04 - val_loss: 5.7593e-04\n",
      "Epoch 406/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.4596e-04 - val_loss: 6.2388e-04\n",
      "Epoch 407/2000\n",
      "3490/3490 [==============================] - 1s 289us/step - loss: 4.0244e-04 - val_loss: 6.0781e-04\n",
      "Epoch 408/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.7983e-04 - val_loss: 5.3944e-04\n",
      "Epoch 409/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.8239e-04 - val_loss: 4.8117e-04\n",
      "Epoch 410/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.8267e-04 - val_loss: 5.2322e-04\n",
      "Epoch 411/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 4.0265e-04 - val_loss: 4.8775e-04\n",
      "Epoch 412/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 3.6589e-04 - val_loss: 5.7596e-04\n",
      "Epoch 413/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.0850e-04 - val_loss: 5.3653e-04\n",
      "Epoch 414/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.5579e-04 - val_loss: 5.2910e-04\n",
      "Epoch 415/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.0038e-04 - val_loss: 4.8043e-04\n",
      "Epoch 416/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 3.6939e-04 - val_loss: 6.5101e-04\n",
      "Epoch 417/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 4.0897e-04 - val_loss: 5.7422e-04\n",
      "Epoch 418/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.9533e-04 - val_loss: 4.8259e-04\n",
      "Epoch 419/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.6528e-04 - val_loss: 4.8034e-04\n",
      "Epoch 420/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.6477e-04 - val_loss: 4.8402e-04\n",
      "Epoch 421/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 3.6869e-04 - val_loss: 5.1592e-04\n",
      "Epoch 422/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.6037e-04 - val_loss: 4.8203e-04\n",
      "Epoch 423/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 3.8552e-04 - val_loss: 5.1255e-04\n",
      "Epoch 424/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.8485e-04 - val_loss: 6.7380e-04\n",
      "Epoch 425/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.8335e-04 - val_loss: 6.0213e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 426/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 3.8891e-04 - val_loss: 5.0432e-04\n",
      "Epoch 427/2000\n",
      "3490/3490 [==============================] - 1s 287us/step - loss: 3.7830e-04 - val_loss: 4.8252e-04\n",
      "Epoch 428/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.7033e-04 - val_loss: 4.8506e-04\n",
      "Epoch 429/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.6224e-04 - val_loss: 4.9236e-04\n",
      "Epoch 430/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.6609e-04 - val_loss: 7.3270e-04\n",
      "Epoch 431/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.0327e-04 - val_loss: 5.0419e-04\n",
      "Epoch 432/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.6612e-04 - val_loss: 5.0058e-04\n",
      "Epoch 433/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.6289e-04 - val_loss: 4.8908e-04\n",
      "Epoch 434/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.6256e-04 - val_loss: 4.8736e-04\n",
      "Epoch 435/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.7152e-04 - val_loss: 6.7606e-04\n",
      "Epoch 436/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.8215e-04 - val_loss: 6.3858e-04\n",
      "Epoch 437/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.8259e-04 - val_loss: 5.1601e-04\n",
      "Epoch 438/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.7239e-04 - val_loss: 4.8580e-04\n",
      "Epoch 439/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 3.8398e-04 - val_loss: 5.2742e-04\n",
      "Epoch 440/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.7794e-04 - val_loss: 7.8705e-04\n",
      "Epoch 441/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.9590e-04 - val_loss: 5.4313e-04\n",
      "Epoch 442/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.6141e-04 - val_loss: 4.9879e-04\n",
      "Epoch 443/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.5553e-04 - val_loss: 4.7600e-04\n",
      "Epoch 444/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.7150e-04 - val_loss: 4.8900e-04\n",
      "Epoch 445/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.6422e-04 - val_loss: 5.0136e-04\n",
      "Epoch 446/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.7834e-04 - val_loss: 6.7383e-04\n",
      "Epoch 447/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.7810e-04 - val_loss: 4.9271e-04\n",
      "Epoch 448/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.6015e-04 - val_loss: 5.1642e-04\n",
      "Epoch 449/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.6006e-04 - val_loss: 4.7822e-04\n",
      "Epoch 450/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.7249e-04 - val_loss: 4.8022e-04\n",
      "Epoch 451/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.5786e-04 - val_loss: 4.8296e-04\n",
      "Epoch 452/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 3.7452e-04 - val_loss: 5.9390e-04\n",
      "Epoch 453/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 3.8920e-04 - val_loss: 6.5141e-04\n",
      "Epoch 454/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.7033e-04 - val_loss: 4.9715e-04\n",
      "Epoch 455/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.7154e-04 - val_loss: 4.8105e-04\n",
      "Epoch 456/2000\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 3.6486e-04 - val_loss: 5.0593e-04\n",
      "Epoch 457/2000\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 3.7770e-04 - val_loss: 6.1021e-04\n",
      "Epoch 458/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.7655e-04 - val_loss: 6.9335e-04\n",
      "Epoch 459/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 3.7623e-04 - val_loss: 5.7723e-04\n",
      "Epoch 460/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 3.6790e-04 - val_loss: 5.0869e-04\n",
      "Epoch 461/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.5754e-04 - val_loss: 5.0232e-04\n",
      "Epoch 462/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.7033e-04 - val_loss: 6.7008e-04\n",
      "Epoch 463/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 3.8373e-04 - val_loss: 5.8157e-04\n",
      "Epoch 464/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 3.5882e-04 - val_loss: 5.1889e-04\n",
      "Epoch 465/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.5793e-04 - val_loss: 4.8127e-04\n",
      "Epoch 466/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.7491e-04 - val_loss: 6.2145e-04\n",
      "Epoch 467/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.9354e-04 - val_loss: 5.1702e-04\n",
      "Epoch 468/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.7082e-04 - val_loss: 4.8990e-04\n",
      "Epoch 469/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.7405e-04 - val_loss: 4.8018e-04\n",
      "Epoch 470/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.5947e-04 - val_loss: 5.5460e-04\n",
      "Epoch 471/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.6237e-04 - val_loss: 5.7503e-04\n",
      "Epoch 472/2000\n",
      "3490/3490 [==============================] - 1s 287us/step - loss: 3.7264e-04 - val_loss: 4.8723e-04\n",
      "Epoch 473/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.6214e-04 - val_loss: 4.9219e-04\n",
      "Epoch 474/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 3.5876e-04 - val_loss: 5.6598e-04\n",
      "Epoch 475/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.6011e-04 - val_loss: 5.7599e-04\n",
      "Epoch 476/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.6796e-04 - val_loss: 4.8337e-04\n",
      "Epoch 477/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.5721e-04 - val_loss: 4.8384e-04\n",
      "Epoch 478/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.6530e-04 - val_loss: 4.9894e-04\n",
      "Epoch 479/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.7317e-04 - val_loss: 4.9589e-04\n",
      "Epoch 480/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.7144e-04 - val_loss: 7.2666e-04\n",
      "Epoch 481/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 3.9632e-04 - val_loss: 5.3305e-04\n",
      "Epoch 482/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.9165e-04 - val_loss: 5.0869e-04\n",
      "Epoch 483/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.6903e-04 - val_loss: 4.8047e-04\n",
      "Epoch 484/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.5824e-04 - val_loss: 5.1467e-04\n",
      "Epoch 485/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.6246e-04 - val_loss: 5.5184e-04\n",
      "Epoch 486/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.6001e-04 - val_loss: 5.7188e-04\n",
      "Epoch 487/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.6978e-04 - val_loss: 5.5552e-04\n",
      "Epoch 488/2000\n",
      "3490/3490 [==============================] - 1s 292us/step - loss: 3.6153e-04 - val_loss: 5.0025e-04\n",
      "Epoch 489/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.8529e-04 - val_loss: 4.9793e-04\n",
      "Epoch 490/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.6499e-04 - val_loss: 4.8826e-04\n",
      "Epoch 491/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.5146e-04 - val_loss: 4.9716e-04\n",
      "Epoch 492/2000\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 3.4928e-04 - val_loss: 5.1582e-04\n",
      "Epoch 493/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.5237e-04 - val_loss: 4.9050e-04\n",
      "Epoch 494/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.7523e-04 - val_loss: 4.8248e-04\n",
      "Epoch 495/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 3.6132e-04 - val_loss: 5.5934e-04\n",
      "Epoch 496/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.7171e-04 - val_loss: 5.9347e-04\n",
      "Epoch 497/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.5265e-04 - val_loss: 4.9691e-04\n",
      "Epoch 498/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.4612e-04 - val_loss: 5.0209e-04\n",
      "Epoch 499/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.4948e-04 - val_loss: 4.9100e-04\n",
      "Epoch 500/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.7357e-04 - val_loss: 5.2113e-04\n",
      "Epoch 501/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.0822e-04 - val_loss: 4.9867e-04\n",
      "Epoch 502/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 3.6975e-04 - val_loss: 5.6230e-04\n",
      "Epoch 503/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.5451e-04 - val_loss: 5.1517e-04\n",
      "Epoch 504/2000\n",
      "3490/3490 [==============================] - 1s 288us/step - loss: 3.5622e-04 - val_loss: 6.2839e-04\n",
      "Epoch 505/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.7361e-04 - val_loss: 5.6821e-04\n",
      "Epoch 506/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.6515e-04 - val_loss: 6.2019e-04\n",
      "Epoch 507/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.6157e-04 - val_loss: 5.0386e-04\n",
      "Epoch 508/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.6830e-04 - val_loss: 5.2409e-04\n",
      "Epoch 509/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 4.0528e-04 - val_loss: 4.9345e-04\n",
      "Epoch 510/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.5623e-04 - val_loss: 5.9770e-04\n",
      "Epoch 511/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.5944e-04 - val_loss: 5.2351e-04\n",
      "Epoch 512/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.4535e-04 - val_loss: 4.9695e-04\n",
      "Epoch 513/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.5039e-04 - val_loss: 5.2226e-04\n",
      "Epoch 514/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.8144e-04 - val_loss: 4.9748e-04\n",
      "Epoch 515/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.7198e-04 - val_loss: 4.8565e-04\n",
      "Epoch 516/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.6298e-04 - val_loss: 6.2600e-04\n",
      "Epoch 517/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.7224e-04 - val_loss: 6.0874e-04\n",
      "Epoch 518/2000\n",
      "3490/3490 [==============================] - 1s 288us/step - loss: 3.5033e-04 - val_loss: 4.9022e-04\n",
      "Epoch 519/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.6206e-04 - val_loss: 4.9119e-04\n",
      "Epoch 520/2000\n",
      "3490/3490 [==============================] - 1s 287us/step - loss: 3.5747e-04 - val_loss: 5.6663e-04\n",
      "Epoch 521/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.5761e-04 - val_loss: 5.3145e-04\n",
      "Epoch 522/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.5777e-04 - val_loss: 4.9561e-04\n",
      "Epoch 523/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.8067e-04 - val_loss: 5.0013e-04\n",
      "Epoch 524/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.6827e-04 - val_loss: 5.0523e-04\n",
      "Epoch 525/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.6633e-04 - val_loss: 5.0667e-04\n",
      "Epoch 526/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.5097e-04 - val_loss: 5.3447e-04\n",
      "Epoch 527/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.4626e-04 - val_loss: 5.0500e-04\n",
      "Epoch 528/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.5121e-04 - val_loss: 5.2322e-04\n",
      "Epoch 529/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 3.4408e-04 - val_loss: 5.0095e-04\n",
      "Epoch 530/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.4566e-04 - val_loss: 5.0294e-04\n",
      "Epoch 531/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.4938e-04 - val_loss: 5.0387e-04\n",
      "Epoch 532/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.5867e-04 - val_loss: 5.3741e-04\n",
      "Epoch 533/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 3.4752e-04 - val_loss: 4.9973e-04\n",
      "Epoch 534/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.6911e-04 - val_loss: 6.1924e-04\n",
      "Epoch 535/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 4.1644e-04 - val_loss: 5.6608e-04\n",
      "Epoch 536/2000\n",
      "3490/3490 [==============================] - 1s 287us/step - loss: 4.1138e-04 - val_loss: 5.0967e-04\n",
      "Epoch 537/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.1137e-04 - val_loss: 6.9173e-04\n",
      "Epoch 538/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.8621e-04 - val_loss: 6.3211e-04\n",
      "Epoch 539/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.8550e-04 - val_loss: 4.9106e-04\n",
      "Epoch 540/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.5826e-04 - val_loss: 4.8921e-04\n",
      "Epoch 541/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.4901e-04 - val_loss: 4.9046e-04\n",
      "Epoch 542/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.6639e-04 - val_loss: 5.3125e-04\n",
      "Epoch 543/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.4875e-04 - val_loss: 5.1686e-04\n",
      "Epoch 544/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.4238e-04 - val_loss: 4.9373e-04\n",
      "Epoch 545/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.4393e-04 - val_loss: 5.6855e-04\n",
      "Epoch 546/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.9283e-04 - val_loss: 6.6644e-04\n",
      "Epoch 547/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.7569e-04 - val_loss: 6.0744e-04\n",
      "Epoch 548/2000\n",
      "3490/3490 [==============================] - 1s 288us/step - loss: 3.8016e-04 - val_loss: 5.4203e-04\n",
      "Epoch 549/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.6155e-04 - val_loss: 5.0646e-04\n",
      "Epoch 550/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.6383e-04 - val_loss: 5.5534e-04\n",
      "Epoch 551/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 4.0097e-04 - val_loss: 5.1029e-04\n",
      "Epoch 552/2000\n",
      "3490/3490 [==============================] - 1s 287us/step - loss: 3.5804e-04 - val_loss: 6.5392e-04\n",
      "Epoch 553/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 3.8873e-04 - val_loss: 5.4762e-04\n",
      "Epoch 554/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.5589e-04 - val_loss: 5.0903e-04\n",
      "Epoch 555/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.5214e-04 - val_loss: 5.2301e-04\n",
      "Epoch 556/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.7436e-04 - val_loss: 6.2374e-04\n",
      "Epoch 557/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.6837e-04 - val_loss: 4.9969e-04\n",
      "Epoch 558/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.4476e-04 - val_loss: 5.1763e-04\n",
      "Epoch 559/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.4915e-04 - val_loss: 6.1191e-04\n",
      "Epoch 560/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.8298e-04 - val_loss: 5.0344e-04\n",
      "Epoch 561/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.5594e-04 - val_loss: 5.0348e-04\n",
      "Epoch 562/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.8187e-04 - val_loss: 5.4436e-04\n",
      "Epoch 563/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.8371e-04 - val_loss: 7.3082e-04\n",
      "Epoch 564/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.8558e-04 - val_loss: 6.4959e-04\n",
      "Epoch 565/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.7105e-04 - val_loss: 5.2791e-04\n",
      "Epoch 566/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.5951e-04 - val_loss: 5.0291e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 567/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 3.5722e-04 - val_loss: 6.6495e-04\n",
      "Epoch 568/2000\n",
      "3490/3490 [==============================] - 1s 287us/step - loss: 3.9270e-04 - val_loss: 5.5820e-04\n",
      "Epoch 569/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 3.5512e-04 - val_loss: 4.9680e-04\n",
      "Epoch 570/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.4999e-04 - val_loss: 6.2414e-04\n",
      "Epoch 571/2000\n",
      "3490/3490 [==============================] - 1s 287us/step - loss: 3.5880e-04 - val_loss: 5.1359e-04\n",
      "Epoch 572/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.5315e-04 - val_loss: 4.9779e-04\n",
      "Epoch 573/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.4721e-04 - val_loss: 5.1592e-04\n",
      "Epoch 574/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.6326e-04 - val_loss: 5.9793e-04\n",
      "Epoch 575/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.4825e-04 - val_loss: 6.5051e-04\n",
      "Epoch 576/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.7671e-04 - val_loss: 5.7205e-04\n",
      "Epoch 577/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.4098e-04 - val_loss: 5.1896e-04\n",
      "Epoch 578/2000\n",
      "3490/3490 [==============================] - 1s 288us/step - loss: 3.4051e-04 - val_loss: 4.9825e-04\n",
      "Epoch 579/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.3542e-04 - val_loss: 5.0554e-04\n",
      "Epoch 580/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.3882e-04 - val_loss: 5.4156e-04\n",
      "Epoch 581/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.3978e-04 - val_loss: 4.9611e-04\n",
      "Epoch 582/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.6014e-04 - val_loss: 5.3802e-04\n",
      "Epoch 583/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.7688e-04 - val_loss: 5.7790e-04\n",
      "Epoch 584/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.8892e-04 - val_loss: 6.5395e-04\n",
      "Epoch 585/2000\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 3.6881e-04 - val_loss: 4.9748e-04\n",
      "Epoch 586/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.6378e-04 - val_loss: 5.3507e-04\n",
      "Epoch 587/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.6535e-04 - val_loss: 5.0167e-04\n",
      "Epoch 588/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.6581e-04 - val_loss: 5.8300e-04\n",
      "Epoch 589/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.5693e-04 - val_loss: 5.5516e-04\n",
      "Epoch 590/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.3550e-04 - val_loss: 4.8017e-04\n",
      "Epoch 591/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.3421e-04 - val_loss: 4.9590e-04\n",
      "Epoch 592/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.3145e-04 - val_loss: 5.0820e-04\n",
      "Epoch 593/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.3111e-04 - val_loss: 4.9791e-04\n",
      "Epoch 594/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.5157e-04 - val_loss: 6.6125e-04\n",
      "Epoch 595/2000\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 3.4483e-04 - val_loss: 5.1458e-04\n",
      "Epoch 596/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.2934e-04 - val_loss: 4.9326e-04\n",
      "Epoch 597/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.5674e-04 - val_loss: 5.7626e-04\n",
      "Epoch 598/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.6638e-04 - val_loss: 5.0830e-04\n",
      "Epoch 599/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.3607e-04 - val_loss: 5.5895e-04\n",
      "Epoch 600/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.4359e-04 - val_loss: 5.1946e-04\n",
      "Epoch 601/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.5060e-04 - val_loss: 5.0625e-04\n",
      "Epoch 602/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.5174e-04 - val_loss: 5.5814e-04\n",
      "Epoch 603/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.2913e-04 - val_loss: 4.8593e-04\n",
      "Epoch 604/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.3016e-04 - val_loss: 5.0178e-04\n",
      "Epoch 605/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.3870e-04 - val_loss: 5.2227e-04\n",
      "Epoch 606/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.5432e-04 - val_loss: 5.5498e-04\n",
      "Epoch 607/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.3549e-04 - val_loss: 5.0547e-04\n",
      "Epoch 608/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 3.3520e-04 - val_loss: 5.3435e-04\n",
      "Epoch 609/2000\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 3.4025e-04 - val_loss: 4.9164e-04\n",
      "Epoch 610/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 3.3092e-04 - val_loss: 5.3074e-04\n",
      "Epoch 611/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.2577e-04 - val_loss: 5.0801e-04\n",
      "Epoch 612/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.3939e-04 - val_loss: 5.1691e-04\n",
      "Epoch 613/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 3.4927e-04 - val_loss: 5.2207e-04\n",
      "Epoch 614/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.3017e-04 - val_loss: 5.5940e-04\n",
      "Epoch 615/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 3.5532e-04 - val_loss: 5.7473e-04\n",
      "Epoch 616/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.6074e-04 - val_loss: 4.9800e-04\n",
      "Epoch 617/2000\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 3.3720e-04 - val_loss: 5.0714e-04\n",
      "Epoch 618/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.2521e-04 - val_loss: 5.2525e-04\n",
      "Epoch 619/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.2463e-04 - val_loss: 5.4608e-04\n",
      "Epoch 620/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.3659e-04 - val_loss: 5.1097e-04\n",
      "Epoch 621/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.2712e-04 - val_loss: 5.2609e-04\n",
      "Epoch 622/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.3469e-04 - val_loss: 4.9938e-04\n",
      "Epoch 623/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 3.3536e-04 - val_loss: 5.0169e-04\n",
      "Epoch 624/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.5503e-04 - val_loss: 6.2748e-04\n",
      "Epoch 625/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 3.5738e-04 - val_loss: 6.1165e-04\n",
      "Epoch 626/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.4095e-04 - val_loss: 5.0530e-04\n",
      "Epoch 627/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.3373e-04 - val_loss: 5.7807e-04\n",
      "Epoch 628/2000\n",
      "3490/3490 [==============================] - 1s 288us/step - loss: 3.4206e-04 - val_loss: 5.3776e-04\n",
      "Epoch 629/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.3457e-04 - val_loss: 5.6862e-04\n",
      "Epoch 630/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 3.4944e-04 - val_loss: 5.5628e-04\n",
      "Epoch 631/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.4301e-04 - val_loss: 5.2737e-04\n",
      "Epoch 632/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.6652e-04 - val_loss: 5.2788e-04\n",
      "Epoch 633/2000\n",
      "3490/3490 [==============================] - 1s 287us/step - loss: 3.4970e-04 - val_loss: 5.2732e-04\n",
      "Epoch 634/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 3.4036e-04 - val_loss: 5.4423e-04\n",
      "Epoch 635/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.2865e-04 - val_loss: 5.2067e-04\n",
      "Epoch 636/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.3211e-04 - val_loss: 5.9509e-04\n",
      "Epoch 637/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.5030e-04 - val_loss: 5.0161e-04\n",
      "Epoch 638/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.3255e-04 - val_loss: 5.2421e-04\n",
      "Epoch 639/2000\n",
      "3490/3490 [==============================] - 1s 287us/step - loss: 3.2807e-04 - val_loss: 6.0189e-04\n",
      "Epoch 640/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.4336e-04 - val_loss: 5.5901e-04\n",
      "Epoch 641/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.4150e-04 - val_loss: 5.1907e-04\n",
      "Epoch 642/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.5755e-04 - val_loss: 6.0685e-04\n",
      "Epoch 643/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.6497e-04 - val_loss: 5.7515e-04\n",
      "Epoch 644/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 3.3528e-04 - val_loss: 5.3065e-04\n",
      "Epoch 645/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.4849e-04 - val_loss: 5.7246e-04\n",
      "Epoch 646/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.3925e-04 - val_loss: 6.2029e-04\n",
      "Epoch 647/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.6797e-04 - val_loss: 5.6718e-04\n",
      "Epoch 648/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.3144e-04 - val_loss: 5.7153e-04\n",
      "Epoch 649/2000\n",
      "3490/3490 [==============================] - 1s 288us/step - loss: 3.4755e-04 - val_loss: 6.3638e-04\n",
      "Epoch 650/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.3931e-04 - val_loss: 5.4482e-04\n",
      "Epoch 651/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.1796e-04 - val_loss: 5.2794e-04\n",
      "Epoch 652/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.1060e-04 - val_loss: 5.3155e-04\n",
      "Epoch 653/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.1016e-04 - val_loss: 5.4527e-04\n",
      "Epoch 654/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.1625e-04 - val_loss: 6.7756e-04\n",
      "Epoch 655/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.4701e-04 - val_loss: 5.3276e-04\n",
      "Epoch 656/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 3.5620e-04 - val_loss: 5.3316e-04\n",
      "Epoch 657/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.7606e-04 - val_loss: 6.0012e-04\n",
      "Epoch 658/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.5038e-04 - val_loss: 6.0120e-04\n",
      "Epoch 659/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 3.3841e-04 - val_loss: 5.8320e-04\n",
      "Epoch 660/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.2015e-04 - val_loss: 5.6637e-04\n",
      "Epoch 661/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.5868e-04 - val_loss: 6.1890e-04\n",
      "Epoch 662/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.3429e-04 - val_loss: 5.5342e-04\n",
      "Epoch 663/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 3.2318e-04 - val_loss: 5.5727e-04\n",
      "Epoch 664/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 3.2983e-04 - val_loss: 5.1929e-04\n",
      "Epoch 665/2000\n",
      "3490/3490 [==============================] - 1s 287us/step - loss: 3.4191e-04 - val_loss: 6.4132e-04\n",
      "Epoch 666/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.2743e-04 - val_loss: 5.5353e-04\n",
      "Epoch 667/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.2680e-04 - val_loss: 5.4404e-04\n",
      "Epoch 668/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 3.3180e-04 - val_loss: 6.0669e-04\n",
      "Epoch 669/2000\n",
      "3490/3490 [==============================] - 1s 288us/step - loss: 3.2482e-04 - val_loss: 5.9836e-04\n",
      "Epoch 670/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.1617e-04 - val_loss: 5.6807e-04\n",
      "Epoch 671/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.3537e-04 - val_loss: 6.3053e-04\n",
      "Epoch 672/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.3336e-04 - val_loss: 5.4523e-04\n",
      "Epoch 673/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.2868e-04 - val_loss: 5.1130e-04\n",
      "Epoch 674/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 3.2734e-04 - val_loss: 6.3294e-04\n",
      "Epoch 675/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.4270e-04 - val_loss: 5.9315e-04\n",
      "Epoch 676/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.3369e-04 - val_loss: 5.7599e-04\n",
      "Epoch 677/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.3657e-04 - val_loss: 5.2692e-04\n",
      "Epoch 678/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.2197e-04 - val_loss: 5.7058e-04\n",
      "Epoch 679/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.2508e-04 - val_loss: 5.1905e-04\n",
      "Epoch 680/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.2912e-04 - val_loss: 5.5889e-04\n",
      "Epoch 681/2000\n",
      "3490/3490 [==============================] - 1s 288us/step - loss: 3.1693e-04 - val_loss: 5.4976e-04\n",
      "Epoch 682/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.0867e-04 - val_loss: 5.4639e-04\n",
      "Epoch 683/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.1976e-04 - val_loss: 5.5464e-04\n",
      "Epoch 684/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.3032e-04 - val_loss: 6.1836e-04\n",
      "Epoch 685/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 3.2551e-04 - val_loss: 6.2000e-04\n",
      "Epoch 686/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.3845e-04 - val_loss: 6.6876e-04\n",
      "Epoch 687/2000\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 3.3853e-04 - val_loss: 5.5920e-04\n",
      "Epoch 688/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.2387e-04 - val_loss: 5.6063e-04\n",
      "Epoch 689/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 3.2309e-04 - val_loss: 5.5325e-04\n",
      "Epoch 690/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.3568e-04 - val_loss: 6.2441e-04\n",
      "Epoch 691/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.2561e-04 - val_loss: 6.1843e-04\n",
      "Epoch 692/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.4417e-04 - val_loss: 6.5800e-04\n",
      "Epoch 693/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.2111e-04 - val_loss: 5.4812e-04\n",
      "Epoch 694/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 3.1052e-04 - val_loss: 5.4587e-04\n",
      "Epoch 695/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 3.1168e-04 - val_loss: 5.6666e-04\n",
      "Epoch 696/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.1904e-04 - val_loss: 5.5494e-04\n",
      "Epoch 697/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.0917e-04 - val_loss: 5.6910e-04\n",
      "Epoch 698/2000\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 3.4404e-04 - val_loss: 8.3087e-04\n",
      "Epoch 699/2000\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 3.7574e-04 - val_loss: 7.2889e-04\n",
      "Epoch 700/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.5834e-04 - val_loss: 5.1376e-04\n",
      "Epoch 701/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.5786e-04 - val_loss: 5.0258e-04\n",
      "Epoch 702/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.6096e-04 - val_loss: 5.6601e-04\n",
      "Epoch 703/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 3.2328e-04 - val_loss: 5.5649e-04\n",
      "Epoch 704/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.5324e-04 - val_loss: 7.3766e-04\n",
      "Epoch 705/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.4091e-04 - val_loss: 5.8862e-04\n",
      "Epoch 706/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.1936e-04 - val_loss: 5.3698e-04\n",
      "Epoch 707/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 3.0321e-04 - val_loss: 5.7399e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 708/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 2.9561e-04 - val_loss: 5.7298e-04\n",
      "Epoch 709/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.2346e-04 - val_loss: 6.1242e-04\n",
      "Epoch 710/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.6527e-04 - val_loss: 6.8248e-04\n",
      "Epoch 711/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 3.6649e-04 - val_loss: 5.6552e-04\n",
      "Epoch 712/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.7375e-04 - val_loss: 6.0279e-04\n",
      "Epoch 713/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.6810e-04 - val_loss: 7.5936e-04\n",
      "Epoch 714/2000\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 3.5500e-04 - val_loss: 5.5544e-04\n",
      "Epoch 715/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 3.5398e-04 - val_loss: 5.7750e-04\n",
      "Epoch 716/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.5316e-04 - val_loss: 5.9915e-04\n",
      "Epoch 717/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.5110e-04 - val_loss: 5.6650e-04\n",
      "Epoch 718/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.1734e-04 - val_loss: 5.7916e-04\n",
      "Epoch 719/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.0737e-04 - val_loss: 5.6824e-04\n",
      "Epoch 720/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.0995e-04 - val_loss: 5.3198e-04\n",
      "Epoch 721/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.0644e-04 - val_loss: 5.5661e-04\n",
      "Epoch 722/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.0868e-04 - val_loss: 6.0113e-04\n",
      "Epoch 723/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.1314e-04 - val_loss: 6.3102e-04\n",
      "Epoch 724/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 2.9902e-04 - val_loss: 5.6387e-04\n",
      "Epoch 725/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.9884e-04 - val_loss: 5.6040e-04\n",
      "Epoch 726/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.0817e-04 - val_loss: 5.7615e-04\n",
      "Epoch 727/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 2.8755e-04 - val_loss: 5.9276e-04\n",
      "Epoch 728/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 2.9044e-04 - val_loss: 6.4710e-04\n",
      "Epoch 729/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 3.0423e-04 - val_loss: 7.0455e-04\n",
      "Epoch 730/2000\n",
      "3490/3490 [==============================] - 1s 289us/step - loss: 3.1248e-04 - val_loss: 6.8638e-04\n",
      "Epoch 731/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 3.0923e-04 - val_loss: 5.9404e-04\n",
      "Epoch 732/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.9274e-04 - val_loss: 5.5428e-04\n",
      "Epoch 733/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 2.9327e-04 - val_loss: 5.8228e-04\n",
      "Epoch 734/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 2.8765e-04 - val_loss: 5.9821e-04\n",
      "Epoch 735/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 2.8524e-04 - val_loss: 6.2095e-04\n",
      "Epoch 736/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.8942e-04 - val_loss: 6.3237e-04\n",
      "Epoch 737/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 2.8518e-04 - val_loss: 5.9355e-04\n",
      "Epoch 738/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 2.9301e-04 - val_loss: 5.6380e-04\n",
      "Epoch 739/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.8799e-04 - val_loss: 6.4413e-04\n",
      "Epoch 740/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.3482e-04 - val_loss: 6.6941e-04\n",
      "Epoch 741/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.3073e-04 - val_loss: 5.5961e-04\n",
      "Epoch 742/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.5590e-04 - val_loss: 5.0206e-04\n",
      "Epoch 743/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.2534e-04 - val_loss: 5.6292e-04\n",
      "Epoch 744/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.7189e-04 - val_loss: 6.3896e-04\n",
      "Epoch 745/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.1871e-04 - val_loss: 6.7687e-04\n",
      "Epoch 746/2000\n",
      "3490/3490 [==============================] - 1s 289us/step - loss: 3.1225e-04 - val_loss: 6.2426e-04\n",
      "Epoch 747/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.0352e-04 - val_loss: 6.4334e-04\n",
      "Epoch 748/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.9408e-04 - val_loss: 5.2684e-04\n",
      "Epoch 749/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.0021e-04 - val_loss: 5.4208e-04\n",
      "Epoch 750/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 2.9004e-04 - val_loss: 6.2379e-04\n",
      "Epoch 751/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.0452e-04 - val_loss: 7.7292e-04\n",
      "Epoch 752/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.0840e-04 - val_loss: 6.1392e-04\n",
      "Epoch 753/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 2.9893e-04 - val_loss: 6.1369e-04\n",
      "Epoch 754/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 2.9048e-04 - val_loss: 5.9570e-04\n",
      "Epoch 755/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 2.8791e-04 - val_loss: 6.8864e-04\n",
      "Epoch 756/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.8623e-04 - val_loss: 6.1380e-04\n",
      "Epoch 757/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.9248e-04 - val_loss: 7.4609e-04\n",
      "Epoch 758/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.0368e-04 - val_loss: 6.2423e-04\n",
      "Epoch 759/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.2363e-04 - val_loss: 5.6634e-04\n",
      "Epoch 760/2000\n",
      "3490/3490 [==============================] - 1s 290us/step - loss: 2.9836e-04 - val_loss: 5.9287e-04\n",
      "Epoch 761/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.1667e-04 - val_loss: 6.2966e-04\n",
      "Epoch 762/2000\n",
      "3490/3490 [==============================] - 1s 289us/step - loss: 2.8908e-04 - val_loss: 6.3406e-04\n",
      "Epoch 763/2000\n",
      "3490/3490 [==============================] - 1s 290us/step - loss: 2.8818e-04 - val_loss: 7.0008e-04\n",
      "Epoch 764/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 2.8682e-04 - val_loss: 6.6549e-04\n",
      "Epoch 765/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 2.7785e-04 - val_loss: 5.8645e-04\n",
      "Epoch 766/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 2.6766e-04 - val_loss: 6.1719e-04\n",
      "Epoch 767/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 2.6621e-04 - val_loss: 6.5322e-04\n",
      "Epoch 768/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 2.9532e-04 - val_loss: 6.0547e-04\n",
      "Epoch 769/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.7462e-04 - val_loss: 6.2862e-04\n",
      "Epoch 770/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.2387e-04 - val_loss: 7.5979e-04\n",
      "Epoch 771/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.2877e-04 - val_loss: 5.4170e-04\n",
      "Epoch 772/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.1766e-04 - val_loss: 4.9355e-04\n",
      "Epoch 773/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.0579e-04 - val_loss: 5.3581e-04\n",
      "Epoch 774/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.1614e-04 - val_loss: 5.9027e-04\n",
      "Epoch 775/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 3.0788e-04 - val_loss: 7.1875e-04\n",
      "Epoch 776/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.8565e-04 - val_loss: 6.2666e-04\n",
      "Epoch 777/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.6885e-04 - val_loss: 6.8045e-04\n",
      "Epoch 778/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3490/3490 [==============================] - 1s 287us/step - loss: 2.7230e-04 - val_loss: 7.3678e-04\n",
      "Epoch 779/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 2.9280e-04 - val_loss: 7.6310e-04\n",
      "Epoch 780/2000\n",
      "3490/3490 [==============================] - ETA: 0s - loss: 2.7964e-0 - 1s 282us/step - loss: 2.8401e-04 - val_loss: 6.2832e-04\n",
      "Epoch 781/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 2.6876e-04 - val_loss: 6.7085e-04\n",
      "Epoch 782/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 2.8105e-04 - val_loss: 6.2472e-04\n",
      "Epoch 783/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.0009e-04 - val_loss: 7.3589e-04\n",
      "Epoch 784/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 2.8939e-04 - val_loss: 6.4069e-04\n",
      "Epoch 785/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 2.8281e-04 - val_loss: 6.1745e-04\n",
      "Epoch 786/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 2.7611e-04 - val_loss: 6.7887e-04\n",
      "Epoch 787/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.8704e-04 - val_loss: 6.5923e-04\n",
      "Epoch 788/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.7797e-04 - val_loss: 7.8318e-04\n",
      "Epoch 789/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 2.7787e-04 - val_loss: 6.0722e-04\n",
      "Epoch 790/2000\n",
      "3490/3490 [==============================] - 1s 289us/step - loss: 2.8776e-04 - val_loss: 7.8104e-04\n",
      "Epoch 791/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 2.9171e-04 - val_loss: 6.9487e-04\n",
      "Epoch 792/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.7009e-04 - val_loss: 6.5632e-04\n",
      "Epoch 793/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 2.6818e-04 - val_loss: 6.7708e-04\n",
      "Epoch 794/2000\n",
      "3490/3490 [==============================] - 1s 291us/step - loss: 2.8973e-04 - val_loss: 7.2963e-04\n",
      "Epoch 795/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 2.9715e-04 - val_loss: 8.3028e-04\n",
      "Epoch 796/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 3.0565e-04 - val_loss: 7.2440e-04\n",
      "Epoch 797/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.6799e-04 - val_loss: 7.3534e-04\n",
      "Epoch 798/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 2.6164e-04 - val_loss: 6.9515e-04\n",
      "Epoch 799/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 2.6217e-04 - val_loss: 7.0276e-04\n",
      "Epoch 800/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.6218e-04 - val_loss: 6.8482e-04\n",
      "Epoch 801/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 2.5687e-04 - val_loss: 6.8988e-04\n",
      "Epoch 802/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.4962e-04 - val_loss: 7.7655e-04\n",
      "Epoch 803/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.7491e-04 - val_loss: 7.5107e-04\n",
      "Epoch 804/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.8903e-04 - val_loss: 8.7496e-04\n",
      "Epoch 805/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.8662e-04 - val_loss: 8.1925e-04\n",
      "Epoch 806/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.7155e-04 - val_loss: 7.1739e-04\n",
      "Epoch 807/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 2.6949e-04 - val_loss: 7.1912e-04\n",
      "Epoch 808/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.5879e-04 - val_loss: 7.2991e-04\n",
      "Epoch 809/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.5884e-04 - val_loss: 6.7467e-04\n",
      "Epoch 810/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 2.6666e-04 - val_loss: 7.4814e-04\n",
      "Epoch 811/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 2.5998e-04 - val_loss: 7.8464e-04\n",
      "Epoch 812/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 2.8119e-04 - val_loss: 8.4400e-04\n",
      "Epoch 813/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 2.6828e-04 - val_loss: 8.3812e-04\n",
      "Epoch 814/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 2.9600e-04 - val_loss: 9.5271e-04\n",
      "Epoch 815/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.3122e-04 - val_loss: 9.9682e-04\n",
      "Epoch 816/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.7229e-04 - val_loss: 0.0010\n",
      "Epoch 817/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.4486e-04 - val_loss: 6.6196e-04\n",
      "Epoch 818/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.2697e-04 - val_loss: 7.6471e-04\n",
      "Epoch 819/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.8527e-04 - val_loss: 7.2142e-04\n",
      "Epoch 820/2000\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 2.6334e-04 - val_loss: 7.4707e-04\n",
      "Epoch 821/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.5467e-04 - val_loss: 8.1916e-04\n",
      "Epoch 822/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.6142e-04 - val_loss: 7.1848e-04\n",
      "Epoch 823/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.4801e-04 - val_loss: 7.0459e-04\n",
      "Epoch 824/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.6547e-04 - val_loss: 7.8748e-04\n",
      "Epoch 825/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 2.4866e-04 - val_loss: 7.4578e-04\n",
      "Epoch 826/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 2.4990e-04 - val_loss: 8.4722e-04\n",
      "Epoch 827/2000\n",
      "3490/3490 [==============================] - 1s 287us/step - loss: 2.7538e-04 - val_loss: 8.1700e-04\n",
      "Epoch 828/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.7386e-04 - val_loss: 8.4122e-04\n",
      "Epoch 829/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 2.5990e-04 - val_loss: 7.3486e-04\n",
      "Epoch 830/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 2.5433e-04 - val_loss: 7.8177e-04\n",
      "Epoch 831/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.5778e-04 - val_loss: 8.1748e-04\n",
      "Epoch 832/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.4565e-04 - val_loss: 8.0525e-04\n",
      "Epoch 833/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 2.4816e-04 - val_loss: 7.8218e-04\n",
      "Epoch 834/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.4143e-04 - val_loss: 8.0009e-04\n",
      "Epoch 835/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 2.4177e-04 - val_loss: 7.6528e-04\n",
      "Epoch 836/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.3809e-04 - val_loss: 7.9075e-04\n",
      "Epoch 837/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 2.4695e-04 - val_loss: 8.5803e-04\n",
      "Epoch 838/2000\n",
      "3490/3490 [==============================] - 1s 288us/step - loss: 2.5766e-04 - val_loss: 9.6168e-04\n",
      "Epoch 839/2000\n",
      "3490/3490 [==============================] - 1s 287us/step - loss: 2.5357e-04 - val_loss: 7.4541e-04\n",
      "Epoch 840/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 2.5838e-04 - val_loss: 7.3129e-04\n",
      "Epoch 841/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.8080e-04 - val_loss: 9.3410e-04\n",
      "Epoch 842/2000\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 3.1676e-04 - val_loss: 8.3900e-04\n",
      "Epoch 843/2000\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 2.8569e-04 - val_loss: 7.6049e-04\n",
      "Epoch 844/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 2.9694e-04 - val_loss: 7.8629e-04\n",
      "Epoch 845/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 2.6928e-04 - val_loss: 7.5431e-04\n",
      "Epoch 846/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.4949e-04 - val_loss: 7.2730e-04\n",
      "Epoch 847/2000\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 2.4374e-04 - val_loss: 7.5651e-04\n",
      "Epoch 848/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.6878e-04 - val_loss: 8.0138e-04\n",
      "Epoch 849/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 2.5270e-04 - val_loss: 7.7765e-04\n",
      "Epoch 850/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 2.5621e-04 - val_loss: 7.3622e-04\n",
      "Epoch 851/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 2.5057e-04 - val_loss: 8.2894e-04\n",
      "Epoch 852/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 2.3781e-04 - val_loss: 8.1327e-04\n",
      "Epoch 853/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.3543e-04 - val_loss: 7.6136e-04\n",
      "Epoch 854/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 2.3450e-04 - val_loss: 7.7625e-04\n",
      "Epoch 855/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.4218e-04 - val_loss: 8.3837e-04\n",
      "Epoch 856/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 2.2984e-04 - val_loss: 7.8297e-04\n",
      "Epoch 857/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 2.3073e-04 - val_loss: 9.1408e-04\n",
      "Epoch 858/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 2.3584e-04 - val_loss: 0.0010\n",
      "Epoch 859/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 2.7566e-04 - val_loss: 0.0010\n",
      "Epoch 860/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.6695e-04 - val_loss: 7.6589e-04\n",
      "Epoch 861/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 2.3926e-04 - val_loss: 9.3700e-04\n",
      "Epoch 862/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 2.3329e-04 - val_loss: 7.5853e-04\n",
      "Epoch 863/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.3812e-04 - val_loss: 8.7379e-04\n",
      "Epoch 864/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.6873e-04 - val_loss: 7.2889e-04\n",
      "Epoch 865/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 2.6169e-04 - val_loss: 8.4890e-04\n",
      "Epoch 866/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.4893e-04 - val_loss: 7.4779e-04\n",
      "Epoch 867/2000\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 2.5147e-04 - val_loss: 8.3422e-04\n",
      "Epoch 868/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.6645e-04 - val_loss: 7.2826e-04\n",
      "Epoch 869/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 2.2755e-04 - val_loss: 8.4378e-04\n",
      "Epoch 870/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 2.4835e-04 - val_loss: 8.3209e-04\n",
      "Epoch 871/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 2.5325e-04 - val_loss: 9.0661e-04\n",
      "Epoch 872/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 2.3469e-04 - val_loss: 9.0846e-04\n",
      "Epoch 873/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.3122e-04 - val_loss: 8.6135e-04\n",
      "Epoch 874/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.2864e-04 - val_loss: 9.2593e-04\n",
      "Epoch 875/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 2.1483e-04 - val_loss: 9.6327e-04\n",
      "Epoch 876/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 2.3215e-04 - val_loss: 8.4718e-04\n",
      "Epoch 877/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 2.2835e-04 - val_loss: 0.0010\n",
      "Epoch 878/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.3057e-04 - val_loss: 8.1345e-04\n",
      "Epoch 879/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.5594e-04 - val_loss: 8.6112e-04\n",
      "Epoch 880/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 2.4380e-04 - val_loss: 9.0952e-04\n",
      "Epoch 881/2000\n",
      "3490/3490 [==============================] - 1s 287us/step - loss: 2.3444e-04 - val_loss: 9.6005e-04\n",
      "Epoch 882/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 2.2894e-04 - val_loss: 8.9511e-04\n",
      "Epoch 883/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.1316e-04 - val_loss: 8.7637e-04\n",
      "Epoch 884/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 2.1341e-04 - val_loss: 8.7771e-04\n",
      "Epoch 885/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 2.5154e-04 - val_loss: 0.0012\n",
      "Epoch 886/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.9574e-04 - val_loss: 8.9134e-04\n",
      "Epoch 887/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 2.6885e-04 - val_loss: 7.5384e-04\n",
      "Epoch 888/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.4487e-04 - val_loss: 8.6393e-04\n",
      "Epoch 889/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 2.4209e-04 - val_loss: 8.3091e-04\n",
      "Epoch 890/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.4840e-04 - val_loss: 8.6984e-04\n",
      "Epoch 891/2000\n",
      "3490/3490 [==============================] - 1s 289us/step - loss: 2.4312e-04 - val_loss: 8.4994e-04\n",
      "Epoch 892/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 2.3838e-04 - val_loss: 9.0607e-04\n",
      "Epoch 893/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 2.2158e-04 - val_loss: 8.3071e-04\n",
      "Epoch 894/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 2.3889e-04 - val_loss: 9.5346e-04\n",
      "Epoch 895/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 2.3567e-04 - val_loss: 8.3937e-04\n",
      "Epoch 896/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 2.1106e-04 - val_loss: 9.0662e-04\n",
      "Epoch 897/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.2423e-04 - val_loss: 9.5210e-04\n",
      "Epoch 898/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.4440e-04 - val_loss: 8.8889e-04\n",
      "Epoch 899/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 2.2354e-04 - val_loss: 9.5909e-04\n",
      "Epoch 900/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.1751e-04 - val_loss: 8.6925e-04\n",
      "Epoch 901/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 2.1414e-04 - val_loss: 9.4357e-04\n",
      "Epoch 902/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 2.2311e-04 - val_loss: 9.7547e-04\n",
      "Epoch 903/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 2.2820e-04 - val_loss: 8.2984e-04\n",
      "Epoch 904/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 2.1639e-04 - val_loss: 9.1901e-04\n",
      "Epoch 905/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.2497e-04 - val_loss: 9.9079e-04\n",
      "Epoch 906/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 2.2496e-04 - val_loss: 9.5120e-04\n",
      "Epoch 907/2000\n",
      "3490/3490 [==============================] - 1s 288us/step - loss: 2.2382e-04 - val_loss: 9.8476e-04\n",
      "Epoch 908/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 2.2223e-04 - val_loss: 8.9687e-04\n",
      "Epoch 909/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 2.1360e-04 - val_loss: 9.9372e-04\n",
      "Epoch 910/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.1232e-04 - val_loss: 9.1655e-04\n",
      "Epoch 911/2000\n",
      "3490/3490 [==============================] - 1s 289us/step - loss: 2.1463e-04 - val_loss: 9.4465e-04\n",
      "Epoch 912/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.9655e-04 - val_loss: 9.2777e-04\n",
      "Epoch 913/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.0901e-04 - val_loss: 0.0011\n",
      "Epoch 914/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.1427e-04 - val_loss: 0.0011\n",
      "Epoch 915/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 2.4153e-04 - val_loss: 0.0011\n",
      "Epoch 916/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.2619e-04 - val_loss: 9.0800e-04\n",
      "Epoch 917/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 2.0889e-04 - val_loss: 9.7979e-04\n",
      "Epoch 918/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.2015e-04 - val_loss: 0.0011\n",
      "Epoch 919/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3490/3490 [==============================] - 1s 284us/step - loss: 2.0888e-04 - val_loss: 0.0010\n",
      "Epoch 920/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.9173e-04 - val_loss: 0.0011\n",
      "Epoch 921/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 2.1267e-04 - val_loss: 8.9490e-04\n",
      "Epoch 922/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 2.0400e-04 - val_loss: 0.0011\n",
      "Epoch 923/2000\n",
      "3490/3490 [==============================] - 1s 287us/step - loss: 2.0874e-04 - val_loss: 0.0013\n",
      "Epoch 924/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 2.3040e-04 - val_loss: 9.5946e-04\n",
      "Epoch 925/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.1193e-04 - val_loss: 0.0010\n",
      "Epoch 926/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 2.0355e-04 - val_loss: 0.0011\n",
      "Epoch 927/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.9951e-04 - val_loss: 9.7924e-04\n",
      "Epoch 928/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.2104e-04 - val_loss: 0.0012\n",
      "Epoch 929/2000\n",
      "3490/3490 [==============================] - 1s 280us/step - loss: 2.3208e-04 - val_loss: 9.0863e-04\n",
      "Epoch 930/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 2.1968e-04 - val_loss: 0.0010\n",
      "Epoch 931/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 2.0734e-04 - val_loss: 8.2670e-04\n",
      "Epoch 932/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 2.5102e-04 - val_loss: 0.0010\n",
      "Epoch 933/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 2.7580e-04 - val_loss: 9.8464e-04\n",
      "Epoch 934/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.4611e-04 - val_loss: 8.8135e-04\n",
      "Epoch 935/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.3099e-04 - val_loss: 9.2507e-04\n",
      "Epoch 936/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.2741e-04 - val_loss: 8.7053e-04\n",
      "Epoch 937/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.1619e-04 - val_loss: 7.8332e-04\n",
      "Epoch 938/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.2090e-04 - val_loss: 8.1210e-04\n",
      "Epoch 939/2000\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 2.2499e-04 - val_loss: 9.6737e-04\n",
      "Epoch 940/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 2.0018e-04 - val_loss: 9.4560e-04\n",
      "Epoch 941/2000\n",
      "3490/3490 [==============================] - 1s 287us/step - loss: 2.0965e-04 - val_loss: 0.0011\n",
      "Epoch 942/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.9882e-04 - val_loss: 8.7872e-04\n",
      "Epoch 943/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 2.0178e-04 - val_loss: 9.1575e-04\n",
      "Epoch 944/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 2.0008e-04 - val_loss: 9.1408e-04\n",
      "Epoch 945/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.9612e-04 - val_loss: 0.0011\n",
      "Epoch 946/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 1.9213e-04 - val_loss: 0.0011\n",
      "Epoch 947/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.0609e-04 - val_loss: 0.0011\n",
      "Epoch 948/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 2.0636e-04 - val_loss: 9.3784e-04\n",
      "Epoch 949/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 2.0320e-04 - val_loss: 0.0012\n",
      "Epoch 950/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.9802e-04 - val_loss: 0.0011\n",
      "Epoch 951/2000\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 1.8820e-04 - val_loss: 0.0010\n",
      "Epoch 952/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.8973e-04 - val_loss: 0.0011\n",
      "Epoch 953/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.9280e-04 - val_loss: 0.0011\n",
      "Epoch 954/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 2.0164e-04 - val_loss: 0.0014\n",
      "Epoch 955/2000\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 1.9463e-04 - val_loss: 0.0013\n",
      "Epoch 956/2000\n",
      "3490/3490 [==============================] - 1s 291us/step - loss: 2.0362e-04 - val_loss: 0.0012\n",
      "Epoch 957/2000\n",
      "3490/3490 [==============================] - 1s 289us/step - loss: 1.8572e-04 - val_loss: 0.0010\n",
      "Epoch 958/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 1.8453e-04 - val_loss: 0.0012\n",
      "Epoch 959/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.8120e-04 - val_loss: 0.0012\n",
      "Epoch 960/2000\n",
      "3490/3490 [==============================] - 1s 290us/step - loss: 1.9178e-04 - val_loss: 0.0011\n",
      "Epoch 961/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.9341e-04 - val_loss: 9.5427e-04\n",
      "Epoch 962/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.9322e-04 - val_loss: 0.0014\n",
      "Epoch 963/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.9781e-04 - val_loss: 9.3001e-04\n",
      "Epoch 964/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.2627e-04 - val_loss: 8.4146e-04\n",
      "Epoch 965/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 2.2764e-04 - val_loss: 9.6006e-04\n",
      "Epoch 966/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 2.0501e-04 - val_loss: 9.9294e-04\n",
      "Epoch 967/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 1.9789e-04 - val_loss: 0.0011\n",
      "Epoch 968/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.9068e-04 - val_loss: 0.0012\n",
      "Epoch 969/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.8404e-04 - val_loss: 9.8044e-04\n",
      "Epoch 970/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.8122e-04 - val_loss: 0.0010\n",
      "Epoch 971/2000\n",
      "3490/3490 [==============================] - 1s 292us/step - loss: 1.9056e-04 - val_loss: 0.0012\n",
      "Epoch 972/2000\n",
      "3490/3490 [==============================] - 1s 287us/step - loss: 1.9412e-04 - val_loss: 0.0010\n",
      "Epoch 973/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 1.9153e-04 - val_loss: 0.0011\n",
      "Epoch 974/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.8359e-04 - val_loss: 0.0011\n",
      "Epoch 975/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.8132e-04 - val_loss: 0.0012\n",
      "Epoch 976/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.7533e-04 - val_loss: 0.0010\n",
      "Epoch 977/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.7713e-04 - val_loss: 0.0011\n",
      "Epoch 978/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.7599e-04 - val_loss: 0.0012\n",
      "Epoch 979/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.8769e-04 - val_loss: 0.0013\n",
      "Epoch 980/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.9010e-04 - val_loss: 0.0014\n",
      "Epoch 981/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.9074e-04 - val_loss: 0.0014\n",
      "Epoch 982/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.8685e-04 - val_loss: 0.0013\n",
      "Epoch 983/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.9047e-04 - val_loss: 0.0015\n",
      "Epoch 984/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 1.9812e-04 - val_loss: 0.0011\n",
      "Epoch 985/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.8460e-04 - val_loss: 0.0013\n",
      "Epoch 986/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.8981e-04 - val_loss: 0.0014\n",
      "Epoch 987/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 1.8842e-04 - val_loss: 0.0015\n",
      "Epoch 988/2000\n",
      "3490/3490 [==============================] - 1s 287us/step - loss: 1.9035e-04 - val_loss: 0.0012\n",
      "Epoch 989/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.8895e-04 - val_loss: 0.0013\n",
      "Epoch 990/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 1.8474e-04 - val_loss: 0.0014\n",
      "Epoch 991/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.7822e-04 - val_loss: 0.0013\n",
      "Epoch 992/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 1.8837e-04 - val_loss: 0.0015\n",
      "Epoch 993/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.7719e-04 - val_loss: 0.0013\n",
      "Epoch 994/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 1.7525e-04 - val_loss: 0.0014\n",
      "Epoch 995/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.7451e-04 - val_loss: 0.0015\n",
      "Epoch 996/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 1.7619e-04 - val_loss: 0.0012\n",
      "Epoch 997/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.9225e-04 - val_loss: 0.0020\n",
      "Epoch 998/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 2.1379e-04 - val_loss: 0.0019\n",
      "Epoch 999/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.0924e-04 - val_loss: 0.0012\n",
      "Epoch 1000/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.7956e-04 - val_loss: 0.0012\n",
      "Epoch 1001/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.8905e-04 - val_loss: 0.0012\n",
      "Epoch 1002/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 2.0531e-04 - val_loss: 0.0011\n",
      "Epoch 1003/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 2.1979e-04 - val_loss: 0.0012\n",
      "Epoch 1004/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 1.9364e-04 - val_loss: 0.0013\n",
      "Epoch 1005/2000\n",
      "3490/3490 [==============================] - ETA: 0s - loss: 1.8702e-0 - 1s 284us/step - loss: 1.8925e-04 - val_loss: 0.0012\n",
      "Epoch 1006/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 2.1912e-04 - val_loss: 0.0012\n",
      "Epoch 1007/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 2.0830e-04 - val_loss: 0.0011\n",
      "Epoch 1008/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.9611e-04 - val_loss: 0.0012\n",
      "Epoch 1009/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.8565e-04 - val_loss: 0.0017\n",
      "Epoch 1010/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.9569e-04 - val_loss: 0.0011\n",
      "Epoch 1011/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.9721e-04 - val_loss: 0.0013\n",
      "Epoch 1012/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.8906e-04 - val_loss: 0.0012\n",
      "Epoch 1013/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.9089e-04 - val_loss: 0.0015\n",
      "Epoch 1014/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.8916e-04 - val_loss: 0.0012\n",
      "Epoch 1015/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.9466e-04 - val_loss: 0.0011\n",
      "Epoch 1016/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.9791e-04 - val_loss: 0.0013\n",
      "Epoch 1017/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 2.0138e-04 - val_loss: 0.0014\n",
      "Epoch 1018/2000\n",
      "3490/3490 [==============================] - 1s 287us/step - loss: 1.8147e-04 - val_loss: 0.0013\n",
      "Epoch 1019/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 1.8226e-04 - val_loss: 0.0014\n",
      "Epoch 1020/2000\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 1.5863e-04 - val_loss: 0.0013\n",
      "Epoch 1021/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 1.6505e-04 - val_loss: 0.0013\n",
      "Epoch 1022/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.8166e-04 - val_loss: 0.0014\n",
      "Epoch 1023/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.8006e-04 - val_loss: 0.0019\n",
      "Epoch 1024/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.9795e-04 - val_loss: 0.0012\n",
      "Epoch 1025/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.7144e-04 - val_loss: 0.0012\n",
      "Epoch 1026/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.8062e-04 - val_loss: 0.0014\n",
      "Epoch 1027/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.7841e-04 - val_loss: 0.0012\n",
      "Epoch 1028/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.8023e-04 - val_loss: 0.0013\n",
      "Epoch 1029/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.6662e-04 - val_loss: 0.0014\n",
      "Epoch 1030/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 1.6693e-04 - val_loss: 0.0016\n",
      "Epoch 1031/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 1.6650e-04 - val_loss: 0.0014\n",
      "Epoch 1032/2000\n",
      "3490/3490 [==============================] - 1s 288us/step - loss: 1.6452e-04 - val_loss: 0.0013\n",
      "Epoch 1033/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.5612e-04 - val_loss: 0.0014\n",
      "Epoch 1034/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 1.7466e-04 - val_loss: 0.0015\n",
      "Epoch 1035/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.7461e-04 - val_loss: 0.0016\n",
      "Epoch 1036/2000\n",
      "3490/3490 [==============================] - 1s 289us/step - loss: 2.1712e-04 - val_loss: 0.0013\n",
      "Epoch 1037/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.9716e-04 - val_loss: 0.0014\n",
      "Epoch 1038/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.7251e-04 - val_loss: 0.0013\n",
      "Epoch 1039/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.7859e-04 - val_loss: 0.0016\n",
      "Epoch 1040/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.6404e-04 - val_loss: 0.0014\n",
      "Epoch 1041/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 1.6315e-04 - val_loss: 0.0013\n",
      "Epoch 1042/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.6159e-04 - val_loss: 0.0015\n",
      "Epoch 1043/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.6134e-04 - val_loss: 0.0015\n",
      "Epoch 1044/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.6121e-04 - val_loss: 0.0016\n",
      "Epoch 1045/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.5689e-04 - val_loss: 0.0014\n",
      "Epoch 1046/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.7467e-04 - val_loss: 0.0015\n",
      "Epoch 1047/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.9103e-04 - val_loss: 0.0017\n",
      "Epoch 1048/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.7237e-04 - val_loss: 0.0012\n",
      "Epoch 1049/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.8162e-04 - val_loss: 0.0013\n",
      "Epoch 1050/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 2.0674e-04 - val_loss: 0.0015\n",
      "Epoch 1051/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.7347e-04 - val_loss: 0.0016\n",
      "Epoch 1052/2000\n",
      "3490/3490 [==============================] - 1s 288us/step - loss: 1.5409e-04 - val_loss: 0.0014\n",
      "Epoch 1053/2000\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 1.5159e-04 - val_loss: 0.0013\n",
      "Epoch 1054/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.5500e-04 - val_loss: 0.0015\n",
      "Epoch 1055/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 1.6926e-04 - val_loss: 0.0014\n",
      "Epoch 1056/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.6772e-04 - val_loss: 0.0017\n",
      "Epoch 1057/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.7380e-04 - val_loss: 0.0016\n",
      "Epoch 1058/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.8557e-04 - val_loss: 0.0014\n",
      "Epoch 1059/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.6066e-04 - val_loss: 0.0017\n",
      "Epoch 1060/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.5634e-04 - val_loss: 0.0017\n",
      "Epoch 1061/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.7232e-04 - val_loss: 0.0015\n",
      "Epoch 1062/2000\n",
      "3490/3490 [==============================] - 1s 287us/step - loss: 1.5989e-04 - val_loss: 0.0015\n",
      "Epoch 1063/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.7289e-04 - val_loss: 0.0013\n",
      "Epoch 1064/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 1.5883e-04 - val_loss: 0.0015\n",
      "Epoch 1065/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.6154e-04 - val_loss: 0.0015\n",
      "Epoch 1066/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.6005e-04 - val_loss: 0.0015\n",
      "Epoch 1067/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.7047e-04 - val_loss: 0.0017\n",
      "Epoch 1068/2000\n",
      "3490/3490 [==============================] - 1s 288us/step - loss: 1.7730e-04 - val_loss: 0.0020\n",
      "Epoch 1069/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.7505e-04 - val_loss: 0.0014\n",
      "Epoch 1070/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.6530e-04 - val_loss: 0.0017\n",
      "Epoch 1071/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 1.7276e-04 - val_loss: 0.0014\n",
      "Epoch 1072/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.6651e-04 - val_loss: 0.0017\n",
      "Epoch 1073/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.7210e-04 - val_loss: 0.0014\n",
      "Epoch 1074/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.4979e-04 - val_loss: 0.0015\n",
      "Epoch 1075/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.5009e-04 - val_loss: 0.0019\n",
      "Epoch 1076/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.5182e-04 - val_loss: 0.0013\n",
      "Epoch 1077/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.6327e-04 - val_loss: 0.0015\n",
      "Epoch 1078/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.7039e-04 - val_loss: 0.0016\n",
      "Epoch 1079/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 1.6130e-04 - val_loss: 0.0016\n",
      "Epoch 1080/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 1.5363e-04 - val_loss: 0.0016\n",
      "Epoch 1081/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.5276e-04 - val_loss: 0.0016\n",
      "Epoch 1082/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.4525e-04 - val_loss: 0.0015\n",
      "Epoch 1083/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.4021e-04 - val_loss: 0.0017\n",
      "Epoch 1084/2000\n",
      "3490/3490 [==============================] - ETA: 0s - loss: 1.4135e-0 - 1s 288us/step - loss: 1.4252e-04 - val_loss: 0.0017\n",
      "Epoch 1085/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.5070e-04 - val_loss: 0.0019\n",
      "Epoch 1086/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.4383e-04 - val_loss: 0.0017\n",
      "Epoch 1087/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.4458e-04 - val_loss: 0.0017\n",
      "Epoch 1088/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.3681e-04 - val_loss: 0.0017\n",
      "Epoch 1089/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.3789e-04 - val_loss: 0.0017\n",
      "Epoch 1090/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.4939e-04 - val_loss: 0.0017\n",
      "Epoch 1091/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.4729e-04 - val_loss: 0.0019\n",
      "Epoch 1092/2000\n",
      "3490/3490 [==============================] - 1s 288us/step - loss: 1.4144e-04 - val_loss: 0.0016\n",
      "Epoch 1093/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.5257e-04 - val_loss: 0.0017\n",
      "Epoch 1094/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.4738e-04 - val_loss: 0.0018\n",
      "Epoch 1095/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.5023e-04 - val_loss: 0.0023\n",
      "Epoch 1096/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.5666e-04 - val_loss: 0.0017\n",
      "Epoch 1097/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.5044e-04 - val_loss: 0.0016\n",
      "Epoch 1098/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.6437e-04 - val_loss: 0.0016\n",
      "Epoch 1099/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.6799e-04 - val_loss: 0.0017\n",
      "Epoch 1100/2000\n",
      "3490/3490 [==============================] - 1s 288us/step - loss: 1.6360e-04 - val_loss: 0.0015\n",
      "Epoch 1101/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 1.6145e-04 - val_loss: 0.0015\n",
      "Epoch 1102/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.5752e-04 - val_loss: 0.0016\n",
      "Epoch 1103/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.5001e-04 - val_loss: 0.0014\n",
      "Epoch 1104/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.6020e-04 - val_loss: 0.0016\n",
      "Epoch 1105/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 1.7001e-04 - val_loss: 0.0014\n",
      "Epoch 1106/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.6408e-04 - val_loss: 0.0014\n",
      "Epoch 1107/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.5255e-04 - val_loss: 0.0015\n",
      "Epoch 1108/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.5191e-04 - val_loss: 0.0015\n",
      "Epoch 1109/2000\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 1.3832e-04 - val_loss: 0.0016\n",
      "Epoch 1110/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.4430e-04 - val_loss: 0.0016\n",
      "Epoch 1111/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.3329e-04 - val_loss: 0.0017\n",
      "Epoch 1112/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.3917e-04 - val_loss: 0.0018\n",
      "Epoch 1113/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.4810e-04 - val_loss: 0.0018\n",
      "Epoch 1114/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.4444e-04 - val_loss: 0.0021\n",
      "Epoch 1115/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.5818e-04 - val_loss: 0.0018\n",
      "Epoch 1116/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.6445e-04 - val_loss: 0.0018\n",
      "Epoch 1117/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.3636e-04 - val_loss: 0.0020\n",
      "Epoch 1118/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.4396e-04 - val_loss: 0.0015\n",
      "Epoch 1119/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 1.6245e-04 - val_loss: 0.0019\n",
      "Epoch 1120/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.5875e-04 - val_loss: 0.0019\n",
      "Epoch 1121/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.6579e-04 - val_loss: 0.0019\n",
      "Epoch 1122/2000\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 2.0341e-04 - val_loss: 0.0019\n",
      "Epoch 1123/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.9169e-04 - val_loss: 0.0019\n",
      "Epoch 1124/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 2.0011e-04 - val_loss: 0.0019\n",
      "Epoch 1125/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.5827e-04 - val_loss: 0.0020\n",
      "Epoch 1126/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.4628e-04 - val_loss: 0.0015\n",
      "Epoch 1127/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.4199e-04 - val_loss: 0.0018\n",
      "Epoch 1128/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.3800e-04 - val_loss: 0.0018\n",
      "Epoch 1129/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.3472e-04 - val_loss: 0.0018\n",
      "Epoch 1130/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.2443e-04 - val_loss: 0.0018\n",
      "Epoch 1131/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 1.2760e-04 - val_loss: 0.0018\n",
      "Epoch 1132/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 1.3560e-04 - val_loss: 0.0017\n",
      "Epoch 1133/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 1.3153e-04 - val_loss: 0.0018\n",
      "Epoch 1134/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.2712e-04 - val_loss: 0.0018\n",
      "Epoch 1135/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.2829e-04 - val_loss: 0.0019\n",
      "Epoch 1136/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.4360e-04 - val_loss: 0.0019\n",
      "Epoch 1137/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.3332e-04 - val_loss: 0.0022\n",
      "Epoch 1138/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.3437e-04 - val_loss: 0.0018\n",
      "Epoch 1139/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 1.4326e-04 - val_loss: 0.0020\n",
      "Epoch 1140/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 1.5043e-04 - val_loss: 0.0020\n",
      "Epoch 1141/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 1.4786e-04 - val_loss: 0.0021\n",
      "Epoch 1142/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.5162e-04 - val_loss: 0.0017\n",
      "Epoch 1143/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 1.4205e-04 - val_loss: 0.0021\n",
      "Epoch 1144/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 1.5002e-04 - val_loss: 0.0019\n",
      "Epoch 1145/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.6970e-04 - val_loss: 0.0017\n",
      "Epoch 1146/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.8402e-04 - val_loss: 0.0024\n",
      "Epoch 1147/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.7749e-04 - val_loss: 0.0020\n",
      "Epoch 1148/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 2.3472e-04 - val_loss: 0.0017\n",
      "Epoch 1149/2000\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 1.9669e-04 - val_loss: 0.0018\n",
      "Epoch 1150/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.7918e-04 - val_loss: 0.0016\n",
      "Epoch 1151/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.5771e-04 - val_loss: 0.0018\n",
      "Epoch 1152/2000\n",
      "3490/3490 [==============================] - 1s 294us/step - loss: 1.5776e-04 - val_loss: 0.0020\n",
      "Epoch 1153/2000\n",
      "3490/3490 [==============================] - 1s 296us/step - loss: 1.7657e-04 - val_loss: 0.0018\n",
      "Epoch 1154/2000\n",
      "3490/3490 [==============================] - 1s 290us/step - loss: 1.4642e-04 - val_loss: 0.0018\n",
      "Epoch 1155/2000\n",
      "3490/3490 [==============================] - 1s 295us/step - loss: 1.3318e-04 - val_loss: 0.0018\n",
      "Epoch 1156/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.3794e-04 - val_loss: 0.0018\n",
      "Epoch 1157/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.4045e-04 - val_loss: 0.0019\n",
      "Epoch 1158/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.2342e-04 - val_loss: 0.0020\n",
      "Epoch 1159/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.2781e-04 - val_loss: 0.0022\n",
      "Epoch 1160/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.4858e-04 - val_loss: 0.0020\n",
      "Epoch 1161/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.5906e-04 - val_loss: 0.0018\n",
      "Epoch 1162/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.3709e-04 - val_loss: 0.0020\n",
      "Epoch 1163/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.2267e-04 - val_loss: 0.0021\n",
      "Epoch 1164/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 1.2514e-04 - val_loss: 0.0018\n",
      "Epoch 1165/2000\n",
      "3490/3490 [==============================] - 1s 288us/step - loss: 1.2765e-04 - val_loss: 0.0019\n",
      "Epoch 1166/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.2456e-04 - val_loss: 0.0022\n",
      "Epoch 1167/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.2745e-04 - val_loss: 0.0020\n",
      "Epoch 1168/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.3656e-04 - val_loss: 0.0021\n",
      "Epoch 1169/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.4435e-04 - val_loss: 0.0020\n",
      "Epoch 1170/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.3861e-04 - val_loss: 0.0019\n",
      "Epoch 1171/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 1.2776e-04 - val_loss: 0.0019\n",
      "Epoch 1172/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 1.2507e-04 - val_loss: 0.0021\n",
      "Epoch 1173/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.2409e-04 - val_loss: 0.0020\n",
      "Epoch 1174/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.2962e-04 - val_loss: 0.0023\n",
      "Epoch 1175/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.3473e-04 - val_loss: 0.0022\n",
      "Epoch 1176/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 1.1450e-04 - val_loss: 0.0024\n",
      "Epoch 1177/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.1410e-04 - val_loss: 0.0023\n",
      "Epoch 1178/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.1591e-04 - val_loss: 0.0023\n",
      "Epoch 1179/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.3204e-04 - val_loss: 0.0020\n",
      "Epoch 1180/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.1942e-04 - val_loss: 0.0022\n",
      "Epoch 1181/2000\n",
      "3490/3490 [==============================] - 1s 289us/step - loss: 1.2446e-04 - val_loss: 0.0026\n",
      "Epoch 1182/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.3234e-04 - val_loss: 0.0022\n",
      "Epoch 1183/2000\n",
      "3490/3490 [==============================] - 1s 288us/step - loss: 1.1963e-04 - val_loss: 0.0023\n",
      "Epoch 1184/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.3365e-04 - val_loss: 0.0022\n",
      "Epoch 1185/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.2880e-04 - val_loss: 0.0023\n",
      "Epoch 1186/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.1604e-04 - val_loss: 0.0022\n",
      "Epoch 1187/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.1837e-04 - val_loss: 0.0024\n",
      "Epoch 1188/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.2654e-04 - val_loss: 0.0024\n",
      "Epoch 1189/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.3267e-04 - val_loss: 0.0022\n",
      "Epoch 1190/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.1204e-04 - val_loss: 0.0024\n",
      "Epoch 1191/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.1385e-04 - val_loss: 0.0025\n",
      "Epoch 1192/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.2451e-04 - val_loss: 0.0023\n",
      "Epoch 1193/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 1.3379e-04 - val_loss: 0.0021\n",
      "Epoch 1194/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.3375e-04 - val_loss: 0.0022\n",
      "Epoch 1195/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.3167e-04 - val_loss: 0.0023\n",
      "Epoch 1196/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.3422e-04 - val_loss: 0.0020\n",
      "Epoch 1197/2000\n",
      "3490/3490 [==============================] - 1s 288us/step - loss: 1.2965e-04 - val_loss: 0.0023\n",
      "Epoch 1198/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.3535e-04 - val_loss: 0.0022\n",
      "Epoch 1199/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.3204e-04 - val_loss: 0.0020\n",
      "Epoch 1200/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.5584e-04 - val_loss: 0.0023\n",
      "Epoch 1201/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.8456e-04 - val_loss: 0.0021\n",
      "Epoch 1202/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.7659e-04 - val_loss: 0.0019\n",
      "Epoch 1203/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.5488e-04 - val_loss: 0.0026\n",
      "Epoch 1204/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.4008e-04 - val_loss: 0.0025\n",
      "Epoch 1205/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 1.4561e-04 - val_loss: 0.0022\n",
      "Epoch 1206/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.4268e-04 - val_loss: 0.0024\n",
      "Epoch 1207/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.3210e-04 - val_loss: 0.0021\n",
      "Epoch 1208/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 1.3172e-04 - val_loss: 0.0030\n",
      "Epoch 1209/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.2590e-04 - val_loss: 0.0022\n",
      "Epoch 1210/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.1765e-04 - val_loss: 0.0022\n",
      "Epoch 1211/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.2027e-04 - val_loss: 0.0025\n",
      "Epoch 1212/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.4319e-04 - val_loss: 0.0026\n",
      "Epoch 1213/2000\n",
      "3490/3490 [==============================] - 1s 296us/step - loss: 1.2787e-04 - val_loss: 0.0025\n",
      "Epoch 1214/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.2153e-04 - val_loss: 0.0025\n",
      "Epoch 1215/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.2630e-04 - val_loss: 0.0023\n",
      "Epoch 1216/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.2115e-04 - val_loss: 0.0027\n",
      "Epoch 1217/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.2136e-04 - val_loss: 0.0024\n",
      "Epoch 1218/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.1167e-04 - val_loss: 0.0022\n",
      "Epoch 1219/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.1637e-04 - val_loss: 0.0025\n",
      "Epoch 1220/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.2241e-04 - val_loss: 0.0025\n",
      "Epoch 1221/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 1.2842e-04 - val_loss: 0.0026\n",
      "Epoch 1222/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 1.2349e-04 - val_loss: 0.0021\n",
      "Epoch 1223/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.2327e-04 - val_loss: 0.0022\n",
      "Epoch 1224/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.1767e-04 - val_loss: 0.0028\n",
      "Epoch 1225/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.2401e-04 - val_loss: 0.0023\n",
      "Epoch 1226/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.2109e-04 - val_loss: 0.0023\n",
      "Epoch 1227/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.3192e-04 - val_loss: 0.0024\n",
      "Epoch 1228/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.2241e-04 - val_loss: 0.0023\n",
      "Epoch 1229/2000\n",
      "3490/3490 [==============================] - 1s 288us/step - loss: 1.2558e-04 - val_loss: 0.0025\n",
      "Epoch 1230/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.2413e-04 - val_loss: 0.0024\n",
      "Epoch 1231/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.1114e-04 - val_loss: 0.0024\n",
      "Epoch 1232/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.0993e-04 - val_loss: 0.0024\n",
      "Epoch 1233/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.0656e-04 - val_loss: 0.0025\n",
      "Epoch 1234/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.2504e-04 - val_loss: 0.0021\n",
      "Epoch 1235/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.1176e-04 - val_loss: 0.0025\n",
      "Epoch 1236/2000\n",
      "3490/3490 [==============================] - 1s 289us/step - loss: 1.0288e-04 - val_loss: 0.0024\n",
      "Epoch 1237/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.1768e-04 - val_loss: 0.0025\n",
      "Epoch 1238/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.1801e-04 - val_loss: 0.0022\n",
      "Epoch 1239/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 1.0725e-04 - val_loss: 0.0025\n",
      "Epoch 1240/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.1070e-04 - val_loss: 0.0023\n",
      "Epoch 1241/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 1.2644e-04 - val_loss: 0.0021\n",
      "Epoch 1242/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.1391e-04 - val_loss: 0.0022\n",
      "Epoch 1243/2000\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 1.0632e-04 - val_loss: 0.0021\n",
      "Epoch 1244/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 9.9470e-05 - val_loss: 0.0025\n",
      "Epoch 1245/2000\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 1.1778e-04 - val_loss: 0.0021\n",
      "Epoch 1246/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.0837e-04 - val_loss: 0.0022\n",
      "Epoch 1247/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 1.0686e-04 - val_loss: 0.0022\n",
      "Epoch 1248/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 1.0301e-04 - val_loss: 0.0022\n",
      "Epoch 1249/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.0626e-04 - val_loss: 0.0020\n",
      "Epoch 1250/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 9.8972e-05 - val_loss: 0.0023\n",
      "Epoch 1251/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 9.4859e-05 - val_loss: 0.0022\n",
      "Epoch 1252/2000\n",
      "3490/3490 [==============================] - ETA: 0s - loss: 9.3276e-0 - 1s 283us/step - loss: 9.5633e-05 - val_loss: 0.0023\n",
      "Epoch 1253/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.0612e-04 - val_loss: 0.0024\n",
      "Epoch 1254/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.0174e-04 - val_loss: 0.0021\n",
      "Epoch 1255/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.0524e-04 - val_loss: 0.0021\n",
      "Epoch 1256/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.0074e-04 - val_loss: 0.0023\n",
      "Epoch 1257/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.0523e-04 - val_loss: 0.0022\n",
      "Epoch 1258/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.2279e-04 - val_loss: 0.0024\n",
      "Epoch 1259/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.3977e-04 - val_loss: 0.0023\n",
      "Epoch 1260/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.5143e-04 - val_loss: 0.0021\n",
      "Epoch 1261/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 1.2936e-04 - val_loss: 0.0021\n",
      "Epoch 1262/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.1770e-04 - val_loss: 0.0019\n",
      "Epoch 1263/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 1.1936e-04 - val_loss: 0.0026\n",
      "Epoch 1264/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.1869e-04 - val_loss: 0.0022\n",
      "Epoch 1265/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.1601e-04 - val_loss: 0.0023\n",
      "Epoch 1266/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 1.0386e-04 - val_loss: 0.0026\n",
      "Epoch 1267/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.0098e-04 - val_loss: 0.0022\n",
      "Epoch 1268/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.0376e-04 - val_loss: 0.0021\n",
      "Epoch 1269/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.0603e-04 - val_loss: 0.0025\n",
      "Epoch 1270/2000\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 1.0796e-04 - val_loss: 0.0022\n",
      "Epoch 1271/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.1042e-04 - val_loss: 0.0026\n",
      "Epoch 1272/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.1001e-04 - val_loss: 0.0026\n",
      "Epoch 1273/2000\n",
      "3490/3490 [==============================] - 1s 288us/step - loss: 1.1417e-04 - val_loss: 0.0024\n",
      "Epoch 1274/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.0692e-04 - val_loss: 0.0023\n",
      "Epoch 1275/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.1362e-04 - val_loss: 0.0024\n",
      "Epoch 1276/2000\n",
      "3490/3490 [==============================] - 1s 293us/step - loss: 1.1840e-04 - val_loss: 0.0024\n",
      "Epoch 1277/2000\n",
      "3490/3490 [==============================] - 1s 287us/step - loss: 1.2835e-04 - val_loss: 0.0024\n",
      "Epoch 1278/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 1.1402e-04 - val_loss: 0.0023\n",
      "Epoch 1279/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.3661e-04 - val_loss: 0.0027\n",
      "Epoch 1280/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 1.5818e-04 - val_loss: 0.0024\n",
      "Epoch 1281/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 1.4701e-04 - val_loss: 0.0028\n",
      "Epoch 1282/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 1.1358e-04 - val_loss: 0.0022\n",
      "Epoch 1283/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 1.0921e-04 - val_loss: 0.0024\n",
      "Epoch 1284/2000\n",
      "3490/3490 [==============================] - 1s 292us/step - loss: 1.2970e-04 - val_loss: 0.0027\n",
      "Epoch 1285/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.2990e-04 - val_loss: 0.0020\n",
      "Epoch 1286/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.6004e-04 - val_loss: 0.0023\n",
      "Epoch 1287/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.6049e-04 - val_loss: 0.0023\n",
      "Epoch 1288/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.2637e-04 - val_loss: 0.0022\n",
      "Epoch 1289/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.1017e-04 - val_loss: 0.0020\n",
      "Epoch 1290/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.1364e-04 - val_loss: 0.0023\n",
      "Epoch 1291/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.0212e-04 - val_loss: 0.0022\n",
      "Epoch 1292/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 9.7829e-05 - val_loss: 0.0024\n",
      "Epoch 1293/2000\n",
      "3490/3490 [==============================] - 1s 287us/step - loss: 9.8703e-05 - val_loss: 0.0021\n",
      "Epoch 1294/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 1.0622e-04 - val_loss: 0.0023\n",
      "Epoch 1295/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 9.6530e-05 - val_loss: 0.0026\n",
      "Epoch 1296/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 9.3803e-05 - val_loss: 0.0024\n",
      "Epoch 1297/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 9.1737e-05 - val_loss: 0.0024\n",
      "Epoch 1298/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 8.7521e-05 - val_loss: 0.0024\n",
      "Epoch 1299/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 8.6072e-05 - val_loss: 0.0024\n",
      "Epoch 1300/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 9.6922e-05 - val_loss: 0.0025\n",
      "Epoch 1301/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 8.8398e-05 - val_loss: 0.0025\n",
      "Epoch 1302/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 8.8232e-05 - val_loss: 0.0025\n",
      "Epoch 1303/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 9.2928e-05 - val_loss: 0.0022\n",
      "Epoch 1304/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 9.3049e-05 - val_loss: 0.0024\n",
      "Epoch 1305/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 9.3733e-05 - val_loss: 0.0024\n",
      "Epoch 1306/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 9.6391e-05 - val_loss: 0.0023\n",
      "Epoch 1307/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 9.5384e-05 - val_loss: 0.0025\n",
      "Epoch 1308/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 9.0642e-05 - val_loss: 0.0024\n",
      "Epoch 1309/2000\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 9.0231e-05 - val_loss: 0.0026\n",
      "Epoch 1310/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.0542e-04 - val_loss: 0.0026\n",
      "Epoch 1311/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 9.4443e-05 - val_loss: 0.0026\n",
      "Epoch 1312/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 1.2077e-04 - val_loss: 0.0027\n",
      "Epoch 1313/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.5360e-04 - val_loss: 0.0027\n",
      "Epoch 1314/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.2575e-04 - val_loss: 0.0022\n",
      "Epoch 1315/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.2394e-04 - val_loss: 0.0023\n",
      "Epoch 1316/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.1820e-04 - val_loss: 0.0025\n",
      "Epoch 1317/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.0936e-04 - val_loss: 0.0023\n",
      "Epoch 1318/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.0542e-04 - val_loss: 0.0026\n",
      "Epoch 1319/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.0414e-04 - val_loss: 0.0024\n",
      "Epoch 1320/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 9.7505e-05 - val_loss: 0.0022\n",
      "Epoch 1321/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 9.3170e-05 - val_loss: 0.0027\n",
      "Epoch 1322/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.0323e-04 - val_loss: 0.0026\n",
      "Epoch 1323/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.0120e-04 - val_loss: 0.0023\n",
      "Epoch 1324/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 9.0693e-05 - val_loss: 0.0024\n",
      "Epoch 1325/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 9.6799e-05 - val_loss: 0.0024\n",
      "Epoch 1326/2000\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 9.9048e-05 - val_loss: 0.0026\n",
      "Epoch 1327/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.2961e-04 - val_loss: 0.0026\n",
      "Epoch 1328/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 1.2430e-04 - val_loss: 0.0024\n",
      "Epoch 1329/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 1.2042e-04 - val_loss: 0.0025\n",
      "Epoch 1330/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 9.4296e-05 - val_loss: 0.0027\n",
      "Epoch 1331/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 9.3315e-05 - val_loss: 0.0024\n",
      "Epoch 1332/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 8.6043e-05 - val_loss: 0.0025\n",
      "Epoch 1333/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 9.5742e-05 - val_loss: 0.0025\n",
      "Epoch 1334/2000\n",
      "3490/3490 [==============================] - 1s 288us/step - loss: 1.0353e-04 - val_loss: 0.0027\n",
      "Epoch 1335/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.1576e-04 - val_loss: 0.0026\n",
      "Epoch 1336/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.2152e-04 - val_loss: 0.0026\n",
      "Epoch 1337/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 1.1311e-04 - val_loss: 0.0023\n",
      "Epoch 1338/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.0639e-04 - val_loss: 0.0025\n",
      "Epoch 1339/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.0406e-04 - val_loss: 0.0024\n",
      "Epoch 1340/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.1650e-04 - val_loss: 0.0024\n",
      "Epoch 1341/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 1.3091e-04 - val_loss: 0.0022\n",
      "Epoch 1342/2000\n",
      "3490/3490 [==============================] - 1s 288us/step - loss: 1.1276e-04 - val_loss: 0.0025\n",
      "Epoch 1343/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.0602e-04 - val_loss: 0.0023\n",
      "Epoch 1344/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.1116e-04 - val_loss: 0.0020\n",
      "Epoch 1345/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.0995e-04 - val_loss: 0.0022\n",
      "Epoch 1346/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 8.4942e-05 - val_loss: 0.0024\n",
      "Epoch 1347/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 8.4349e-05 - val_loss: 0.0021\n",
      "Epoch 1348/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 8.5870e-05 - val_loss: 0.0022\n",
      "Epoch 1349/2000\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 8.6800e-05 - val_loss: 0.0021\n",
      "Epoch 1350/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 9.2763e-05 - val_loss: 0.0023\n",
      "Epoch 1351/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3490/3490 [==============================] - 1s 287us/step - loss: 9.8259e-05 - val_loss: 0.0023\n",
      "Epoch 1352/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.0098e-04 - val_loss: 0.0023\n",
      "Epoch 1353/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 9.7839e-05 - val_loss: 0.0024\n",
      "Epoch 1354/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.1236e-04 - val_loss: 0.0028\n",
      "Epoch 1355/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.2090e-04 - val_loss: 0.0022\n",
      "Epoch 1356/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.1193e-04 - val_loss: 0.0025\n",
      "Epoch 1357/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.4927e-04 - val_loss: 0.0023\n",
      "Epoch 1358/2000\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 1.4081e-04 - val_loss: 0.0023\n",
      "Epoch 1359/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 1.0862e-04 - val_loss: 0.0023\n",
      "Epoch 1360/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.1985e-04 - val_loss: 0.0027\n",
      "Epoch 1361/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.0546e-04 - val_loss: 0.0022\n",
      "Epoch 1362/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 9.2297e-05 - val_loss: 0.0024\n",
      "Epoch 1363/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.0094e-04 - val_loss: 0.0025\n",
      "Epoch 1364/2000\n",
      "3490/3490 [==============================] - 1s 289us/step - loss: 1.0139e-04 - val_loss: 0.0023\n",
      "Epoch 1365/2000\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 9.0008e-05 - val_loss: 0.0024\n",
      "Epoch 1366/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 8.3446e-05 - val_loss: 0.0026\n",
      "Epoch 1367/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 7.9425e-05 - val_loss: 0.0025\n",
      "Epoch 1368/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 8.1546e-05 - val_loss: 0.0027\n",
      "Epoch 1369/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 8.3129e-05 - val_loss: 0.0026\n",
      "Epoch 1370/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 8.2826e-05 - val_loss: 0.0027\n",
      "Epoch 1371/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 7.9823e-05 - val_loss: 0.0025\n",
      "Epoch 1372/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 8.0424e-05 - val_loss: 0.0026\n",
      "Epoch 1373/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 8.2812e-05 - val_loss: 0.0027\n",
      "Epoch 1374/2000\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 9.1383e-05 - val_loss: 0.0027\n",
      "Epoch 1375/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 9.1898e-05 - val_loss: 0.0027\n",
      "Epoch 1376/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 8.6160e-05 - val_loss: 0.0027\n",
      "Epoch 1377/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 8.8699e-05 - val_loss: 0.0026\n",
      "Epoch 1378/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 8.1925e-05 - val_loss: 0.0027\n",
      "Epoch 1379/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 8.1918e-05 - val_loss: 0.0026\n",
      "Epoch 1380/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 8.9679e-05 - val_loss: 0.0026\n",
      "Epoch 1381/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 8.6841e-05 - val_loss: 0.0027\n",
      "Epoch 1382/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 8.2232e-05 - val_loss: 0.0027\n",
      "Epoch 1383/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 7.9301e-05 - val_loss: 0.0027\n",
      "Epoch 1384/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 8.1818e-05 - val_loss: 0.0026\n",
      "Epoch 1385/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 8.8360e-05 - val_loss: 0.0028\n",
      "Epoch 1386/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 8.6607e-05 - val_loss: 0.0027\n",
      "Epoch 1387/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 9.5023e-05 - val_loss: 0.0028\n",
      "Epoch 1388/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 9.1331e-05 - val_loss: 0.0024\n",
      "Epoch 1389/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 8.3242e-05 - val_loss: 0.0026\n",
      "Epoch 1390/2000\n",
      "3490/3490 [==============================] - 1s 287us/step - loss: 9.1968e-05 - val_loss: 0.0026\n",
      "Epoch 1391/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 8.6143e-05 - val_loss: 0.0026\n",
      "Epoch 1392/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 8.4387e-05 - val_loss: 0.0027\n",
      "Epoch 1393/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 9.8855e-05 - val_loss: 0.0029\n",
      "Epoch 1394/2000\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 9.1773e-05 - val_loss: 0.0029\n",
      "Epoch 1395/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.0054e-04 - val_loss: 0.0028\n",
      "Epoch 1396/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 9.5220e-05 - val_loss: 0.0026\n",
      "Epoch 1397/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 9.8711e-05 - val_loss: 0.0026\n",
      "Epoch 1398/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 8.8388e-05 - val_loss: 0.0027\n",
      "Epoch 1399/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 9.8484e-05 - val_loss: 0.0026\n",
      "Epoch 1400/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 9.3380e-05 - val_loss: 0.0025\n",
      "Epoch 1401/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 8.1085e-05 - val_loss: 0.0024\n",
      "Epoch 1402/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 9.4421e-05 - val_loss: 0.0026\n",
      "Epoch 1403/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 1.0114e-04 - val_loss: 0.0026\n",
      "Epoch 1404/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 9.9858e-05 - val_loss: 0.0026\n",
      "Epoch 1405/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.0905e-04 - val_loss: 0.0026\n",
      "Epoch 1406/2000\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 1.0041e-04 - val_loss: 0.0026\n",
      "Epoch 1407/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.1107e-04 - val_loss: 0.0026\n",
      "Epoch 1408/2000\n",
      "3490/3490 [==============================] - 1s 287us/step - loss: 9.7446e-05 - val_loss: 0.0029\n",
      "Epoch 1409/2000\n",
      "3490/3490 [==============================] - 1s 289us/step - loss: 9.1081e-05 - val_loss: 0.0027\n",
      "Epoch 1410/2000\n",
      "3490/3490 [==============================] - 1s 291us/step - loss: 8.6714e-05 - val_loss: 0.0028\n",
      "Epoch 1411/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 9.3970e-05 - val_loss: 0.0026\n",
      "Epoch 1412/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 8.8616e-05 - val_loss: 0.0029\n",
      "Epoch 1413/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 8.0319e-05 - val_loss: 0.0026\n",
      "Epoch 1414/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 8.4644e-05 - val_loss: 0.0026\n",
      "Epoch 1415/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 7.9477e-05 - val_loss: 0.0025\n",
      "Epoch 1416/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 8.2355e-05 - val_loss: 0.0027\n",
      "Epoch 1417/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 9.5538e-05 - val_loss: 0.0026\n",
      "Epoch 1418/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 9.3740e-05 - val_loss: 0.0028\n",
      "Epoch 1419/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 8.6807e-05 - val_loss: 0.0027\n",
      "Epoch 1420/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 8.2954e-05 - val_loss: 0.0026\n",
      "Epoch 1421/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 7.8281e-05 - val_loss: 0.0026\n",
      "Epoch 1422/2000\n",
      "3490/3490 [==============================] - 1s 287us/step - loss: 7.3244e-05 - val_loss: 0.0027\n",
      "Epoch 1423/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3490/3490 [==============================] - 1s 285us/step - loss: 7.3800e-05 - val_loss: 0.0025\n",
      "Epoch 1424/2000\n",
      "3490/3490 [==============================] - 1s 287us/step - loss: 7.7851e-05 - val_loss: 0.0027\n",
      "Epoch 1425/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 7.6256e-05 - val_loss: 0.0028\n",
      "Epoch 1426/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 8.2436e-05 - val_loss: 0.0029\n",
      "Epoch 1427/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 8.6752e-05 - val_loss: 0.0028\n",
      "Epoch 1428/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 8.7399e-05 - val_loss: 0.0027\n",
      "Epoch 1429/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 8.5167e-05 - val_loss: 0.0026\n",
      "Epoch 1430/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 7.4624e-05 - val_loss: 0.0028\n",
      "Epoch 1431/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 7.5866e-05 - val_loss: 0.0027\n",
      "Epoch 1432/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 7.9579e-05 - val_loss: 0.0027\n",
      "Epoch 1433/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 8.5761e-05 - val_loss: 0.0030\n",
      "Epoch 1434/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 8.6313e-05 - val_loss: 0.0029\n",
      "Epoch 1435/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 9.4056e-05 - val_loss: 0.0027\n",
      "Epoch 1436/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 1.0896e-04 - val_loss: 0.0026\n",
      "Epoch 1437/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.0472e-04 - val_loss: 0.0027\n",
      "Epoch 1438/2000\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 9.0440e-05 - val_loss: 0.0026\n",
      "Epoch 1439/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 8.5570e-05 - val_loss: 0.0026\n",
      "Epoch 1440/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 8.0611e-05 - val_loss: 0.0026\n",
      "Epoch 1441/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 7.5803e-05 - val_loss: 0.0026\n",
      "Epoch 1442/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 7.1148e-05 - val_loss: 0.0026\n",
      "Epoch 1443/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 7.0016e-05 - val_loss: 0.0028\n",
      "Epoch 1444/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 8.1731e-05 - val_loss: 0.0027\n",
      "Epoch 1445/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 9.2042e-05 - val_loss: 0.0028\n",
      "Epoch 1446/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 8.8684e-05 - val_loss: 0.0028\n",
      "Epoch 1447/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 9.6425e-05 - val_loss: 0.0026\n",
      "Epoch 1448/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 9.4694e-05 - val_loss: 0.0027\n",
      "Epoch 1449/2000\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 8.6899e-05 - val_loss: 0.0026\n",
      "Epoch 1450/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 8.1860e-05 - val_loss: 0.0028\n",
      "Epoch 1451/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 8.1092e-05 - val_loss: 0.0026\n",
      "Epoch 1452/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 7.8925e-05 - val_loss: 0.0028\n",
      "Epoch 1453/2000\n",
      "3490/3490 [==============================] - 1s 290us/step - loss: 7.4386e-05 - val_loss: 0.0026\n",
      "Epoch 1454/2000\n",
      "3490/3490 [==============================] - 1s 288us/step - loss: 7.6296e-05 - val_loss: 0.0027\n",
      "Epoch 1455/2000\n",
      "3490/3490 [==============================] - 1s 289us/step - loss: 8.1268e-05 - val_loss: 0.0025\n",
      "Epoch 1456/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 8.6652e-05 - val_loss: 0.0026\n",
      "Epoch 1457/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 7.9335e-05 - val_loss: 0.0027\n",
      "Epoch 1458/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 7.3779e-05 - val_loss: 0.0025\n",
      "Epoch 1459/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 7.3886e-05 - val_loss: 0.0026\n",
      "Epoch 1460/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 6.9808e-05 - val_loss: 0.0028\n",
      "Epoch 1461/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 7.1344e-05 - val_loss: 0.0027\n",
      "Epoch 1462/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 7.6121e-05 - val_loss: 0.0027\n",
      "Epoch 1463/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 7.5234e-05 - val_loss: 0.0026\n",
      "Epoch 1464/2000\n",
      "3490/3490 [==============================] - ETA: 0s - loss: 7.5225e-0 - 1s 285us/step - loss: 7.5631e-05 - val_loss: 0.0027\n",
      "Epoch 1465/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 8.2578e-05 - val_loss: 0.0028\n",
      "Epoch 1466/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 8.8309e-05 - val_loss: 0.0027\n",
      "Epoch 1467/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 8.1656e-05 - val_loss: 0.0025\n",
      "Epoch 1468/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 8.0862e-05 - val_loss: 0.0026\n",
      "Epoch 1469/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 7.7996e-05 - val_loss: 0.0026\n",
      "Epoch 1470/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 7.3603e-05 - val_loss: 0.0029\n",
      "Epoch 1471/2000\n",
      "3490/3490 [==============================] - 1s 288us/step - loss: 7.8519e-05 - val_loss: 0.0028\n",
      "Epoch 1472/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 7.9165e-05 - val_loss: 0.0028\n",
      "Epoch 1473/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 8.1975e-05 - val_loss: 0.0028\n",
      "Epoch 1474/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 8.2885e-05 - val_loss: 0.0028\n",
      "Epoch 1475/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 9.0611e-05 - val_loss: 0.0029\n",
      "Epoch 1476/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 8.1869e-05 - val_loss: 0.0027\n",
      "Epoch 1477/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 8.8144e-05 - val_loss: 0.0027\n",
      "Epoch 1478/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.1849e-04 - val_loss: 0.0029\n",
      "Epoch 1479/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.1079e-04 - val_loss: 0.0030\n",
      "Epoch 1480/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 1.2023e-04 - val_loss: 0.0028\n",
      "Epoch 1481/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 1.0763e-04 - val_loss: 0.0028\n",
      "Epoch 1482/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.0568e-04 - val_loss: 0.0026\n",
      "Epoch 1483/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 1.1872e-04 - val_loss: 0.0028\n",
      "Epoch 1484/2000\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 1.0291e-04 - val_loss: 0.0026\n",
      "Epoch 1485/2000\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 8.6794e-05 - val_loss: 0.0030\n",
      "Epoch 1486/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 7.3818e-05 - val_loss: 0.0029\n",
      "Epoch 1487/2000\n",
      "3490/3490 [==============================] - 1s 289us/step - loss: 6.6529e-05 - val_loss: 0.0029\n",
      "Epoch 1488/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 6.6569e-05 - val_loss: 0.0028\n",
      "Epoch 1489/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 7.0076e-05 - val_loss: 0.0027\n",
      "Epoch 1490/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 8.1532e-05 - val_loss: 0.0027\n",
      "Epoch 1491/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 8.2851e-05 - val_loss: 0.0026\n",
      "Epoch 1492/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 7.8034e-05 - val_loss: 0.0025\n",
      "Epoch 1493/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 7.7276e-05 - val_loss: 0.0027\n",
      "Epoch 1494/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 8.1934e-05 - val_loss: 0.0027\n",
      "Epoch 1495/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3490/3490 [==============================] - 1s 283us/step - loss: 6.9861e-05 - val_loss: 0.0028\n",
      "Epoch 1496/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 7.0890e-05 - val_loss: 0.0030\n",
      "Epoch 1497/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 7.0579e-05 - val_loss: 0.0028\n",
      "Epoch 1498/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 6.9214e-05 - val_loss: 0.0027\n",
      "Epoch 1499/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 6.9444e-05 - val_loss: 0.0029\n",
      "Epoch 1500/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 8.0428e-05 - val_loss: 0.0031\n",
      "Epoch 1501/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 6.6768e-05 - val_loss: 0.0029\n",
      "Epoch 1502/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 6.7075e-05 - val_loss: 0.0030\n",
      "Epoch 1503/2000\n",
      "3490/3490 [==============================] - 1s 287us/step - loss: 6.5874e-05 - val_loss: 0.0028\n",
      "Epoch 1504/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 7.1015e-05 - val_loss: 0.0030\n",
      "Epoch 1505/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 7.0102e-05 - val_loss: 0.0029\n",
      "Epoch 1506/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 6.7484e-05 - val_loss: 0.0030\n",
      "Epoch 1507/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 7.4393e-05 - val_loss: 0.0030\n",
      "Epoch 1508/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 7.4621e-05 - val_loss: 0.0030\n",
      "Epoch 1509/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 7.1915e-05 - val_loss: 0.0027\n",
      "Epoch 1510/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 8.8880e-05 - val_loss: 0.0028\n",
      "Epoch 1511/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 8.3781e-05 - val_loss: 0.0028\n",
      "Epoch 1512/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 7.1966e-05 - val_loss: 0.0030\n",
      "Epoch 1513/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 7.7248e-05 - val_loss: 0.0028\n",
      "Epoch 1514/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 7.4454e-05 - val_loss: 0.0030\n",
      "Epoch 1515/2000\n",
      "3490/3490 [==============================] - 1s 287us/step - loss: 7.0014e-05 - val_loss: 0.0029\n",
      "Epoch 1516/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 7.4411e-05 - val_loss: 0.0030\n",
      "Epoch 1517/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 7.3074e-05 - val_loss: 0.0028\n",
      "Epoch 1518/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 6.3816e-05 - val_loss: 0.0028\n",
      "Epoch 1519/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 6.9408e-05 - val_loss: 0.0025\n",
      "Epoch 1520/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 7.0962e-05 - val_loss: 0.0028\n",
      "Epoch 1521/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 7.3274e-05 - val_loss: 0.0029\n",
      "Epoch 1522/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 8.6361e-05 - val_loss: 0.0028\n",
      "Epoch 1523/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 9.7380e-05 - val_loss: 0.0025\n",
      "Epoch 1524/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.0775e-04 - val_loss: 0.0026\n",
      "Epoch 1525/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 7.8626e-05 - val_loss: 0.0027\n",
      "Epoch 1526/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 7.6522e-05 - val_loss: 0.0026\n",
      "Epoch 1527/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 6.6887e-05 - val_loss: 0.0027\n",
      "Epoch 1528/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 6.5446e-05 - val_loss: 0.0027\n",
      "Epoch 1529/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 6.2700e-05 - val_loss: 0.0027\n",
      "Epoch 1530/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 6.7993e-05 - val_loss: 0.0027\n",
      "Epoch 1531/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 6.9743e-05 - val_loss: 0.0028\n",
      "Epoch 1532/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 6.7509e-05 - val_loss: 0.0028\n",
      "Epoch 1533/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 7.1846e-05 - val_loss: 0.0027\n",
      "Epoch 1534/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 7.0561e-05 - val_loss: 0.0028\n",
      "Epoch 1535/2000\n",
      "3490/3490 [==============================] - 1s 288us/step - loss: 7.2665e-05 - val_loss: 0.0029\n",
      "Epoch 1536/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 7.5621e-05 - val_loss: 0.0030\n",
      "Epoch 1537/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 8.6651e-05 - val_loss: 0.0027\n",
      "Epoch 1538/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 7.4555e-05 - val_loss: 0.0027\n",
      "Epoch 1539/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 7.9105e-05 - val_loss: 0.0028\n",
      "Epoch 1540/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 8.8785e-05 - val_loss: 0.0029\n",
      "Epoch 1541/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 8.8593e-05 - val_loss: 0.0026\n",
      "Epoch 1542/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 8.5753e-05 - val_loss: 0.0027\n",
      "Epoch 1543/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 9.9412e-05 - val_loss: 0.0026\n",
      "Epoch 1544/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 7.8674e-05 - val_loss: 0.0029\n",
      "Epoch 1545/2000\n",
      "3490/3490 [==============================] - 1s 288us/step - loss: 7.6669e-05 - val_loss: 0.0026\n",
      "Epoch 1546/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 7.2463e-05 - val_loss: 0.0027\n",
      "Epoch 1547/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 7.9722e-05 - val_loss: 0.0026\n",
      "Epoch 1548/2000\n",
      "3490/3490 [==============================] - 1s 289us/step - loss: 8.6723e-05 - val_loss: 0.0028\n",
      "Epoch 1549/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 7.9842e-05 - val_loss: 0.0025\n",
      "Epoch 1550/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 7.4571e-05 - val_loss: 0.0027\n",
      "Epoch 1551/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 8.7124e-05 - val_loss: 0.0028\n",
      "Epoch 1552/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 7.6422e-05 - val_loss: 0.0028\n",
      "Epoch 1553/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 6.8176e-05 - val_loss: 0.0027\n",
      "Epoch 1554/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 6.6462e-05 - val_loss: 0.0028\n",
      "Epoch 1555/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 6.1275e-05 - val_loss: 0.0027\n",
      "Epoch 1556/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 6.1521e-05 - val_loss: 0.0028\n",
      "Epoch 1557/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 5.7090e-05 - val_loss: 0.0027\n",
      "Epoch 1558/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 6.0128e-05 - val_loss: 0.0028\n",
      "Epoch 1559/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 6.5305e-05 - val_loss: 0.0028\n",
      "Epoch 1560/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 6.8860e-05 - val_loss: 0.0027\n",
      "Epoch 1561/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 7.0839e-05 - val_loss: 0.0027\n",
      "Epoch 1562/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 6.3857e-05 - val_loss: 0.0028\n",
      "Epoch 1563/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 6.5620e-05 - val_loss: 0.0027\n",
      "Epoch 1564/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 6.6614e-05 - val_loss: 0.0027\n",
      "Epoch 1565/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 6.7962e-05 - val_loss: 0.0027\n",
      "Epoch 1566/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 6.1482e-05 - val_loss: 0.0026\n",
      "Epoch 1567/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3490/3490 [==============================] - 1s 286us/step - loss: 5.8981e-05 - val_loss: 0.0026\n",
      "Epoch 1568/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 7.1961e-05 - val_loss: 0.0026\n",
      "Epoch 1569/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 7.1174e-05 - val_loss: 0.0027\n",
      "Epoch 1570/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 6.7569e-05 - val_loss: 0.0029\n",
      "Epoch 1571/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 7.5898e-05 - val_loss: 0.0028\n",
      "Epoch 1572/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 8.3451e-05 - val_loss: 0.0026\n",
      "Epoch 1573/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 9.6014e-05 - val_loss: 0.0024\n",
      "Epoch 1574/2000\n",
      "3490/3490 [==============================] - ETA: 0s - loss: 7.4511e-0 - 1s 285us/step - loss: 7.3300e-05 - val_loss: 0.0028\n",
      "Epoch 1575/2000\n",
      "3490/3490 [==============================] - 1s 287us/step - loss: 8.0604e-05 - val_loss: 0.0027\n",
      "Epoch 1576/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 8.5708e-05 - val_loss: 0.0028\n",
      "Epoch 1577/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 7.9205e-05 - val_loss: 0.0025\n",
      "Epoch 1578/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 6.8636e-05 - val_loss: 0.0027\n",
      "Epoch 1579/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 6.7550e-05 - val_loss: 0.0026\n",
      "Epoch 1580/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 6.0669e-05 - val_loss: 0.0028\n",
      "Epoch 1581/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 7.3042e-05 - val_loss: 0.0029\n",
      "Epoch 1582/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 8.2767e-05 - val_loss: 0.0026\n",
      "Epoch 1583/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 6.5116e-05 - val_loss: 0.0024\n",
      "Epoch 1584/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 7.9628e-05 - val_loss: 0.0026\n",
      "Epoch 1585/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 6.6844e-05 - val_loss: 0.0026\n",
      "Epoch 1586/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 6.1106e-05 - val_loss: 0.0025\n",
      "Epoch 1587/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 6.4715e-05 - val_loss: 0.0027\n",
      "Epoch 1588/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 7.3925e-05 - val_loss: 0.0026\n",
      "Epoch 1589/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 8.1423e-05 - val_loss: 0.0028\n",
      "Epoch 1590/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 7.2340e-05 - val_loss: 0.0025\n",
      "Epoch 1591/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 6.7420e-05 - val_loss: 0.0027\n",
      "Epoch 1592/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 7.0937e-05 - val_loss: 0.0025\n",
      "Epoch 1593/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 6.2130e-05 - val_loss: 0.0028\n",
      "Epoch 1594/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 6.4589e-05 - val_loss: 0.0027\n",
      "Epoch 1595/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 5.9637e-05 - val_loss: 0.0027\n",
      "Epoch 1596/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.4531e-05 - val_loss: 0.0027\n",
      "Epoch 1597/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 5.5775e-05 - val_loss: 0.0027\n",
      "Epoch 1598/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 6.2397e-05 - val_loss: 0.0028\n",
      "Epoch 1599/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 5.7094e-05 - val_loss: 0.0026\n",
      "Epoch 1600/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 6.9051e-05 - val_loss: 0.0029\n",
      "Epoch 1601/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 6.1687e-05 - val_loss: 0.0028\n",
      "Epoch 1602/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 6.4952e-05 - val_loss: 0.0028\n",
      "Epoch 1603/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 7.8301e-05 - val_loss: 0.0027\n",
      "Epoch 1604/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 7.6932e-05 - val_loss: 0.0028\n",
      "Epoch 1605/2000\n",
      "3490/3490 [==============================] - 1s 287us/step - loss: 8.0916e-05 - val_loss: 0.0032\n",
      "Epoch 1606/2000\n",
      "3490/3490 [==============================] - ETA: 0s - loss: 7.8515e-0 - 1s 285us/step - loss: 7.7042e-05 - val_loss: 0.0027\n",
      "Epoch 1607/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 7.0364e-05 - val_loss: 0.0028\n",
      "Epoch 1608/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 6.3495e-05 - val_loss: 0.0028\n",
      "Epoch 1609/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 6.4281e-05 - val_loss: 0.0029\n",
      "Epoch 1610/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 6.1945e-05 - val_loss: 0.0029\n",
      "Epoch 1611/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 6.3326e-05 - val_loss: 0.0027\n",
      "Epoch 1612/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.9395e-05 - val_loss: 0.0028\n",
      "Epoch 1613/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.4438e-05 - val_loss: 0.0028\n",
      "Epoch 1614/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.8257e-05 - val_loss: 0.0029\n",
      "Epoch 1615/2000\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 5.9888e-05 - val_loss: 0.0027\n",
      "Epoch 1616/2000\n",
      "3490/3490 [==============================] - 1s 287us/step - loss: 6.0045e-05 - val_loss: 0.0028\n",
      "Epoch 1617/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 6.3969e-05 - val_loss: 0.0028\n",
      "Epoch 1618/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 6.0025e-05 - val_loss: 0.0029\n",
      "Epoch 1619/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.6578e-05 - val_loss: 0.0028\n",
      "Epoch 1620/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.5566e-05 - val_loss: 0.0028\n",
      "Epoch 1621/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.4118e-05 - val_loss: 0.0028\n",
      "Epoch 1622/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 5.0393e-05 - val_loss: 0.0029\n",
      "Epoch 1623/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 5.7430e-05 - val_loss: 0.0029\n",
      "Epoch 1624/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 5.6797e-05 - val_loss: 0.0029\n",
      "Epoch 1625/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.7106e-05 - val_loss: 0.0027\n",
      "Epoch 1626/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 5.6046e-05 - val_loss: 0.0028\n",
      "Epoch 1627/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 5.3624e-05 - val_loss: 0.0028\n",
      "Epoch 1628/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.7212e-05 - val_loss: 0.0028\n",
      "Epoch 1629/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 6.3746e-05 - val_loss: 0.0027\n",
      "Epoch 1630/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 6.2602e-05 - val_loss: 0.0028\n",
      "Epoch 1631/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 6.9064e-05 - val_loss: 0.0028\n",
      "Epoch 1632/2000\n",
      "3490/3490 [==============================] - 1s 287us/step - loss: 6.5624e-05 - val_loss: 0.0028\n",
      "Epoch 1633/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 6.8933e-05 - val_loss: 0.0028\n",
      "Epoch 1634/2000\n",
      "3490/3490 [==============================] - 1s 289us/step - loss: 6.5420e-05 - val_loss: 0.0028\n",
      "Epoch 1635/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 6.5124e-05 - val_loss: 0.0030\n",
      "Epoch 1636/2000\n",
      "3490/3490 [==============================] - 1s 287us/step - loss: 6.4946e-05 - val_loss: 0.0030\n",
      "Epoch 1637/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 7.4340e-05 - val_loss: 0.0030\n",
      "Epoch 1638/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 7.3731e-05 - val_loss: 0.0028\n",
      "Epoch 1639/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3490/3490 [==============================] - 1s 282us/step - loss: 6.0766e-05 - val_loss: 0.0029\n",
      "Epoch 1640/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 6.1477e-05 - val_loss: 0.0028\n",
      "Epoch 1641/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 6.5644e-05 - val_loss: 0.0030\n",
      "Epoch 1642/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 6.8084e-05 - val_loss: 0.0028\n",
      "Epoch 1643/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 6.3212e-05 - val_loss: 0.0027\n",
      "Epoch 1644/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 6.5540e-05 - val_loss: 0.0028\n",
      "Epoch 1645/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.4242e-05 - val_loss: 0.0027\n",
      "Epoch 1646/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 5.9774e-05 - val_loss: 0.0027\n",
      "Epoch 1647/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 5.7718e-05 - val_loss: 0.0027\n",
      "Epoch 1648/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 6.3522e-05 - val_loss: 0.0028\n",
      "Epoch 1649/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 6.1039e-05 - val_loss: 0.0029\n",
      "Epoch 1650/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 6.3687e-05 - val_loss: 0.0028\n",
      "Epoch 1651/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 6.4738e-05 - val_loss: 0.0029\n",
      "Epoch 1652/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 5.8340e-05 - val_loss: 0.0027\n",
      "Epoch 1653/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 5.5463e-05 - val_loss: 0.0027\n",
      "Epoch 1654/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 6.1838e-05 - val_loss: 0.0028\n",
      "Epoch 1655/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 6.1853e-05 - val_loss: 0.0028\n",
      "Epoch 1656/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 6.3277e-05 - val_loss: 0.0026\n",
      "Epoch 1657/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 6.9109e-05 - val_loss: 0.0029\n",
      "Epoch 1658/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 6.6463e-05 - val_loss: 0.0030\n",
      "Epoch 1659/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 6.7131e-05 - val_loss: 0.0027\n",
      "Epoch 1660/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 6.0057e-05 - val_loss: 0.0026\n",
      "Epoch 1661/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 6.1152e-05 - val_loss: 0.0026\n",
      "Epoch 1662/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 6.7331e-05 - val_loss: 0.0026\n",
      "Epoch 1663/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.5378e-05 - val_loss: 0.0027\n",
      "Epoch 1664/2000\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 6.1038e-05 - val_loss: 0.0026\n",
      "Epoch 1665/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.8030e-05 - val_loss: 0.0025\n",
      "Epoch 1666/2000\n",
      "3490/3490 [==============================] - 1s 288us/step - loss: 5.7636e-05 - val_loss: 0.0026\n",
      "Epoch 1667/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 7.1243e-05 - val_loss: 0.0025\n",
      "Epoch 1668/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 7.0053e-05 - val_loss: 0.0025\n",
      "Epoch 1669/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 5.8092e-05 - val_loss: 0.0030\n",
      "Epoch 1670/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 5.7569e-05 - val_loss: 0.0029\n",
      "Epoch 1671/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 6.6852e-05 - val_loss: 0.0028\n",
      "Epoch 1672/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 7.6003e-05 - val_loss: 0.0027\n",
      "Epoch 1673/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 7.3045e-05 - val_loss: 0.0027\n",
      "Epoch 1674/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 6.9116e-05 - val_loss: 0.0031\n",
      "Epoch 1675/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 7.5871e-05 - val_loss: 0.0028\n",
      "Epoch 1676/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 6.9484e-05 - val_loss: 0.0028\n",
      "Epoch 1677/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 9.1152e-05 - val_loss: 0.0027\n",
      "Epoch 1678/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 6.9967e-05 - val_loss: 0.0027\n",
      "Epoch 1679/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 6.4414e-05 - val_loss: 0.0027\n",
      "Epoch 1680/2000\n",
      "3490/3490 [==============================] - 1s 288us/step - loss: 6.2696e-05 - val_loss: 0.0028\n",
      "Epoch 1681/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 5.3247e-05 - val_loss: 0.0027\n",
      "Epoch 1682/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 5.1977e-05 - val_loss: 0.0027\n",
      "Epoch 1683/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.3019e-05 - val_loss: 0.0026\n",
      "Epoch 1684/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.5563e-05 - val_loss: 0.0027\n",
      "Epoch 1685/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.3943e-05 - val_loss: 0.0027\n",
      "Epoch 1686/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.3202e-05 - val_loss: 0.0028\n",
      "Epoch 1687/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.1568e-05 - val_loss: 0.0026\n",
      "Epoch 1688/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 6.2257e-05 - val_loss: 0.0028\n",
      "Epoch 1689/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 6.1190e-05 - val_loss: 0.0025\n",
      "Epoch 1690/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 5.2935e-05 - val_loss: 0.0028\n",
      "Epoch 1691/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 5.1012e-05 - val_loss: 0.0028\n",
      "Epoch 1692/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 5.7427e-05 - val_loss: 0.0027\n",
      "Epoch 1693/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 5.9165e-05 - val_loss: 0.0027\n",
      "Epoch 1694/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.2731e-05 - val_loss: 0.0029\n",
      "Epoch 1695/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.2230e-05 - val_loss: 0.0028\n",
      "Epoch 1696/2000\n",
      "3490/3490 [==============================] - 1s 292us/step - loss: 5.0194e-05 - val_loss: 0.0027\n",
      "Epoch 1697/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 5.3789e-05 - val_loss: 0.0026\n",
      "Epoch 1698/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.2828e-05 - val_loss: 0.0027\n",
      "Epoch 1699/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.7198e-05 - val_loss: 0.0028\n",
      "Epoch 1700/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 7.8067e-05 - val_loss: 0.0031\n",
      "Epoch 1701/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 1.1810e-04 - val_loss: 0.0026\n",
      "Epoch 1702/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 1.1061e-04 - val_loss: 0.0025\n",
      "Epoch 1703/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 9.8717e-05 - val_loss: 0.0025\n",
      "Epoch 1704/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 8.2075e-05 - val_loss: 0.0027\n",
      "Epoch 1705/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 8.0429e-05 - val_loss: 0.0027\n",
      "Epoch 1706/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 7.7586e-05 - val_loss: 0.0024\n",
      "Epoch 1707/2000\n",
      "3490/3490 [==============================] - ETA: 0s - loss: 6.7841e-0 - 1s 283us/step - loss: 6.6613e-05 - val_loss: 0.0027\n",
      "Epoch 1708/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 6.9090e-05 - val_loss: 0.0027\n",
      "Epoch 1709/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 6.3676e-05 - val_loss: 0.0027\n",
      "Epoch 1710/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 5.8996e-05 - val_loss: 0.0026\n",
      "Epoch 1711/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3490/3490 [==============================] - 1s 285us/step - loss: 5.2028e-05 - val_loss: 0.0026\n",
      "Epoch 1712/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 5.1296e-05 - val_loss: 0.0026\n",
      "Epoch 1713/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 4.9905e-05 - val_loss: 0.0027\n",
      "Epoch 1714/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 5.3666e-05 - val_loss: 0.0028\n",
      "Epoch 1715/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 4.9881e-05 - val_loss: 0.0027\n",
      "Epoch 1716/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.1967e-05 - val_loss: 0.0027\n",
      "Epoch 1717/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.6542e-05 - val_loss: 0.0029\n",
      "Epoch 1718/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 4.5823e-05 - val_loss: 0.0028\n",
      "Epoch 1719/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 4.8160e-05 - val_loss: 0.0029\n",
      "Epoch 1720/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 5.0898e-05 - val_loss: 0.0025\n",
      "Epoch 1721/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 4.8701e-05 - val_loss: 0.0028\n",
      "Epoch 1722/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.9475e-05 - val_loss: 0.0028\n",
      "Epoch 1723/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.5515e-05 - val_loss: 0.0029\n",
      "Epoch 1724/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 4.4329e-05 - val_loss: 0.0030\n",
      "Epoch 1725/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.4218e-05 - val_loss: 0.0030\n",
      "Epoch 1726/2000\n",
      "3490/3490 [==============================] - 1s 287us/step - loss: 5.2134e-05 - val_loss: 0.0029\n",
      "Epoch 1727/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 4.9707e-05 - val_loss: 0.0028\n",
      "Epoch 1728/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 4.8937e-05 - val_loss: 0.0029\n",
      "Epoch 1729/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 4.8538e-05 - val_loss: 0.0030\n",
      "Epoch 1730/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.6133e-05 - val_loss: 0.0029\n",
      "Epoch 1731/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 5.1087e-05 - val_loss: 0.0027\n",
      "Epoch 1732/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 5.8132e-05 - val_loss: 0.0030\n",
      "Epoch 1733/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 4.6494e-05 - val_loss: 0.0029\n",
      "Epoch 1734/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 4.8039e-05 - val_loss: 0.0028\n",
      "Epoch 1735/2000\n",
      "3490/3490 [==============================] - 1s 280us/step - loss: 4.8378e-05 - val_loss: 0.0029\n",
      "Epoch 1736/2000\n",
      "3490/3490 [==============================] - 1s 280us/step - loss: 4.8011e-05 - val_loss: 0.0029\n",
      "Epoch 1737/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.3723e-05 - val_loss: 0.0030\n",
      "Epoch 1738/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 5.7989e-05 - val_loss: 0.0030\n",
      "Epoch 1739/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 6.0158e-05 - val_loss: 0.0028\n",
      "Epoch 1740/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 6.7326e-05 - val_loss: 0.0029\n",
      "Epoch 1741/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 5.8118e-05 - val_loss: 0.0028\n",
      "Epoch 1742/2000\n",
      "3490/3490 [==============================] - 1s 287us/step - loss: 5.2785e-05 - val_loss: 0.0029\n",
      "Epoch 1743/2000\n",
      "3490/3490 [==============================] - 1s 287us/step - loss: 5.1399e-05 - val_loss: 0.0031\n",
      "Epoch 1744/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 5.1905e-05 - val_loss: 0.0029\n",
      "Epoch 1745/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.1091e-05 - val_loss: 0.0031\n",
      "Epoch 1746/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.2894e-05 - val_loss: 0.0029\n",
      "Epoch 1747/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 5.0962e-05 - val_loss: 0.0031\n",
      "Epoch 1748/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.5244e-05 - val_loss: 0.0029\n",
      "Epoch 1749/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 5.8414e-05 - val_loss: 0.0030\n",
      "Epoch 1750/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 5.3113e-05 - val_loss: 0.0031\n",
      "Epoch 1751/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.7971e-05 - val_loss: 0.0029\n",
      "Epoch 1752/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.9995e-05 - val_loss: 0.0028\n",
      "Epoch 1753/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.7315e-05 - val_loss: 0.0026\n",
      "Epoch 1754/2000\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 6.8285e-05 - val_loss: 0.0028\n",
      "Epoch 1755/2000\n",
      "3490/3490 [==============================] - 1s 289us/step - loss: 6.9701e-05 - val_loss: 0.0028\n",
      "Epoch 1756/2000\n",
      "3490/3490 [==============================] - 1s 295us/step - loss: 5.8484e-05 - val_loss: 0.0029\n",
      "Epoch 1757/2000\n",
      "3490/3490 [==============================] - 1s 293us/step - loss: 6.0315e-05 - val_loss: 0.0029\n",
      "Epoch 1758/2000\n",
      "3490/3490 [==============================] - 1s 289us/step - loss: 6.9354e-05 - val_loss: 0.0027\n",
      "Epoch 1759/2000\n",
      "3490/3490 [==============================] - 1s 289us/step - loss: 7.6235e-05 - val_loss: 0.0029\n",
      "Epoch 1760/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 6.8865e-05 - val_loss: 0.0027\n",
      "Epoch 1761/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 7.2958e-05 - val_loss: 0.0025\n",
      "Epoch 1762/2000\n",
      "3490/3490 [==============================] - 1s 296us/step - loss: 6.2551e-05 - val_loss: 0.0028\n",
      "Epoch 1763/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 5.2510e-05 - val_loss: 0.0028\n",
      "Epoch 1764/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 5.6224e-05 - val_loss: 0.0027\n",
      "Epoch 1765/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 5.3271e-05 - val_loss: 0.0028\n",
      "Epoch 1766/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 5.4640e-05 - val_loss: 0.0027\n",
      "Epoch 1767/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 5.6457e-05 - val_loss: 0.0028\n",
      "Epoch 1768/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.7920e-05 - val_loss: 0.0027\n",
      "Epoch 1769/2000\n",
      "3490/3490 [==============================] - 1s 287us/step - loss: 5.8130e-05 - val_loss: 0.0028\n",
      "Epoch 1770/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 6.0481e-05 - val_loss: 0.0027\n",
      "Epoch 1771/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 4.9074e-05 - val_loss: 0.0027\n",
      "Epoch 1772/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.7498e-05 - val_loss: 0.0028\n",
      "Epoch 1773/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.8768e-05 - val_loss: 0.0030\n",
      "Epoch 1774/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.7488e-05 - val_loss: 0.0030\n",
      "Epoch 1775/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.8889e-05 - val_loss: 0.0028\n",
      "Epoch 1776/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 5.0191e-05 - val_loss: 0.0029\n",
      "Epoch 1777/2000\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 4.7547e-05 - val_loss: 0.0029\n",
      "Epoch 1778/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 4.3596e-05 - val_loss: 0.0028\n",
      "Epoch 1779/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.8871e-05 - val_loss: 0.0027\n",
      "Epoch 1780/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.3451e-05 - val_loss: 0.0028\n",
      "Epoch 1781/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.5416e-05 - val_loss: 0.0027\n",
      "Epoch 1782/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 4.2357e-05 - val_loss: 0.0029\n",
      "Epoch 1783/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.3576e-05 - val_loss: 0.0029\n",
      "Epoch 1784/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 4.7882e-05 - val_loss: 0.0030\n",
      "Epoch 1785/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 4.5417e-05 - val_loss: 0.0029\n",
      "Epoch 1786/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 4.5054e-05 - val_loss: 0.0029\n",
      "Epoch 1787/2000\n",
      "3490/3490 [==============================] - 1s 287us/step - loss: 4.5533e-05 - val_loss: 0.0030\n",
      "Epoch 1788/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 4.8928e-05 - val_loss: 0.0030\n",
      "Epoch 1789/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 5.0991e-05 - val_loss: 0.0030\n",
      "Epoch 1790/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.6289e-05 - val_loss: 0.0030\n",
      "Epoch 1791/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.3913e-05 - val_loss: 0.0028\n",
      "Epoch 1792/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 5.4430e-05 - val_loss: 0.0028\n",
      "Epoch 1793/2000\n",
      "3490/3490 [==============================] - 1s 288us/step - loss: 6.8991e-05 - val_loss: 0.0027\n",
      "Epoch 1794/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 6.7933e-05 - val_loss: 0.0029\n",
      "Epoch 1795/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 6.6211e-05 - val_loss: 0.0027\n",
      "Epoch 1796/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 4.9917e-05 - val_loss: 0.0027\n",
      "Epoch 1797/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 4.7945e-05 - val_loss: 0.0028\n",
      "Epoch 1798/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.4074e-05 - val_loss: 0.0028\n",
      "Epoch 1799/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.8530e-05 - val_loss: 0.0028\n",
      "Epoch 1800/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.6578e-05 - val_loss: 0.0029\n",
      "Epoch 1801/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.2988e-05 - val_loss: 0.0028\n",
      "Epoch 1802/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 4.6865e-05 - val_loss: 0.0028\n",
      "Epoch 1803/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.1088e-05 - val_loss: 0.0027\n",
      "Epoch 1804/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 5.1654e-05 - val_loss: 0.0029\n",
      "Epoch 1805/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 5.2991e-05 - val_loss: 0.0028\n",
      "Epoch 1806/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 4.6925e-05 - val_loss: 0.0030\n",
      "Epoch 1807/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 5.7595e-05 - val_loss: 0.0029\n",
      "Epoch 1808/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 5.3796e-05 - val_loss: 0.0030\n",
      "Epoch 1809/2000\n",
      "3490/3490 [==============================] - 1s 288us/step - loss: 4.9444e-05 - val_loss: 0.0030\n",
      "Epoch 1810/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.3568e-05 - val_loss: 0.0031\n",
      "Epoch 1811/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 5.0641e-05 - val_loss: 0.0028\n",
      "Epoch 1812/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 5.0600e-05 - val_loss: 0.0028\n",
      "Epoch 1813/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 4.3260e-05 - val_loss: 0.0031\n",
      "Epoch 1814/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.8843e-05 - val_loss: 0.0028\n",
      "Epoch 1815/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 5.5490e-05 - val_loss: 0.0032\n",
      "Epoch 1816/2000\n",
      "3490/3490 [==============================] - ETA: 0s - loss: 6.6039e-0 - 1s 283us/step - loss: 6.4016e-05 - val_loss: 0.0028\n",
      "Epoch 1817/2000\n",
      "3490/3490 [==============================] - 1s 288us/step - loss: 5.6308e-05 - val_loss: 0.0028\n",
      "Epoch 1818/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.7839e-05 - val_loss: 0.0028\n",
      "Epoch 1819/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.4985e-05 - val_loss: 0.0028\n",
      "Epoch 1820/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 5.3145e-05 - val_loss: 0.0029\n",
      "Epoch 1821/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 5.9728e-05 - val_loss: 0.0029\n",
      "Epoch 1822/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.4037e-05 - val_loss: 0.0028\n",
      "Epoch 1823/2000\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 5.0930e-05 - val_loss: 0.0029\n",
      "Epoch 1824/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.8511e-05 - val_loss: 0.0027\n",
      "Epoch 1825/2000\n",
      "3490/3490 [==============================] - 1s 288us/step - loss: 6.4390e-05 - val_loss: 0.0030\n",
      "Epoch 1826/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 7.3958e-05 - val_loss: 0.0028\n",
      "Epoch 1827/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 5.5200e-05 - val_loss: 0.0029\n",
      "Epoch 1828/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 4.4269e-05 - val_loss: 0.0028\n",
      "Epoch 1829/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 4.3417e-05 - val_loss: 0.0029\n",
      "Epoch 1830/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 4.7627e-05 - val_loss: 0.0028\n",
      "Epoch 1831/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 5.3842e-05 - val_loss: 0.0030\n",
      "Epoch 1832/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 4.9053e-05 - val_loss: 0.0030\n",
      "Epoch 1833/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.5687e-05 - val_loss: 0.0030\n",
      "Epoch 1834/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 4.2508e-05 - val_loss: 0.0029\n",
      "Epoch 1835/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 4.0487e-05 - val_loss: 0.0030\n",
      "Epoch 1836/2000\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 4.2769e-05 - val_loss: 0.0030\n",
      "Epoch 1837/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 4.2734e-05 - val_loss: 0.0028\n",
      "Epoch 1838/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.3922e-05 - val_loss: 0.0028\n",
      "Epoch 1839/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 4.8502e-05 - val_loss: 0.0029\n",
      "Epoch 1840/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 4.9652e-05 - val_loss: 0.0030\n",
      "Epoch 1841/2000\n",
      "3490/3490 [==============================] - 1s 288us/step - loss: 4.3232e-05 - val_loss: 0.0030\n",
      "Epoch 1842/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.1723e-05 - val_loss: 0.0032\n",
      "Epoch 1843/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.2181e-05 - val_loss: 0.0028\n",
      "Epoch 1844/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 5.0300e-05 - val_loss: 0.0032\n",
      "Epoch 1845/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 5.2488e-05 - val_loss: 0.0029\n",
      "Epoch 1846/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 4.2056e-05 - val_loss: 0.0030\n",
      "Epoch 1847/2000\n",
      "3490/3490 [==============================] - 1s 287us/step - loss: 4.3611e-05 - val_loss: 0.0028\n",
      "Epoch 1848/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 4.5479e-05 - val_loss: 0.0028\n",
      "Epoch 1849/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 4.5291e-05 - val_loss: 0.0028\n",
      "Epoch 1850/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 4.7191e-05 - val_loss: 0.0029\n",
      "Epoch 1851/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 4.6217e-05 - val_loss: 0.0028\n",
      "Epoch 1852/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 5.8288e-05 - val_loss: 0.0029\n",
      "Epoch 1853/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 5.3092e-05 - val_loss: 0.0029\n",
      "Epoch 1854/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 6.6659e-05 - val_loss: 0.0029\n",
      "Epoch 1855/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3490/3490 [==============================] - 1s 281us/step - loss: 6.4327e-05 - val_loss: 0.0032\n",
      "Epoch 1856/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 7.3427e-05 - val_loss: 0.0029\n",
      "Epoch 1857/2000\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 9.8590e-05 - val_loss: 0.0032\n",
      "Epoch 1858/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 1.0244e-04 - val_loss: 0.0031\n",
      "Epoch 1859/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 9.4976e-05 - val_loss: 0.0027\n",
      "Epoch 1860/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 6.7141e-05 - val_loss: 0.0028\n",
      "Epoch 1861/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 6.2290e-05 - val_loss: 0.0030\n",
      "Epoch 1862/2000\n",
      "3490/3490 [==============================] - ETA: 0s - loss: 7.4075e-0 - 1s 283us/step - loss: 7.6301e-05 - val_loss: 0.0031\n",
      "Epoch 1863/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 9.3234e-05 - val_loss: 0.0028\n",
      "Epoch 1864/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 7.6768e-05 - val_loss: 0.0029\n",
      "Epoch 1865/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.9830e-05 - val_loss: 0.0025\n",
      "Epoch 1866/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 6.4656e-05 - val_loss: 0.0027\n",
      "Epoch 1867/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 7.3177e-05 - val_loss: 0.0028\n",
      "Epoch 1868/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 8.9846e-05 - val_loss: 0.0034\n",
      "Epoch 1869/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 7.7341e-05 - val_loss: 0.0028\n",
      "Epoch 1870/2000\n",
      "3490/3490 [==============================] - ETA: 0s - loss: 6.2138e-0 - 1s 283us/step - loss: 6.4203e-05 - val_loss: 0.0028\n",
      "Epoch 1871/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 5.3640e-05 - val_loss: 0.0026\n",
      "Epoch 1872/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 5.0214e-05 - val_loss: 0.0028\n",
      "Epoch 1873/2000\n",
      "3490/3490 [==============================] - 1s 289us/step - loss: 4.4925e-05 - val_loss: 0.0027\n",
      "Epoch 1874/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 4.6491e-05 - val_loss: 0.0029\n",
      "Epoch 1875/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 4.7753e-05 - val_loss: 0.0027\n",
      "Epoch 1876/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 4.0055e-05 - val_loss: 0.0026\n",
      "Epoch 1877/2000\n",
      "3490/3490 [==============================] - 1s 289us/step - loss: 4.0835e-05 - val_loss: 0.0028\n",
      "Epoch 1878/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 3.7797e-05 - val_loss: 0.0027\n",
      "Epoch 1879/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.1258e-05 - val_loss: 0.0029\n",
      "Epoch 1880/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 4.4906e-05 - val_loss: 0.0026\n",
      "Epoch 1881/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 4.7162e-05 - val_loss: 0.0027\n",
      "Epoch 1882/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 4.4346e-05 - val_loss: 0.0029\n",
      "Epoch 1883/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.4388e-05 - val_loss: 0.0029\n",
      "Epoch 1884/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 4.4925e-05 - val_loss: 0.0026\n",
      "Epoch 1885/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.6182e-05 - val_loss: 0.0027\n",
      "Epoch 1886/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 4.1387e-05 - val_loss: 0.0026\n",
      "Epoch 1887/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 4.6483e-05 - val_loss: 0.0028\n",
      "Epoch 1888/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 4.5180e-05 - val_loss: 0.0028\n",
      "Epoch 1889/2000\n",
      "3490/3490 [==============================] - 1s 288us/step - loss: 4.2562e-05 - val_loss: 0.0028\n",
      "Epoch 1890/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.0444e-05 - val_loss: 0.0028\n",
      "Epoch 1891/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 4.1578e-05 - val_loss: 0.0028\n",
      "Epoch 1892/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 4.2708e-05 - val_loss: 0.0029\n",
      "Epoch 1893/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.5087e-05 - val_loss: 0.0029\n",
      "Epoch 1894/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.7836e-05 - val_loss: 0.0027\n",
      "Epoch 1895/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.0099e-05 - val_loss: 0.0030\n",
      "Epoch 1896/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 4.5600e-05 - val_loss: 0.0028\n",
      "Epoch 1897/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 4.7280e-05 - val_loss: 0.0029\n",
      "Epoch 1898/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.0998e-05 - val_loss: 0.0028\n",
      "Epoch 1899/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 4.8245e-05 - val_loss: 0.0029\n",
      "Epoch 1900/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.4284e-05 - val_loss: 0.0028\n",
      "Epoch 1901/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 4.5797e-05 - val_loss: 0.0029\n",
      "Epoch 1902/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.1905e-05 - val_loss: 0.0028\n",
      "Epoch 1903/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 4.0888e-05 - val_loss: 0.0029\n",
      "Epoch 1904/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 4.0067e-05 - val_loss: 0.0028\n",
      "Epoch 1905/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 3.8804e-05 - val_loss: 0.0029\n",
      "Epoch 1906/2000\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 4.8630e-05 - val_loss: 0.0027\n",
      "Epoch 1907/2000\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 4.5204e-05 - val_loss: 0.0029\n",
      "Epoch 1908/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 4.8449e-05 - val_loss: 0.0027\n",
      "Epoch 1909/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.3756e-05 - val_loss: 0.0029\n",
      "Epoch 1910/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 4.2962e-05 - val_loss: 0.0031\n",
      "Epoch 1911/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 4.5218e-05 - val_loss: 0.0030\n",
      "Epoch 1912/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.3600e-05 - val_loss: 0.0031\n",
      "Epoch 1913/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.2286e-05 - val_loss: 0.0030\n",
      "Epoch 1914/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.0812e-05 - val_loss: 0.0029\n",
      "Epoch 1915/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 5.4152e-05 - val_loss: 0.0030\n",
      "Epoch 1916/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 5.6685e-05 - val_loss: 0.0028\n",
      "Epoch 1917/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.4361e-05 - val_loss: 0.0031\n",
      "Epoch 1918/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 5.5403e-05 - val_loss: 0.0029\n",
      "Epoch 1919/2000\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 4.7136e-05 - val_loss: 0.0029\n",
      "Epoch 1920/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.9822e-05 - val_loss: 0.0031\n",
      "Epoch 1921/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 4.3380e-05 - val_loss: 0.0029\n",
      "Epoch 1922/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 4.2024e-05 - val_loss: 0.0030\n",
      "Epoch 1923/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 4.4110e-05 - val_loss: 0.0030\n",
      "Epoch 1924/2000\n",
      "3490/3490 [==============================] - 1s 288us/step - loss: 5.3237e-05 - val_loss: 0.0029\n",
      "Epoch 1925/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.0780e-05 - val_loss: 0.0030\n",
      "Epoch 1926/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.9780e-05 - val_loss: 0.0028\n",
      "Epoch 1927/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.2431e-05 - val_loss: 0.0027\n",
      "Epoch 1928/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.8854e-05 - val_loss: 0.0029\n",
      "Epoch 1929/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.8542e-05 - val_loss: 0.0030\n",
      "Epoch 1930/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.2663e-05 - val_loss: 0.0030\n",
      "Epoch 1931/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.4293e-05 - val_loss: 0.0029\n",
      "Epoch 1932/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.5613e-05 - val_loss: 0.0030\n",
      "Epoch 1933/2000\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 5.0722e-05 - val_loss: 0.0029\n",
      "Epoch 1934/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 4.6890e-05 - val_loss: 0.0028\n",
      "Epoch 1935/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 4.4086e-05 - val_loss: 0.0030\n",
      "Epoch 1936/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.3854e-05 - val_loss: 0.0029\n",
      "Epoch 1937/2000\n",
      "3490/3490 [==============================] - 1s 288us/step - loss: 4.5104e-05 - val_loss: 0.0030\n",
      "Epoch 1938/2000\n",
      "3490/3490 [==============================] - 1s 298us/step - loss: 4.1646e-05 - val_loss: 0.0029\n",
      "Epoch 1939/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.9275e-05 - val_loss: 0.0029\n",
      "Epoch 1940/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.7533e-05 - val_loss: 0.0030\n",
      "Epoch 1941/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.9415e-05 - val_loss: 0.0029\n",
      "Epoch 1942/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 4.3585e-05 - val_loss: 0.0031\n",
      "Epoch 1943/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 5.0993e-05 - val_loss: 0.0030\n",
      "Epoch 1944/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 4.4550e-05 - val_loss: 0.0029\n",
      "Epoch 1945/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 4.3913e-05 - val_loss: 0.0030\n",
      "Epoch 1946/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.8104e-05 - val_loss: 0.0029\n",
      "Epoch 1947/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.8158e-05 - val_loss: 0.0029\n",
      "Epoch 1948/2000\n",
      "3490/3490 [==============================] - 1s 287us/step - loss: 4.3382e-05 - val_loss: 0.0031\n",
      "Epoch 1949/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.4118e-05 - val_loss: 0.0027\n",
      "Epoch 1950/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 7.1243e-05 - val_loss: 0.0030\n",
      "Epoch 1951/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 6.3361e-05 - val_loss: 0.0030\n",
      "Epoch 1952/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.4875e-05 - val_loss: 0.0029\n",
      "Epoch 1953/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 6.3972e-05 - val_loss: 0.0028\n",
      "Epoch 1954/2000\n",
      "3490/3490 [==============================] - 1s 289us/step - loss: 6.1039e-05 - val_loss: 0.0031\n",
      "Epoch 1955/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 5.6020e-05 - val_loss: 0.0026\n",
      "Epoch 1956/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 4.4177e-05 - val_loss: 0.0027\n",
      "Epoch 1957/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.7794e-05 - val_loss: 0.0027\n",
      "Epoch 1958/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.0524e-05 - val_loss: 0.0028\n",
      "Epoch 1959/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.0130e-05 - val_loss: 0.0030\n",
      "Epoch 1960/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.0327e-05 - val_loss: 0.0028\n",
      "Epoch 1961/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 4.3782e-05 - val_loss: 0.0031\n",
      "Epoch 1962/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.8652e-05 - val_loss: 0.0030\n",
      "Epoch 1963/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 4.5387e-05 - val_loss: 0.0029\n",
      "Epoch 1964/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 5.9316e-05 - val_loss: 0.0030\n",
      "Epoch 1965/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 5.2916e-05 - val_loss: 0.0028\n",
      "Epoch 1966/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 4.6969e-05 - val_loss: 0.0028\n",
      "Epoch 1967/2000\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 4.4233e-05 - val_loss: 0.0029\n",
      "Epoch 1968/2000\n",
      "3490/3490 [==============================] - 1s 287us/step - loss: 4.4361e-05 - val_loss: 0.0031\n",
      "Epoch 1969/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 5.3662e-05 - val_loss: 0.0028\n",
      "Epoch 1970/2000\n",
      "3490/3490 [==============================] - 1s 288us/step - loss: 6.4675e-05 - val_loss: 0.0032\n",
      "Epoch 1971/2000\n",
      "3490/3490 [==============================] - 1s 285us/step - loss: 5.0496e-05 - val_loss: 0.0029\n",
      "Epoch 1972/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.4966e-05 - val_loss: 0.0027\n",
      "Epoch 1973/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 4.4071e-05 - val_loss: 0.0028\n",
      "Epoch 1974/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 5.1937e-05 - val_loss: 0.0030\n",
      "Epoch 1975/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 4.7579e-05 - val_loss: 0.0031\n",
      "Epoch 1976/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.8013e-05 - val_loss: 0.0030\n",
      "Epoch 1977/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 4.2385e-05 - val_loss: 0.0028\n",
      "Epoch 1978/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 4.5851e-05 - val_loss: 0.0030\n",
      "Epoch 1979/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.5655e-05 - val_loss: 0.0030\n",
      "Epoch 1980/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 4.7980e-05 - val_loss: 0.0030\n",
      "Epoch 1981/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 4.2999e-05 - val_loss: 0.0030\n",
      "Epoch 1982/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 4.0179e-05 - val_loss: 0.0032\n",
      "Epoch 1983/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 4.3971e-05 - val_loss: 0.0031\n",
      "Epoch 1984/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.5637e-05 - val_loss: 0.0031\n",
      "Epoch 1985/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.3805e-05 - val_loss: 0.0031\n",
      "Epoch 1986/2000\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 3.5409e-05 - val_loss: 0.0031\n",
      "Epoch 1987/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 4.0101e-05 - val_loss: 0.0033\n",
      "Epoch 1988/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.7419e-05 - val_loss: 0.0031\n",
      "Epoch 1989/2000\n",
      "3490/3490 [==============================] - 1s 286us/step - loss: 3.8191e-05 - val_loss: 0.0029\n",
      "Epoch 1990/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 4.2459e-05 - val_loss: 0.0030\n",
      "Epoch 1991/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.7150e-05 - val_loss: 0.0030\n",
      "Epoch 1992/2000\n",
      "3490/3490 [==============================] - 1s 281us/step - loss: 3.3430e-05 - val_loss: 0.0030\n",
      "Epoch 1993/2000\n",
      "3490/3490 [==============================] - ETA: 0s - loss: 3.2772e-0 - 1s 283us/step - loss: 3.2743e-05 - val_loss: 0.0030\n",
      "Epoch 1994/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.2875e-05 - val_loss: 0.0030\n",
      "Epoch 1995/2000\n",
      "3490/3490 [==============================] - 1s 282us/step - loss: 3.5521e-05 - val_loss: 0.0031\n",
      "Epoch 1996/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.5726e-05 - val_loss: 0.0031\n",
      "Epoch 1997/2000\n",
      "3490/3490 [==============================] - 1s 283us/step - loss: 3.4922e-05 - val_loss: 0.0031\n",
      "Epoch 1998/2000\n",
      "3490/3490 [==============================] - 1s 290us/step - loss: 3.8021e-05 - val_loss: 0.0030\n",
      "Epoch 1999/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.4265e-05 - val_loss: 0.0031\n",
      "Epoch 2000/2000\n",
      "3490/3490 [==============================] - 1s 284us/step - loss: 3.8413e-05 - val_loss: 0.0033\n"
     ]
    }
   ],
   "source": [
    "final_model = build_lstm(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'density': 166,\n",
       " 'activation': 'relu',\n",
       " 'twice': False,\n",
       " 'optimizer': 'adam',\n",
       " 'shuffle': True,\n",
       " 'lstmsize': 180,\n",
       " 'full_density': True,\n",
       " 'callbacks': [<keras.callbacks.callbacks.ModelCheckpoint at 0x25ef3775f88>]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_182\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_315 (LSTM)              (None, 180)               133920    \n",
      "_________________________________________________________________\n",
      "dense_880 (Dense)            (None, 166)               30046     \n",
      "_________________________________________________________________\n",
      "dense_881 (Dense)            (None, 83)                13861     \n",
      "_________________________________________________________________\n",
      "dense_882 (Dense)            (None, 41)                3444      \n",
      "_________________________________________________________________\n",
      "dense_883 (Dense)            (None, 20)                840       \n",
      "_________________________________________________________________\n",
      "dense_884 (Dense)            (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 182,132\n",
      "Trainable params: 182,132\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model[0].load_weights('./checkpoints/IBM_4days/IBM.(best).hdf5')\n",
    "y_predicted = final_model[0].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y_test = y_normaliser.inverse_transform(y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE is 16.93\n",
      "Medium error is 2.87\n"
     ]
    }
   ],
   "source": [
    "loss = np.mean((unscaled_y_test - predicted_y_test)**2)\n",
    "medium_error = np.mean(abs(unscaled_y_test - predicted_y_test))\n",
    "print(f'MSE is {loss:.2f}\\nMedium error is {medium_error:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_down_test = []\n",
    "up_down_predicted = []\n",
    "\n",
    "for y,x in zip(Y_test,X_test):\n",
    "    if y[0] > x[-1][0]: up_down_test.append(1)\n",
    "    elif y[0] < x[-1][0]: up_down_test.append(-1)\n",
    "    else: up_down_test.append(0)\n",
    "        \n",
    "for y,x in zip(y_predicted,X_test):\n",
    "    if y[0] > x[-1][0]: up_down_predicted.append(1)\n",
    "    elif y[0] < x[-1][0]: up_down_predicted.append(-1)\n",
    "    else: up_down_predicted.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trend accuracy is: 58.66%\n"
     ]
    }
   ],
   "source": [
    "print(f'Trend accuracy is: {(sum(1 for r,p in zip(up_down_test,up_down_predicted) if r == p)/len(up_down_test))*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for upward trend is: 50.00%\n",
      "Accuracy for downward trend is: 68.60%\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy for upward trend is: {(sum(1 for r,p in zip(up_down_test,up_down_predicted) if r == 1 and p == 1)/sum(1 for v in up_down_test if v == 1))*100:.2f}%')\n",
    "print(f'Accuracy for downward trend is: {(sum(1 for r,p in zip(up_down_test,up_down_predicted) if r == -1 and p == -1)/sum(1 for v in up_down_test if v == -1))*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predictions over the last 92 days in test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 3200x2400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "figure(num=None, figsize=(40, 30), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "plt.plot(range(92), unscaled_y_test[-92:])\n",
    "plt.plot(range(92), predicted_y_test[-92:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Last 4 days + prediction of next 4 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 3200x2400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure(num=None, figsize=(40, 30), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "plt.plot(range(8), unscaled_y_test[-8:])\n",
    "plt.plot(range(8), np.append(unscaled_y_test[-8:-4], predicted_y_test[-4:]))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
