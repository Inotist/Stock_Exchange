{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from joblib import load\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./datasets/IBM_daily.csv').sort_values(by='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>1. open</th>\n",
       "      <th>2. high</th>\n",
       "      <th>3. low</th>\n",
       "      <th>4. close</th>\n",
       "      <th>5. volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5217</th>\n",
       "      <td>1999-11-01</td>\n",
       "      <td>98.50</td>\n",
       "      <td>98.8100</td>\n",
       "      <td>96.37</td>\n",
       "      <td>96.75</td>\n",
       "      <td>9551800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5216</th>\n",
       "      <td>1999-11-02</td>\n",
       "      <td>96.75</td>\n",
       "      <td>96.8100</td>\n",
       "      <td>93.69</td>\n",
       "      <td>94.81</td>\n",
       "      <td>11105400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5215</th>\n",
       "      <td>1999-11-03</td>\n",
       "      <td>95.87</td>\n",
       "      <td>95.9400</td>\n",
       "      <td>93.50</td>\n",
       "      <td>94.37</td>\n",
       "      <td>10369100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5214</th>\n",
       "      <td>1999-11-04</td>\n",
       "      <td>94.44</td>\n",
       "      <td>94.4400</td>\n",
       "      <td>90.00</td>\n",
       "      <td>91.56</td>\n",
       "      <td>16697600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5213</th>\n",
       "      <td>1999-11-05</td>\n",
       "      <td>92.75</td>\n",
       "      <td>92.9400</td>\n",
       "      <td>90.19</td>\n",
       "      <td>90.25</td>\n",
       "      <td>13737600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-07-22</td>\n",
       "      <td>125.90</td>\n",
       "      <td>129.4700</td>\n",
       "      <td>125.80</td>\n",
       "      <td>128.67</td>\n",
       "      <td>8195366.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-07-23</td>\n",
       "      <td>129.10</td>\n",
       "      <td>129.3700</td>\n",
       "      <td>127.15</td>\n",
       "      <td>127.33</td>\n",
       "      <td>4220136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-07-24</td>\n",
       "      <td>126.48</td>\n",
       "      <td>127.6459</td>\n",
       "      <td>125.50</td>\n",
       "      <td>125.79</td>\n",
       "      <td>3531076.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-07-27</td>\n",
       "      <td>124.86</td>\n",
       "      <td>126.3200</td>\n",
       "      <td>124.71</td>\n",
       "      <td>126.21</td>\n",
       "      <td>3733547.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-28</td>\n",
       "      <td>125.82</td>\n",
       "      <td>126.3400</td>\n",
       "      <td>124.15</td>\n",
       "      <td>124.47</td>\n",
       "      <td>4157538.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5218 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  1. open   2. high  3. low  4. close   5. volume\n",
       "5217  1999-11-01    98.50   98.8100   96.37     96.75   9551800.0\n",
       "5216  1999-11-02    96.75   96.8100   93.69     94.81  11105400.0\n",
       "5215  1999-11-03    95.87   95.9400   93.50     94.37  10369100.0\n",
       "5214  1999-11-04    94.44   94.4400   90.00     91.56  16697600.0\n",
       "5213  1999-11-05    92.75   92.9400   90.19     90.25  13737600.0\n",
       "...          ...      ...       ...     ...       ...         ...\n",
       "4     2020-07-22   125.90  129.4700  125.80    128.67   8195366.0\n",
       "3     2020-07-23   129.10  129.3700  127.15    127.33   4220136.0\n",
       "2     2020-07-24   126.48  127.6459  125.50    125.79   3531076.0\n",
       "1     2020-07-27   124.86  126.3200  124.71    126.21   3733547.0\n",
       "0     2020-07-28   125.82  126.3400  124.15    124.47   4157538.0\n",
       "\n",
       "[5218 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1. open</th>\n",
       "      <th>2. high</th>\n",
       "      <th>3. low</th>\n",
       "      <th>4. close</th>\n",
       "      <th>5. volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5217</th>\n",
       "      <td>98.50</td>\n",
       "      <td>98.8100</td>\n",
       "      <td>96.37</td>\n",
       "      <td>96.75</td>\n",
       "      <td>9551800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5216</th>\n",
       "      <td>96.75</td>\n",
       "      <td>96.8100</td>\n",
       "      <td>93.69</td>\n",
       "      <td>94.81</td>\n",
       "      <td>11105400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5215</th>\n",
       "      <td>95.87</td>\n",
       "      <td>95.9400</td>\n",
       "      <td>93.50</td>\n",
       "      <td>94.37</td>\n",
       "      <td>10369100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5214</th>\n",
       "      <td>94.44</td>\n",
       "      <td>94.4400</td>\n",
       "      <td>90.00</td>\n",
       "      <td>91.56</td>\n",
       "      <td>16697600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5213</th>\n",
       "      <td>92.75</td>\n",
       "      <td>92.9400</td>\n",
       "      <td>90.19</td>\n",
       "      <td>90.25</td>\n",
       "      <td>13737600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>125.90</td>\n",
       "      <td>129.4700</td>\n",
       "      <td>125.80</td>\n",
       "      <td>128.67</td>\n",
       "      <td>8195366.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>129.10</td>\n",
       "      <td>129.3700</td>\n",
       "      <td>127.15</td>\n",
       "      <td>127.33</td>\n",
       "      <td>4220136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>126.48</td>\n",
       "      <td>127.6459</td>\n",
       "      <td>125.50</td>\n",
       "      <td>125.79</td>\n",
       "      <td>3531076.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>124.86</td>\n",
       "      <td>126.3200</td>\n",
       "      <td>124.71</td>\n",
       "      <td>126.21</td>\n",
       "      <td>3733547.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>125.82</td>\n",
       "      <td>126.3400</td>\n",
       "      <td>124.15</td>\n",
       "      <td>124.47</td>\n",
       "      <td>4157538.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5218 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      1. open   2. high  3. low  4. close   5. volume\n",
       "5217    98.50   98.8100   96.37     96.75   9551800.0\n",
       "5216    96.75   96.8100   93.69     94.81  11105400.0\n",
       "5215    95.87   95.9400   93.50     94.37  10369100.0\n",
       "5214    94.44   94.4400   90.00     91.56  16697600.0\n",
       "5213    92.75   92.9400   90.19     90.25  13737600.0\n",
       "...       ...       ...     ...       ...         ...\n",
       "4      125.90  129.4700  125.80    128.67   8195366.0\n",
       "3      129.10  129.3700  127.15    127.33   4220136.0\n",
       "2      126.48  127.6459  125.50    125.79   3531076.0\n",
       "1      124.86  126.3200  124.71    126.21   3733547.0\n",
       "0      125.82  126.3400  124.15    124.47   4157538.0\n",
       "\n",
       "[5218 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(columns='date')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequence for the LSTM network\n",
    "backlook = 92\n",
    "\n",
    "# Days to predict\n",
    "days = 4\n",
    "\n",
    "# Size of data split for testing\n",
    "train_size = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test split\n",
    "split = int(len(data) * train_size)\n",
    "\n",
    "train = data.to_numpy()[:split]\n",
    "test = data.to_numpy()[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load normalisers\n",
    "normaliser = load('./normalisers/x_normaliser.joblib')\n",
    "y_normaliser = load('./normalisers/y_normaliser.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise data\n",
    "train_norm = normaliser.transform(train)\n",
    "test_norm = normaliser.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now I get indexes for chunks from 4 in 4 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = []\n",
    "\n",
    "for i in range(days):\n",
    "    index.append(np.arange(i,len(train),days))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_index = []\n",
    "\n",
    "for i in range(len(index[0]) - backlook):\n",
    "    for e in range(days):\n",
    "        try: ordered_index.append(index[e][i:i+backlook])\n",
    "        except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalised train chunks\n",
    "X_train = np.array([train_norm[ix].copy() for ix in ordered_index])\n",
    "Y_train = np.array([train_norm[ordered_index[i+days][-1],0].copy() for i in range(len(ordered_index) - days)])\n",
    "Y_train = np.expand_dims(Y_train, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete those sequences that doesn't have a -th day in the results\n",
    "X_train = X_train[:Y_train.shape[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Same for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = []\n",
    "\n",
    "for i in range(days):\n",
    "    index.append(np.arange(i,len(test),days))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_index = []\n",
    "\n",
    "for i in range(len(index[0]) - backlook):\n",
    "    for e in range(days):\n",
    "        try: ordered_index.append(index[e][i:i+backlook])\n",
    "        except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalised train chunks\n",
    "X_test = np.array([test_norm[ix].copy() for ix in ordered_index])\n",
    "Y_test = np.array([test_norm[ordered_index[i+days][-1],0].copy() for i in range(len(ordered_index) - days)])\n",
    "Y_test = np.expand_dims(Y_test, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete those sequences that doesn't have a -th day in the results\n",
    "X_test = X_test[:Y_test.shape[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm(x, y, batch_size=512, epochs=24, **params):\n",
    "    \n",
    "    # List of parameters\n",
    "    if 'lstmsize' not in params: params['lstmsize'] = x.shape[1]\n",
    "    if 'density' not in params: params['density'] = int((params['lstmsize']//1.5)*2)\n",
    "    if 'activation' not in params: params['activation'] = 'relu'\n",
    "    if 'twice' not in params: params['twice'] = False\n",
    "    if 'optimizer' not in params: params['optimizer'] = 'adam'\n",
    "    if 'shuffle' not in params: params['shuffle'] = False\n",
    "    \n",
    "    # Model definition\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(params['lstmsize'], input_shape=x.shape[1:], return_sequences=params['twice']))\n",
    "    \n",
    "    if 'dropout' in params:\n",
    "        model.add(Dropout(params['dropout']))\n",
    "    \n",
    "    if params['twice']:\n",
    "        model.add(LSTM(params['lstmsize']))\n",
    "        \n",
    "        if 'dropout' in params:\n",
    "            model.add(Dropout(params['dropout']))\n",
    "            \n",
    "    model.add(Dense(params['density'], activation=params['activation']))\n",
    "    \n",
    "    if 'full_density' in params and params['full_density']:\n",
    "        density = params['density']//2\n",
    "        while density >= 12:\n",
    "            model.add(Dense(density, activation=params['activation']))\n",
    "            density //= 2\n",
    "            \n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    \n",
    "    model.compile(loss='mse', optimizer=params['optimizer'])\n",
    "    \n",
    "    if 'callbacks' in params:\n",
    "        callback = model.fit(x=x, y=y, validation_split=0.1, batch_size=batch_size, epochs=epochs, shuffle=params['shuffle'],\n",
    "                            callbacks=params['callbacks'])\n",
    "    else:\n",
    "        callback = model.fit(x=x, y=y, validation_split=0.1, batch_size=batch_size, epochs=epochs, shuffle=params['shuffle'])\n",
    "    \n",
    "    return [model, callback, params]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evolutive algorith to search for the most optimal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_genes(x, y, population_size, population=[]):\n",
    "    if population_size-len(population) < 0:\n",
    "        print('population size must be greater or equal than actual population')\n",
    "        return\n",
    "    \n",
    "    if len(population) > 0:\n",
    "        if len(population) < 3:\n",
    "            print('population should be empty or 3 at least')\n",
    "            return\n",
    "        \n",
    "        population[2] = breed_genes(x, y, population[0][2].copy())\n",
    "        population[1] = breed_genes(x, y, combine=(population[0][2], population[1][2]))\n",
    "        population = population[:3]\n",
    "    \n",
    "    for _ in range(population_size-len(population)):\n",
    "        subject = breed_genes(x, y)\n",
    "        population.append(subject)\n",
    "        \n",
    "    return population\n",
    "\n",
    "def breed_genes(x, y, genes={}, combine=None):\n",
    "    genes['x'] = x\n",
    "    genes['y'] = y\n",
    "    \n",
    "    if type(combine) is list or type(combine) is tuple:\n",
    "        genes['lstmsize'] = combine[np.random.randint(0,2)]['lstmsize']\n",
    "        genes['density'] = combine[np.random.randint(0,2)]['density']\n",
    "        genes['activation'] = combine[np.random.randint(0,2)]['activation']\n",
    "        genes['twice'] = combine[np.random.randint(0,2)]['twice']\n",
    "        genes['optimizer'] = combine[np.random.randint(0,2)]['optimizer']\n",
    "        genes['shuffle'] = combine[np.random.randint(0,2)]['shuffle']\n",
    "        \n",
    "        genes['dropout'] = combine[np.random.randint(0,2)].get('dropout')\n",
    "        if genes['dropout'] is None: del genes['dropout']\n",
    "        genes['full_density'] = combine[np.random.randint(0,2)].get('full_density')\n",
    "        if genes['full_density'] is None: del genes['full_density']\n",
    "            \n",
    "    else:\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['lstmsize'] = int((np.random.randint(x.shape[1],x.shape[1]*2)//2)*2)\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['density'] = int((np.random.randint(x.shape[1]//2,x.shape[1]*2.66)//2)*2)\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            activation = [\n",
    "                'relu',\n",
    "                'sigmoid',\n",
    "                'softplus',\n",
    "                'softsign',\n",
    "                'tanh',\n",
    "                'selu',\n",
    "                'elu',\n",
    "                'exponential'\n",
    "            ]\n",
    "            genes['activation'] = activation[np.random.randint(0,8)]\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['twice'] = True\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            optimizer = [\n",
    "                'sgd',\n",
    "                'rmsprop',\n",
    "                'adam',\n",
    "                'adadelta',\n",
    "                'adagrad',\n",
    "                'adamax',\n",
    "                'nadam'\n",
    "            ]\n",
    "            genes['optimizer'] = optimizer[np.random.randint(0,7)]\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['shuffle'] = True\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['dropout'] = np.random.randint(1,4)/10\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['full_density'] = True\n",
    "            \n",
    "    new_model = build_lstm(**genes)\n",
    "        \n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def breed_population(x, y, generations, population_size, population=[]):\n",
    "    \n",
    "    if generations > 1 and population_size < 3:\n",
    "        print('population size should be of a minimum of 3 for more than one generation')\n",
    "        return\n",
    "    \n",
    "    for g in range(generations):\n",
    "        print(f'\\nGENERATION {g}\\n')\n",
    "        population = set_genes(x, y, population_size, population)\n",
    "        population = sorted(population, key=lambda x: x[1].history['val_loss'][-1]+x[1].history['loss'][-1])\n",
    "        \n",
    "    return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GENERATION 0\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 1s 340us/step - loss: 0.0181 - val_loss: 0.0023\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 216us/step - loss: 0.0136 - val_loss: 0.0228\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 213us/step - loss: 0.0203 - val_loss: 0.0234\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 213us/step - loss: 0.0479 - val_loss: 0.0047\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 215us/step - loss: 0.0180 - val_loss: 9.3090e-04\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 0.0207 - val_loss: 0.0067\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 212us/step - loss: 0.0038 - val_loss: 0.0049\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 214us/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 212us/step - loss: 0.0013 - val_loss: 8.5811e-04\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 0.0011 - val_loss: 7.8906e-04\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 8.6321e-04 - val_loss: 0.0010\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 8.1136e-04 - val_loss: 8.0400e-04\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 8.1229e-04 - val_loss: 8.5675e-04\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 215us/step - loss: 7.9229e-04 - val_loss: 8.4311e-04\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 8.0694e-04 - val_loss: 8.2016e-04\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 213us/step - loss: 7.8177e-04 - val_loss: 8.3706e-04\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 216us/step - loss: 7.9182e-04 - val_loss: 8.1268e-04\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 214us/step - loss: 7.7098e-04 - val_loss: 8.2080e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 214us/step - loss: 7.8018e-04 - val_loss: 8.0651e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 7.6010e-04 - val_loss: 8.0495e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 7.7250e-04 - val_loss: 7.9957e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 213us/step - loss: 7.4938e-04 - val_loss: 7.8872e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 216us/step - loss: 7.7037e-04 - val_loss: 7.9478e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 1s 317us/step - loss: 0.1582 - val_loss: 0.0608\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 215us/step - loss: 0.0150 - val_loss: 0.0208\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 215us/step - loss: 0.0083 - val_loss: 9.7801e-04\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 214us/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 221us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 213us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 214us/step - loss: 0.0012 - val_loss: 9.4858e-04\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 215us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 215us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 212us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 222us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 214us/step - loss: 9.9792e-04 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 9.9017e-04 - val_loss: 0.0013\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 221us/step - loss: 9.8258e-04 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 9.7508e-04 - val_loss: 0.0012\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 9.6819e-04 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 221us/step - loss: 9.6063e-04 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 9.5383e-04 - val_loss: 0.0012\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 216us/step - loss: 9.4686e-04 - val_loss: 0.0012\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 1s 367us/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 246us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 246us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 246us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 246us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 246us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 247us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 247us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 247us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 252us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 259us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 244us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 258us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 247us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 250us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 248us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 251us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 246us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 246us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 246us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 249us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 249us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 248us/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 255us/step - loss: nan - val_loss: nan\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 1s 318us/step - loss: 0.0774 - val_loss: 0.0274\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 167us/step - loss: 0.0108 - val_loss: 0.0128\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 172us/step - loss: 0.0060 - val_loss: 0.0033\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 163us/step - loss: 0.0054 - val_loss: 0.0023\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 154us/step - loss: 0.0038 - val_loss: 0.0023\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 161us/step - loss: 0.0034 - val_loss: 0.0010\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 155us/step - loss: 0.0031 - val_loss: 0.0020\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: 0.0031 - val_loss: 0.0019\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 153us/step - loss: 0.0030 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 159us/step - loss: 0.0029 - val_loss: 0.0018\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 160us/step - loss: 0.0030 - val_loss: 0.0016\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 149us/step - loss: 0.0029 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 149us/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 150us/step - loss: 0.0026 - val_loss: 0.0015\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 161us/step - loss: 0.0026 - val_loss: 0.0015\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 158us/step - loss: 0.0026 - val_loss: 0.0015\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 165us/step - loss: 0.0025 - val_loss: 0.0014\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 164us/step - loss: 0.0025 - val_loss: 0.0014\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 157us/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 161us/step - loss: 0.0024 - val_loss: 0.0013\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 154us/step - loss: 0.0024 - val_loss: 0.0014\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 167us/step - loss: 0.0024 - val_loss: 0.0014\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 155us/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 156us/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 2s 531us/step - loss: 0.0696 - val_loss: 0.0031\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 324us/step - loss: 0.0101 - val_loss: 0.0035\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 321us/step - loss: 0.0059 - val_loss: 0.0037\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 326us/step - loss: 0.0042 - val_loss: 0.0020\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 322us/step - loss: 0.0039 - val_loss: 0.0030\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 327us/step - loss: 0.0036 - val_loss: 0.0025\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 324us/step - loss: 0.0034 - val_loss: 0.0023\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 327us/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 324us/step - loss: 0.0033 - val_loss: 0.0024\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 324us/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 341us/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 332us/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 326us/step - loss: 0.0030 - val_loss: 0.0025\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 324us/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 329us/step - loss: 0.0029 - val_loss: 0.0024\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 323us/step - loss: 0.0030 - val_loss: 0.0022\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 328us/step - loss: 0.0029 - val_loss: 0.0024\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 327us/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 330us/step - loss: 0.0027 - val_loss: 0.0022\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 326us/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 324us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 325us/step - loss: 0.0028 - val_loss: 0.0021\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 321us/step - loss: 0.0027 - val_loss: 0.0019\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 328us/step - loss: 0.0027 - val_loss: 0.0021\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 2s 586us/step - loss: 0.1156 - val_loss: 0.0234\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 380us/step - loss: 0.0384 - val_loss: 0.0126\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 382us/step - loss: 0.0290 - val_loss: 0.0085\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 381us/step - loss: 0.0230 - val_loss: 0.0058\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 377us/step - loss: 0.0178 - val_loss: 0.0046\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 379us/step - loss: 0.0149 - val_loss: 0.0034\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 382us/step - loss: 0.0118 - val_loss: 0.0030\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 380us/step - loss: 0.0091 - val_loss: 0.0028\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 382us/step - loss: 0.0078 - val_loss: 0.0027\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 381us/step - loss: 0.0067 - val_loss: 0.0027\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 382us/step - loss: 0.0062 - val_loss: 0.0028\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 378us/step - loss: 0.0060 - val_loss: 0.0029\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 384us/step - loss: 0.0058 - val_loss: 0.0030\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 380us/step - loss: 0.0053 - val_loss: 0.0031\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 383us/step - loss: 0.0052 - val_loss: 0.0032\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 382us/step - loss: 0.0051 - val_loss: 0.0033\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 381us/step - loss: 0.0050 - val_loss: 0.0033\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 378us/step - loss: 0.0051 - val_loss: 0.0034\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 382us/step - loss: 0.0049 - val_loss: 0.0033\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 385us/step - loss: 0.0049 - val_loss: 0.0034\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 382us/step - loss: 0.0048 - val_loss: 0.0033\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 378us/step - loss: 0.0050 - val_loss: 0.0033\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 382us/step - loss: 0.0048 - val_loss: 0.0035\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 377us/step - loss: 0.0047 - val_loss: 0.0037\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 2s 591us/step - loss: 0.1007 - val_loss: 0.0124\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 382us/step - loss: 0.0315 - val_loss: 0.0079\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 400us/step - loss: 0.0227 - val_loss: 0.0050\n",
      "Epoch 4/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 2s 395us/step - loss: 0.0166 - val_loss: 0.0040\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 390us/step - loss: 0.0123 - val_loss: 0.0027\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 387us/step - loss: 0.0100 - val_loss: 0.0025\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 376us/step - loss: 0.0086 - val_loss: 0.0025\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 380us/step - loss: 0.0077 - val_loss: 0.0025\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 376us/step - loss: 0.0069 - val_loss: 0.0025\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 378us/step - loss: 0.0068 - val_loss: 0.0026\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 379us/step - loss: 0.0067 - val_loss: 0.0027\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 378us/step - loss: 0.0062 - val_loss: 0.0028\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 376us/step - loss: 0.0061 - val_loss: 0.0031\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 380us/step - loss: 0.0061 - val_loss: 0.0029\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 376us/step - loss: 0.0063 - val_loss: 0.0030\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 384us/step - loss: 0.0059 - val_loss: 0.0031\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 381us/step - loss: 0.0059 - val_loss: 0.0032\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 384us/step - loss: 0.0055 - val_loss: 0.0030\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 379us/step - loss: 0.0057 - val_loss: 0.0030\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 372us/step - loss: 0.0057 - val_loss: 0.0031\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 379us/step - loss: 0.0055 - val_loss: 0.0031\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 376us/step - loss: 0.0059 - val_loss: 0.0032\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 380us/step - loss: 0.0055 - val_loss: 0.0033\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 376us/step - loss: 0.0053 - val_loss: 0.0032\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 3s 704us/step - loss: 0.0488 - val_loss: 0.0076\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 460us/step - loss: 0.0197 - val_loss: 0.0052\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 456us/step - loss: 0.0155 - val_loss: 0.0033\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 458us/step - loss: 0.0117 - val_loss: 0.0029\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 458us/step - loss: 0.0095 - val_loss: 0.0026\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 459us/step - loss: 0.0080 - val_loss: 0.0025\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 455us/step - loss: 0.0068 - val_loss: 0.0025\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 452us/step - loss: 0.0064 - val_loss: 0.0027\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 460us/step - loss: 0.0060 - val_loss: 0.0029\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 462us/step - loss: 0.0057 - val_loss: 0.0028\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 459us/step - loss: 0.0056 - val_loss: 0.0033\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 458us/step - loss: 0.0055 - val_loss: 0.0031\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 458us/step - loss: 0.0054 - val_loss: 0.0032\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 458us/step - loss: 0.0055 - val_loss: 0.0036\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 458us/step - loss: 0.0053 - val_loss: 0.0037\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 460us/step - loss: 0.0054 - val_loss: 0.0034\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 455us/step - loss: 0.0053 - val_loss: 0.0035\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 457us/step - loss: 0.0052 - val_loss: 0.0037\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 461us/step - loss: 0.0050 - val_loss: 0.0034\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 457us/step - loss: 0.0050 - val_loss: 0.0035\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 455us/step - loss: 0.0051 - val_loss: 0.0035\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 452us/step - loss: 0.0049 - val_loss: 0.0033\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 458us/step - loss: 0.0048 - val_loss: 0.0034\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 457us/step - loss: 0.0047 - val_loss: 0.0034\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 3s 827us/step - loss: 0.0828 - val_loss: 0.0090\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 573us/step - loss: 0.0256 - val_loss: 0.0064\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 572us/step - loss: 0.0179 - val_loss: 0.0038\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 571us/step - loss: 0.0127 - val_loss: 0.0028\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 566us/step - loss: 0.0104 - val_loss: 0.0028\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 572us/step - loss: 0.0082 - val_loss: 0.0027\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 572us/step - loss: 0.0075 - val_loss: 0.0029\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 570us/step - loss: 0.0075 - val_loss: 0.0029\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 582us/step - loss: 0.0071 - val_loss: 0.0032\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 573us/step - loss: 0.0070 - val_loss: 0.0030\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 572us/step - loss: 0.0064 - val_loss: 0.0031\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 573us/step - loss: 0.0064 - val_loss: 0.0034\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 574us/step - loss: 0.0062 - val_loss: 0.0033\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 574us/step - loss: 0.0058 - val_loss: 0.0031\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 570us/step - loss: 0.0057 - val_loss: 0.0031\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 571us/step - loss: 0.0059 - val_loss: 0.0031\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 569us/step - loss: 0.0057 - val_loss: 0.0030\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 567us/step - loss: 0.0055 - val_loss: 0.0032\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 572us/step - loss: 0.0056 - val_loss: 0.0032\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 571us/step - loss: 0.0057 - val_loss: 0.0031\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 572us/step - loss: 0.0053 - val_loss: 0.0028\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 572us/step - loss: 0.0056 - val_loss: 0.0032\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 573us/step - loss: 0.0052 - val_loss: 0.0031\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 573us/step - loss: 0.0052 - val_loss: 0.0033\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 3s 845us/step - loss: 0.1926 - val_loss: 0.1181\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 576us/step - loss: 0.0789 - val_loss: 0.0559\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 571us/step - loss: 0.0688 - val_loss: 0.0423\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 570us/step - loss: 0.0679 - val_loss: 0.0385\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 580us/step - loss: 0.0678 - val_loss: 0.0375\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 579us/step - loss: 0.0678 - val_loss: 0.0368\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 569us/step - loss: 0.0678 - val_loss: 0.0362\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 578us/step - loss: 0.0678 - val_loss: 0.0366\n",
      "Epoch 9/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 2s 574us/step - loss: 0.0679 - val_loss: 0.0366\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 579us/step - loss: 0.0678 - val_loss: 0.0371\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 574us/step - loss: 0.0678 - val_loss: 0.0368\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 579us/step - loss: 0.0678 - val_loss: 0.0360\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 577us/step - loss: 0.0678 - val_loss: 0.0367\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 579us/step - loss: 0.0678 - val_loss: 0.0363\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 577us/step - loss: 0.0679 - val_loss: 0.0370\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 575us/step - loss: 0.0678 - val_loss: 0.0368\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 573us/step - loss: 0.0678 - val_loss: 0.0370\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 581us/step - loss: 0.0678 - val_loss: 0.0374\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 576us/step - loss: 0.0678 - val_loss: 0.0376\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 575us/step - loss: 0.0678 - val_loss: 0.0376\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 574us/step - loss: 0.0678 - val_loss: 0.0368\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 574us/step - loss: 0.0678 - val_loss: 0.0368\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 575us/step - loss: 0.0678 - val_loss: 0.0358\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 575us/step - loss: 0.0679 - val_loss: 0.0372\n",
      "\n",
      "GENERATION 1\n",
      "\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 1s 376us/step - loss: 1.6282 - val_loss: 0.1712\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 168us/step - loss: 0.0366 - val_loss: 0.0012\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 166us/step - loss: 0.0273 - val_loss: 0.0070\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 172us/step - loss: 0.0065 - val_loss: 0.0075\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 173us/step - loss: 0.0116 - val_loss: 0.0048\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 166us/step - loss: 0.0049 - val_loss: 0.0012\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 171us/step - loss: 0.0026 - val_loss: 0.0014\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 169us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 168us/step - loss: 9.7514e-04 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 169us/step - loss: 9.8174e-04 - val_loss: 9.5327e-04\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 170us/step - loss: 0.0010 - val_loss: 9.7263e-04\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 167us/step - loss: 9.8271e-04 - val_loss: 0.0010\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 171us/step - loss: 9.7079e-04 - val_loss: 9.3729e-04\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 170us/step - loss: 9.3587e-04 - val_loss: 9.7295e-04\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 167us/step - loss: 9.4769e-04 - val_loss: 9.3695e-04\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 171us/step - loss: 9.2364e-04 - val_loss: 9.5221e-04\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 170us/step - loss: 9.2876e-04 - val_loss: 9.4155e-04\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 168us/step - loss: 9.1275e-04 - val_loss: 9.4044e-04\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 171us/step - loss: 9.1748e-04 - val_loss: 9.4190e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 170us/step - loss: 9.0270e-04 - val_loss: 9.2911e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 166us/step - loss: 9.0768e-04 - val_loss: 9.3869e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 171us/step - loss: 8.9213e-04 - val_loss: 9.1769e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 169us/step - loss: 8.9730e-04 - val_loss: 9.3489e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 167us/step - loss: 8.8124e-04 - val_loss: 9.0672e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 2s 437us/step - loss: 0.0369 - val_loss: 0.0190\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 0.0084 - val_loss: 0.0101\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 216us/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 214us/step - loss: 9.2205e-04 - val_loss: 8.4003e-04\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 216us/step - loss: 8.5347e-04 - val_loss: 0.0011\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 8.2586e-04 - val_loss: 8.4989e-04\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 8.0025e-04 - val_loss: 9.2893e-04\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 7.9344e-04 - val_loss: 8.8622e-04\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 7.8350e-04 - val_loss: 8.1945e-04\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 7.7381e-04 - val_loss: 9.1291e-04\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 214us/step - loss: 7.6558e-04 - val_loss: 8.2510e-04\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 7.5349e-04 - val_loss: 8.0043e-04\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 7.4534e-04 - val_loss: 8.1356e-04\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 7.3419e-04 - val_loss: 7.8338e-04\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 7.2656e-04 - val_loss: 8.1565e-04\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 7.1873e-04 - val_loss: 7.6971e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 7.0951e-04 - val_loss: 7.6644e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 216us/step - loss: 7.0054e-04 - val_loss: 7.5281e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 6.9344e-04 - val_loss: 7.3912e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 216us/step - loss: 6.8536e-04 - val_loss: 7.2624e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 6.7911e-04 - val_loss: 7.0862e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 2s 408us/step - loss: 0.0714 - val_loss: 0.0176\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 0.0080 - val_loss: 0.0052\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 0.0030 - val_loss: 0.0045\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 9.8391e-04 - val_loss: 0.0010\n",
      "Epoch 11/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 1s 185us/step - loss: 9.5549e-04 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 9.3141e-04 - val_loss: 0.0010\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 9.0168e-04 - val_loss: 0.0010\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 8.6598e-04 - val_loss: 9.9796e-04\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 8.3493e-04 - val_loss: 8.5697e-04\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 8.0126e-04 - val_loss: 8.3755e-04\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 7.7857e-04 - val_loss: 8.3829e-04\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 181us/step - loss: 7.5960e-04 - val_loss: 8.5436e-04\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 7.4163e-04 - val_loss: 7.7675e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 7.2085e-04 - val_loss: 7.6525e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 7.0570e-04 - val_loss: 7.3320e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 6.9056e-04 - val_loss: 7.2635e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 6.7838e-04 - val_loss: 7.0761e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 6.6909e-04 - val_loss: 7.0511e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 3s 823us/step - loss: 0.0710 - val_loss: 0.0157\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 516us/step - loss: 0.0108 - val_loss: 0.0066\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 517us/step - loss: 0.0063 - val_loss: 0.0055\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 516us/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 527us/step - loss: 0.0049 - val_loss: 0.0082\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 520us/step - loss: 0.0060 - val_loss: 0.0042\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 516us/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 516us/step - loss: 0.0043 - val_loss: 0.0059\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 515us/step - loss: 0.0067 - val_loss: 0.0082\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 515us/step - loss: 0.0056 - val_loss: 0.0044\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 519us/step - loss: 0.0043 - val_loss: 0.0051\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 516us/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 514us/step - loss: 0.0041 - val_loss: 0.0068\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 513us/step - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 513us/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 513us/step - loss: 0.0046 - val_loss: 0.0038\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 513us/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 514us/step - loss: 0.0043 - val_loss: 0.0032\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 517us/step - loss: 0.0031 - val_loss: 0.0024\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 514us/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 512us/step - loss: 0.0045 - val_loss: 0.0052\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 513us/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 513us/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 512us/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 3s 714us/step - loss: 0.0744 - val_loss: 0.0211\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 373us/step - loss: 0.0114 - val_loss: 0.0046\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 373us/step - loss: 0.0114 - val_loss: 0.0117\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 373us/step - loss: 0.0099 - val_loss: 0.0034\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 372us/step - loss: 0.0087 - val_loss: 0.0030\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 377us/step - loss: 0.0058 - val_loss: 0.0026\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 372us/step - loss: 0.0056 - val_loss: 0.0039\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 372us/step - loss: 0.0081 - val_loss: 0.0185\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 373us/step - loss: 0.0098 - val_loss: 0.0090\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 373us/step - loss: 0.0081 - val_loss: 0.0072\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 375us/step - loss: 0.0070 - val_loss: 0.0025\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 376us/step - loss: 0.0046 - val_loss: 0.0028\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 375us/step - loss: 0.0057 - val_loss: 0.0085\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 373us/step - loss: 0.0092 - val_loss: 0.0043\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 374us/step - loss: 0.0060 - val_loss: 0.0072\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 370us/step - loss: 0.0068 - val_loss: 0.0041\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 376us/step - loss: 0.0052 - val_loss: 0.0066\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 375us/step - loss: 0.0061 - val_loss: 0.0034\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 374us/step - loss: 0.0036 - val_loss: 0.0022\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 370us/step - loss: 0.0043 - val_loss: 0.0051\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 372us/step - loss: 0.0074 - val_loss: 0.0045\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 373us/step - loss: 0.0056 - val_loss: 0.0036\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 379us/step - loss: 0.0056 - val_loss: 0.0043\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 376us/step - loss: 0.0059 - val_loss: 0.0034\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 3s 695us/step - loss: 1.9281 - val_loss: 0.0048\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 370us/step - loss: 0.0105 - val_loss: 0.0100\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 372us/step - loss: 0.0126 - val_loss: 0.0071\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 372us/step - loss: 0.0081 - val_loss: 0.0041\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 373us/step - loss: 0.0069 - val_loss: 0.0057\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 371us/step - loss: 0.0065 - val_loss: 0.0040\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 373us/step - loss: 0.0069 - val_loss: 0.0044\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 379us/step - loss: 0.0062 - val_loss: 0.0080\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 370us/step - loss: 0.0061 - val_loss: 0.0035\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 374us/step - loss: 0.0060 - val_loss: 0.0045\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 372us/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 377us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 372us/step - loss: 0.0052 - val_loss: 0.0054\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 373us/step - loss: 0.0053 - val_loss: 0.0086\n",
      "Epoch 15/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 1s 373us/step - loss: 0.0053 - val_loss: 0.0038\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 370us/step - loss: 0.0048 - val_loss: 0.0033\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 373us/step - loss: 0.0049 - val_loss: 0.0055\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 371us/step - loss: 0.0047 - val_loss: 0.0037\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 380us/step - loss: 0.0045 - val_loss: 0.0038\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 370us/step - loss: 0.0045 - val_loss: 0.0036\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 375us/step - loss: 0.0043 - val_loss: 0.0058\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 371us/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 374us/step - loss: 0.0042 - val_loss: 0.0050\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 371us/step - loss: 0.0046 - val_loss: 0.0052\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 3s 721us/step - loss: 0.6604 - val_loss: 0.0138\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 375us/step - loss: 0.0100 - val_loss: 0.0044\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 374us/step - loss: 0.0061 - val_loss: 0.0052\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 376us/step - loss: 0.0064 - val_loss: 0.0066\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 371us/step - loss: 0.0061 - val_loss: 0.0033\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 373us/step - loss: 0.0048 - val_loss: 0.0032\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 372us/step - loss: 0.0046 - val_loss: 0.0032\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 375us/step - loss: 0.0044 - val_loss: 0.0038\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 375us/step - loss: 0.0049 - val_loss: 0.0039\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 370us/step - loss: 0.0050 - val_loss: 0.0035\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 373us/step - loss: 0.0043 - val_loss: 0.0030\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 374us/step - loss: 0.0041 - val_loss: 0.0031\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 378us/step - loss: 0.0041 - val_loss: 0.0029\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 373us/step - loss: 0.0040 - val_loss: 0.0029\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 372us/step - loss: 0.0039 - val_loss: 0.0029\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 374us/step - loss: 0.0040 - val_loss: 0.0028\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 374us/step - loss: 0.0039 - val_loss: 0.0030\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 374us/step - loss: 0.0037 - val_loss: 0.0027\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 381us/step - loss: 0.0035 - val_loss: 0.0027\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 382us/step - loss: 0.0036 - val_loss: 0.0026\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 386us/step - loss: 0.0036 - val_loss: 0.0026\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 371us/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 370us/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 374us/step - loss: 0.0035 - val_loss: 0.0026\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 3s 821us/step - loss: 0.8963 - val_loss: 0.0040\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 469us/step - loss: 0.0315 - val_loss: 0.0051\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 464us/step - loss: 0.0077 - val_loss: 0.0068\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 467us/step - loss: 0.0074 - val_loss: 0.0047\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 470us/step - loss: 0.0054 - val_loss: 0.0045\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 469us/step - loss: 0.0047 - val_loss: 0.0061\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 470us/step - loss: 0.0046 - val_loss: 0.0042\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 469us/step - loss: 0.0046 - val_loss: 0.0036\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 471us/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 467us/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 470us/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 471us/step - loss: 0.0038 - val_loss: 0.0033\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 468us/step - loss: 0.0039 - val_loss: 0.0041\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 464us/step - loss: 0.0038 - val_loss: 0.0044\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 469us/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 473us/step - loss: 0.0036 - val_loss: 0.0031\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 469us/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 470us/step - loss: 0.0035 - val_loss: 0.0049\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 470us/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 470us/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 473us/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 471us/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 469us/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 470us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 3s 891us/step - loss: 0.5881 - val_loss: 0.3572\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 475us/step - loss: 0.1550 - val_loss: 0.1082\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 473us/step - loss: 0.0748 - val_loss: 0.0386\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 471us/step - loss: 0.0689 - val_loss: 0.0210\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 467us/step - loss: 0.0710 - val_loss: 0.0194\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 474us/step - loss: 0.0705 - val_loss: 0.0231\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 474us/step - loss: 0.0690 - val_loss: 0.0289\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 473us/step - loss: 0.0680 - val_loss: 0.0340\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 472us/step - loss: 0.0678 - val_loss: 0.0375\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 476us/step - loss: 0.0677 - val_loss: 0.0388\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 474us/step - loss: 0.0678 - val_loss: 0.0389\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 468us/step - loss: 0.0677 - val_loss: 0.0383\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 473us/step - loss: 0.0677 - val_loss: 0.0375\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 471us/step - loss: 0.0677 - val_loss: 0.0370\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 475us/step - loss: 0.0677 - val_loss: 0.0371\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 475us/step - loss: 0.0677 - val_loss: 0.0367\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 474us/step - loss: 0.0677 - val_loss: 0.0366\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 469us/step - loss: 0.0677 - val_loss: 0.0366\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 474us/step - loss: 0.0677 - val_loss: 0.0367\n",
      "Epoch 20/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 2s 474us/step - loss: 0.0677 - val_loss: 0.0372\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 469us/step - loss: 0.0677 - val_loss: 0.0372\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 472us/step - loss: 0.0677 - val_loss: 0.0372\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 471us/step - loss: 0.0677 - val_loss: 0.0370\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 467us/step - loss: 0.0677 - val_loss: 0.0370\n",
      "\n",
      "GENERATION 2\n",
      "\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 3s 808us/step - loss: 0.1302 - val_loss: 0.0790\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 382us/step - loss: 0.0701 - val_loss: 0.0183\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 384us/step - loss: 0.0714 - val_loss: 0.0187\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 381us/step - loss: 0.0657 - val_loss: 0.0316\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 383us/step - loss: 0.0595 - val_loss: 0.0299\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 380us/step - loss: 0.0506 - val_loss: 0.0213\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 381us/step - loss: 0.0385 - val_loss: 0.0100\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 383us/step - loss: 0.0266 - val_loss: 0.0045\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 384us/step - loss: 0.0204 - val_loss: 0.0064\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 381us/step - loss: 0.0145 - val_loss: 0.0080\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 385us/step - loss: 0.0116 - val_loss: 0.0269\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 383us/step - loss: 0.0094 - val_loss: 0.0027\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 383us/step - loss: 0.0058 - val_loss: 0.0040\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 381us/step - loss: 0.0042 - val_loss: 0.0038\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 381us/step - loss: 0.0033 - val_loss: 0.0029\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 381us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 380us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 383us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 385us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 385us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 380us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 382us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 379us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 384us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 2s 560us/step - loss: 0.0562 - val_loss: 0.0158\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 216us/step - loss: 0.0099 - val_loss: 0.0086\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 0.0044 - val_loss: 0.0027\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 221us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 216us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 9.9129e-04 - val_loss: 0.0010\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 9.7519e-04 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 9.5477e-04 - val_loss: 9.7938e-04\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 9.3882e-04 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 9.3069e-04 - val_loss: 9.4872e-04\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 215us/step - loss: 9.1882e-04 - val_loss: 0.0010\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 9.0859e-04 - val_loss: 9.5773e-04\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 8.9594e-04 - val_loss: 9.3714e-04\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 8.9234e-04 - val_loss: 9.8676e-04\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 8.7475e-04 - val_loss: 9.2583e-04\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 8.6233e-04 - val_loss: 9.0778e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 216us/step - loss: 8.5155e-04 - val_loss: 9.2004e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 216us/step - loss: 8.4459e-04 - val_loss: 8.6908e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 8.3131e-04 - val_loss: 9.0016e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 8.2159e-04 - val_loss: 8.5498e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 8.1233e-04 - val_loss: 8.6781e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 2s 571us/step - loss: 0.0251 - val_loss: 0.0209\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 192us/step - loss: 0.0077 - val_loss: 0.0076\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 197us/step - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 197us/step - loss: 0.0027 - val_loss: 0.0022\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 197us/step - loss: 0.0021 - val_loss: 0.0010\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 193us/step - loss: 0.0019 - val_loss: 0.0010\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 197us/step - loss: 0.0017 - val_loss: 9.2973e-04\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 198us/step - loss: 0.0018 - val_loss: 8.9854e-04\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 196us/step - loss: 0.0016 - val_loss: 9.8656e-04\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 194us/step - loss: 0.0016 - val_loss: 8.6524e-04\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 195us/step - loss: 0.0014 - val_loss: 8.6716e-04\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 195us/step - loss: 0.0014 - val_loss: 8.4671e-04\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 198us/step - loss: 0.0015 - val_loss: 8.2958e-04\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 192us/step - loss: 0.0014 - val_loss: 8.5351e-04\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 196us/step - loss: 0.0013 - val_loss: 8.4544e-04\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 200us/step - loss: 0.0013 - val_loss: 7.9442e-04\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 198us/step - loss: 0.0012 - val_loss: 7.7407e-04\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 196us/step - loss: 0.0013 - val_loss: 7.6427e-04\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 192us/step - loss: 0.0012 - val_loss: 7.5942e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 198us/step - loss: 0.0012 - val_loss: 7.5451e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 200us/step - loss: 0.0012 - val_loss: 7.3334e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 194us/step - loss: 0.0011 - val_loss: 7.2511e-04\n",
      "Epoch 23/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 1s 192us/step - loss: 0.0012 - val_loss: 7.2756e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 195us/step - loss: 0.0011 - val_loss: 7.3560e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 2s 569us/step - loss: 0.0642 - val_loss: 0.0044\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 194us/step - loss: 0.0133 - val_loss: 0.0013\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 0.0054 - val_loss: 0.0028\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 196us/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 194us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 198us/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 196us/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 197us/step - loss: 0.0019 - val_loss: 9.8148e-04\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 195us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 196us/step - loss: 0.0017 - val_loss: 9.8322e-04\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 196us/step - loss: 0.0017 - val_loss: 9.9762e-04\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 0.0016 - val_loss: 9.6694e-04\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 196us/step - loss: 0.0016 - val_loss: 9.5579e-04\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 195us/step - loss: 0.0015 - val_loss: 9.5074e-04\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 197us/step - loss: 0.0015 - val_loss: 9.1831e-04\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 191us/step - loss: 0.0014 - val_loss: 9.2539e-04\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 202us/step - loss: 0.0013 - val_loss: 8.8188e-04\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 215us/step - loss: 0.0014 - val_loss: 8.6106e-04\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 207us/step - loss: 0.0013 - val_loss: 8.6905e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 204us/step - loss: 0.0014 - val_loss: 8.5103e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 196us/step - loss: 0.0013 - val_loss: 8.6048e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 204us/step - loss: 0.0013 - val_loss: 8.2383e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 199us/step - loss: 0.0013 - val_loss: 8.1235e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 199us/step - loss: 0.0012 - val_loss: 8.2398e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 2s 594us/step - loss: 0.0910 - val_loss: 0.0097\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 176us/step - loss: 0.0200 - val_loss: 0.0015\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 178us/step - loss: 0.0096 - val_loss: 0.0016\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 180us/step - loss: 0.0057 - val_loss: 0.0018\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 177us/step - loss: 0.0043 - val_loss: 0.0030\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 0.0039 - val_loss: 0.0013\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 180us/step - loss: 0.0034 - val_loss: 0.0014\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 176us/step - loss: 0.0032 - val_loss: 8.7287e-04\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 177us/step - loss: 0.0027 - val_loss: 8.8976e-04\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 181us/step - loss: 0.0026 - val_loss: 8.4060e-04\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 178us/step - loss: 0.0027 - val_loss: 8.5518e-04\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 179us/step - loss: 0.0024 - val_loss: 8.4434e-04\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 181us/step - loss: 0.0024 - val_loss: 8.4112e-04\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 180us/step - loss: 0.0022 - val_loss: 8.1323e-04\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 0.0022 - val_loss: 8.3880e-04\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 0.0022 - val_loss: 7.9840e-04\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 193us/step - loss: 0.0021 - val_loss: 7.9004e-04\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 0.0021 - val_loss: 7.8883e-04\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 0.0019 - val_loss: 8.2257e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 210us/step - loss: 0.0020 - val_loss: 7.7161e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 178us/step - loss: 0.0020 - val_loss: 7.7596e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 181us/step - loss: 0.0019 - val_loss: 9.2623e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 175us/step - loss: 0.0019 - val_loss: 8.5581e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 0.0018 - val_loss: 7.4695e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 2s 594us/step - loss: 0.0613 - val_loss: 0.0030\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 177us/step - loss: 0.0136 - val_loss: 0.0017\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 176us/step - loss: 0.0054 - val_loss: 0.0017\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 175us/step - loss: 0.0055 - val_loss: 0.0057\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 175us/step - loss: 0.0063 - val_loss: 0.0012\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 175us/step - loss: 0.0034 - val_loss: 9.4544e-04\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 172us/step - loss: 0.0039 - val_loss: 0.0044\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 196us/step - loss: 0.0048 - val_loss: 9.9693e-04\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 0.0025 - val_loss: 9.6884e-04\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 180us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 0.0042 - val_loss: 0.0019\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 206us/step - loss: 0.0023 - val_loss: 8.3445e-04\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 178us/step - loss: 0.0029 - val_loss: 0.0014\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 175us/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 181us/step - loss: 0.0024 - val_loss: 9.4910e-04\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 177us/step - loss: 0.0020 - val_loss: 7.3207e-04\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 194us/step - loss: 0.0018 - val_loss: 9.2039e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 178us/step - loss: 0.0039 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 177us/step - loss: 0.0020 - val_loss: 6.7902e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 178us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 2s 590us/step - loss: 0.0883 - val_loss: 0.0015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 177us/step - loss: 0.0073 - val_loss: 0.0015\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 180us/step - loss: 0.0126 - val_loss: 0.0257\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 191us/step - loss: 0.0105 - val_loss: 0.0061\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 179us/step - loss: 0.0115 - val_loss: 0.0040\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 0.0054 - val_loss: 0.0142\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 191us/step - loss: 0.0115 - val_loss: 0.0011\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 0.0031 - val_loss: 0.0094\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 0.0113 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 0.0037 - val_loss: 0.0165\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 178us/step - loss: 0.0080 - val_loss: 9.8133e-04\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 176us/step - loss: 0.0054 - val_loss: 0.0074\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 196us/step - loss: 0.0053 - val_loss: 0.0037\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 0.0059 - val_loss: 0.0026\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 177us/step - loss: 0.0040 - val_loss: 0.0054\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 0.0061 - val_loss: 0.0014\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 194us/step - loss: 0.0038 - val_loss: 0.0057\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 0.0054 - val_loss: 0.0032\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 0.0031 - val_loss: 0.0061\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 202us/step - loss: 0.0053 - val_loss: 0.0017\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 198us/step - loss: 0.0034 - val_loss: 0.0025\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 179us/step - loss: 0.0048 - val_loss: 0.0030\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 197us/step - loss: 0.0036 - val_loss: 0.0050\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 193us/step - loss: 0.0039 - val_loss: 0.0012\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 4s 1ms/step - loss: 0.1717 - val_loss: 0.0115\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 556us/step - loss: 0.0141 - val_loss: 0.0024\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 555us/step - loss: 0.0074 - val_loss: 0.0065\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 554us/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 555us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 553us/step - loss: 0.0029 - val_loss: 0.0019\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 570us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 602us/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 596us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 582us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 564us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 555us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 564us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 566us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 575us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 571us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 552us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 555us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 555us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 554us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 559us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 559us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 552us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 555us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 4s 934us/step - loss: 1.2675 - val_loss: 0.0408\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 400us/step - loss: 0.0435 - val_loss: 0.0333\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 403us/step - loss: 0.0160 - val_loss: 0.0271\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 397us/step - loss: 0.0132 - val_loss: 0.0042\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 400us/step - loss: 0.0077 - val_loss: 0.0062\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 394us/step - loss: 0.0044 - val_loss: 0.0022\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 399us/step - loss: 0.0042 - val_loss: 0.0024\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 397us/step - loss: 0.0037 - val_loss: 0.0043\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 402us/step - loss: 0.0036 - val_loss: 0.0024\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 396us/step - loss: 0.0034 - val_loss: 0.0025\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 397us/step - loss: 0.0033 - val_loss: 0.0029\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 399us/step - loss: 0.0031 - val_loss: 0.0025\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 401us/step - loss: 0.0030 - val_loss: 0.0024\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 398us/step - loss: 0.0033 - val_loss: 0.0026\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 396us/step - loss: 0.0031 - val_loss: 0.0024\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 401us/step - loss: 0.0032 - val_loss: 0.0023\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 400us/step - loss: 0.0031 - val_loss: 0.0025\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 401us/step - loss: 0.0031 - val_loss: 0.0024\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 396us/step - loss: 0.0031 - val_loss: 0.0023\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 401us/step - loss: 0.0030 - val_loss: 0.0023\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 399us/step - loss: 0.0031 - val_loss: 0.0023\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 396us/step - loss: 0.0031 - val_loss: 0.0023\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 402us/step - loss: 0.0029 - val_loss: 0.0023\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 394us/step - loss: 0.0029 - val_loss: 0.0021\n",
      "\n",
      "GENERATION 3\n",
      "\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 4s 934us/step - loss: 0.0537 - val_loss: 0.0340\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 397us/step - loss: 0.0150 - val_loss: 0.0067\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 398us/step - loss: 0.0076 - val_loss: 0.0056\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 398us/step - loss: 0.0060 - val_loss: 0.0021\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 402us/step - loss: 0.0051 - val_loss: 0.0020\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 397us/step - loss: 0.0046 - val_loss: 0.0027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 396us/step - loss: 0.0039 - val_loss: 0.0019\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 401us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 400us/step - loss: 0.0037 - val_loss: 0.0025\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 397us/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 396us/step - loss: 0.0033 - val_loss: 0.0026\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 400us/step - loss: 0.0033 - val_loss: 0.0025\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 397us/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 399us/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 396us/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 404us/step - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 401us/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 395us/step - loss: 0.0027 - val_loss: 0.0016\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 399us/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 396us/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 400us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 393us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 398us/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 396us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 3s 683us/step - loss: 0.0646 - val_loss: 0.0060\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 221us/step - loss: 0.0065 - val_loss: 0.0061\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 215us/step - loss: 0.0027 - val_loss: 0.0014\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 216us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 215us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 214us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 216us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 9.8808e-04 - val_loss: 0.0011\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 9.6013e-04 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 9.2470e-04 - val_loss: 0.0010\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 216us/step - loss: 8.8973e-04 - val_loss: 9.6296e-04\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 213us/step - loss: 8.7327e-04 - val_loss: 9.2885e-04\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 8.5043e-04 - val_loss: 9.0527e-04\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 8.3188e-04 - val_loss: 8.8597e-04\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 8.2440e-04 - val_loss: 8.7345e-04\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 8.0147e-04 - val_loss: 8.5014e-04\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 7.9278e-04 - val_loss: 8.4461e-04\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 215us/step - loss: 7.7030e-04 - val_loss: 8.6421e-04\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 215us/step - loss: 7.6369e-04 - val_loss: 8.1291e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 7.4496e-04 - val_loss: 8.0144e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 7.3882e-04 - val_loss: 7.7704e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 7.3427e-04 - val_loss: 7.6511e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 216us/step - loss: 7.2021e-04 - val_loss: 7.8023e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 216us/step - loss: 7.1716e-04 - val_loss: 7.9684e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 3s 703us/step - loss: 0.4297 - val_loss: 0.0042\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 215us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 216us/step - loss: 0.0016 - val_loss: 0.0034\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 216us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 216us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 216us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 216us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 213us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 216us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 216us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 216us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 216us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 214us/step - loss: 9.9434e-04 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 9.8334e-04 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 215us/step - loss: 9.7549e-04 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 9.8535e-04 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 214us/step - loss: 9.4706e-04 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 9.6069e-04 - val_loss: 0.0010\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 9.2942e-04 - val_loss: 0.0010\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 3s 691us/step - loss: 0.4285 - val_loss: 0.0057\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 216us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 215us/step - loss: 9.1107e-04 - val_loss: 0.0011\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 9.4191e-04 - val_loss: 0.0011\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 214us/step - loss: 8.8116e-04 - val_loss: 0.0012\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 215us/step - loss: 9.8307e-04 - val_loss: 0.0014\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 9.4451e-04 - val_loss: 0.0012\n",
      "Epoch 10/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 1s 218us/step - loss: 9.0075e-04 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 8.3614e-04 - val_loss: 8.9179e-04\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 8.9026e-04 - val_loss: 8.8997e-04\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 8.2939e-04 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 221us/step - loss: 9.0379e-04 - val_loss: 8.6625e-04\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 8.0036e-04 - val_loss: 8.9346e-04\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 7.8469e-04 - val_loss: 8.8225e-04\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 216us/step - loss: 8.3232e-04 - val_loss: 8.2978e-04\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 7.8927e-04 - val_loss: 9.4500e-04\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 216us/step - loss: 7.6459e-04 - val_loss: 8.5026e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 214us/step - loss: 7.5506e-04 - val_loss: 8.2039e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 7.3951e-04 - val_loss: 7.8297e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 7.4702e-04 - val_loss: 8.1808e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 7.8477e-04 - val_loss: 0.0012\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 8.2058e-04 - val_loss: 8.5150e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 4s 1ms/step - loss: 0.3097 - val_loss: 0.0461\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 461us/step - loss: 0.0310 - val_loss: 0.0031\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 461us/step - loss: 0.0038 - val_loss: 0.0053\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 461us/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 462us/step - loss: 0.0029 - val_loss: 0.0053\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 461us/step - loss: 0.0032 - val_loss: 0.0040\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 462us/step - loss: 0.0032 - val_loss: 0.0056\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 463us/step - loss: 0.0030 - val_loss: 0.0024\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 464us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 464us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 460us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 461us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 463us/step - loss: 0.0028 - val_loss: 0.0023\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 464us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 461us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 459us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 461us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 463us/step - loss: 0.0020 - val_loss: 0.0034\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 465us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 461us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 458us/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 459us/step - loss: 0.0021 - val_loss: 0.0033\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 461us/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 463us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 4s 1ms/step - loss: 0.3577 - val_loss: 0.0903\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 402us/step - loss: 0.0157 - val_loss: 0.0044\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 406us/step - loss: 0.0057 - val_loss: 0.0042\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 401us/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 405us/step - loss: 0.0047 - val_loss: 0.0032\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 401us/step - loss: 0.0046 - val_loss: 0.0028\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 410us/step - loss: 0.0043 - val_loss: 0.0028\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 408us/step - loss: 0.0043 - val_loss: 0.0029\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 405us/step - loss: 0.0042 - val_loss: 0.0027\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 410us/step - loss: 0.0039 - val_loss: 0.0032\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 407us/step - loss: 0.0047 - val_loss: 0.0030\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 408us/step - loss: 0.0038 - val_loss: 0.0027\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 405us/step - loss: 0.0037 - val_loss: 0.0030\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 403us/step - loss: 0.0037 - val_loss: 0.0027\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 405us/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 404us/step - loss: 0.0036 - val_loss: 0.0025\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 409us/step - loss: 0.0037 - val_loss: 0.0025\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 403us/step - loss: 0.0036 - val_loss: 0.0024\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 410us/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 407us/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 406us/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 407us/step - loss: 0.0034 - val_loss: 0.0027\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 403us/step - loss: 0.0035 - val_loss: 0.0027\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 403us/step - loss: 0.0033 - val_loss: 0.0023\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 4s 1ms/step - loss: 1.6226 - val_loss: 0.0043\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 402us/step - loss: 0.0099 - val_loss: 0.0123\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 410us/step - loss: 0.0082 - val_loss: 0.0036\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 404us/step - loss: 0.0055 - val_loss: 0.0037\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 409us/step - loss: 0.0052 - val_loss: 0.0038\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 409us/step - loss: 0.0053 - val_loss: 0.0034\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 405us/step - loss: 0.0050 - val_loss: 0.0033\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 410us/step - loss: 0.0049 - val_loss: 0.0043\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 404us/step - loss: 0.0053 - val_loss: 0.0032\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 408us/step - loss: 0.0048 - val_loss: 0.0033\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 402us/step - loss: 0.0046 - val_loss: 0.0037\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 412us/step - loss: 0.0045 - val_loss: 0.0030\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 413us/step - loss: 0.0044 - val_loss: 0.0030\n",
      "Epoch 14/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 2s 407us/step - loss: 0.0045 - val_loss: 0.0032\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 405us/step - loss: 0.0044 - val_loss: 0.0031\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 402us/step - loss: 0.0044 - val_loss: 0.0030\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 409us/step - loss: 0.0042 - val_loss: 0.0030\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 407us/step - loss: 0.0041 - val_loss: 0.0035\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 404us/step - loss: 0.0044 - val_loss: 0.0031\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 409us/step - loss: 0.0042 - val_loss: 0.0029\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 403us/step - loss: 0.0040 - val_loss: 0.0026\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 406us/step - loss: 0.0038 - val_loss: 0.0032\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 408us/step - loss: 0.0039 - val_loss: 0.0031\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 404us/step - loss: 0.0038 - val_loss: 0.0025\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 4s 1ms/step - loss: 0.2829 - val_loss: 0.0078\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 406us/step - loss: 0.0107 - val_loss: 0.0030\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 405us/step - loss: 0.0060 - val_loss: 0.0025\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 408us/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 411us/step - loss: 0.0065 - val_loss: 0.0037\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 407us/step - loss: 0.0049 - val_loss: 0.0029\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 405us/step - loss: 0.0045 - val_loss: 0.0026\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 402us/step - loss: 0.0042 - val_loss: 0.0035\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 405us/step - loss: 0.0043 - val_loss: 0.0023\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 402us/step - loss: 0.0042 - val_loss: 0.0029\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 406us/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 405us/step - loss: 0.0037 - val_loss: 0.0027\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 408us/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 407us/step - loss: 0.0036 - val_loss: 0.0025\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 407us/step - loss: 0.0037 - val_loss: 0.0023\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 412us/step - loss: 0.0035 - val_loss: 0.0026\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 408us/step - loss: 0.0035 - val_loss: 0.0023\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 413us/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 407us/step - loss: 0.0034 - val_loss: 0.0026\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 401us/step - loss: 0.0034 - val_loss: 0.0022\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 407us/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 402us/step - loss: 0.0033 - val_loss: 0.0023\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 406us/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 402us/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 4s 1ms/step - loss: 0.5796 - val_loss: 0.0032\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 403us/step - loss: 0.0080 - val_loss: 0.0031\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 407us/step - loss: 0.0056 - val_loss: 0.0037\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 403us/step - loss: 0.0049 - val_loss: 0.0054\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 408us/step - loss: 0.0051 - val_loss: 0.0033\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 408us/step - loss: 0.0042 - val_loss: 0.0033\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 406us/step - loss: 0.0042 - val_loss: 0.0027\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 416us/step - loss: 0.0041 - val_loss: 0.0029\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 404us/step - loss: 0.0041 - val_loss: 0.0026\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 407us/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 406us/step - loss: 0.0046 - val_loss: 0.0026\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 402us/step - loss: 0.0038 - val_loss: 0.0025\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 405us/step - loss: 0.0038 - val_loss: 0.0032\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 402us/step - loss: 0.0040 - val_loss: 0.0032\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 407us/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 404us/step - loss: 0.0035 - val_loss: 0.0023\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 410us/step - loss: 0.0036 - val_loss: 0.0024\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 409us/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 402us/step - loss: 0.0036 - val_loss: 0.0023\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 407us/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 402us/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 403us/step - loss: 0.0036 - val_loss: 0.0026\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 403us/step - loss: 0.0033 - val_loss: 0.0023\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 405us/step - loss: 0.0032 - val_loss: 0.0025\n",
      "\n",
      "GENERATION 4\n",
      "\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 4s 1ms/step - loss: 0.0545 - val_loss: 0.0211\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 382us/step - loss: 0.0095 - val_loss: 0.0095\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 379us/step - loss: 0.0044 - val_loss: 0.0024\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 379us/step - loss: 0.0030 - val_loss: 0.0023\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 383us/step - loss: 0.0026 - val_loss: 0.0048\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 377us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 381us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 378us/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 385us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 381us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 383us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 381us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 382us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 380us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 383us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 377us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 380us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 379us/step - loss: 0.0015 - val_loss: 0.0018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 386us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 383us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 384us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 378us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 380us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 380us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 3s 792us/step - loss: 0.0956 - val_loss: 0.0285\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 0.0094 - val_loss: 0.0080\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 9.9543e-04 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 181us/step - loss: 9.8313e-04 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 9.5818e-04 - val_loss: 0.0010\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 9.4402e-04 - val_loss: 0.0010\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 9.2498e-04 - val_loss: 0.0010\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 9.0692e-04 - val_loss: 9.7370e-04\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 8.8544e-04 - val_loss: 9.5437e-04\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 8.6822e-04 - val_loss: 9.5093e-04\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 181us/step - loss: 8.5291e-04 - val_loss: 9.2750e-04\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 8.3220e-04 - val_loss: 8.9726e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 8.2126e-04 - val_loss: 8.7383e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 8.0845e-04 - val_loss: 8.6724e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 7.8667e-04 - val_loss: 8.3179e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 7.6661e-04 - val_loss: 8.1756e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 7.5349e-04 - val_loss: 8.0015e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 3s 818us/step - loss: 0.0570 - val_loss: 0.0043\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 0.0066 - val_loss: 0.0039\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 183us/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 9.7872e-04 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 9.5823e-04 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 9.1866e-04 - val_loss: 0.0010\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 8.7301e-04 - val_loss: 9.7719e-04\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 8.2487e-04 - val_loss: 9.4326e-04\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 7.8739e-04 - val_loss: 8.6891e-04\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 7.5186e-04 - val_loss: 8.2151e-04\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 7.2561e-04 - val_loss: 7.9123e-04\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 184us/step - loss: 7.0058e-04 - val_loss: 7.9166e-04\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 185us/step - loss: 6.8780e-04 - val_loss: 7.4252e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 6.7823e-04 - val_loss: 7.1821e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 6.5679e-04 - val_loss: 7.3944e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 6.4414e-04 - val_loss: 7.4597e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 6.5823e-04 - val_loss: 6.9165e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 6.4043e-04 - val_loss: 6.7799e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 4s 1ms/step - loss: 0.1206 - val_loss: 0.0041\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 386us/step - loss: 0.0198 - val_loss: 0.0034\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 378us/step - loss: 0.0103 - val_loss: 0.0042\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 386us/step - loss: 0.0068 - val_loss: 0.0029\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 378us/step - loss: 0.0053 - val_loss: 0.0036\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 380us/step - loss: 0.0045 - val_loss: 0.0024\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 380us/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 381us/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 378us/step - loss: 0.0037 - val_loss: 0.0021\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 381us/step - loss: 0.0035 - val_loss: 0.0021\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 376us/step - loss: 0.0033 - val_loss: 0.0027\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 383us/step - loss: 0.0031 - val_loss: 0.0025\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 382us/step - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 384us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 378us/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 381us/step - loss: 0.0030 - val_loss: 0.0025\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 380us/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 388us/step - loss: 0.0029 - val_loss: 0.0023\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 378us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 380us/step - loss: 0.0026 - val_loss: 0.0039\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 376us/step - loss: 0.0026 - val_loss: 0.0043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 379us/step - loss: 0.0025 - val_loss: 0.0044\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 376us/step - loss: 0.0025 - val_loss: 0.0039\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 381us/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 4s 1ms/step - loss: 0.0606 - val_loss: 0.0296\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 377us/step - loss: 0.0152 - val_loss: 0.0100\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 384us/step - loss: 0.0084 - val_loss: 0.0042\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 377us/step - loss: 0.0055 - val_loss: 0.0028\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 383us/step - loss: 0.0044 - val_loss: 0.0023\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 385us/step - loss: 0.0043 - val_loss: 0.0028\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 383us/step - loss: 0.0037 - val_loss: 0.0032\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 377us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 387us/step - loss: 0.0034 - val_loss: 0.0021\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 379us/step - loss: 0.0034 - val_loss: 0.0025\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 381us/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 377us/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 381us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 376us/step - loss: 0.0030 - val_loss: 0.0024\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 380us/step - loss: 0.0029 - val_loss: 0.0024\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 388us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 386us/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 377us/step - loss: 0.0027 - val_loss: 0.0022\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 379us/step - loss: 0.0026 - val_loss: 0.0049\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 382us/step - loss: 0.0026 - val_loss: 0.0054\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 378us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 380us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 377us/step - loss: 0.0023 - val_loss: 0.0055\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 383us/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 6s 1ms/step - loss: 0.1403 - val_loss: 0.0446\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 573us/step - loss: 0.0401 - val_loss: 0.0193\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 571us/step - loss: 0.0150 - val_loss: 0.0061\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 576us/step - loss: 0.0060 - val_loss: 0.0027\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 574us/step - loss: 0.0044 - val_loss: 0.0041\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 579us/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 609us/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 607us/step - loss: 0.0032 - val_loss: 0.0023\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 594us/step - loss: 0.0031 - val_loss: 0.0024\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 576us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 594us/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 608us/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 596us/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 597us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 631us/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 625us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 608us/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 595us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 609us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 582us/step - loss: 0.0022 - val_loss: 0.0047\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 600us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 590us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 586us/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 585us/step - loss: 0.0021 - val_loss: 0.0065\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 6s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 572us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 578us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 577us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 584us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 577us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 580us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 577us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 581us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 576us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 582us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 580us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 583us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 574us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 582us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 582us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 581us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 574us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 577us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 577us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 582us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 576us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 574us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 578us/step - loss: nan - val_loss: nan\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 6s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 586us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 580us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 2s 578us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 579us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 576us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 577us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 577us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 576us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 579us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 577us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 579us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 577us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 582us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 578us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 574us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 576us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 574us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 575us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 579us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 573us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 574us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 582us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 575us/step - loss: nan - val_loss: nan\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 6s 1ms/step - loss: 179501350.9190 - val_loss: 19.5731\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 583us/step - loss: 698.6116 - val_loss: 1.8439\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 578us/step - loss: 83.1536 - val_loss: 0.6592\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 576us/step - loss: 34.9395 - val_loss: 0.3650\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 579us/step - loss: 22.0529 - val_loss: 0.2483\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 576us/step - loss: 17.8870 - val_loss: 0.1857\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 578us/step - loss: 16.3329 - val_loss: 0.1416\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 579us/step - loss: 15.5435 - val_loss: 0.1043\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 578us/step - loss: 15.0701 - val_loss: 0.0689\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 574us/step - loss: 14.8951 - val_loss: 0.0366\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 578us/step - loss: 14.8155 - val_loss: 0.0137\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 575us/step - loss: 14.8933 - val_loss: 0.0049\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 581us/step - loss: 14.6785 - val_loss: 0.0150\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 575us/step - loss: 14.7691 - val_loss: 0.0302\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 579us/step - loss: 15.2721 - val_loss: 0.0450\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 577us/step - loss: 14.6031 - val_loss: 0.0732\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 576us/step - loss: 13.9450 - val_loss: 0.1229\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 576us/step - loss: 14.5604 - val_loss: 0.1997\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 577us/step - loss: 14.3250 - val_loss: 0.3063\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 577us/step - loss: 14.1573 - val_loss: 0.4233\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 577us/step - loss: 13.6902 - val_loss: 0.6695\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 578us/step - loss: 13.3491 - val_loss: 1.0062\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 577us/step - loss: 13.1827 - val_loss: 1.3888\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 578us/step - loss: 12.5227 - val_loss: 1.8313\n",
      "\n",
      "GENERATION 5\n",
      "\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 5s 1ms/step - loss: 1.8265 - val_loss: 0.0024\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 383us/step - loss: 0.0042 - val_loss: 0.0038\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 387us/step - loss: 0.0041 - val_loss: 0.0049\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 384us/step - loss: 0.0034 - val_loss: 0.0028\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 385us/step - loss: 0.0029 - val_loss: 0.0020\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 385us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 387us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 388us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 394us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 383us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 387us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 386us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 386us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 384us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 388us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 382us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 388us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 384us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 395us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 384us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 397us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 383us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 386us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 383us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 4s 1ms/step - loss: 0.0886 - val_loss: 0.0342\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 0.0100 - val_loss: 0.0134\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 0.0048 - val_loss: 0.0060\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 191us/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 194us/step - loss: 9.9342e-04 - val_loss: 0.0010\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 9.5241e-04 - val_loss: 0.0011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 9.0849e-04 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 191us/step - loss: 8.8760e-04 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 8.5910e-04 - val_loss: 9.7459e-04\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 186us/step - loss: 8.3959e-04 - val_loss: 9.4157e-04\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 8.1489e-04 - val_loss: 8.6148e-04\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 192us/step - loss: 7.9169e-04 - val_loss: 8.5203e-04\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 7.7879e-04 - val_loss: 8.3099e-04\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 187us/step - loss: 7.6368e-04 - val_loss: 8.0722e-04\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 7.5659e-04 - val_loss: 8.0349e-04\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 7.2933e-04 - val_loss: 7.8110e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 7.1683e-04 - val_loss: 7.7270e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 193us/step - loss: 7.0882e-04 - val_loss: 7.5604e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 7.0235e-04 - val_loss: 7.5897e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 191us/step - loss: 6.8933e-04 - val_loss: 7.4434e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 6.8513e-04 - val_loss: 7.4219e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 5s 1ms/step - loss: 0.1469 - val_loss: 0.0457\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 386us/step - loss: 0.0196 - val_loss: 0.0048\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 391us/step - loss: 0.0066 - val_loss: 0.0044\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 386us/step - loss: 0.0038 - val_loss: 0.0033\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 386us/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 389us/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 386us/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 391us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 387us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 388us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 385us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 389us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 388us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 391us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 384us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 389us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 385us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 388us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 384us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 391us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 388us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 390us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 388us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 393us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 5s 1ms/step - loss: 3194525191431809536.0000 - val_loss: 3564798720.0000\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 385us/step - loss: 6840894646.3778 - val_loss: 3564797952.0000\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 388us/step - loss: 6840895161.2727 - val_loss: 3564796672.0000\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 393us/step - loss: 6840895271.4099 - val_loss: 3564797952.0000\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 389us/step - loss: 6840895633.5338 - val_loss: 3564798464.0000\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 387us/step - loss: 6840894143.5888 - val_loss: 3564797696.0000\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 388us/step - loss: 6840894087.7965 - val_loss: 3564798720.0000\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 388us/step - loss: 6840894179.2485 - val_loss: 3564798208.0000\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 390us/step - loss: 6840893206.6985 - val_loss: 3564796160.0000\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 388us/step - loss: 6840891646.3552 - val_loss: 3564795648.0000\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 388us/step - loss: 6840889053.9851 - val_loss: 3564795136.0000\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 386us/step - loss: 6840887484.9571 - val_loss: 3564793600.0000\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 391us/step - loss: 6840874167.0357 - val_loss: 3564780288.0000\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 389us/step - loss: 6840830338.9936 - val_loss: 3564761344.0000\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 392us/step - loss: 6840780804.2107 - val_loss: 3564738048.0000\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 387us/step - loss: 6840722850.8373 - val_loss: 3564714752.0000\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 389us/step - loss: 6840663280.1439 - val_loss: 3564685056.0000\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 384us/step - loss: 6840578291.6967 - val_loss: 3564640768.0000\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 388us/step - loss: 6840434731.9496 - val_loss: 3564564736.0000\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 386us/step - loss: 6840229416.7916 - val_loss: 3564480000.0000\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 389us/step - loss: 6839996042.5598 - val_loss: 3564376320.0000\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 390us/step - loss: 6839722717.3272 - val_loss: 3564258560.0000\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 390us/step - loss: 6839395838.4210 - val_loss: 3564110080.0000\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 386us/step - loss: 6839003136.6579 - val_loss: 3563933696.0000\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 6s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 386us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 389us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 392us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 391us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 385us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 390us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 385us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 389us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 2s 389us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 392us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 387us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 390us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 386us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 393us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 387us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 387us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 395us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 404us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 386us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 389us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 386us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 386us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 387us/step - loss: nan - val_loss: nan\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 6s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 409us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 403us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 410us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 408us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 402us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 409us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 403us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 407us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 404us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 410us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 405us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 408us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 411us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 407us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 409us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 407us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 402us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 405us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 403us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 406us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 404us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 411us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 408us/step - loss: nan - val_loss: nan\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 6s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 404us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 412us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 407us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 410us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 408us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 406us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 408us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 402us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 406us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 403us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 404us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 414us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 405us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 409us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 405us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 411us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 409us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 403us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 409us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 405us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 405us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 401us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 409us/step - loss: nan - val_loss: nan\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 6s 2ms/step - loss: 526.1985 - val_loss: 2.8395\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 402us/step - loss: 7.1455 - val_loss: 2.7454\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 406us/step - loss: 4.2735 - val_loss: 0.4879\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 404us/step - loss: 2.4922 - val_loss: 0.1738\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 401us/step - loss: 1.6534 - val_loss: 0.0450\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 409us/step - loss: 1.2317 - val_loss: 0.0375\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 408us/step - loss: 1.0094 - val_loss: 0.0555\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 402us/step - loss: 0.8996 - val_loss: 0.0481\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 406us/step - loss: 0.7393 - val_loss: 0.0264\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 401us/step - loss: 0.6553 - val_loss: 0.0140\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 401us/step - loss: 0.5383 - val_loss: 0.0051\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 402us/step - loss: 0.4902 - val_loss: 0.0195\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 410us/step - loss: 0.4468 - val_loss: 0.0342\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 407us/step - loss: 0.4063 - val_loss: 0.0189\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 401us/step - loss: 0.3704 - val_loss: 0.0057\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 406us/step - loss: 0.3393 - val_loss: 0.0030\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 400us/step - loss: 0.2913 - val_loss: 0.0211\n",
      "Epoch 18/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 2s 403us/step - loss: 0.2571 - val_loss: 0.0035\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 400us/step - loss: 0.2239 - val_loss: 0.0177\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 413us/step - loss: 0.1987 - val_loss: 0.0050\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 405us/step - loss: 0.2110 - val_loss: 0.0464\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 403us/step - loss: 0.2496 - val_loss: 0.0124\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 410us/step - loss: 0.1354 - val_loss: 0.0047\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 400us/step - loss: 0.1130 - val_loss: 0.0030\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 6s 2ms/step - loss: 0.2203 - val_loss: 0.0030\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 408us/step - loss: 0.0088 - val_loss: 0.0026\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 408us/step - loss: 0.0078 - val_loss: 0.0028\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 401us/step - loss: 0.0072 - val_loss: 0.0020\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 403us/step - loss: 0.0063 - val_loss: 0.0043\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 403us/step - loss: 0.0062 - val_loss: 0.0024\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 409us/step - loss: 0.0062 - val_loss: 0.0026\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 403us/step - loss: 0.0061 - val_loss: 0.0151\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 406us/step - loss: 0.0192 - val_loss: 0.0110\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 404us/step - loss: 0.0072 - val_loss: 0.0037\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 404us/step - loss: 0.0060 - val_loss: 0.0193\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 407us/step - loss: 0.0153 - val_loss: 0.0123\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 404us/step - loss: 0.0064 - val_loss: 0.0057\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 405us/step - loss: 0.0040 - val_loss: 0.0054\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 400us/step - loss: 0.0081 - val_loss: 0.0166\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 404us/step - loss: 0.0089 - val_loss: 0.0117\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 403us/step - loss: 0.0058 - val_loss: 0.0144\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 405us/step - loss: 0.0067 - val_loss: 0.0136\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 408us/step - loss: 0.0087 - val_loss: 0.0149\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 402us/step - loss: 0.0066 - val_loss: 0.0131\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 406us/step - loss: 0.0051 - val_loss: 0.0055\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 403us/step - loss: 0.0045 - val_loss: 0.0117\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 401us/step - loss: 0.0064 - val_loss: 0.0096\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 404us/step - loss: 0.0066 - val_loss: 0.0121\n",
      "\n",
      "GENERATION 6\n",
      "\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 6s 2ms/step - loss: 0.0692 - val_loss: 0.0279\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 407us/step - loss: 0.0150 - val_loss: 0.0095\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 405us/step - loss: 0.0072 - val_loss: 0.0020\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 407us/step - loss: 0.0055 - val_loss: 0.0019\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 405us/step - loss: 0.0045 - val_loss: 0.0037\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 402us/step - loss: 0.0043 - val_loss: 0.0018\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 406us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 399us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 405us/step - loss: 0.0036 - val_loss: 0.0017\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 407us/step - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 407us/step - loss: 0.0033 - val_loss: 0.0018\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 407us/step - loss: 0.0032 - val_loss: 0.0017\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 404us/step - loss: 0.0030 - val_loss: 0.0016\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 411us/step - loss: 0.0031 - val_loss: 0.0016\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 403us/step - loss: 0.0030 - val_loss: 0.0015\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 405us/step - loss: 0.0028 - val_loss: 0.0018\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 402us/step - loss: 0.0028 - val_loss: 0.0018\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 402us/step - loss: 0.0027 - val_loss: 0.0020\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 404us/step - loss: 0.0026 - val_loss: 0.0021\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 412us/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 407us/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 402us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 407us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 404us/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 5s 1ms/step - loss: 0.0962 - val_loss: 0.0188\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 193us/step - loss: 0.0102 - val_loss: 0.0102\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 195us/step - loss: 0.0042 - val_loss: 0.0049\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 194us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 191us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 192us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 191us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 193us/step - loss: 9.9329e-04 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 192us/step - loss: 9.7601e-04 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 192us/step - loss: 9.4515e-04 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 188us/step - loss: 9.2517e-04 - val_loss: 0.0010\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 191us/step - loss: 9.0103e-04 - val_loss: 0.0010\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 191us/step - loss: 8.8490e-04 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 193us/step - loss: 8.7196e-04 - val_loss: 9.9907e-04\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 8.4180e-04 - val_loss: 9.6003e-04\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 192us/step - loss: 8.1207e-04 - val_loss: 9.0574e-04\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 195us/step - loss: 7.7973e-04 - val_loss: 8.3111e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 202us/step - loss: 7.5697e-04 - val_loss: 8.2283e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 7.4487e-04 - val_loss: 8.0426e-04\n",
      "Epoch 22/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 1s 192us/step - loss: 7.2510e-04 - val_loss: 7.7247e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 193us/step - loss: 7.0732e-04 - val_loss: 7.5463e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 193us/step - loss: 6.9755e-04 - val_loss: 7.4786e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 7s 2ms/step - loss: 0.0811 - val_loss: 0.0299\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 411us/step - loss: 0.0174 - val_loss: 0.0173\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 410us/step - loss: 0.0090 - val_loss: 0.0061\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 401us/step - loss: 0.0070 - val_loss: 0.0054\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 407us/step - loss: 0.0055 - val_loss: 0.0023\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 407us/step - loss: 0.0050 - val_loss: 0.0023\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 402us/step - loss: 0.0044 - val_loss: 0.0022\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 407us/step - loss: 0.0042 - val_loss: 0.0023\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 405us/step - loss: 0.0040 - val_loss: 0.0022\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 407us/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 409us/step - loss: 0.0036 - val_loss: 0.0024\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 402us/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 398us/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 408us/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 405us/step - loss: 0.0033 - val_loss: 0.0027\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 403us/step - loss: 0.0034 - val_loss: 0.0023\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 408us/step - loss: 0.0031 - val_loss: 0.0027\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 404us/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 406us/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 413us/step - loss: 0.0029 - val_loss: 0.0026\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 403us/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 402us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 404us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 405us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 7s 2ms/step - loss: 0.1444 - val_loss: 0.0096\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 380us/step - loss: 0.0193 - val_loss: 0.0245\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 412us/step - loss: 0.0152 - val_loss: 0.0099\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 385us/step - loss: 0.0100 - val_loss: 0.0232\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 386us/step - loss: 0.0126 - val_loss: 0.0082\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 385us/step - loss: 0.0069 - val_loss: 0.0034\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 384us/step - loss: 0.0057 - val_loss: 0.0074\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 387us/step - loss: 0.0069 - val_loss: 0.0070\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 397us/step - loss: 0.0075 - val_loss: 0.0092\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 438us/step - loss: 0.0072 - val_loss: 0.0060\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 428us/step - loss: 0.0076 - val_loss: 0.0087\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 419us/step - loss: 0.0076 - val_loss: 0.0066\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 402us/step - loss: 0.0070 - val_loss: 0.0049\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 400us/step - loss: 0.0060 - val_loss: 0.0059\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 397us/step - loss: 0.0057 - val_loss: 0.0046\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 405us/step - loss: 0.0051 - val_loss: 0.0070\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 402us/step - loss: 0.0067 - val_loss: 0.0040\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 399us/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 401us/step - loss: 0.0064 - val_loss: 0.0037\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 404us/step - loss: 0.0060 - val_loss: 0.0047\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 402us/step - loss: 0.0042 - val_loss: 0.0030\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 396us/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 400us/step - loss: 0.0060 - val_loss: 0.0059\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 398us/step - loss: 0.0051 - val_loss: 0.0044\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 8s 2ms/step - loss: 0.1074 - val_loss: 0.0140\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 487us/step - loss: 0.0190 - val_loss: 0.0194\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 485us/step - loss: 0.0185 - val_loss: 0.0124\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 489us/step - loss: 0.0113 - val_loss: 0.0143\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 490us/step - loss: 0.0094 - val_loss: 0.0098\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 488us/step - loss: 0.0074 - val_loss: 0.0090\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 491us/step - loss: 0.0075 - val_loss: 0.0089\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 484us/step - loss: 0.0071 - val_loss: 0.0096\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 491us/step - loss: 0.0096 - val_loss: 0.0113\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 490us/step - loss: 0.0081 - val_loss: 0.0054\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 486us/step - loss: 0.0054 - val_loss: 0.0089\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 501us/step - loss: 0.0066 - val_loss: 0.0045\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 486us/step - loss: 0.0063 - val_loss: 0.0114\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 488us/step - loss: 0.0081 - val_loss: 0.0072\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 488us/step - loss: 0.0066 - val_loss: 0.0064\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 484us/step - loss: 0.0051 - val_loss: 0.0040\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 499us/step - loss: 0.0057 - val_loss: 0.0069\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 489us/step - loss: 0.0069 - val_loss: 0.0081\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 487us/step - loss: 0.0060 - val_loss: 0.0067\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 494us/step - loss: 0.0071 - val_loss: 0.0050\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 486us/step - loss: 0.0050 - val_loss: 0.0062\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 490us/step - loss: 0.0066 - val_loss: 0.0037\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 485us/step - loss: 0.0042 - val_loss: 0.0060\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 482us/step - loss: 0.0048 - val_loss: 0.0032\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 8s 2ms/step - loss: 0.0959 - val_loss: 0.0117\n",
      "Epoch 2/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 2s 489us/step - loss: 0.0176 - val_loss: 0.0167\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 488us/step - loss: 0.0156 - val_loss: 0.0208\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 490us/step - loss: 0.0138 - val_loss: 0.0064\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 486us/step - loss: 0.0072 - val_loss: 0.0146\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 487us/step - loss: 0.0105 - val_loss: 0.0201\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 486us/step - loss: 0.0108 - val_loss: 0.0135\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 489us/step - loss: 0.0092 - val_loss: 0.0114\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 493us/step - loss: 0.0085 - val_loss: 0.0109\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 486us/step - loss: 0.0059 - val_loss: 0.0053\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 491us/step - loss: 0.0059 - val_loss: 0.0056\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 487us/step - loss: 0.0063 - val_loss: 0.0097\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 489us/step - loss: 0.0068 - val_loss: 0.0061\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 488us/step - loss: 0.0054 - val_loss: 0.0062\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 494us/step - loss: 0.0059 - val_loss: 0.0081\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 488us/step - loss: 0.0077 - val_loss: 0.0057\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 481us/step - loss: 0.0054 - val_loss: 0.0056\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 488us/step - loss: 0.0066 - val_loss: 0.0049\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 488us/step - loss: 0.0059 - val_loss: 0.0069\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 484us/step - loss: 0.0051 - val_loss: 0.0060\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 491us/step - loss: 0.0061 - val_loss: 0.0042\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 485us/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 491us/step - loss: 0.0039 - val_loss: 0.0063\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 492us/step - loss: 0.0063 - val_loss: 0.0056\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 8s 2ms/step - loss: 1616054919480427528859305377792.0000 - val_loss: 205176240868954210304.0000\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 520us/step - loss: 186583664572275980383551488.0000 - val_loss: 205057212138177691648.0000\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 522us/step - loss: 33926941449558322305768095744.0000 - val_loss: 204287008640967114752.0000\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 520us/step - loss: 2686029041197278846156537856.0000 - val_loss: 204252985353157214208.0000\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 519us/step - loss: 5130649286569091607683923968.0000 - val_loss: 204252967760971169792.0000\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 516us/step - loss: 1396212463558538204649400563662848.0000 - val_loss: 204252967760971169792.0000\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 516us/step - loss: 4614840709515837803804131065856.0000 - val_loss: 204252967760971169792.0000\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 519us/step - loss: 2100843704140246362605223936.0000 - val_loss: 204252967760971169792.0000\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 520us/step - loss: 9125373480755256379666595840.0000 - val_loss: 204252967760971169792.0000\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 516us/step - loss: 45578069059148331854373847040.0000 - val_loss: 204252967760971169792.0000\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 515us/step - loss: 2332317950774421110178971648.0000 - val_loss: 204252967760971169792.0000\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 515us/step - loss: 1825765601587886514490845429760.0000 - val_loss: 204252967760971169792.0000\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 519us/step - loss: 213747622396996951400775680.0000 - val_loss: 204252967760971169792.0000\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 518us/step - loss: 3699693422837901989997455605760.0000 - val_loss: 204252967760971169792.0000\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 517us/step - loss: 4030955392194235831613915136.0000 - val_loss: 204252967760971169792.0000\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 519us/step - loss: 15814263883111443090093637632.0000 - val_loss: 204252967760971169792.0000\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 521us/step - loss: 516736244257809345674215424.0000 - val_loss: 204252967760971169792.0000\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 523us/step - loss: 7033019631033524917000455847936.0000 - val_loss: 204252967760971169792.0000\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 518us/step - loss: 8452419906780032988157575168.0000 - val_loss: 204252967760971169792.0000\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 517us/step - loss: 201311349715496265098199040.0000 - val_loss: 204252967760971169792.0000\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 518us/step - loss: 106694352999322803905757184.0000 - val_loss: 204252967760971169792.0000\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 516us/step - loss: 2385785597121666399212666880.0000 - val_loss: 204252967760971169792.0000\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 520us/step - loss: 163676379402782020694691545088.0000 - val_loss: 204252967760971169792.0000\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 521us/step - loss: 42549511887044514790418415616.0000 - val_loss: 204252967760971169792.0000\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 8s 2ms/step - loss: 61476155418382117213323741102080.0000 - val_loss: 11210239721160606482432.0000\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 514us/step - loss: 3729764793208801842758147899392.0000 - val_loss: 11209870425991162101760.0000\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 514us/step - loss: 13242179353350325103499445010432.0000 - val_loss: 11209645246009793576960.0000\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 516us/step - loss: 219414957859888432675050718494720.0000 - val_loss: 11209642994209979891712.0000\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 515us/step - loss: 410040778601509965998388204797952.0000 - val_loss: 11209642994209979891712.0000\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 514us/step - loss: 1357601608970313889259211194368.0000 - val_loss: 11209631735210911465472.0000\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 518us/step - loss: 354658862763684132936046608384.0000 - val_loss: 11209631735210911465472.0000\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 520us/step - loss: 21535226883667548642162197397504.0000 - val_loss: 11209631735210911465472.0000\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 522us/step - loss: 12353360955354838779263147048960.0000 - val_loss: 11209631735210911465472.0000\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 528us/step - loss: 228291166540020056471613871226880.0000 - val_loss: 11209628357511190937600.0000\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 515us/step - loss: 313411916509890512365321617145856.0000 - val_loss: 11209628357511190937600.0000\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 519us/step - loss: 1620041291505585449702343783219200.0000 - val_loss: 11209628357511190937600.0000\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 515us/step - loss: 2823447176781630841853560487936.0000 - val_loss: 11209628357511190937600.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 521us/step - loss: 26792202983181426142632938045440.0000 - val_loss: 11209628357511190937600.0000\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 512us/step - loss: 6232061186159733424112439132160.0000 - val_loss: 11209628357511190937600.0000\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 519us/step - loss: 25033839465749529912533545333555200.0000 - val_loss: 11209628357511190937600.0000\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 515us/step - loss: 37890940595822104968090188005769216.0000 - val_loss: 11209628357511190937600.0000\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 513us/step - loss: 14979865986885137146668700925952.0000 - val_loss: 11209628357511190937600.0000\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 513us/step - loss: 50090157717230750109377977384960.0000 - val_loss: 11209628357511190937600.0000\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 512us/step - loss: 342005227047968358091710267392.0000 - val_loss: 11209628357511190937600.0000\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 513us/step - loss: 186274711256813367250326126592.0000 - val_loss: 11209628357511190937600.0000\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 515us/step - loss: 24897943332920280783447283204096.0000 - val_loss: 11209628357511190937600.0000\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 514us/step - loss: 14153573212844587391321738936582144.0000 - val_loss: 11209628357511190937600.0000\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 517us/step - loss: 454803978411349194182678806528.0000 - val_loss: 11209628357511190937600.0000\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 8s 2ms/step - loss: 79022002422.7250 - val_loss: 13615.8789\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 523us/step - loss: 250968.5913 - val_loss: 19686.0215\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 522us/step - loss: 236035.4391 - val_loss: 4826.0942\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 517us/step - loss: 171717.9473 - val_loss: 5976.2114\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 519us/step - loss: 158218.7437 - val_loss: 2073.0669\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 521us/step - loss: 99635.9737 - val_loss: 3651.0154\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 516us/step - loss: 89570.7812 - val_loss: 804.5212\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 518us/step - loss: 57403.9248 - val_loss: 11428.9111\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 518us/step - loss: 65818.9244 - val_loss: 4910.0693\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 515us/step - loss: 84798.3720 - val_loss: 1303.2905\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 516us/step - loss: 60771.6517 - val_loss: 13478.9668\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 514us/step - loss: 57682.6017 - val_loss: 10987.3184\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 515us/step - loss: 154661.5128 - val_loss: 7557.6670\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 515us/step - loss: 36006.8679 - val_loss: 11325.3174\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 518us/step - loss: 32768.8532 - val_loss: 8822.3184\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 523us/step - loss: 54544.7193 - val_loss: 6819.4346\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 525us/step - loss: 51211.0711 - val_loss: 4435.5869\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 523us/step - loss: 49331.8915 - val_loss: 3118.1187\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 516us/step - loss: 21069.4100 - val_loss: 3566.6682\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 519us/step - loss: 43757.4982 - val_loss: 4039.8147\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 515us/step - loss: 616775.4828 - val_loss: 7102.6143\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 516us/step - loss: 24619.7597 - val_loss: 11719.4619\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 516us/step - loss: 43637.6020 - val_loss: 5349.4395\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 524us/step - loss: 28897.6941 - val_loss: 10385.1475\n",
      "\n",
      "GENERATION 7\n",
      "\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 7s 2ms/step - loss: 0.0685 - val_loss: 0.0016\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 182us/step - loss: 0.0165 - val_loss: 0.0014\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 177us/step - loss: 0.0066 - val_loss: 0.0074\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 173us/step - loss: 0.0041 - val_loss: 0.0013\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 176us/step - loss: 0.0034 - val_loss: 0.0065\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 175us/step - loss: 0.0030 - val_loss: 0.0010\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 175us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 179us/step - loss: 0.0025 - val_loss: 0.0012\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 174us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 169us/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 171us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 172us/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 167us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 173us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 172us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 167us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 170us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 169us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 167us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 170us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - ETA: 0s - loss: 0.001 - 1s 169us/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 171us/step - loss: 0.0016 - val_loss: 9.7775e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 173us/step - loss: 0.0015 - val_loss: 9.6089e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 178us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 7s 2ms/step - loss: 0.0764 - val_loss: 0.0173\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 200us/step - loss: 0.0084 - val_loss: 0.0055\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 204us/step - loss: 0.0037 - val_loss: 0.0024\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 203us/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 204us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 199us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 198us/step - loss: 9.9555e-04 - val_loss: 0.0010\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 201us/step - loss: 9.6113e-04 - val_loss: 0.0012\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 198us/step - loss: 9.2743e-04 - val_loss: 9.8239e-04\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 201us/step - loss: 8.8088e-04 - val_loss: 9.5337e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 198us/step - loss: 8.5377e-04 - val_loss: 9.9018e-04\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 201us/step - loss: 8.2116e-04 - val_loss: 9.1799e-04\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 202us/step - loss: 7.9736e-04 - val_loss: 9.2658e-04\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 206us/step - loss: 7.7132e-04 - val_loss: 8.7992e-04\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 198us/step - loss: 7.4724e-04 - val_loss: 8.1771e-04\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 196us/step - loss: 7.2305e-04 - val_loss: 7.9552e-04\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 200us/step - loss: 7.0633e-04 - val_loss: 7.4918e-04\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 200us/step - loss: 6.7969e-04 - val_loss: 7.5652e-04\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 198us/step - loss: 6.6652e-04 - val_loss: 7.1759e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 196us/step - loss: 6.5494e-04 - val_loss: 7.0618e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 205us/step - loss: 6.4370e-04 - val_loss: 6.9307e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 202us/step - loss: 6.3628e-04 - val_loss: 7.1065e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 200us/step - loss: 6.4177e-04 - val_loss: 6.7072e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 201us/step - loss: 6.2651e-04 - val_loss: 6.6921e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 7s 2ms/step - loss: 0.2486 - val_loss: 0.3223\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 197us/step - loss: 0.1961 - val_loss: 0.2591\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 203us/step - loss: 0.1595 - val_loss: 0.2109\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 202us/step - loss: 0.1332 - val_loss: 0.1740\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 200us/step - loss: 0.1142 - val_loss: 0.1454\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 201us/step - loss: 0.1006 - val_loss: 0.1235\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 198us/step - loss: 0.0908 - val_loss: 0.1062\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 203us/step - loss: 0.0834 - val_loss: 0.0924\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 203us/step - loss: 0.0778 - val_loss: 0.0814\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 198us/step - loss: 0.0735 - val_loss: 0.0726\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 200us/step - loss: 0.0704 - val_loss: 0.0659\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 199us/step - loss: 0.0680 - val_loss: 0.0603\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 202us/step - loss: 0.0662 - val_loss: 0.0555\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 203us/step - loss: 0.0648 - val_loss: 0.0516\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 201us/step - loss: 0.0637 - val_loss: 0.0484\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 199us/step - loss: 0.0628 - val_loss: 0.0456\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 206us/step - loss: 0.0621 - val_loss: 0.0430\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 203us/step - loss: 0.0602 - val_loss: 0.0373\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 202us/step - loss: 0.0577 - val_loss: 0.0336\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 202us/step - loss: 0.0558 - val_loss: 0.0317\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 201us/step - loss: 0.0544 - val_loss: 0.0301\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 202us/step - loss: 0.0529 - val_loss: 0.0290\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 202us/step - loss: 0.0516 - val_loss: 0.0282\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 203us/step - loss: 0.0506 - val_loss: 0.0271\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 8s 2ms/step - loss: 0.0745 - val_loss: 0.0191\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 415us/step - loss: 0.0101 - val_loss: 0.0043\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 416us/step - loss: 0.0053 - val_loss: 0.0027\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 413us/step - loss: 0.0038 - val_loss: 0.0025\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 414us/step - loss: 0.0032 - val_loss: 0.0037\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 414us/step - loss: 0.0030 - val_loss: 0.0025\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 412us/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 414us/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 412us/step - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 414us/step - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 409us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 412us/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 412us/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 414us/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 415us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 418us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 415us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 416us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 415us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 412us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 417us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 412us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 413us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 409us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 9s 2ms/step - loss: 0.0800 - val_loss: 0.0303\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 413us/step - loss: 0.0121 - val_loss: 0.0027\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 412us/step - loss: 0.0052 - val_loss: 0.0089\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 414us/step - loss: 0.0041 - val_loss: 0.0027\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 412us/step - loss: 0.0032 - val_loss: 0.0026\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 413us/step - loss: 0.0028 - val_loss: 0.0023\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 413us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 412us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 414us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 414us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 421us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 415us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 413us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 419us/step - loss: 0.0020 - val_loss: 0.0025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 413us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 416us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 417us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 422us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 424us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 415us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 418us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 418us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 412us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 416us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 9s 2ms/step - loss: 0.0880 - val_loss: 0.0123\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 390us/step - loss: 0.0148 - val_loss: 0.0156\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 389us/step - loss: 0.0072 - val_loss: 0.0026\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 388us/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 390us/step - loss: 0.0033 - val_loss: 0.0026\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 391us/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 393us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 386us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 391us/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 387us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 391us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 388us/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 390us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 388us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 390us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 394us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 393us/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 391us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 392us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 398us/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 388us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 391us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 387us/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 392us/step - loss: 0.0015 - val_loss: 0.0024\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 9s 2ms/step - loss: 0.7110 - val_loss: 0.0592\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 389us/step - loss: 0.1277 - val_loss: 0.0463\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 401us/step - loss: 0.0815 - val_loss: 0.1339\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 387us/step - loss: 0.0969 - val_loss: 0.1022\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 391us/step - loss: 0.0760 - val_loss: 0.0457\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 389us/step - loss: 0.0682 - val_loss: 0.0233\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 393us/step - loss: 0.0699 - val_loss: 0.0239\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 393us/step - loss: 0.0685 - val_loss: 0.0344\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 389us/step - loss: 0.0679 - val_loss: 0.0428\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 392us/step - loss: 0.0680 - val_loss: 0.0419\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 391us/step - loss: 0.0678 - val_loss: 0.0361\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 394us/step - loss: 0.0677 - val_loss: 0.0345\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 390us/step - loss: 0.0677 - val_loss: 0.0356\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 392us/step - loss: 0.0676 - val_loss: 0.0374\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 390us/step - loss: 0.0675 - val_loss: 0.0385\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 393us/step - loss: 0.0675 - val_loss: 0.0365\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 389us/step - loss: 0.0673 - val_loss: 0.0353\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 394us/step - loss: 0.0671 - val_loss: 0.0354\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 390us/step - loss: 0.0669 - val_loss: 0.0371\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 394us/step - loss: 0.0656 - val_loss: 0.0325\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 389us/step - loss: 0.0643 - val_loss: 0.0316\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 397us/step - loss: 0.0640 - val_loss: 0.0338\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 393us/step - loss: 0.0548 - val_loss: 0.0176\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 392us/step - loss: 0.0490 - val_loss: 0.0101\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 9s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 394us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 391us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 391us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 391us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 395us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 392us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 388us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 390us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 390us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 391us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 386us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 390us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 386us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 388us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 387us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 399us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 387us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 394us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 388us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 2s 390us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 388us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 392us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 386us/step - loss: nan - val_loss: nan\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 9s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 423us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 426us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 428us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 427us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 430us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 427us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 430us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 426us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 429us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 430us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 425us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 424us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 427us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 428us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 426us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 424us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 427us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 424us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 427us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 432us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 425us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 425us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 430us/step - loss: nan - val_loss: nan\n",
      "\n",
      "GENERATION 8\n",
      "\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 8s 2ms/step - loss: 0.1390 - val_loss: 0.0560\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 235us/step - loss: 0.0168 - val_loss: 0.0177\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 234us/step - loss: 0.0076 - val_loss: 0.0077\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 235us/step - loss: 0.0040 - val_loss: 0.0029\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 237us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 235us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 238us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 237us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 236us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 236us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 235us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 239us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 238us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 236us/step - loss: 9.5881e-04 - val_loss: 0.0010\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 240us/step - loss: 9.0974e-04 - val_loss: 9.1335e-04\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 232us/step - loss: 8.6553e-04 - val_loss: 8.9633e-04\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 235us/step - loss: 8.1041e-04 - val_loss: 8.9557e-04\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 235us/step - loss: 7.7736e-04 - val_loss: 7.9690e-04\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 236us/step - loss: 7.4701e-04 - val_loss: 7.8459e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 237us/step - loss: 7.3917e-04 - val_loss: 7.4053e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 234us/step - loss: 7.0191e-04 - val_loss: 7.2952e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 235us/step - loss: 6.9045e-04 - val_loss: 7.1907e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 237us/step - loss: 6.8766e-04 - val_loss: 6.8955e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 238us/step - loss: 6.8410e-04 - val_loss: 6.9364e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 8s 2ms/step - loss: 0.0605 - val_loss: 0.0037\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 201us/step - loss: 0.0077 - val_loss: 0.0046\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 199us/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 206us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 198us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 200us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 201us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 199us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 199us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 198us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 201us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 200us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 198us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 199us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 199us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 200us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 203us/step - loss: 9.9354e-04 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 204us/step - loss: 9.7432e-04 - val_loss: 0.0010\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 197us/step - loss: 9.4674e-04 - val_loss: 9.8816e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 199us/step - loss: 9.2946e-04 - val_loss: 9.6189e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 201us/step - loss: 8.9405e-04 - val_loss: 9.4617e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 200us/step - loss: 8.6954e-04 - val_loss: 9.1432e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 200us/step - loss: 8.4409e-04 - val_loss: 8.8210e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 200us/step - loss: 8.2059e-04 - val_loss: 8.5702e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 8s 2ms/step - loss: 0.0642 - val_loss: 0.0015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 200us/step - loss: 0.0103 - val_loss: 0.0021\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 196us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 198us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 200us/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 199us/step - loss: 0.0012 - val_loss: 9.6022e-04\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 196us/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 199us/step - loss: 9.9086e-04 - val_loss: 9.9364e-04\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 199us/step - loss: 9.5258e-04 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 200us/step - loss: 9.2242e-04 - val_loss: 0.0010\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 201us/step - loss: 8.9614e-04 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 198us/step - loss: 8.8403e-04 - val_loss: 0.0010\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 199us/step - loss: 8.7299e-04 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 200us/step - loss: 8.7038e-04 - val_loss: 9.3603e-04\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 199us/step - loss: 8.5641e-04 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 196us/step - loss: 8.4969e-04 - val_loss: 9.1398e-04\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 198us/step - loss: 8.3218e-04 - val_loss: 0.0010\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 200us/step - loss: 8.2766e-04 - val_loss: 9.0716e-04\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 199us/step - loss: 8.1139e-04 - val_loss: 9.5303e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 201us/step - loss: 8.0446e-04 - val_loss: 9.2142e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 196us/step - loss: 7.9240e-04 - val_loss: 8.7677e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 200us/step - loss: 7.8479e-04 - val_loss: 9.1093e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 200us/step - loss: 7.7663e-04 - val_loss: 8.7641e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 199us/step - loss: 7.7023e-04 - val_loss: 8.0307e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 9s 2ms/step - loss: 0.0447 - val_loss: 0.0063\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 197us/step - loss: 0.0087 - val_loss: 0.0018\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 204us/step - loss: 0.0037 - val_loss: 9.6191e-04\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 201us/step - loss: 0.0021 - val_loss: 9.1138e-04\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 200us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 200us/step - loss: 0.0011 - val_loss: 8.8882e-04\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 196us/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 199us/step - loss: 9.4670e-04 - val_loss: 9.0562e-04\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 200us/step - loss: 9.0726e-04 - val_loss: 0.0010\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 198us/step - loss: 8.8124e-04 - val_loss: 9.4998e-04\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 197us/step - loss: 8.6116e-04 - val_loss: 9.7172e-04\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 199us/step - loss: 8.5069e-04 - val_loss: 9.3927e-04\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 201us/step - loss: 8.4187e-04 - val_loss: 8.9089e-04\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 201us/step - loss: 8.2954e-04 - val_loss: 9.5717e-04\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 198us/step - loss: 8.1879e-04 - val_loss: 8.5124e-04\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 197us/step - loss: 8.1345e-04 - val_loss: 9.2467e-04\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 199us/step - loss: 7.9780e-04 - val_loss: 8.5093e-04\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 201us/step - loss: 7.8753e-04 - val_loss: 8.4521e-04\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 200us/step - loss: 7.7719e-04 - val_loss: 8.4473e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 195us/step - loss: 7.6632e-04 - val_loss: 8.1684e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 200us/step - loss: 7.5743e-04 - val_loss: 7.9379e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 201us/step - loss: 7.4723e-04 - val_loss: 8.4932e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 208us/step - loss: 7.4156e-04 - val_loss: 7.8128e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 203us/step - loss: 7.3085e-04 - val_loss: 7.6156e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 9s 2ms/step - loss: 0.0568 - val_loss: 0.0015\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 202us/step - loss: 0.0059 - val_loss: 0.0022\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 199us/step - loss: 0.0035 - val_loss: 0.0060\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 201us/step - loss: 0.0025 - val_loss: 8.9174e-04\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 201us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 200us/step - loss: 0.0019 - val_loss: 9.8857e-04\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 200us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 198us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 202us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 201us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 201us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 205us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 201us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 201us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 204us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 208us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 198us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 200us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 203us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 201us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 202us/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 197us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 202us/step - loss: 0.0013 - val_loss: 9.8132e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 203us/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 10s 3ms/step - loss: 0.0682 - val_loss: 0.0030\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 427us/step - loss: 0.0108 - val_loss: 0.0025\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 431us/step - loss: 0.0070 - val_loss: 0.0025\n",
      "Epoch 4/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 2s 426us/step - loss: 0.0051 - val_loss: 0.0026\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 425us/step - loss: 0.0046 - val_loss: 0.0019\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 424us/step - loss: 0.0041 - val_loss: 0.0031\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 425us/step - loss: 0.0040 - val_loss: 0.0018\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 423us/step - loss: 0.0040 - val_loss: 0.0027\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 429us/step - loss: 0.0039 - val_loss: 0.0019\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 424us/step - loss: 0.0038 - val_loss: 0.0023\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 423us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 428us/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 427us/step - loss: 0.0036 - val_loss: 0.0021\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 425us/step - loss: 0.0036 - val_loss: 0.0022\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 425us/step - loss: 0.0034 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 430us/step - loss: 0.0034 - val_loss: 0.0021\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 424us/step - loss: 0.0033 - val_loss: 0.0020\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 430us/step - loss: 0.0032 - val_loss: 0.0019\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 427us/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 425us/step - loss: 0.0032 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 425us/step - loss: 0.0033 - val_loss: 0.0019\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 427us/step - loss: 0.0033 - val_loss: 0.0020\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 426us/step - loss: 0.0033 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 424us/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 10s 3ms/step - loss: 0.1119 - val_loss: 0.0232\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 398us/step - loss: 0.0131 - val_loss: 0.0065\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 401us/step - loss: 0.0066 - val_loss: 0.0054\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 401us/step - loss: 0.0043 - val_loss: 0.0072\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 408us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 399us/step - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 404us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 399us/step - loss: 0.0026 - val_loss: 0.0020\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 402us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 401us/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 402us/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 404us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 398us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 402us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 403us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 403us/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 401us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 403us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 404us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 400us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 402us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 400us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 404us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 399us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 10s 3ms/step - loss: 0.0972 - val_loss: 0.0251\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 404us/step - loss: 0.0133 - val_loss: 0.0082\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 399us/step - loss: 0.0083 - val_loss: 0.0064\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 402us/step - loss: 0.0054 - val_loss: 0.0031\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 398us/step - loss: 0.0042 - val_loss: 0.0023\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 406us/step - loss: 0.0037 - val_loss: 0.0052\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 404us/step - loss: 0.0035 - val_loss: 0.0023\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 409us/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 403us/step - loss: 0.0033 - val_loss: 0.0027\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 398us/step - loss: 0.0034 - val_loss: 0.0029\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 402us/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 398us/step - loss: 0.0031 - val_loss: 0.0025\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 405us/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 402us/step - loss: 0.0031 - val_loss: 0.0026\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 400us/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 399us/step - loss: 0.0030 - val_loss: 0.0025\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 404us/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 408us/step - loss: 0.0029 - val_loss: 0.0026\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 406us/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 403us/step - loss: 0.0029 - val_loss: 0.0025\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 401us/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 403us/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 398us/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 403us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 10s 3ms/step - loss: 0.7989 - val_loss: 0.2556\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 400us/step - loss: 0.1016 - val_loss: 0.0046\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 404us/step - loss: 0.0742 - val_loss: 0.0374\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 397us/step - loss: 0.0604 - val_loss: 0.0312\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 398us/step - loss: 0.0471 - val_loss: 0.0073\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 398us/step - loss: 0.0293 - val_loss: 0.0044\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 405us/step - loss: 0.0114 - val_loss: 0.0125\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 403us/step - loss: 0.0088 - val_loss: 0.0040\n",
      "Epoch 9/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 2s 398us/step - loss: 0.0069 - val_loss: 0.0093\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 400us/step - loss: 0.0062 - val_loss: 0.0061\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 403us/step - loss: 0.0057 - val_loss: 0.0043\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 406us/step - loss: 0.0053 - val_loss: 0.0038\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 402us/step - loss: 0.0050 - val_loss: 0.0034\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 402us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 399us/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 401us/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 403us/step - loss: 0.0045 - val_loss: 0.0052\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 401us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 407us/step - loss: 0.0042 - val_loss: 0.0038\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 398us/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 405us/step - loss: 0.0039 - val_loss: 0.0041\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 398us/step - loss: 0.0039 - val_loss: 0.0042\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 403us/step - loss: 0.0038 - val_loss: 0.0032\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 405us/step - loss: 0.0039 - val_loss: 0.0029\n",
      "\n",
      "GENERATION 9\n",
      "\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 11s 3ms/step - loss: 0.0548 - val_loss: 0.0255\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 414us/step - loss: 0.0109 - val_loss: 0.0130\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 418us/step - loss: 0.0047 - val_loss: 0.0022\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 409us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 411us/step - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 409us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 413us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 417us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 409us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 413us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 410us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 420us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 413us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 407us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 410us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 407us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 414us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 416us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 407us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 410us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 409us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 416us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 407us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 408us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 10s 3ms/step - loss: 0.1057 - val_loss: 0.0390\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 201us/step - loss: 0.0123 - val_loss: 0.0095\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 205us/step - loss: 0.0052 - val_loss: 0.0054\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 204us/step - loss: 0.0030 - val_loss: 0.0023\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 204us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 202us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 208us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 204us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 204us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 203us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 202us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 204us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 203us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 205us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 206us/step - loss: 9.7546e-04 - val_loss: 0.0010\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 201us/step - loss: 9.4995e-04 - val_loss: 9.9012e-04\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 205us/step - loss: 9.2323e-04 - val_loss: 9.9131e-04\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 206us/step - loss: 9.0839e-04 - val_loss: 0.0010\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 204us/step - loss: 8.7581e-04 - val_loss: 9.9726e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 205us/step - loss: 8.4794e-04 - val_loss: 9.1171e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 203us/step - loss: 8.2562e-04 - val_loss: 8.5540e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 204us/step - loss: 8.0269e-04 - val_loss: 8.5061e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 206us/step - loss: 7.7908e-04 - val_loss: 8.5596e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 202us/step - loss: 7.5839e-04 - val_loss: 7.9910e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 10s 3ms/step - loss: 0.0563 - val_loss: 0.0030\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 236us/step - loss: 0.0132 - val_loss: 0.0024\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 239us/step - loss: 0.0057 - val_loss: 0.0019\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 237us/step - loss: 0.0052 - val_loss: 0.0063\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 236us/step - loss: 0.0039 - val_loss: 0.0019\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 235us/step - loss: 0.0031 - val_loss: 0.0020\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 235us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 237us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 236us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 236us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 237us/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 239us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 13/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 1s 239us/step - loss: 9.9481e-04 - val_loss: 0.0014\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 237us/step - loss: 9.6068e-04 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 237us/step - loss: 9.6374e-04 - val_loss: 0.0017\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 242us/step - loss: 9.3929e-04 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 238us/step - loss: 8.8098e-04 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 234us/step - loss: 8.9813e-04 - val_loss: 0.0013\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 233us/step - loss: 8.6166e-04 - val_loss: 9.5483e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 238us/step - loss: 8.3683e-04 - val_loss: 0.0012\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 236us/step - loss: 8.1245e-04 - val_loss: 9.9151e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 236us/step - loss: 8.0200e-04 - val_loss: 9.0171e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 236us/step - loss: 7.8362e-04 - val_loss: 9.3143e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 236us/step - loss: 7.7984e-04 - val_loss: 8.8741e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 12s 3ms/step - loss: 0.2463 - val_loss: 0.0116\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 498us/step - loss: 0.0216 - val_loss: 0.0349\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 496us/step - loss: 0.0121 - val_loss: 0.0032\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 494us/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 494us/step - loss: 0.0031 - val_loss: 0.0034\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 496us/step - loss: 0.0028 - val_loss: 0.0133\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 499us/step - loss: 0.0067 - val_loss: 0.0032\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 493us/step - loss: 0.0025 - val_loss: 0.0038\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 497us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 497us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 494us/step - loss: 0.0027 - val_loss: 0.0122\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 496us/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 498us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 495us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 501us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 500us/step - loss: 0.0026 - val_loss: 0.0020\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 498us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 495us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 495us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 494us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 498us/step - loss: 0.0027 - val_loss: 0.0022\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 488us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 491us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 505us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 12s 3ms/step - loss: 0.0912 - val_loss: 0.0349\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 496us/step - loss: 0.0428 - val_loss: 0.0222\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 494us/step - loss: 0.0375 - val_loss: 0.0179\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 499us/step - loss: 0.0331 - val_loss: 0.0156\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 497us/step - loss: 0.0290 - val_loss: 0.0137\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 492us/step - loss: 0.0251 - val_loss: 0.0123\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 495us/step - loss: 0.0216 - val_loss: 0.0100\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 496us/step - loss: 0.0184 - val_loss: 0.0084\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 500us/step - loss: 0.0156 - val_loss: 0.0070\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 495us/step - loss: 0.0131 - val_loss: 0.0053\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 492us/step - loss: 0.0111 - val_loss: 0.0044\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 504us/step - loss: 0.0095 - val_loss: 0.0036\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 503us/step - loss: 0.0083 - val_loss: 0.0032\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 499us/step - loss: 0.0074 - val_loss: 0.0028\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 494us/step - loss: 0.0067 - val_loss: 0.0027\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 498us/step - loss: 0.0062 - val_loss: 0.0027\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 498us/step - loss: 0.0058 - val_loss: 0.0027\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 495us/step - loss: 0.0056 - val_loss: 0.0028\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 493us/step - loss: 0.0054 - val_loss: 0.0029\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 512us/step - loss: 0.0052 - val_loss: 0.0030\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 510us/step - loss: 0.0051 - val_loss: 0.0031\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 487us/step - loss: 0.0050 - val_loss: 0.0033\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 472us/step - loss: 0.0049 - val_loss: 0.0033\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 466us/step - loss: 0.0049 - val_loss: 0.0034\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 12s 3ms/step - loss: 3.0109 - val_loss: 0.0044\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 525us/step - loss: 0.0083 - val_loss: 0.0040\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 518us/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 533us/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 525us/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 527us/step - loss: 0.0035 - val_loss: 0.0048\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 505us/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 512us/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 523us/step - loss: 0.0032 - val_loss: 0.0039\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 506us/step - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 511us/step - loss: 0.0032 - val_loss: 0.0040\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 508us/step - loss: 0.0030 - val_loss: 0.0044\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 512us/step - loss: 0.0030 - val_loss: 0.0041\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 518us/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 512us/step - loss: 0.0029 - val_loss: 0.0044\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 516us/step - loss: 0.0028 - val_loss: 0.0040\n",
      "Epoch 17/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 2s 510us/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 514us/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 512us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 510us/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 511us/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 511us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 510us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 512us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 11s 3ms/step - loss: 7.7808 - val_loss: 0.0041\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 373us/step - loss: 0.0070 - val_loss: 0.0038\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 373us/step - loss: 0.0047 - val_loss: 0.0039\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 371us/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 378us/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 376us/step - loss: 0.0032 - val_loss: 0.0041\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 371us/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 377us/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 372us/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 374us/step - loss: 0.0029 - val_loss: 0.0039\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 370us/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 376us/step - loss: 0.0029 - val_loss: 0.0040\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 370us/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 373us/step - loss: 0.0028 - val_loss: 0.0041\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 370us/step - loss: 0.0028 - val_loss: 0.0039\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 377us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 384us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 369us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 376us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 373us/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 377us/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 370us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 375us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 374us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 11s 3ms/step - loss: 5.6534 - val_loss: 0.0035\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 369us/step - loss: 0.0066 - val_loss: 0.0023\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 376us/step - loss: 0.0032 - val_loss: 0.0025\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 372us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 374us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 371us/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 372us/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 378us/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 374us/step - loss: 0.0019 - val_loss: 0.0030\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 379us/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 375us/step - loss: 0.0018 - val_loss: 0.0033\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 374us/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 371us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 375us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 374us/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 374us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 375us/step - loss: 0.0017 - val_loss: 0.0027\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 380us/step - loss: 0.0017 - val_loss: 0.0027\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 376us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 374us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 376us/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 371us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 377us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 377us/step - loss: 0.0016 - val_loss: 0.0025\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 11s 3ms/step - loss: 0.9730 - val_loss: 0.0045\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 374us/step - loss: 0.0084 - val_loss: 0.0027\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 369us/step - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 373us/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 372us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 372us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 371us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 370us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 372us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 371us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 379us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 376us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 373us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 371us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 373us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 372us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 373us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 377us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 371us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 374us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 371us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 22/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 1s 377us/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 373us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 370us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "\n",
      "GENERATION 10\n",
      "\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 10s 3ms/step - loss: 0.0748 - val_loss: 0.0168\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 198us/step - loss: 0.0075 - val_loss: 0.0075\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 196us/step - loss: 0.0032 - val_loss: 0.0061\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 194us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 195us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 196us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 195us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 200us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 195us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 202us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 200us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 195us/step - loss: 9.9589e-04 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 195us/step - loss: 9.7390e-04 - val_loss: 0.0010\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 195us/step - loss: 9.5725e-04 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 197us/step - loss: 9.3154e-04 - val_loss: 0.0010\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 196us/step - loss: 9.1200e-04 - val_loss: 9.7382e-04\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 196us/step - loss: 8.9462e-04 - val_loss: 9.6426e-04\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 196us/step - loss: 8.7625e-04 - val_loss: 9.9020e-04\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 197us/step - loss: 8.5199e-04 - val_loss: 9.6243e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 196us/step - loss: 8.3970e-04 - val_loss: 9.2008e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 194us/step - loss: 8.1948e-04 - val_loss: 8.7658e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 198us/step - loss: 7.9768e-04 - val_loss: 8.6487e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 198us/step - loss: 7.6833e-04 - val_loss: 7.9635e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 196us/step - loss: 7.4066e-04 - val_loss: 7.7538e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 11s 3ms/step - loss: 0.1064 - val_loss: 0.0296\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 194us/step - loss: 0.0113 - val_loss: 0.0109\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 196us/step - loss: 0.0045 - val_loss: 0.0059\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 195us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 195us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 197us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 197us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 197us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 193us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 197us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 196us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 196us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 194us/step - loss: 9.9114e-04 - val_loss: 0.0011-\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 198us/step - loss: 9.7797e-04 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 199us/step - loss: 9.6376e-04 - val_loss: 0.0010\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 201us/step - loss: 9.4985e-04 - val_loss: 0.0010\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 198us/step - loss: 9.3679e-04 - val_loss: 9.9034e-04\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 193us/step - loss: 9.2408e-04 - val_loss: 9.9109e-04\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 198us/step - loss: 9.0823e-04 - val_loss: 9.6978e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 201us/step - loss: 8.9511e-04 - val_loss: 9.5996e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 197us/step - loss: 8.8240e-04 - val_loss: 9.6343e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 193us/step - loss: 8.7141e-04 - val_loss: 9.2487e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 198us/step - loss: 8.5492e-04 - val_loss: 8.9830e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 197us/step - loss: 8.4285e-04 - val_loss: 8.9010e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 10s 3ms/step - loss: 0.0400 - val_loss: 0.0028\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 200us/step - loss: 0.0054 - val_loss: 0.0059\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 199us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 201us/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 198us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 196us/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 199us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 195us/step - loss: 9.5563e-04 - val_loss: 0.0010\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 197us/step - loss: 9.4206e-04 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 193us/step - loss: 9.1136e-04 - val_loss: 9.8028e-04\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 198us/step - loss: 8.8391e-04 - val_loss: 0.0010\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 198us/step - loss: 8.5339e-04 - val_loss: 9.2181e-04\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 198us/step - loss: 8.2446e-04 - val_loss: 8.6640e-04\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 197us/step - loss: 7.9695e-04 - val_loss: 8.5473e-04\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 195us/step - loss: 7.6533e-04 - val_loss: 7.9843e-04\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 197us/step - loss: 7.4592e-04 - val_loss: 7.8437e-04\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 197us/step - loss: 7.3114e-04 - val_loss: 7.6299e-04\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 198us/step - loss: 7.0920e-04 - val_loss: 7.6169e-04\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 195us/step - loss: 6.9028e-04 - val_loss: 7.2756e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 195us/step - loss: 6.8586e-04 - val_loss: 7.3593e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 198us/step - loss: 6.7005e-04 - val_loss: 7.1988e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 199us/step - loss: 6.6234e-04 - val_loss: 7.1014e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 200us/step - loss: 6.6300e-04 - val_loss: 6.8997e-04\n",
      "Epoch 24/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 1s 195us/step - loss: 6.5396e-04 - val_loss: 6.9156e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 12s 3ms/step - loss: 0.0632 - val_loss: 0.0323\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 493us/step - loss: 0.0123 - val_loss: 0.0085\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 498us/step - loss: 0.0055 - val_loss: 0.0018\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 490us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 492us/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 493us/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 488us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 493us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 495us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 494us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 496us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 496us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 491us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 492us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 494us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 495us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 492us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 494us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 491us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 493us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 492us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 496us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 492us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 495us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 12s 3ms/step - loss: 0.1148 - val_loss: 0.0339\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 491us/step - loss: 0.0329 - val_loss: 0.0115\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 490us/step - loss: 0.0259 - val_loss: 0.0077\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 496us/step - loss: 0.0220 - val_loss: 0.0061\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 486us/step - loss: 0.0188 - val_loss: 0.0052\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 492us/step - loss: 0.0160 - val_loss: 0.0044\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 501us/step - loss: 0.0136 - val_loss: 0.0041\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 492us/step - loss: 0.0118 - val_loss: 0.0034\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 494us/step - loss: 0.0105 - val_loss: 0.0031\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 494us/step - loss: 0.0087 - val_loss: 0.0029\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 489us/step - loss: 0.0079 - val_loss: 0.0027\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 493us/step - loss: 0.0071 - val_loss: 0.0026\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 495us/step - loss: 0.0062 - val_loss: 0.0026\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 490us/step - loss: 0.0059 - val_loss: 0.0026\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 490us/step - loss: 0.0054 - val_loss: 0.0026\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 496us/step - loss: 0.0050 - val_loss: 0.0026\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 487us/step - loss: 0.0048 - val_loss: 0.0027\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 488us/step - loss: 0.0047 - val_loss: 0.0028\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 495us/step - loss: 0.0045 - val_loss: 0.0028\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 492us/step - loss: 0.0043 - val_loss: 0.0029\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 491us/step - loss: 0.0043 - val_loss: 0.0030\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 497us/step - loss: 0.0045 - val_loss: 0.0031\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 490us/step - loss: 0.0043 - val_loss: 0.0030\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 495us/step - loss: 0.0041 - val_loss: 0.0031\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 14s 3ms/step - loss: 0.1532 - val_loss: 0.0888\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 537us/step - loss: 0.0468 - val_loss: 0.0207\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 538us/step - loss: 0.0246 - val_loss: 0.0074\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 530us/step - loss: 0.0194 - val_loss: 0.0044\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 528us/step - loss: 0.0172 - val_loss: 0.0035\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 531us/step - loss: 0.0149 - val_loss: 0.0031\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 535us/step - loss: 0.0131 - val_loss: 0.0029\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 528us/step - loss: 0.0117 - val_loss: 0.0028\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 529us/step - loss: 0.0108 - val_loss: 0.0027\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 540us/step - loss: 0.0094 - val_loss: 0.0026\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 535us/step - loss: 0.0086 - val_loss: 0.0026\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 530us/step - loss: 0.0081 - val_loss: 0.0026\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 534us/step - loss: 0.0073 - val_loss: 0.0026\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 531us/step - loss: 0.0068 - val_loss: 0.0027\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 527us/step - loss: 0.0063 - val_loss: 0.0028\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 534us/step - loss: 0.0059 - val_loss: 0.0028\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 539us/step - loss: 0.0057 - val_loss: 0.0029\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 533us/step - loss: 0.0055 - val_loss: 0.0031\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 534us/step - loss: 0.0051 - val_loss: 0.0031\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 536us/step - loss: 0.0049 - val_loss: 0.0031\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 530us/step - loss: 0.0047 - val_loss: 0.0032\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 529us/step - loss: 0.0048 - val_loss: 0.0033\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 537us/step - loss: 0.0045 - val_loss: 0.0033\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 529us/step - loss: 0.0045 - val_loss: 0.0035\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 14s 4ms/step - loss: 0.1764 - val_loss: 0.1446\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 599us/step - loss: 0.0800 - val_loss: 0.0627\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 592us/step - loss: 0.0484 - val_loss: 0.0301\n",
      "Epoch 4/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 2s 595us/step - loss: 0.0380 - val_loss: 0.0178\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 591us/step - loss: 0.0336 - val_loss: 0.0125\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 594us/step - loss: 0.0309 - val_loss: 0.0098\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 592us/step - loss: 0.0284 - val_loss: 0.0087\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 591us/step - loss: 0.0260 - val_loss: 0.0077\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 596us/step - loss: 0.0238 - val_loss: 0.0069\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 593us/step - loss: 0.0216 - val_loss: 0.0062\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 593us/step - loss: 0.0195 - val_loss: 0.0056\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 593us/step - loss: 0.0177 - val_loss: 0.0050\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 593us/step - loss: 0.0160 - val_loss: 0.0045\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 595us/step - loss: 0.0144 - val_loss: 0.0040\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 595us/step - loss: 0.0129 - val_loss: 0.0037\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 599us/step - loss: 0.0115 - val_loss: 0.0034\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 592us/step - loss: 0.0102 - val_loss: 0.0032\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 592us/step - loss: 0.0092 - val_loss: 0.0031\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 590us/step - loss: 0.0083 - val_loss: 0.0029\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 595us/step - loss: 0.0074 - val_loss: 0.0029\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 592us/step - loss: 0.0067 - val_loss: 0.0028\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 592us/step - loss: 0.0061 - val_loss: 0.0028\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 600us/step - loss: 0.0056 - val_loss: 0.0028\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 591us/step - loss: 0.0052 - val_loss: 0.0028\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 14s 4ms/step - loss: 0.5976 - val_loss: 0.1152\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 595us/step - loss: 0.0330 - val_loss: 0.0042\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 595us/step - loss: 0.0062 - val_loss: 0.0066\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 608us/step - loss: 0.0072 - val_loss: 0.0088\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 599us/step - loss: 0.0051 - val_loss: 0.0042\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 598us/step - loss: 0.0032 - val_loss: 0.0040\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 602us/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 595us/step - loss: 0.0032 - val_loss: 0.0026\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 596us/step - loss: 0.0029 - val_loss: 0.0024\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 600us/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 597us/step - loss: 0.0029 - val_loss: 0.0026\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 596us/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 599us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 603us/step - loss: 0.0029 - val_loss: 0.0027\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 597us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 598us/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 602us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 597us/step - loss: 0.0028 - val_loss: 0.0021\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 598us/step - loss: 0.0029 - val_loss: 0.0023\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 597us/step - loss: 0.0027 - val_loss: 0.0022\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 592us/step - loss: 0.0027 - val_loss: 0.0020\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 597us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 596us/step - loss: 0.0026 - val_loss: 0.0021\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 599us/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 14s 4ms/step - loss: 0.8064 - val_loss: 0.0489\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 596us/step - loss: 0.0689 - val_loss: 0.0473\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 593us/step - loss: 0.0723 - val_loss: 0.0402\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 592us/step - loss: 0.0573 - val_loss: 0.0073\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 596us/step - loss: 0.0598 - val_loss: 0.0788\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 597us/step - loss: 0.0535 - val_loss: 0.0036\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 592us/step - loss: 0.0432 - val_loss: 0.0039\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 591us/step - loss: 0.0279 - val_loss: 0.0063\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 594us/step - loss: 0.0098 - val_loss: 0.0270\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 600us/step - loss: 0.0177 - val_loss: 0.0048\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 595us/step - loss: 0.0070 - val_loss: 0.0036\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 604us/step - loss: 0.0081 - val_loss: 0.0094\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 595us/step - loss: 0.0079 - val_loss: 0.0025\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 593us/step - loss: 0.0070 - val_loss: 0.0065\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 597us/step - loss: 0.0076 - val_loss: 0.0029\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 594us/step - loss: 0.0064 - val_loss: 0.0064\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 596us/step - loss: 0.0071 - val_loss: 0.0026\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 597us/step - loss: 0.0051 - val_loss: 0.0026\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 601us/step - loss: 0.0056 - val_loss: 0.0020\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 591us/step - loss: 0.0046 - val_loss: 0.0024\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 596us/step - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 599us/step - loss: 0.0069 - val_loss: 0.0031\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 595us/step - loss: 0.0046 - val_loss: 0.0031\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 597us/step - loss: 0.0042 - val_loss: 0.0038\n",
      "\n",
      "GENERATION 11\n",
      "\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 14s 4ms/step - loss: 0.2091 - val_loss: 0.0134\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 431us/step - loss: 0.0342 - val_loss: 0.0372\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 432us/step - loss: 0.0196 - val_loss: 0.0216\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 434us/step - loss: 0.0102 - val_loss: 0.0072\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 429us/step - loss: 0.0063 - val_loss: 0.0047\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 429us/step - loss: 0.0050 - val_loss: 0.0031\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 431us/step - loss: 0.0043 - val_loss: 0.0028\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 428us/step - loss: 0.0039 - val_loss: 0.0026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 428us/step - loss: 0.0039 - val_loss: 0.0024\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 430us/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 431us/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 432us/step - loss: 0.0035 - val_loss: 0.0028\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 431us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 433us/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 427us/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 430us/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 436us/step - loss: 0.0030 - val_loss: 0.0041\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 428us/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 425us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 433us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 425us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 433us/step - loss: 0.0026 - val_loss: 0.0064\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 429us/step - loss: 0.0027 - val_loss: 0.0054\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 427us/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 13s 3ms/step - loss: 0.0919 - val_loss: 0.0317\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 205us/step - loss: 0.0107 - val_loss: 0.0083\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 205us/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 202us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 200us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 207us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 207us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 204us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 210us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 202us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 204us/step - loss: 9.9695e-04 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 206us/step - loss: 9.6888e-04 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 205us/step - loss: 9.4170e-04 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 205us/step - loss: 9.1898e-04 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 201us/step - loss: 8.8930e-04 - val_loss: 9.5944e-04\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 205us/step - loss: 8.5243e-04 - val_loss: 9.3515e-04\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 208us/step - loss: 8.2797e-04 - val_loss: 9.2278e-04\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 207us/step - loss: 8.0897e-04 - val_loss: 8.9623e-04\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 205us/step - loss: 7.8574e-04 - val_loss: 8.4559e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 201us/step - loss: 7.5251e-04 - val_loss: 8.1471e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 204us/step - loss: 7.3360e-04 - val_loss: 7.8573e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 204us/step - loss: 7.2877e-04 - val_loss: 7.6101e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 204us/step - loss: 7.0044e-04 - val_loss: 7.4906e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 203us/step - loss: 6.8553e-04 - val_loss: 7.3921e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 13s 3ms/step - loss: 0.1755 - val_loss: 0.0201\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 204us/step - loss: 0.0198 - val_loss: 0.0122\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 203us/step - loss: 0.0119 - val_loss: 0.0016\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 200us/step - loss: 0.0056 - val_loss: 0.0018\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 202us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 203us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 203us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 204us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 200us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 205us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 205us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 204us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 202us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 201us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 206us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 205us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 205us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 200us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 203us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 204us/step - loss: 9.7768e-04 - val_loss: 0.0010\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 203us/step - loss: 9.4350e-04 - val_loss: 9.8718e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 210us/step - loss: 9.0854e-04 - val_loss: 9.8079e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 201us/step - loss: 8.8363e-04 - val_loss: 9.0852e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 205us/step - loss: 8.5226e-04 - val_loss: 8.6454e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 15s 4ms/step - loss: 0.0984 - val_loss: 0.0060\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 421us/step - loss: 0.0136 - val_loss: 0.0120\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 419us/step - loss: 0.0096 - val_loss: 0.0146\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 419us/step - loss: 0.0098 - val_loss: 0.0110\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 422us/step - loss: 0.0057 - val_loss: 0.0051\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 425us/step - loss: 0.0061 - val_loss: 0.0116\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 423us/step - loss: 0.0085 - val_loss: 0.0111\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 415us/step - loss: 0.0060 - val_loss: 0.0060\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 422us/step - loss: 0.0045 - val_loss: 0.0037\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 419us/step - loss: 0.0048 - val_loss: 0.0112\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 419us/step - loss: 0.0071 - val_loss: 0.0031\n",
      "Epoch 12/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 2s 424us/step - loss: 0.0048 - val_loss: 0.0138\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 416us/step - loss: 0.0055 - val_loss: 0.0021\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 423us/step - loss: 0.0033 - val_loss: 0.0099\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 422us/step - loss: 0.0055 - val_loss: 0.0046\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 415us/step - loss: 0.0046 - val_loss: 0.0042\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 437us/step - loss: 0.0041 - val_loss: 0.0060\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 420us/step - loss: 0.0032 - val_loss: 0.0024\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 416us/step - loss: 0.0037 - val_loss: 0.0082\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 420us/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 422us/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 420us/step - loss: 0.0044 - val_loss: 0.0057\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 419us/step - loss: 0.0032 - val_loss: 0.0053\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 420us/step - loss: 0.0038 - val_loss: 0.0041\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 15s 4ms/step - loss: 3.5434 - val_loss: 0.0070\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 415us/step - loss: 0.0276 - val_loss: 0.0031\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 416us/step - loss: 0.0086 - val_loss: 0.0017\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 418us/step - loss: 0.0052 - val_loss: 0.0024\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 416us/step - loss: 0.0045 - val_loss: 0.0018\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 421us/step - loss: 0.0043 - val_loss: 0.0022\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 418us/step - loss: 0.0040 - val_loss: 0.0019\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 423us/step - loss: 0.0041 - val_loss: 0.0020\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 417us/step - loss: 0.0040 - val_loss: 0.0022\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 420us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 420us/step - loss: 0.0036 - val_loss: 0.0016\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 418us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 418us/step - loss: 0.0035 - val_loss: 0.0021\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 421us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 415us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 418us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 418us/step - loss: 0.0033 - val_loss: 0.0018\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 418us/step - loss: 0.0032 - val_loss: 0.0020\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 424us/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 425us/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 416us/step - loss: 0.0031 - val_loss: 0.0019\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 419us/step - loss: 0.0032 - val_loss: 0.0018\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 419us/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 417us/step - loss: 0.0030 - val_loss: 0.0015\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 16s 4ms/step - loss: 7.1891 - val_loss: 0.0124\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 420us/step - loss: 0.0242 - val_loss: 0.0026\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 416us/step - loss: 0.0086 - val_loss: 0.0025\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 421us/step - loss: 0.0069 - val_loss: 0.0029\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 420us/step - loss: 0.0058 - val_loss: 0.0027\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 419us/step - loss: 0.0057 - val_loss: 0.0033\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 426us/step - loss: 0.0052 - val_loss: 0.0038\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 419us/step - loss: 0.0052 - val_loss: 0.0034\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 417us/step - loss: 0.0048 - val_loss: 0.0033\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 421us/step - loss: 0.0051 - val_loss: 0.0035\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 421us/step - loss: 0.0045 - val_loss: 0.0039\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 418us/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 424us/step - loss: 0.0045 - val_loss: 0.0038\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 424us/step - loss: 0.0044 - val_loss: 0.0028\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 418us/step - loss: 0.0041 - val_loss: 0.0033\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 421us/step - loss: 0.0040 - val_loss: 0.0028\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 416us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 424us/step - loss: 0.0041 - val_loss: 0.0031\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 422us/step - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 415us/step - loss: 0.0039 - val_loss: 0.0031\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 418us/step - loss: 0.0038 - val_loss: 0.0033\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 421us/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 420us/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 427us/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 15s 4ms/step - loss: 0.4249 - val_loss: 0.0031\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 422us/step - loss: 0.0235 - val_loss: 0.0046\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 418us/step - loss: 0.0121 - val_loss: 0.0047\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 420us/step - loss: 0.0087 - val_loss: 0.0039\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 421us/step - loss: 0.0066 - val_loss: 0.0029\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 415us/step - loss: 0.0054 - val_loss: 0.0041\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 420us/step - loss: 0.0051 - val_loss: 0.0055\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 419us/step - loss: 0.0056 - val_loss: 0.0136\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 423us/step - loss: 0.0050 - val_loss: 0.0044\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 419us/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 422us/step - loss: 0.0038 - val_loss: 0.0044\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 414us/step - loss: 0.0039 - val_loss: 0.0072\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 419us/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 417us/step - loss: 0.0039 - val_loss: 0.0088\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 424us/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 417us/step - loss: 0.0036 - val_loss: 0.0032\n",
      "Epoch 17/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 2s 416us/step - loss: 0.0033 - val_loss: 0.0051\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 421us/step - loss: 0.0035 - val_loss: 0.0069\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 420us/step - loss: 0.0039 - val_loss: 0.0058\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 415us/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 420us/step - loss: 0.0032 - val_loss: 0.0027\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 418us/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 419us/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 419us/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 16s 4ms/step - loss: 0.1005 - val_loss: 0.0185\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 420us/step - loss: 0.0362 - val_loss: 0.0123\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 425us/step - loss: 0.0232 - val_loss: 0.0048\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 417us/step - loss: 0.0153 - val_loss: 0.0041\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 417us/step - loss: 0.0114 - val_loss: 0.0027\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 418us/step - loss: 0.0094 - val_loss: 0.0024\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 419us/step - loss: 0.0083 - val_loss: 0.0023\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 416us/step - loss: 0.0076 - val_loss: 0.0024\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 424us/step - loss: 0.0075 - val_loss: 0.0025\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 417us/step - loss: 0.0066 - val_loss: 0.0027\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 421us/step - loss: 0.0067 - val_loss: 0.0032\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 420us/step - loss: 0.0064 - val_loss: 0.0031\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 420us/step - loss: 0.0064 - val_loss: 0.0025\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 424us/step - loss: 0.0060 - val_loss: 0.0030\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 423us/step - loss: 0.0061 - val_loss: 0.0028\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 415us/step - loss: 0.0058 - val_loss: 0.0030\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 420us/step - loss: 0.0059 - val_loss: 0.0029\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 421us/step - loss: 0.0059 - val_loss: 0.0029\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 417us/step - loss: 0.0057 - val_loss: 0.0027\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 425us/step - loss: 0.0058 - val_loss: 0.0031\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 424us/step - loss: 0.0057 - val_loss: 0.0029\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 425us/step - loss: 0.0054 - val_loss: 0.0029\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 421us/step - loss: 0.0055 - val_loss: 0.0033\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 420us/step - loss: 0.0053 - val_loss: 0.0031\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 16s 4ms/step - loss: 0.1162 - val_loss: 0.0333\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 417us/step - loss: 0.0434 - val_loss: 0.0171\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 420us/step - loss: 0.0370 - val_loss: 0.0130\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 419us/step - loss: 0.0313 - val_loss: 0.0116\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 418us/step - loss: 0.0269 - val_loss: 0.0091\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 431us/step - loss: 0.0225 - val_loss: 0.0070\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 420us/step - loss: 0.0188 - val_loss: 0.0055\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 417us/step - loss: 0.0155 - val_loss: 0.0041\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 422us/step - loss: 0.0125 - val_loss: 0.0036\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 419us/step - loss: 0.0107 - val_loss: 0.0030\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 424us/step - loss: 0.0087 - val_loss: 0.0027\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 424us/step - loss: 0.0083 - val_loss: 0.0025\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 417us/step - loss: 0.0072 - val_loss: 0.0026\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 422us/step - loss: 0.0065 - val_loss: 0.0027\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 421us/step - loss: 0.0060 - val_loss: 0.0029\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 425us/step - loss: 0.0057 - val_loss: 0.0030\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 421us/step - loss: 0.0055 - val_loss: 0.0032\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 423us/step - loss: 0.0053 - val_loss: 0.0031\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 418us/step - loss: 0.0052 - val_loss: 0.0033\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 428us/step - loss: 0.0051 - val_loss: 0.0036\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 418us/step - loss: 0.0053 - val_loss: 0.0037\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 419us/step - loss: 0.0048 - val_loss: 0.0037\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 418us/step - loss: 0.0049 - val_loss: 0.0040\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 420us/step - loss: 0.0050 - val_loss: 0.0037\n",
      "\n",
      "GENERATION 12\n",
      "\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 15s 4ms/step - loss: 0.1158 - val_loss: 0.0378\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 210us/step - loss: 0.0113 - val_loss: 0.0158\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 212us/step - loss: 0.0064 - val_loss: 0.0049\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 209us/step - loss: 0.0048 - val_loss: 0.0032\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 209us/step - loss: 0.0036 - val_loss: 0.0011\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 206us/step - loss: 0.0026 - val_loss: 0.0010\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 211us/step - loss: 0.0024 - val_loss: 0.0011\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 214us/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 210us/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 209us/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 209us/step - loss: 0.0020 - val_loss: 0.0010\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 210us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 216us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 210us/step - loss: 0.0018 - val_loss: 9.9133e-04\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 210us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 210us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 209us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 213us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 213us/step - loss: 0.0015 - val_loss: 0.0012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 209us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 208us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 208us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 15s 4ms/step - loss: 0.0777 - val_loss: 0.0129\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 206us/step - loss: 0.0077 - val_loss: 0.0052\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 209us/step - loss: 0.0035 - val_loss: 0.0054\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 208us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 209us/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 208us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 205us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 208us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 208us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 208us/step - loss: 9.5238e-04 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 207us/step - loss: 9.0869e-04 - val_loss: 9.7199e-04\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 205us/step - loss: 8.6268e-04 - val_loss: 9.3339e-04\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 214us/step - loss: 8.2041e-04 - val_loss: 9.3757e-04\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 211us/step - loss: 7.6047e-04 - val_loss: 7.8132e-04\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 213us/step - loss: 7.1570e-04 - val_loss: 7.3979e-04\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 207us/step - loss: 6.8479e-04 - val_loss: 7.1303e-04\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 208us/step - loss: 6.7264e-04 - val_loss: 7.5109e-04\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 205us/step - loss: 6.4225e-04 - val_loss: 6.9064e-04\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 209us/step - loss: 6.3030e-04 - val_loss: 6.7856e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 210us/step - loss: 6.2216e-04 - val_loss: 6.5892e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 207us/step - loss: 6.1059e-04 - val_loss: 6.4909e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 208us/step - loss: 6.1393e-04 - val_loss: 6.6382e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 206us/step - loss: 6.0078e-04 - val_loss: 6.7514e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 209us/step - loss: 5.9448e-04 - val_loss: 6.4950e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 15s 4ms/step - loss: 0.0269 - val_loss: 0.0032\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 208us/step - loss: 0.0048 - val_loss: 0.0031\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 209us/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 208us/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 211us/step - loss: 0.0026 - val_loss: 0.0020\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 208us/step - loss: 0.0029 - val_loss: 0.0018\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 209us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 211us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 209us/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 211us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 206us/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 210us/step - loss: 0.0016 - val_loss: 8.5213e-04\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 211us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 210us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 211us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 206us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 210us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 209us/step - loss: 0.0015 - val_loss: 0.0024\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 209us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 209us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 212us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 208us/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 209us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 214us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 15s 4ms/step - loss: 0.0665 - val_loss: 0.0068\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 207us/step - loss: 0.0075 - val_loss: 0.0031\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 208us/step - loss: 0.0036 - val_loss: 0.0011\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 207us/step - loss: 0.0025 - val_loss: 0.0011\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 205us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 208us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 209us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 208us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 207us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 205us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 208us/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 207us/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 209us/step - loss: 0.0015 - val_loss: 9.8855e-04\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 208us/step - loss: 0.0015 - val_loss: 9.8111e-04\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 206us/step - loss: 0.0015 - val_loss: 9.7751e-04\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 215us/step - loss: 0.0015 - val_loss: 9.5571e-04\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 210us/step - loss: 0.0014 - val_loss: 9.7272e-04\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 208us/step - loss: 0.0014 - val_loss: 9.1758e-04\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 210us/step - loss: 0.0014 - val_loss: 9.9466e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 207us/step - loss: 0.0013 - val_loss: 9.0708e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 205us/step - loss: 0.0013 - val_loss: 9.2264e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 209us/step - loss: 0.0013 - val_loss: 9.5828e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 207us/step - loss: 0.0012 - val_loss: 9.1452e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 208us/step - loss: 0.0012 - val_loss: 9.0951e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 17s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 442us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 439us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 437us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 431us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 432us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 432us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 436us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 432us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 429us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 438us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 437us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 430us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 432us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 443us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 430us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 440us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 432us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 431us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 431us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 439us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 435us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 432us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 435us/step - loss: nan - val_loss: nan\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 18s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 440us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 438us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 439us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 435us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 438us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 432us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 438us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 436us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 440us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 434us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 439us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 437us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 432us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 436us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 436us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 429us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 439us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 434us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 433us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 436us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 446us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 435us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 434us/step - loss: nan - val_loss: nan\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 18s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 425us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 444us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 441us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 445us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 425us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 411us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 408us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 415us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 416us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 406us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 410us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 410us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 409us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 406us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 412us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 410us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 408us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 409us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 406us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 409us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 410us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 411us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 413us/step - loss: nan - val_loss: nan\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 17s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 553us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 558us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 557us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 555us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 559us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 554us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 555us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 559us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 554us/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 557us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 559us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 553us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 557us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 557us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 554us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 556us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 555us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 556us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 556us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 557us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 551us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 556us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 555us/step - loss: nan - val_loss: nan\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 18s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 557us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 555us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 560us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 558us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 553us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 562us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 601us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 598us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 597us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 596us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 592us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 591us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 603us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 593us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 594us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 593us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 594us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 591us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 597us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 594us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 593us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 595us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 591us/step - loss: nan - val_loss: nan\n",
      "\n",
      "GENERATION 13\n",
      "\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 19s 5ms/step - loss: 0.0729 - val_loss: 0.0234\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 417us/step - loss: 0.0123 - val_loss: 0.0137\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 418us/step - loss: 0.0049 - val_loss: 0.0024\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 415us/step - loss: 0.0028 - val_loss: 0.0020\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 417us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 414us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 416us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 417us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 419us/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 420us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 418us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 416us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 418us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 413us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 423us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 416us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 414us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 420us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 422us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 415us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 416us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 413us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 415us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 417us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 18s 5ms/step - loss: 0.0571 - val_loss: 0.0098\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 213us/step - loss: 0.0066 - val_loss: 0.0033\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 211us/step - loss: 0.0028 - val_loss: 0.0015\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 208us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 211us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 214us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 211us/step - loss: 0.0010 - val_loss: 9.7582e-04\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 210us/step - loss: 9.2134e-04 - val_loss: 9.7522e-04\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 209us/step - loss: 8.8546e-04 - val_loss: 9.6008e-04\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 205us/step - loss: 8.5726e-04 - val_loss: 9.1500e-04\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 210us/step - loss: 8.3196e-04 - val_loss: 8.8353e-04\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 209us/step - loss: 7.9965e-04 - val_loss: 8.3722e-04\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 211us/step - loss: 7.7007e-04 - val_loss: 8.1016e-04\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 212us/step - loss: 7.4561e-04 - val_loss: 7.9383e-04\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 209us/step - loss: 7.2094e-04 - val_loss: 7.7512e-04\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 207us/step - loss: 7.0522e-04 - val_loss: 7.4381e-04\n",
      "Epoch 17/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 1s 210us/step - loss: 6.8470e-04 - val_loss: 7.2862e-04\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 215us/step - loss: 6.7308e-04 - val_loss: 7.6374e-04\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 215us/step - loss: 6.7567e-04 - val_loss: 7.0208e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 209us/step - loss: 6.5417e-04 - val_loss: 6.9584e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 207us/step - loss: 6.5047e-04 - val_loss: 6.9540e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 209us/step - loss: 6.3794e-04 - val_loss: 6.8069e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 210us/step - loss: 6.2914e-04 - val_loss: 6.6531e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 211us/step - loss: 6.2115e-04 - val_loss: 6.6401e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 18s 5ms/step - loss: 0.2345 - val_loss: 0.2390\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 210us/step - loss: 0.0693 - val_loss: 0.0028\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 215us/step - loss: 0.0442 - val_loss: 0.0089\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 214us/step - loss: 0.0273 - val_loss: 0.0078\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 0.0213 - val_loss: 0.0120\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 207us/step - loss: 0.0147 - val_loss: 0.0159\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 211us/step - loss: 0.0136 - val_loss: 0.0204\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 208us/step - loss: 0.0130 - val_loss: 0.0170\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 209us/step - loss: 0.0133 - val_loss: 0.0121\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 210us/step - loss: 0.0108 - val_loss: 0.0142\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 211us/step - loss: 0.0106 - val_loss: 0.0133\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 207us/step - loss: 0.0110 - val_loss: 0.0131\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 211us/step - loss: 0.0090 - val_loss: 0.0142\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 210us/step - loss: 0.0095 - val_loss: 0.0135\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 210us/step - loss: 0.0082 - val_loss: 0.0081\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 209us/step - loss: 0.0082 - val_loss: 0.0121\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 208us/step - loss: 0.0073 - val_loss: 0.0092\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 212us/step - loss: 0.0084 - val_loss: 0.0059\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 209us/step - loss: 0.0060 - val_loss: 0.0086\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 211us/step - loss: 0.0075 - val_loss: 0.0104\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 209us/step - loss: 0.0051 - val_loss: 0.0074\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 210us/step - loss: 0.0075 - val_loss: 0.0070\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 215us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 210us/step - loss: 0.0068 - val_loss: 0.0089\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 20s 5ms/step - loss: 2.7907 - val_loss: 2.3935\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 514us/step - loss: 1.6278 - val_loss: 1.6371\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 514us/step - loss: 1.0878 - val_loss: 1.1510\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 510us/step - loss: 0.7366 - val_loss: 0.8106\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 511us/step - loss: 0.4974 - val_loss: 0.5662\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 517us/step - loss: 0.3332 - val_loss: 0.3889\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 511us/step - loss: 0.2219 - val_loss: 0.2610\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 525us/step - loss: 0.1493 - val_loss: 0.1712\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 517us/step - loss: 0.1053 - val_loss: 0.1106\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 515us/step - loss: 0.0819 - val_loss: 0.0730\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 517us/step - loss: 0.0716 - val_loss: 0.0513\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 515us/step - loss: 0.0684 - val_loss: 0.0413\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 517us/step - loss: 0.0678 - val_loss: 0.0383\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 520us/step - loss: 0.0677 - val_loss: 0.0368\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 522us/step - loss: 0.0678 - val_loss: 0.0336\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 523us/step - loss: 0.0678 - val_loss: 0.0395\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 514us/step - loss: 0.0677 - val_loss: 0.0322\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 514us/step - loss: 0.0678 - val_loss: 0.0393\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 520us/step - loss: 0.0679 - val_loss: 0.0280\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 517us/step - loss: 0.0681 - val_loss: 0.0378\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 516us/step - loss: 0.0679 - val_loss: 0.0407\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 512us/step - loss: 0.0678 - val_loss: 0.0289\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 515us/step - loss: 0.0681 - val_loss: 0.0372\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 514us/step - loss: 0.0677 - val_loss: 0.0415\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 20s 5ms/step - loss: 0.1250 - val_loss: 0.0328\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 522us/step - loss: 0.0685 - val_loss: 0.0297\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 521us/step - loss: 0.0676 - val_loss: 0.0367\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 524us/step - loss: 0.0664 - val_loss: 0.0244\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 513us/step - loss: 0.0609 - val_loss: 0.0167\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 513us/step - loss: 0.0286 - val_loss: 0.0083\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 511us/step - loss: 0.0294 - val_loss: 0.0343\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 513us/step - loss: 0.0280 - val_loss: 0.0182\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 514us/step - loss: 0.0137 - val_loss: 0.0154\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 513us/step - loss: 0.0112 - val_loss: 0.0113\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 514us/step - loss: 0.0180 - val_loss: 0.0061\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 522us/step - loss: 0.0197 - val_loss: 0.0253\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 513us/step - loss: 0.0093 - val_loss: 0.0141\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 519us/step - loss: 0.0071 - val_loss: 0.0190\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 519us/step - loss: 0.0098 - val_loss: 0.0351\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 512us/step - loss: 0.0118 - val_loss: 0.0030\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 514us/step - loss: 0.0032 - val_loss: 0.0302\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 512us/step - loss: 0.0132 - val_loss: 0.0106\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 511us/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 525us/step - loss: 0.0051 - val_loss: 0.0422\n",
      "Epoch 21/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 2s 511us/step - loss: 0.0206 - val_loss: 0.0289\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 513us/step - loss: 0.0043 - val_loss: 0.0024\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 512us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 512us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 21s 5ms/step - loss: 8.7404 - val_loss: 0.0121\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 514us/step - loss: 0.0727 - val_loss: 0.0294\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 517us/step - loss: 0.0685 - val_loss: 0.0581\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 514us/step - loss: 0.0669 - val_loss: 0.0421\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 515us/step - loss: 0.0669 - val_loss: 0.1226\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 520us/step - loss: 0.0748 - val_loss: 0.1930\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 515us/step - loss: 0.0577 - val_loss: 0.1379\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 513us/step - loss: 0.1207 - val_loss: 0.0459\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 515us/step - loss: 0.0590 - val_loss: 0.0434\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 515us/step - loss: 0.0693 - val_loss: 0.0238\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 516us/step - loss: 0.0315 - val_loss: 0.0040\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 515us/step - loss: 0.1024 - val_loss: 0.0299\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 519us/step - loss: 0.0631 - val_loss: 0.0420\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 522us/step - loss: 0.0603 - val_loss: 0.1238\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 518us/step - loss: 0.0728 - val_loss: 0.1194\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 518us/step - loss: 0.0610 - val_loss: 0.0487\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 518us/step - loss: 0.0387 - val_loss: 0.0060\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 517us/step - loss: 0.0110 - val_loss: 0.0056\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 517us/step - loss: 0.0281 - val_loss: 0.1464\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 517us/step - loss: 0.0383 - val_loss: 0.0111\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 516us/step - loss: 0.0089 - val_loss: 0.0173\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 521us/step - loss: 0.0082 - val_loss: 0.0172\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 519us/step - loss: 0.0074 - val_loss: 0.0108\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 514us/step - loss: 0.0151 - val_loss: 0.0932\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 21s 5ms/step - loss: 1.8015 - val_loss: 0.0172\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 514us/step - loss: 0.0285 - val_loss: 0.0620\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 516us/step - loss: 0.0318 - val_loss: 0.0047\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 516us/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 515us/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 515us/step - loss: 0.0051 - val_loss: 0.0045\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 517us/step - loss: 0.0043 - val_loss: 0.0069\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 512us/step - loss: 0.0052 - val_loss: 0.0108\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 512us/step - loss: 0.0054 - val_loss: 0.0119\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 512us/step - loss: 0.0052 - val_loss: 0.0062\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 513us/step - loss: 0.0040 - val_loss: 0.0049\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 520us/step - loss: 0.0041 - val_loss: 0.0064\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 513us/step - loss: 0.0039 - val_loss: 0.0053\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 511us/step - loss: 0.0037 - val_loss: 0.0059\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 518us/step - loss: 0.0049 - val_loss: 0.0089\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 511us/step - loss: 0.0053 - val_loss: 0.0106\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 511us/step - loss: 0.0047 - val_loss: 0.0083\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 511us/step - loss: 0.0039 - val_loss: 0.0051\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 513us/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 514us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 513us/step - loss: 0.0032 - val_loss: 0.0045\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 516us/step - loss: 0.0032 - val_loss: 0.0027\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 518us/step - loss: 0.0033 - val_loss: 0.0027\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 513us/step - loss: 0.0047 - val_loss: 0.0037\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 21s 5ms/step - loss: 1.0352 - val_loss: 0.0224\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 582us/step - loss: 0.0361 - val_loss: 0.1954\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 587us/step - loss: 0.0407 - val_loss: 0.0038\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 583us/step - loss: 0.0085 - val_loss: 0.0054\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 585us/step - loss: 0.0050 - val_loss: 0.0051\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 587us/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 584us/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 588us/step - loss: 0.0044 - val_loss: 0.0041\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 585us/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 588us/step - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 584us/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 584us/step - loss: 0.0039 - val_loss: 0.0042\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 592us/step - loss: 0.0038 - val_loss: 0.0041\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 585us/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 588us/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 583us/step - loss: 0.0037 - val_loss: 0.0033\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 588us/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 585us/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 585us/step - loss: 0.0037 - val_loss: 0.0031\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 588us/step - loss: 0.0036 - val_loss: 0.0031\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 580us/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 590us/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 584us/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 587us/step - loss: 0.0036 - val_loss: 0.0032\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 22s 6ms/step - loss: 0.1627 - val_loss: 0.0362\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 608us/step - loss: 0.0691 - val_loss: 0.0355\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 588us/step - loss: 0.0681 - val_loss: 0.0383\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 585us/step - loss: 0.0673 - val_loss: 0.0379\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 583us/step - loss: 0.0667 - val_loss: 0.0254\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 583us/step - loss: 0.0658 - val_loss: 0.0373\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 581us/step - loss: 0.0649 - val_loss: 0.0381\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 578us/step - loss: 0.0644 - val_loss: 0.0334\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 585us/step - loss: 0.0633 - val_loss: 0.0432\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 584us/step - loss: 0.0628 - val_loss: 0.0372\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 582us/step - loss: 0.0619 - val_loss: 0.0350\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 585us/step - loss: 0.0610 - val_loss: 0.0290\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 581us/step - loss: 0.0601 - val_loss: 0.0346\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 578us/step - loss: 0.0593 - val_loss: 0.0307\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 582us/step - loss: 0.0587 - val_loss: 0.0291\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 584us/step - loss: 0.0578 - val_loss: 0.0317\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 589us/step - loss: 0.0569 - val_loss: 0.0403\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 580us/step - loss: 0.0561 - val_loss: 0.0300\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 585us/step - loss: 0.0553 - val_loss: 0.0318\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 583us/step - loss: 0.0543 - val_loss: 0.0281\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 583us/step - loss: 0.0534 - val_loss: 0.0274\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 580us/step - loss: 0.0527 - val_loss: 0.0294\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 581us/step - loss: 0.0516 - val_loss: 0.0269\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 584us/step - loss: 0.0506 - val_loss: 0.0209\n",
      "\n",
      "GENERATION 14\n",
      "\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 20s 5ms/step - loss: 0.0711 - val_loss: 0.0086\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 0.0072 - val_loss: 0.0052\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 221us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 9.6765e-04 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 9.4135e-04 - val_loss: 9.9361e-04\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 9.2778e-04 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 221us/step - loss: 9.0102e-04 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 8.7451e-04 - val_loss: 9.4975e-04\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 8.4627e-04 - val_loss: 9.0984e-04\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 8.2605e-04 - val_loss: 9.1073e-04\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 7.8592e-04 - val_loss: 8.4031e-04\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 7.6049e-04 - val_loss: 7.9527e-04\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 7.3484e-04 - val_loss: 7.7151e-04\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 222us/step - loss: 7.2073e-04 - val_loss: 7.5879e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 6.9914e-04 - val_loss: 7.4061e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 7.0518e-04 - val_loss: 7.2319e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 6.7535e-04 - val_loss: 7.6417e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 221us/step - loss: 6.7162e-04 - val_loss: 7.0024e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 221us/step - loss: 6.5785e-04 - val_loss: 6.9639e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 20s 5ms/step - loss: 0.0584 - val_loss: 0.0023\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 210us/step - loss: 0.0054 - val_loss: 0.0022\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 210us/step - loss: 0.0029 - val_loss: 0.0020\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 210us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 209us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 212us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 212us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 211us/step - loss: 9.8878e-04 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 209us/step - loss: 9.5029e-04 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 209us/step - loss: 9.2777e-04 - val_loss: 0.0010\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 210us/step - loss: 8.9737e-04 - val_loss: 9.9782e-04\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 212us/step - loss: 8.6001e-04 - val_loss: 9.1083e-04\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 211us/step - loss: 8.3481e-04 - val_loss: 8.8240e-04\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 211us/step - loss: 8.1172e-04 - val_loss: 8.7121e-04\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 210us/step - loss: 7.9970e-04 - val_loss: 9.1442e-04\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 210us/step - loss: 7.8468e-04 - val_loss: 8.6049e-04\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 213us/step - loss: 7.5407e-04 - val_loss: 8.1088e-04\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 213us/step - loss: 7.3779e-04 - val_loss: 7.8079e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 211us/step - loss: 7.2036e-04 - val_loss: 7.8064e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 212us/step - loss: 7.0930e-04 - val_loss: 7.4611e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 208us/step - loss: 6.9936e-04 - val_loss: 7.3310e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 210us/step - loss: 6.7702e-04 - val_loss: 7.2265e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 211us/step - loss: 6.7090e-04 - val_loss: 7.0600e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 21s 5ms/step - loss: 0.0815 - val_loss: 0.0024\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 0.0127 - val_loss: 0.0056\n",
      "Epoch 3/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 1s 217us/step - loss: 0.0075 - val_loss: 0.0015\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 0.0051 - val_loss: 0.0028\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 0.0038 - val_loss: 0.0013\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 215us/step - loss: 0.0033 - val_loss: 0.0013\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 0.0028 - val_loss: 0.0013\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 216us/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 214us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 232us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 216us/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 0.0016 - val_loss: 0.0030\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 0.0015 - val_loss: 0.0033\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 20s 5ms/step - loss: 0.1489 - val_loss: 0.0483\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 263us/step - loss: 0.0170 - val_loss: 0.0086\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 265us/step - loss: 0.0072 - val_loss: 0.0017\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 266us/step - loss: 0.0046 - val_loss: 0.0031\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 262us/step - loss: 0.0033 - val_loss: 0.0024\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 269us/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 263us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 264us/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 261us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 262us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 264us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 270us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 264us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 263us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 264us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 268us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 262us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 263us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 263us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 264us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 264us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 261us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 262us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 265us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 21s 5ms/step - loss: 0.0901 - val_loss: 0.0016\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 267us/step - loss: 0.0108 - val_loss: 0.0016\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 263us/step - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 268us/step - loss: 0.0037 - val_loss: 0.0022\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 270us/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 264us/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 266us/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 266us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 267us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 262us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 263us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 266us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 266us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 264us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 265us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 266us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 264us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 262us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 264us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 269us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 263us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 264us/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 267us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 266us/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 21s 5ms/step - loss: 0.0801 - val_loss: 0.0019\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 262us/step - loss: 0.0062 - val_loss: 0.0088\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 265us/step - loss: 0.0082 - val_loss: 0.0139\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 261us/step - loss: 0.0088 - val_loss: 0.0057\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 260us/step - loss: 0.0084 - val_loss: 0.0036\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 264us/step - loss: 0.0066 - val_loss: 0.0061\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 264us/step - loss: 0.0062 - val_loss: 0.0039\n",
      "Epoch 8/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 1s 263us/step - loss: 0.0067 - val_loss: 0.0052\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 261us/step - loss: 0.0051 - val_loss: 0.0082\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 260us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 261us/step - loss: 0.0053 - val_loss: 0.0024\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 272us/step - loss: 0.0060 - val_loss: 0.0056\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 265us/step - loss: 0.0042 - val_loss: 0.0034\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 263us/step - loss: 0.0049 - val_loss: 0.0032\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 261us/step - loss: 0.0040 - val_loss: 0.0049\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 262us/step - loss: 0.0043 - val_loss: 0.0027\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 262us/step - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 264us/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 261us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 261us/step - loss: 0.0044 - val_loss: 0.0024\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 260us/step - loss: 0.0030 - val_loss: 0.0068\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 261us/step - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 263us/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 264us/step - loss: 0.0027 - val_loss: 0.0063\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 22s 6ms/step - loss: 0.1642 - val_loss: 0.0165\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 263us/step - loss: 0.0237 - val_loss: 0.0110\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 267us/step - loss: 0.0115 - val_loss: 0.0169\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 281us/step - loss: 0.0130 - val_loss: 0.0095\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 272us/step - loss: 0.0102 - val_loss: 0.0069\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 270us/step - loss: 0.0083 - val_loss: 0.0075\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 264us/step - loss: 0.0084 - val_loss: 0.0095\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 265us/step - loss: 0.0083 - val_loss: 0.0098\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 271us/step - loss: 0.0075 - val_loss: 0.0061\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 273us/step - loss: 0.0072 - val_loss: 0.0072\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 270us/step - loss: 0.0064 - val_loss: 0.0040\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 265us/step - loss: 0.0069 - val_loss: 0.0047\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 266us/step - loss: 0.0057 - val_loss: 0.0040\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 274us/step - loss: 0.0068 - val_loss: 0.0038\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 265us/step - loss: 0.0047 - val_loss: 0.0031\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 266us/step - loss: 0.0056 - val_loss: 0.0037\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 267us/step - loss: 0.0043 - val_loss: 0.0060\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 263us/step - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 269us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 275us/step - loss: 0.0046 - val_loss: 0.0026\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 269us/step - loss: 0.0050 - val_loss: 0.0023\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 266us/step - loss: 0.0033 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 267us/step - loss: 0.0041 - val_loss: 0.0053\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 265us/step - loss: 0.0041 - val_loss: 0.0013\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 21s 5ms/step - loss: 0.1904 - val_loss: 0.0160\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 264us/step - loss: 0.0295 - val_loss: 0.0185\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 263us/step - loss: 0.0166 - val_loss: 0.0221\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 265us/step - loss: 0.0085 - val_loss: 0.0020\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 267us/step - loss: 0.0053 - val_loss: 0.0071\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 263us/step - loss: 0.0037 - val_loss: 0.0012\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 264us/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 264us/step - loss: 0.0028 - val_loss: 0.0014\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 264us/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 267us/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 266us/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 267us/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 264us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 263us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 267us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 268us/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 261us/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 264us/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 267us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 265us/step - loss: 0.0017 - val_loss: 9.1264e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 265us/step - loss: 0.0016 - val_loss: 9.0925e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 265us/step - loss: 0.0015 - val_loss: 8.2055e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 262us/step - loss: 0.0016 - val_loss: 8.5311e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 260us/step - loss: 0.0015 - val_loss: 9.2477e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 22s 6ms/step - loss: 1.2068 - val_loss: 0.0043\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 268us/step - loss: 0.1174 - val_loss: 0.0791\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 266us/step - loss: 0.0570 - val_loss: 0.0188\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 265us/step - loss: 0.0262 - val_loss: 0.0066\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 265us/step - loss: 0.0128 - val_loss: 9.3562e-04\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 264us/step - loss: 0.0062 - val_loss: 0.0012\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 264us/step - loss: 0.0041 - val_loss: 9.9576e-04\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 266us/step - loss: 0.0032 - val_loss: 0.0012\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 267us/step - loss: 0.0028 - val_loss: 0.0010\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 263us/step - loss: 0.0026 - val_loss: 9.2404e-04\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 265us/step - loss: 0.0024 - val_loss: 8.9648e-04\n",
      "Epoch 12/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 1s 269us/step - loss: 0.0023 - val_loss: 8.7539e-04\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 265us/step - loss: 0.0023 - val_loss: 8.7502e-04\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 264us/step - loss: 0.0023 - val_loss: 8.6690e-04\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 269us/step - loss: 0.0023 - val_loss: 8.9745e-04\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 267us/step - loss: 0.0021 - val_loss: 8.8057e-04\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 265us/step - loss: 0.0021 - val_loss: 8.7336e-04\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 267us/step - loss: 0.0021 - val_loss: 8.7219e-04\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 266us/step - loss: 0.0020 - val_loss: 8.4460e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 264us/step - loss: 0.0020 - val_loss: 9.4147e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 265us/step - loss: 0.0019 - val_loss: 8.5134e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 268us/step - loss: 0.0019 - val_loss: 9.0064e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 266us/step - loss: 0.0020 - val_loss: 9.0334e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 265us/step - loss: 0.0020 - val_loss: 8.5638e-04\n",
      "\n",
      "GENERATION 15\n",
      "\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 21s 5ms/step - loss: 0.1524 - val_loss: 0.0170\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 215us/step - loss: 0.0129 - val_loss: 0.0167\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 210us/step - loss: 0.0095 - val_loss: 0.0145\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 212us/step - loss: 0.0088 - val_loss: 0.0103\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 213us/step - loss: 0.0077 - val_loss: 0.0026\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 214us/step - loss: 0.0079 - val_loss: 0.0128\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 0.0069 - val_loss: 0.0063\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 214us/step - loss: 0.0062 - val_loss: 0.0090\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 210us/step - loss: 0.0053 - val_loss: 0.0130\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 214us/step - loss: 0.0057 - val_loss: 0.0036\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 213us/step - loss: 0.0053 - val_loss: 0.0040\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 214us/step - loss: 0.0046 - val_loss: 0.0067\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 212us/step - loss: 0.0052 - val_loss: 0.0024\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 214us/step - loss: 0.0037 - val_loss: 0.0058\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 211us/step - loss: 0.0046 - val_loss: 0.0034\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 215us/step - loss: 0.0043 - val_loss: 0.0056\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 215us/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 214us/step - loss: 0.0038 - val_loss: 0.0053\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 0.0033 - val_loss: 0.0040\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 215us/step - loss: 0.0044 - val_loss: 0.0032\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 213us/step - loss: 0.0030 - val_loss: 0.0062\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 214us/step - loss: 0.0036 - val_loss: 0.0026\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 213us/step - loss: 0.0028 - val_loss: 0.0045\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 22s 6ms/step - loss: 0.1517 - val_loss: 0.0421\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 0.0126 - val_loss: 0.0097\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 222us/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 222us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 222us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 234us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 222us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 221us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 222us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 9.9205e-04 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 221us/step - loss: 9.6145e-04 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 9.4198e-04 - val_loss: 0.0010\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 221us/step - loss: 9.1714e-04 - val_loss: 9.8634e-04\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 8.8714e-04 - val_loss: 9.4858e-04\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 222us/step - loss: 8.6997e-04 - val_loss: 9.2095e-04\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 8.3805e-04 - val_loss: 9.0556e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 8.1740e-04 - val_loss: 8.7486e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 7.9760e-04 - val_loss: 8.4650e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 7.8100e-04 - val_loss: 8.2597e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 7.6024e-04 - val_loss: 8.2570e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 7.4646e-04 - val_loss: 8.2343e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 21s 6ms/step - loss: 0.0819 - val_loss: 0.0064\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 0.0081 - val_loss: 0.0043\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 222us/step - loss: 0.0042 - val_loss: 0.0054\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 0.0026 - val_loss: 0.0021\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 0.0019 - val_loss: 0.0010\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 222us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 221us/step - loss: 0.0016 - val_loss: 9.4383e-04\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 0.0014 - val_loss: 9.1608e-04\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 0.0014 - val_loss: 9.1289e-04\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 211us/step - loss: 0.0013 - val_loss: 8.8558e-04\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 216us/step - loss: 0.0013 - val_loss: 8.6989e-04\n",
      "Epoch 15/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 1s 213us/step - loss: 0.0013 - val_loss: 8.5263e-04\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 214us/step - loss: 0.0012 - val_loss: 8.4099e-04\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 208us/step - loss: 0.0012 - val_loss: 8.1982e-04\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 208us/step - loss: 0.0012 - val_loss: 8.4300e-04\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 205us/step - loss: 0.0011 - val_loss: 8.7167e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 209us/step - loss: 0.0011 - val_loss: 8.3800e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 209us/step - loss: 0.0011 - val_loss: 8.3554e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 207us/step - loss: 0.0011 - val_loss: 9.1090e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 208us/step - loss: 0.0011 - val_loss: 9.2640e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 206us/step - loss: 0.0011 - val_loss: 8.6687e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 21s 5ms/step - loss: 0.0782 - val_loss: 0.0018\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 248us/step - loss: 0.0119 - val_loss: 0.0015\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 247us/step - loss: 0.0045 - val_loss: 0.0057\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 248us/step - loss: 0.0028 - val_loss: 0.0019\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 250us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 248us/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 248us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 251us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 248us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 255us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 253us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 277us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 268us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 267us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 266us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 267us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 272us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 265us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 272us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 265us/step - loss: 0.0014 - val_loss: 9.9272e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 271us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 265us/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 283us/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 279us/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 21s 5ms/step - loss: 0.0724 - val_loss: 0.0028\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 253us/step - loss: 0.0177 - val_loss: 0.0032\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 262us/step - loss: 0.0068 - val_loss: 0.0030\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 254us/step - loss: 0.0056 - val_loss: 0.0071\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 270us/step - loss: 0.0043 - val_loss: 0.0016\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 254us/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 252us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 257us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 255us/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 255us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 256us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 258us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 272us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 272us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 272us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 270us/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 256us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 261us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 254us/step - loss: 0.0011 - val_loss: 9.8179e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 254us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 251us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 252us/step - loss: 0.0011 - val_loss: 8.8584e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 265us/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 268us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 21s 5ms/step - loss: 0.0809 - val_loss: 0.0026\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 256us/step - loss: 0.0180 - val_loss: 0.0019\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 256us/step - loss: 0.0076 - val_loss: 0.0025\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 255us/step - loss: 0.0053 - val_loss: 0.0076\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 259us/step - loss: 0.0043 - val_loss: 0.0017\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 262us/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 254us/step - loss: 0.0031 - val_loss: 0.0022\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 255us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 254us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 257us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 257us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 258us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 254us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 257us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 255us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 256us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 255us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 256us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 19/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 1s 257us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 255us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 255us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 258us/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 254us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 253us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 21s 5ms/step - loss: 0.2076 - val_loss: 0.0126\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 252us/step - loss: 0.0272 - val_loss: 0.0037\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 252us/step - loss: 0.0081 - val_loss: 0.0061\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 252us/step - loss: 0.0039 - val_loss: 0.0089\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 250us/step - loss: 0.0048 - val_loss: 0.0106\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 250us/step - loss: 0.0028 - val_loss: 0.0076\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 250us/step - loss: 0.0032 - val_loss: 0.0074\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 252us/step - loss: 0.0030 - val_loss: 0.0061\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 254us/step - loss: 0.0026 - val_loss: 0.0089\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 256us/step - loss: 0.0027 - val_loss: 0.0077\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 256us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 255us/step - loss: 0.0019 - val_loss: 0.0035\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 259us/step - loss: 0.0024 - val_loss: 0.0113\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 263us/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 253us/step - loss: 0.0022 - val_loss: 0.0078\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 256us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 255us/step - loss: 0.0017 - val_loss: 0.0034\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 255us/step - loss: 0.0017 - val_loss: 0.0027\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 256us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 255us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 255us/step - loss: 0.0019 - val_loss: 0.0048\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 255us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 258us/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 255us/step - loss: 0.0020 - val_loss: 0.0059\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 22s 6ms/step - loss: 0.0518 - val_loss: 0.0049\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 256us/step - loss: 0.0062 - val_loss: 0.0052\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 257us/step - loss: 0.0052 - val_loss: 0.0088\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 256us/step - loss: 0.0064 - val_loss: 0.0215\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 260us/step - loss: 0.0093 - val_loss: 0.0216\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 256us/step - loss: 0.0077 - val_loss: 0.0171\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 257us/step - loss: 0.0055 - val_loss: 0.0073\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 255us/step - loss: 0.0039 - val_loss: 0.0034\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 253us/step - loss: 0.0035 - val_loss: 0.0080\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 257us/step - loss: 0.0080 - val_loss: 0.0296\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 256us/step - loss: 0.0096 - val_loss: 0.0128\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 255us/step - loss: 0.0043 - val_loss: 0.0070\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 256us/step - loss: 0.0038 - val_loss: 0.0106\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 255us/step - loss: 0.0048 - val_loss: 0.0114\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 255us/step - loss: 0.0049 - val_loss: 0.0161\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 254us/step - loss: 0.0067 - val_loss: 0.0103\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 254us/step - loss: 0.0047 - val_loss: 0.0089\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 253us/step - loss: 0.0043 - val_loss: 0.0108\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 253us/step - loss: 0.0047 - val_loss: 0.0125\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 254us/step - loss: 0.0067 - val_loss: 0.0146\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 258us/step - loss: 0.0049 - val_loss: 0.0094\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 254us/step - loss: 0.0035 - val_loss: 0.0069\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 253us/step - loss: 0.0038 - val_loss: 0.0099\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 254us/step - loss: 0.0054 - val_loss: 0.0144\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 22s 6ms/step - loss: 0.0645 - val_loss: 0.0027\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 255us/step - loss: 0.0069 - val_loss: 0.0038\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 255us/step - loss: 0.0056 - val_loss: 0.0018\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 254us/step - loss: 0.0084 - val_loss: 0.0018\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 252us/step - loss: 0.0058 - val_loss: 0.0018\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 251us/step - loss: 0.0052 - val_loss: 0.0025\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 253us/step - loss: 0.0055 - val_loss: 0.0017\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 256us/step - loss: 0.0066 - val_loss: 0.0016\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 255us/step - loss: 0.0075 - val_loss: 0.0017\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 256us/step - loss: 0.0051 - val_loss: 0.0015\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 257us/step - loss: 0.0059 - val_loss: 0.0015\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 257us/step - loss: 0.0059 - val_loss: 0.0018\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 256us/step - loss: 0.0047 - val_loss: 0.0016\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 257us/step - loss: 0.0042 - val_loss: 0.0013\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 256us/step - loss: 0.0059 - val_loss: 0.0025\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 256us/step - loss: 0.0055 - val_loss: 0.0016\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 261us/step - loss: 0.0048 - val_loss: 0.0018\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 255us/step - loss: 0.0030 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 255us/step - loss: 0.0033 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 256us/step - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 256us/step - loss: 0.0042 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 255us/step - loss: 0.0036 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 256us/step - loss: 0.0051 - val_loss: 0.0017\n",
      "Epoch 24/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 1s 256us/step - loss: 0.0038 - val_loss: 0.0011\n",
      "\n",
      "GENERATION 16\n",
      "\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 21s 5ms/step - loss: 0.0664 - val_loss: 0.0027\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 199us/step - loss: 0.0052 - val_loss: 0.0025\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 200us/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 194us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 195us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 194us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 192us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 189us/step - loss: 9.7580e-04 - val_loss: 0.0011\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 192us/step - loss: 9.3501e-04 - val_loss: 0.0010\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 194us/step - loss: 9.1447e-04 - val_loss: 0.0010\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 192us/step - loss: 8.9948e-04 - val_loss: 0.0010\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 8.8446e-04 - val_loss: 9.8753e-04\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 192us/step - loss: 8.6851e-04 - val_loss: 9.9797e-04\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 192us/step - loss: 8.5404e-04 - val_loss: 9.6659e-04\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 191us/step - loss: 8.3581e-04 - val_loss: 9.4693e-04\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 190us/step - loss: 8.2006e-04 - val_loss: 9.0125e-04\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 193us/step - loss: 8.0251e-04 - val_loss: 9.1657e-04\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 191us/step - loss: 7.8505e-04 - val_loss: 8.8560e-04\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 192us/step - loss: 7.6813e-04 - val_loss: 8.4926e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 192us/step - loss: 7.5058e-04 - val_loss: 8.6733e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 194us/step - loss: 7.3091e-04 - val_loss: 8.0298e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 192us/step - loss: 7.1659e-04 - val_loss: 7.7062e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 194us/step - loss: 7.0344e-04 - val_loss: 7.6244e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 195us/step - loss: 6.9420e-04 - val_loss: 7.5405e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 22s 6ms/step - loss: 0.0831 - val_loss: 0.0282\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 199us/step - loss: 0.0092 - val_loss: 0.0073\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 195us/step - loss: 0.0032 - val_loss: 0.0043\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 198us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 198us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 197us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 196us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 197us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 199us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 196us/step - loss: 9.8225e-04 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 195us/step - loss: 9.4666e-04 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 197us/step - loss: 9.2794e-04 - val_loss: 0.0010\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 197us/step - loss: 9.2027e-04 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 198us/step - loss: 8.9337e-04 - val_loss: 9.8771e-04\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 196us/step - loss: 8.7312e-04 - val_loss: 9.8140e-04\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 195us/step - loss: 8.5658e-04 - val_loss: 0.0010\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 197us/step - loss: 8.4649e-04 - val_loss: 0.0010\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 200us/step - loss: 8.3736e-04 - val_loss: 9.6707e-04\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 202us/step - loss: 8.1172e-04 - val_loss: 9.9101e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 194us/step - loss: 8.0421e-04 - val_loss: 9.1198e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 196us/step - loss: 7.9044e-04 - val_loss: 8.7776e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 197us/step - loss: 7.6900e-04 - val_loss: 8.5271e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 197us/step - loss: 7.5160e-04 - val_loss: 8.5401e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 194us/step - loss: 7.3901e-04 - val_loss: 8.2840e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 22s 6ms/step - loss: 0.0962 - val_loss: 0.0096\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 199us/step - loss: 0.0254 - val_loss: 0.0156\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 201us/step - loss: 0.0102 - val_loss: 0.0057\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 198us/step - loss: 0.0059 - val_loss: 0.0032\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 199us/step - loss: 0.0050 - val_loss: 0.0034\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 199us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 202us/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 197us/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 202us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 200us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 201us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 205us/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 197us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 202us/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 201us/step - loss: 9.8818e-04 - val_loss: 0.0013\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 201us/step - loss: 9.3384e-04 - val_loss: 0.0010\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 198us/step - loss: 8.8842e-04 - val_loss: 8.6855e-04\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 198us/step - loss: 8.4786e-04 - val_loss: 0.0010\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 200us/step - loss: 8.0180e-04 - val_loss: 8.6618e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 201us/step - loss: 7.8854e-04 - val_loss: 7.8549e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 206us/step - loss: 7.7543e-04 - val_loss: 8.2596e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 198us/step - loss: 7.5406e-04 - val_loss: 8.0019e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 199us/step - loss: 7.4549e-04 - val_loss: 7.4174e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 200us/step - loss: 7.3125e-04 - val_loss: 8.2819e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 24s 6ms/step - loss: 0.0427 - val_loss: 0.0162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 422us/step - loss: 0.0131 - val_loss: 0.0048\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 415us/step - loss: 0.0044 - val_loss: 0.0031\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 420us/step - loss: 0.0097 - val_loss: 0.0072\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 419us/step - loss: 0.0051 - val_loss: 0.0031\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 419us/step - loss: 0.0031 - val_loss: 0.0025\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 419us/step - loss: 0.0064 - val_loss: 0.0073\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 417us/step - loss: 0.0055 - val_loss: 0.0017\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 417us/step - loss: 0.0048 - val_loss: 0.0025\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 421us/step - loss: 0.0045 - val_loss: 0.0016\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 417us/step - loss: 0.0028 - val_loss: 0.0015\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 422us/step - loss: 0.0055 - val_loss: 0.0016\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 415us/step - loss: 0.0041 - val_loss: 0.0015\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 421us/step - loss: 0.0029 - val_loss: 0.0015\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 415us/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 417us/step - loss: 0.0039 - val_loss: 0.0032\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 419us/step - loss: 0.0045 - val_loss: 0.0014\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 422us/step - loss: 0.0024 - val_loss: 0.0014\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 417us/step - loss: 0.0037 - val_loss: 0.0023\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 425us/step - loss: 0.0032 - val_loss: 0.0018\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 425us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 416us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 426us/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 417us/step - loss: 0.0043 - val_loss: 0.0012\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 24s 6ms/step - loss: 0.0493 - val_loss: 0.1142\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 427us/step - loss: 0.0307 - val_loss: 0.0062\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 417us/step - loss: 0.0050 - val_loss: 0.0029\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 415us/step - loss: 0.0127 - val_loss: 0.0052\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 419us/step - loss: 0.0039 - val_loss: 0.0058\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 419us/step - loss: 0.0032 - val_loss: 0.0052\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 419us/step - loss: 0.0032 - val_loss: 0.0023\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 424us/step - loss: 0.0053 - val_loss: 0.0023\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 417us/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 418us/step - loss: 0.0028 - val_loss: 0.0021\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 417us/step - loss: 0.0034 - val_loss: 0.0021\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 418us/step - loss: 0.0040 - val_loss: 0.0023\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 422us/step - loss: 0.0033 - val_loss: 0.0028\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 422us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 417us/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 417us/step - loss: 0.0043 - val_loss: 0.0018\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 417us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 418us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 423us/step - loss: 0.0028 - val_loss: 0.0021\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 417us/step - loss: 0.0032 - val_loss: 0.0018\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 424us/step - loss: 0.0029 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 420us/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 417us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 420us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 25s 6ms/step - loss: 0.0571 - val_loss: 0.0023\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 590us/step - loss: 0.0134 - val_loss: 0.0023\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 584us/step - loss: 0.0044 - val_loss: 0.0038\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 585us/step - loss: 0.0037 - val_loss: 0.0027\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 585us/step - loss: 0.0064 - val_loss: 0.0058\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 584us/step - loss: 0.0054 - val_loss: 0.0018\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 585us/step - loss: 0.0034 - val_loss: 0.0019\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 583us/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 589us/step - loss: 0.0046 - val_loss: 0.0022\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 585us/step - loss: 0.0032 - val_loss: 0.0027\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 585us/step - loss: 0.0055 - val_loss: 0.0026\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 589us/step - loss: 0.0036 - val_loss: 0.0016\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 587us/step - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 3s 649us/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 585us/step - loss: 0.0049 - val_loss: 0.0016\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 593us/step - loss: 0.0026 - val_loss: 0.0014\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 583us/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 583us/step - loss: 0.0036 - val_loss: 0.0021\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 586us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 589us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 155us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 589us/step - loss: 0.0055 - val_loss: 0.0025\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 589us/step - loss: 0.0031 - val_loss: 0.0012\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 584us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 26s 7ms/step - loss: 0.0323 - val_loss: 0.0027\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 591us/step - loss: 0.0060 - val_loss: 0.0039\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 585us/step - loss: 0.0049 - val_loss: 0.0022\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 583us/step - loss: 0.0123 - val_loss: 0.0039\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 586us/step - loss: 0.0067 - val_loss: 0.0023\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 583us/step - loss: 0.0044 - val_loss: 0.0023\n",
      "Epoch 7/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 2s 586us/step - loss: 0.0081 - val_loss: 0.0040\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 587us/step - loss: 0.0071 - val_loss: 0.0020\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 587us/step - loss: 0.0049 - val_loss: 0.0020\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 587us/step - loss: 0.0056 - val_loss: 0.0023\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 585us/step - loss: 0.0054 - val_loss: 0.0023\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 587us/step - loss: 0.0056 - val_loss: 0.0019\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 584us/step - loss: 0.0054 - val_loss: 0.0024\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 586us/step - loss: 0.0058 - val_loss: 0.0030\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 592us/step - loss: 0.0067 - val_loss: 0.0047\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 588us/step - loss: 0.0057 - val_loss: 0.0027\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 587us/step - loss: 0.0048 - val_loss: 0.0018\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 584us/step - loss: 0.0042 - val_loss: 0.0017\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 629us/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 615us/step - loss: 0.0058 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 600us/step - loss: 0.0055 - val_loss: 0.0019\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 625us/step - loss: 0.0035 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 622us/step - loss: 0.0038 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 594us/step - loss: 0.0052 - val_loss: 0.0027\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 30s 8ms/step - loss: 0.0572 - val_loss: 0.0039\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 635us/step - loss: 0.0065 - val_loss: 0.0053\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 3s 646us/step - loss: 0.0083 - val_loss: 0.0258\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 635us/step - loss: 0.0103 - val_loss: 0.0091\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 642us/step - loss: 0.0056 - val_loss: 0.0053\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 638us/step - loss: 0.0047 - val_loss: 0.0081\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 3s 648us/step - loss: 0.0059 - val_loss: 0.0184\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 641us/step - loss: 0.0088 - val_loss: 0.0144\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 3s 645us/step - loss: 0.0065 - val_loss: 0.0116\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 633us/step - loss: 0.0066 - val_loss: 0.0138\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 3s 650us/step - loss: 0.0062 - val_loss: 0.0094\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 642us/step - loss: 0.0051 - val_loss: 0.0091\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 3s 652us/step - loss: 0.0045 - val_loss: 0.0114\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 636us/step - loss: 0.0063 - val_loss: 0.0129\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 3s 646us/step - loss: 0.0062 - val_loss: 0.0071\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 634us/step - loss: 0.0045 - val_loss: 0.0106\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 642us/step - loss: 0.0051 - val_loss: 0.0075\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 634us/step - loss: 0.0045 - val_loss: 0.0063\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 3s 644us/step - loss: 0.0060 - val_loss: 0.0126\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 633us/step - loss: 0.0052 - val_loss: 0.0079\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 3s 643us/step - loss: 0.0044 - val_loss: 0.0099\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 3s 644us/step - loss: 0.0043 - val_loss: 0.0085\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 3s 655us/step - loss: 0.0043 - val_loss: 0.0094\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 640us/step - loss: 0.0045 - val_loss: 0.0079\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 30s 8ms/step - loss: 0.0503 - val_loss: 0.0032\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 438us/step - loss: 0.0077 - val_loss: 0.0045\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 439us/step - loss: 0.0088 - val_loss: 0.0025\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 432us/step - loss: 0.0073 - val_loss: 0.0030\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 443us/step - loss: 0.0075 - val_loss: 0.0025\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 442us/step - loss: 0.0077 - val_loss: 0.0037\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 438us/step - loss: 0.0078 - val_loss: 0.0025\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 444us/step - loss: 0.0076 - val_loss: 0.0031\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 441us/step - loss: 0.0081 - val_loss: 0.0031\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 441us/step - loss: 0.0081 - val_loss: 0.0047\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 439us/step - loss: 0.0075 - val_loss: 0.0024\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 438us/step - loss: 0.0065 - val_loss: 0.0030\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 439us/step - loss: 0.0071 - val_loss: 0.0032\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 440us/step - loss: 0.0067 - val_loss: 0.0028\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 438us/step - loss: 0.0045 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 447us/step - loss: 0.0047 - val_loss: 0.0035\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 441us/step - loss: 0.0072 - val_loss: 0.0027\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 433us/step - loss: 0.0061 - val_loss: 0.0020\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 442us/step - loss: 0.0049 - val_loss: 0.0030\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 435us/step - loss: 0.0055 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 437us/step - loss: 0.0052 - val_loss: 0.0020\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 441us/step - loss: 0.0042 - val_loss: 0.0031\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 439us/step - loss: 0.0056 - val_loss: 0.0026\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 437us/step - loss: 0.0048 - val_loss: 0.0018\n",
      "\n",
      "GENERATION 17\n",
      "\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 31s 8ms/step - loss: 0.0774 - val_loss: 0.0257\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 470us/step - loss: 0.0135 - val_loss: 0.0147\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 458us/step - loss: 0.0066 - val_loss: 0.0028\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 462us/step - loss: 0.0041 - val_loss: 0.0024\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 458us/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 459us/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 465us/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 461us/step - loss: 0.0027 - val_loss: 0.0022\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 455us/step - loss: 0.0026 - val_loss: 0.0020\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 458us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 469us/step - loss: 0.0025 - val_loss: 0.0021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 460us/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 456us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 459us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 452us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 468us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 459us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 461us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 463us/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 452us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 465us/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 462us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 455us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 458us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 29s 7ms/step - loss: 0.0294 - val_loss: 0.0076\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 0.0028 - val_loss: 0.0016\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 221us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 221us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 9.9162e-04 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 221us/step - loss: 9.8098e-04 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 9.6701e-04 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 9.5384e-04 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 9.4081e-04 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 9.2804e-04 - val_loss: 0.0010\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 9.0221e-04 - val_loss: 9.7558e-04\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 8.9003e-04 - val_loss: 9.9491e-04\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 8.7824e-04 - val_loss: 9.6225e-04\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 8.6182e-04 - val_loss: 9.0031e-04\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 8.5916e-04 - val_loss: 9.4169e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 8.4354e-04 - val_loss: 9.1858e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 8.3307e-04 - val_loss: 8.7068e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 8.2204e-04 - val_loss: 8.7945e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 8.1187e-04 - val_loss: 8.6156e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 8.0292e-04 - val_loss: 8.6598e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 31s 8ms/step - loss: 0.0615 - val_loss: 0.0024\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 458us/step - loss: 0.0058 - val_loss: 0.0051\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 462us/step - loss: 0.0039 - val_loss: 0.0025\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 455us/step - loss: 0.0030 - val_loss: 0.0024\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 458us/step - loss: 0.0028 - val_loss: 0.0021\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 459us/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 460us/step - loss: 0.0026 - val_loss: 0.0020\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 461us/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 454us/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 456us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 459us/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 463us/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 460us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 455us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 458us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 465us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 457us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 463us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 460us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 456us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 466us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 463us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 460us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 455us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 31s 8ms/step - loss: 0.0810 - val_loss: 0.0302\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 472us/step - loss: 0.0154 - val_loss: 0.0141\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 458us/step - loss: 0.0072 - val_loss: 0.0047\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 466us/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 465us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 462us/step - loss: 0.0031 - val_loss: 0.0034\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 458us/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 457us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 460us/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 463us/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 468us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 463us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 457us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 460us/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 462us/step - loss: 0.0021 - val_loss: 0.0017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 464us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 455us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 463us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 462us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 464us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 463us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 460us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 463us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 459us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 31s 8ms/step - loss: 0.1523 - val_loss: 0.0898\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 447us/step - loss: 0.0543 - val_loss: 0.0294\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 450us/step - loss: 0.0367 - val_loss: 0.0153\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 448us/step - loss: 0.0315 - val_loss: 0.0111\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 443us/step - loss: 0.0282 - val_loss: 0.0087\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 441us/step - loss: 0.0247 - val_loss: 0.0074\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 440us/step - loss: 0.0211 - val_loss: 0.0061\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 442us/step - loss: 0.0183 - val_loss: 0.0051\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 441us/step - loss: 0.0162 - val_loss: 0.0044\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 446us/step - loss: 0.0140 - val_loss: 0.0037\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 442us/step - loss: 0.0121 - val_loss: 0.0032\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 439us/step - loss: 0.0102 - val_loss: 0.0030\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 442us/step - loss: 0.0092 - val_loss: 0.0027\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 435us/step - loss: 0.0079 - val_loss: 0.0026\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 440us/step - loss: 0.0070 - val_loss: 0.0026\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 446us/step - loss: 0.0064 - val_loss: 0.0027\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 435us/step - loss: 0.0058 - val_loss: 0.0028\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 438us/step - loss: 0.0052 - val_loss: 0.0029\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 442us/step - loss: 0.0049 - val_loss: 0.0030\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 446us/step - loss: 0.0045 - val_loss: 0.0031\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 436us/step - loss: 0.0044 - val_loss: 0.0033\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 440us/step - loss: 0.0042 - val_loss: 0.0034\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 440us/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 440us/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 33s 8ms/step - loss: 0.2315 - val_loss: 0.2719\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 585us/step - loss: 0.1586 - val_loss: 0.1860\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 590us/step - loss: 0.1143 - val_loss: 0.1292\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 591us/step - loss: 0.0878 - val_loss: 0.0926\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 587us/step - loss: 0.0724 - val_loss: 0.0694\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 591us/step - loss: 0.0636 - val_loss: 0.0540\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 589us/step - loss: 0.0583 - val_loss: 0.0435\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 583us/step - loss: 0.0550 - val_loss: 0.0363\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 586us/step - loss: 0.0529 - val_loss: 0.0314\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 588us/step - loss: 0.0509 - val_loss: 0.0279\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 588us/step - loss: 0.0492 - val_loss: 0.0251\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 585us/step - loss: 0.0477 - val_loss: 0.0228\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 590us/step - loss: 0.0460 - val_loss: 0.0212\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 588us/step - loss: 0.0447 - val_loss: 0.0200\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 588us/step - loss: 0.0433 - val_loss: 0.0187\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 584us/step - loss: 0.0421 - val_loss: 0.0175\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 587us/step - loss: 0.0408 - val_loss: 0.0166\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 589us/step - loss: 0.0395 - val_loss: 0.0156\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 589us/step - loss: 0.0380 - val_loss: 0.0148\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 590us/step - loss: 0.0367 - val_loss: 0.0138\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 589us/step - loss: 0.0355 - val_loss: 0.0131\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 589us/step - loss: 0.0340 - val_loss: 0.0120\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 586us/step - loss: 0.0325 - val_loss: 0.0113\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 589us/step - loss: 0.0311 - val_loss: 0.0105\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 33s 9ms/step - loss: 0.1784 - val_loss: 0.1510\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 585us/step - loss: 0.0841 - val_loss: 0.0643\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 586us/step - loss: 0.0539 - val_loss: 0.0335\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 585us/step - loss: 0.0452 - val_loss: 0.0217\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 583us/step - loss: 0.0417 - val_loss: 0.0172\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 589us/step - loss: 0.0391 - val_loss: 0.0148\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 587us/step - loss: 0.0369 - val_loss: 0.0137\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 584us/step - loss: 0.0348 - val_loss: 0.0124\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 586us/step - loss: 0.0323 - val_loss: 0.0117\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 590us/step - loss: 0.0299 - val_loss: 0.0108\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 587us/step - loss: 0.0281 - val_loss: 0.0097\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 583us/step - loss: 0.0259 - val_loss: 0.0086\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 587us/step - loss: 0.0243 - val_loss: 0.0076\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 591us/step - loss: 0.0218 - val_loss: 0.0072\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 591us/step - loss: 0.0202 - val_loss: 0.0063\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 585us/step - loss: 0.0181 - val_loss: 0.0056\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 586us/step - loss: 0.0169 - val_loss: 0.0048\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 587us/step - loss: 0.0150 - val_loss: 0.0044\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 586us/step - loss: 0.0135 - val_loss: 0.0041\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 586us/step - loss: 0.0126 - val_loss: 0.0037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 590us/step - loss: 0.0112 - val_loss: 0.0033\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 588us/step - loss: 0.0103 - val_loss: 0.0031\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 584us/step - loss: 0.0092 - val_loss: 0.0029\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 584us/step - loss: 0.0085 - val_loss: 0.0028\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 34s 9ms/step - loss: 0.1578 - val_loss: 0.1056\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 583us/step - loss: 0.0610 - val_loss: 0.0373\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 586us/step - loss: 0.0377 - val_loss: 0.0172\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 584us/step - loss: 0.0308 - val_loss: 0.0110\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 584us/step - loss: 0.0278 - val_loss: 0.0084\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 589us/step - loss: 0.0257 - val_loss: 0.0073\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 591us/step - loss: 0.0238 - val_loss: 0.0063\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 583us/step - loss: 0.0214 - val_loss: 0.0059\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 588us/step - loss: 0.0196 - val_loss: 0.0054\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 591us/step - loss: 0.0180 - val_loss: 0.0049\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 583us/step - loss: 0.0167 - val_loss: 0.0046\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 585us/step - loss: 0.0150 - val_loss: 0.0041\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 588us/step - loss: 0.0137 - val_loss: 0.0038\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 587us/step - loss: 0.0127 - val_loss: 0.0035\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 584us/step - loss: 0.0116 - val_loss: 0.0031\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 589us/step - loss: 0.0107 - val_loss: 0.0030\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 585us/step - loss: 0.0099 - val_loss: 0.0028\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 586us/step - loss: 0.0091 - val_loss: 0.0027\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 587us/step - loss: 0.0081 - val_loss: 0.0026\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 591us/step - loss: 0.0075 - val_loss: 0.0026\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 584us/step - loss: 0.0072 - val_loss: 0.0025\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 588us/step - loss: 0.0065 - val_loss: 0.0025\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 584us/step - loss: 0.0062 - val_loss: 0.0025\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 589us/step - loss: 0.0059 - val_loss: 0.0025\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 34s 9ms/step - loss: 0.2319 - val_loss: 0.2716\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 587us/step - loss: 0.1552 - val_loss: 0.1866\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 585us/step - loss: 0.1113 - val_loss: 0.1249\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 585us/step - loss: 0.0853 - val_loss: 0.0848\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 588us/step - loss: 0.0696 - val_loss: 0.0598\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 591us/step - loss: 0.0616 - val_loss: 0.0452\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 590us/step - loss: 0.0565 - val_loss: 0.0364\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 586us/step - loss: 0.0536 - val_loss: 0.0307\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 587us/step - loss: 0.0513 - val_loss: 0.0267\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 584us/step - loss: 0.0494 - val_loss: 0.0240\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 587us/step - loss: 0.0477 - val_loss: 0.0213\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 587us/step - loss: 0.0457 - val_loss: 0.0193\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 586us/step - loss: 0.0436 - val_loss: 0.0174\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 583us/step - loss: 0.0415 - val_loss: 0.0159\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 587us/step - loss: 0.0394 - val_loss: 0.0148\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 590us/step - loss: 0.0379 - val_loss: 0.0139\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 588us/step - loss: 0.0360 - val_loss: 0.0131\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 584us/step - loss: 0.0340 - val_loss: 0.0124\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 588us/step - loss: 0.0326 - val_loss: 0.0114\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 585us/step - loss: 0.0309 - val_loss: 0.0107\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 588us/step - loss: 0.0290 - val_loss: 0.0097\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 587us/step - loss: 0.0275 - val_loss: 0.0089\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 587us/step - loss: 0.0259 - val_loss: 0.0083\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 583us/step - loss: 0.0246 - val_loss: 0.0076\n",
      "\n",
      "GENERATION 18\n",
      "\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 33s 8ms/step - loss: 0.2195 - val_loss: 0.2056\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 0.1066 - val_loss: 0.0990\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 0.0640 - val_loss: 0.0540\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 0.0470 - val_loss: 0.0332\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 0.0396 - val_loss: 0.0239\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 0.0358 - val_loss: 0.0186\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 234us/step - loss: 0.0332 - val_loss: 0.0153\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 0.0310 - val_loss: 0.0130\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 0.0289 - val_loss: 0.0115\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 0.0269 - val_loss: 0.0103\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 0.0249 - val_loss: 0.0094\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 0.0230 - val_loss: 0.0084\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 221us/step - loss: 0.0211 - val_loss: 0.0077\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 0.0193 - val_loss: 0.0068\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 0.0175 - val_loss: 0.0061\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 0.0158 - val_loss: 0.0056\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 0.0143 - val_loss: 0.0050\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 0.0130 - val_loss: 0.0045\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 0.0117 - val_loss: 0.0040\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 0.0104 - val_loss: 0.0036\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 0.0093 - val_loss: 0.0032\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 0.0083 - val_loss: 0.0029\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 0.0073 - val_loss: 0.0026\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 232us/step - loss: 0.0065 - val_loss: 0.0023\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 31s 8ms/step - loss: 0.0318 - val_loss: 0.0100\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 0.0035 - val_loss: 0.0020\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 9.4568e-04 - val_loss: 9.6410e-04\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 9.0028e-04 - val_loss: 0.0011\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 8.7227e-04 - val_loss: 9.5247e-04\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 222us/step - loss: 8.3983e-04 - val_loss: 9.7940e-04\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 8.2426e-04 - val_loss: 9.0448e-04\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 8.0290e-04 - val_loss: 8.7447e-04\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 7.8831e-04 - val_loss: 8.5078e-04\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 7.7804e-04 - val_loss: 8.3108e-04\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 7.6179e-04 - val_loss: 8.4883e-04\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 222us/step - loss: 7.4812e-04 - val_loss: 8.1546e-04\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 222us/step - loss: 7.4027e-04 - val_loss: 7.9177e-04\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 221us/step - loss: 7.2627e-04 - val_loss: 7.7734e-04\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 7.2074e-04 - val_loss: 7.7926e-04\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 7.0637e-04 - val_loss: 7.7472e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 7.0099e-04 - val_loss: 7.7374e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 6.9059e-04 - val_loss: 7.4308e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 221us/step - loss: 6.8099e-04 - val_loss: 7.3721e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 222us/step - loss: 6.7436e-04 - val_loss: 7.3250e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 222us/step - loss: 6.6427e-04 - val_loss: 7.0438e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 33s 9ms/step - loss: 0.1118 - val_loss: 0.0042\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 263us/step - loss: 0.0153 - val_loss: 0.0058\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 264us/step - loss: 0.0076 - val_loss: 0.0018\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 263us/step - loss: 0.0050 - val_loss: 0.0030\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 264us/step - loss: 0.0037 - val_loss: 0.0016\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 267us/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 265us/step - loss: 0.0029 - val_loss: 0.0017\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 272us/step - loss: 0.0029 - val_loss: 0.0018\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 266us/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 266us/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 266us/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 264us/step - loss: 0.0026 - val_loss: 0.0020\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 266us/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 260us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 263us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 262us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 264us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 264us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 265us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 263us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 261us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 265us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 264us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 264us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 32s 8ms/step - loss: 0.1198 - val_loss: 0.0047\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 262us/step - loss: 0.0110 - val_loss: 0.0082\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 264us/step - loss: 0.0108 - val_loss: 0.0072\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 267us/step - loss: 0.0091 - val_loss: 0.0052\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 263us/step - loss: 0.0078 - val_loss: 0.0063\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 269us/step - loss: 0.0075 - val_loss: 0.0030\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 260us/step - loss: 0.0075 - val_loss: 0.0065\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 263us/step - loss: 0.0071 - val_loss: 0.0074\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 265us/step - loss: 0.0049 - val_loss: 0.0032\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 263us/step - loss: 0.0079 - val_loss: 0.0037\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 261us/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 263us/step - loss: 0.0059 - val_loss: 0.0029\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 269us/step - loss: 0.0045 - val_loss: 0.0026\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 266us/step - loss: 0.0052 - val_loss: 0.0026\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 268us/step - loss: 0.0047 - val_loss: 0.0025\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 264us/step - loss: 0.0042 - val_loss: 0.0049\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 265us/step - loss: 0.0043 - val_loss: 0.0016\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 265us/step - loss: 0.0045 - val_loss: 0.0021\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 265us/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 265us/step - loss: 0.0042 - val_loss: 0.0027\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 269us/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 265us/step - loss: 0.0034 - val_loss: 8.6023e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 266us/step - loss: 0.0041 - val_loss: 0.0014\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 268us/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 33s 9ms/step - loss: 0.1168 - val_loss: 0.0022\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 0.0065 - val_loss: 0.0047\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 0.0104 - val_loss: 0.0238\n",
      "Epoch 4/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 1s 218us/step - loss: 0.0082 - val_loss: 0.0149\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 211us/step - loss: 0.0073 - val_loss: 0.0110\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 214us/step - loss: 0.0076 - val_loss: 0.0149\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 0.0061 - val_loss: 0.0230\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 211us/step - loss: 0.0061 - val_loss: 0.0147\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 215us/step - loss: 0.0065 - val_loss: 0.0123\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 215us/step - loss: 0.0054 - val_loss: 0.0129\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 216us/step - loss: 0.0057 - val_loss: 0.0168\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 0.0034 - val_loss: 0.0060\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 0.0061 - val_loss: 0.0099\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 209us/step - loss: 0.0042 - val_loss: 0.0121\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 0.0046 - val_loss: 0.0097\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 215us/step - loss: 0.0040 - val_loss: 0.0053\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 215us/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 214us/step - loss: 0.0019 - val_loss: 0.0123\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 216us/step - loss: 0.0059 - val_loss: 0.0070\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 0.0028 - val_loss: 0.0093\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 210us/step - loss: 0.0042 - val_loss: 0.0114\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 0.0035 - val_loss: 0.0083\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 216us/step - loss: 0.0032 - val_loss: 0.0104\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 0.0038 - val_loss: 0.0108\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 33s 8ms/step - loss: 0.1179 - val_loss: 0.0014\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 0.0070 - val_loss: 0.0013\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 221us/step - loss: 0.0056 - val_loss: 0.0013\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 0.0144 - val_loss: 0.0161\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 0.0061 - val_loss: 0.0015\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 211us/step - loss: 0.0141 - val_loss: 0.0116\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 215us/step - loss: 0.0062 - val_loss: 0.0061\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 0.0105 - val_loss: 0.0028\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 215us/step - loss: 0.0084 - val_loss: 0.0046\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 216us/step - loss: 0.0063 - val_loss: 0.0125\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 216us/step - loss: 0.0085 - val_loss: 0.0040\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 215us/step - loss: 0.0054 - val_loss: 0.0120\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 0.0092 - val_loss: 0.0018\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 213us/step - loss: 0.0049 - val_loss: 0.0075\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 216us/step - loss: 0.0073 - val_loss: 0.0029\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 215us/step - loss: 0.0054 - val_loss: 0.0060\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 212us/step - loss: 0.0053 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 215us/step - loss: 0.0062 - val_loss: 0.0064\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 221us/step - loss: 0.0049 - val_loss: 0.0026\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 215us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 0.0044 - val_loss: 0.0035\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 215us/step - loss: 0.0047 - val_loss: 0.0024\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 0.0046 - val_loss: 0.0054\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 32s 8ms/step - loss: 0.0950 - val_loss: 0.0022\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 401us/step - loss: 0.0061 - val_loss: 0.0176\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 392us/step - loss: 0.0133 - val_loss: 0.0095\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 397us/step - loss: 0.0130 - val_loss: 0.0099\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 396us/step - loss: 0.0125 - val_loss: 0.0192\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 397us/step - loss: 0.0106 - val_loss: 0.0142\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 398us/step - loss: 0.0127 - val_loss: 0.0076\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 397us/step - loss: 0.0083 - val_loss: 0.0170\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 398us/step - loss: 0.0113 - val_loss: 0.0081\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 397us/step - loss: 0.0073 - val_loss: 0.0160\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 401us/step - loss: 0.0109 - val_loss: 0.0119\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 397us/step - loss: 0.0062 - val_loss: 0.0175\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 395us/step - loss: 0.0089 - val_loss: 0.0077\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 392us/step - loss: 0.0071 - val_loss: 0.0128\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 399us/step - loss: 0.0065 - val_loss: 0.0098\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 397us/step - loss: 0.0087 - val_loss: 0.0128\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 398us/step - loss: 0.0050 - val_loss: 0.0108\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 393us/step - loss: 0.0075 - val_loss: 0.0074\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 397us/step - loss: 0.0055 - val_loss: 0.0103\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 397us/step - loss: 0.0077 - val_loss: 0.0125\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 401us/step - loss: 0.0035 - val_loss: 0.0064\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 396us/step - loss: 0.0083 - val_loss: 0.0066\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 398us/step - loss: 0.0037 - val_loss: 0.0117\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 397us/step - loss: 0.0059 - val_loss: 0.0081\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 29s 7ms/step - loss: 0.1130 - val_loss: 0.0315\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 398us/step - loss: 0.0443 - val_loss: 0.0150\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 394us/step - loss: 0.0374 - val_loss: 0.0119\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 397us/step - loss: 0.0308 - val_loss: 0.0091\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 395us/step - loss: 0.0264 - val_loss: 0.0078\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 403us/step - loss: 0.0219 - val_loss: 0.0061\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 398us/step - loss: 0.0189 - val_loss: 0.0051\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 398us/step - loss: 0.0159 - val_loss: 0.0040\n",
      "Epoch 9/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 2s 396us/step - loss: 0.0137 - val_loss: 0.0032\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 400us/step - loss: 0.0118 - val_loss: 0.0030\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 403us/step - loss: 0.0098 - val_loss: 0.0027\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 394us/step - loss: 0.0087 - val_loss: 0.0026\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 397us/step - loss: 0.0083 - val_loss: 0.0026\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 397us/step - loss: 0.0071 - val_loss: 0.0026\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 400us/step - loss: 0.0071 - val_loss: 0.0027\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 395us/step - loss: 0.0064 - val_loss: 0.0027\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 405us/step - loss: 0.0062 - val_loss: 0.0028\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 400us/step - loss: 0.0060 - val_loss: 0.0031\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 398us/step - loss: 0.0057 - val_loss: 0.0031\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 396us/step - loss: 0.0054 - val_loss: 0.0032\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 394us/step - loss: 0.0056 - val_loss: 0.0034\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 396us/step - loss: 0.0054 - val_loss: 0.0033\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 395us/step - loss: 0.0053 - val_loss: 0.0035\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 399us/step - loss: 0.0054 - val_loss: 0.0035\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 31s 8ms/step - loss: 0.0753 - val_loss: 0.0078\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 435us/step - loss: 0.0178 - val_loss: 0.0038\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 441us/step - loss: 0.0103 - val_loss: 0.0027\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 435us/step - loss: 0.0073 - val_loss: 0.0025\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 433us/step - loss: 0.0056 - val_loss: 0.0025\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 430us/step - loss: 0.0050 - val_loss: 0.0027\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 443us/step - loss: 0.0047 - val_loss: 0.0028\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 433us/step - loss: 0.0044 - val_loss: 0.0028\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 443us/step - loss: 0.0046 - val_loss: 0.0033\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 440us/step - loss: 0.0046 - val_loss: 0.0031\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 432us/step - loss: 0.0044 - val_loss: 0.0034\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 434us/step - loss: 0.0045 - val_loss: 0.0030\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 435us/step - loss: 0.0043 - val_loss: 0.0032\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 441us/step - loss: 0.0042 - val_loss: 0.0031\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 433us/step - loss: 0.0043 - val_loss: 0.0031\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 432us/step - loss: 0.0041 - val_loss: 0.0031\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 439us/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 433us/step - loss: 0.0041 - val_loss: 0.0033\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 448us/step - loss: 0.0040 - val_loss: 0.0031\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 437us/step - loss: 0.0041 - val_loss: 0.0028\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 436us/step - loss: 0.0041 - val_loss: 0.0028\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 428us/step - loss: 0.0039 - val_loss: 0.0030\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 442us/step - loss: 0.0039 - val_loss: 0.0029\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 435us/step - loss: 0.0040 - val_loss: 0.0031\n",
      "\n",
      "GENERATION 19\n",
      "\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 29s 7ms/step - loss: 0.2095 - val_loss: 0.1264\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 207us/step - loss: 0.0619 - val_loss: 0.0339\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 204us/step - loss: 0.0287 - val_loss: 0.0115\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 204us/step - loss: 0.0210 - val_loss: 0.0056\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 201us/step - loss: 0.0181 - val_loss: 0.0039\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 204us/step - loss: 0.0160 - val_loss: 0.0031\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 204us/step - loss: 0.0144 - val_loss: 0.0026\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 204us/step - loss: 0.0129 - val_loss: 0.0024\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 202us/step - loss: 0.0115 - val_loss: 0.0022\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 203us/step - loss: 0.0106 - val_loss: 0.0021\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 206us/step - loss: 0.0097 - val_loss: 0.0019\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 206us/step - loss: 0.0087 - val_loss: 0.0018\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 206us/step - loss: 0.0076 - val_loss: 0.0017\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 200us/step - loss: 0.0070 - val_loss: 0.0017\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 205us/step - loss: 0.0065 - val_loss: 0.0016\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 204us/step - loss: 0.0059 - val_loss: 0.0015\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 207us/step - loss: 0.0053 - val_loss: 0.0015\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 207us/step - loss: 0.0050 - val_loss: 0.0015\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 202us/step - loss: 0.0048 - val_loss: 0.0015\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 205us/step - loss: 0.0043 - val_loss: 0.0015\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 206us/step - loss: 0.0041 - val_loss: 0.0015\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 210us/step - loss: 0.0037 - val_loss: 0.0015\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 205us/step - loss: 0.0037 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 201us/step - loss: 0.0035 - val_loss: 0.0015\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 29s 8ms/step - loss: 0.0511 - val_loss: 0.0036\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 1s 208us/step - loss: 0.0064 - val_loss: 0.0031\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 1s 205us/step - loss: 0.0029 - val_loss: 0.0043\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 1s 207us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 1s 207us/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 1s 204us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 1s 207us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 1s 205us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 1s 209us/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 1s 210us/step - loss: 9.9411e-04 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 1s 202us/step - loss: 9.8197e-04 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 1s 204us/step - loss: 9.6329e-04 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 1s 207us/step - loss: 9.4396e-04 - val_loss: 0.0011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 1s 204us/step - loss: 9.2179e-04 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 1s 206us/step - loss: 9.0268e-04 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 1s 203us/step - loss: 8.8490e-04 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 1s 205us/step - loss: 8.6869e-04 - val_loss: 0.0010\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 1s 205us/step - loss: 8.4666e-04 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 1s 206us/step - loss: 8.2939e-04 - val_loss: 9.6035e-04\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 1s 206us/step - loss: 8.0468e-04 - val_loss: 9.2796e-04\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 1s 202us/step - loss: 7.7746e-04 - val_loss: 8.5530e-04\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 1s 206us/step - loss: 7.3651e-04 - val_loss: 7.8523e-04\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 1s 206us/step - loss: 7.1749e-04 - val_loss: 7.6262e-04\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 1s 205us/step - loss: 7.0369e-04 - val_loss: 7.7102e-04\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 31s 8ms/step - loss: 0.1430 - val_loss: 0.0408\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 425us/step - loss: 0.0283 - val_loss: 0.0173\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 419us/step - loss: 0.0106 - val_loss: 0.0095\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 416us/step - loss: 0.0052 - val_loss: 0.0027\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 417us/step - loss: 0.0033 - val_loss: 0.0040\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 421us/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 415us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 425us/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 420us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 419us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 419us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 417us/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 429us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 432us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 436us/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 425us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 421us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 424us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 425us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 423us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 416us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 416us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 427us/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 422us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 35s 9ms/step - loss: 0.0885 - val_loss: 0.0342\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 424us/step - loss: 0.0167 - val_loss: 0.0203\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 421us/step - loss: 0.0075 - val_loss: 0.0056\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 416us/step - loss: 0.0042 - val_loss: 0.0063\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 417us/step - loss: 0.0030 - val_loss: 0.0026\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 413us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 421us/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 422us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 419us/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 421us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 411us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 420us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 417us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 412us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 421us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 432us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 422us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 416us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 419us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 417us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 420us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 418us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 418us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 418us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 38s 10ms/step - loss: 0.0698 - val_loss: 0.0287\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 425us/step - loss: 0.0121 - val_loss: 0.0124\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 419us/step - loss: 0.0061 - val_loss: 0.0042\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 419us/step - loss: 0.0038 - val_loss: 0.0052\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 416us/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 416us/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 420us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 423us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 426us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 420us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 416us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 416us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 427us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 417us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 419us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 418us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 413us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 18/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 2s 422us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 420us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 418us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 421us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 416us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 418us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 418us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 38s 10ms/step - loss: 0.1812 - val_loss: 0.0185\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 417us/step - loss: 0.0275 - val_loss: 0.0291\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 417us/step - loss: 0.0128 - val_loss: 0.0154\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 419us/step - loss: 0.0059 - val_loss: 0.0029\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 423us/step - loss: 0.0034 - val_loss: 0.0026\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 419us/step - loss: 0.0032 - val_loss: 0.0065\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 432us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 426us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 423us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 425us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 421us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 426us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 426us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 419us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 422us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 428us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 423us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 416us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 424us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 424us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 419us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 419us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 416us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 417us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 39s 10ms/step - loss: 0.2371 - val_loss: 0.1273\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 436us/step - loss: 0.0467 - val_loss: 0.0292\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 434us/step - loss: 0.0193 - val_loss: 0.0183\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 438us/step - loss: 0.0079 - val_loss: 0.0052\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 441us/step - loss: 0.0045 - val_loss: 0.0029\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 437us/step - loss: 0.0036 - val_loss: 0.0059\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 436us/step - loss: 0.0032 - val_loss: 0.0025\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 440us/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 447us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 442us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 438us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 443us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 439us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 436us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 438us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 444us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 434us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 443us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 449us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 438us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 439us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 438us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 439us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 438us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 39s 10ms/step - loss: 0.8449 - val_loss: 0.6441\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 437us/step - loss: 0.2900 - val_loss: 0.1941\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 432us/step - loss: 0.0944 - val_loss: 0.0409\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 440us/step - loss: 0.0706 - val_loss: 0.0110\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 437us/step - loss: 0.0793 - val_loss: 0.0104\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 433us/step - loss: 0.0749 - val_loss: 0.0207\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 439us/step - loss: 0.0686 - val_loss: 0.0360\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 441us/step - loss: 0.0680 - val_loss: 0.0457\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 444us/step - loss: 0.0682 - val_loss: 0.0441\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 434us/step - loss: 0.0680 - val_loss: 0.0392\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 438us/step - loss: 0.0677 - val_loss: 0.0360\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 434us/step - loss: 0.0677 - val_loss: 0.0354\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 436us/step - loss: 0.0677 - val_loss: 0.0363\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 438us/step - loss: 0.0677 - val_loss: 0.0371\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 443us/step - loss: 0.0677 - val_loss: 0.0374\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 441us/step - loss: 0.0677 - val_loss: 0.0369\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 437us/step - loss: 0.0677 - val_loss: 0.0370\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 447us/step - loss: 0.0677 - val_loss: 0.0378\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 434us/step - loss: 0.0677 - val_loss: 0.0372\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 439us/step - loss: 0.0677 - val_loss: 0.0366\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 435us/step - loss: 0.0677 - val_loss: 0.0366\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 440us/step - loss: 0.0677 - val_loss: 0.0363\n",
      "Epoch 23/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 2s 439us/step - loss: 0.0677 - val_loss: 0.0378\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 435us/step - loss: 0.0677 - val_loss: 0.0373\n",
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/24\n",
      "3891/3891 [==============================] - 40s 10ms/step - loss: 1.7361 - val_loss: 1.1659\n",
      "Epoch 2/24\n",
      "3891/3891 [==============================] - 2s 429us/step - loss: 0.5237 - val_loss: 0.2885\n",
      "Epoch 3/24\n",
      "3891/3891 [==============================] - 2s 436us/step - loss: 0.1137 - val_loss: 0.0378\n",
      "Epoch 4/24\n",
      "3891/3891 [==============================] - 2s 435us/step - loss: 0.0752 - val_loss: 0.0054\n",
      "Epoch 5/24\n",
      "3891/3891 [==============================] - 2s 429us/step - loss: 0.0931 - val_loss: 0.0051\n",
      "Epoch 6/24\n",
      "3891/3891 [==============================] - 2s 440us/step - loss: 0.0845 - val_loss: 0.0134\n",
      "Epoch 7/24\n",
      "3891/3891 [==============================] - 2s 432us/step - loss: 0.0709 - val_loss: 0.0318\n",
      "Epoch 8/24\n",
      "3891/3891 [==============================] - 2s 432us/step - loss: 0.0679 - val_loss: 0.0469\n",
      "Epoch 9/24\n",
      "3891/3891 [==============================] - 2s 433us/step - loss: 0.0687 - val_loss: 0.0488\n",
      "Epoch 10/24\n",
      "3891/3891 [==============================] - 2s 436us/step - loss: 0.0684 - val_loss: 0.0420\n",
      "Epoch 11/24\n",
      "3891/3891 [==============================] - 2s 433us/step - loss: 0.0678 - val_loss: 0.0366\n",
      "Epoch 12/24\n",
      "3891/3891 [==============================] - 2s 434us/step - loss: 0.0677 - val_loss: 0.0342\n",
      "Epoch 13/24\n",
      "3891/3891 [==============================] - 2s 440us/step - loss: 0.0678 - val_loss: 0.0351\n",
      "Epoch 14/24\n",
      "3891/3891 [==============================] - 2s 435us/step - loss: 0.0677 - val_loss: 0.0365\n",
      "Epoch 15/24\n",
      "3891/3891 [==============================] - 2s 441us/step - loss: 0.0677 - val_loss: 0.0380\n",
      "Epoch 16/24\n",
      "3891/3891 [==============================] - 2s 443us/step - loss: 0.0677 - val_loss: 0.0371\n",
      "Epoch 17/24\n",
      "3891/3891 [==============================] - 2s 435us/step - loss: 0.0677 - val_loss: 0.0365\n",
      "Epoch 18/24\n",
      "3891/3891 [==============================] - 2s 432us/step - loss: 0.0677 - val_loss: 0.0362\n",
      "Epoch 19/24\n",
      "3891/3891 [==============================] - 2s 434us/step - loss: 0.0677 - val_loss: 0.0366\n",
      "Epoch 20/24\n",
      "3891/3891 [==============================] - 2s 434us/step - loss: 0.0677 - val_loss: 0.0379\n",
      "Epoch 21/24\n",
      "3891/3891 [==============================] - 2s 435us/step - loss: 0.0677 - val_loss: 0.0373\n",
      "Epoch 22/24\n",
      "3891/3891 [==============================] - 2s 432us/step - loss: 0.0677 - val_loss: 0.0357\n",
      "Epoch 23/24\n",
      "3891/3891 [==============================] - 2s 434us/step - loss: 0.0677 - val_loss: 0.0360\n",
      "Epoch 24/24\n",
      "3891/3891 [==============================] - 2s 438us/step - loss: 0.0677 - val_loss: 0.0371\n"
     ]
    }
   ],
   "source": [
    "best_models = breed_population(X_train, Y_train, generations=20, population_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.012932972051203251,\n",
       " 0.005194666795432568,\n",
       " 0.005362418945878744,\n",
       " 0.0018238824559375644,\n",
       " 0.002546928124502301,\n",
       " 0.0011899657547473907,\n",
       " 0.0017382557271048427,\n",
       " 0.0012006565229967237,\n",
       " 0.0011902314145117998,\n",
       " 0.0011436198838055134,\n",
       " 0.0009719928493723273,\n",
       " 0.0009333891794085503,\n",
       " 0.0009375653462484479,\n",
       " 0.0007813152624294162,\n",
       " 0.0007397860754281282,\n",
       " 0.0007130292942747474,\n",
       " 0.0007510942523367703,\n",
       " 0.0006906398921273649,\n",
       " 0.0006785563891753554,\n",
       " 0.0006589163676835597,\n",
       " 0.0006490867235697806,\n",
       " 0.0006638187915086746,\n",
       " 0.0006751418113708496,\n",
       " 0.0006495012203231454]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models[0][1].history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal parameters\n",
      "_______________________\n",
      "lstmsize: 118\n",
      "activation: relu\n",
      "optimizer: adam\n",
      "shuffle: True\n",
      "density: 98\n",
      "twice: False\n"
     ]
    }
   ],
   "source": [
    "print('optimal parameters')\n",
    "print('_______________________')\n",
    "for key,val in best_models[0][2].items():\n",
    "    if key != 'x' and key != 'y': print(f'{key}: {val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_111\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_185 (LSTM)              (None, 118)               58528     \n",
      "_________________________________________________________________\n",
      "dense_413 (Dense)            (None, 98)                11662     \n",
      "_________________________________________________________________\n",
      "dense_414 (Dense)            (None, 1)                 99        \n",
      "=================================================================\n",
      "Total params: 70,289\n",
      "Trainable params: 70,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_models[0][0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibm_checkpoint = ModelCheckpoint(\n",
    "    filepath='./checkpoints/IBM.{epoch}-{val_loss}.hdf5',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = best_models[0][2]\n",
    "params['x'] = X_train\n",
    "params['y'] = Y_train\n",
    "params['epochs'] = 2000\n",
    "params['callbacks'] = [ibm_checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3891 samples, validate on 433 samples\n",
      "Epoch 1/2000\n",
      "3891/3891 [==============================] - 39s 10ms/step - loss: 0.0641 - val_loss: 0.0042\n",
      "Epoch 2/2000\n",
      "3891/3891 [==============================] - 1s 244us/step - loss: 0.0077 - val_loss: 0.0020\n",
      "Epoch 3/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 0.0028 - val_loss: 0.0012\n",
      "Epoch 4/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 5/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 6/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 7/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 8/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 9.8615e-04 - val_loss: 0.0011\n",
      "Epoch 9/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 9.6338e-04 - val_loss: 0.0011\n",
      "Epoch 10/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 9.4321e-04 - val_loss: 0.0010\n",
      "Epoch 11/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 9.2674e-04 - val_loss: 0.0011\n",
      "Epoch 12/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 9.1888e-04 - val_loss: 0.0010\n",
      "Epoch 13/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 8.9633e-04 - val_loss: 9.9481e-04\n",
      "Epoch 14/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 8.8279e-04 - val_loss: 0.0010\n",
      "Epoch 15/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 8.8140e-04 - val_loss: 9.6372e-04\n",
      "Epoch 16/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 8.6301e-04 - val_loss: 9.3037e-04\n",
      "Epoch 17/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 8.4282e-04 - val_loss: 9.0958e-04\n",
      "Epoch 18/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 8.2800e-04 - val_loss: 8.8837e-04\n",
      "Epoch 19/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 8.1699e-04 - val_loss: 8.7396e-04\n",
      "Epoch 20/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 8.0755e-04 - val_loss: 8.6183e-04\n",
      "Epoch 21/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 7.9252e-04 - val_loss: 8.6084e-04\n",
      "Epoch 22/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 7.8810e-04 - val_loss: 8.3312e-04\n",
      "Epoch 23/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 7.7053e-04 - val_loss: 8.2827e-04\n",
      "Epoch 24/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 7.6454e-04 - val_loss: 8.2525e-04\n",
      "Epoch 25/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 7.6772e-04 - val_loss: 8.3044e-04\n",
      "Epoch 26/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 7.5427e-04 - val_loss: 8.4956e-04\n",
      "Epoch 27/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 7.5111e-04 - val_loss: 7.8028e-04\n",
      "Epoch 28/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 7.2703e-04 - val_loss: 7.6768e-04\n",
      "Epoch 29/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 7.2480e-04 - val_loss: 8.3090e-04\n",
      "Epoch 30/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 7.3141e-04 - val_loss: 7.8578e-04\n",
      "Epoch 31/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 7.2416e-04 - val_loss: 7.4069e-04\n",
      "Epoch 32/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 6.9700e-04 - val_loss: 7.4402e-04\n",
      "Epoch 33/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 6.9288e-04 - val_loss: 7.2633e-04\n",
      "Epoch 34/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 6.8336e-04 - val_loss: 7.1995e-04\n",
      "Epoch 35/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 6.7873e-04 - val_loss: 7.2902e-04\n",
      "Epoch 36/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 6.9047e-04 - val_loss: 7.0832e-04\n",
      "Epoch 37/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 6.6320e-04 - val_loss: 6.9856e-04\n",
      "Epoch 38/2000\n",
      "3891/3891 [==============================] - 1s 232us/step - loss: 6.5714e-04 - val_loss: 6.9682e-04\n",
      "Epoch 39/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 6.5277e-04 - val_loss: 6.8248e-04\n",
      "Epoch 40/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 6.5347e-04 - val_loss: 7.2517e-04\n",
      "Epoch 41/2000\n",
      "3891/3891 [==============================] - 1s 222us/step - loss: 6.5660e-04 - val_loss: 6.9472e-04\n",
      "Epoch 42/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 6.4900e-04 - val_loss: 6.6460e-04\n",
      "Epoch 43/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 6.5187e-04 - val_loss: 6.7757e-04\n",
      "Epoch 44/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 6.2793e-04 - val_loss: 6.5606e-04\n",
      "Epoch 45/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 6.3967e-04 - val_loss: 6.8910e-04\n",
      "Epoch 46/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 6.3602e-04 - val_loss: 6.5051e-04\n",
      "Epoch 47/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 6.2242e-04 - val_loss: 6.4594e-04\n",
      "Epoch 48/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 6.1091e-04 - val_loss: 6.3873e-04\n",
      "Epoch 49/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 6.0870e-04 - val_loss: 6.2855e-04\n",
      "Epoch 50/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 5.9552e-04 - val_loss: 6.2732e-04\n",
      "Epoch 51/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 5.9091e-04 - val_loss: 6.1567e-04\n",
      "Epoch 52/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 5.8989e-04 - val_loss: 6.4794e-04\n",
      "Epoch 53/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 5.9365e-04 - val_loss: 6.6113e-04\n",
      "Epoch 54/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 6.1046e-04 - val_loss: 6.9971e-04\n",
      "Epoch 55/2000\n",
      "3891/3891 [==============================] - 1s 234us/step - loss: 6.2395e-04 - val_loss: 7.5554e-04\n",
      "Epoch 56/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 6.1595e-04 - val_loss: 6.3363e-04\n",
      "Epoch 57/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 5.8200e-04 - val_loss: 6.1683e-04\n",
      "Epoch 58/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 5.6809e-04 - val_loss: 5.8290e-04\n",
      "Epoch 59/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 5.6432e-04 - val_loss: 5.8365e-04\n",
      "Epoch 60/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 5.5339e-04 - val_loss: 5.7267e-04\n",
      "Epoch 61/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 5.6763e-04 - val_loss: 5.9344e-04\n",
      "Epoch 62/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 5.5112e-04 - val_loss: 5.6741e-04\n",
      "Epoch 63/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 5.4621e-04 - val_loss: 5.6119e-04\n",
      "Epoch 64/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 5.3880e-04 - val_loss: 5.5707e-04\n",
      "Epoch 65/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 5.3406e-04 - val_loss: 5.5527e-04\n",
      "Epoch 66/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 5.3827e-04 - val_loss: 5.8744e-04\n",
      "Epoch 67/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 5.2902e-04 - val_loss: 5.4765e-04\n",
      "Epoch 68/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 5.4454e-04 - val_loss: 5.3898e-04\n",
      "Epoch 69/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 5.3897e-04 - val_loss: 5.6591e-04\n",
      "Epoch 70/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 5.1994e-04 - val_loss: 5.3074e-04\n",
      "Epoch 71/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 5.1663e-04 - val_loss: 5.2783e-04\n",
      "Epoch 72/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 1s 225us/step - loss: 5.1698e-04 - val_loss: 5.5608e-04\n",
      "Epoch 73/2000\n",
      "3891/3891 [==============================] - 1s 232us/step - loss: 5.1092e-04 - val_loss: 5.2362e-04\n",
      "Epoch 74/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 5.0581e-04 - val_loss: 5.1569e-04\n",
      "Epoch 75/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 5.0392e-04 - val_loss: 5.1262e-04\n",
      "Epoch 76/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 5.1900e-04 - val_loss: 5.3970e-04\n",
      "Epoch 77/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 5.0438e-04 - val_loss: 6.1182e-04\n",
      "Epoch 78/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 5.2370e-04 - val_loss: 5.9011e-04\n",
      "Epoch 79/2000\n",
      "3891/3891 [==============================] - 1s 233us/step - loss: 4.9815e-04 - val_loss: 5.1203e-04\n",
      "Epoch 80/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 5.0322e-04 - val_loss: 5.2339e-04\n",
      "Epoch 81/2000\n",
      "3891/3891 [==============================] - 1s 232us/step - loss: 5.0271e-04 - val_loss: 5.0142e-04\n",
      "Epoch 82/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 5.1067e-04 - val_loss: 6.1421e-04\n",
      "Epoch 83/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 5.0410e-04 - val_loss: 5.1627e-04\n",
      "Epoch 84/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 5.0481e-04 - val_loss: 5.2083e-04\n",
      "Epoch 85/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 5.2051e-04 - val_loss: 4.9709e-04\n",
      "Epoch 86/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 5.1767e-04 - val_loss: 7.5512e-04\n",
      "Epoch 87/2000\n",
      "3891/3891 [==============================] - 1s 222us/step - loss: 5.1681e-04 - val_loss: 5.6848e-04\n",
      "Epoch 88/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 5.1428e-04 - val_loss: 4.9171e-04\n",
      "Epoch 89/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 4.9173e-04 - val_loss: 4.9068e-04\n",
      "Epoch 90/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 4.6902e-04 - val_loss: 4.9229e-04\n",
      "Epoch 91/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 4.7776e-04 - val_loss: 6.0281e-04\n",
      "Epoch 92/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 4.8532e-04 - val_loss: 4.7744e-04\n",
      "Epoch 93/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 4.6311e-04 - val_loss: 4.7946e-04\n",
      "Epoch 94/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 4.6065e-04 - val_loss: 4.7392e-04\n",
      "Epoch 95/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 4.5763e-04 - val_loss: 5.3043e-04\n",
      "Epoch 96/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 4.5987e-04 - val_loss: 4.7055e-04\n",
      "Epoch 97/2000\n",
      "3891/3891 [==============================] - 1s 233us/step - loss: 4.5804e-04 - val_loss: 5.0993e-04\n",
      "Epoch 98/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 4.6550e-04 - val_loss: 4.8464e-04\n",
      "Epoch 99/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 4.5239e-04 - val_loss: 4.7091e-04\n",
      "Epoch 100/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 4.5600e-04 - val_loss: 4.6335e-04\n",
      "Epoch 101/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 4.4503e-04 - val_loss: 4.6311e-04\n",
      "Epoch 102/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 4.5792e-04 - val_loss: 4.6859e-04\n",
      "Epoch 103/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 4.5000e-04 - val_loss: 4.8819e-04\n",
      "Epoch 104/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 4.5174e-04 - val_loss: 4.5636e-04\n",
      "Epoch 105/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 4.5129e-04 - val_loss: 4.5646e-04\n",
      "Epoch 106/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 4.5678e-04 - val_loss: 4.6691e-04\n",
      "Epoch 107/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 4.4774e-04 - val_loss: 4.5309e-04\n",
      "Epoch 108/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 4.3451e-04 - val_loss: 4.7123e-04\n",
      "Epoch 109/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 4.5808e-04 - val_loss: 4.5003e-04\n",
      "Epoch 110/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 4.7935e-04 - val_loss: 4.7823e-04\n",
      "Epoch 111/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 4.5591e-04 - val_loss: 4.9170e-04\n",
      "Epoch 112/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 4.4962e-04 - val_loss: 4.9680e-04\n",
      "Epoch 113/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 4.3016e-04 - val_loss: 4.5455e-04\n",
      "Epoch 114/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 4.3121e-04 - val_loss: 4.8530e-04\n",
      "Epoch 115/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 4.3222e-04 - val_loss: 5.5618e-04\n",
      "Epoch 116/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 4.5373e-04 - val_loss: 4.5388e-04\n",
      "Epoch 117/2000\n",
      "3891/3891 [==============================] - 1s 222us/step - loss: 4.4578e-04 - val_loss: 4.7338e-04\n",
      "Epoch 118/2000\n",
      "3891/3891 [==============================] - 1s 222us/step - loss: 4.3644e-04 - val_loss: 4.4348e-04\n",
      "Epoch 119/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 4.4309e-04 - val_loss: 4.8316e-04\n",
      "Epoch 120/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 4.7408e-04 - val_loss: 4.6153e-04\n",
      "Epoch 121/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 4.4610e-04 - val_loss: 4.3992e-04\n",
      "Epoch 122/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 4.4926e-04 - val_loss: 4.8309e-04\n",
      "Epoch 123/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 4.2881e-04 - val_loss: 4.6954e-04\n",
      "Epoch 124/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 4.2242e-04 - val_loss: 4.6490e-04\n",
      "Epoch 125/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 4.2897e-04 - val_loss: 4.6039e-04\n",
      "Epoch 126/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 4.1898e-04 - val_loss: 4.4135e-04\n",
      "Epoch 127/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 4.3027e-04 - val_loss: 5.1463e-04\n",
      "Epoch 128/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 4.4525e-04 - val_loss: 4.3378e-04\n",
      "Epoch 129/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 4.1828e-04 - val_loss: 4.7019e-04\n",
      "Epoch 130/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 4.1680e-04 - val_loss: 4.3665e-04\n",
      "Epoch 131/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 4.1880e-04 - val_loss: 4.3276e-04\n",
      "Epoch 132/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 4.1505e-04 - val_loss: 4.4947e-04\n",
      "Epoch 133/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 4.2191e-04 - val_loss: 4.3390e-04\n",
      "Epoch 134/2000\n",
      "3891/3891 [==============================] - 1s 240us/step - loss: 4.1199e-04 - val_loss: 4.8575e-04\n",
      "Epoch 135/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 4.3264e-04 - val_loss: 4.3017e-04\n",
      "Epoch 136/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 4.4491e-04 - val_loss: 4.3277e-04\n",
      "Epoch 137/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 4.4016e-04 - val_loss: 4.2868e-04\n",
      "Epoch 138/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 4.6350e-04 - val_loss: 4.3908e-04\n",
      "Epoch 139/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 4.2903e-04 - val_loss: 4.6754e-04\n",
      "Epoch 140/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 4.5739e-04 - val_loss: 5.1619e-04\n",
      "Epoch 141/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 4.5316e-04 - val_loss: 5.4867e-04\n",
      "Epoch 142/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 4.5791e-04 - val_loss: 4.4376e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 4.4614e-04 - val_loss: 5.3403e-04\n",
      "Epoch 144/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 4.6687e-04 - val_loss: 6.1213e-04\n",
      "Epoch 145/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 4.3830e-04 - val_loss: 4.3049e-04\n",
      "Epoch 146/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 4.2077e-04 - val_loss: 4.2836e-04\n",
      "Epoch 147/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 4.1511e-04 - val_loss: 4.7978e-04\n",
      "Epoch 148/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 4.2396e-04 - val_loss: 5.1312e-04\n",
      "Epoch 149/2000\n",
      "3891/3891 [==============================] - 1s 222us/step - loss: 4.2695e-04 - val_loss: 4.6078e-04\n",
      "Epoch 150/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 4.1820e-04 - val_loss: 4.3523e-04\n",
      "Epoch 151/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 4.1101e-04 - val_loss: 4.2514e-04\n",
      "Epoch 152/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 4.1479e-04 - val_loss: 4.8129e-04\n",
      "Epoch 153/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 4.3122e-04 - val_loss: 6.1458e-04\n",
      "Epoch 154/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 4.4365e-04 - val_loss: 4.2898e-04\n",
      "Epoch 155/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 4.1700e-04 - val_loss: 4.2735e-04\n",
      "Epoch 156/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 4.1868e-04 - val_loss: 4.3335e-04\n",
      "Epoch 157/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 4.1900e-04 - val_loss: 4.2552e-04\n",
      "Epoch 158/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 4.0965e-04 - val_loss: 4.2318e-04\n",
      "Epoch 159/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 4.1455e-04 - val_loss: 4.2189e-04\n",
      "Epoch 160/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 4.2399e-04 - val_loss: 4.3228e-04\n",
      "Epoch 161/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 4.1399e-04 - val_loss: 4.8346e-04\n",
      "Epoch 162/2000\n",
      "3891/3891 [==============================] - 1s 233us/step - loss: 4.3246e-04 - val_loss: 5.2933e-04\n",
      "Epoch 163/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 4.1707e-04 - val_loss: 4.2889e-04\n",
      "Epoch 164/2000\n",
      "3891/3891 [==============================] - 1s 234us/step - loss: 4.1082e-04 - val_loss: 4.2746e-04\n",
      "Epoch 165/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 4.1541e-04 - val_loss: 4.7712e-04\n",
      "Epoch 166/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 4.3643e-04 - val_loss: 4.3016e-04\n",
      "Epoch 167/2000\n",
      "3891/3891 [==============================] - 1s 221us/step - loss: 4.2411e-04 - val_loss: 4.3245e-04\n",
      "Epoch 168/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 4.0450e-04 - val_loss: 4.4480e-04\n",
      "Epoch 169/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 4.0491e-04 - val_loss: 4.4466e-04\n",
      "Epoch 170/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 4.3644e-04 - val_loss: 4.4224e-04\n",
      "Epoch 171/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 4.4753e-04 - val_loss: 4.1978e-04\n",
      "Epoch 172/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 4.2921e-04 - val_loss: 4.4699e-04\n",
      "Epoch 173/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 4.1245e-04 - val_loss: 5.0094e-04\n",
      "Epoch 174/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 4.1952e-04 - val_loss: 5.0685e-04\n",
      "Epoch 175/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 4.2312e-04 - val_loss: 4.2866e-04\n",
      "Epoch 176/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 4.0385e-04 - val_loss: 4.3333e-04\n",
      "Epoch 177/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 4.1093e-04 - val_loss: 4.2157e-04\n",
      "Epoch 178/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 4.0615e-04 - val_loss: 4.2394e-04\n",
      "Epoch 179/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 4.1049e-04 - val_loss: 4.2910e-04\n",
      "Epoch 180/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 4.0279e-04 - val_loss: 4.2065e-04\n",
      "Epoch 181/2000\n",
      "3891/3891 [==============================] - 1s 232us/step - loss: 4.0738e-04 - val_loss: 4.4258e-04\n",
      "Epoch 182/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 4.1763e-04 - val_loss: 4.2388e-04\n",
      "Epoch 183/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 4.1298e-04 - val_loss: 4.8006e-04\n",
      "Epoch 184/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 4.1109e-04 - val_loss: 4.1861e-04\n",
      "Epoch 185/2000\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 4.0243e-04 - val_loss: 4.1909e-04\n",
      "Epoch 186/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 4.0209e-04 - val_loss: 4.2120e-04\n",
      "Epoch 187/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.9949e-04 - val_loss: 4.1938e-04\n",
      "Epoch 188/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 4.1648e-04 - val_loss: 4.6033e-04\n",
      "Epoch 189/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 4.4066e-04 - val_loss: 4.2266e-04\n",
      "Epoch 190/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 4.5330e-04 - val_loss: 5.7463e-04\n",
      "Epoch 191/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 4.3199e-04 - val_loss: 4.3409e-04\n",
      "Epoch 192/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 4.3575e-04 - val_loss: 5.3989e-04\n",
      "Epoch 193/2000\n",
      "3891/3891 [==============================] - 1s 221us/step - loss: 4.6354e-04 - val_loss: 4.2564e-04\n",
      "Epoch 194/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 4.3588e-04 - val_loss: 6.2987e-04\n",
      "Epoch 195/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 4.2656e-04 - val_loss: 4.1696e-04\n",
      "Epoch 196/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 4.0059e-04 - val_loss: 4.2803e-04\n",
      "Epoch 197/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 4.0132e-04 - val_loss: 4.2554e-04\n",
      "Epoch 198/2000\n",
      "3891/3891 [==============================] - 1s 238us/step - loss: 4.1532e-04 - val_loss: 4.7042e-04\n",
      "Epoch 199/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 4.4706e-04 - val_loss: 7.6792e-04\n",
      "Epoch 200/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 5.0866e-04 - val_loss: 4.5025e-04\n",
      "Epoch 201/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 4.4888e-04 - val_loss: 4.5248e-04\n",
      "Epoch 202/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 4.2511e-04 - val_loss: 4.1945e-04\n",
      "Epoch 203/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 4.0961e-04 - val_loss: 4.7927e-04\n",
      "Epoch 204/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 4.2101e-04 - val_loss: 4.2727e-04\n",
      "Epoch 205/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 4.0453e-04 - val_loss: 4.3363e-04\n",
      "Epoch 206/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 4.0475e-04 - val_loss: 4.2348e-04\n",
      "Epoch 207/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 4.0952e-04 - val_loss: 4.3031e-04\n",
      "Epoch 208/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 4.0344e-04 - val_loss: 4.2084e-04\n",
      "Epoch 209/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 4.0040e-04 - val_loss: 4.4658e-04\n",
      "Epoch 210/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 4.1301e-04 - val_loss: 4.5615e-04\n",
      "Epoch 211/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 4.1383e-04 - val_loss: 4.1818e-04\n",
      "Epoch 212/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 4.0355e-04 - val_loss: 4.4737e-04\n",
      "Epoch 213/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 1s 226us/step - loss: 4.0167e-04 - val_loss: 4.4035e-04\n",
      "Epoch 214/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 4.0517e-04 - val_loss: 4.4160e-04\n",
      "Epoch 215/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 4.2290e-04 - val_loss: 4.1790e-04\n",
      "Epoch 216/2000\n",
      "3891/3891 [==============================] - 1s 232us/step - loss: 4.1551e-04 - val_loss: 4.1772e-04\n",
      "Epoch 217/2000\n",
      "3891/3891 [==============================] - 1s 232us/step - loss: 3.9733e-04 - val_loss: 4.2762e-04\n",
      "Epoch 218/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 3.9867e-04 - val_loss: 4.1793e-04\n",
      "Epoch 219/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 4.0301e-04 - val_loss: 4.2702e-04\n",
      "Epoch 220/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 4.0200e-04 - val_loss: 4.9626e-04\n",
      "Epoch 221/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 4.1132e-04 - val_loss: 4.2310e-04\n",
      "Epoch 222/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 3.9800e-04 - val_loss: 4.3922e-04\n",
      "Epoch 223/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 4.0058e-04 - val_loss: 4.8660e-04\n",
      "Epoch 224/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 4.0665e-04 - val_loss: 4.2229e-04\n",
      "Epoch 225/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 3.9903e-04 - val_loss: 4.1639e-04\n",
      "Epoch 226/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.9968e-04 - val_loss: 4.2897e-04\n",
      "Epoch 227/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 4.0135e-04 - val_loss: 4.1668e-04\n",
      "Epoch 228/2000\n",
      "3891/3891 [==============================] - 1s 222us/step - loss: 4.1128e-04 - val_loss: 4.4869e-04\n",
      "Epoch 229/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 4.1565e-04 - val_loss: 4.2332e-04\n",
      "Epoch 230/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 4.0668e-04 - val_loss: 4.4224e-04\n",
      "Epoch 231/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 4.0292e-04 - val_loss: 4.1730e-04\n",
      "Epoch 232/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 4.1486e-04 - val_loss: 4.3417e-04\n",
      "Epoch 233/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 4.1438e-04 - val_loss: 4.1739e-04\n",
      "Epoch 234/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 4.0536e-04 - val_loss: 4.3260e-04\n",
      "Epoch 235/2000\n",
      "3891/3891 [==============================] - 1s 232us/step - loss: 3.9803e-04 - val_loss: 4.3371e-04\n",
      "Epoch 236/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 4.0855e-04 - val_loss: 4.4029e-04\n",
      "Epoch 237/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 4.3333e-04 - val_loss: 4.6445e-04\n",
      "Epoch 238/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 4.1827e-04 - val_loss: 4.4334e-04\n",
      "Epoch 239/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 4.2656e-04 - val_loss: 5.7866e-04\n",
      "Epoch 240/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 4.4941e-04 - val_loss: 4.2262e-04\n",
      "Epoch 241/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 4.1706e-04 - val_loss: 4.2295e-04\n",
      "Epoch 242/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 4.0409e-04 - val_loss: 4.2219e-04\n",
      "Epoch 243/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 3.9715e-04 - val_loss: 4.1771e-04\n",
      "Epoch 244/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 4.0050e-04 - val_loss: 4.6744e-04\n",
      "Epoch 245/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 4.0237e-04 - val_loss: 4.5332e-04\n",
      "Epoch 246/2000\n",
      "3891/3891 [==============================] - 1s 221us/step - loss: 4.2554e-04 - val_loss: 4.2143e-04\n",
      "Epoch 247/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 4.0196e-04 - val_loss: 4.2237e-04\n",
      "Epoch 248/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 4.0217e-04 - val_loss: 4.4066e-04\n",
      "Epoch 249/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 3.9908e-04 - val_loss: 4.4645e-04\n",
      "Epoch 250/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 4.1293e-04 - val_loss: 4.5349e-04\n",
      "Epoch 251/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 4.1949e-04 - val_loss: 4.1574e-04\n",
      "Epoch 252/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 4.0164e-04 - val_loss: 4.1699e-04\n",
      "Epoch 253/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 4.0105e-04 - val_loss: 4.1691e-04\n",
      "Epoch 254/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.9906e-04 - val_loss: 4.2019e-04\n",
      "Epoch 255/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 3.9839e-04 - val_loss: 4.1614e-04\n",
      "Epoch 256/2000\n",
      "3891/3891 [==============================] - 1s 232us/step - loss: 4.0283e-04 - val_loss: 4.6197e-04\n",
      "Epoch 257/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 4.0086e-04 - val_loss: 4.3187e-04\n",
      "Epoch 258/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 4.0091e-04 - val_loss: 4.1931e-04\n",
      "Epoch 259/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.9617e-04 - val_loss: 4.2109e-04\n",
      "Epoch 260/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 3.9703e-04 - val_loss: 4.1865e-04\n",
      "Epoch 261/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.9923e-04 - val_loss: 4.6052e-04\n",
      "Epoch 262/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 3.9885e-04 - val_loss: 4.3492e-04\n",
      "Epoch 263/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 4.1071e-04 - val_loss: 4.8782e-04\n",
      "Epoch 264/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 4.1128e-04 - val_loss: 4.1479e-04\n",
      "Epoch 265/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 4.0183e-04 - val_loss: 4.1899e-04\n",
      "Epoch 266/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.9799e-04 - val_loss: 4.1671e-04\n",
      "Epoch 267/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 4.1710e-04 - val_loss: 5.0388e-04\n",
      "Epoch 268/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 4.1332e-04 - val_loss: 4.8204e-04\n",
      "Epoch 269/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 4.1901e-04 - val_loss: 4.2513e-04\n",
      "Epoch 270/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 4.1453e-04 - val_loss: 4.3804e-04\n",
      "Epoch 271/2000\n",
      "3891/3891 [==============================] - 1s 235us/step - loss: 4.1374e-04 - val_loss: 4.6986e-04\n",
      "Epoch 272/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 3.9807e-04 - val_loss: 4.1618e-04\n",
      "Epoch 273/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 4.0013e-04 - val_loss: 4.3646e-04\n",
      "Epoch 274/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 4.0636e-04 - val_loss: 4.4618e-04\n",
      "Epoch 275/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 4.1251e-04 - val_loss: 4.6487e-04\n",
      "Epoch 276/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 4.2106e-04 - val_loss: 4.3846e-04\n",
      "Epoch 277/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 4.0226e-04 - val_loss: 4.1878e-04\n",
      "Epoch 278/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 4.0346e-04 - val_loss: 4.4054e-04\n",
      "Epoch 279/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.9840e-04 - val_loss: 4.2126e-04\n",
      "Epoch 280/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 4.0284e-04 - val_loss: 4.1620e-04\n",
      "Epoch 281/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 4.0255e-04 - val_loss: 4.1878e-04\n",
      "Epoch 282/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 3.9930e-04 - val_loss: 5.0716e-04\n",
      "Epoch 283/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 4.1170e-04 - val_loss: 4.1685e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 284/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 3.9848e-04 - val_loss: 4.3101e-04\n",
      "Epoch 285/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 4.3057e-04 - val_loss: 4.2244e-04\n",
      "Epoch 286/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 4.0482e-04 - val_loss: 5.7328e-04\n",
      "Epoch 287/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 4.7027e-04 - val_loss: 5.7623e-04\n",
      "Epoch 288/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 4.2401e-04 - val_loss: 4.2503e-04\n",
      "Epoch 289/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 4.0971e-04 - val_loss: 4.5458e-04\n",
      "Epoch 290/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 4.1380e-04 - val_loss: 4.7892e-04\n",
      "Epoch 291/2000\n",
      "3891/3891 [==============================] - 1s 222us/step - loss: 3.9890e-04 - val_loss: 4.1803e-04\n",
      "Epoch 292/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.9652e-04 - val_loss: 4.7398e-04\n",
      "Epoch 293/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 4.0559e-04 - val_loss: 4.1800e-04\n",
      "Epoch 294/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 4.0739e-04 - val_loss: 4.3065e-04\n",
      "Epoch 295/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 3.9424e-04 - val_loss: 4.5244e-04\n",
      "Epoch 296/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 4.0340e-04 - val_loss: 4.2103e-04\n",
      "Epoch 297/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 3.9707e-04 - val_loss: 4.4600e-04\n",
      "Epoch 298/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 4.0884e-04 - val_loss: 5.2609e-04\n",
      "Epoch 299/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 4.2704e-04 - val_loss: 4.1751e-04\n",
      "Epoch 300/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 4.2548e-04 - val_loss: 4.1870e-04\n",
      "Epoch 301/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 3.9723e-04 - val_loss: 4.1604e-04\n",
      "Epoch 302/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.9829e-04 - val_loss: 4.2351e-04\n",
      "Epoch 303/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 3.9476e-04 - val_loss: 4.3809e-04\n",
      "Epoch 304/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 3.9981e-04 - val_loss: 4.2508e-04\n",
      "Epoch 305/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 4.1052e-04 - val_loss: 4.4137e-04\n",
      "Epoch 306/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 4.0727e-04 - val_loss: 4.1572e-04\n",
      "Epoch 307/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 4.0157e-04 - val_loss: 4.2415e-04\n",
      "Epoch 308/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 4.0765e-04 - val_loss: 5.2450e-04\n",
      "Epoch 309/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 4.1809e-04 - val_loss: 5.1304e-04\n",
      "Epoch 310/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 4.1020e-04 - val_loss: 4.1662e-04\n",
      "Epoch 311/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 4.1990e-04 - val_loss: 4.3870e-04\n",
      "Epoch 312/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 4.1105e-04 - val_loss: 4.2501e-04\n",
      "Epoch 313/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 4.0353e-04 - val_loss: 4.4002e-04\n",
      "Epoch 314/2000\n",
      "3891/3891 [==============================] - 1s 222us/step - loss: 3.9473e-04 - val_loss: 4.1534e-04\n",
      "Epoch 315/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 3.9552e-04 - val_loss: 4.2180e-04\n",
      "Epoch 316/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 4.0098e-04 - val_loss: 4.3363e-04\n",
      "Epoch 317/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 3.9343e-04 - val_loss: 4.1615e-04\n",
      "Epoch 318/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 3.9343e-04 - val_loss: 4.2364e-04\n",
      "Epoch 319/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 3.9208e-04 - val_loss: 4.2249e-04\n",
      "Epoch 320/2000\n",
      "3891/3891 [==============================] - 1s 222us/step - loss: 3.9201e-04 - val_loss: 4.1457e-04\n",
      "Epoch 321/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 3.9537e-04 - val_loss: 4.1506e-04\n",
      "Epoch 322/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 4.0205e-04 - val_loss: 4.1599e-04\n",
      "Epoch 323/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 4.0186e-04 - val_loss: 4.1696e-04\n",
      "Epoch 324/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 3.9303e-04 - val_loss: 4.3018e-04\n",
      "Epoch 325/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 4.0046e-04 - val_loss: 4.7801e-04\n",
      "Epoch 326/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 4.1982e-04 - val_loss: 4.4287e-04\n",
      "Epoch 327/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 4.0181e-04 - val_loss: 4.3602e-04\n",
      "Epoch 328/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 3.9559e-04 - val_loss: 4.1454e-04\n",
      "Epoch 329/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 3.9224e-04 - val_loss: 4.1989e-04\n",
      "Epoch 330/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.9727e-04 - val_loss: 4.6852e-04\n",
      "Epoch 331/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 4.1012e-04 - val_loss: 5.8408e-04\n",
      "Epoch 332/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 4.4226e-04 - val_loss: 4.1241e-04\n",
      "Epoch 333/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 4.2345e-04 - val_loss: 4.1330e-04\n",
      "Epoch 334/2000\n",
      "3891/3891 [==============================] - 1s 222us/step - loss: 4.2274e-04 - val_loss: 4.1431e-04\n",
      "Epoch 335/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 3.9884e-04 - val_loss: 4.1516e-04\n",
      "Epoch 336/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.9612e-04 - val_loss: 4.1569e-04\n",
      "Epoch 337/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 4.0474e-04 - val_loss: 4.4937e-04\n",
      "Epoch 338/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 4.1362e-04 - val_loss: 4.3298e-04\n",
      "Epoch 339/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 4.0991e-04 - val_loss: 6.4904e-04\n",
      "Epoch 340/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 4.8067e-04 - val_loss: 5.5273e-04\n",
      "Epoch 341/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 4.6768e-04 - val_loss: 4.6791e-04\n",
      "Epoch 342/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 4.2583e-04 - val_loss: 4.2104e-04\n",
      "Epoch 343/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 3.9406e-04 - val_loss: 4.2083e-04\n",
      "Epoch 344/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.9544e-04 - val_loss: 4.3068e-04\n",
      "Epoch 345/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 3.9841e-04 - val_loss: 4.7330e-04\n",
      "Epoch 346/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 4.0497e-04 - val_loss: 4.5193e-04\n",
      "Epoch 347/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 4.0678e-04 - val_loss: 4.2200e-04\n",
      "Epoch 348/2000\n",
      "3891/3891 [==============================] - 1s 232us/step - loss: 3.9690e-04 - val_loss: 4.5811e-04\n",
      "Epoch 349/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 4.1099e-04 - val_loss: 4.6796e-04\n",
      "Epoch 350/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 4.3636e-04 - val_loss: 4.1700e-04\n",
      "Epoch 351/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 4.3086e-04 - val_loss: 4.5068e-04\n",
      "Epoch 352/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.9729e-04 - val_loss: 4.2276e-04\n",
      "Epoch 353/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 4.1191e-04 - val_loss: 4.1449e-04\n",
      "Epoch 354/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 1s 231us/step - loss: 3.9090e-04 - val_loss: 4.2052e-04\n",
      "Epoch 355/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 4.0428e-04 - val_loss: 4.1519e-04\n",
      "Epoch 356/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.9175e-04 - val_loss: 4.1389e-04\n",
      "Epoch 357/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.9174e-04 - val_loss: 4.2204e-04\n",
      "Epoch 358/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 3.9168e-04 - val_loss: 4.1517e-04\n",
      "Epoch 359/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 3.9405e-04 - val_loss: 4.5206e-04\n",
      "Epoch 360/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 4.0951e-04 - val_loss: 5.8026e-04\n",
      "Epoch 361/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 4.3428e-04 - val_loss: 4.2405e-04\n",
      "Epoch 362/2000\n",
      "3891/3891 [==============================] - 1s 232us/step - loss: 4.2731e-04 - val_loss: 4.1319e-04\n",
      "Epoch 363/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 3.9937e-04 - val_loss: 4.2385e-04\n",
      "Epoch 364/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 3.9858e-04 - val_loss: 5.0354e-04\n",
      "Epoch 365/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 4.0245e-04 - val_loss: 4.5395e-04\n",
      "Epoch 366/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 3.9864e-04 - val_loss: 4.2824e-04\n",
      "Epoch 367/2000\n",
      "3891/3891 [==============================] - 1s 232us/step - loss: 4.1472e-04 - val_loss: 4.5417e-04\n",
      "Epoch 368/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 4.3555e-04 - val_loss: 4.2424e-04\n",
      "Epoch 369/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.9272e-04 - val_loss: 4.2524e-04\n",
      "Epoch 370/2000\n",
      "3891/3891 [==============================] - 1s 222us/step - loss: 3.9062e-04 - val_loss: 4.1408e-04\n",
      "Epoch 371/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.9138e-04 - val_loss: 4.1504e-04\n",
      "Epoch 372/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.9105e-04 - val_loss: 4.1549e-04\n",
      "Epoch 373/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 4.0140e-04 - val_loss: 4.2280e-04\n",
      "Epoch 374/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 4.1856e-04 - val_loss: 4.5179e-04\n",
      "Epoch 375/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 4.1586e-04 - val_loss: 5.1296e-04\n",
      "Epoch 376/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 4.1386e-04 - val_loss: 4.2958e-04\n",
      "Epoch 377/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 3.9273e-04 - val_loss: 4.2220e-04\n",
      "Epoch 378/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 4.0771e-04 - val_loss: 4.5082e-04\n",
      "Epoch 379/2000\n",
      "3891/3891 [==============================] - 1s 232us/step - loss: 3.9725e-04 - val_loss: 4.1530e-04\n",
      "Epoch 380/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 3.9085e-04 - val_loss: 4.1553e-04\n",
      "Epoch 381/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 3.9933e-04 - val_loss: 4.4220e-04\n",
      "Epoch 382/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 3.9999e-04 - val_loss: 4.1275e-04\n",
      "Epoch 383/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.9575e-04 - val_loss: 4.1596e-04\n",
      "Epoch 384/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.9229e-04 - val_loss: 4.3043e-04\n",
      "Epoch 385/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 3.9600e-04 - val_loss: 4.1945e-04\n",
      "Epoch 386/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 3.9415e-04 - val_loss: 4.2119e-04\n",
      "Epoch 387/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.9146e-04 - val_loss: 4.1790e-04\n",
      "Epoch 388/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 3.9383e-04 - val_loss: 4.1616e-04\n",
      "Epoch 389/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.9536e-04 - val_loss: 4.1425e-04\n",
      "Epoch 390/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.9188e-04 - val_loss: 4.1806e-04\n",
      "Epoch 391/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 3.8869e-04 - val_loss: 4.1382e-04\n",
      "Epoch 392/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.9566e-04 - val_loss: 4.4156e-04\n",
      "Epoch 393/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.9675e-04 - val_loss: 4.1344e-04\n",
      "Epoch 394/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 4.0375e-04 - val_loss: 4.2625e-04\n",
      "Epoch 395/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 3.9731e-04 - val_loss: 4.1665e-04\n",
      "Epoch 396/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.9103e-04 - val_loss: 4.2430e-04\n",
      "Epoch 397/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.9918e-04 - val_loss: 4.1473e-04\n",
      "Epoch 398/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.9819e-04 - val_loss: 4.1766e-04\n",
      "Epoch 399/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.9596e-04 - val_loss: 4.2145e-04\n",
      "Epoch 400/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 3.9377e-04 - val_loss: 4.6759e-04\n",
      "Epoch 401/2000\n",
      "3891/3891 [==============================] - 1s 234us/step - loss: 4.0415e-04 - val_loss: 4.1708e-04\n",
      "Epoch 402/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 3.9304e-04 - val_loss: 4.1383e-04\n",
      "Epoch 403/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 3.9432e-04 - val_loss: 4.2808e-04\n",
      "Epoch 404/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 3.9456e-04 - val_loss: 4.3092e-04\n",
      "Epoch 405/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.9164e-04 - val_loss: 4.2071e-04\n",
      "Epoch 406/2000\n",
      "3891/3891 [==============================] - 1s 222us/step - loss: 3.9743e-04 - val_loss: 4.3757e-04\n",
      "Epoch 407/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 3.9596e-04 - val_loss: 4.1387e-04\n",
      "Epoch 408/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 3.9645e-04 - val_loss: 4.1314e-04\n",
      "Epoch 409/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 3.9945e-04 - val_loss: 5.5606e-04\n",
      "Epoch 410/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 4.1370e-04 - val_loss: 4.1313e-04\n",
      "Epoch 411/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 4.0292e-04 - val_loss: 4.6562e-04\n",
      "Epoch 412/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 4.1606e-04 - val_loss: 4.1262e-04\n",
      "Epoch 413/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 3.9654e-04 - val_loss: 5.1496e-04\n",
      "Epoch 414/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 4.2670e-04 - val_loss: 4.4583e-04\n",
      "Epoch 415/2000\n",
      "3891/3891 [==============================] - 1s 235us/step - loss: 3.9482e-04 - val_loss: 4.1274e-04\n",
      "Epoch 416/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.9296e-04 - val_loss: 4.1496e-04\n",
      "Epoch 417/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.8934e-04 - val_loss: 4.1892e-04\n",
      "Epoch 418/2000\n",
      "3891/3891 [==============================] - 1s 234us/step - loss: 3.8853e-04 - val_loss: 4.2211e-04\n",
      "Epoch 419/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 3.8761e-04 - val_loss: 4.1486e-04\n",
      "Epoch 420/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 3.8707e-04 - val_loss: 4.5261e-04\n",
      "Epoch 421/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 3.9861e-04 - val_loss: 4.5502e-04\n",
      "Epoch 422/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 3.9195e-04 - val_loss: 4.2573e-04\n",
      "Epoch 423/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 3.9387e-04 - val_loss: 4.4752e-04\n",
      "Epoch 424/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 3.8967e-04 - val_loss: 4.3707e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 425/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 4.0907e-04 - val_loss: 4.4327e-04\n",
      "Epoch 426/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 4.2633e-04 - val_loss: 4.1135e-04\n",
      "Epoch 427/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.8698e-04 - val_loss: 4.1741e-04\n",
      "Epoch 428/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 3.8792e-04 - val_loss: 4.2175e-04\n",
      "Epoch 429/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 4.0771e-04 - val_loss: 4.1598e-04\n",
      "Epoch 430/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 4.0891e-04 - val_loss: 4.2680e-04\n",
      "Epoch 431/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 4.0583e-04 - val_loss: 4.1169e-04\n",
      "Epoch 432/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.8696e-04 - val_loss: 4.2186e-04\n",
      "Epoch 433/2000\n",
      "3891/3891 [==============================] - 1s 232us/step - loss: 3.8812e-04 - val_loss: 4.1531e-04\n",
      "Epoch 434/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.9381e-04 - val_loss: 4.3230e-04\n",
      "Epoch 435/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 4.4158e-04 - val_loss: 5.6311e-04\n",
      "Epoch 436/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 4.4107e-04 - val_loss: 4.4847e-04\n",
      "Epoch 437/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 3.9648e-04 - val_loss: 4.3574e-04\n",
      "Epoch 438/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.8885e-04 - val_loss: 4.4367e-04\n",
      "Epoch 439/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 3.9244e-04 - val_loss: 4.2270e-04\n",
      "Epoch 440/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 3.8868e-04 - val_loss: 4.3103e-04\n",
      "Epoch 441/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.8821e-04 - val_loss: 4.4341e-04\n",
      "Epoch 442/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 3.8868e-04 - val_loss: 4.1356e-04\n",
      "Epoch 443/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 3.9472e-04 - val_loss: 4.1980e-04\n",
      "Epoch 444/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 4.1425e-04 - val_loss: 5.0583e-04\n",
      "Epoch 445/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 4.1106e-04 - val_loss: 4.2776e-04\n",
      "Epoch 446/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 4.0829e-04 - val_loss: 4.6881e-04\n",
      "Epoch 447/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 4.1983e-04 - val_loss: 4.2293e-04\n",
      "Epoch 448/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 4.1170e-04 - val_loss: 4.9788e-04\n",
      "Epoch 449/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 3.9603e-04 - val_loss: 4.1747e-04\n",
      "Epoch 450/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 3.9144e-04 - val_loss: 4.1442e-04\n",
      "Epoch 451/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 3.9190e-04 - val_loss: 4.2439e-04\n",
      "Epoch 452/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.9534e-04 - val_loss: 4.7487e-04\n",
      "Epoch 453/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 3.9890e-04 - val_loss: 4.1413e-04\n",
      "Epoch 454/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 4.0530e-04 - val_loss: 4.3717e-04\n",
      "Epoch 455/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 4.1740e-04 - val_loss: 4.2587e-04\n",
      "Epoch 456/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 4.0149e-04 - val_loss: 4.1293e-04\n",
      "Epoch 457/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 4.0194e-04 - val_loss: 5.0662e-04\n",
      "Epoch 458/2000\n",
      "3891/3891 [==============================] - 1s 222us/step - loss: 3.9541e-04 - val_loss: 4.1873e-04\n",
      "Epoch 459/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 3.9831e-04 - val_loss: 4.2958e-04\n",
      "Epoch 460/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.9340e-04 - val_loss: 4.2168e-04\n",
      "Epoch 461/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.9974e-04 - val_loss: 4.1355e-04\n",
      "Epoch 462/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 3.8695e-04 - val_loss: 4.1431e-04\n",
      "Epoch 463/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 3.9382e-04 - val_loss: 4.2142e-04\n",
      "Epoch 464/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.8580e-04 - val_loss: 4.1390e-04\n",
      "Epoch 465/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 3.9161e-04 - val_loss: 4.1689e-04\n",
      "Epoch 466/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 3.9215e-04 - val_loss: 4.1497e-04\n",
      "Epoch 467/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 3.8778e-04 - val_loss: 4.1937e-04\n",
      "Epoch 468/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 3.9141e-04 - val_loss: 4.4636e-04\n",
      "Epoch 469/2000\n",
      "3891/3891 [==============================] - 1s 237us/step - loss: 3.8663e-04 - val_loss: 4.1412e-04\n",
      "Epoch 470/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 4.0055e-04 - val_loss: 4.1793e-04\n",
      "Epoch 471/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 3.8979e-04 - val_loss: 4.2071e-04\n",
      "Epoch 472/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 3.8688e-04 - val_loss: 4.2429e-04\n",
      "Epoch 473/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.9390e-04 - val_loss: 4.1373e-04\n",
      "Epoch 474/2000\n",
      "3891/3891 [==============================] - 1s 232us/step - loss: 3.9821e-04 - val_loss: 4.2359e-04\n",
      "Epoch 475/2000\n",
      "3891/3891 [==============================] - 1s 235us/step - loss: 3.9867e-04 - val_loss: 4.1492e-04\n",
      "Epoch 476/2000\n",
      "3891/3891 [==============================] - 1s 234us/step - loss: 3.8782e-04 - val_loss: 4.1658e-04\n",
      "Epoch 477/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 4.0024e-04 - val_loss: 4.6384e-04\n",
      "Epoch 478/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 3.9632e-04 - val_loss: 4.1464e-04\n",
      "Epoch 479/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 3.9177e-04 - val_loss: 4.2414e-04\n",
      "Epoch 480/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 3.9405e-04 - val_loss: 4.5296e-04\n",
      "Epoch 481/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 4.1237e-04 - val_loss: 4.9000e-04\n",
      "Epoch 482/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 4.2528e-04 - val_loss: 4.2293e-04\n",
      "Epoch 483/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 4.0125e-04 - val_loss: 4.4179e-04\n",
      "Epoch 484/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 4.0247e-04 - val_loss: 4.2260e-04\n",
      "Epoch 485/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 3.9333e-04 - val_loss: 4.8324e-04\n",
      "Epoch 486/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 4.0604e-04 - val_loss: 4.4894e-04\n",
      "Epoch 487/2000\n",
      "3891/3891 [==============================] - 1s 235us/step - loss: 3.8775e-04 - val_loss: 4.1906e-04\n",
      "Epoch 488/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.9051e-04 - val_loss: 4.3850e-04\n",
      "Epoch 489/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.8855e-04 - val_loss: 4.1554e-04\n",
      "Epoch 490/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 3.9123e-04 - val_loss: 4.4430e-04\n",
      "Epoch 491/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 3.8949e-04 - val_loss: 4.2062e-04\n",
      "Epoch 492/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 4.0680e-04 - val_loss: 4.8467e-04\n",
      "Epoch 493/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 4.1783e-04 - val_loss: 4.3405e-04\n",
      "Epoch 494/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 4.0356e-04 - val_loss: 5.3120e-04\n",
      "Epoch 495/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 1s 225us/step - loss: 4.0061e-04 - val_loss: 4.2106e-04\n",
      "Epoch 496/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.9446e-04 - val_loss: 4.1633e-04\n",
      "Epoch 497/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 3.8807e-04 - val_loss: 4.1761e-04\n",
      "Epoch 498/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.9497e-04 - val_loss: 4.1425e-04\n",
      "Epoch 499/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.8234e-04 - val_loss: 5.2694e-04\n",
      "Epoch 500/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 4.0221e-04 - val_loss: 4.6968e-04\n",
      "Epoch 501/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 3.9389e-04 - val_loss: 4.2754e-04\n",
      "Epoch 502/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 3.8648e-04 - val_loss: 4.3220e-04\n",
      "Epoch 503/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 3.9779e-04 - val_loss: 4.2291e-04\n",
      "Epoch 504/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 3.8646e-04 - val_loss: 4.3411e-04\n",
      "Epoch 505/2000\n",
      "3891/3891 [==============================] - 1s 232us/step - loss: 3.8597e-04 - val_loss: 4.1520e-04\n",
      "Epoch 506/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.8536e-04 - val_loss: 4.1483e-04\n",
      "Epoch 507/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 3.8697e-04 - val_loss: 4.1469e-04\n",
      "Epoch 508/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 3.8219e-04 - val_loss: 5.8359e-04\n",
      "Epoch 509/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 4.4491e-04 - val_loss: 4.1542e-04\n",
      "Epoch 510/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 4.0714e-04 - val_loss: 4.5121e-04\n",
      "Epoch 511/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 3.9787e-04 - val_loss: 4.4462e-04\n",
      "Epoch 512/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 3.9610e-04 - val_loss: 4.2749e-04\n",
      "Epoch 513/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 3.8487e-04 - val_loss: 4.2561e-04\n",
      "Epoch 514/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 3.8897e-04 - val_loss: 4.4939e-04\n",
      "Epoch 515/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.8576e-04 - val_loss: 4.2796e-04\n",
      "Epoch 516/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 3.8543e-04 - val_loss: 4.1535e-04\n",
      "Epoch 517/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 3.8235e-04 - val_loss: 4.2754e-04\n",
      "Epoch 518/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 3.9363e-04 - val_loss: 4.4722e-04\n",
      "Epoch 519/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 4.1034e-04 - val_loss: 4.3864e-04\n",
      "Epoch 520/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 4.0866e-04 - val_loss: 4.1500e-04\n",
      "Epoch 521/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 3.9739e-04 - val_loss: 4.4400e-04\n",
      "Epoch 522/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 4.0648e-04 - val_loss: 4.3561e-04\n",
      "Epoch 523/2000\n",
      "3891/3891 [==============================] - 1s 232us/step - loss: 3.9198e-04 - val_loss: 4.2702e-04\n",
      "Epoch 524/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 3.8996e-04 - val_loss: 4.3588e-04\n",
      "Epoch 525/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 4.0390e-04 - val_loss: 4.2366e-04\n",
      "Epoch 526/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 3.8845e-04 - val_loss: 4.1968e-04\n",
      "Epoch 527/2000\n",
      "3891/3891 [==============================] - 1s 222us/step - loss: 3.8050e-04 - val_loss: 4.1741e-04\n",
      "Epoch 528/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 3.8143e-04 - val_loss: 4.1479e-04\n",
      "Epoch 529/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.8449e-04 - val_loss: 4.2607e-04\n",
      "Epoch 530/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 3.8724e-04 - val_loss: 4.1681e-04\n",
      "Epoch 531/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 3.8395e-04 - val_loss: 4.5467e-04\n",
      "Epoch 532/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 3.8477e-04 - val_loss: 4.2242e-04\n",
      "Epoch 533/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 3.8894e-04 - val_loss: 4.2381e-04\n",
      "Epoch 534/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 3.9883e-04 - val_loss: 4.2121e-04\n",
      "Epoch 535/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 4.0916e-04 - val_loss: 5.6167e-04\n",
      "Epoch 536/2000\n",
      "3891/3891 [==============================] - 1s 234us/step - loss: 4.1252e-04 - val_loss: 4.7104e-04\n",
      "Epoch 537/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 4.1893e-04 - val_loss: 4.8358e-04\n",
      "Epoch 538/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 4.2408e-04 - val_loss: 4.1340e-04\n",
      "Epoch 539/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 3.8673e-04 - val_loss: 4.4520e-04\n",
      "Epoch 540/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 3.8967e-04 - val_loss: 4.9786e-04\n",
      "Epoch 541/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 3.9873e-04 - val_loss: 4.4791e-04\n",
      "Epoch 542/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.9121e-04 - val_loss: 4.6346e-04\n",
      "Epoch 543/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.9508e-04 - val_loss: 4.1810e-04\n",
      "Epoch 544/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 4.0446e-04 - val_loss: 4.1415e-04\n",
      "Epoch 545/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.8372e-04 - val_loss: 4.3294e-04\n",
      "Epoch 546/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 3.9409e-04 - val_loss: 4.3368e-04\n",
      "Epoch 547/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 3.8407e-04 - val_loss: 4.9630e-04\n",
      "Epoch 548/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 3.8939e-04 - val_loss: 4.2255e-04\n",
      "Epoch 549/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 3.8720e-04 - val_loss: 4.1763e-04\n",
      "Epoch 550/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 3.9135e-04 - val_loss: 4.5479e-04\n",
      "Epoch 551/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 4.1494e-04 - val_loss: 4.2067e-04\n",
      "Epoch 552/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 4.1098e-04 - val_loss: 4.9022e-04\n",
      "Epoch 553/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 3.8865e-04 - val_loss: 4.1911e-04\n",
      "Epoch 554/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.9246e-04 - val_loss: 4.2362e-04\n",
      "Epoch 555/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 3.9905e-04 - val_loss: 4.2454e-04\n",
      "Epoch 556/2000\n",
      "3891/3891 [==============================] - 1s 222us/step - loss: 3.9458e-04 - val_loss: 4.4969e-04\n",
      "Epoch 557/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.8147e-04 - val_loss: 4.1718e-04\n",
      "Epoch 558/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 3.8079e-04 - val_loss: 4.1700e-04\n",
      "Epoch 559/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.8925e-04 - val_loss: 4.8318e-04\n",
      "Epoch 560/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 3.8484e-04 - val_loss: 4.4062e-04\n",
      "Epoch 561/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 3.7772e-04 - val_loss: 4.2082e-04\n",
      "Epoch 562/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.8154e-04 - val_loss: 4.1822e-04\n",
      "Epoch 563/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.9311e-04 - val_loss: 5.2425e-04\n",
      "Epoch 564/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 4.0313e-04 - val_loss: 4.2962e-04\n",
      "Epoch 565/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 4.1115e-04 - val_loss: 5.1044e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 566/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 3.9833e-04 - val_loss: 4.2587e-04\n",
      "Epoch 567/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 3.8370e-04 - val_loss: 4.4397e-04\n",
      "Epoch 568/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.9626e-04 - val_loss: 4.2795e-04\n",
      "Epoch 569/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 3.8282e-04 - val_loss: 4.1743e-04\n",
      "Epoch 570/2000\n",
      "3891/3891 [==============================] - 1s 232us/step - loss: 3.8790e-04 - val_loss: 4.4410e-04\n",
      "Epoch 571/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.9528e-04 - val_loss: 4.5342e-04\n",
      "Epoch 572/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 3.9699e-04 - val_loss: 4.3725e-04\n",
      "Epoch 573/2000\n",
      "3891/3891 [==============================] - 1s 222us/step - loss: 3.8643e-04 - val_loss: 5.4937e-04\n",
      "Epoch 574/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 4.1351e-04 - val_loss: 4.3130e-04\n",
      "Epoch 575/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 4.0687e-04 - val_loss: 4.2404e-04\n",
      "Epoch 576/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 4.1238e-04 - val_loss: 5.3582e-04\n",
      "Epoch 577/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 4.5185e-04 - val_loss: 4.2412e-04\n",
      "Epoch 578/2000\n",
      "3891/3891 [==============================] - 1s 232us/step - loss: 4.0416e-04 - val_loss: 4.2203e-04\n",
      "Epoch 579/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.8225e-04 - val_loss: 4.2139e-04\n",
      "Epoch 580/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.9067e-04 - val_loss: 4.5470e-04\n",
      "Epoch 581/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 3.9113e-04 - val_loss: 4.2756e-04\n",
      "Epoch 582/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 4.0396e-04 - val_loss: 4.9259e-04\n",
      "Epoch 583/2000\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 4.1893e-04 - val_loss: 4.3559e-04\n",
      "Epoch 584/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.9361e-04 - val_loss: 4.7659e-04\n",
      "Epoch 585/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 4.0620e-04 - val_loss: 4.7266e-04\n",
      "Epoch 586/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 3.9327e-04 - val_loss: 4.1686e-04\n",
      "Epoch 587/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.8449e-04 - val_loss: 4.1753e-04\n",
      "Epoch 588/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 3.8700e-04 - val_loss: 4.1863e-04\n",
      "Epoch 589/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 3.7983e-04 - val_loss: 4.4410e-04\n",
      "Epoch 590/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.8302e-04 - val_loss: 4.5286e-04\n",
      "Epoch 591/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.8416e-04 - val_loss: 4.1935e-04\n",
      "Epoch 592/2000\n",
      "3891/3891 [==============================] - 1s 222us/step - loss: 3.7775e-04 - val_loss: 4.2385e-04\n",
      "Epoch 593/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.7912e-04 - val_loss: 4.3822e-04\n",
      "Epoch 594/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 3.8545e-04 - val_loss: 4.2627e-04\n",
      "Epoch 595/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 3.9176e-04 - val_loss: 4.1858e-04\n",
      "Epoch 596/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 3.7977e-04 - val_loss: 4.4191e-04\n",
      "Epoch 597/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 3.8678e-04 - val_loss: 4.1810e-04\n",
      "Epoch 598/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.8053e-04 - val_loss: 4.1905e-04\n",
      "Epoch 599/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.8159e-04 - val_loss: 4.1886e-04\n",
      "Epoch 600/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 3.8343e-04 - val_loss: 4.5749e-04\n",
      "Epoch 601/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 3.9344e-04 - val_loss: 4.1956e-04\n",
      "Epoch 602/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 3.7876e-04 - val_loss: 4.3434e-04\n",
      "Epoch 603/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.7944e-04 - val_loss: 4.1845e-04\n",
      "Epoch 604/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 3.8277e-04 - val_loss: 4.3225e-04\n",
      "Epoch 605/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 4.0121e-04 - val_loss: 4.6346e-04\n",
      "Epoch 606/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 3.8641e-04 - val_loss: 4.2500e-04\n",
      "Epoch 607/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 3.7849e-04 - val_loss: 4.2062e-04\n",
      "Epoch 608/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 3.8504e-04 - val_loss: 4.2442e-04\n",
      "Epoch 609/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 3.8079e-04 - val_loss: 4.2044e-04\n",
      "Epoch 610/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 3.7801e-04 - val_loss: 4.2175e-04\n",
      "Epoch 611/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 3.7771e-04 - val_loss: 4.1857e-04\n",
      "Epoch 612/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.7686e-04 - val_loss: 4.2125e-04\n",
      "Epoch 613/2000\n",
      "3891/3891 [==============================] - 1s 232us/step - loss: 3.9367e-04 - val_loss: 4.2160e-04\n",
      "Epoch 614/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 3.9786e-04 - val_loss: 5.1017e-04\n",
      "Epoch 615/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.8637e-04 - val_loss: 4.4344e-04\n",
      "Epoch 616/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 4.0375e-04 - val_loss: 4.7846e-04\n",
      "Epoch 617/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 3.9829e-04 - val_loss: 4.2103e-04\n",
      "Epoch 618/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 4.0558e-04 - val_loss: 5.4872e-04\n",
      "Epoch 619/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 4.1020e-04 - val_loss: 4.4798e-04\n",
      "Epoch 620/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 3.9406e-04 - val_loss: 4.1984e-04\n",
      "Epoch 621/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.8416e-04 - val_loss: 4.2864e-04\n",
      "Epoch 622/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.8206e-04 - val_loss: 4.1967e-04\n",
      "Epoch 623/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 3.8356e-04 - val_loss: 4.2906e-04\n",
      "Epoch 624/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 3.8546e-04 - val_loss: 4.4411e-04\n",
      "Epoch 625/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 3.7647e-04 - val_loss: 4.1988e-04\n",
      "Epoch 626/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 3.8047e-04 - val_loss: 4.1884e-04\n",
      "Epoch 627/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 3.8038e-04 - val_loss: 5.0705e-04\n",
      "Epoch 628/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.8663e-04 - val_loss: 4.1948e-04\n",
      "Epoch 629/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 3.7745e-04 - val_loss: 4.1934e-04\n",
      "Epoch 630/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.7740e-04 - val_loss: 4.1954e-04\n",
      "Epoch 631/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.7566e-04 - val_loss: 4.8484e-04\n",
      "Epoch 632/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 4.1781e-04 - val_loss: 4.9510e-04\n",
      "Epoch 633/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 4.0113e-04 - val_loss: 4.3222e-04\n",
      "Epoch 634/2000\n",
      "3891/3891 [==============================] - 1s 238us/step - loss: 3.7735e-04 - val_loss: 4.2451e-04\n",
      "Epoch 635/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 3.8021e-04 - val_loss: 4.7986e-04\n",
      "Epoch 636/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 1s 225us/step - loss: 4.0105e-04 - val_loss: 4.3929e-04\n",
      "Epoch 637/2000\n",
      "3891/3891 [==============================] - 1s 232us/step - loss: 4.4174e-04 - val_loss: 8.2197e-04\n",
      "Epoch 638/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 4.6655e-04 - val_loss: 4.4946e-04\n",
      "Epoch 639/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 3.8903e-04 - val_loss: 4.6279e-04\n",
      "Epoch 640/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 3.8163e-04 - val_loss: 4.2846e-04\n",
      "Epoch 641/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 3.7665e-04 - val_loss: 4.5783e-04\n",
      "Epoch 642/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 3.8643e-04 - val_loss: 4.2333e-04\n",
      "Epoch 643/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 4.0024e-04 - val_loss: 4.7270e-04\n",
      "Epoch 644/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 3.9737e-04 - val_loss: 4.2057e-04\n",
      "Epoch 645/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.8674e-04 - val_loss: 5.1091e-04\n",
      "Epoch 646/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 3.8585e-04 - val_loss: 4.2737e-04\n",
      "Epoch 647/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 3.8281e-04 - val_loss: 4.2221e-04\n",
      "Epoch 648/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.7262e-04 - val_loss: 4.2663e-04\n",
      "Epoch 649/2000\n",
      "3891/3891 [==============================] - 1s 232us/step - loss: 3.7272e-04 - val_loss: 4.3089e-04\n",
      "Epoch 650/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 3.8667e-04 - val_loss: 4.6151e-04\n",
      "Epoch 651/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 3.9483e-04 - val_loss: 4.7590e-04\n",
      "Epoch 652/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 3.9294e-04 - val_loss: 4.2038e-04\n",
      "Epoch 653/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 3.7578e-04 - val_loss: 4.3114e-04\n",
      "Epoch 654/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.7165e-04 - val_loss: 4.2059e-04\n",
      "Epoch 655/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.7309e-04 - val_loss: 4.3320e-04\n",
      "Epoch 656/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 3.7298e-04 - val_loss: 4.3616e-04\n",
      "Epoch 657/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 3.8959e-04 - val_loss: 4.6352e-04\n",
      "Epoch 658/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.7583e-04 - val_loss: 4.2076e-04\n",
      "Epoch 659/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 3.7401e-04 - val_loss: 4.2733e-04\n",
      "Epoch 660/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.7864e-04 - val_loss: 4.9193e-04\n",
      "Epoch 661/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.8336e-04 - val_loss: 4.2141e-04\n",
      "Epoch 662/2000\n",
      "3891/3891 [==============================] - 1s 222us/step - loss: 3.7312e-04 - val_loss: 4.4101e-04\n",
      "Epoch 663/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 3.7557e-04 - val_loss: 4.3079e-04\n",
      "Epoch 664/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.7940e-04 - val_loss: 4.2968e-04\n",
      "Epoch 665/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 3.7755e-04 - val_loss: 4.2170e-04\n",
      "Epoch 666/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 3.8442e-04 - val_loss: 4.3893e-04\n",
      "Epoch 667/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 3.7133e-04 - val_loss: 4.2271e-04\n",
      "Epoch 668/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 3.8294e-04 - val_loss: 4.8414e-04\n",
      "Epoch 669/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 4.0390e-04 - val_loss: 4.4991e-04\n",
      "Epoch 670/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 3.7909e-04 - val_loss: 4.3229e-04\n",
      "Epoch 671/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.6868e-04 - val_loss: 4.2617e-04\n",
      "Epoch 672/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 3.7077e-04 - val_loss: 4.2437e-04\n",
      "Epoch 673/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 3.7091e-04 - val_loss: 4.5195e-04\n",
      "Epoch 674/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 3.7041e-04 - val_loss: 4.2496e-04\n",
      "Epoch 675/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 3.7619e-04 - val_loss: 4.2805e-04\n",
      "Epoch 676/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 3.7026e-04 - val_loss: 4.2491e-04\n",
      "Epoch 677/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.6735e-04 - val_loss: 4.4745e-04\n",
      "Epoch 678/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 3.8171e-04 - val_loss: 4.2938e-04\n",
      "Epoch 679/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 3.9530e-04 - val_loss: 4.8258e-04\n",
      "Epoch 680/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 3.9520e-04 - val_loss: 4.3313e-04\n",
      "Epoch 681/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 4.0415e-04 - val_loss: 5.0482e-04\n",
      "Epoch 682/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 3.8596e-04 - val_loss: 4.4987e-04\n",
      "Epoch 683/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.9369e-04 - val_loss: 4.7267e-04\n",
      "Epoch 684/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 3.8518e-04 - val_loss: 5.3263e-04\n",
      "Epoch 685/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 4.1141e-04 - val_loss: 4.4051e-04\n",
      "Epoch 686/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 4.0501e-04 - val_loss: 5.1055e-04\n",
      "Epoch 687/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 4.1133e-04 - val_loss: 4.2253e-04\n",
      "Epoch 688/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.8168e-04 - val_loss: 4.2910e-04\n",
      "Epoch 689/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.7890e-04 - val_loss: 4.6158e-04\n",
      "Epoch 690/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.8452e-04 - val_loss: 5.0944e-04\n",
      "Epoch 691/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 3.8971e-04 - val_loss: 4.2564e-04\n",
      "Epoch 692/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.8146e-04 - val_loss: 4.2691e-04\n",
      "Epoch 693/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.8858e-04 - val_loss: 5.0987e-04\n",
      "Epoch 694/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 4.0914e-04 - val_loss: 4.8578e-04\n",
      "Epoch 695/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 4.1188e-04 - val_loss: 4.7924e-04\n",
      "Epoch 696/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 3.8405e-04 - val_loss: 4.8104e-04\n",
      "Epoch 697/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 3.7949e-04 - val_loss: 4.4316e-04\n",
      "Epoch 698/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 3.7422e-04 - val_loss: 4.3231e-04\n",
      "Epoch 699/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.6405e-04 - val_loss: 4.4305e-04\n",
      "Epoch 700/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 3.6528e-04 - val_loss: 4.4106e-04\n",
      "Epoch 701/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.6139e-04 - val_loss: 4.6237e-04\n",
      "Epoch 702/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 3.6450e-04 - val_loss: 4.5729e-04\n",
      "Epoch 703/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 3.6568e-04 - val_loss: 4.4896e-04\n",
      "Epoch 704/2000\n",
      "3891/3891 [==============================] - 1s 233us/step - loss: 3.7884e-04 - val_loss: 4.9100e-04\n",
      "Epoch 705/2000\n",
      "3891/3891 [==============================] - 1s 232us/step - loss: 3.7615e-04 - val_loss: 4.6228e-04\n",
      "Epoch 706/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 3.6340e-04 - val_loss: 4.5077e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 707/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 3.6048e-04 - val_loss: 4.6055e-04\n",
      "Epoch 708/2000\n",
      "3891/3891 [==============================] - 1s 238us/step - loss: 3.6709e-04 - val_loss: 4.6324e-04\n",
      "Epoch 709/2000\n",
      "3891/3891 [==============================] - 1s 239us/step - loss: 3.7783e-04 - val_loss: 4.6748e-04\n",
      "Epoch 710/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.7338e-04 - val_loss: 4.8418e-04\n",
      "Epoch 711/2000\n",
      "3891/3891 [==============================] - 1s 234us/step - loss: 3.7152e-04 - val_loss: 5.2199e-04\n",
      "Epoch 712/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 3.9165e-04 - val_loss: 4.4441e-04\n",
      "Epoch 713/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.6326e-04 - val_loss: 4.5020e-04\n",
      "Epoch 714/2000\n",
      "3891/3891 [==============================] - 1s 233us/step - loss: 3.5751e-04 - val_loss: 4.6297e-04\n",
      "Epoch 715/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 3.6129e-04 - val_loss: 4.6717e-04\n",
      "Epoch 716/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 3.5616e-04 - val_loss: 4.6122e-04\n",
      "Epoch 717/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 3.5432e-04 - val_loss: 4.7143e-04\n",
      "Epoch 718/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 3.5790e-04 - val_loss: 4.7768e-04\n",
      "Epoch 719/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 3.6079e-04 - val_loss: 4.6084e-04\n",
      "Epoch 720/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.5961e-04 - val_loss: 4.9782e-04\n",
      "Epoch 721/2000\n",
      "3891/3891 [==============================] - 1s 232us/step - loss: 3.6171e-04 - val_loss: 4.7550e-04\n",
      "Epoch 722/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 3.7171e-04 - val_loss: 4.8031e-04\n",
      "Epoch 723/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 3.6599e-04 - val_loss: 4.6634e-04\n",
      "Epoch 724/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 3.6451e-04 - val_loss: 5.8468e-04\n",
      "Epoch 725/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.9302e-04 - val_loss: 4.6513e-04\n",
      "Epoch 726/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.7980e-04 - val_loss: 5.2340e-04\n",
      "Epoch 727/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 3.9257e-04 - val_loss: 4.4966e-04\n",
      "Epoch 728/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 3.7825e-04 - val_loss: 4.9274e-04\n",
      "Epoch 729/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 3.6964e-04 - val_loss: 4.6172e-04\n",
      "Epoch 730/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 3.5931e-04 - val_loss: 4.6012e-04\n",
      "Epoch 731/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 3.7701e-04 - val_loss: 4.7317e-04\n",
      "Epoch 732/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 3.7391e-04 - val_loss: 4.6156e-04\n",
      "Epoch 733/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 3.5993e-04 - val_loss: 4.6179e-04\n",
      "Epoch 734/2000\n",
      "3891/3891 [==============================] - 1s 232us/step - loss: 3.5592e-04 - val_loss: 5.7803e-04\n",
      "Epoch 735/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.7675e-04 - val_loss: 4.5158e-04\n",
      "Epoch 736/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 3.5341e-04 - val_loss: 4.6294e-04\n",
      "Epoch 737/2000\n",
      "3891/3891 [==============================] - 1s 232us/step - loss: 3.5172e-04 - val_loss: 5.0642e-04\n",
      "Epoch 738/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 3.6341e-04 - val_loss: 4.7138e-04\n",
      "Epoch 739/2000\n",
      "3891/3891 [==============================] - 1s 239us/step - loss: 3.5815e-04 - val_loss: 4.9108e-04\n",
      "Epoch 740/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 3.5221e-04 - val_loss: 4.8548e-04\n",
      "Epoch 741/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 3.5393e-04 - val_loss: 4.9297e-04\n",
      "Epoch 742/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.5674e-04 - val_loss: 4.9947e-04\n",
      "Epoch 743/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 3.5991e-04 - val_loss: 4.6722e-04\n",
      "Epoch 744/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.5422e-04 - val_loss: 4.6821e-04\n",
      "Epoch 745/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.5922e-04 - val_loss: 4.8127e-04\n",
      "Epoch 746/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.5200e-04 - val_loss: 4.6968e-04\n",
      "Epoch 747/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.5143e-04 - val_loss: 4.9087e-04\n",
      "Epoch 748/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 3.6423e-04 - val_loss: 5.0776e-04\n",
      "Epoch 749/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 3.6070e-04 - val_loss: 4.9770e-04\n",
      "Epoch 750/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 3.6624e-04 - val_loss: 4.6654e-04\n",
      "Epoch 751/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 3.6119e-04 - val_loss: 4.8828e-04\n",
      "Epoch 752/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.5705e-04 - val_loss: 4.7971e-04\n",
      "Epoch 753/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 3.5445e-04 - val_loss: 4.6340e-04\n",
      "Epoch 754/2000\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 3.5426e-04 - val_loss: 4.7528e-04\n",
      "Epoch 755/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 3.4754e-04 - val_loss: 5.0997e-04\n",
      "Epoch 756/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.5462e-04 - val_loss: 4.8327e-04\n",
      "Epoch 757/2000\n",
      "3891/3891 [==============================] - 1s 233us/step - loss: 3.5656e-04 - val_loss: 5.2551e-04\n",
      "Epoch 758/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 3.5021e-04 - val_loss: 4.7390e-04\n",
      "Epoch 759/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 3.5102e-04 - val_loss: 4.8310e-04\n",
      "Epoch 760/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 3.4696e-04 - val_loss: 5.4083e-04\n",
      "Epoch 761/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 3.6586e-04 - val_loss: 5.7415e-04\n",
      "Epoch 762/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 3.5876e-04 - val_loss: 4.8372e-04\n",
      "Epoch 763/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.5015e-04 - val_loss: 5.0818e-04\n",
      "Epoch 764/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 3.5570e-04 - val_loss: 4.9640e-04\n",
      "Epoch 765/2000\n",
      "3891/3891 [==============================] - 1s 234us/step - loss: 3.5662e-04 - val_loss: 5.3700e-04\n",
      "Epoch 766/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 3.5663e-04 - val_loss: 5.2107e-04\n",
      "Epoch 767/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 3.5510e-04 - val_loss: 4.7982e-04\n",
      "Epoch 768/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.5582e-04 - val_loss: 4.7906e-04\n",
      "Epoch 769/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 3.6929e-04 - val_loss: 4.7664e-04\n",
      "Epoch 770/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.6914e-04 - val_loss: 5.5610e-04\n",
      "Epoch 771/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 3.6480e-04 - val_loss: 4.7951e-04\n",
      "Epoch 772/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 3.5219e-04 - val_loss: 4.9013e-04\n",
      "Epoch 773/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.5629e-04 - val_loss: 4.7598e-04\n",
      "Epoch 774/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.4878e-04 - val_loss: 5.0819e-04\n",
      "Epoch 775/2000\n",
      "3891/3891 [==============================] - 1s 233us/step - loss: 3.5136e-04 - val_loss: 4.8145e-04\n",
      "Epoch 776/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 3.4845e-04 - val_loss: 4.9663e-04\n",
      "Epoch 777/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 1s 224us/step - loss: 3.4467e-04 - val_loss: 4.9925e-04\n",
      "Epoch 778/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 3.4890e-04 - val_loss: 5.0919e-04\n",
      "Epoch 779/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 3.4469e-04 - val_loss: 5.2278e-04\n",
      "Epoch 780/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 3.5087e-04 - val_loss: 5.4733e-04\n",
      "Epoch 781/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.6582e-04 - val_loss: 5.3423e-04\n",
      "Epoch 782/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 3.5414e-04 - val_loss: 5.1662e-04\n",
      "Epoch 783/2000\n",
      "3891/3891 [==============================] - 1s 232us/step - loss: 3.5318e-04 - val_loss: 5.4467e-04\n",
      "Epoch 784/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 3.6076e-04 - val_loss: 5.0694e-04\n",
      "Epoch 785/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.6571e-04 - val_loss: 5.0086e-04\n",
      "Epoch 786/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 3.5580e-04 - val_loss: 5.1328e-04\n",
      "Epoch 787/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 3.5172e-04 - val_loss: 4.8190e-04\n",
      "Epoch 788/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 3.4481e-04 - val_loss: 5.9027e-04\n",
      "Epoch 789/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 3.6387e-04 - val_loss: 4.8469e-04\n",
      "Epoch 790/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 3.5389e-04 - val_loss: 5.5614e-04\n",
      "Epoch 791/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.6310e-04 - val_loss: 4.9501e-04\n",
      "Epoch 792/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.5751e-04 - val_loss: 4.8709e-04\n",
      "Epoch 793/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 3.6162e-04 - val_loss: 5.2314e-04\n",
      "Epoch 794/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.5649e-04 - val_loss: 5.5916e-04\n",
      "Epoch 795/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 3.5571e-04 - val_loss: 5.2823e-04\n",
      "Epoch 796/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 3.5189e-04 - val_loss: 5.2004e-04\n",
      "Epoch 797/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.5057e-04 - val_loss: 5.6541e-04\n",
      "Epoch 798/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 3.6708e-04 - val_loss: 5.2954e-04\n",
      "Epoch 799/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 3.7955e-04 - val_loss: 6.1234e-04\n",
      "Epoch 800/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 3.6451e-04 - val_loss: 4.9992e-04\n",
      "Epoch 801/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 3.4778e-04 - val_loss: 5.1976e-04\n",
      "Epoch 802/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.5690e-04 - val_loss: 5.7366e-04\n",
      "Epoch 803/2000\n",
      "3891/3891 [==============================] - 1s 232us/step - loss: 3.7465e-04 - val_loss: 5.2417e-04\n",
      "Epoch 804/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.6609e-04 - val_loss: 5.9297e-04\n",
      "Epoch 805/2000\n",
      "3891/3891 [==============================] - 1s 233us/step - loss: 3.7076e-04 - val_loss: 4.8987e-04\n",
      "Epoch 806/2000\n",
      "3891/3891 [==============================] - 1s 234us/step - loss: 3.5877e-04 - val_loss: 4.9084e-04\n",
      "Epoch 807/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.4900e-04 - val_loss: 5.7573e-04\n",
      "Epoch 808/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 3.5374e-04 - val_loss: 5.1717e-04\n",
      "Epoch 809/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 3.7265e-04 - val_loss: 5.0688e-04\n",
      "Epoch 810/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 3.4740e-04 - val_loss: 4.8928e-04\n",
      "Epoch 811/2000\n",
      "3891/3891 [==============================] - 1s 236us/step - loss: 3.5373e-04 - val_loss: 5.9102e-04\n",
      "Epoch 812/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 3.5795e-04 - val_loss: 5.8345e-04\n",
      "Epoch 813/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.5955e-04 - val_loss: 5.0773e-04\n",
      "Epoch 814/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 3.4668e-04 - val_loss: 5.1255e-04\n",
      "Epoch 815/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 3.4498e-04 - val_loss: 5.1262e-04\n",
      "Epoch 816/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 3.5005e-04 - val_loss: 5.3109e-04\n",
      "Epoch 817/2000\n",
      "3891/3891 [==============================] - 1s 232us/step - loss: 3.5876e-04 - val_loss: 5.2625e-04\n",
      "Epoch 818/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.5285e-04 - val_loss: 5.2715e-04\n",
      "Epoch 819/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.4072e-04 - val_loss: 5.7512e-04\n",
      "Epoch 820/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.4228e-04 - val_loss: 5.2770e-04\n",
      "Epoch 821/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.4292e-04 - val_loss: 5.8257e-04\n",
      "Epoch 822/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 3.5174e-04 - val_loss: 5.3771e-04\n",
      "Epoch 823/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.3999e-04 - val_loss: 5.2643e-04\n",
      "Epoch 824/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 3.4051e-04 - val_loss: 5.2129e-04\n",
      "Epoch 825/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 3.4751e-04 - val_loss: 5.1504e-04\n",
      "Epoch 826/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 3.4376e-04 - val_loss: 5.5649e-04\n",
      "Epoch 827/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 3.4943e-04 - val_loss: 5.2864e-04\n",
      "Epoch 828/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 3.5920e-04 - val_loss: 4.6996e-04\n",
      "Epoch 829/2000\n",
      "3891/3891 [==============================] - 1s 233us/step - loss: 3.6788e-04 - val_loss: 5.3948e-04\n",
      "Epoch 830/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 3.6337e-04 - val_loss: 4.5855e-04\n",
      "Epoch 831/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 3.5523e-04 - val_loss: 4.7313e-04\n",
      "Epoch 832/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 3.8076e-04 - val_loss: 5.4172e-04\n",
      "Epoch 833/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.5601e-04 - val_loss: 4.8152e-04\n",
      "Epoch 834/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 3.4612e-04 - val_loss: 4.9965e-04\n",
      "Epoch 835/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 3.4014e-04 - val_loss: 5.9610e-04\n",
      "Epoch 836/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 3.4705e-04 - val_loss: 5.4724e-04\n",
      "Epoch 837/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 3.6426e-04 - val_loss: 5.0635e-04\n",
      "Epoch 838/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 3.5322e-04 - val_loss: 5.8266e-04\n",
      "Epoch 839/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 3.6084e-04 - val_loss: 6.1364e-04\n",
      "Epoch 840/2000\n",
      "3891/3891 [==============================] - 1s 232us/step - loss: 4.2531e-04 - val_loss: 5.0250e-04\n",
      "Epoch 841/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.7296e-04 - val_loss: 4.9432e-04\n",
      "Epoch 842/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 3.5238e-04 - val_loss: 5.2471e-04\n",
      "Epoch 843/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 3.4808e-04 - val_loss: 5.7767e-04\n",
      "Epoch 844/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.6560e-04 - val_loss: 5.3116e-04\n",
      "Epoch 845/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.7205e-04 - val_loss: 6.3243e-04\n",
      "Epoch 846/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.9105e-04 - val_loss: 6.6483e-04\n",
      "Epoch 847/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 3.6562e-04 - val_loss: 5.0051e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 848/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.5493e-04 - val_loss: 5.4053e-04\n",
      "Epoch 849/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.4968e-04 - val_loss: 5.7566e-04\n",
      "Epoch 850/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 3.6040e-04 - val_loss: 5.3803e-04\n",
      "Epoch 851/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.5555e-04 - val_loss: 5.4441e-04\n",
      "Epoch 852/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 3.5419e-04 - val_loss: 5.4779e-04\n",
      "Epoch 853/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.4345e-04 - val_loss: 5.3245e-04\n",
      "Epoch 854/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 3.4586e-04 - val_loss: 5.3850e-04\n",
      "Epoch 855/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 3.3665e-04 - val_loss: 5.7635e-04\n",
      "Epoch 856/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 3.3921e-04 - val_loss: 5.5334e-04\n",
      "Epoch 857/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 3.3247e-04 - val_loss: 5.6651e-04\n",
      "Epoch 858/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.3288e-04 - val_loss: 5.8973e-04\n",
      "Epoch 859/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 3.4081e-04 - val_loss: 5.7957e-04\n",
      "Epoch 860/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.3615e-04 - val_loss: 5.9416e-04\n",
      "Epoch 861/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 3.5375e-04 - val_loss: 5.3609e-04\n",
      "Epoch 862/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.3810e-04 - val_loss: 5.9370e-04\n",
      "Epoch 863/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 3.4160e-04 - val_loss: 5.3426e-04\n",
      "Epoch 864/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.3984e-04 - val_loss: 5.6962e-04\n",
      "Epoch 865/2000\n",
      "3891/3891 [==============================] - 1s 232us/step - loss: 3.5988e-04 - val_loss: 4.7977e-04\n",
      "Epoch 866/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.5136e-04 - val_loss: 5.1583e-04\n",
      "Epoch 867/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.3629e-04 - val_loss: 5.4504e-04\n",
      "Epoch 868/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.2925e-04 - val_loss: 5.4815e-04\n",
      "Epoch 869/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 3.2962e-04 - val_loss: 5.7185e-04\n",
      "Epoch 870/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 3.2948e-04 - val_loss: 5.6550e-04\n",
      "Epoch 871/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 3.3562e-04 - val_loss: 5.5829e-04\n",
      "Epoch 872/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.3106e-04 - val_loss: 5.6406e-04\n",
      "Epoch 873/2000\n",
      "3891/3891 [==============================] - 1s 234us/step - loss: 3.3186e-04 - val_loss: 5.4336e-04\n",
      "Epoch 874/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.2930e-04 - val_loss: 5.8290e-04\n",
      "Epoch 875/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 3.2686e-04 - val_loss: 5.6774e-04\n",
      "Epoch 876/2000\n",
      "3891/3891 [==============================] - 1s 233us/step - loss: 3.2500e-04 - val_loss: 5.5296e-04\n",
      "Epoch 877/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 3.2448e-04 - val_loss: 5.6667e-04\n",
      "Epoch 878/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 3.2744e-04 - val_loss: 6.5410e-04\n",
      "Epoch 879/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 3.7386e-04 - val_loss: 5.7664e-04\n",
      "Epoch 880/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.5688e-04 - val_loss: 5.6886e-04\n",
      "Epoch 881/2000\n",
      "3891/3891 [==============================] - 1s 232us/step - loss: 3.6258e-04 - val_loss: 5.3491e-04\n",
      "Epoch 882/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 3.3556e-04 - val_loss: 6.1094e-04\n",
      "Epoch 883/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 3.3565e-04 - val_loss: 5.6311e-04\n",
      "Epoch 884/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.3295e-04 - val_loss: 6.2655e-04\n",
      "Epoch 885/2000\n",
      "3891/3891 [==============================] - 1s 240us/step - loss: 3.3517e-04 - val_loss: 6.1772e-04\n",
      "Epoch 886/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 3.3011e-04 - val_loss: 6.1302e-04\n",
      "Epoch 887/2000\n",
      "3891/3891 [==============================] - 1s 236us/step - loss: 3.2836e-04 - val_loss: 6.1725e-04\n",
      "Epoch 888/2000\n",
      "3891/3891 [==============================] - 1s 235us/step - loss: 3.2537e-04 - val_loss: 6.0169e-04\n",
      "Epoch 889/2000\n",
      "3891/3891 [==============================] - 1s 232us/step - loss: 3.4024e-04 - val_loss: 5.8384e-04\n",
      "Epoch 890/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 3.3105e-04 - val_loss: 5.7178e-04\n",
      "Epoch 891/2000\n",
      "3891/3891 [==============================] - 1s 239us/step - loss: 3.2982e-04 - val_loss: 5.9710e-04\n",
      "Epoch 892/2000\n",
      "3891/3891 [==============================] - 1s 244us/step - loss: 3.3051e-04 - val_loss: 5.7874e-04\n",
      "Epoch 893/2000\n",
      "3891/3891 [==============================] - 1s 238us/step - loss: 3.2676e-04 - val_loss: 6.0066e-04\n",
      "Epoch 894/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 3.2248e-04 - val_loss: 6.0873e-04\n",
      "Epoch 895/2000\n",
      "3891/3891 [==============================] - 1s 232us/step - loss: 3.4095e-04 - val_loss: 5.7999e-04\n",
      "Epoch 896/2000\n",
      "3891/3891 [==============================] - 1s 235us/step - loss: 3.4195e-04 - val_loss: 5.7565e-04\n",
      "Epoch 897/2000\n",
      "3891/3891 [==============================] - 1s 234us/step - loss: 3.3553e-04 - val_loss: 6.0600e-04\n",
      "Epoch 898/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 3.5400e-04 - val_loss: 6.4203e-04\n",
      "Epoch 899/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 3.6162e-04 - val_loss: 6.9297e-04\n",
      "Epoch 900/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 3.5363e-04 - val_loss: 5.7677e-04\n",
      "Epoch 901/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 3.3141e-04 - val_loss: 5.7108e-04\n",
      "Epoch 902/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 3.3004e-04 - val_loss: 5.8524e-04\n",
      "Epoch 903/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 3.4389e-04 - val_loss: 5.9913e-04\n",
      "Epoch 904/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 3.2673e-04 - val_loss: 8.8412e-04\n",
      "Epoch 905/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 3.4951e-04 - val_loss: 5.9347e-04\n",
      "Epoch 906/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.3590e-04 - val_loss: 6.1639e-04\n",
      "Epoch 907/2000\n",
      "3891/3891 [==============================] - 1s 235us/step - loss: 3.3070e-04 - val_loss: 5.6443e-04\n",
      "Epoch 908/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 3.2196e-04 - val_loss: 6.2994e-04\n",
      "Epoch 909/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.2816e-04 - val_loss: 6.1629e-04\n",
      "Epoch 910/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 3.1966e-04 - val_loss: 5.8499e-04\n",
      "Epoch 911/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 3.1935e-04 - val_loss: 6.3979e-04\n",
      "Epoch 912/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.4525e-04 - val_loss: 6.4110e-04\n",
      "Epoch 913/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.4051e-04 - val_loss: 6.0030e-04\n",
      "Epoch 914/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 3.2187e-04 - val_loss: 5.9267e-04\n",
      "Epoch 915/2000\n",
      "3891/3891 [==============================] - 1s 221us/step - loss: 3.2166e-04 - val_loss: 6.2200e-04\n",
      "Epoch 916/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 3.1698e-04 - val_loss: 6.5089e-04\n",
      "Epoch 917/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 3.1742e-04 - val_loss: 6.6337e-04\n",
      "Epoch 918/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 1s 232us/step - loss: 3.2027e-04 - val_loss: 6.6035e-04\n",
      "Epoch 919/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.2357e-04 - val_loss: 5.8383e-04\n",
      "Epoch 920/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.1791e-04 - val_loss: 6.0734e-04\n",
      "Epoch 921/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 3.1056e-04 - val_loss: 6.1862e-04\n",
      "Epoch 922/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.2138e-04 - val_loss: 6.3125e-04\n",
      "Epoch 923/2000\n",
      "3891/3891 [==============================] - 1s 222us/step - loss: 3.2322e-04 - val_loss: 6.3685e-04\n",
      "Epoch 924/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 3.2807e-04 - val_loss: 6.0817e-04\n",
      "Epoch 925/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.3455e-04 - val_loss: 6.5773e-04\n",
      "Epoch 926/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.2219e-04 - val_loss: 6.4337e-04\n",
      "Epoch 927/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.2431e-04 - val_loss: 5.4312e-04\n",
      "Epoch 928/2000\n",
      "3891/3891 [==============================] - 1s 232us/step - loss: 3.5022e-04 - val_loss: 7.4198e-04\n",
      "Epoch 929/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.4146e-04 - val_loss: 5.6821e-04\n",
      "Epoch 930/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 3.2125e-04 - val_loss: 6.7946e-04\n",
      "Epoch 931/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 3.2582e-04 - val_loss: 6.4212e-04\n",
      "Epoch 932/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 3.7038e-04 - val_loss: 6.9107e-04\n",
      "Epoch 933/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 3.7567e-04 - val_loss: 7.3509e-04\n",
      "Epoch 934/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.5520e-04 - val_loss: 5.9922e-04\n",
      "Epoch 935/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 3.4484e-04 - val_loss: 5.1107e-04\n",
      "Epoch 936/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.2128e-04 - val_loss: 5.6109e-04\n",
      "Epoch 937/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 3.2928e-04 - val_loss: 6.2947e-04\n",
      "Epoch 938/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 3.3649e-04 - val_loss: 6.1670e-04\n",
      "Epoch 939/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 3.2783e-04 - val_loss: 6.3842e-04\n",
      "Epoch 940/2000\n",
      "3891/3891 [==============================] - 1s 247us/step - loss: 3.1695e-04 - val_loss: 6.7223e-04\n",
      "Epoch 941/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 3.2365e-04 - val_loss: 6.3865e-04\n",
      "Epoch 942/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 3.1885e-04 - val_loss: 6.9993e-04\n",
      "Epoch 943/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 3.1159e-04 - val_loss: 6.2355e-04\n",
      "Epoch 944/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 3.0459e-04 - val_loss: 6.5672e-04\n",
      "Epoch 945/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 3.1377e-04 - val_loss: 6.9558e-04\n",
      "Epoch 946/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 3.1728e-04 - val_loss: 5.8184e-04\n",
      "Epoch 947/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 3.1248e-04 - val_loss: 6.6223e-04\n",
      "Epoch 948/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 3.1510e-04 - val_loss: 6.7623e-04\n",
      "Epoch 949/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.1407e-04 - val_loss: 6.8195e-04\n",
      "Epoch 950/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 3.0175e-04 - val_loss: 6.6355e-04\n",
      "Epoch 951/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 3.0311e-04 - val_loss: 6.0340e-04\n",
      "Epoch 952/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.1047e-04 - val_loss: 6.6510e-04\n",
      "Epoch 953/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 3.0541e-04 - val_loss: 7.2866e-04\n",
      "Epoch 954/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 3.1401e-04 - val_loss: 7.5639e-04\n",
      "Epoch 955/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 2.9993e-04 - val_loss: 6.7744e-04\n",
      "Epoch 956/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.0922e-04 - val_loss: 6.7855e-04\n",
      "Epoch 957/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 3.0776e-04 - val_loss: 6.2923e-04\n",
      "Epoch 958/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 2.9706e-04 - val_loss: 8.0101e-04\n",
      "Epoch 959/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 3.1346e-04 - val_loss: 6.5902e-04\n",
      "Epoch 960/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 3.0297e-04 - val_loss: 6.9523e-04\n",
      "Epoch 961/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 3.0143e-04 - val_loss: 7.5382e-04\n",
      "Epoch 962/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.0952e-04 - val_loss: 7.9249e-04\n",
      "Epoch 963/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.1334e-04 - val_loss: 7.5397e-04\n",
      "Epoch 964/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.1232e-04 - val_loss: 7.5184e-04\n",
      "Epoch 965/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.2660e-04 - val_loss: 6.3462e-04\n",
      "Epoch 966/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.1389e-04 - val_loss: 6.4049e-04\n",
      "Epoch 967/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.2814e-04 - val_loss: 5.9808e-04\n",
      "Epoch 968/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 3.0908e-04 - val_loss: 8.0728e-04\n",
      "Epoch 969/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 3.0671e-04 - val_loss: 7.4716e-04\n",
      "Epoch 970/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 2.9543e-04 - val_loss: 7.4393e-04\n",
      "Epoch 971/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 2.9674e-04 - val_loss: 7.1995e-04\n",
      "Epoch 972/2000\n",
      "3891/3891 [==============================] - 1s 232us/step - loss: 3.0632e-04 - val_loss: 9.5991e-04\n",
      "Epoch 973/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 3.1927e-04 - val_loss: 8.4902e-04\n",
      "Epoch 974/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 3.1771e-04 - val_loss: 0.0010\n",
      "Epoch 975/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 3.2072e-04 - val_loss: 6.8354e-04\n",
      "Epoch 976/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 3.5090e-04 - val_loss: 6.7449e-04\n",
      "Epoch 977/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.2536e-04 - val_loss: 6.7986e-04\n",
      "Epoch 978/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 3.1187e-04 - val_loss: 6.8911e-04\n",
      "Epoch 979/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 2.9413e-04 - val_loss: 7.0536e-04\n",
      "Epoch 980/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 2.9476e-04 - val_loss: 7.1412e-04\n",
      "Epoch 981/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 3.0226e-04 - val_loss: 7.9802e-04\n",
      "Epoch 982/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 2.9830e-04 - val_loss: 6.8846e-04\n",
      "Epoch 983/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 2.9739e-04 - val_loss: 8.1274e-04\n",
      "Epoch 984/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 2.9501e-04 - val_loss: 7.3285e-04\n",
      "Epoch 985/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 2.9117e-04 - val_loss: 9.0449e-04\n",
      "Epoch 986/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 2.8780e-04 - val_loss: 0.0010\n",
      "Epoch 987/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 2.8439e-04 - val_loss: 9.0656e-04\n",
      "Epoch 988/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 2.9092e-04 - val_loss: 9.2486e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 989/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 2.8235e-04 - val_loss: 8.4352e-04\n",
      "Epoch 990/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 2.9696e-04 - val_loss: 9.7154e-04\n",
      "Epoch 991/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 2.9119e-04 - val_loss: 8.9696e-04\n",
      "Epoch 992/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 2.8472e-04 - val_loss: 9.2346e-04\n",
      "Epoch 993/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 2.9449e-04 - val_loss: 9.4600e-04\n",
      "Epoch 994/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 2.8816e-04 - val_loss: 0.0010\n",
      "Epoch 995/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 2.8414e-04 - val_loss: 7.9230e-04\n",
      "Epoch 996/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 3.1163e-04 - val_loss: 7.1826e-04\n",
      "Epoch 997/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.0726e-04 - val_loss: 8.2502e-04\n",
      "Epoch 998/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 3.0581e-04 - val_loss: 9.2413e-04\n",
      "Epoch 999/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 2.8519e-04 - val_loss: 0.0010\n",
      "Epoch 1000/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 2.8781e-04 - val_loss: 0.0010\n",
      "Epoch 1001/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 2.9048e-04 - val_loss: 8.6329e-04\n",
      "Epoch 1002/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 2.8503e-04 - val_loss: 9.6652e-04\n",
      "Epoch 1003/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 2.7351e-04 - val_loss: 0.0011\n",
      "Epoch 1004/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 2.9712e-04 - val_loss: 9.5387e-04\n",
      "Epoch 1005/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 2.9707e-04 - val_loss: 9.4829e-04\n",
      "Epoch 1006/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 2.9874e-04 - val_loss: 8.4561e-04\n",
      "Epoch 1007/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 2.8491e-04 - val_loss: 0.0012\n",
      "Epoch 1008/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 2.8315e-04 - val_loss: 0.0011\n",
      "Epoch 1009/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 2.7031e-04 - val_loss: 9.9646e-04\n",
      "Epoch 1010/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 3.0619e-04 - val_loss: 9.5411e-04\n",
      "Epoch 1011/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 2.9473e-04 - val_loss: 8.9018e-04\n",
      "Epoch 1012/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 2.9564e-04 - val_loss: 0.0011\n",
      "Epoch 1013/2000\n",
      "3891/3891 [==============================] - 1s 222us/step - loss: 3.0543e-04 - val_loss: 0.0012\n",
      "Epoch 1014/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 2.8285e-04 - val_loss: 9.2583e-04\n",
      "Epoch 1015/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 2.9070e-04 - val_loss: 9.9960e-04\n",
      "Epoch 1016/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 2.8786e-04 - val_loss: 8.8000e-04\n",
      "Epoch 1017/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 2.8862e-04 - val_loss: 0.0011\n",
      "Epoch 1018/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 2.7190e-04 - val_loss: 9.3157e-04\n",
      "Epoch 1019/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 2.7703e-04 - val_loss: 9.6795e-04\n",
      "Epoch 1020/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 2.7970e-04 - val_loss: 9.8511e-04\n",
      "Epoch 1021/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 2.9029e-04 - val_loss: 7.9729e-04\n",
      "Epoch 1022/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 2.9303e-04 - val_loss: 0.0011\n",
      "Epoch 1023/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 3.0406e-04 - val_loss: 0.0014\n",
      "Epoch 1024/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 2.7958e-04 - val_loss: 9.1904e-04\n",
      "Epoch 1025/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 2.7536e-04 - val_loss: 0.0011\n",
      "Epoch 1026/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 2.7365e-04 - val_loss: 9.5920e-04\n",
      "Epoch 1027/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 2.7584e-04 - val_loss: 0.0010\n",
      "Epoch 1028/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 2.8107e-04 - val_loss: 9.2699e-04\n",
      "Epoch 1029/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 3.1380e-04 - val_loss: 9.2517e-04\n",
      "Epoch 1030/2000\n",
      "3891/3891 [==============================] - 1s 221us/step - loss: 3.1535e-04 - val_loss: 0.0010\n",
      "Epoch 1031/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 2.8490e-04 - val_loss: 0.0011\n",
      "Epoch 1032/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 2.8131e-04 - val_loss: 9.5679e-04\n",
      "Epoch 1033/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 2.8779e-04 - val_loss: 8.1040e-04\n",
      "Epoch 1034/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 2.8259e-04 - val_loss: 9.5300e-04\n",
      "Epoch 1035/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 2.8157e-04 - val_loss: 0.0016\n",
      "Epoch 1036/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 2.8737e-04 - val_loss: 0.0011\n",
      "Epoch 1037/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 2.7520e-04 - val_loss: 0.0012\n",
      "Epoch 1038/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 2.7158e-04 - val_loss: 0.0011\n",
      "Epoch 1039/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 2.6649e-04 - val_loss: 0.0012\n",
      "Epoch 1040/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 2.7315e-04 - val_loss: 0.0013\n",
      "Epoch 1041/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 2.7803e-04 - val_loss: 0.0012\n",
      "Epoch 1042/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 2.6385e-04 - val_loss: 0.0016\n",
      "Epoch 1043/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 2.7278e-04 - val_loss: 0.0013\n",
      "Epoch 1044/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 2.8080e-04 - val_loss: 9.2597e-04\n",
      "Epoch 1045/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 2.7139e-04 - val_loss: 0.0013\n",
      "Epoch 1046/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 2.7125e-04 - val_loss: 0.0012\n",
      "Epoch 1047/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 2.7563e-04 - val_loss: 0.0016\n",
      "Epoch 1048/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 2.6158e-04 - val_loss: 0.0013\n",
      "Epoch 1049/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 2.6510e-04 - val_loss: 0.0013\n",
      "Epoch 1050/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 2.6261e-04 - val_loss: 0.0015\n",
      "Epoch 1051/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 2.6355e-04 - val_loss: 0.0014\n",
      "Epoch 1052/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 2.7521e-04 - val_loss: 0.0014\n",
      "Epoch 1053/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 2.7346e-04 - val_loss: 0.0012\n",
      "Epoch 1054/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 2.6185e-04 - val_loss: 0.0013\n",
      "Epoch 1055/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 2.6568e-04 - val_loss: 0.0011\n",
      "Epoch 1056/2000\n",
      "3891/3891 [==============================] - 1s 221us/step - loss: 2.6447e-04 - val_loss: 0.0015\n",
      "Epoch 1057/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 2.4763e-04 - val_loss: 0.0016\n",
      "Epoch 1058/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 2.7324e-04 - val_loss: 0.0017\n",
      "Epoch 1059/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 2.9589e-04 - val_loss: 0.0014\n",
      "Epoch 1060/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 1s 225us/step - loss: 2.6627e-04 - val_loss: 0.0014\n",
      "Epoch 1061/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 2.6136e-04 - val_loss: 0.0012\n",
      "Epoch 1062/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 2.5784e-04 - val_loss: 0.0013\n",
      "Epoch 1063/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 2.5797e-04 - val_loss: 0.0018\n",
      "Epoch 1064/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 2.5164e-04 - val_loss: 0.0013\n",
      "Epoch 1065/2000\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 2.7455e-04 - val_loss: 0.0016\n",
      "Epoch 1066/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 2.6377e-04 - val_loss: 0.0015\n",
      "Epoch 1067/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 2.5683e-04 - val_loss: 0.0016\n",
      "Epoch 1068/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 2.7203e-04 - val_loss: 0.0012\n",
      "Epoch 1069/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 2.8646e-04 - val_loss: 0.0019\n",
      "Epoch 1070/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 2.8411e-04 - val_loss: 0.0016\n",
      "Epoch 1071/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 2.7966e-04 - val_loss: 0.0016\n",
      "Epoch 1072/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 2.6786e-04 - val_loss: 0.0010\n",
      "Epoch 1073/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 2.5508e-04 - val_loss: 0.0013\n",
      "Epoch 1074/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 2.6136e-04 - val_loss: 0.0016\n",
      "Epoch 1075/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 2.5657e-04 - val_loss: 0.0014\n",
      "Epoch 1076/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 2.4125e-04 - val_loss: 0.0017\n",
      "Epoch 1077/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 2.4285e-04 - val_loss: 0.0019\n",
      "Epoch 1078/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 2.5464e-04 - val_loss: 0.0016\n",
      "Epoch 1079/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 2.4957e-04 - val_loss: 0.0014\n",
      "Epoch 1080/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 2.6048e-04 - val_loss: 0.0015\n",
      "Epoch 1081/2000\n",
      "3891/3891 [==============================] - 1s 232us/step - loss: 2.5055e-04 - val_loss: 0.0015\n",
      "Epoch 1082/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 2.4845e-04 - val_loss: 0.0016\n",
      "Epoch 1083/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 2.6055e-04 - val_loss: 0.0015\n",
      "Epoch 1084/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 2.7735e-04 - val_loss: 0.0018\n",
      "Epoch 1085/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 2.4362e-04 - val_loss: 0.0016\n",
      "Epoch 1086/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 2.5737e-04 - val_loss: 0.0018\n",
      "Epoch 1087/2000\n",
      "3891/3891 [==============================] - 1s 222us/step - loss: 2.7004e-04 - val_loss: 0.0018\n",
      "Epoch 1088/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 2.5583e-04 - val_loss: 0.0019\n",
      "Epoch 1089/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 2.4500e-04 - val_loss: 0.0020\n",
      "Epoch 1090/2000\n",
      "3891/3891 [==============================] - 1s 222us/step - loss: 2.3956e-04 - val_loss: 0.0022\n",
      "Epoch 1091/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 2.3729e-04 - val_loss: 0.0019\n",
      "Epoch 1092/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 2.4691e-04 - val_loss: 0.0017\n",
      "Epoch 1093/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 2.5278e-04 - val_loss: 0.0021\n",
      "Epoch 1094/2000\n",
      "3891/3891 [==============================] - 1s 222us/step - loss: 2.4517e-04 - val_loss: 0.0025\n",
      "Epoch 1095/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 2.5438e-04 - val_loss: 0.0015\n",
      "Epoch 1096/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 2.4673e-04 - val_loss: 0.0021\n",
      "Epoch 1097/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 2.4291e-04 - val_loss: 0.0016\n",
      "Epoch 1098/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 2.4158e-04 - val_loss: 0.0016\n",
      "Epoch 1099/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 2.4545e-04 - val_loss: 0.0023\n",
      "Epoch 1100/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 2.3326e-04 - val_loss: 0.0021\n",
      "Epoch 1101/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 2.3413e-04 - val_loss: 0.0019\n",
      "Epoch 1102/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 2.3791e-04 - val_loss: 0.0022\n",
      "Epoch 1103/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 2.3660e-04 - val_loss: 0.0024\n",
      "Epoch 1104/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 2.3479e-04 - val_loss: 0.0028\n",
      "Epoch 1105/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 2.3316e-04 - val_loss: 0.0020\n",
      "Epoch 1106/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 2.4378e-04 - val_loss: 0.0023\n",
      "Epoch 1107/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 2.3974e-04 - val_loss: 0.0023\n",
      "Epoch 1108/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 2.4008e-04 - val_loss: 0.0022\n",
      "Epoch 1109/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 2.2335e-04 - val_loss: 0.0026\n",
      "Epoch 1110/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 2.3587e-04 - val_loss: 0.0030\n",
      "Epoch 1111/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 2.8815e-04 - val_loss: 0.0023\n",
      "Epoch 1112/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 2.5719e-04 - val_loss: 0.0023\n",
      "Epoch 1113/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 2.3956e-04 - val_loss: 0.0019\n",
      "Epoch 1114/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 2.3207e-04 - val_loss: 0.0025\n",
      "Epoch 1115/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 2.4076e-04 - val_loss: 0.0022\n",
      "Epoch 1116/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 2.4041e-04 - val_loss: 0.0024\n",
      "Epoch 1117/2000\n",
      "3891/3891 [==============================] - 1s 233us/step - loss: 2.4610e-04 - val_loss: 0.0025\n",
      "Epoch 1118/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 2.4233e-04 - val_loss: 0.0023\n",
      "Epoch 1119/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 2.3432e-04 - val_loss: 0.0021\n",
      "Epoch 1120/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 2.3931e-04 - val_loss: 0.0026\n",
      "Epoch 1121/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 2.3549e-04 - val_loss: 0.0026\n",
      "Epoch 1122/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 2.3541e-04 - val_loss: 0.0025\n",
      "Epoch 1123/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 2.3254e-04 - val_loss: 0.0026\n",
      "Epoch 1124/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 2.4009e-04 - val_loss: 0.0023\n",
      "Epoch 1125/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 2.1723e-04 - val_loss: 0.0028\n",
      "Epoch 1126/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 2.3163e-04 - val_loss: 0.0024\n",
      "Epoch 1127/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 2.2259e-04 - val_loss: 0.0031\n",
      "Epoch 1128/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 2.3968e-04 - val_loss: 0.0026\n",
      "Epoch 1129/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 2.2207e-04 - val_loss: 0.0031\n",
      "Epoch 1130/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 2.5079e-04 - val_loss: 0.0027\n",
      "Epoch 1131/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 2.2841e-04 - val_loss: 0.0034\n",
      "Epoch 1132/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 1s 222us/step - loss: 2.5205e-04 - val_loss: 0.0030\n",
      "Epoch 1133/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 2.5750e-04 - val_loss: 0.0026\n",
      "Epoch 1134/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 2.3627e-04 - val_loss: 0.0023\n",
      "Epoch 1135/2000\n",
      "3891/3891 [==============================] - 1s 232us/step - loss: 2.2955e-04 - val_loss: 0.0022\n",
      "Epoch 1136/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 2.2618e-04 - val_loss: 0.0027\n",
      "Epoch 1137/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 2.2698e-04 - val_loss: 0.0025\n",
      "Epoch 1138/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 2.2139e-04 - val_loss: 0.0029\n",
      "Epoch 1139/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 2.1808e-04 - val_loss: 0.0023\n",
      "Epoch 1140/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 2.1643e-04 - val_loss: 0.0030\n",
      "Epoch 1141/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 2.1878e-04 - val_loss: 0.0033\n",
      "Epoch 1142/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 2.3682e-04 - val_loss: 0.0022\n",
      "Epoch 1143/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 2.2228e-04 - val_loss: 0.0026\n",
      "Epoch 1144/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 2.1743e-04 - val_loss: 0.0030\n",
      "Epoch 1145/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 2.1250e-04 - val_loss: 0.0032\n",
      "Epoch 1146/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 2.0831e-04 - val_loss: 0.0033\n",
      "Epoch 1147/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 2.1135e-04 - val_loss: 0.0028\n",
      "Epoch 1148/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 2.0679e-04 - val_loss: 0.0021\n",
      "Epoch 1149/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 2.2196e-04 - val_loss: 0.0030\n",
      "Epoch 1150/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 2.4465e-04 - val_loss: 0.0020\n",
      "Epoch 1151/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 2.3602e-04 - val_loss: 0.0019\n",
      "Epoch 1152/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 2.2415e-04 - val_loss: 0.0020\n",
      "Epoch 1153/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 2.2445e-04 - val_loss: 0.0026\n",
      "Epoch 1154/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 2.0467e-04 - val_loss: 0.0024\n",
      "Epoch 1155/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 2.2510e-04 - val_loss: 0.0027\n",
      "Epoch 1156/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 2.1386e-04 - val_loss: 0.0026\n",
      "Epoch 1157/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 2.0902e-04 - val_loss: 0.0029\n",
      "Epoch 1158/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 2.1882e-04 - val_loss: 0.0027\n",
      "Epoch 1159/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 2.3319e-04 - val_loss: 0.0027\n",
      "Epoch 1160/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 2.3144e-04 - val_loss: 0.0018\n",
      "Epoch 1161/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 2.3308e-04 - val_loss: 0.0026\n",
      "Epoch 1162/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 2.3387e-04 - val_loss: 0.0025\n",
      "Epoch 1163/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 2.2634e-04 - val_loss: 0.0028\n",
      "Epoch 1164/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 2.1390e-04 - val_loss: 0.0030\n",
      "Epoch 1165/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 2.2645e-04 - val_loss: 0.0027\n",
      "Epoch 1166/2000\n",
      "3891/3891 [==============================] - 1s 222us/step - loss: 2.3311e-04 - val_loss: 0.0027\n",
      "Epoch 1167/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 2.3433e-04 - val_loss: 0.0027\n",
      "Epoch 1168/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 2.1578e-04 - val_loss: 0.0025\n",
      "Epoch 1169/2000\n",
      "3891/3891 [==============================] - 1s 232us/step - loss: 2.0753e-04 - val_loss: 0.0029\n",
      "Epoch 1170/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 2.0075e-04 - val_loss: 0.0028\n",
      "Epoch 1171/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.9951e-04 - val_loss: 0.0027\n",
      "Epoch 1172/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 2.0916e-04 - val_loss: 0.0026\n",
      "Epoch 1173/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 2.1103e-04 - val_loss: 0.0026\n",
      "Epoch 1174/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 1.9982e-04 - val_loss: 0.0028\n",
      "Epoch 1175/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 1.9588e-04 - val_loss: 0.0029\n",
      "Epoch 1176/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 2.0888e-04 - val_loss: 0.0029\n",
      "Epoch 1177/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 2.0249e-04 - val_loss: 0.0031\n",
      "Epoch 1178/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 2.0383e-04 - val_loss: 0.0032\n",
      "Epoch 1179/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 2.2029e-04 - val_loss: 0.0040\n",
      "Epoch 1180/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 2.1866e-04 - val_loss: 0.0030\n",
      "Epoch 1181/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 2.0593e-04 - val_loss: 0.0029\n",
      "Epoch 1182/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 2.0048e-04 - val_loss: 0.0038\n",
      "Epoch 1183/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 2.0609e-04 - val_loss: 0.0034\n",
      "Epoch 1184/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 2.0655e-04 - val_loss: 0.0029\n",
      "Epoch 1185/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 2.0598e-04 - val_loss: 0.0031\n",
      "Epoch 1186/2000\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 2.1342e-04 - val_loss: 0.0030\n",
      "Epoch 1187/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 2.0967e-04 - val_loss: 0.0035\n",
      "Epoch 1188/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 2.1067e-04 - val_loss: 0.0036\n",
      "Epoch 1189/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 2.0554e-04 - val_loss: 0.0033\n",
      "Epoch 1190/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 2.0319e-04 - val_loss: 0.0030\n",
      "Epoch 1191/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 2.1469e-04 - val_loss: 0.0028\n",
      "Epoch 1192/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 2.0223e-04 - val_loss: 0.0030\n",
      "Epoch 1193/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 2.0033e-04 - val_loss: 0.0031\n",
      "Epoch 1194/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.9339e-04 - val_loss: 0.0028\n",
      "Epoch 1195/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 1.9005e-04 - val_loss: 0.0030\n",
      "Epoch 1196/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 1.9482e-04 - val_loss: 0.0034\n",
      "Epoch 1197/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.9388e-04 - val_loss: 0.0032\n",
      "Epoch 1198/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.9641e-04 - val_loss: 0.0031\n",
      "Epoch 1199/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 1.9955e-04 - val_loss: 0.0032\n",
      "Epoch 1200/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 1.9948e-04 - val_loss: 0.0033\n",
      "Epoch 1201/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 1.9492e-04 - val_loss: 0.0029\n",
      "Epoch 1202/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.9793e-04 - val_loss: 0.0026\n",
      "Epoch 1203/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 2.1933e-04 - val_loss: 0.0028\n",
      "Epoch 1204/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 1s 230us/step - loss: 2.5640e-04 - val_loss: 0.0029\n",
      "Epoch 1205/2000\n",
      "3891/3891 [==============================] - 1s 222us/step - loss: 2.2875e-04 - val_loss: 0.0036\n",
      "Epoch 1206/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 2.1694e-04 - val_loss: 0.0029\n",
      "Epoch 1207/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 1.9926e-04 - val_loss: 0.0029\n",
      "Epoch 1208/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 1.9376e-04 - val_loss: 0.0035\n",
      "Epoch 1209/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 2.0078e-04 - val_loss: 0.0034\n",
      "Epoch 1210/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 2.0435e-04 - val_loss: 0.0032\n",
      "Epoch 1211/2000\n",
      "3891/3891 [==============================] - 1s 238us/step - loss: 2.0576e-04 - val_loss: 0.0036\n",
      "Epoch 1212/2000\n",
      "3891/3891 [==============================] - 1s 236us/step - loss: 1.9161e-04 - val_loss: 0.0030\n",
      "Epoch 1213/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 2.0632e-04 - val_loss: 0.0032\n",
      "Epoch 1214/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.9647e-04 - val_loss: 0.0031\n",
      "Epoch 1215/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 1.9427e-04 - val_loss: 0.0033\n",
      "Epoch 1216/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.9918e-04 - val_loss: 0.0035\n",
      "Epoch 1217/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 1.9298e-04 - val_loss: 0.0032\n",
      "Epoch 1218/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 1.9650e-04 - val_loss: 0.0030\n",
      "Epoch 1219/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 1.8714e-04 - val_loss: 0.0029\n",
      "Epoch 1220/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.8633e-04 - val_loss: 0.0038\n",
      "Epoch 1221/2000\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 1.8390e-04 - val_loss: 0.0036\n",
      "Epoch 1222/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 1.9093e-04 - val_loss: 0.0030\n",
      "Epoch 1223/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 1.8847e-04 - val_loss: 0.0041\n",
      "Epoch 1224/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 1.9303e-04 - val_loss: 0.0037\n",
      "Epoch 1225/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 2.0384e-04 - val_loss: 0.0033\n",
      "Epoch 1226/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 1.8802e-04 - val_loss: 0.0031\n",
      "Epoch 1227/2000\n",
      "3891/3891 [==============================] - 1s 232us/step - loss: 1.9492e-04 - val_loss: 0.0034\n",
      "Epoch 1228/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 2.0750e-04 - val_loss: 0.0038\n",
      "Epoch 1229/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 2.0227e-04 - val_loss: 0.0038\n",
      "Epoch 1230/2000\n",
      "3891/3891 [==============================] - 1s 222us/step - loss: 2.0703e-04 - val_loss: 0.0032\n",
      "Epoch 1231/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 2.0209e-04 - val_loss: 0.0032\n",
      "Epoch 1232/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 1.9017e-04 - val_loss: 0.0035\n",
      "Epoch 1233/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 1.8163e-04 - val_loss: 0.0037\n",
      "Epoch 1234/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.8828e-04 - val_loss: 0.0036\n",
      "Epoch 1235/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 2.0699e-04 - val_loss: 0.0030\n",
      "Epoch 1236/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 2.1957e-04 - val_loss: 0.0028\n",
      "Epoch 1237/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 2.0641e-04 - val_loss: 0.0031\n",
      "Epoch 1238/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 2.0289e-04 - val_loss: 0.0030\n",
      "Epoch 1239/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 1.8870e-04 - val_loss: 0.0031\n",
      "Epoch 1240/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 1.8403e-04 - val_loss: 0.0036\n",
      "Epoch 1241/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 1.9402e-04 - val_loss: 0.0031\n",
      "Epoch 1242/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.8031e-04 - val_loss: 0.0029\n",
      "Epoch 1243/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 1.8360e-04 - val_loss: 0.0030\n",
      "Epoch 1244/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 1.9145e-04 - val_loss: 0.0033\n",
      "Epoch 1245/2000\n",
      "3891/3891 [==============================] - 1s 233us/step - loss: 1.8133e-04 - val_loss: 0.0036\n",
      "Epoch 1246/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.8669e-04 - val_loss: 0.0032\n",
      "Epoch 1247/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 1.7575e-04 - val_loss: 0.0034\n",
      "Epoch 1248/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.7619e-04 - val_loss: 0.0035\n",
      "Epoch 1249/2000\n",
      "3891/3891 [==============================] - 1s 222us/step - loss: 1.7582e-04 - val_loss: 0.0034\n",
      "Epoch 1250/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 1.7572e-04 - val_loss: 0.0031\n",
      "Epoch 1251/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 1.7816e-04 - val_loss: 0.0035\n",
      "Epoch 1252/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.8236e-04 - val_loss: 0.0034\n",
      "Epoch 1253/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 1.8233e-04 - val_loss: 0.0033\n",
      "Epoch 1254/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 1.7954e-04 - val_loss: 0.0035\n",
      "Epoch 1255/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.8267e-04 - val_loss: 0.0031\n",
      "Epoch 1256/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.8366e-04 - val_loss: 0.0032\n",
      "Epoch 1257/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 1.8646e-04 - val_loss: 0.0032\n",
      "Epoch 1258/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 1.8366e-04 - val_loss: 0.0040\n",
      "Epoch 1259/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.7060e-04 - val_loss: 0.0032\n",
      "Epoch 1260/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.6667e-04 - val_loss: 0.0034\n",
      "Epoch 1261/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.6516e-04 - val_loss: 0.0035\n",
      "Epoch 1262/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 1.6971e-04 - val_loss: 0.0036\n",
      "Epoch 1263/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.6524e-04 - val_loss: 0.0037\n",
      "Epoch 1264/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.6738e-04 - val_loss: 0.0040\n",
      "Epoch 1265/2000\n",
      "3891/3891 [==============================] - 1s 222us/step - loss: 1.8148e-04 - val_loss: 0.0037\n",
      "Epoch 1266/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 1.7349e-04 - val_loss: 0.0039\n",
      "Epoch 1267/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 1.7755e-04 - val_loss: 0.0032\n",
      "Epoch 1268/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.7137e-04 - val_loss: 0.0031\n",
      "Epoch 1269/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.7705e-04 - val_loss: 0.0029\n",
      "Epoch 1270/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 1.8363e-04 - val_loss: 0.0032\n",
      "Epoch 1271/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.7120e-04 - val_loss: 0.0031\n",
      "Epoch 1272/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.8354e-04 - val_loss: 0.0031\n",
      "Epoch 1273/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.9755e-04 - val_loss: 0.0031\n",
      "Epoch 1274/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 2.1534e-04 - val_loss: 0.0030\n",
      "Epoch 1275/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 1.8832e-04 - val_loss: 0.0029\n",
      "Epoch 1276/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 1s 228us/step - loss: 1.7801e-04 - val_loss: 0.0033\n",
      "Epoch 1277/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 1.9653e-04 - val_loss: 0.0035\n",
      "Epoch 1278/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 2.0731e-04 - val_loss: 0.0030\n",
      "Epoch 1279/2000\n",
      "3891/3891 [==============================] - 1s 235us/step - loss: 2.0965e-04 - val_loss: 0.0029\n",
      "Epoch 1280/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 2.0611e-04 - val_loss: 0.0034\n",
      "Epoch 1281/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 2.2883e-04 - val_loss: 0.0030\n",
      "Epoch 1282/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 1.9043e-04 - val_loss: 0.0027\n",
      "Epoch 1283/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 1.7881e-04 - val_loss: 0.0030\n",
      "Epoch 1284/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 1.9006e-04 - val_loss: 0.0030\n",
      "Epoch 1285/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 1.7829e-04 - val_loss: 0.0031\n",
      "Epoch 1286/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.8153e-04 - val_loss: 0.0031\n",
      "Epoch 1287/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.8269e-04 - val_loss: 0.0036\n",
      "Epoch 1288/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 1.7334e-04 - val_loss: 0.0036\n",
      "Epoch 1289/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 1.6794e-04 - val_loss: 0.0033\n",
      "Epoch 1290/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 1.6488e-04 - val_loss: 0.0033\n",
      "Epoch 1291/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 1.6300e-04 - val_loss: 0.0035\n",
      "Epoch 1292/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 1.8282e-04 - val_loss: 0.0038\n",
      "Epoch 1293/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 1.7343e-04 - val_loss: 0.0036\n",
      "Epoch 1294/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.6889e-04 - val_loss: 0.0029\n",
      "Epoch 1295/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.7202e-04 - val_loss: 0.0031\n",
      "Epoch 1296/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 1.7077e-04 - val_loss: 0.0034\n",
      "Epoch 1297/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 1.7107e-04 - val_loss: 0.0031\n",
      "Epoch 1298/2000\n",
      "3891/3891 [==============================] - 1s 237us/step - loss: 1.6336e-04 - val_loss: 0.0031\n",
      "Epoch 1299/2000\n",
      "3891/3891 [==============================] - 1s 222us/step - loss: 1.6508e-04 - val_loss: 0.0036\n",
      "Epoch 1300/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 1.6067e-04 - val_loss: 0.0029\n",
      "Epoch 1301/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.7246e-04 - val_loss: 0.0035\n",
      "Epoch 1302/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 1.8511e-04 - val_loss: 0.0037\n",
      "Epoch 1303/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 1.6861e-04 - val_loss: 0.0035\n",
      "Epoch 1304/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 1.5152e-04 - val_loss: 0.0028\n",
      "Epoch 1305/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 1.5840e-04 - val_loss: 0.0026\n",
      "Epoch 1306/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 1.6415e-04 - val_loss: 0.0033\n",
      "Epoch 1307/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 1.5878e-04 - val_loss: 0.0030\n",
      "Epoch 1308/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.6596e-04 - val_loss: 0.0032\n",
      "Epoch 1309/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.7820e-04 - val_loss: 0.0033\n",
      "Epoch 1310/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 1.7099e-04 - val_loss: 0.0030\n",
      "Epoch 1311/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 1.5995e-04 - val_loss: 0.0039\n",
      "Epoch 1312/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.6300e-04 - val_loss: 0.0035\n",
      "Epoch 1313/2000\n",
      "3891/3891 [==============================] - 1s 233us/step - loss: 1.6119e-04 - val_loss: 0.0036\n",
      "Epoch 1314/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.5925e-04 - val_loss: 0.0033\n",
      "Epoch 1315/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.5309e-04 - val_loss: 0.0032\n",
      "Epoch 1316/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 1.5579e-04 - val_loss: 0.0033\n",
      "Epoch 1317/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 1.5854e-04 - val_loss: 0.0036\n",
      "Epoch 1318/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 1.6599e-04 - val_loss: 0.0036\n",
      "Epoch 1319/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 1.6363e-04 - val_loss: 0.0035\n",
      "Epoch 1320/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 1.6217e-04 - val_loss: 0.0036\n",
      "Epoch 1321/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.6345e-04 - val_loss: 0.0037\n",
      "Epoch 1322/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.7016e-04 - val_loss: 0.0034\n",
      "Epoch 1323/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 1.6406e-04 - val_loss: 0.0035\n",
      "Epoch 1324/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.6848e-04 - val_loss: 0.0037\n",
      "Epoch 1325/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 1.5728e-04 - val_loss: 0.0032\n",
      "Epoch 1326/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.7122e-04 - val_loss: 0.0033\n",
      "Epoch 1327/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.5581e-04 - val_loss: 0.0034\n",
      "Epoch 1328/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 1.7080e-04 - val_loss: 0.0037\n",
      "Epoch 1329/2000\n",
      "3891/3891 [==============================] - 1s 232us/step - loss: 1.7446e-04 - val_loss: 0.0038\n",
      "Epoch 1330/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 1.6251e-04 - val_loss: 0.0037\n",
      "Epoch 1331/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 1.6483e-04 - val_loss: 0.0035\n",
      "Epoch 1332/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.5802e-04 - val_loss: 0.0038\n",
      "Epoch 1333/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.5384e-04 - val_loss: 0.0035\n",
      "Epoch 1334/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 1.5191e-04 - val_loss: 0.0035\n",
      "Epoch 1335/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.5410e-04 - val_loss: 0.0033\n",
      "Epoch 1336/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.4832e-04 - val_loss: 0.0035\n",
      "Epoch 1337/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.5555e-04 - val_loss: 0.0036\n",
      "Epoch 1338/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.5160e-04 - val_loss: 0.0034\n",
      "Epoch 1339/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 1.5468e-04 - val_loss: 0.0032\n",
      "Epoch 1340/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.5765e-04 - val_loss: 0.0036\n",
      "Epoch 1341/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 1.4617e-04 - val_loss: 0.0036\n",
      "Epoch 1342/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 1.5008e-04 - val_loss: 0.0035\n",
      "Epoch 1343/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.4175e-04 - val_loss: 0.0036\n",
      "Epoch 1344/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 1.5079e-04 - val_loss: 0.0035\n",
      "Epoch 1345/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 1.4908e-04 - val_loss: 0.0037\n",
      "Epoch 1346/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 1.4480e-04 - val_loss: 0.0041\n",
      "Epoch 1347/2000\n",
      "3891/3891 [==============================] - 1s 232us/step - loss: 1.4855e-04 - val_loss: 0.0039\n",
      "Epoch 1348/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.4849e-04 - val_loss: 0.0037\n",
      "Epoch 1349/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.4570e-04 - val_loss: 0.0033\n",
      "Epoch 1350/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.5324e-04 - val_loss: 0.0036\n",
      "Epoch 1351/2000\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 1.4943e-04 - val_loss: 0.0040\n",
      "Epoch 1352/2000\n",
      "3891/3891 [==============================] - 1s 235us/step - loss: 1.4926e-04 - val_loss: 0.0037\n",
      "Epoch 1353/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 1.3991e-04 - val_loss: 0.0036\n",
      "Epoch 1354/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 1.4266e-04 - val_loss: 0.0035\n",
      "Epoch 1355/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 1.3963e-04 - val_loss: 0.0037\n",
      "Epoch 1356/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 1.4714e-04 - val_loss: 0.0042\n",
      "Epoch 1357/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 1.7371e-04 - val_loss: 0.0034\n",
      "Epoch 1358/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.7459e-04 - val_loss: 0.0036\n",
      "Epoch 1359/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.6947e-04 - val_loss: 0.0038\n",
      "Epoch 1360/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 1.4662e-04 - val_loss: 0.0036\n",
      "Epoch 1361/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 1.6162e-04 - val_loss: 0.0035\n",
      "Epoch 1362/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 1.5457e-04 - val_loss: 0.0034\n",
      "Epoch 1363/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.4976e-04 - val_loss: 0.0039\n",
      "Epoch 1364/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.4265e-04 - val_loss: 0.0038\n",
      "Epoch 1365/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.5239e-04 - val_loss: 0.0038\n",
      "Epoch 1366/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 1.4812e-04 - val_loss: 0.0034\n",
      "Epoch 1367/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.4385e-04 - val_loss: 0.0039\n",
      "Epoch 1368/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 1.4301e-04 - val_loss: 0.0037\n",
      "Epoch 1369/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 1.4672e-04 - val_loss: 0.0037\n",
      "Epoch 1370/2000\n",
      "3891/3891 [==============================] - 1s 235us/step - loss: 1.5053e-04 - val_loss: 0.0040\n",
      "Epoch 1371/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 1.4223e-04 - val_loss: 0.0039\n",
      "Epoch 1372/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 1.6299e-04 - val_loss: 0.0036\n",
      "Epoch 1373/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 1.4989e-04 - val_loss: 0.0036\n",
      "Epoch 1374/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 1.4592e-04 - val_loss: 0.0036\n",
      "Epoch 1375/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.5207e-04 - val_loss: 0.0038\n",
      "Epoch 1376/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.4181e-04 - val_loss: 0.0042\n",
      "Epoch 1377/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 1.4982e-04 - val_loss: 0.0035\n",
      "Epoch 1378/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 1.4561e-04 - val_loss: 0.0036\n",
      "Epoch 1379/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 1.4441e-04 - val_loss: 0.0034\n",
      "Epoch 1380/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.4275e-04 - val_loss: 0.0037\n",
      "Epoch 1381/2000\n",
      "3891/3891 [==============================] - 1s 232us/step - loss: 1.4046e-04 - val_loss: 0.0039\n",
      "Epoch 1382/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.3847e-04 - val_loss: 0.0034\n",
      "Epoch 1383/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 1.3671e-04 - val_loss: 0.0038\n",
      "Epoch 1384/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 1.4670e-04 - val_loss: 0.0034\n",
      "Epoch 1385/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.4289e-04 - val_loss: 0.0035\n",
      "Epoch 1386/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 1.2848e-04 - val_loss: 0.0038\n",
      "Epoch 1387/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.4003e-04 - val_loss: 0.0040\n",
      "Epoch 1388/2000\n",
      "3891/3891 [==============================] - 1s 232us/step - loss: 1.3142e-04 - val_loss: 0.0039\n",
      "Epoch 1389/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.4318e-04 - val_loss: 0.0038\n",
      "Epoch 1390/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 1.3625e-04 - val_loss: 0.0043\n",
      "Epoch 1391/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 1.4563e-04 - val_loss: 0.0042\n",
      "Epoch 1392/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 1.4593e-04 - val_loss: 0.0039\n",
      "Epoch 1393/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 1.4230e-04 - val_loss: 0.0037\n",
      "Epoch 1394/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 1.3884e-04 - val_loss: 0.0036\n",
      "Epoch 1395/2000\n",
      "3891/3891 [==============================] - 1s 222us/step - loss: 1.4024e-04 - val_loss: 0.0039\n",
      "Epoch 1396/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 1.4148e-04 - val_loss: 0.0035\n",
      "Epoch 1397/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.5571e-04 - val_loss: 0.0035\n",
      "Epoch 1398/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.6660e-04 - val_loss: 0.0037\n",
      "Epoch 1399/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 1.5230e-04 - val_loss: 0.0039\n",
      "Epoch 1400/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 1.3952e-04 - val_loss: 0.0039\n",
      "Epoch 1401/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 1.3433e-04 - val_loss: 0.0042\n",
      "Epoch 1402/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 1.4787e-04 - val_loss: 0.0037\n",
      "Epoch 1403/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 1.4461e-04 - val_loss: 0.0038\n",
      "Epoch 1404/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 1.4154e-04 - val_loss: 0.0035\n",
      "Epoch 1405/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.3848e-04 - val_loss: 0.0036\n",
      "Epoch 1406/2000\n",
      "3891/3891 [==============================] - 1s 232us/step - loss: 1.4092e-04 - val_loss: 0.0034\n",
      "Epoch 1407/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 1.5485e-04 - val_loss: 0.0040\n",
      "Epoch 1408/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.6052e-04 - val_loss: 0.0031\n",
      "Epoch 1409/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.5222e-04 - val_loss: 0.0033\n",
      "Epoch 1410/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.5830e-04 - val_loss: 0.0034\n",
      "Epoch 1411/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 1.6028e-04 - val_loss: 0.0033\n",
      "Epoch 1412/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 1.8166e-04 - val_loss: 0.0034\n",
      "Epoch 1413/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.4739e-04 - val_loss: 0.0033\n",
      "Epoch 1414/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 1.4172e-04 - val_loss: 0.0029\n",
      "Epoch 1415/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.4097e-04 - val_loss: 0.0036\n",
      "Epoch 1416/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 1.3635e-04 - val_loss: 0.0037\n",
      "Epoch 1417/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.3469e-04 - val_loss: 0.0035\n",
      "Epoch 1418/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 1.3183e-04 - val_loss: 0.0037\n",
      "Epoch 1419/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 1.3200e-04 - val_loss: 0.0038\n",
      "Epoch 1420/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 1s 224us/step - loss: 1.3306e-04 - val_loss: 0.0035\n",
      "Epoch 1421/2000\n",
      "3891/3891 [==============================] - 1s 222us/step - loss: 1.4111e-04 - val_loss: 0.0034\n",
      "Epoch 1422/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 1.3197e-04 - val_loss: 0.0040\n",
      "Epoch 1423/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 1.3114e-04 - val_loss: 0.0039\n",
      "Epoch 1424/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 1.3022e-04 - val_loss: 0.0038\n",
      "Epoch 1425/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 1.3992e-04 - val_loss: 0.0040\n",
      "Epoch 1426/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.4614e-04 - val_loss: 0.0035\n",
      "Epoch 1427/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 1.4282e-04 - val_loss: 0.0037\n",
      "Epoch 1428/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 1.4301e-04 - val_loss: 0.0040\n",
      "Epoch 1429/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.3883e-04 - val_loss: 0.0039\n",
      "Epoch 1430/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.3386e-04 - val_loss: 0.0039\n",
      "Epoch 1431/2000\n",
      "3891/3891 [==============================] - 1s 236us/step - loss: 1.4723e-04 - val_loss: 0.0037\n",
      "Epoch 1432/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 1.4768e-04 - val_loss: 0.0035\n",
      "Epoch 1433/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.3518e-04 - val_loss: 0.0035\n",
      "Epoch 1434/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 1.3393e-04 - val_loss: 0.0033\n",
      "Epoch 1435/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.3530e-04 - val_loss: 0.0033\n",
      "Epoch 1436/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.3248e-04 - val_loss: 0.0037\n",
      "Epoch 1437/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 1.3447e-04 - val_loss: 0.0030\n",
      "Epoch 1438/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.3808e-04 - val_loss: 0.0036\n",
      "Epoch 1439/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.4344e-04 - val_loss: 0.0042\n",
      "Epoch 1440/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.4402e-04 - val_loss: 0.0037\n",
      "Epoch 1441/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 1.4449e-04 - val_loss: 0.0037\n",
      "Epoch 1442/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.4558e-04 - val_loss: 0.0036\n",
      "Epoch 1443/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 1.3216e-04 - val_loss: 0.0041\n",
      "Epoch 1444/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.2848e-04 - val_loss: 0.0039\n",
      "Epoch 1445/2000\n",
      "3891/3891 [==============================] - 1s 221us/step - loss: 1.2630e-04 - val_loss: 0.0037\n",
      "Epoch 1446/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.2898e-04 - val_loss: 0.0037\n",
      "Epoch 1447/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 1.3131e-04 - val_loss: 0.0037\n",
      "Epoch 1448/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 1.2036e-04 - val_loss: 0.0038\n",
      "Epoch 1449/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 1.1982e-04 - val_loss: 0.0035\n",
      "Epoch 1450/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.2617e-04 - val_loss: 0.0038\n",
      "Epoch 1451/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.2027e-04 - val_loss: 0.0041\n",
      "Epoch 1452/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 1.2171e-04 - val_loss: 0.0036\n",
      "Epoch 1453/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.2122e-04 - val_loss: 0.0038\n",
      "Epoch 1454/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 1.3053e-04 - val_loss: 0.0042\n",
      "Epoch 1455/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 1.4510e-04 - val_loss: 0.0037\n",
      "Epoch 1456/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 1.2661e-04 - val_loss: 0.0036\n",
      "Epoch 1457/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 1.2796e-04 - val_loss: 0.0036\n",
      "Epoch 1458/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 1.2197e-04 - val_loss: 0.0038\n",
      "Epoch 1459/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 1.2330e-04 - val_loss: 0.0040\n",
      "Epoch 1460/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 1.2566e-04 - val_loss: 0.0041\n",
      "Epoch 1461/2000\n",
      "3891/3891 [==============================] - 1s 232us/step - loss: 1.2266e-04 - val_loss: 0.0036\n",
      "Epoch 1462/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.2552e-04 - val_loss: 0.0037\n",
      "Epoch 1463/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 1.3385e-04 - val_loss: 0.0034\n",
      "Epoch 1464/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.3443e-04 - val_loss: 0.0040\n",
      "Epoch 1465/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 1.3718e-04 - val_loss: 0.0033\n",
      "Epoch 1466/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.2520e-04 - val_loss: 0.0035\n",
      "Epoch 1467/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 1.2445e-04 - val_loss: 0.0037\n",
      "Epoch 1468/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 1.2118e-04 - val_loss: 0.0035\n",
      "Epoch 1469/2000\n",
      "3891/3891 [==============================] - 1s 222us/step - loss: 1.2867e-04 - val_loss: 0.0038\n",
      "Epoch 1470/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 1.3718e-04 - val_loss: 0.0038\n",
      "Epoch 1471/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.3540e-04 - val_loss: 0.0037\n",
      "Epoch 1472/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.4460e-04 - val_loss: 0.0036\n",
      "Epoch 1473/2000\n",
      "3891/3891 [==============================] - 1s 222us/step - loss: 1.3599e-04 - val_loss: 0.0038\n",
      "Epoch 1474/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.3293e-04 - val_loss: 0.0040\n",
      "Epoch 1475/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 1.3154e-04 - val_loss: 0.0037\n",
      "Epoch 1476/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 1.2778e-04 - val_loss: 0.0031\n",
      "Epoch 1477/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 1.2973e-04 - val_loss: 0.0035\n",
      "Epoch 1478/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 1.2473e-04 - val_loss: 0.0034\n",
      "Epoch 1479/2000\n",
      "3891/3891 [==============================] - 1s 233us/step - loss: 1.3157e-04 - val_loss: 0.0033\n",
      "Epoch 1480/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 1.2893e-04 - val_loss: 0.0038\n",
      "Epoch 1481/2000\n",
      "3891/3891 [==============================] - 1s 222us/step - loss: 1.4546e-04 - val_loss: 0.0036\n",
      "Epoch 1482/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 1.3373e-04 - val_loss: 0.0041\n",
      "Epoch 1483/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 1.3019e-04 - val_loss: 0.0038\n",
      "Epoch 1484/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.2569e-04 - val_loss: 0.0036\n",
      "Epoch 1485/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 1.3322e-04 - val_loss: 0.0036\n",
      "Epoch 1486/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 1.2156e-04 - val_loss: 0.0037\n",
      "Epoch 1487/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 1.3071e-04 - val_loss: 0.0032\n",
      "Epoch 1488/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 1.3855e-04 - val_loss: 0.0033\n",
      "Epoch 1489/2000\n",
      "3891/3891 [==============================] - 1s 221us/step - loss: 1.4563e-04 - val_loss: 0.0037\n",
      "Epoch 1490/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 1.2954e-04 - val_loss: 0.0034\n",
      "Epoch 1491/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.2317e-04 - val_loss: 0.0033\n",
      "Epoch 1492/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 1s 228us/step - loss: 1.1490e-04 - val_loss: 0.0038\n",
      "Epoch 1493/2000\n",
      "3891/3891 [==============================] - 1s 234us/step - loss: 1.1858e-04 - val_loss: 0.0041\n",
      "Epoch 1494/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 1.1620e-04 - val_loss: 0.0039\n",
      "Epoch 1495/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 1.1756e-04 - val_loss: 0.0033\n",
      "Epoch 1496/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 1.3609e-04 - val_loss: 0.0032\n",
      "Epoch 1497/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 1.2544e-04 - val_loss: 0.0038\n",
      "Epoch 1498/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 1.2465e-04 - val_loss: 0.0034\n",
      "Epoch 1499/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 1.2394e-04 - val_loss: 0.0035\n",
      "Epoch 1500/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 1.1756e-04 - val_loss: 0.0037\n",
      "Epoch 1501/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 1.1921e-04 - val_loss: 0.0035\n",
      "Epoch 1502/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 1.1500e-04 - val_loss: 0.0039\n",
      "Epoch 1503/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 1.1956e-04 - val_loss: 0.0037\n",
      "Epoch 1504/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 1.2645e-04 - val_loss: 0.0035\n",
      "Epoch 1505/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 1.3351e-04 - val_loss: 0.0037\n",
      "Epoch 1506/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 1.3485e-04 - val_loss: 0.0037\n",
      "Epoch 1507/2000\n",
      "3891/3891 [==============================] - 1s 221us/step - loss: 1.2971e-04 - val_loss: 0.0035\n",
      "Epoch 1508/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 1.2772e-04 - val_loss: 0.0035\n",
      "Epoch 1509/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.2355e-04 - val_loss: 0.0035\n",
      "Epoch 1510/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 1.1922e-04 - val_loss: 0.0036\n",
      "Epoch 1511/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 1.1451e-04 - val_loss: 0.0035\n",
      "Epoch 1512/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.1385e-04 - val_loss: 0.0036\n",
      "Epoch 1513/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.1928e-04 - val_loss: 0.0036\n",
      "Epoch 1514/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 1.3041e-04 - val_loss: 0.0035\n",
      "Epoch 1515/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 1.2765e-04 - val_loss: 0.0038\n",
      "Epoch 1516/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.2329e-04 - val_loss: 0.0041\n",
      "Epoch 1517/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 1.1919e-04 - val_loss: 0.0038\n",
      "Epoch 1518/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 1.1573e-04 - val_loss: 0.0030\n",
      "Epoch 1519/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 1.2217e-04 - val_loss: 0.0031\n",
      "Epoch 1520/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.2132e-04 - val_loss: 0.0037\n",
      "Epoch 1521/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 1.2537e-04 - val_loss: 0.0037\n",
      "Epoch 1522/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 1.1780e-04 - val_loss: 0.0036\n",
      "Epoch 1523/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 1.2231e-04 - val_loss: 0.0038\n",
      "Epoch 1524/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 1.1470e-04 - val_loss: 0.0041\n",
      "Epoch 1525/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.1794e-04 - val_loss: 0.0033\n",
      "Epoch 1526/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.1852e-04 - val_loss: 0.0034\n",
      "Epoch 1527/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 1.1376e-04 - val_loss: 0.0034\n",
      "Epoch 1528/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 1.1829e-04 - val_loss: 0.0033\n",
      "Epoch 1529/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 1.2037e-04 - val_loss: 0.0036\n",
      "Epoch 1530/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.1719e-04 - val_loss: 0.0036\n",
      "Epoch 1531/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.2503e-04 - val_loss: 0.0040\n",
      "Epoch 1532/2000\n",
      "3891/3891 [==============================] - 1s 222us/step - loss: 1.4245e-04 - val_loss: 0.0034\n",
      "Epoch 1533/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 1.3565e-04 - val_loss: 0.0035\n",
      "Epoch 1534/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 1.2795e-04 - val_loss: 0.0034\n",
      "Epoch 1535/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.2819e-04 - val_loss: 0.0032\n",
      "Epoch 1536/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 1.1853e-04 - val_loss: 0.0032\n",
      "Epoch 1537/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 1.1230e-04 - val_loss: 0.0035\n",
      "Epoch 1538/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.1335e-04 - val_loss: 0.0041\n",
      "Epoch 1539/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 1.0995e-04 - val_loss: 0.0036\n",
      "Epoch 1540/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.1254e-04 - val_loss: 0.0038\n",
      "Epoch 1541/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 1.1230e-04 - val_loss: 0.0037\n",
      "Epoch 1542/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 1.0998e-04 - val_loss: 0.0032\n",
      "Epoch 1543/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 1.1730e-04 - val_loss: 0.0037\n",
      "Epoch 1544/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 1.1209e-04 - val_loss: 0.0036\n",
      "Epoch 1545/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.2863e-04 - val_loss: 0.0037\n",
      "Epoch 1546/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 1.2499e-04 - val_loss: 0.0038\n",
      "Epoch 1547/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 1.1660e-04 - val_loss: 0.0038\n",
      "Epoch 1548/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 1.1872e-04 - val_loss: 0.0038\n",
      "Epoch 1549/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 1.1966e-04 - val_loss: 0.0039\n",
      "Epoch 1550/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 1.1253e-04 - val_loss: 0.0042\n",
      "Epoch 1551/2000\n",
      "3891/3891 [==============================] - 1s 234us/step - loss: 1.1640e-04 - val_loss: 0.0044\n",
      "Epoch 1552/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.2431e-04 - val_loss: 0.0039\n",
      "Epoch 1553/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 1.3547e-04 - val_loss: 0.0036\n",
      "Epoch 1554/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 1.2287e-04 - val_loss: 0.0037\n",
      "Epoch 1555/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 1.1990e-04 - val_loss: 0.0040\n",
      "Epoch 1556/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.2729e-04 - val_loss: 0.0039\n",
      "Epoch 1557/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 1.2183e-04 - val_loss: 0.0039\n",
      "Epoch 1558/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 1.1357e-04 - val_loss: 0.0040\n",
      "Epoch 1559/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 1.1914e-04 - val_loss: 0.0039\n",
      "Epoch 1560/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 1.0733e-04 - val_loss: 0.0036\n",
      "Epoch 1561/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 1.0640e-04 - val_loss: 0.0038\n",
      "Epoch 1562/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.0754e-04 - val_loss: 0.0038\n",
      "Epoch 1563/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 1.0965e-04 - val_loss: 0.0038\n",
      "Epoch 1564/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 1s 224us/step - loss: 1.1243e-04 - val_loss: 0.0040\n",
      "Epoch 1565/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.0846e-04 - val_loss: 0.0039\n",
      "Epoch 1566/2000\n",
      "3891/3891 [==============================] - 1s 222us/step - loss: 1.0787e-04 - val_loss: 0.0039\n",
      "Epoch 1567/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.0556e-04 - val_loss: 0.0036\n",
      "Epoch 1568/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.1003e-04 - val_loss: 0.0040\n",
      "Epoch 1569/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 1.2174e-04 - val_loss: 0.0044\n",
      "Epoch 1570/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 1.2842e-04 - val_loss: 0.0038\n",
      "Epoch 1571/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 1.1205e-04 - val_loss: 0.0037\n",
      "Epoch 1572/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 1.0884e-04 - val_loss: 0.0039\n",
      "Epoch 1573/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 1.0603e-04 - val_loss: 0.0038\n",
      "Epoch 1574/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 1.0658e-04 - val_loss: 0.0039\n",
      "Epoch 1575/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 1.0053e-04 - val_loss: 0.0036\n",
      "Epoch 1576/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.0028e-04 - val_loss: 0.0037\n",
      "Epoch 1577/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 1.0531e-04 - val_loss: 0.0041\n",
      "Epoch 1578/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 1.2231e-04 - val_loss: 0.0042\n",
      "Epoch 1579/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 1.2489e-04 - val_loss: 0.0039\n",
      "Epoch 1580/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 1.2351e-04 - val_loss: 0.0039\n",
      "Epoch 1581/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.1225e-04 - val_loss: 0.0034\n",
      "Epoch 1582/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 1.0293e-04 - val_loss: 0.0042\n",
      "Epoch 1583/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 1.0651e-04 - val_loss: 0.0039\n",
      "Epoch 1584/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 1.0260e-04 - val_loss: 0.0038\n",
      "Epoch 1585/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 1.0808e-04 - val_loss: 0.0039\n",
      "Epoch 1586/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.1559e-04 - val_loss: 0.0038\n",
      "Epoch 1587/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 1.0982e-04 - val_loss: 0.0041\n",
      "Epoch 1588/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 1.0754e-04 - val_loss: 0.0043\n",
      "Epoch 1589/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 1.1224e-04 - val_loss: 0.0041\n",
      "Epoch 1590/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.0527e-04 - val_loss: 0.0044\n",
      "Epoch 1591/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.1101e-04 - val_loss: 0.0037\n",
      "Epoch 1592/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 1.1792e-04 - val_loss: 0.0040\n",
      "Epoch 1593/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 1.1806e-04 - val_loss: 0.0038\n",
      "Epoch 1594/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.1669e-04 - val_loss: 0.0046\n",
      "Epoch 1595/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 1.4127e-04 - val_loss: 0.0038\n",
      "Epoch 1596/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 1.3609e-04 - val_loss: 0.0041\n",
      "Epoch 1597/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.1519e-04 - val_loss: 0.0043\n",
      "Epoch 1598/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 1.1070e-04 - val_loss: 0.0035\n",
      "Epoch 1599/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.0358e-04 - val_loss: 0.0036\n",
      "Epoch 1600/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.0660e-04 - val_loss: 0.0039\n",
      "Epoch 1601/2000\n",
      "3891/3891 [==============================] - 1s 222us/step - loss: 1.0283e-04 - val_loss: 0.0039\n",
      "Epoch 1602/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 1.0243e-04 - val_loss: 0.0038\n",
      "Epoch 1603/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 9.9561e-05 - val_loss: 0.0037\n",
      "Epoch 1604/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 1.0345e-04 - val_loss: 0.0039\n",
      "Epoch 1605/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.0273e-04 - val_loss: 0.0042\n",
      "Epoch 1606/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 1.0120e-04 - val_loss: 0.0039\n",
      "Epoch 1607/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 9.8853e-05 - val_loss: 0.0042\n",
      "Epoch 1608/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 1.0386e-04 - val_loss: 0.0043\n",
      "Epoch 1609/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 1.0180e-04 - val_loss: 0.0040\n",
      "Epoch 1610/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 1.0379e-04 - val_loss: 0.0039\n",
      "Epoch 1611/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 1.0222e-04 - val_loss: 0.0038\n",
      "Epoch 1612/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 1.0763e-04 - val_loss: 0.0040\n",
      "Epoch 1613/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.1304e-04 - val_loss: 0.0040\n",
      "Epoch 1614/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 1.1549e-04 - val_loss: 0.0038\n",
      "Epoch 1615/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 1.1100e-04 - val_loss: 0.0036\n",
      "Epoch 1616/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 1.0766e-04 - val_loss: 0.0039\n",
      "Epoch 1617/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 1.0224e-04 - val_loss: 0.0041\n",
      "Epoch 1618/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 9.9797e-05 - val_loss: 0.0042\n",
      "Epoch 1619/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 1.0949e-04 - val_loss: 0.0042\n",
      "Epoch 1620/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 1.1264e-04 - val_loss: 0.0041\n",
      "Epoch 1621/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 1.2257e-04 - val_loss: 0.0042\n",
      "Epoch 1622/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.2255e-04 - val_loss: 0.0041\n",
      "Epoch 1623/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 1.0595e-04 - val_loss: 0.0040\n",
      "Epoch 1624/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 1.0878e-04 - val_loss: 0.0042\n",
      "Epoch 1625/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 1.1123e-04 - val_loss: 0.0039\n",
      "Epoch 1626/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 1.0210e-04 - val_loss: 0.0035\n",
      "Epoch 1627/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 9.8196e-05 - val_loss: 0.0039\n",
      "Epoch 1628/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 9.5619e-05 - val_loss: 0.0042\n",
      "Epoch 1629/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.0094e-04 - val_loss: 0.0043\n",
      "Epoch 1630/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 1.0182e-04 - val_loss: 0.0042\n",
      "Epoch 1631/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 1.0025e-04 - val_loss: 0.0041\n",
      "Epoch 1632/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 1.0435e-04 - val_loss: 0.0035\n",
      "Epoch 1633/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 1.0354e-04 - val_loss: 0.0041\n",
      "Epoch 1634/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 9.7735e-05 - val_loss: 0.0039\n",
      "Epoch 1635/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 1.0190e-04 - val_loss: 0.0041\n",
      "Epoch 1636/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 1s 228us/step - loss: 1.0302e-04 - val_loss: 0.0040\n",
      "Epoch 1637/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 1.3136e-04 - val_loss: 0.0039\n",
      "Epoch 1638/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 1.2094e-04 - val_loss: 0.0038\n",
      "Epoch 1639/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.1677e-04 - val_loss: 0.0041\n",
      "Epoch 1640/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 1.1295e-04 - val_loss: 0.0036\n",
      "Epoch 1641/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.0889e-04 - val_loss: 0.0043\n",
      "Epoch 1642/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 1.1109e-04 - val_loss: 0.0045\n",
      "Epoch 1643/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.1322e-04 - val_loss: 0.0040\n",
      "Epoch 1644/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 1.0431e-04 - val_loss: 0.0044\n",
      "Epoch 1645/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 1.0307e-04 - val_loss: 0.0040\n",
      "Epoch 1646/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 9.5927e-05 - val_loss: 0.0036\n",
      "Epoch 1647/2000\n",
      "3891/3891 [==============================] - 1s 232us/step - loss: 1.0310e-04 - val_loss: 0.0039\n",
      "Epoch 1648/2000\n",
      "3891/3891 [==============================] - 1s 235us/step - loss: 1.0501e-04 - val_loss: 0.0042\n",
      "Epoch 1649/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 9.9880e-05 - val_loss: 0.0044\n",
      "Epoch 1650/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 9.8068e-05 - val_loss: 0.0043\n",
      "Epoch 1651/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 1.0310e-04 - val_loss: 0.0045\n",
      "Epoch 1652/2000\n",
      "3891/3891 [==============================] - 1s 236us/step - loss: 1.0090e-04 - val_loss: 0.0043\n",
      "Epoch 1653/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 9.6160e-05 - val_loss: 0.0041\n",
      "Epoch 1654/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 9.7249e-05 - val_loss: 0.0041\n",
      "Epoch 1655/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 9.6052e-05 - val_loss: 0.0043\n",
      "Epoch 1656/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.0788e-04 - val_loss: 0.0041\n",
      "Epoch 1657/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 1.0050e-04 - val_loss: 0.0041\n",
      "Epoch 1658/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 9.5552e-05 - val_loss: 0.0041\n",
      "Epoch 1659/2000\n",
      "3891/3891 [==============================] - 1s 237us/step - loss: 9.6210e-05 - val_loss: 0.0044\n",
      "Epoch 1660/2000\n",
      "3891/3891 [==============================] - 1s 232us/step - loss: 9.5006e-05 - val_loss: 0.0043\n",
      "Epoch 1661/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 9.5088e-05 - val_loss: 0.0041\n",
      "Epoch 1662/2000\n",
      "3891/3891 [==============================] - 1s 251us/step - loss: 9.7546e-05 - val_loss: 0.0043\n",
      "Epoch 1663/2000\n",
      "3891/3891 [==============================] - 1s 242us/step - loss: 1.0784e-04 - val_loss: 0.0037\n",
      "Epoch 1664/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.1098e-04 - val_loss: 0.0039\n",
      "Epoch 1665/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 1.0625e-04 - val_loss: 0.0037\n",
      "Epoch 1666/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.1392e-04 - val_loss: 0.0041\n",
      "Epoch 1667/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 1.0139e-04 - val_loss: 0.0039\n",
      "Epoch 1668/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 1.0244e-04 - val_loss: 0.0039\n",
      "Epoch 1669/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 1.0160e-04 - val_loss: 0.0046\n",
      "Epoch 1670/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.0997e-04 - val_loss: 0.0043\n",
      "Epoch 1671/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 1.0375e-04 - val_loss: 0.0039\n",
      "Epoch 1672/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 9.8801e-05 - val_loss: 0.0038\n",
      "Epoch 1673/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 9.9618e-05 - val_loss: 0.0042\n",
      "Epoch 1674/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 1.0575e-04 - val_loss: 0.0037\n",
      "Epoch 1675/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 1.0185e-04 - val_loss: 0.0041\n",
      "Epoch 1676/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.0993e-04 - val_loss: 0.0039\n",
      "Epoch 1677/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 1.0770e-04 - val_loss: 0.0046\n",
      "Epoch 1678/2000\n",
      "3891/3891 [==============================] - 1s 232us/step - loss: 1.1990e-04 - val_loss: 0.0041\n",
      "Epoch 1679/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.1294e-04 - val_loss: 0.0040\n",
      "Epoch 1680/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.0687e-04 - val_loss: 0.0038\n",
      "Epoch 1681/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 9.9629e-05 - val_loss: 0.0039\n",
      "Epoch 1682/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 9.1148e-05 - val_loss: 0.0040\n",
      "Epoch 1683/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 9.2021e-05 - val_loss: 0.0037\n",
      "Epoch 1684/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 9.7641e-05 - val_loss: 0.0037\n",
      "Epoch 1685/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 9.3761e-05 - val_loss: 0.0041\n",
      "Epoch 1686/2000\n",
      "3891/3891 [==============================] - 1s 235us/step - loss: 9.5603e-05 - val_loss: 0.0045\n",
      "Epoch 1687/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 1.0171e-04 - val_loss: 0.0043\n",
      "Epoch 1688/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 9.2863e-05 - val_loss: 0.0043\n",
      "Epoch 1689/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 9.1973e-05 - val_loss: 0.0041\n",
      "Epoch 1690/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 9.2611e-05 - val_loss: 0.0039\n",
      "Epoch 1691/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 9.6605e-05 - val_loss: 0.0043\n",
      "Epoch 1692/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 9.0436e-05 - val_loss: 0.0043\n",
      "Epoch 1693/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 9.2178e-05 - val_loss: 0.0041\n",
      "Epoch 1694/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 9.2896e-05 - val_loss: 0.0041\n",
      "Epoch 1695/2000\n",
      "3891/3891 [==============================] - 1s 232us/step - loss: 8.8592e-05 - val_loss: 0.0043\n",
      "Epoch 1696/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 9.1034e-05 - val_loss: 0.0041\n",
      "Epoch 1697/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 9.2677e-05 - val_loss: 0.0042\n",
      "Epoch 1698/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 1.0374e-04 - val_loss: 0.0041\n",
      "Epoch 1699/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.0019e-04 - val_loss: 0.0042\n",
      "Epoch 1700/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 9.9973e-05 - val_loss: 0.0045\n",
      "Epoch 1701/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 1.0425e-04 - val_loss: 0.0039\n",
      "Epoch 1702/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 1.0771e-04 - val_loss: 0.0038\n",
      "Epoch 1703/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 1.0423e-04 - val_loss: 0.0040\n",
      "Epoch 1704/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 9.9615e-05 - val_loss: 0.0041\n",
      "Epoch 1705/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 9.6305e-05 - val_loss: 0.0040\n",
      "Epoch 1706/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 9.6912e-05 - val_loss: 0.0045\n",
      "Epoch 1707/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 9.8972e-05 - val_loss: 0.0042\n",
      "Epoch 1708/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 1s 224us/step - loss: 9.8071e-05 - val_loss: 0.0040\n",
      "Epoch 1709/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 1.0763e-04 - val_loss: 0.0039\n",
      "Epoch 1710/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 1.0610e-04 - val_loss: 0.0039\n",
      "Epoch 1711/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 1.0957e-04 - val_loss: 0.0036\n",
      "Epoch 1712/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 9.9036e-05 - val_loss: 0.0042\n",
      "Epoch 1713/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 9.8000e-05 - val_loss: 0.0041\n",
      "Epoch 1714/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 9.6254e-05 - val_loss: 0.0040\n",
      "Epoch 1715/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 1.0002e-04 - val_loss: 0.0043\n",
      "Epoch 1716/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.0494e-04 - val_loss: 0.0039\n",
      "Epoch 1717/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 1.0700e-04 - val_loss: 0.0039\n",
      "Epoch 1718/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 9.7239e-05 - val_loss: 0.0036\n",
      "Epoch 1719/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 9.1469e-05 - val_loss: 0.0038\n",
      "Epoch 1720/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 9.8335e-05 - val_loss: 0.0041\n",
      "Epoch 1721/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 9.9673e-05 - val_loss: 0.0039\n",
      "Epoch 1722/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 9.3645e-05 - val_loss: 0.0038\n",
      "Epoch 1723/2000\n",
      "3891/3891 [==============================] - 1s 231us/step - loss: 1.0475e-04 - val_loss: 0.0039\n",
      "Epoch 1724/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 9.8760e-05 - val_loss: 0.0040\n",
      "Epoch 1725/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 9.4634e-05 - val_loss: 0.0040\n",
      "Epoch 1726/2000\n",
      "3891/3891 [==============================] - 1s 235us/step - loss: 9.6523e-05 - val_loss: 0.0042\n",
      "Epoch 1727/2000\n",
      "3891/3891 [==============================] - 1s 235us/step - loss: 8.6699e-05 - val_loss: 0.0040\n",
      "Epoch 1728/2000\n",
      "3891/3891 [==============================] - 1s 221us/step - loss: 8.2582e-05 - val_loss: 0.0041\n",
      "Epoch 1729/2000\n",
      "3891/3891 [==============================] - 1s 222us/step - loss: 8.0373e-05 - val_loss: 0.0039\n",
      "Epoch 1730/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 8.3858e-05 - val_loss: 0.0042\n",
      "Epoch 1731/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 8.3642e-05 - val_loss: 0.0039\n",
      "Epoch 1732/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 8.4701e-05 - val_loss: 0.0043\n",
      "Epoch 1733/2000\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 8.6854e-05 - val_loss: 0.0042\n",
      "Epoch 1734/2000\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 8.4084e-05 - val_loss: 0.0042\n",
      "Epoch 1735/2000\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 9.2763e-05 - val_loss: 0.0040\n",
      "Epoch 1736/2000\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 9.4088e-05 - val_loss: 0.0038\n",
      "Epoch 1737/2000\n",
      "3891/3891 [==============================] - 1s 222us/step - loss: 9.3014e-05 - val_loss: 0.0041\n",
      "Epoch 1738/2000\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 8.6624e-05 - val_loss: 0.0044\n",
      "Epoch 1739/2000\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 9.3315e-05 - val_loss: 0.0039\n",
      "Epoch 1740/2000\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 9.7603e-05 - val_loss: 0.0042\n",
      "Epoch 1741/2000\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 9.4083e-05 - val_loss: 0.0042\n",
      "Epoch 1742/2000\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 8.2774e-05 - val_loss: 0.0039\n",
      "Epoch 1743/2000\n",
      "3891/3891 [==============================] - 1s 221us/step - loss: 8.3168e-05 - val_loss: 0.0041\n",
      "Epoch 1744/2000\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 8.3936e-05 - val_loss: 0.0042\n",
      "Epoch 1745/2000\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 8.4699e-05 - val_loss: 0.0044\n",
      "Epoch 1746/2000\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 9.1142e-05 - val_loss: 0.0040\n",
      "Epoch 1747/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 9.4719e-05 - val_loss: 0.0042\n",
      "Epoch 1748/2000\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 9.0238e-05 - val_loss: 0.0039\n",
      "Epoch 1749/2000\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 9.1259e-05 - val_loss: 0.0040\n",
      "Epoch 1750/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 9.8681e-05 - val_loss: 0.0036\n",
      "Epoch 1751/2000\n",
      "3891/3891 [==============================] - 1s 221us/step - loss: 1.1750e-04 - val_loss: 0.0042\n",
      "Epoch 1752/2000\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 1.0550e-04 - val_loss: 0.0042\n",
      "Epoch 1753/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 9.4536e-05 - val_loss: 0.0039\n",
      "Epoch 1754/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 9.8008e-05 - val_loss: 0.0041\n",
      "Epoch 1755/2000\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 9.4182e-05 - val_loss: 0.0038\n",
      "Epoch 1756/2000\n",
      "3891/3891 [==============================] - 1s 216us/step - loss: 9.2675e-05 - val_loss: 0.0038\n",
      "Epoch 1757/2000\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 9.0889e-05 - val_loss: 0.0041\n",
      "Epoch 1758/2000\n",
      "3891/3891 [==============================] - 1s 221us/step - loss: 8.3518e-05 - val_loss: 0.0040\n",
      "Epoch 1759/2000\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 8.3307e-05 - val_loss: 0.0040\n",
      "Epoch 1760/2000\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 9.2931e-05 - val_loss: 0.0039\n",
      "Epoch 1761/2000\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 7.8828e-05 - val_loss: 0.0044\n",
      "Epoch 1762/2000\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 8.5030e-05 - val_loss: 0.0042\n",
      "Epoch 1763/2000\n",
      "3891/3891 [==============================] - 1s 215us/step - loss: 9.2324e-05 - val_loss: 0.0039\n",
      "Epoch 1764/2000\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 8.9207e-05 - val_loss: 0.0040\n",
      "Epoch 1765/2000\n",
      "3891/3891 [==============================] - 1s 222us/step - loss: 8.9695e-05 - val_loss: 0.0042\n",
      "Epoch 1766/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 9.3175e-05 - val_loss: 0.0040\n",
      "Epoch 1767/2000\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 8.8530e-05 - val_loss: 0.0039\n",
      "Epoch 1768/2000\n",
      "3891/3891 [==============================] - 1s 221us/step - loss: 8.3963e-05 - val_loss: 0.0043\n",
      "Epoch 1769/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 8.0853e-05 - val_loss: 0.0040\n",
      "Epoch 1770/2000\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 7.8353e-05 - val_loss: 0.0038\n",
      "Epoch 1771/2000\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 8.5227e-05 - val_loss: 0.0038\n",
      "Epoch 1772/2000\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 8.6146e-05 - val_loss: 0.0045\n",
      "Epoch 1773/2000\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 9.0361e-05 - val_loss: 0.0038\n",
      "Epoch 1774/2000\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 8.4996e-05 - val_loss: 0.0040\n",
      "Epoch 1775/2000\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 8.7832e-05 - val_loss: 0.0039\n",
      "Epoch 1776/2000\n",
      "3891/3891 [==============================] - 1s 222us/step - loss: 9.4173e-05 - val_loss: 0.0037\n",
      "Epoch 1777/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 8.9365e-05 - val_loss: 0.0040\n",
      "Epoch 1778/2000\n",
      "3891/3891 [==============================] - 1s 237us/step - loss: 9.8525e-05 - val_loss: 0.0042\n",
      "Epoch 1779/2000\n",
      "3891/3891 [==============================] - 1s 232us/step - loss: 9.7889e-05 - val_loss: 0.0041\n",
      "Epoch 1780/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 1s 220us/step - loss: 9.7260e-05 - val_loss: 0.0043\n",
      "Epoch 1781/2000\n",
      "3891/3891 [==============================] - 1s 222us/step - loss: 9.4056e-05 - val_loss: 0.0039\n",
      "Epoch 1782/2000\n",
      "3891/3891 [==============================] - 1s 234us/step - loss: 1.0171e-04 - val_loss: 0.0043\n",
      "Epoch 1783/2000\n",
      "3891/3891 [==============================] - 1s 222us/step - loss: 1.1246e-04 - val_loss: 0.0041\n",
      "Epoch 1784/2000\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 9.8569e-05 - val_loss: 0.0041\n",
      "Epoch 1785/2000\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 9.3586e-05 - val_loss: 0.0040\n",
      "Epoch 1786/2000\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 9.7282e-05 - val_loss: 0.0042\n",
      "Epoch 1787/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 1.1782e-04 - val_loss: 0.0041\n",
      "Epoch 1788/2000\n",
      "3891/3891 [==============================] - 1s 229us/step - loss: 1.1142e-04 - val_loss: 0.0045\n",
      "Epoch 1789/2000\n",
      "3891/3891 [==============================] - 1s 232us/step - loss: 9.6848e-05 - val_loss: 0.0040\n",
      "Epoch 1790/2000\n",
      "3891/3891 [==============================] - 1s 238us/step - loss: 8.6236e-05 - val_loss: 0.0037\n",
      "Epoch 1791/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 9.1411e-05 - val_loss: 0.0045\n",
      "Epoch 1792/2000\n",
      "3891/3891 [==============================] - 1s 216us/step - loss: 9.5122e-05 - val_loss: 0.0042\n",
      "Epoch 1793/2000\n",
      "3891/3891 [==============================] - 1s 215us/step - loss: 8.8945e-05 - val_loss: 0.0044\n",
      "Epoch 1794/2000\n",
      "3891/3891 [==============================] - 1s 216us/step - loss: 9.0898e-05 - val_loss: 0.0045\n",
      "Epoch 1795/2000\n",
      "3891/3891 [==============================] - 1s 221us/step - loss: 8.5231e-05 - val_loss: 0.0035\n",
      "Epoch 1796/2000\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 8.9205e-05 - val_loss: 0.0038\n",
      "Epoch 1797/2000\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 8.7417e-05 - val_loss: 0.0040\n",
      "Epoch 1798/2000\n",
      "3891/3891 [==============================] - 1s 222us/step - loss: 9.0879e-05 - val_loss: 0.0042\n",
      "Epoch 1799/2000\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 8.6177e-05 - val_loss: 0.0042\n",
      "Epoch 1800/2000\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 9.3723e-05 - val_loss: 0.0039\n",
      "Epoch 1801/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 9.1085e-05 - val_loss: 0.0044\n",
      "Epoch 1802/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 9.1640e-05 - val_loss: 0.0041\n",
      "Epoch 1803/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 8.8966e-05 - val_loss: 0.0042\n",
      "Epoch 1804/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 8.5559e-05 - val_loss: 0.0042\n",
      "Epoch 1805/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 8.1832e-05 - val_loss: 0.0042\n",
      "Epoch 1806/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 7.5952e-05 - val_loss: 0.0040\n",
      "Epoch 1807/2000\n",
      "3891/3891 [==============================] - 1s 222us/step - loss: 7.6829e-05 - val_loss: 0.0039\n",
      "Epoch 1808/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 7.3983e-05 - val_loss: 0.0042\n",
      "Epoch 1809/2000\n",
      "3891/3891 [==============================] - 1s 221us/step - loss: 7.6896e-05 - val_loss: 0.0039\n",
      "Epoch 1810/2000\n",
      "3891/3891 [==============================] - 1s 230us/step - loss: 7.7154e-05 - val_loss: 0.0038\n",
      "Epoch 1811/2000\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 7.5654e-05 - val_loss: 0.0039\n",
      "Epoch 1812/2000\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 7.5110e-05 - val_loss: 0.0041\n",
      "Epoch 1813/2000\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 7.8501e-05 - val_loss: 0.0041\n",
      "Epoch 1814/2000\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 7.5495e-05 - val_loss: 0.0045\n",
      "Epoch 1815/2000\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 8.4054e-05 - val_loss: 0.0043\n",
      "Epoch 1816/2000\n",
      "3891/3891 [==============================] - 1s 215us/step - loss: 8.5575e-05 - val_loss: 0.0045\n",
      "Epoch 1817/2000\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 8.3577e-05 - val_loss: 0.0038\n",
      "Epoch 1818/2000\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 8.2373e-05 - val_loss: 0.0043\n",
      "Epoch 1819/2000\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 8.7734e-05 - val_loss: 0.0043\n",
      "Epoch 1820/2000\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 8.1235e-05 - val_loss: 0.0046\n",
      "Epoch 1821/2000\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 7.9806e-05 - val_loss: 0.0037\n",
      "Epoch 1822/2000\n",
      "3891/3891 [==============================] - 1s 216us/step - loss: 7.9472e-05 - val_loss: 0.0044\n",
      "Epoch 1823/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 8.3038e-05 - val_loss: 0.0039\n",
      "Epoch 1824/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 7.9542e-05 - val_loss: 0.0043\n",
      "Epoch 1825/2000\n",
      "3891/3891 [==============================] - 1s 216us/step - loss: 7.6162e-05 - val_loss: 0.0044\n",
      "Epoch 1826/2000\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 7.7422e-05 - val_loss: 0.0041\n",
      "Epoch 1827/2000\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 7.5739e-05 - val_loss: 0.0044\n",
      "Epoch 1828/2000\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 7.2039e-05 - val_loss: 0.0041\n",
      "Epoch 1829/2000\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 7.0686e-05 - val_loss: 0.0043\n",
      "Epoch 1830/2000\n",
      "3891/3891 [==============================] - 1s 216us/step - loss: 7.3370e-05 - val_loss: 0.0042\n",
      "Epoch 1831/2000\n",
      "3891/3891 [==============================] - 1s 216us/step - loss: 7.7148e-05 - val_loss: 0.0045\n",
      "Epoch 1832/2000\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 7.3050e-05 - val_loss: 0.0042\n",
      "Epoch 1833/2000\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 7.3684e-05 - val_loss: 0.0044\n",
      "Epoch 1834/2000\n",
      "3891/3891 [==============================] - 1s 216us/step - loss: 7.6949e-05 - val_loss: 0.0041\n",
      "Epoch 1835/2000\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 7.7941e-05 - val_loss: 0.0042\n",
      "Epoch 1836/2000\n",
      "3891/3891 [==============================] - 1s 215us/step - loss: 7.9099e-05 - val_loss: 0.0044\n",
      "Epoch 1837/2000\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 7.7021e-05 - val_loss: 0.0041\n",
      "Epoch 1838/2000\n",
      "3891/3891 [==============================] - 1s 216us/step - loss: 7.5799e-05 - val_loss: 0.0042\n",
      "Epoch 1839/2000\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 8.0792e-05 - val_loss: 0.0044\n",
      "Epoch 1840/2000\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 8.7805e-05 - val_loss: 0.0042\n",
      "Epoch 1841/2000\n",
      "3891/3891 [==============================] - 1s 216us/step - loss: 7.9049e-05 - val_loss: 0.0041\n",
      "Epoch 1842/2000\n",
      "3891/3891 [==============================] - 1s 216us/step - loss: 7.9464e-05 - val_loss: 0.0038\n",
      "Epoch 1843/2000\n",
      "3891/3891 [==============================] - 1s 222us/step - loss: 7.9726e-05 - val_loss: 0.0041\n",
      "Epoch 1844/2000\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 8.8435e-05 - val_loss: 0.0046\n",
      "Epoch 1845/2000\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 8.6114e-05 - val_loss: 0.0042\n",
      "Epoch 1846/2000\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 9.3109e-05 - val_loss: 0.0040\n",
      "Epoch 1847/2000\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 1.0119e-04 - val_loss: 0.0037\n",
      "Epoch 1848/2000\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 1.0796e-04 - val_loss: 0.0035\n",
      "Epoch 1849/2000\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 1.0017e-04 - val_loss: 0.0042\n",
      "Epoch 1850/2000\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 9.6638e-05 - val_loss: 0.0044\n",
      "Epoch 1851/2000\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 8.6615e-05 - val_loss: 0.0040\n",
      "Epoch 1852/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 1s 221us/step - loss: 8.2832e-05 - val_loss: 0.0041\n",
      "Epoch 1853/2000\n",
      "3891/3891 [==============================] - 1s 216us/step - loss: 8.3631e-05 - val_loss: 0.0041\n",
      "Epoch 1854/2000\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 8.3186e-05 - val_loss: 0.0040\n",
      "Epoch 1855/2000\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 7.9825e-05 - val_loss: 0.0042\n",
      "Epoch 1856/2000\n",
      "3891/3891 [==============================] - 1s 216us/step - loss: 8.3945e-05 - val_loss: 0.0041\n",
      "Epoch 1857/2000\n",
      "3891/3891 [==============================] - 1s 215us/step - loss: 8.0129e-05 - val_loss: 0.0041\n",
      "Epoch 1858/2000\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 8.1690e-05 - val_loss: 0.0041\n",
      "Epoch 1859/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 7.5294e-05 - val_loss: 0.0040\n",
      "Epoch 1860/2000\n",
      "3891/3891 [==============================] - 1s 216us/step - loss: 7.6198e-05 - val_loss: 0.0043\n",
      "Epoch 1861/2000\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 7.8229e-05 - val_loss: 0.0040\n",
      "Epoch 1862/2000\n",
      "3891/3891 [==============================] - 1s 221us/step - loss: 7.9866e-05 - val_loss: 0.0043\n",
      "Epoch 1863/2000\n",
      "3891/3891 [==============================] - 1s 216us/step - loss: 7.8108e-05 - val_loss: 0.0041\n",
      "Epoch 1864/2000\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 7.7697e-05 - val_loss: 0.0040\n",
      "Epoch 1865/2000\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 7.3594e-05 - val_loss: 0.0041\n",
      "Epoch 1866/2000\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 7.5324e-05 - val_loss: 0.0041\n",
      "Epoch 1867/2000\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 8.1270e-05 - val_loss: 0.0041\n",
      "Epoch 1868/2000\n",
      "3891/3891 [==============================] - 1s 216us/step - loss: 8.1731e-05 - val_loss: 0.0039\n",
      "Epoch 1869/2000\n",
      "3891/3891 [==============================] - 1s 215us/step - loss: 8.2846e-05 - val_loss: 0.0040\n",
      "Epoch 1870/2000\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 7.1903e-05 - val_loss: 0.0040\n",
      "Epoch 1871/2000\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 7.4549e-05 - val_loss: 0.0045\n",
      "Epoch 1872/2000\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 8.9249e-05 - val_loss: 0.0047\n",
      "Epoch 1873/2000\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 8.5153e-05 - val_loss: 0.0041\n",
      "Epoch 1874/2000\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 8.7272e-05 - val_loss: 0.0038\n",
      "Epoch 1875/2000\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 8.3449e-05 - val_loss: 0.0036\n",
      "Epoch 1876/2000\n",
      "3891/3891 [==============================] - 1s 214us/step - loss: 8.5762e-05 - val_loss: 0.0037\n",
      "Epoch 1877/2000\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 7.8426e-05 - val_loss: 0.0044\n",
      "Epoch 1878/2000\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 7.9302e-05 - val_loss: 0.0045\n",
      "Epoch 1879/2000\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 7.8286e-05 - val_loss: 0.0043\n",
      "Epoch 1880/2000\n",
      "3891/3891 [==============================] - 1s 222us/step - loss: 7.9230e-05 - val_loss: 0.0041\n",
      "Epoch 1881/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 8.1600e-05 - val_loss: 0.0041\n",
      "Epoch 1882/2000\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 9.4752e-05 - val_loss: 0.0045\n",
      "Epoch 1883/2000\n",
      "3891/3891 [==============================] - 1s 215us/step - loss: 9.4613e-05 - val_loss: 0.0039\n",
      "Epoch 1884/2000\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 1.0550e-04 - val_loss: 0.0042\n",
      "Epoch 1885/2000\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 1.0783e-04 - val_loss: 0.0041\n",
      "Epoch 1886/2000\n",
      "3891/3891 [==============================] - 1s 215us/step - loss: 9.7166e-05 - val_loss: 0.0042\n",
      "Epoch 1887/2000\n",
      "3891/3891 [==============================] - 1s 216us/step - loss: 1.1223e-04 - val_loss: 0.0037\n",
      "Epoch 1888/2000\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 1.0794e-04 - val_loss: 0.0037\n",
      "Epoch 1889/2000\n",
      "3891/3891 [==============================] - 1s 216us/step - loss: 1.1269e-04 - val_loss: 0.0036\n",
      "Epoch 1890/2000\n",
      "3891/3891 [==============================] - 1s 215us/step - loss: 9.8278e-05 - val_loss: 0.0034\n",
      "Epoch 1891/2000\n",
      "3891/3891 [==============================] - 1s 216us/step - loss: 9.1733e-05 - val_loss: 0.0039\n",
      "Epoch 1892/2000\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 8.2590e-05 - val_loss: 0.0036\n",
      "Epoch 1893/2000\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 7.7693e-05 - val_loss: 0.0041\n",
      "Epoch 1894/2000\n",
      "3891/3891 [==============================] - 1s 227us/step - loss: 7.7038e-05 - val_loss: 0.0041\n",
      "Epoch 1895/2000\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 7.4836e-05 - val_loss: 0.0039\n",
      "Epoch 1896/2000\n",
      "3891/3891 [==============================] - 1s 214us/step - loss: 7.6568e-05 - val_loss: 0.0041\n",
      "Epoch 1897/2000\n",
      "3891/3891 [==============================] - 1s 215us/step - loss: 7.1186e-05 - val_loss: 0.0037\n",
      "Epoch 1898/2000\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 7.0703e-05 - val_loss: 0.0039\n",
      "Epoch 1899/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 6.5791e-05 - val_loss: 0.0041\n",
      "Epoch 1900/2000\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 6.7695e-05 - val_loss: 0.0041\n",
      "Epoch 1901/2000\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 6.7964e-05 - val_loss: 0.0040\n",
      "Epoch 1902/2000\n",
      "3891/3891 [==============================] - 1s 216us/step - loss: 6.8554e-05 - val_loss: 0.0042\n",
      "Epoch 1903/2000\n",
      "3891/3891 [==============================] - 1s 216us/step - loss: 7.0770e-05 - val_loss: 0.0042\n",
      "Epoch 1904/2000\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 7.2311e-05 - val_loss: 0.0043\n",
      "Epoch 1905/2000\n",
      "3891/3891 [==============================] - 1s 215us/step - loss: 7.4437e-05 - val_loss: 0.0041\n",
      "Epoch 1906/2000\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 7.0843e-05 - val_loss: 0.0043\n",
      "Epoch 1907/2000\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 6.8645e-05 - val_loss: 0.0039\n",
      "Epoch 1908/2000\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 6.9240e-05 - val_loss: 0.0041\n",
      "Epoch 1909/2000\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 7.1350e-05 - val_loss: 0.0043\n",
      "Epoch 1910/2000\n",
      "3891/3891 [==============================] - 1s 221us/step - loss: 7.5654e-05 - val_loss: 0.0042\n",
      "Epoch 1911/2000\n",
      "3891/3891 [==============================] - 1s 232us/step - loss: 7.3357e-05 - val_loss: 0.0039\n",
      "Epoch 1912/2000\n",
      "3891/3891 [==============================] - 1s 238us/step - loss: 7.4992e-05 - val_loss: 0.0046\n",
      "Epoch 1913/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 7.5498e-05 - val_loss: 0.0040\n",
      "Epoch 1914/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 8.3838e-05 - val_loss: 0.0044\n",
      "Epoch 1915/2000\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 8.6438e-05 - val_loss: 0.0045\n",
      "Epoch 1916/2000\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 7.5879e-05 - val_loss: 0.0041\n",
      "Epoch 1917/2000\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 7.2244e-05 - val_loss: 0.0045\n",
      "Epoch 1918/2000\n",
      "3891/3891 [==============================] - 1s 222us/step - loss: 7.1462e-05 - val_loss: 0.0044\n",
      "Epoch 1919/2000\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 6.7234e-05 - val_loss: 0.0040\n",
      "Epoch 1920/2000\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 7.0873e-05 - val_loss: 0.0042\n",
      "Epoch 1921/2000\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 7.1717e-05 - val_loss: 0.0040\n",
      "Epoch 1922/2000\n",
      "3891/3891 [==============================] - 1s 216us/step - loss: 7.6105e-05 - val_loss: 0.0043\n",
      "Epoch 1923/2000\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 7.3076e-05 - val_loss: 0.0043\n",
      "Epoch 1924/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 1s 218us/step - loss: 6.9872e-05 - val_loss: 0.0046\n",
      "Epoch 1925/2000\n",
      "3891/3891 [==============================] - 1s 214us/step - loss: 6.9643e-05 - val_loss: 0.0043\n",
      "Epoch 1926/2000\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 7.0019e-05 - val_loss: 0.0042\n",
      "Epoch 1927/2000\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 7.0773e-05 - val_loss: 0.0043\n",
      "Epoch 1928/2000\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 6.4034e-05 - val_loss: 0.0041\n",
      "Epoch 1929/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 6.6620e-05 - val_loss: 0.0047\n",
      "Epoch 1930/2000\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 6.7360e-05 - val_loss: 0.0044\n",
      "Epoch 1931/2000\n",
      "3891/3891 [==============================] - 1s 215us/step - loss: 8.3399e-05 - val_loss: 0.0043\n",
      "Epoch 1932/2000\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 7.3852e-05 - val_loss: 0.0043\n",
      "Epoch 1933/2000\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 6.9454e-05 - val_loss: 0.0043\n",
      "Epoch 1934/2000\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 6.8821e-05 - val_loss: 0.0044\n",
      "Epoch 1935/2000\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 7.7554e-05 - val_loss: 0.0041\n",
      "Epoch 1936/2000\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 7.5281e-05 - val_loss: 0.0042\n",
      "Epoch 1937/2000\n",
      "3891/3891 [==============================] - 1s 223us/step - loss: 7.6538e-05 - val_loss: 0.0044\n",
      "Epoch 1938/2000\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 7.8895e-05 - val_loss: 0.0042\n",
      "Epoch 1939/2000\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 9.3257e-05 - val_loss: 0.0046\n",
      "Epoch 1940/2000\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 8.7360e-05 - val_loss: 0.0044\n",
      "Epoch 1941/2000\n",
      "3891/3891 [==============================] - 1s 228us/step - loss: 8.5696e-05 - val_loss: 0.0044\n",
      "Epoch 1942/2000\n",
      "3891/3891 [==============================] - 1s 226us/step - loss: 9.0351e-05 - val_loss: 0.0042\n",
      "Epoch 1943/2000\n",
      "3891/3891 [==============================] - 1s 221us/step - loss: 8.3165e-05 - val_loss: 0.0041\n",
      "Epoch 1944/2000\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 9.3415e-05 - val_loss: 0.0046\n",
      "Epoch 1945/2000\n",
      "3891/3891 [==============================] - 1s 214us/step - loss: 9.4092e-05 - val_loss: 0.0045\n",
      "Epoch 1946/2000\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 8.6665e-05 - val_loss: 0.0037\n",
      "Epoch 1947/2000\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 8.2567e-05 - val_loss: 0.0036\n",
      "Epoch 1948/2000\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 7.2185e-05 - val_loss: 0.0040\n",
      "Epoch 1949/2000\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 6.6989e-05 - val_loss: 0.0042\n",
      "Epoch 1950/2000\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 6.9576e-05 - val_loss: 0.0044\n",
      "Epoch 1951/2000\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 6.8740e-05 - val_loss: 0.0046\n",
      "Epoch 1952/2000\n",
      "3891/3891 [==============================] - 1s 215us/step - loss: 6.8842e-05 - val_loss: 0.0040\n",
      "Epoch 1953/2000\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 6.6912e-05 - val_loss: 0.0041\n",
      "Epoch 1954/2000\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 6.8482e-05 - val_loss: 0.0040\n",
      "Epoch 1955/2000\n",
      "3891/3891 [==============================] - 1s 221us/step - loss: 6.9065e-05 - val_loss: 0.0043\n",
      "Epoch 1956/2000\n",
      "3891/3891 [==============================] - 1s 222us/step - loss: 6.6008e-05 - val_loss: 0.0045\n",
      "Epoch 1957/2000\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 6.5681e-05 - val_loss: 0.0047\n",
      "Epoch 1958/2000\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 6.3551e-05 - val_loss: 0.0043\n",
      "Epoch 1959/2000\n",
      "3891/3891 [==============================] - 1s 215us/step - loss: 6.3208e-05 - val_loss: 0.0048\n",
      "Epoch 1960/2000\n",
      "3891/3891 [==============================] - 1s 216us/step - loss: 7.4942e-05 - val_loss: 0.0045\n",
      "Epoch 1961/2000\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 7.2514e-05 - val_loss: 0.0040\n",
      "Epoch 1962/2000\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 7.1443e-05 - val_loss: 0.0040\n",
      "Epoch 1963/2000\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 7.7995e-05 - val_loss: 0.0046\n",
      "Epoch 1964/2000\n",
      "3891/3891 [==============================] - 1s 234us/step - loss: 7.0399e-05 - val_loss: 0.0046\n",
      "Epoch 1965/2000\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 7.9610e-05 - val_loss: 0.0040\n",
      "Epoch 1966/2000\n",
      "3891/3891 [==============================] - 1s 216us/step - loss: 8.2360e-05 - val_loss: 0.0045\n",
      "Epoch 1967/2000\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 7.9508e-05 - val_loss: 0.0042\n",
      "Epoch 1968/2000\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 7.4374e-05 - val_loss: 0.0041\n",
      "Epoch 1969/2000\n",
      "3891/3891 [==============================] - 1s 216us/step - loss: 6.8492e-05 - val_loss: 0.0041\n",
      "Epoch 1970/2000\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 7.4205e-05 - val_loss: 0.0040\n",
      "Epoch 1971/2000\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 8.1071e-05 - val_loss: 0.0041\n",
      "Epoch 1972/2000\n",
      "3891/3891 [==============================] - 1s 215us/step - loss: 7.6115e-05 - val_loss: 0.0041\n",
      "Epoch 1973/2000\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 7.6026e-05 - val_loss: 0.0045\n",
      "Epoch 1974/2000\n",
      "3891/3891 [==============================] - 1s 224us/step - loss: 7.2349e-05 - val_loss: 0.0044\n",
      "Epoch 1975/2000\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 6.6991e-05 - val_loss: 0.0040\n",
      "Epoch 1976/2000\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 6.7090e-05 - val_loss: 0.0040\n",
      "Epoch 1977/2000\n",
      "3891/3891 [==============================] - 1s 216us/step - loss: 6.9614e-05 - val_loss: 0.0041\n",
      "Epoch 1978/2000\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 7.0897e-05 - val_loss: 0.0040\n",
      "Epoch 1979/2000\n",
      "3891/3891 [==============================] - 1s 216us/step - loss: 6.9496e-05 - val_loss: 0.0043\n",
      "Epoch 1980/2000\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 7.9693e-05 - val_loss: 0.0038\n",
      "Epoch 1981/2000\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 8.5484e-05 - val_loss: 0.0043\n",
      "Epoch 1982/2000\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 7.4144e-05 - val_loss: 0.0045\n",
      "Epoch 1983/2000\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 6.6823e-05 - val_loss: 0.0044\n",
      "Epoch 1984/2000\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 6.9859e-05 - val_loss: 0.0042\n",
      "Epoch 1985/2000\n",
      "3891/3891 [==============================] - 1s 216us/step - loss: 7.2207e-05 - val_loss: 0.0039\n",
      "Epoch 1986/2000\n",
      "3891/3891 [==============================] - 1s 215us/step - loss: 7.1378e-05 - val_loss: 0.0040\n",
      "Epoch 1987/2000\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 7.2842e-05 - val_loss: 0.0046\n",
      "Epoch 1988/2000\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 7.2167e-05 - val_loss: 0.0039\n",
      "Epoch 1989/2000\n",
      "3891/3891 [==============================] - 1s 216us/step - loss: 7.6370e-05 - val_loss: 0.0037\n",
      "Epoch 1990/2000\n",
      "3891/3891 [==============================] - 1s 219us/step - loss: 7.4095e-05 - val_loss: 0.0043\n",
      "Epoch 1991/2000\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 6.8484e-05 - val_loss: 0.0046\n",
      "Epoch 1992/2000\n",
      "3891/3891 [==============================] - 1s 214us/step - loss: 6.9423e-05 - val_loss: 0.0043\n",
      "Epoch 1993/2000\n",
      "3891/3891 [==============================] - 1s 225us/step - loss: 7.1129e-05 - val_loss: 0.0043\n",
      "Epoch 1994/2000\n",
      "3891/3891 [==============================] - 1s 220us/step - loss: 6.4548e-05 - val_loss: 0.0042\n",
      "Epoch 1995/2000\n",
      "3891/3891 [==============================] - 1s 217us/step - loss: 6.7085e-05 - val_loss: 0.0042\n",
      "Epoch 1996/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891/3891 [==============================] - 1s 221us/step - loss: 6.4646e-05 - val_loss: 0.0045\n",
      "Epoch 1997/2000\n",
      "3891/3891 [==============================] - 1s 218us/step - loss: 6.3197e-05 - val_loss: 0.0044\n",
      "Epoch 1998/2000\n",
      "3891/3891 [==============================] - 1s 215us/step - loss: 6.3474e-05 - val_loss: 0.0044\n",
      "Epoch 1999/2000\n",
      "3891/3891 [==============================] - 1s 221us/step - loss: 6.2409e-05 - val_loss: 0.0040\n",
      "Epoch 2000/2000\n",
      "3891/3891 [==============================] - 1s 221us/step - loss: 6.4728e-05 - val_loss: 0.0042\n"
     ]
    }
   ],
   "source": [
    "final_model = build_lstm(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lstmsize': 118,\n",
       " 'activation': 'relu',\n",
       " 'optimizer': 'adam',\n",
       " 'shuffle': True,\n",
       " 'density': 98,\n",
       " 'twice': False,\n",
       " 'callbacks': [<keras.callbacks.callbacks.ModelCheckpoint at 0x292126ea3c8>]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_182\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_292 (LSTM)              (None, 118)               58528     \n",
      "_________________________________________________________________\n",
      "dense_706 (Dense)            (None, 98)                11662     \n",
      "_________________________________________________________________\n",
      "dense_707 (Dense)            (None, 1)                 99        \n",
      "=================================================================\n",
      "Total params: 70,289\n",
      "Trainable params: 70,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model[0].load_weights('./checkpoints/IBM_4days/IBM.(best).hdf5')\n",
    "y_predicted = final_model[0].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y_test = y_normaliser.inverse_transform(y_predicted)\n",
    "true_y_test = y_normaliser.inverse_transform(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE is 41.23\n",
      "Medium error is 4.75\n"
     ]
    }
   ],
   "source": [
    "loss = np.mean((true_y_test - predicted_y_test)**2)\n",
    "medium_error = np.mean(abs(true_y_test - predicted_y_test))\n",
    "print(f'MSE is {loss:.2f}\\nMedium error is {medium_error:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_down_test = []\n",
    "up_down_predicted = []\n",
    "\n",
    "for y,x in zip(Y_test,X_test):\n",
    "    if y[0] > x[-1][0]: up_down_test.append(1)\n",
    "    elif y[0] < x[-1][0]: up_down_test.append(-1)\n",
    "    else: up_down_test.append(0)\n",
    "        \n",
    "for y,x in zip(y_predicted,X_test):\n",
    "    if y[0] > x[-1][0]: up_down_predicted.append(1)\n",
    "    elif y[0] < x[-1][0]: up_down_predicted.append(-1)\n",
    "    else: up_down_predicted.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trend accuracy is: 60.53%\n"
     ]
    }
   ],
   "source": [
    "print(f'Trend accuracy is: {(sum(1 for r,p in zip(up_down_test,up_down_predicted) if r == p)/len(up_down_test))*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for upward trend is: 44.58%\n",
      "Accuracy for downward trend is: 79.71%\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy for upward trend is: {(sum(1 for r,p in zip(up_down_test,up_down_predicted) if r == 1 and p == 1)/sum(1 for v in up_down_test if v == 1))*100:.2f}%')\n",
    "print(f'Accuracy for downward trend is: {(sum(1 for r,p in zip(up_down_test,up_down_predicted) if r == -1 and p == -1)/sum(1 for v in up_down_test if v == -1))*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predictions over the last 92 days in test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 3200x2400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "figure(num=None, figsize=(40, 30), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "plt.plot(range(92), true_y_test[-92:])\n",
    "plt.plot(range(92), predicted_y_test[-92:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Last 16 days + prediction of last 8 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 3200x2400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure(num=None, figsize=(40, 30), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "plt.plot(range(16), true_y_test[-16:])\n",
    "plt.plot(range(16), np.append(true_y_test[-16:-8], predicted_y_test[-8:]))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
