{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./datasets/IBM_daily.csv').sort_values(by='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>1. open</th>\n",
       "      <th>2. high</th>\n",
       "      <th>3. low</th>\n",
       "      <th>4. close</th>\n",
       "      <th>5. volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5217</th>\n",
       "      <td>1999-11-01</td>\n",
       "      <td>98.50</td>\n",
       "      <td>98.8100</td>\n",
       "      <td>96.37</td>\n",
       "      <td>96.75</td>\n",
       "      <td>9551800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5216</th>\n",
       "      <td>1999-11-02</td>\n",
       "      <td>96.75</td>\n",
       "      <td>96.8100</td>\n",
       "      <td>93.69</td>\n",
       "      <td>94.81</td>\n",
       "      <td>11105400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5215</th>\n",
       "      <td>1999-11-03</td>\n",
       "      <td>95.87</td>\n",
       "      <td>95.9400</td>\n",
       "      <td>93.50</td>\n",
       "      <td>94.37</td>\n",
       "      <td>10369100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5214</th>\n",
       "      <td>1999-11-04</td>\n",
       "      <td>94.44</td>\n",
       "      <td>94.4400</td>\n",
       "      <td>90.00</td>\n",
       "      <td>91.56</td>\n",
       "      <td>16697600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5213</th>\n",
       "      <td>1999-11-05</td>\n",
       "      <td>92.75</td>\n",
       "      <td>92.9400</td>\n",
       "      <td>90.19</td>\n",
       "      <td>90.25</td>\n",
       "      <td>13737600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-07-22</td>\n",
       "      <td>125.90</td>\n",
       "      <td>129.4700</td>\n",
       "      <td>125.80</td>\n",
       "      <td>128.67</td>\n",
       "      <td>8195366.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-07-23</td>\n",
       "      <td>129.10</td>\n",
       "      <td>129.3700</td>\n",
       "      <td>127.15</td>\n",
       "      <td>127.33</td>\n",
       "      <td>4220136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-07-24</td>\n",
       "      <td>126.48</td>\n",
       "      <td>127.6459</td>\n",
       "      <td>125.50</td>\n",
       "      <td>125.79</td>\n",
       "      <td>3531076.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-07-27</td>\n",
       "      <td>124.86</td>\n",
       "      <td>126.3200</td>\n",
       "      <td>124.71</td>\n",
       "      <td>126.21</td>\n",
       "      <td>3733547.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-28</td>\n",
       "      <td>125.82</td>\n",
       "      <td>126.3400</td>\n",
       "      <td>124.15</td>\n",
       "      <td>124.47</td>\n",
       "      <td>4157538.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5218 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  1. open   2. high  3. low  4. close   5. volume\n",
       "5217  1999-11-01    98.50   98.8100   96.37     96.75   9551800.0\n",
       "5216  1999-11-02    96.75   96.8100   93.69     94.81  11105400.0\n",
       "5215  1999-11-03    95.87   95.9400   93.50     94.37  10369100.0\n",
       "5214  1999-11-04    94.44   94.4400   90.00     91.56  16697600.0\n",
       "5213  1999-11-05    92.75   92.9400   90.19     90.25  13737600.0\n",
       "...          ...      ...       ...     ...       ...         ...\n",
       "4     2020-07-22   125.90  129.4700  125.80    128.67   8195366.0\n",
       "3     2020-07-23   129.10  129.3700  127.15    127.33   4220136.0\n",
       "2     2020-07-24   126.48  127.6459  125.50    125.79   3531076.0\n",
       "1     2020-07-27   124.86  126.3200  124.71    126.21   3733547.0\n",
       "0     2020-07-28   125.82  126.3400  124.15    124.47   4157538.0\n",
       "\n",
       "[5218 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1. open</th>\n",
       "      <th>2. high</th>\n",
       "      <th>3. low</th>\n",
       "      <th>4. close</th>\n",
       "      <th>5. volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5217</th>\n",
       "      <td>98.50</td>\n",
       "      <td>98.8100</td>\n",
       "      <td>96.37</td>\n",
       "      <td>96.75</td>\n",
       "      <td>9551800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5216</th>\n",
       "      <td>96.75</td>\n",
       "      <td>96.8100</td>\n",
       "      <td>93.69</td>\n",
       "      <td>94.81</td>\n",
       "      <td>11105400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5215</th>\n",
       "      <td>95.87</td>\n",
       "      <td>95.9400</td>\n",
       "      <td>93.50</td>\n",
       "      <td>94.37</td>\n",
       "      <td>10369100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5214</th>\n",
       "      <td>94.44</td>\n",
       "      <td>94.4400</td>\n",
       "      <td>90.00</td>\n",
       "      <td>91.56</td>\n",
       "      <td>16697600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5213</th>\n",
       "      <td>92.75</td>\n",
       "      <td>92.9400</td>\n",
       "      <td>90.19</td>\n",
       "      <td>90.25</td>\n",
       "      <td>13737600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>125.90</td>\n",
       "      <td>129.4700</td>\n",
       "      <td>125.80</td>\n",
       "      <td>128.67</td>\n",
       "      <td>8195366.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>129.10</td>\n",
       "      <td>129.3700</td>\n",
       "      <td>127.15</td>\n",
       "      <td>127.33</td>\n",
       "      <td>4220136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>126.48</td>\n",
       "      <td>127.6459</td>\n",
       "      <td>125.50</td>\n",
       "      <td>125.79</td>\n",
       "      <td>3531076.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>124.86</td>\n",
       "      <td>126.3200</td>\n",
       "      <td>124.71</td>\n",
       "      <td>126.21</td>\n",
       "      <td>3733547.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>125.82</td>\n",
       "      <td>126.3400</td>\n",
       "      <td>124.15</td>\n",
       "      <td>124.47</td>\n",
       "      <td>4157538.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5218 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      1. open   2. high  3. low  4. close   5. volume\n",
       "5217    98.50   98.8100   96.37     96.75   9551800.0\n",
       "5216    96.75   96.8100   93.69     94.81  11105400.0\n",
       "5215    95.87   95.9400   93.50     94.37  10369100.0\n",
       "5214    94.44   94.4400   90.00     91.56  16697600.0\n",
       "5213    92.75   92.9400   90.19     90.25  13737600.0\n",
       "...       ...       ...     ...       ...         ...\n",
       "4      125.90  129.4700  125.80    128.67   8195366.0\n",
       "3      129.10  129.3700  127.15    127.33   4220136.0\n",
       "2      126.48  127.6459  125.50    125.79   3531076.0\n",
       "1      124.86  126.3200  124.71    126.21   3733547.0\n",
       "0      125.82  126.3400  124.15    124.47   4157538.0\n",
       "\n",
       "[5218 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(columns='date')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequence for the LSTM network\n",
    "backlook = 92\n",
    "\n",
    "# Days to predict\n",
    "days = 3\n",
    "\n",
    "# Size of data split for testing\n",
    "train_size = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = []\n",
    "\n",
    "for i in range(days):\n",
    "    index.append(np.arange(i,len(data),days))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_index = []\n",
    "\n",
    "for i in range(len(index[0]) - backlook):\n",
    "    for e in range(len(index)):\n",
    "        try: ordered_index.append(index[e][i:i+backlook])\n",
    "        except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise data\n",
    "normaliser = preprocessing.MinMaxScaler()\n",
    "data_norm = normaliser.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalised chunks\n",
    "historical_sequences_norm = np.array([data_norm[ix].copy() for ix in ordered_index])\n",
    "next_day_open_values_norm = np.array([data_norm[ordered_index[i+days][-1],0].copy() for i in range(len(ordered_index) - days)])\n",
    "next_day_open_values_norm = np.expand_dims(next_day_open_values_norm, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete those sequences that doesn't have a -th day in the results\n",
    "historical_sequences_norm = historical_sequences_norm[:next_day_open_values_norm.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4941, 92, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "historical_sequences_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4941, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_day_open_values_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25726373],\n",
       "       [0.2848877 ],\n",
       "       [0.29303801],\n",
       "       ...,\n",
       "       [0.46319915],\n",
       "       [0.44689853],\n",
       "       [0.43681951]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Y raw data\n",
    "next_day_open_values = np.array([data.to_numpy()[ordered_index[i+days][-1],0] for i in range(len(ordered_index) - days)])\n",
    "next_day_open_values = np.expand_dims(next_day_open_values, -1)\n",
    "\n",
    "# Y normaliser\n",
    "y_normaliser = preprocessing.MinMaxScaler()\n",
    "y_normaliser.fit_transform(next_day_open_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test split\n",
    "split = int(historical_sequences_norm.shape[0] * train_size)\n",
    "\n",
    "X_train = historical_sequences_norm[:split]\n",
    "Y_train = next_day_open_values_norm[:split]\n",
    "\n",
    "X_test = historical_sequences_norm[split:]\n",
    "Y_test = next_day_open_values_norm[split:]\n",
    "unscaled_y_test = next_day_open_values[split:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm(x, y, batch_size=512, epochs=24, **params):\n",
    "    \n",
    "    # List of parameters\n",
    "    if 'lstmsize' not in params: params['lstmsize'] = x.shape[1]\n",
    "    if 'density' not in params: params['density'] = int((params['lstmsize']//1.5)*2)\n",
    "    if 'activation' not in params: params['activation'] = 'relu'\n",
    "    if 'twice' not in params: params['twice'] = False\n",
    "    if 'optimizer' not in params: params['optimizer'] = 'adam'\n",
    "    if 'shuffle' not in params: params['shuffle'] = False\n",
    "    \n",
    "    # Model definition\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(params['lstmsize'], input_shape=x.shape[1:], return_sequences=params['twice']))\n",
    "    \n",
    "    if 'dropout' in params:\n",
    "        model.add(Dropout(params['dropout']))\n",
    "    \n",
    "    if params['twice']:\n",
    "        model.add(LSTM(params['lstmsize']))\n",
    "        \n",
    "        if 'dropout' in params:\n",
    "            model.add(Dropout(params['dropout']))\n",
    "            \n",
    "    model.add(Dense(params['density'], activation=params['activation']))\n",
    "    \n",
    "    if 'full_density' in params and params['full_density']:\n",
    "        density = params['density']//2\n",
    "        while density >= 12:\n",
    "            model.add(Dense(density, activation=params['activation']))\n",
    "            density //= 2\n",
    "            \n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    \n",
    "    model.compile(loss='mse', optimizer=params['optimizer'])\n",
    "    \n",
    "    if 'callbacks' in params:\n",
    "        callback = model.fit(x=x, y=y, validation_split=0.1, batch_size=batch_size, epochs=epochs, shuffle=params['shuffle'],\n",
    "                            callbacks=params['callbacks'])\n",
    "    else:\n",
    "        callback = model.fit(x=x, y=y, validation_split=0.1, batch_size=batch_size, epochs=epochs, shuffle=params['shuffle'])\n",
    "    \n",
    "    return [model, callback, params]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evolutive algorith to search for the most optimal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_genes(x, y, population_size, population=[]):\n",
    "    if population_size-len(population) < 0:\n",
    "        print('population size must be greater or equal than actual population')\n",
    "        return\n",
    "    \n",
    "    if len(population) > 0:\n",
    "        if len(population) < 3:\n",
    "            print('population should be empty or 3 at least')\n",
    "            return\n",
    "        \n",
    "        population[2] = breed_genes(x, y, population[0][2].copy())\n",
    "        population[1] = breed_genes(x, y, combine=(population[0][2], population[1][2]))\n",
    "        population = population[:3]\n",
    "    \n",
    "    for _ in range(population_size-len(population)):\n",
    "        subject = breed_genes(x, y)\n",
    "        population.append(subject)\n",
    "        \n",
    "    return population\n",
    "\n",
    "def breed_genes(x, y, genes={}, combine=None):\n",
    "    genes['x'] = x\n",
    "    genes['y'] = y\n",
    "    \n",
    "    if type(combine) is list or type(combine) is tuple:\n",
    "        genes['lstmsize'] = combine[np.random.randint(0,2)]['lstmsize']\n",
    "        genes['density'] = combine[np.random.randint(0,2)]['density']\n",
    "        genes['activation'] = combine[np.random.randint(0,2)]['activation']\n",
    "        genes['twice'] = combine[np.random.randint(0,2)]['twice']\n",
    "        genes['optimizer'] = combine[np.random.randint(0,2)]['optimizer']\n",
    "        genes['shuffle'] = combine[np.random.randint(0,2)]['shuffle']\n",
    "        \n",
    "        genes['dropout'] = combine[np.random.randint(0,2)].get('dropout')\n",
    "        if genes['dropout'] is None: del genes['dropout']\n",
    "        genes['full_density'] = combine[np.random.randint(0,2)].get('full_density')\n",
    "        if genes['full_density'] is None: del genes['full_density']\n",
    "            \n",
    "    else:\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['lstmsize'] = int((np.random.randint(x.shape[1],x.shape[1]*2)//2)*2)\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['density'] = int((np.random.randint(x.shape[1]//2,x.shape[1]*2.66)//2)*2)\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            activation = [\n",
    "                'relu',\n",
    "                'sigmoid',\n",
    "                'softplus',\n",
    "                'softsign',\n",
    "                'tanh',\n",
    "                'selu',\n",
    "                'elu',\n",
    "                'exponential'\n",
    "            ]\n",
    "            genes['activation'] = activation[np.random.randint(0,8)]\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['twice'] = True\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            optimizer = [\n",
    "                'sgd',\n",
    "                'rmsprop',\n",
    "                'adam',\n",
    "                'adadelta',\n",
    "                'adagrad',\n",
    "                'adamax',\n",
    "                'nadam'\n",
    "            ]\n",
    "            genes['optimizer'] = optimizer[np.random.randint(0,7)]\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['shuffle'] = True\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['dropout'] = np.random.randint(1,4)/10\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['full_density'] = True\n",
    "            \n",
    "    new_model = build_lstm(**genes)\n",
    "        \n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def breed_population(x, y, generations, population_size, population=[]):\n",
    "    \n",
    "    if generations > 1 and population_size < 3:\n",
    "        print('population size should be of a minimum of 3 for more than one generation')\n",
    "        return\n",
    "    \n",
    "    for g in range(generations):\n",
    "        print(f'\\nGENERATION {g}\\n')\n",
    "        population = set_genes(x, y, population_size, population)\n",
    "        population = sorted(population, key=lambda x: x[1].history['val_loss'][-1]+x[1].history['loss'][-1])\n",
    "        \n",
    "    return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GENERATION 0\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 1s 283us/step - loss: 0.0074 - val_loss: 0.0026\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 146us/step - loss: 0.0110 - val_loss: 0.0016\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 148us/step - loss: 0.0161 - val_loss: 0.0011\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 149us/step - loss: 0.0237 - val_loss: 0.0209\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 147us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 147us/step - loss: 0.0039 - val_loss: 9.9836e-04\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 147us/step - loss: 0.0040 - val_loss: 0.0018\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 147us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 152us/step - loss: 0.0010 - val_loss: 9.1365e-04\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 162us/step - loss: 7.4509e-04 - val_loss: 9.3748e-04\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 151us/step - loss: 7.3652e-04 - val_loss: 8.5519e-04\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 147us/step - loss: 7.7266e-04 - val_loss: 7.5397e-04\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 149us/step - loss: 7.0131e-04 - val_loss: 8.6671e-04\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 152us/step - loss: 6.9845e-04 - val_loss: 7.5179e-04\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 150us/step - loss: 6.6924e-04 - val_loss: 8.1302e-04\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 157us/step - loss: 6.7496e-04 - val_loss: 7.4689e-04\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 150us/step - loss: 6.5280e-04 - val_loss: 7.7779e-04\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 148us/step - loss: 6.5946e-04 - val_loss: 7.4396e-04\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 147us/step - loss: 6.4290e-04 - val_loss: 7.6115e-04\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 148us/step - loss: 6.5824e-04 - val_loss: 7.3419e-04\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 151us/step - loss: 6.4128e-04 - val_loss: 7.4797e-04\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 146us/step - loss: 6.7469e-04 - val_loss: 7.2492e-04\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 149us/step - loss: 6.6265e-04 - val_loss: 7.3234e-04\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 147us/step - loss: 7.5288e-04 - val_loss: 7.2042e-04\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 2s 570us/step - loss: 0.0239 - val_loss: 0.0187\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 380us/step - loss: 0.0169 - val_loss: 0.0326\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 370us/step - loss: 0.0396 - val_loss: 0.0017\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 373us/step - loss: 0.0306 - val_loss: 0.0043\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 380us/step - loss: 0.0555 - val_loss: 0.0216\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 376us/step - loss: 0.0129 - val_loss: 0.0027\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 381us/step - loss: 0.0299 - val_loss: 0.0112\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 371us/step - loss: 0.0058 - val_loss: 0.0098\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 375us/step - loss: 0.0060 - val_loss: 0.0026\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 369us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 368us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 368us/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 368us/step - loss: 0.0017 - val_loss: 0.0027\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 369us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 367us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 368us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 377us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 374us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 378us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 367us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 370us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 371us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 379us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 374us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 2s 589us/step - loss: 0.0917 - val_loss: 0.0204\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 383us/step - loss: 0.0213 - val_loss: 0.0055\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 388us/step - loss: 0.0095 - val_loss: 0.0022\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 386us/step - loss: 0.0070 - val_loss: 0.0017\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 384us/step - loss: 0.0051 - val_loss: 0.0021\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 383us/step - loss: 0.0043 - val_loss: 0.0015\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 382us/step - loss: 0.0039 - val_loss: 0.0019\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 384us/step - loss: 0.0035 - val_loss: 0.0014\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 384us/step - loss: 0.0031 - val_loss: 0.0016\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 384us/step - loss: 0.0032 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 385us/step - loss: 0.0031 - val_loss: 0.0015\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 382us/step - loss: 0.0031 - val_loss: 0.0015\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 390us/step - loss: 0.0029 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 385us/step - loss: 0.0028 - val_loss: 0.0014\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 397us/step - loss: 0.0028 - val_loss: 0.0013\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 385us/step - loss: 0.0027 - val_loss: 0.0014\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 389us/step - loss: 0.0026 - val_loss: 0.0014\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 388us/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 387us/step - loss: 0.0026 - val_loss: 0.0013\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 387us/step - loss: 0.0025 - val_loss: 0.0012\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 390us/step - loss: 0.0025 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 386us/step - loss: 0.0024 - val_loss: 0.0012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 388us/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 386us/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 2s 635us/step - loss: 0.0680 - val_loss: 0.0465\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 396us/step - loss: 0.0190 - val_loss: 0.0239\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 409us/step - loss: 0.0091 - val_loss: 0.0068\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 425us/step - loss: 0.0065 - val_loss: 0.0064\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 411us/step - loss: 0.0049 - val_loss: 0.0017\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 389us/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 386us/step - loss: 0.0037 - val_loss: 0.0016\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 397us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 390us/step - loss: 0.0031 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 389us/step - loss: 0.0033 - val_loss: 0.0019\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 392us/step - loss: 0.0031 - val_loss: 0.0015\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 401us/step - loss: 0.0031 - val_loss: 0.0017\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 392us/step - loss: 0.0029 - val_loss: 0.0015\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 391us/step - loss: 0.0028 - val_loss: 0.0014\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 390us/step - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 397us/step - loss: 0.0027 - val_loss: 0.0014\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 390us/step - loss: 0.0027 - val_loss: 0.0014\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 388us/step - loss: 0.0026 - val_loss: 0.0014\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 384us/step - loss: 0.0025 - val_loss: 0.0014\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 387us/step - loss: 0.0024 - val_loss: 0.0013\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 386us/step - loss: 0.0023 - val_loss: 0.0013\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 388us/step - loss: 0.0024 - val_loss: 0.0013\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 399us/step - loss: 0.0023 - val_loss: 0.0013\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 394us/step - loss: 0.0023 - val_loss: 0.0013\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 2s 627us/step - loss: 0.1044 - val_loss: 0.0021\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 401us/step - loss: 0.0058 - val_loss: 0.0054\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 394us/step - loss: 0.0100 - val_loss: 0.0049\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 392us/step - loss: 0.0113 - val_loss: 0.0124\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 395us/step - loss: 0.0098 - val_loss: 0.0098\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 411us/step - loss: 0.0109 - val_loss: 0.0101\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 391us/step - loss: 0.0104 - val_loss: 0.0045\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 386us/step - loss: 0.0089 - val_loss: 0.0077\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 388us/step - loss: 0.0082 - val_loss: 0.0108\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 390us/step - loss: 0.0114 - val_loss: 0.0067\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 387us/step - loss: 0.0050 - val_loss: 0.0139\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 392us/step - loss: 0.0107 - val_loss: 0.0069\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 385us/step - loss: 0.0068 - val_loss: 0.0048\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 386us/step - loss: 0.0066 - val_loss: 0.0119\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 386us/step - loss: 0.0087 - val_loss: 0.0038\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 385us/step - loss: 0.0061 - val_loss: 0.0073\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 387us/step - loss: 0.0079 - val_loss: 0.0075\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 388us/step - loss: 0.0056 - val_loss: 0.0077\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 385us/step - loss: 0.0069 - val_loss: 0.0072\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 384us/step - loss: 0.0049 - val_loss: 0.0040\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 391us/step - loss: 0.0053 - val_loss: 0.0055\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 384us/step - loss: 0.0065 - val_loss: 0.0069\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 385us/step - loss: 0.0044 - val_loss: 0.0037\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 387us/step - loss: 0.0058 - val_loss: 0.0082\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 2s 648us/step - loss: 0.1844 - val_loss: 0.0020\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 387us/step - loss: 0.0069 - val_loss: 0.0021\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 387us/step - loss: 0.0068 - val_loss: 0.0131\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 387us/step - loss: 0.0105 - val_loss: 0.0085\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 387us/step - loss: 0.0119 - val_loss: 0.0187\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 387us/step - loss: 0.0131 - val_loss: 0.0131\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 392us/step - loss: 0.0120 - val_loss: 0.0197\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 394us/step - loss: 0.0139 - val_loss: 0.0066\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 389us/step - loss: 0.0109 - val_loss: 0.0232\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 388us/step - loss: 0.0141 - val_loss: 0.0094\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 389us/step - loss: 0.0091 - val_loss: 0.0104\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 389us/step - loss: 0.0098 - val_loss: 0.0145\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 385us/step - loss: 0.0122 - val_loss: 0.0092\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 387us/step - loss: 0.0064 - val_loss: 0.0067\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 387us/step - loss: 0.0111 - val_loss: 0.0195\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 385us/step - loss: 0.0074 - val_loss: 0.0022\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 388us/step - loss: 0.0073 - val_loss: 0.0152\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 390us/step - loss: 0.0098 - val_loss: 0.0023\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 387us/step - loss: 0.0055 - val_loss: 0.0082\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 388us/step - loss: 0.0078 - val_loss: 0.0121\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 386us/step - loss: 0.0078 - val_loss: 0.0080\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 388us/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 389us/step - loss: 0.0073 - val_loss: 0.0149\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 388us/step - loss: 0.0081 - val_loss: 0.0013\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 3s 781us/step - loss: 0.4528 - val_loss: 0.0024\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 505us/step - loss: 0.0073 - val_loss: 0.0056\n",
      "Epoch 3/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3556/3556 [==============================] - 2s 515us/step - loss: 0.0152 - val_loss: 0.0170\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 504us/step - loss: 0.0115 - val_loss: 0.0185\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 2s 503us/step - loss: 0.0128 - val_loss: 0.0276\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 2s 503us/step - loss: 0.0171 - val_loss: 0.0128\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 503us/step - loss: 0.0172 - val_loss: 0.0203\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 505us/step - loss: 0.0157 - val_loss: 0.0094\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 2s 508us/step - loss: 0.0149 - val_loss: 0.0245\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 2s 507us/step - loss: 0.0160 - val_loss: 0.0259\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 2s 502us/step - loss: 0.0175 - val_loss: 0.0270\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 509us/step - loss: 0.0152 - val_loss: 0.0226\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 504us/step - loss: 0.0143 - val_loss: 0.0167\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 2s 505us/step - loss: 0.0083 - val_loss: 0.0139\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 2s 503us/step - loss: 0.0145 - val_loss: 0.0314\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 2s 503us/step - loss: 0.0207 - val_loss: 0.0017\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 2s 504us/step - loss: 0.0029 - val_loss: 0.0150\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 503us/step - loss: 0.0088 - val_loss: 0.0091\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 2s 506us/step - loss: 0.0105 - val_loss: 0.0215\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 2s 509us/step - loss: 0.0120 - val_loss: 0.0018\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 2s 507us/step - loss: 0.0041 - val_loss: 0.0227\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 2s 502us/step - loss: 0.0113 - val_loss: 0.0210\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 2s 503us/step - loss: 0.0082 - val_loss: 0.0071\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 2s 505us/step - loss: 0.0065 - val_loss: 0.0053\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 3s 799us/step - loss: 0.3025 - val_loss: 0.0023\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 502us/step - loss: 0.0080 - val_loss: 0.0122\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 2s 503us/step - loss: 0.0123 - val_loss: 0.0050\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 507us/step - loss: 0.0125 - val_loss: 0.0278\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 2s 506us/step - loss: 0.0127 - val_loss: 0.0127\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 2s 502us/step - loss: 0.0149 - val_loss: 0.0280\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 505us/step - loss: 0.0126 - val_loss: 0.0169\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 505us/step - loss: 0.0168 - val_loss: 0.0181\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 2s 503us/step - loss: 0.0161 - val_loss: 0.0172\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 2s 509us/step - loss: 0.0164 - val_loss: 0.0105\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 2s 505us/step - loss: 0.0077 - val_loss: 0.0244\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 502us/step - loss: 0.0227 - val_loss: 0.0309\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 508us/step - loss: 0.0062 - val_loss: 0.0028\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 2s 505us/step - loss: 0.0032 - val_loss: 0.0196\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 2s 505us/step - loss: 0.0208 - val_loss: 0.0190\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 2s 506us/step - loss: 0.0044 - val_loss: 0.0017\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 2s 505us/step - loss: 0.0088 - val_loss: 0.0154\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 505us/step - loss: 0.0109 - val_loss: 0.0249\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 2s 503us/step - loss: 0.0110 - val_loss: 0.0060\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 2s 503us/step - loss: 0.0036 - val_loss: 0.0064\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 2s 504us/step - loss: 0.0090 - val_loss: 0.0241\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 2s 510us/step - loss: 0.0089 - val_loss: 0.0033\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 2s 522us/step - loss: 0.0046 - val_loss: 0.0079\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 2s 525us/step - loss: 0.0087 - val_loss: 0.0252\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 3s 704us/step - loss: 0.1285 - val_loss: 0.0023\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 371us/step - loss: 0.0076 - val_loss: 0.0778\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 370us/step - loss: 0.0176 - val_loss: 0.0258\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 369us/step - loss: 0.0164 - val_loss: 0.0121\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 369us/step - loss: 0.0169 - val_loss: 0.0141\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 377us/step - loss: 0.0118 - val_loss: 0.0138\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 368us/step - loss: 0.0134 - val_loss: 0.0254\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 367us/step - loss: 0.0156 - val_loss: 0.0125\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 368us/step - loss: 0.0095 - val_loss: 0.0150\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 371us/step - loss: 0.0110 - val_loss: 0.0354\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 375us/step - loss: 0.0151 - val_loss: 0.0106\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 370us/step - loss: 0.0061 - val_loss: 0.0088\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 371us/step - loss: 0.0109 - val_loss: 0.0108\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 371us/step - loss: 0.0098 - val_loss: 0.0046\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 369us/step - loss: 0.0072 - val_loss: 0.0103\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 369us/step - loss: 0.0076 - val_loss: 0.0144\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 369us/step - loss: 0.0120 - val_loss: 0.0053\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 376us/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 370us/step - loss: 0.0108 - val_loss: 0.0180\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 375us/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 372us/step - loss: 0.0093 - val_loss: 0.0299\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 370us/step - loss: 0.0067 - val_loss: 0.0013\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 369us/step - loss: 0.0036 - val_loss: 0.0123\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 378us/step - loss: 0.0090 - val_loss: 0.0017\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 2s 696us/step - loss: 0.1791 - val_loss: 0.0143\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 370us/step - loss: 0.0156 - val_loss: 0.0044\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 371us/step - loss: 0.0146 - val_loss: 0.0031\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 377us/step - loss: 0.0054 - val_loss: 0.0279\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 372us/step - loss: 0.0174 - val_loss: 0.0111\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 373us/step - loss: 0.0156 - val_loss: 0.0085\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 373us/step - loss: 0.0118 - val_loss: 0.0121\n",
      "Epoch 8/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3556/3556 [==============================] - 1s 368us/step - loss: 0.0151 - val_loss: 0.0139\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 367us/step - loss: 0.0106 - val_loss: 0.0178\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 369us/step - loss: 0.0116 - val_loss: 0.0180\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 368us/step - loss: 0.0116 - val_loss: 0.0145\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 367us/step - loss: 0.0092 - val_loss: 0.0130\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 369us/step - loss: 0.0101 - val_loss: 0.0182\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 368us/step - loss: 0.0097 - val_loss: 0.0117\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 367us/step - loss: 0.0098 - val_loss: 0.0138\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 375us/step - loss: 0.0086 - val_loss: 0.0071\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 368us/step - loss: 0.0092 - val_loss: 0.0127\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 369us/step - loss: 0.0067 - val_loss: 0.0116\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 369us/step - loss: 0.0076 - val_loss: 0.0088\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 374us/step - loss: 0.0089 - val_loss: 0.0043\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 368us/step - loss: 0.0063 - val_loss: 0.0135\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 369us/step - loss: 0.0064 - val_loss: 0.0101\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 369us/step - loss: 0.0073 - val_loss: 0.0174\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 369us/step - loss: 0.0064 - val_loss: 0.0098\n",
      "\n",
      "GENERATION 1\n",
      "\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 2s 427us/step - loss: 0.3755 - val_loss: 0.1372\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 182us/step - loss: 0.1092 - val_loss: 0.0106\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 185us/step - loss: 0.0220 - val_loss: 0.0035\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 192us/step - loss: 0.0120 - val_loss: 0.0019\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 183us/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 183us/step - loss: 0.0027 - val_loss: 0.0013\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 185us/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 184us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 183us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 183us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 184us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 183us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 183us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 184us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 185us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 185us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 184us/step - loss: 0.0011 - val_loss: 9.8705e-04\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 182us/step - loss: 0.0010 - val_loss: 9.4297e-04\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 185us/step - loss: 0.0010 - val_loss: 9.8827e-04\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 184us/step - loss: 9.7760e-04 - val_loss: 8.9247e-04\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 184us/step - loss: 9.5505e-04 - val_loss: 9.8317e-04\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 186us/step - loss: 9.3338e-04 - val_loss: 9.2217e-04\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 183us/step - loss: 9.1246e-04 - val_loss: 8.7980e-04\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 185us/step - loss: 8.8964e-04 - val_loss: 8.6437e-04\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 2s 444us/step - loss: 0.0274 - val_loss: 0.0013\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 177us/step - loss: 0.0093 - val_loss: 0.0039\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 176us/step - loss: 0.0173 - val_loss: 0.0032\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 176us/step - loss: 0.0475 - val_loss: 0.0170\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 177us/step - loss: 0.0121 - val_loss: 0.0128\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 185us/step - loss: 0.0093 - val_loss: 0.0064\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 180us/step - loss: 0.0012 - val_loss: 8.6717e-04\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 178us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 176us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 178us/step - loss: 7.8593e-04 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 178us/step - loss: 6.8854e-04 - val_loss: 7.5865e-04\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 177us/step - loss: 7.3751e-04 - val_loss: 6.3536e-04\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 178us/step - loss: 6.4504e-04 - val_loss: 8.7821e-04\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 177us/step - loss: 6.2998e-04 - val_loss: 6.4186e-04\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 179us/step - loss: 5.8990e-04 - val_loss: 7.2078e-04\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 178us/step - loss: 5.9142e-04 - val_loss: 6.8602e-04\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 178us/step - loss: 5.9007e-04 - val_loss: 6.7207e-04\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 177us/step - loss: 5.8245e-04 - val_loss: 6.9558e-04\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 178us/step - loss: 5.8458e-04 - val_loss: 6.6063e-04\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 176us/step - loss: 5.7576e-04 - val_loss: 6.8266e-04\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 179us/step - loss: 5.7841e-04 - val_loss: 6.5313e-04\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 178us/step - loss: 5.6972e-04 - val_loss: 6.6955e-04\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 178us/step - loss: 5.7338e-04 - val_loss: 6.4486e-04\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 176us/step - loss: 5.6449e-04 - val_loss: 6.5924e-04\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 3s 704us/step - loss: 0.5488 - val_loss: 0.0079\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 367us/step - loss: 0.0139 - val_loss: 0.0490\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 367us/step - loss: 0.0263 - val_loss: 0.1577\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 368us/step - loss: 0.0228 - val_loss: 0.0746\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 369us/step - loss: 0.0235 - val_loss: 0.2297\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 369us/step - loss: 0.0248 - val_loss: 0.0061\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 366us/step - loss: 0.0105 - val_loss: 0.2773\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 366us/step - loss: 0.0296 - val_loss: 0.0172\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 368us/step - loss: 0.0046 - val_loss: 0.0829\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 372us/step - loss: 0.0189 - val_loss: 0.1427\n",
      "Epoch 11/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3556/3556 [==============================] - 1s 370us/step - loss: 0.0350 - val_loss: 0.1105\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 374us/step - loss: 0.0168 - val_loss: 0.0090\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 369us/step - loss: 0.0160 - val_loss: 0.0071\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 367us/step - loss: 0.0173 - val_loss: 0.0118\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 367us/step - loss: 0.0170 - val_loss: 0.0104\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 366us/step - loss: 0.0175 - val_loss: 0.0085\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 367us/step - loss: 0.0178 - val_loss: 0.0067\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 367us/step - loss: 0.0185 - val_loss: 0.0073\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 367us/step - loss: 0.0181 - val_loss: 0.0062\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 368us/step - loss: 0.0178 - val_loss: 0.0053\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 365us/step - loss: 0.0176 - val_loss: 0.0047\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 368us/step - loss: 0.0176 - val_loss: 0.0053\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 373us/step - loss: 0.0171 - val_loss: 0.0050\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 368us/step - loss: 0.0166 - val_loss: 0.0049\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 3s 855us/step - loss: 1.8385 - val_loss: 0.0213\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 510us/step - loss: 0.1093 - val_loss: 0.0968\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 2s 507us/step - loss: 0.0496 - val_loss: 0.0837\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 507us/step - loss: 0.1054 - val_loss: 0.4387\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 2s 507us/step - loss: 0.1070 - val_loss: 0.0436\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 2s 515us/step - loss: 0.0925 - val_loss: 0.2363\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 507us/step - loss: 0.0620 - val_loss: 0.0037\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 506us/step - loss: 0.0880 - val_loss: 0.2253\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 2s 508us/step - loss: 0.0514 - val_loss: 0.0041\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 2s 508us/step - loss: 0.0726 - val_loss: 0.0955\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 2s 507us/step - loss: 0.0306 - val_loss: 0.0070\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 509us/step - loss: 0.0832 - val_loss: 0.0580\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 512us/step - loss: 0.0240 - val_loss: 0.0081\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 2s 511us/step - loss: 0.0750 - val_loss: 0.0278\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 2s 510us/step - loss: 0.0338 - val_loss: 0.0238\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 2s 507us/step - loss: 0.0528 - val_loss: 0.0215\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 2s 508us/step - loss: 0.0412 - val_loss: 0.0079\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 507us/step - loss: 0.0495 - val_loss: 0.0102\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 2s 507us/step - loss: 0.0368 - val_loss: 0.0083\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 2s 507us/step - loss: 0.0393 - val_loss: 0.0083\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 2s 508us/step - loss: 0.0371 - val_loss: 0.0104\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 2s 507us/step - loss: 0.0418 - val_loss: 0.0088\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 2s 512us/step - loss: 0.0340 - val_loss: 0.0054\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 2s 513us/step - loss: 0.0313 - val_loss: 0.0080\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 3s 899us/step - loss: 0.0869 - val_loss: 0.0068\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 509us/step - loss: 0.0478 - val_loss: 0.0510\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 2s 509us/step - loss: 0.0805 - val_loss: 0.0510\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 507us/step - loss: 0.0748 - val_loss: 0.0541\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 2s 508us/step - loss: 0.0644 - val_loss: 0.0357\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 2s 509us/step - loss: 0.0492 - val_loss: 0.0060\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 511us/step - loss: 0.0287 - val_loss: 0.0345\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 507us/step - loss: 0.0333 - val_loss: 0.0273\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 2s 509us/step - loss: 0.0274 - val_loss: 0.0150\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 2s 512us/step - loss: 0.0180 - val_loss: 0.0170\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 2s 513us/step - loss: 0.0171 - val_loss: 0.0212\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 507us/step - loss: 0.0163 - val_loss: 0.0223\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 515us/step - loss: 0.0166 - val_loss: 0.0243\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 2s 511us/step - loss: 0.0175 - val_loss: 0.0265\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 2s 512us/step - loss: 0.0167 - val_loss: 0.0181\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 2s 508us/step - loss: 0.0162 - val_loss: 0.0251\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 2s 508us/step - loss: 0.0144 - val_loss: 0.0256\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 510us/step - loss: 0.0139 - val_loss: 0.0290\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 2s 509us/step - loss: 0.0224 - val_loss: 0.0442\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 2s 508us/step - loss: 0.0148 - val_loss: 0.0296\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 2s 509us/step - loss: 0.0101 - val_loss: 0.0238\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 2s 508us/step - loss: 0.0079 - val_loss: 0.0265\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 2s 507us/step - loss: 0.0195 - val_loss: 0.0411\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 2s 511us/step - loss: 0.0131 - val_loss: 0.0312\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 3s 910us/step - loss: 0.1211 - val_loss: 0.0170\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 508us/step - loss: 0.0872 - val_loss: 0.0089\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 2s 515us/step - loss: 0.0664 - val_loss: 0.0109\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 508us/step - loss: 0.0499 - val_loss: 0.0141\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 2s 507us/step - loss: 0.0355 - val_loss: 0.0234\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 2s 507us/step - loss: 0.0297 - val_loss: 0.0290\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 512us/step - loss: 0.0234 - val_loss: 0.0351\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 510us/step - loss: 0.0179 - val_loss: 0.0383\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 2s 508us/step - loss: 0.0141 - val_loss: 0.0390\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 2s 507us/step - loss: 0.0103 - val_loss: 0.0391\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 2s 507us/step - loss: 0.0073 - val_loss: 0.0302\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 509us/step - loss: 0.0060 - val_loss: 0.0570\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 511us/step - loss: 0.0068 - val_loss: 0.0445\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 2s 506us/step - loss: 0.0081 - val_loss: 0.0667\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 2s 511us/step - loss: 0.0198 - val_loss: 0.0196\n",
      "Epoch 16/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3556/3556 [==============================] - 2s 512us/step - loss: 0.0094 - val_loss: 0.0110\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 2s 508us/step - loss: 0.0048 - val_loss: 0.0079\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 508us/step - loss: 0.0044 - val_loss: 0.0181\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 2s 509us/step - loss: 0.0063 - val_loss: 0.0585\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 2s 513us/step - loss: 0.0066 - val_loss: 0.0028\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 2s 508us/step - loss: 0.0050 - val_loss: 0.0552\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 2s 507us/step - loss: 0.0126 - val_loss: 0.0639\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 2s 506us/step - loss: 0.0077 - val_loss: 0.0058\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 2s 511us/step - loss: 0.0041 - val_loss: 0.0359\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 3s 902us/step - loss: 0.1693 - val_loss: 0.0135\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 483us/step - loss: 0.1016 - val_loss: 0.0063\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 2s 484us/step - loss: 0.0885 - val_loss: 0.0066\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 485us/step - loss: 0.0859 - val_loss: 0.0068\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 2s 482us/step - loss: 0.0847 - val_loss: 0.0069\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 2s 482us/step - loss: 0.0832 - val_loss: 0.0069\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 488us/step - loss: 0.0803 - val_loss: 0.0066\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 485us/step - loss: 0.0768 - val_loss: 0.0063\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 2s 482us/step - loss: 0.0850 - val_loss: 0.0084\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 2s 484us/step - loss: 0.0389 - val_loss: 0.0133\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 2s 487us/step - loss: 0.0268 - val_loss: 0.0226\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 483us/step - loss: 0.0180 - val_loss: 0.0375\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 482us/step - loss: 0.0132 - val_loss: 0.0415\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 2s 482us/step - loss: 0.0082 - val_loss: 0.0305\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 2s 480us/step - loss: 0.0058 - val_loss: 0.0594\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 2s 481us/step - loss: 0.0191 - val_loss: 0.0146\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 2s 486us/step - loss: 0.0163 - val_loss: 0.0103\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 482us/step - loss: 0.0071 - val_loss: 0.0068\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 2s 482us/step - loss: 0.0050 - val_loss: 0.0088\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 2s 482us/step - loss: 0.0066 - val_loss: 0.0459\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 2s 484us/step - loss: 0.0067 - val_loss: 0.0235\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 2s 484us/step - loss: 0.0096 - val_loss: 0.0623\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 2s 484us/step - loss: 0.0111 - val_loss: 0.0029\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 2s 485us/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 3s 917us/step - loss: 1.1512 - val_loss: 0.0620\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 488us/step - loss: 0.1790 - val_loss: 0.0081\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 2s 485us/step - loss: 0.1088 - val_loss: 0.0080\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 484us/step - loss: 0.0888 - val_loss: 0.0130\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 2s 483us/step - loss: 0.0823 - val_loss: 0.0163\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 2s 482us/step - loss: 0.0802 - val_loss: 0.0175\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 482us/step - loss: 0.0796 - val_loss: 0.0179\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 483us/step - loss: 0.0794 - val_loss: 0.0178\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 2s 486us/step - loss: 0.0795 - val_loss: 0.0179\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 2s 483us/step - loss: 0.0795 - val_loss: 0.0179\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 2s 485us/step - loss: 0.0795 - val_loss: 0.0180\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 483us/step - loss: 0.0795 - val_loss: 0.0181\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 484us/step - loss: 0.0794 - val_loss: 0.0182\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 2s 482us/step - loss: 0.0793 - val_loss: 0.0182\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 2s 484us/step - loss: 0.0792 - val_loss: 0.0183\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 2s 482us/step - loss: 0.0792 - val_loss: 0.0183\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 2s 481us/step - loss: 0.0792 - val_loss: 0.0184\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 487us/step - loss: 0.0792 - val_loss: 0.0185\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 2s 485us/step - loss: 0.0792 - val_loss: 0.0186\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 2s 482us/step - loss: 0.0789 - val_loss: 0.0186\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 2s 484us/step - loss: 0.0790 - val_loss: 0.0187\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 2s 483us/step - loss: 0.0789 - val_loss: 0.0187\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 2s 482us/step - loss: 0.0790 - val_loss: 0.0188\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 2s 482us/step - loss: 0.0788 - val_loss: 0.0188\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 3s 940us/step - loss: 0.0982 - val_loss: 0.2864\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 483us/step - loss: 0.0169 - val_loss: 0.0110\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 2s 484us/step - loss: 0.0057 - val_loss: 0.0882\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 482us/step - loss: 0.0294 - val_loss: 0.1193\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 2s 481us/step - loss: 0.0718 - val_loss: 0.1127\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 2s 483us/step - loss: 0.0270 - val_loss: 0.0124\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 482us/step - loss: 0.0183 - val_loss: 0.0073\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 484us/step - loss: 0.0123 - val_loss: 0.0159\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 2s 482us/step - loss: 0.0123 - val_loss: 0.0186\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 2s 492us/step - loss: 0.0131 - val_loss: 0.0189\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 2s 482us/step - loss: 0.0143 - val_loss: 0.0234\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 483us/step - loss: 0.0175 - val_loss: 0.0331\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 482us/step - loss: 0.0173 - val_loss: 0.0248\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 2s 482us/step - loss: 0.0126 - val_loss: 0.0064\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 2s 484us/step - loss: 0.0128 - val_loss: 0.0115\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 2s 488us/step - loss: 0.0116 - val_loss: 0.0099\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 2s 487us/step - loss: 0.0119 - val_loss: 0.0121\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 482us/step - loss: 0.0146 - val_loss: 0.0232\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 2s 487us/step - loss: 0.0124 - val_loss: 0.0098\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 2s 484us/step - loss: 0.0099 - val_loss: 0.0034\n",
      "Epoch 21/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3556/3556 [==============================] - 2s 485us/step - loss: 0.0103 - val_loss: 0.0082\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 2s 483us/step - loss: 0.0093 - val_loss: 0.0066\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 2s 484us/step - loss: 0.0104 - val_loss: 0.0082\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 2s 481us/step - loss: 0.0116 - val_loss: 0.0133\n",
      "\n",
      "GENERATION 2\n",
      "\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 2s 572us/step - loss: 2.0298 - val_loss: 0.6177\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 183us/step - loss: 0.5276 - val_loss: 0.1076\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 181us/step - loss: 0.1629 - val_loss: 0.0079\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 179us/step - loss: 0.0736 - val_loss: 0.0059\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 181us/step - loss: 0.0204 - val_loss: 0.0031\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 182us/step - loss: 0.0107 - val_loss: 0.0040\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 178us/step - loss: 0.0113 - val_loss: 0.0049\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 178us/step - loss: 0.0075 - val_loss: 0.0018\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 177us/step - loss: 0.0063 - val_loss: 0.0020\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 179us/step - loss: 0.0062 - val_loss: 0.0016\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 179us/step - loss: 0.0056 - val_loss: 0.0019\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 178us/step - loss: 0.0049 - val_loss: 0.0017\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 179us/step - loss: 0.0048 - val_loss: 0.0019\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 177us/step - loss: 0.0046 - val_loss: 0.0018\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 178us/step - loss: 0.0046 - val_loss: 0.0019\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 177us/step - loss: 0.0043 - val_loss: 0.0016\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 179us/step - loss: 0.0041 - val_loss: 0.0019\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 177us/step - loss: 0.0041 - val_loss: 0.0018\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 178us/step - loss: 0.0041 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 179us/step - loss: 0.0039 - val_loss: 0.0018\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 178us/step - loss: 0.0037 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 178us/step - loss: 0.0037 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 177us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 179us/step - loss: 0.0035 - val_loss: 0.0015\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 2s 548us/step - loss: 0.0182 - val_loss: 0.0027\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 148us/step - loss: 0.0042 - val_loss: 0.0052\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 147us/step - loss: 0.0063 - val_loss: 0.0087\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 147us/step - loss: 0.0257 - val_loss: 0.0021\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 147us/step - loss: 0.0385 - val_loss: 0.0086\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 146us/step - loss: 0.0404 - val_loss: 0.0361\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 148us/step - loss: 0.0025 - val_loss: 0.0043\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 147us/step - loss: 0.0072 - val_loss: 0.0047\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 147us/step - loss: 0.0044 - val_loss: 0.0028\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 147us/step - loss: 9.7250e-04 - val_loss: 0.0017\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 148us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 148us/step - loss: 0.0010 - val_loss: 7.4266e-04\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 148us/step - loss: 8.5423e-04 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 149us/step - loss: 8.5612e-04 - val_loss: 0.0014\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 147us/step - loss: 8.0468e-04 - val_loss: 8.5423e-04\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 148us/step - loss: 7.4932e-04 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 148us/step - loss: 7.4705e-04 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 148us/step - loss: 7.4327e-04 - val_loss: 9.2506e-04\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 148us/step - loss: 7.1874e-04 - val_loss: 0.0010\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 148us/step - loss: 7.1374e-04 - val_loss: 9.7181e-04\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 149us/step - loss: 7.0589e-04 - val_loss: 9.4147e-04\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 151us/step - loss: 6.9457e-04 - val_loss: 9.6155e-04\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 153us/step - loss: 6.8862e-04 - val_loss: 9.1591e-04\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 149us/step - loss: 6.7934e-04 - val_loss: 9.1736e-04\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 3s 788us/step - loss: 2.7732 - val_loss: 0.0210\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 298us/step - loss: 0.0116 - val_loss: 0.0024\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 297us/step - loss: 0.0047 - val_loss: 0.0035\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 297us/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 296us/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 297us/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 297us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 298us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 297us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 297us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 297us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 297us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 295us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 303us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 297us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 298us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 296us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 298us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 296us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 297us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 296us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 298us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 300us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 300us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3556/3556 [==============================] - 3s 824us/step - loss: 7.0927 - val_loss: 0.0018\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 298us/step - loss: 0.0045 - val_loss: 0.0030\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 298us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 299us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 299us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 297us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 298us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 299us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 297us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 298us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 296us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 298us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 298us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 297us/step - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 302us/step - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 303us/step - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 299us/step - loss: 0.0017 - val_loss: 0.0034\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 298us/step - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 299us/step - loss: 0.0016 - val_loss: 0.0034\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 298us/step - loss: 0.0016 - val_loss: 0.0034\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 298us/step - loss: 0.0016 - val_loss: 0.0031\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 299us/step - loss: 0.0016 - val_loss: 0.0033\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 307us/step - loss: 0.0016 - val_loss: 0.0033\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 298us/step - loss: 0.0015 - val_loss: 0.0033\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 3s 800us/step - loss: 0.4896 - val_loss: 0.0260\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 305us/step - loss: 0.0189 - val_loss: 0.0031\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 298us/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 301us/step - loss: 0.0052 - val_loss: 0.0106\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 298us/step - loss: 0.0067 - val_loss: 0.0042\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 299us/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 298us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 297us/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 297us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 298us/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 296us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 298us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 297us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 296us/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 296us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 298us/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 303us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 296us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 298us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 297us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 297us/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 302us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 301us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 298us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 3s 822us/step - loss: 0.1052 - val_loss: 0.0112\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 297us/step - loss: 0.0292 - val_loss: 0.0084\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 301us/step - loss: 0.0188 - val_loss: 0.0049\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 298us/step - loss: 0.0121 - val_loss: 0.0037\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 296us/step - loss: 0.0079 - val_loss: 0.0028\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 295us/step - loss: 0.0054 - val_loss: 0.0026\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 296us/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 294us/step - loss: 0.0031 - val_loss: 0.0026\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 296us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 296us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 295us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 294us/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 297us/step - loss: 0.0022 - val_loss: 0.0032\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 295us/step - loss: 0.0021 - val_loss: 0.0031\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 296us/step - loss: 0.0021 - val_loss: 0.0031\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 297us/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 296us/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 301us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 300us/step - loss: 0.0021 - val_loss: 0.0031\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 295us/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 299us/step - loss: 0.0021 - val_loss: 0.0031\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 305us/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 296us/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 297us/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 3s 858us/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 311us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 312us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 314us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 312us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3556/3556 [==============================] - 1s 308us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 309us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 309us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 308us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 310us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 310us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 309us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 309us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 310us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 310us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 308us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 310us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 311us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 315us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 313us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 314us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 311us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 309us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 309us/step - loss: nan - val_loss: nan\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 3s 898us/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 314us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 311us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 319us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 313us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 314us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 312us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 312us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 311us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 313us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 312us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 312us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 313us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 311us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 314us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 312us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 312us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 324us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 318us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 312us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 310us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 313us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 313us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 312us/step - loss: nan - val_loss: nan\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 3s 915us/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 310us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 313us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 315us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 310us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 313us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 310us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 312us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 312us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 312us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 311us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 309us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 312us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 311us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 312us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 321us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 311us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 319us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 312us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 310us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 311us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 313us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 309us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 310us/step - loss: nan - val_loss: nan\n",
      "\n",
      "GENERATION 3\n",
      "\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 3s 895us/step - loss: 0.0756 - val_loss: 0.0057\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 303us/step - loss: 0.0300 - val_loss: 0.0078\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 305us/step - loss: 0.0227 - val_loss: 0.0068\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 307us/step - loss: 0.0160 - val_loss: 0.0060\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 303us/step - loss: 0.0115 - val_loss: 0.0054\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 302us/step - loss: 0.0084 - val_loss: 0.0050\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 302us/step - loss: 0.0063 - val_loss: 0.0047\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 302us/step - loss: 0.0049 - val_loss: 0.0044\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 315us/step - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 302us/step - loss: 0.0034 - val_loss: 0.0041\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 301us/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 304us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 302us/step - loss: 0.0025 - val_loss: 0.0038\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 310us/step - loss: 0.0024 - val_loss: 0.0037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 302us/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 301us/step - loss: 0.0023 - val_loss: 0.0036\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 303us/step - loss: 0.0023 - val_loss: 0.0036\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 309us/step - loss: 0.0022 - val_loss: 0.0036\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 301us/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 303us/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 301us/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 302us/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 305us/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 303us/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 3s 705us/step - loss: 0.0156 - val_loss: 0.0067\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 150us/step - loss: 0.0074 - val_loss: 0.0033\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 149us/step - loss: 0.0115 - val_loss: 0.0039\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 149us/step - loss: 0.0418 - val_loss: 0.0092\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 149us/step - loss: 0.0191 - val_loss: 0.0175\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 150us/step - loss: 0.0098 - val_loss: 0.0084\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 151us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 155us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 151us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 149us/step - loss: 8.6830e-04 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 150us/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 149us/step - loss: 8.6957e-04 - val_loss: 7.5890e-04\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 149us/step - loss: 7.4754e-04 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 148us/step - loss: 7.4037e-04 - val_loss: 0.0010\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 150us/step - loss: 7.4894e-04 - val_loss: 8.4284e-04\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 149us/step - loss: 7.0720e-04 - val_loss: 0.0010\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 149us/step - loss: 7.0611e-04 - val_loss: 8.9842e-04\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 149us/step - loss: 6.9746e-04 - val_loss: 9.1193e-04\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 151us/step - loss: 6.8940e-04 - val_loss: 9.3014e-04\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 150us/step - loss: 6.8704e-04 - val_loss: 8.7828e-04\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 150us/step - loss: 6.7765e-04 - val_loss: 9.0333e-04\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 148us/step - loss: 6.7425e-04 - val_loss: 8.6805e-04\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 151us/step - loss: 6.6732e-04 - val_loss: 8.7207e-04\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 151us/step - loss: 6.6269e-04 - val_loss: 8.5443e-04\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 3s 707us/step - loss: 0.1046 - val_loss: 0.0034\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 148us/step - loss: 0.0312 - val_loss: 0.0057\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 148us/step - loss: 0.0236 - val_loss: 0.0046\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 156us/step - loss: 0.0164 - val_loss: 0.0036\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 150us/step - loss: 0.0115 - val_loss: 0.0030\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 147us/step - loss: 0.0082 - val_loss: 0.0026\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 150us/step - loss: 0.0059 - val_loss: 0.0023\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 149us/step - loss: 0.0044 - val_loss: 0.0020\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 148us/step - loss: 0.0033 - val_loss: 0.0019\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 149us/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 149us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 149us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 149us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 148us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 149us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 148us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 149us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 149us/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 150us/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 148us/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 150us/step - loss: 9.9010e-04 - val_loss: 0.0013\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 148us/step - loss: 9.8048e-04 - val_loss: 0.0013\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 149us/step - loss: 9.7340e-04 - val_loss: 0.0013\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 148us/step - loss: 9.6806e-04 - val_loss: 0.0013\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 3s 852us/step - loss: 2.8941 - val_loss: 0.0035\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 251us/step - loss: 0.0180 - val_loss: 0.0017\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 0.0070 - val_loss: 0.0022\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 0.0040 - val_loss: 0.0026\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 256us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 274us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 260us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 259us/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 255us/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 254us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 261us/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 257us/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 267us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 256us/step - loss: 0.0024 - val_loss: 0.0020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 260us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 260us/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 260us/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 260us/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 3s 878us/step - loss: 1.6029 - val_loss: 0.0019\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 0.0061 - val_loss: 0.0011\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 0.0039 - val_loss: 0.0012\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 0.0032 - val_loss: 0.0013\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 257us/step - loss: 0.0030 - val_loss: 0.0013\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 0.0028 - val_loss: 0.0015\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 254us/step - loss: 0.0029 - val_loss: 0.0014\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 0.0028 - val_loss: 0.0016\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 0.0026 - val_loss: 0.0013\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 257us/step - loss: 0.0026 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 0.0025 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 0.0026 - val_loss: 0.0015\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 251us/step - loss: 0.0024 - val_loss: 0.0014\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 0.0024 - val_loss: 0.0014\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 0.0025 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 251us/step - loss: 0.0023 - val_loss: 0.0013\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 0.0024 - val_loss: 0.0014\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 256us/step - loss: 0.0024 - val_loss: 0.0014\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 254us/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 254us/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 3s 871us/step - loss: 0.1314 - val_loss: 0.0363\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 251us/step - loss: 0.0676 - val_loss: 0.0329\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 0.0666 - val_loss: 0.0338\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 0.0656 - val_loss: 0.0261\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 0.0647 - val_loss: 0.0315\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 0.0637 - val_loss: 0.0332\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 0.0631 - val_loss: 0.0290\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 0.0620 - val_loss: 0.0330\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 0.0613 - val_loss: 0.0260\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 256us/step - loss: 0.0604 - val_loss: 0.0239\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 0.0595 - val_loss: 0.0325\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 0.0586 - val_loss: 0.0243\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 0.0576 - val_loss: 0.0289\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 258us/step - loss: 0.0566 - val_loss: 0.0312\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 0.0559 - val_loss: 0.0265\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 0.0552 - val_loss: 0.0260\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 0.0541 - val_loss: 0.0275\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 0.0531 - val_loss: 0.0261\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 251us/step - loss: 0.0522 - val_loss: 0.0329\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 0.0514 - val_loss: 0.0247\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 251us/step - loss: 0.0504 - val_loss: 0.0229\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 255us/step - loss: 0.0493 - val_loss: 0.0244\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 256us/step - loss: 0.0485 - val_loss: 0.0293\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 0.0477 - val_loss: 0.0237\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 3s 872us/step - loss: 0.1116 - val_loss: 0.0322\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 250us/step - loss: 0.0656 - val_loss: 0.0346\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 0.0650 - val_loss: 0.0335\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 251us/step - loss: 0.0643 - val_loss: 0.0316\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 0.0639 - val_loss: 0.0316\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 0.0632 - val_loss: 0.0277\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 0.0626 - val_loss: 0.0301\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 0.0620 - val_loss: 0.0286\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 251us/step - loss: 0.0614 - val_loss: 0.0289\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 0.0607 - val_loss: 0.0276\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 0.0600 - val_loss: 0.0281\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 0.0594 - val_loss: 0.0293\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 0.0587 - val_loss: 0.0253\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 251us/step - loss: 0.0580 - val_loss: 0.0256\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 258us/step - loss: 0.0574 - val_loss: 0.0275\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 0.0568 - val_loss: 0.0228\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 257us/step - loss: 0.0561 - val_loss: 0.0272\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 256us/step - loss: 0.0553 - val_loss: 0.0312\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 254us/step - loss: 0.0547 - val_loss: 0.0293\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 0.0539 - val_loss: 0.0267\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 0.0533 - val_loss: 0.0246\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 0.0524 - val_loss: 0.0261\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 254us/step - loss: 0.0516 - val_loss: 0.0239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 0.0509 - val_loss: 0.0252\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 5s 1ms/step - loss: 0.4185 - val_loss: 0.0362\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 562us/step - loss: 0.0684 - val_loss: 0.0342\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 2s 560us/step - loss: 0.0680 - val_loss: 0.0376\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 562us/step - loss: 0.0674 - val_loss: 0.0330\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 2s 562us/step - loss: 0.0669 - val_loss: 0.0356\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 2s 563us/step - loss: 0.0664 - val_loss: 0.0301\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 560us/step - loss: 0.0659 - val_loss: 0.0335\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 569us/step - loss: 0.0655 - val_loss: 0.0345\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 2s 569us/step - loss: 0.0648 - val_loss: 0.0362\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 2s 561us/step - loss: 0.0644 - val_loss: 0.0262\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 2s 565us/step - loss: 0.0638 - val_loss: 0.0342\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 563us/step - loss: 0.0632 - val_loss: 0.0298\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 563us/step - loss: 0.0627 - val_loss: 0.0289\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 2s 566us/step - loss: 0.0622 - val_loss: 0.0279\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 2s 568us/step - loss: 0.0616 - val_loss: 0.0336\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 2s 565us/step - loss: 0.0610 - val_loss: 0.0301\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 2s 567us/step - loss: 0.0603 - val_loss: 0.0279\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 563us/step - loss: 0.0597 - val_loss: 0.0299\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 2s 562us/step - loss: 0.0590 - val_loss: 0.0260\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 2s 563us/step - loss: 0.0586 - val_loss: 0.0279\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 2s 565us/step - loss: 0.0578 - val_loss: 0.0275\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 2s 565us/step - loss: 0.0571 - val_loss: 0.0277\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 2s 567us/step - loss: 0.0566 - val_loss: 0.0275\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 2s 567us/step - loss: 0.0559 - val_loss: 0.0263\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 5s 1ms/step - loss: 0.0755 - val_loss: 0.0156\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 562us/step - loss: 0.0263 - val_loss: 0.0068\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 2s 561us/step - loss: 0.0213 - val_loss: 0.0051\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 561us/step - loss: 0.0171 - val_loss: 0.0040\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 2s 563us/step - loss: 0.0143 - val_loss: 0.0034\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 2s 559us/step - loss: 0.0118 - val_loss: 0.0029\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 561us/step - loss: 0.0100 - val_loss: 0.0024\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 564us/step - loss: 0.0090 - val_loss: 0.0023\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 2s 563us/step - loss: 0.0076 - val_loss: 0.0022\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 2s 563us/step - loss: 0.0069 - val_loss: 0.0022\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 2s 568us/step - loss: 0.0065 - val_loss: 0.0022\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 562us/step - loss: 0.0061 - val_loss: 0.0022\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 567us/step - loss: 0.0056 - val_loss: 0.0023\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 2s 563us/step - loss: 0.0054 - val_loss: 0.0024\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 2s 562us/step - loss: 0.0052 - val_loss: 0.0025\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 2s 563us/step - loss: 0.0053 - val_loss: 0.0026\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 2s 560us/step - loss: 0.0049 - val_loss: 0.0026\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 560us/step - loss: 0.0052 - val_loss: 0.0027\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 2s 561us/step - loss: 0.0045 - val_loss: 0.0028\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 2s 561us/step - loss: 0.0047 - val_loss: 0.0027\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 2s 564us/step - loss: 0.0049 - val_loss: 0.0028\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 2s 563us/step - loss: 0.0047 - val_loss: 0.0027\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 2s 564us/step - loss: 0.0046 - val_loss: 0.0028\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 2s 561us/step - loss: 0.0045 - val_loss: 0.0029\n",
      "\n",
      "GENERATION 4\n",
      "\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 3s 891us/step - loss: 0.0287 - val_loss: 0.0041\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 206us/step - loss: 0.0184 - val_loss: 0.0010\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 204us/step - loss: 0.0315 - val_loss: 0.0152\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 211us/step - loss: 0.0062 - val_loss: 0.0120\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 204us/step - loss: 0.0032 - val_loss: 9.9527e-04\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 204us/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 204us/step - loss: 8.5989e-04 - val_loss: 0.0012\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 204us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 203us/step - loss: 9.0512e-04 - val_loss: 8.3389e-04\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 204us/step - loss: 8.5932e-04 - val_loss: 8.4482e-04\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 204us/step - loss: 7.7645e-04 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 203us/step - loss: 7.8152e-04 - val_loss: 0.0010\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 205us/step - loss: 7.7348e-04 - val_loss: 8.8717e-04\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 203us/step - loss: 7.6180e-04 - val_loss: 9.4681e-04\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 204us/step - loss: 7.5605e-04 - val_loss: 9.7994e-04\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 205us/step - loss: 7.5321e-04 - val_loss: 9.2285e-04\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 202us/step - loss: 7.4946e-04 - val_loss: 9.1232e-04\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 205us/step - loss: 7.4390e-04 - val_loss: 9.2911e-04\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 203us/step - loss: 7.4113e-04 - val_loss: 9.1739e-04\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 204us/step - loss: 7.3806e-04 - val_loss: 9.0254e-04\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 203us/step - loss: 7.3407e-04 - val_loss: 9.0265e-04\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 204us/step - loss: 7.3067e-04 - val_loss: 8.9939e-04\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 204us/step - loss: 7.2759e-04 - val_loss: 8.9031e-04\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 204us/step - loss: 7.2423e-04 - val_loss: 8.8505e-04\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 3s 840us/step - loss: 0.0165 - val_loss: 0.0038\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 149us/step - loss: 0.0043 - val_loss: 0.0012\n",
      "Epoch 3/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3556/3556 [==============================] - 1s 150us/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 151us/step - loss: 0.0049 - val_loss: 0.0048\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 156us/step - loss: 0.0074 - val_loss: 0.0024\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 152us/step - loss: 0.0242 - val_loss: 0.0027\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 150us/step - loss: 0.0249 - val_loss: 0.0060\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 150us/step - loss: 0.0276 - val_loss: 0.0216\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 151us/step - loss: 0.0015 - val_loss: 0.0051\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 151us/step - loss: 0.0037 - val_loss: 6.7078e-04\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 150us/step - loss: 0.0033 - val_loss: 9.4574e-04\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 150us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 150us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 149us/step - loss: 8.0175e-04 - val_loss: 0.0014\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 150us/step - loss: 6.5878e-04 - val_loss: 7.0995e-04\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 151us/step - loss: 7.0787e-04 - val_loss: 6.4052e-04\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 151us/step - loss: 6.3550e-04 - val_loss: 9.0760e-04\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 150us/step - loss: 6.2211e-04 - val_loss: 6.4714e-04\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 150us/step - loss: 5.8591e-04 - val_loss: 7.5325e-04\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 157us/step - loss: 5.8526e-04 - val_loss: 7.0730e-04\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 153us/step - loss: 5.8472e-04 - val_loss: 6.8811e-04\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 151us/step - loss: 5.7687e-04 - val_loss: 7.1762e-04\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 151us/step - loss: 5.7711e-04 - val_loss: 6.7514e-04\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 150us/step - loss: 5.6903e-04 - val_loss: 6.9902e-04\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 3s 866us/step - loss: 0.0189 - val_loss: 0.0030\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 150us/step - loss: 0.0112 - val_loss: 0.0050\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 149us/step - loss: 0.0226 - val_loss: 0.0052\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 150us/step - loss: 0.0634 - val_loss: 0.0297\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 149us/step - loss: 0.0137 - val_loss: 0.0183\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 149us/step - loss: 0.0066 - val_loss: 0.0044\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 148us/step - loss: 0.0028 - val_loss: 0.0010\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 149us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 151us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 150us/step - loss: 8.1960e-04 - val_loss: 7.8163e-04\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 149us/step - loss: 8.9491e-04 - val_loss: 0.0010\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 151us/step - loss: 7.6192e-04 - val_loss: 7.4723e-04\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 153us/step - loss: 6.8297e-04 - val_loss: 8.3149e-04\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 159us/step - loss: 6.6446e-04 - val_loss: 7.4764e-04\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 150us/step - loss: 6.7651e-04 - val_loss: 7.2499e-04\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 150us/step - loss: 6.5519e-04 - val_loss: 7.6866e-04\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 150us/step - loss: 6.5818e-04 - val_loss: 7.2073e-04\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 149us/step - loss: 6.4548e-04 - val_loss: 7.4248e-04\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 151us/step - loss: 6.4384e-04 - val_loss: 7.2379e-04\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 149us/step - loss: 6.3996e-04 - val_loss: 7.2382e-04\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 150us/step - loss: 6.3599e-04 - val_loss: 7.1944e-04\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 148us/step - loss: 6.3375e-04 - val_loss: 7.1255e-04\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 150us/step - loss: 6.2905e-04 - val_loss: 7.1117e-04\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 153us/step - loss: 6.2701e-04 - val_loss: 7.0376e-04\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 3s 880us/step - loss: 0.0231 - val_loss: 0.0105\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 151us/step - loss: 0.0128 - val_loss: 0.0028\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 151us/step - loss: 0.0055 - val_loss: 0.0011\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 151us/step - loss: 0.0048 - val_loss: 0.0019\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 149us/step - loss: 0.0035 - val_loss: 9.7269e-04\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 152us/step - loss: 0.0051 - val_loss: 0.0035\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 157us/step - loss: 0.0096 - val_loss: 0.0048\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 151us/step - loss: 0.0309 - val_loss: 0.0032\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 151us/step - loss: 0.0359 - val_loss: 0.0050\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 151us/step - loss: 0.0398 - val_loss: 0.0361\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 151us/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 151us/step - loss: 0.0078 - val_loss: 7.5850e-04\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 151us/step - loss: 0.0079 - val_loss: 0.0024\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 151us/step - loss: 0.0045 - val_loss: 0.0032\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 150us/step - loss: 0.0031 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 151us/step - loss: 0.0027 - val_loss: 6.1809e-04\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 150us/step - loss: 0.0025 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 150us/step - loss: 0.0024 - val_loss: 6.1313e-04\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 152us/step - loss: 0.0023 - val_loss: 6.3125e-04\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 150us/step - loss: 0.0022 - val_loss: 8.6881e-04\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 151us/step - loss: 0.0022 - val_loss: 6.1215e-04\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 151us/step - loss: 0.0022 - val_loss: 7.0128e-04\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 151us/step - loss: 0.0020 - val_loss: 6.4436e-04\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 151us/step - loss: 0.0019 - val_loss: 6.2567e-04\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 3s 978us/step - loss: 0.2554 - val_loss: 0.2390\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 176us/step - loss: 0.0332 - val_loss: 0.1476\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 176us/step - loss: 0.0307 - val_loss: 0.0829\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 178us/step - loss: 0.0287 - val_loss: 0.0525\n",
      "Epoch 5/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3556/3556 [==============================] - 1s 180us/step - loss: 0.0210 - val_loss: 0.0433\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 179us/step - loss: 0.0219 - val_loss: 0.0561\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 175us/step - loss: 0.0198 - val_loss: 0.0689\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 177us/step - loss: 0.0206 - val_loss: 0.0577\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 176us/step - loss: 0.0193 - val_loss: 0.0370\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 176us/step - loss: 0.0161 - val_loss: 0.0271\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 176us/step - loss: 0.0173 - val_loss: 0.0344\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 175us/step - loss: 0.0219 - val_loss: 0.0089\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 177us/step - loss: 0.0105 - val_loss: 0.0895\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 179us/step - loss: 0.0228 - val_loss: 0.0073\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 177us/step - loss: 0.0043 - val_loss: 0.0143\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 176us/step - loss: 0.0209 - val_loss: 0.0255\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 176us/step - loss: 0.0126 - val_loss: 0.0293\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 176us/step - loss: 0.0117 - val_loss: 0.0054\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 176us/step - loss: 0.0105 - val_loss: 0.0046\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 177us/step - loss: 0.0132 - val_loss: 0.0261\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 176us/step - loss: 0.0116 - val_loss: 0.0131\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 176us/step - loss: 0.0117 - val_loss: 0.0210\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 176us/step - loss: 0.0134 - val_loss: 0.0212\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 179us/step - loss: 0.0191 - val_loss: 0.0027\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 5s 1ms/step - loss: 0.6215 - val_loss: 0.5778\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 489us/step - loss: 0.0493 - val_loss: 0.0180\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 2s 491us/step - loss: 0.0081 - val_loss: 0.0796\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 489us/step - loss: 0.0182 - val_loss: 0.0807\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 2s 497us/step - loss: 0.0371 - val_loss: 0.1571\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 2s 493us/step - loss: 0.0321 - val_loss: 0.1657\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 489us/step - loss: 0.0252 - val_loss: 0.0330\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 488us/step - loss: 0.0188 - val_loss: 0.1528\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 2s 488us/step - loss: 0.0345 - val_loss: 0.1311\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 2s 489us/step - loss: 0.0313 - val_loss: 0.0286\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 2s 491us/step - loss: 0.0195 - val_loss: 0.0276\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 491us/step - loss: 0.0235 - val_loss: 0.0032\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 489us/step - loss: 0.0164 - val_loss: 0.0030\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 2s 495us/step - loss: 0.0156 - val_loss: 0.0388\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 2s 489us/step - loss: 0.0152 - val_loss: 0.0439\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 2s 490us/step - loss: 0.0369 - val_loss: 0.1262\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 2s 490us/step - loss: 0.0218 - val_loss: 0.0047\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 491us/step - loss: 0.0194 - val_loss: 0.0047\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 2s 490us/step - loss: 0.0164 - val_loss: 0.0030\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 2s 496us/step - loss: 0.0144 - val_loss: 0.0029\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 2s 491us/step - loss: 0.0157 - val_loss: 0.0171\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 2s 492us/step - loss: 0.0315 - val_loss: 0.0273\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 2s 502us/step - loss: 0.0146 - val_loss: 0.0057\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 2s 493us/step - loss: 0.0127 - val_loss: 0.0025\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 5s 1ms/step - loss: 0.9639 - val_loss: 0.0368\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 532us/step - loss: 0.0215 - val_loss: 0.4456\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 2s 534us/step - loss: 0.0316 - val_loss: 0.0519\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 529us/step - loss: 0.0199 - val_loss: 0.1318\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 2s 531us/step - loss: 0.0295 - val_loss: 0.1789\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 2s 527us/step - loss: 0.0379 - val_loss: 0.1813\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 531us/step - loss: 0.0381 - val_loss: 0.1986\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 527us/step - loss: 0.0299 - val_loss: 0.1817\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 2s 530us/step - loss: 0.0395 - val_loss: 0.0542\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 2s 527us/step - loss: 0.0196 - val_loss: 0.0217\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 2s 534us/step - loss: 0.0146 - val_loss: 0.1486\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 532us/step - loss: 0.0313 - val_loss: 0.0779\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 528us/step - loss: 0.0225 - val_loss: 0.1714\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 2s 527us/step - loss: 0.0247 - val_loss: 0.0151\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 2s 528us/step - loss: 0.0230 - val_loss: 0.0047\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 2s 529us/step - loss: 0.0344 - val_loss: 0.0379\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 2s 531us/step - loss: 0.0197 - val_loss: 0.0979\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 531us/step - loss: 0.0165 - val_loss: 0.0161\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 2s 528us/step - loss: 0.0315 - val_loss: 0.0338\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 2s 533us/step - loss: 0.0118 - val_loss: 0.0140\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 2s 528us/step - loss: 0.0215 - val_loss: 0.0105\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 2s 530us/step - loss: 0.0126 - val_loss: 0.0057\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 2s 529us/step - loss: 0.0166 - val_loss: 0.0704\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 2s 529us/step - loss: 0.0193 - val_loss: 0.0249\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 5s 2ms/step - loss: 0.1894 - val_loss: 0.0034\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 531us/step - loss: 0.0056 - val_loss: 0.0046\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 2s 528us/step - loss: 0.0045 - val_loss: 0.0075\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 530us/step - loss: 0.0042 - val_loss: 0.0067\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 2s 530us/step - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 2s 531us/step - loss: 0.0039 - val_loss: 0.0034\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 529us/step - loss: 0.0053 - val_loss: 0.0145\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 531us/step - loss: 0.0069 - val_loss: 0.0077\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 2s 530us/step - loss: 0.0094 - val_loss: 0.0161\n",
      "Epoch 10/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3556/3556 [==============================] - 2s 530us/step - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 2s 528us/step - loss: 0.0094 - val_loss: 0.0137\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 529us/step - loss: 0.0070 - val_loss: 0.0055\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 529us/step - loss: 0.0071 - val_loss: 0.0114\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 2s 535us/step - loss: 0.0054 - val_loss: 0.0036\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 2s 530us/step - loss: 0.0078 - val_loss: 0.0299\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 2s 530us/step - loss: 0.0085 - val_loss: 0.0046\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 2s 534us/step - loss: 0.0059 - val_loss: 0.0161\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 531us/step - loss: 0.0075 - val_loss: 0.0073\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 2s 530us/step - loss: 0.0070 - val_loss: 0.0157\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 2s 533us/step - loss: 0.0067 - val_loss: 0.0032\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 2s 529us/step - loss: 0.0059 - val_loss: 0.0175\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 2s 529us/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 2s 529us/step - loss: 0.0068 - val_loss: 0.0208\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 2s 532us/step - loss: 0.0070 - val_loss: 0.0043\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 5s 2ms/step - loss: 0.4803 - val_loss: 0.0024\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 489us/step - loss: 0.0084 - val_loss: 0.0028\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 2s 488us/step - loss: 0.0068 - val_loss: 0.0023\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 487us/step - loss: 0.0061 - val_loss: 0.0023\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 2s 495us/step - loss: 0.0057 - val_loss: 0.0018\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 2s 492us/step - loss: 0.0051 - val_loss: 0.0017\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 488us/step - loss: 0.0045 - val_loss: 0.0021\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 489us/step - loss: 0.0092 - val_loss: 0.0344\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 2s 489us/step - loss: 0.0152 - val_loss: 0.0144\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 2s 488us/step - loss: 0.0057 - val_loss: 0.0022\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 2s 488us/step - loss: 0.0078 - val_loss: 0.0277\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 490us/step - loss: 0.0148 - val_loss: 0.0194\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 489us/step - loss: 0.0138 - val_loss: 0.0108\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 2s 492us/step - loss: 0.0079 - val_loss: 0.0065\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 2s 490us/step - loss: 0.0056 - val_loss: 0.0113\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 2s 489us/step - loss: 0.0137 - val_loss: 0.0466\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 2s 493us/step - loss: 0.0379 - val_loss: 0.0209\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 491us/step - loss: 0.0056 - val_loss: 0.0025\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 2s 491us/step - loss: 0.0034 - val_loss: 0.0023\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 2s 488us/step - loss: 0.0040 - val_loss: 0.0073\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 2s 489us/step - loss: 0.0047 - val_loss: 0.0066\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 2s 488us/step - loss: 0.0105 - val_loss: 0.0187\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 2s 491us/step - loss: 0.0116 - val_loss: 0.0141\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 2s 488us/step - loss: 0.0114 - val_loss: 0.0224\n",
      "\n",
      "GENERATION 5\n",
      "\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 4s 1ms/step - loss: 0.1032 - val_loss: 0.1436\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 181us/step - loss: 0.0178 - val_loss: 0.0018\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 181us/step - loss: 0.0081 - val_loss: 0.0015\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 181us/step - loss: 0.0060 - val_loss: 0.0014\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 180us/step - loss: 0.0045 - val_loss: 0.0014\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 181us/step - loss: 0.0036 - val_loss: 0.0016\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 181us/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 180us/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 187us/step - loss: 0.0030 - val_loss: 0.0047\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 183us/step - loss: 0.0033 - val_loss: 0.0075\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 181us/step - loss: 0.0039 - val_loss: 0.0116\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 181us/step - loss: 0.0047 - val_loss: 0.0163\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 179us/step - loss: 0.0058 - val_loss: 0.0202\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 181us/step - loss: 0.0068 - val_loss: 0.0222\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 184us/step - loss: 0.0075 - val_loss: 0.0207\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 184us/step - loss: 0.0078 - val_loss: 0.0174\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 179us/step - loss: 0.0077 - val_loss: 0.0145\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 181us/step - loss: 0.0073 - val_loss: 0.0116\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 179us/step - loss: 0.0068 - val_loss: 0.0096\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 180us/step - loss: 0.0062 - val_loss: 0.0081\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 181us/step - loss: 0.0057 - val_loss: 0.0071\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 180us/step - loss: 0.0053 - val_loss: 0.0067\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 181us/step - loss: 0.0049 - val_loss: 0.0061\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 181us/step - loss: 0.0047 - val_loss: 0.0060\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 4s 1ms/step - loss: 0.0199 - val_loss: 0.0017\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 181us/step - loss: 0.0032 - val_loss: 0.0055\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 181us/step - loss: 0.0078 - val_loss: 0.0065\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 182us/step - loss: 0.0096 - val_loss: 0.0027\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 192us/step - loss: 0.0352 - val_loss: 0.0084\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 187us/step - loss: 0.0208 - val_loss: 0.0084\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 188us/step - loss: 0.0179 - val_loss: 0.0095\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 185us/step - loss: 0.0032 - val_loss: 0.0060\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 182us/step - loss: 0.0017 - val_loss: 9.4241e-04\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 183us/step - loss: 0.0011 - val_loss: 6.6589e-04\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 181us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 181us/step - loss: 8.8247e-04 - val_loss: 6.3349e-04\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 183us/step - loss: 6.6455e-04 - val_loss: 0.0010\n",
      "Epoch 14/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3556/3556 [==============================] - 1s 182us/step - loss: 6.3832e-04 - val_loss: 7.2723e-04\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 181us/step - loss: 6.4457e-04 - val_loss: 6.9778e-04\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 185us/step - loss: 6.1930e-04 - val_loss: 8.1325e-04\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 182us/step - loss: 6.2510e-04 - val_loss: 6.7304e-04\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 183us/step - loss: 5.9781e-04 - val_loss: 7.6640e-04\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 182us/step - loss: 5.9972e-04 - val_loss: 6.8245e-04\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 181us/step - loss: 5.8536e-04 - val_loss: 7.2219e-04\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 183us/step - loss: 5.8562e-04 - val_loss: 6.8087e-04\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 190us/step - loss: 5.7588e-04 - val_loss: 6.9670e-04\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 181us/step - loss: 5.7563e-04 - val_loss: 6.7147e-04\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 185us/step - loss: 5.6712e-04 - val_loss: 6.8005e-04\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 4s 1ms/step - loss: 0.2578 - val_loss: 0.0684\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 183us/step - loss: 0.0167 - val_loss: 0.0267\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 183us/step - loss: 0.0128 - val_loss: 0.0017\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 184us/step - loss: 0.0082 - val_loss: 0.0015\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 185us/step - loss: 0.0039 - val_loss: 0.0013\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 184us/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 184us/step - loss: 0.0016 - val_loss: 9.3227e-04\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 183us/step - loss: 0.0014 - val_loss: 8.1053e-04\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 189us/step - loss: 0.0012 - val_loss: 7.4073e-04\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 188us/step - loss: 0.0011 - val_loss: 6.9974e-04\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 182us/step - loss: 0.0010 - val_loss: 6.9255e-04\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 183us/step - loss: 0.0010 - val_loss: 6.7682e-04\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 183us/step - loss: 9.9451e-04 - val_loss: 6.7617e-04\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 183us/step - loss: 9.8008e-04 - val_loss: 6.6706e-04\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 183us/step - loss: 9.6441e-04 - val_loss: 6.6673e-04\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 183us/step - loss: 9.5142e-04 - val_loss: 6.5462e-04\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 184us/step - loss: 9.3345e-04 - val_loss: 6.5251e-04\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 185us/step - loss: 9.2128e-04 - val_loss: 6.4447e-04\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 185us/step - loss: 9.0903e-04 - val_loss: 6.4435e-04\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 185us/step - loss: 9.0002e-04 - val_loss: 6.3628e-04\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 182us/step - loss: 8.8729e-04 - val_loss: 6.3512e-04\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 183us/step - loss: 8.7908e-04 - val_loss: 6.2796e-04\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 183us/step - loss: 8.6761e-04 - val_loss: 6.2526e-04\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 183us/step - loss: 8.6055e-04 - val_loss: 6.2042e-04\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 5s 1ms/step - loss: 0.1434 - val_loss: 0.0055\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 373us/step - loss: 0.0051 - val_loss: 0.0054\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 374us/step - loss: 0.0166 - val_loss: 0.0129\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 376us/step - loss: 0.0072 - val_loss: 0.0110\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 373us/step - loss: 0.0110 - val_loss: 0.0325\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 380us/step - loss: 0.0125 - val_loss: 0.0098\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 377us/step - loss: 0.0087 - val_loss: 0.0245\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 373us/step - loss: 0.0101 - val_loss: 0.0058\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 375us/step - loss: 0.0082 - val_loss: 0.0178\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 381us/step - loss: 0.0077 - val_loss: 0.0092\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 374us/step - loss: 0.0095 - val_loss: 0.0223\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 376us/step - loss: 0.0113 - val_loss: 0.0021\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 373us/step - loss: 0.0031 - val_loss: 0.0182\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 373us/step - loss: 0.0082 - val_loss: 0.0038\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 375us/step - loss: 0.0065 - val_loss: 0.0141\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 376us/step - loss: 0.0053 - val_loss: 0.0041\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 371us/step - loss: 0.0058 - val_loss: 0.0131\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 376us/step - loss: 0.0054 - val_loss: 0.0066\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 375us/step - loss: 0.0058 - val_loss: 0.0153\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 381us/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 376us/step - loss: 0.0050 - val_loss: 0.0081\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 383us/step - loss: 0.0044 - val_loss: 0.0069\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 375us/step - loss: 0.0056 - val_loss: 0.0105\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 374us/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 5s 2ms/step - loss: 0.1004 - val_loss: 0.0027\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 463us/step - loss: 0.0059 - val_loss: 0.0024\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 2s 459us/step - loss: 0.0151 - val_loss: 0.0054\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 459us/step - loss: 0.0046 - val_loss: 0.0104\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 2s 459us/step - loss: 0.0126 - val_loss: 0.0157\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 2s 459us/step - loss: 0.0113 - val_loss: 0.0071\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 459us/step - loss: 0.0094 - val_loss: 0.0256\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 459us/step - loss: 0.0124 - val_loss: 0.0017\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 2s 467us/step - loss: 0.0035 - val_loss: 0.0211\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 2s 459us/step - loss: 0.0121 - val_loss: 0.0195\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 2s 460us/step - loss: 0.0067 - val_loss: 0.0084\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 466us/step - loss: 0.0038 - val_loss: 0.0095\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 464us/step - loss: 0.0120 - val_loss: 0.0160\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 2s 459us/step - loss: 0.0059 - val_loss: 0.0016\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 2s 462us/step - loss: 0.0025 - val_loss: 0.0246\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 2s 459us/step - loss: 0.0091 - val_loss: 0.0026\n",
      "Epoch 17/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3556/3556 [==============================] - 2s 458us/step - loss: 0.0033 - val_loss: 0.0096\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 459us/step - loss: 0.0052 - val_loss: 0.0111\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 2s 460us/step - loss: 0.0096 - val_loss: 0.0083\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 2s 460us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 2s 464us/step - loss: 0.0058 - val_loss: 0.0167\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 2s 462us/step - loss: 0.0052 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 2s 461us/step - loss: 0.0029 - val_loss: 0.0052\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 2s 462us/step - loss: 0.0058 - val_loss: 0.0091\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 6s 2ms/step - loss: 0.0711 - val_loss: 0.0025\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 460us/step - loss: 0.0144 - val_loss: 0.0045\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 2s 460us/step - loss: 0.0034 - val_loss: 0.0122\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 460us/step - loss: 0.0161 - val_loss: 0.0041\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 2s 459us/step - loss: 0.0083 - val_loss: 0.0193\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 2s 461us/step - loss: 0.0100 - val_loss: 0.0231\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 460us/step - loss: 0.0085 - val_loss: 0.0140\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 461us/step - loss: 0.0060 - val_loss: 0.0048\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 2s 461us/step - loss: 0.0098 - val_loss: 0.0162\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 2s 459us/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 2s 465us/step - loss: 0.0088 - val_loss: 0.0278\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 460us/step - loss: 0.0081 - val_loss: 0.0022\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 460us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 2s 461us/step - loss: 0.0081 - val_loss: 0.0290\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 2s 464us/step - loss: 0.0040 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 2s 464us/step - loss: 0.0044 - val_loss: 0.0186\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 2s 461us/step - loss: 0.0066 - val_loss: 0.0023\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 461us/step - loss: 0.0027 - val_loss: 0.0160\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 2s 461us/step - loss: 0.0048 - val_loss: 0.0042\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 2s 463us/step - loss: 0.0070 - val_loss: 0.0093\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 2s 464us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 2s 464us/step - loss: 0.0029 - val_loss: 0.0160\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 2s 465us/step - loss: 0.0077 - val_loss: 0.0096\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 2s 461us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 5s 2ms/step - loss: 0.2409 - val_loss: 0.0136\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 368us/step - loss: 0.0452 - val_loss: 0.0132\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 366us/step - loss: 0.0468 - val_loss: 0.0046\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 372us/step - loss: 0.0109 - val_loss: 0.0043\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 366us/step - loss: 0.0051 - val_loss: 0.0182\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 367us/step - loss: 0.0043 - val_loss: 0.0077\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 365us/step - loss: 0.0034 - val_loss: 0.0119\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 365us/step - loss: 0.0032 - val_loss: 0.0043\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 365us/step - loss: 0.0031 - val_loss: 0.0044\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 364us/step - loss: 0.0029 - val_loss: 0.0039\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 364us/step - loss: 0.0029 - val_loss: 0.0086\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 370us/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 366us/step - loss: 0.0038 - val_loss: 0.0090\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 364us/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 365us/step - loss: 0.0027 - val_loss: 0.0050\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 363us/step - loss: 0.0025 - val_loss: 0.0070\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 366us/step - loss: 0.0026 - val_loss: 0.0040\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 364us/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 365us/step - loss: 0.0025 - val_loss: 0.0061\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 365us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 366us/step - loss: 0.0025 - val_loss: 0.0075\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 365us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 366us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 370us/step - loss: 0.0024 - val_loss: 0.0062\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 5s 2ms/step - loss: 0.2799 - val_loss: 0.0313\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 364us/step - loss: 0.0547 - val_loss: 0.0135\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 363us/step - loss: 0.0276 - val_loss: 0.0206\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 370us/step - loss: 0.0131 - val_loss: 0.0051\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 365us/step - loss: 0.0043 - val_loss: 0.0095\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 363us/step - loss: 0.0031 - val_loss: 0.0085\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 364us/step - loss: 0.0029 - val_loss: 0.0054\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 364us/step - loss: 0.0027 - val_loss: 0.0081\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 364us/step - loss: 0.0027 - val_loss: 0.0074\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 365us/step - loss: 0.0026 - val_loss: 0.0074\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 364us/step - loss: 0.0026 - val_loss: 0.0101\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 366us/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 364us/step - loss: 0.0026 - val_loss: 0.0046\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 363us/step - loss: 0.0025 - val_loss: 0.0045\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 365us/step - loss: 0.0025 - val_loss: 0.0070\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 367us/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 377us/step - loss: 0.0025 - val_loss: 0.0060\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 370us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 365us/step - loss: 0.0024 - val_loss: 0.0048\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 362us/step - loss: 0.0024 - val_loss: 0.0067\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 365us/step - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 22/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3556/3556 [==============================] - 1s 364us/step - loss: 0.0023 - val_loss: 0.0067\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 364us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 363us/step - loss: 0.0026 - val_loss: 0.0070\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 6s 2ms/step - loss: 0.7988 - val_loss: 0.0340\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 564us/step - loss: 0.1419 - val_loss: 0.0306\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 2s 564us/step - loss: 0.0714 - val_loss: 0.0310\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 565us/step - loss: 0.0716 - val_loss: 0.0402\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 2s 563us/step - loss: 0.0713 - val_loss: 0.0328\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 2s 572us/step - loss: 0.0711 - val_loss: 0.0357\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 563us/step - loss: 0.0713 - val_loss: 0.0357\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 563us/step - loss: 0.0712 - val_loss: 0.0333\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 2s 563us/step - loss: 0.0711 - val_loss: 0.0454\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 2s 563us/step - loss: 0.0618 - val_loss: 0.2313\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 2s 564us/step - loss: 0.0646 - val_loss: 0.0114\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 566us/step - loss: 0.0207 - val_loss: 0.0262\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 560us/step - loss: 0.0121 - val_loss: 0.0072\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 2s 564us/step - loss: 0.0038 - val_loss: 0.0079\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 2s 562us/step - loss: 0.0033 - val_loss: 0.0075\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 2s 561us/step - loss: 0.0030 - val_loss: 0.0065\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 2s 558us/step - loss: 0.0028 - val_loss: 0.0069\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 562us/step - loss: 0.0027 - val_loss: 0.0075\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 2s 561us/step - loss: 0.0027 - val_loss: 0.0047\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 2s 563us/step - loss: 0.0026 - val_loss: 0.0068\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 2s 566us/step - loss: 0.0026 - val_loss: 0.0065\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 2s 562us/step - loss: 0.0025 - val_loss: 0.0063\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 2s 562us/step - loss: 0.0025 - val_loss: 0.0055\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 2s 561us/step - loss: 0.0025 - val_loss: 0.0051\n",
      "\n",
      "GENERATION 6\n",
      "\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 5s 1ms/step - loss: 0.0218 - val_loss: 0.0156\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 245us/step - loss: 0.0258 - val_loss: 0.0158\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 245us/step - loss: 0.0646 - val_loss: 0.0073\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 245us/step - loss: 0.0316 - val_loss: 0.0071\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 245us/step - loss: 0.0211 - val_loss: 0.0191\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 244us/step - loss: 0.0018 - val_loss: 0.0034\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 245us/step - loss: 0.0045 - val_loss: 0.0035\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 245us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 244us/step - loss: 0.0012 - val_loss: 6.9349e-04\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 247us/step - loss: 0.0010 - val_loss: 0.0019\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 246us/step - loss: 7.3337e-04 - val_loss: 7.1216e-04\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 244us/step - loss: 7.7753e-04 - val_loss: 6.9085e-04\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 245us/step - loss: 6.8081e-04 - val_loss: 0.0010\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 247us/step - loss: 6.6635e-04 - val_loss: 7.9817e-04\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 6.6909e-04 - val_loss: 7.3856e-04\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 245us/step - loss: 6.4541e-04 - val_loss: 8.5767e-04\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 245us/step - loss: 6.4545e-04 - val_loss: 7.8328e-04\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 244us/step - loss: 6.4187e-04 - val_loss: 7.6566e-04\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 247us/step - loss: 6.3400e-04 - val_loss: 8.0071e-04\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 249us/step - loss: 6.3227e-04 - val_loss: 7.6598e-04\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 244us/step - loss: 6.2758e-04 - val_loss: 7.6710e-04\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 244us/step - loss: 6.2330e-04 - val_loss: 7.6834e-04\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 247us/step - loss: 6.2038e-04 - val_loss: 7.5254e-04\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 245us/step - loss: 6.1585e-04 - val_loss: 7.5370e-04\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 5s 1ms/step - loss: 0.0278 - val_loss: 0.0018\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 186us/step - loss: 0.0057 - val_loss: 0.0030\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 185us/step - loss: 0.0071 - val_loss: 0.0111\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 183us/step - loss: 0.0349 - val_loss: 0.0017\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 184us/step - loss: 0.0405 - val_loss: 0.0092\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 185us/step - loss: 0.0377 - val_loss: 0.0361\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 183us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 185us/step - loss: 0.0066 - val_loss: 0.0026\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 185us/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 185us/step - loss: 8.9331e-04 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 183us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 184us/step - loss: 9.2971e-04 - val_loss: 7.8147e-04\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 183us/step - loss: 7.4533e-04 - val_loss: 7.8848e-04\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 184us/step - loss: 7.4800e-04 - val_loss: 9.5876e-04\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 185us/step - loss: 6.9050e-04 - val_loss: 6.5931e-04\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 189us/step - loss: 6.5166e-04 - val_loss: 7.3838e-04\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 187us/step - loss: 6.4689e-04 - val_loss: 7.6202e-04\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 184us/step - loss: 6.4513e-04 - val_loss: 6.7695e-04\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 184us/step - loss: 6.2737e-04 - val_loss: 7.2048e-04\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 184us/step - loss: 6.2306e-04 - val_loss: 7.0371e-04\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 184us/step - loss: 6.1989e-04 - val_loss: 6.8311e-04\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 184us/step - loss: 6.1134e-04 - val_loss: 6.9599e-04\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 183us/step - loss: 6.0764e-04 - val_loss: 6.7749e-04\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 185us/step - loss: 6.0222e-04 - val_loss: 6.7485e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 5s 1ms/step - loss: 0.0580 - val_loss: 0.0094\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 183us/step - loss: 0.0131 - val_loss: 9.3151e-04\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 184us/step - loss: 0.0049 - val_loss: 0.0024\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 183us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 182us/step - loss: 0.0014 - val_loss: 0.0032\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 185us/step - loss: 0.0012 - val_loss: 9.7682e-04\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 184us/step - loss: 9.5279e-04 - val_loss: 0.0013\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 183us/step - loss: 8.2822e-04 - val_loss: 7.6948e-04\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 184us/step - loss: 7.5665e-04 - val_loss: 8.3042e-04\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 191us/step - loss: 7.1642e-04 - val_loss: 8.1163e-04\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 184us/step - loss: 6.9532e-04 - val_loss: 7.6808e-04\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 184us/step - loss: 6.8641e-04 - val_loss: 8.1295e-04\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 183us/step - loss: 6.7822e-04 - val_loss: 7.5346e-04\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 184us/step - loss: 6.7183e-04 - val_loss: 7.8967e-04\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 183us/step - loss: 6.6378e-04 - val_loss: 7.3875e-04\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 186us/step - loss: 6.5747e-04 - val_loss: 7.4568e-04\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 184us/step - loss: 6.4989e-04 - val_loss: 7.4262e-04\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 184us/step - loss: 6.4373e-04 - val_loss: 7.3107e-04\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 184us/step - loss: 6.3808e-04 - val_loss: 7.0131e-04\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 183us/step - loss: 6.3165e-04 - val_loss: 7.3669e-04\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 187us/step - loss: 6.2289e-04 - val_loss: 6.8526e-04\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 195us/step - loss: 6.1731e-04 - val_loss: 6.9914e-04\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 183us/step - loss: 6.1190e-04 - val_loss: 6.8395e-04\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 183us/step - loss: 6.0600e-04 - val_loss: 6.6361e-04\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 6s 2ms/step - loss: 0.0835 - val_loss: 0.0023\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 394us/step - loss: 0.0053 - val_loss: 0.0018\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 393us/step - loss: 0.0057 - val_loss: 0.0189\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 393us/step - loss: 0.0111 - val_loss: 0.0018\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 393us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 394us/step - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 395us/step - loss: 0.0033 - val_loss: 0.0015\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 398us/step - loss: 0.0042 - val_loss: 0.0177\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 392us/step - loss: 0.0111 - val_loss: 0.0018\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 393us/step - loss: 0.0034 - val_loss: 0.0019\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 395us/step - loss: 0.0031 - val_loss: 0.0016\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 403us/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 395us/step - loss: 0.0044 - val_loss: 0.0040\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 392us/step - loss: 0.0048 - val_loss: 0.0059\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 395us/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 393us/step - loss: 0.0030 - val_loss: 0.0038\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 390us/step - loss: 0.0033 - val_loss: 0.0050\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 393us/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 400us/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 396us/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 396us/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 393us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 395us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 394us/step - loss: 0.0053 - val_loss: 0.0040\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 6s 2ms/step - loss: 0.6037 - val_loss: 0.0018\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 397us/step - loss: 0.0057 - val_loss: 0.0034\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 395us/step - loss: 0.0044 - val_loss: 0.0111\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 395us/step - loss: 0.0152 - val_loss: 0.0052\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 395us/step - loss: 0.0049 - val_loss: 0.0044\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 395us/step - loss: 0.0030 - val_loss: 0.0026\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 397us/step - loss: 0.0029 - val_loss: 0.0018\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 397us/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 399us/step - loss: 0.0028 - val_loss: 0.0077\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 396us/step - loss: 0.0066 - val_loss: 0.0039\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 394us/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 395us/step - loss: 0.0026 - val_loss: 0.0015\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 395us/step - loss: 0.0030 - val_loss: 0.0045\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 395us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 394us/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 395us/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 395us/step - loss: 0.0030 - val_loss: 0.0045\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 396us/step - loss: 0.0028 - val_loss: 0.0014\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 393us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 397us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 397us/step - loss: 0.0021 - val_loss: 0.0034\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 402us/step - loss: 0.0048 - val_loss: 0.0065\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 394us/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 393us/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 7s 2ms/step - loss: 0.1421 - val_loss: 0.0019\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 401us/step - loss: 0.0047 - val_loss: 0.0022\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 399us/step - loss: 0.0104 - val_loss: 0.0130\n",
      "Epoch 4/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3556/3556 [==============================] - 1s 399us/step - loss: 0.0051 - val_loss: 0.0021\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 400us/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 401us/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 402us/step - loss: 0.0027 - val_loss: 0.0059\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 402us/step - loss: 0.0079 - val_loss: 0.0185\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 406us/step - loss: 0.0074 - val_loss: 0.0050\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 412us/step - loss: 0.0030 - val_loss: 0.0015\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 398us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 402us/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 400us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 400us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 403us/step - loss: 0.0033 - val_loss: 0.0114\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 400us/step - loss: 0.0120 - val_loss: 0.0058\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 404us/step - loss: 0.0028 - val_loss: 0.0013\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 404us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 401us/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 401us/step - loss: 0.0021 - val_loss: 0.0031\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 407us/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 401us/step - loss: 0.0028 - val_loss: 0.0058\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 401us/step - loss: 0.0043 - val_loss: 0.0040\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 400us/step - loss: 0.0053 - val_loss: 0.0063\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 7s 2ms/step - loss: 0.0740 - val_loss: 0.0178\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 361us/step - loss: 0.0133 - val_loss: 0.0122\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 361us/step - loss: 0.0100 - val_loss: 0.0130\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 362us/step - loss: 0.0082 - val_loss: 0.0063\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 361us/step - loss: 0.0064 - val_loss: 0.0089\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 362us/step - loss: 0.0075 - val_loss: 0.0110\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 362us/step - loss: 0.0062 - val_loss: 0.0053\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 361us/step - loss: 0.0047 - val_loss: 0.0063\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 360us/step - loss: 0.0065 - val_loss: 0.0061\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 363us/step - loss: 0.0063 - val_loss: 0.0072\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 366us/step - loss: 0.0047 - val_loss: 0.0042\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 362us/step - loss: 0.0046 - val_loss: 0.0073\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 361us/step - loss: 0.0041 - val_loss: 0.0031\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 360us/step - loss: 0.0048 - val_loss: 0.0089\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 361us/step - loss: 0.0034 - val_loss: 0.0025\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 361us/step - loss: 0.0054 - val_loss: 0.0074\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 362us/step - loss: 0.0036 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 360us/step - loss: 0.0025 - val_loss: 0.0050\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 362us/step - loss: 0.0044 - val_loss: 0.0028\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 366us/step - loss: 0.0032 - val_loss: 0.0062\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 362us/step - loss: 0.0048 - val_loss: 0.0062\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 361us/step - loss: 0.0048 - val_loss: 0.0026\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 367us/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 364us/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 7s 2ms/step - loss: 0.1045 - val_loss: 0.0282\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 389us/step - loss: 0.0129 - val_loss: 0.0034\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 391us/step - loss: 0.0081 - val_loss: 0.0082\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 386us/step - loss: 0.0077 - val_loss: 0.0105\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 385us/step - loss: 0.0062 - val_loss: 0.0029\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 388us/step - loss: 0.0045 - val_loss: 0.0058\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 387us/step - loss: 0.0066 - val_loss: 0.0119\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 393us/step - loss: 0.0073 - val_loss: 0.0059\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 386us/step - loss: 0.0057 - val_loss: 0.0071\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 384us/step - loss: 0.0045 - val_loss: 0.0054\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 384us/step - loss: 0.0065 - val_loss: 0.0075\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 385us/step - loss: 0.0053 - val_loss: 0.0049\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 391us/step - loss: 0.0041 - val_loss: 0.0054\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 384us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 388us/step - loss: 0.0049 - val_loss: 0.0084\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 389us/step - loss: 0.0054 - val_loss: 0.0045\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 388us/step - loss: 0.0043 - val_loss: 0.0078\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 386us/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 384us/step - loss: 0.0043 - val_loss: 0.0079\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 389us/step - loss: 0.0036 - val_loss: 0.0031\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 390us/step - loss: 0.0035 - val_loss: 0.0048\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 387us/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 389us/step - loss: 0.0039 - val_loss: 0.0063\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 393us/step - loss: 0.0042 - val_loss: 0.0023\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 7s 2ms/step - loss: 0.0788 - val_loss: 0.0291\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 389us/step - loss: 0.0650 - val_loss: 0.0217\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 394us/step - loss: 0.0520 - val_loss: 0.0070\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 393us/step - loss: 0.0239 - val_loss: 0.0203\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 391us/step - loss: 0.0104 - val_loss: 0.0415\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 392us/step - loss: 0.0094 - val_loss: 0.0254\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 389us/step - loss: 0.0066 - val_loss: 0.0212\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 391us/step - loss: 0.0058 - val_loss: 0.0260\n",
      "Epoch 9/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3556/3556 [==============================] - 1s 388us/step - loss: 0.0159 - val_loss: 0.0351\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 388us/step - loss: 0.0054 - val_loss: 0.0158\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 389us/step - loss: 0.0058 - val_loss: 0.0062\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 388us/step - loss: 0.0037 - val_loss: 0.0087\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 394us/step - loss: 0.0044 - val_loss: 0.0023\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 388us/step - loss: 0.0046 - val_loss: 0.0187\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 387us/step - loss: 0.0047 - val_loss: 0.0025\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 388us/step - loss: 0.0031 - val_loss: 0.0115\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 393us/step - loss: 0.0038 - val_loss: 0.0029\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 389us/step - loss: 0.0040 - val_loss: 0.0131\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 389us/step - loss: 0.0037 - val_loss: 0.0023\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 389us/step - loss: 0.0026 - val_loss: 0.0065\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 392us/step - loss: 0.0028 - val_loss: 0.0021\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 391us/step - loss: 0.0036 - val_loss: 0.0174\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 388us/step - loss: 0.0039 - val_loss: 0.0017\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 395us/step - loss: 0.0022 - val_loss: 0.0047\n",
      "\n",
      "GENERATION 7\n",
      "\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 6s 2ms/step - loss: 0.0182 - val_loss: 0.0016\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 182us/step - loss: 0.0034 - val_loss: 0.0011\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 183us/step - loss: 0.0031 - val_loss: 0.0054\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 189us/step - loss: 0.0095 - val_loss: 0.0073\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 190us/step - loss: 0.0142 - val_loss: 0.0033\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 183us/step - loss: 0.0382 - val_loss: 0.0108\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 183us/step - loss: 0.0176 - val_loss: 0.0057\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 184us/step - loss: 0.0173 - val_loss: 0.0076\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 185us/step - loss: 0.0052 - val_loss: 0.0056\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 188us/step - loss: 0.0041 - val_loss: 0.0022\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 188us/step - loss: 0.0014 - val_loss: 9.2463e-04\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 186us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 183us/step - loss: 0.0016 - val_loss: 6.4388e-04\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 185us/step - loss: 0.0012 - val_loss: 9.3486e-04\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 183us/step - loss: 0.0011 - val_loss: 7.1029e-04\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 183us/step - loss: 0.0011 - val_loss: 6.4104e-04-\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 182us/step - loss: 0.0011 - val_loss: 7.2630e-04\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 183us/step - loss: 0.0010 - val_loss: 6.5753e-04\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 186us/step - loss: 0.0011 - val_loss: 6.3639e-04\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 184us/step - loss: 0.0011 - val_loss: 6.6124e-04\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 183us/step - loss: 0.0010 - val_loss: 6.1004e-04\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 184us/step - loss: 0.0010 - val_loss: 6.7357e-04\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 184us/step - loss: 0.0010 - val_loss: 6.0011e-04\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 184us/step - loss: 9.9603e-04 - val_loss: 6.2651e-04\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 6s 2ms/step - loss: 0.0238 - val_loss: 0.0029\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 185us/step - loss: 0.0052 - val_loss: 0.0042\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 186us/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 184us/step - loss: 0.0075 - val_loss: 0.0041\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 185us/step - loss: 0.0310 - val_loss: 0.0022\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 185us/step - loss: 0.0342 - val_loss: 0.0076\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 187us/step - loss: 0.0294 - val_loss: 0.0224\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 184us/step - loss: 0.0034 - val_loss: 0.0082\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 190us/step - loss: 0.0029 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 189us/step - loss: 0.0013 - val_loss: 7.1726e-04\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 185us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 193us/step - loss: 0.0011 - val_loss: 7.0535e-04\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 187us/step - loss: 8.3173e-04 - val_loss: 0.0014\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 187us/step - loss: 6.9831e-04 - val_loss: 7.1447e-04\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 186us/step - loss: 6.6517e-04 - val_loss: 8.3777e-04\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 185us/step - loss: 6.6069e-04 - val_loss: 8.4798e-04\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 183us/step - loss: 6.6844e-04 - val_loss: 7.4062e-04\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 186us/step - loss: 6.4193e-04 - val_loss: 8.4363e-04\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 186us/step - loss: 6.4599e-04 - val_loss: 7.3460e-04\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 185us/step - loss: 6.2759e-04 - val_loss: 7.9833e-04\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 185us/step - loss: 6.3052e-04 - val_loss: 7.2884e-04\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 185us/step - loss: 6.1630e-04 - val_loss: 7.6458e-04\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 185us/step - loss: 6.2081e-04 - val_loss: 7.1656e-04\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 184us/step - loss: 6.0763e-04 - val_loss: 7.4175e-04\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 6s 2ms/step - loss: 0.0936 - val_loss: 0.0210\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 185us/step - loss: 0.1119 - val_loss: 0.0072\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 184us/step - loss: 0.1114 - val_loss: 0.0537\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 186us/step - loss: 0.0231 - val_loss: 0.0382\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 183us/step - loss: 0.0222 - val_loss: 0.0144\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 184us/step - loss: 0.0079 - val_loss: 0.0016\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 185us/step - loss: 0.0054 - val_loss: 0.0043\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 185us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 186us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 185us/step - loss: 0.0010 - val_loss: 8.5694e-04\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 184us/step - loss: 0.0011 - val_loss: 8.5722e-04\n",
      "Epoch 12/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3556/3556 [==============================] - 1s 186us/step - loss: 9.1674e-04 - val_loss: 9.7967e-04\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 192us/step - loss: 9.6290e-04 - val_loss: 8.7569e-04\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 190us/step - loss: 8.0939e-04 - val_loss: 9.0501e-04\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 184us/step - loss: 8.3696e-04 - val_loss: 8.3216e-04\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 184us/step - loss: 7.8752e-04 - val_loss: 8.5676e-04\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 186us/step - loss: 7.9571e-04 - val_loss: 8.2426e-04\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 184us/step - loss: 7.7725e-04 - val_loss: 8.3367e-04\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 184us/step - loss: 7.8404e-04 - val_loss: 8.1918e-04\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 183us/step - loss: 7.7122e-04 - val_loss: 8.2086e-04\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 185us/step - loss: 7.7564e-04 - val_loss: 8.1364e-04\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 184us/step - loss: 7.6443e-04 - val_loss: 8.1214e-04\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 185us/step - loss: 7.6774e-04 - val_loss: 8.0753e-04\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 185us/step - loss: 7.5700e-04 - val_loss: 8.0340e-04\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 8s 2ms/step - loss: 0.1431 - val_loss: 0.0067\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 572us/step - loss: 0.0128 - val_loss: 0.0032\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 2s 567us/step - loss: 0.0071 - val_loss: 0.0018\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 570us/step - loss: 0.0055 - val_loss: 0.0018\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 2s 570us/step - loss: 0.0036 - val_loss: 0.0015\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 2s 569us/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 567us/step - loss: 0.0029 - val_loss: 0.0015\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 568us/step - loss: 0.0026 - val_loss: 0.0013\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 2s 569us/step - loss: 0.0024 - val_loss: 0.0013\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 2s 569us/step - loss: 0.0023 - val_loss: 0.0013\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 2s 568us/step - loss: 0.0023 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 567us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 571us/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 2s 568us/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 2s 567us/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 2s 568us/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 2s 569us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 569us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 2s 573us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 2s 571us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 2s 571us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 2s 567us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 2s 565us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 2s 569us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 8s 2ms/step - loss: 1.8563 - val_loss: 0.0205\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 576us/step - loss: 0.2558 - val_loss: 0.0987\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 2s 566us/step - loss: 0.0542 - val_loss: 0.0265\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 569us/step - loss: 0.0316 - val_loss: 0.0092\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 2s 570us/step - loss: 0.0200 - val_loss: 0.0030\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 2s 568us/step - loss: 0.0127 - val_loss: 0.0066\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 569us/step - loss: 0.0099 - val_loss: 0.0031\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 567us/step - loss: 0.0082 - val_loss: 0.0030\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 2s 566us/step - loss: 0.0074 - val_loss: 0.0050\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 2s 565us/step - loss: 0.0064 - val_loss: 0.0061\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 2s 567us/step - loss: 0.0059 - val_loss: 0.0042\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 569us/step - loss: 0.0057 - val_loss: 0.0043\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 569us/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 2s 567us/step - loss: 0.0053 - val_loss: 0.0040\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 2s 567us/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 2s 567us/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 2s 571us/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 567us/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 2s 567us/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 2s 564us/step - loss: 0.0044 - val_loss: 0.0036\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 2s 569us/step - loss: 0.0040 - val_loss: 0.0034\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 2s 571us/step - loss: 0.0039 - val_loss: 0.0031\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 2s 573us/step - loss: 0.0040 - val_loss: 0.0034\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 2s 566us/step - loss: 0.0038 - val_loss: 0.0032\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 8s 2ms/step - loss: 0.7079 - val_loss: 0.0025\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 478us/step - loss: 0.0366 - val_loss: 0.0039\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 2s 476us/step - loss: 0.0251 - val_loss: 0.0083\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 475us/step - loss: 0.0176 - val_loss: 0.0208\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 2s 478us/step - loss: 0.0154 - val_loss: 0.0017\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 2s 481us/step - loss: 0.0082 - val_loss: 0.0021\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 476us/step - loss: 0.0033 - val_loss: 0.0016\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 476us/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 2s 477us/step - loss: 0.0025 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 2s 477us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 2s 480us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 478us/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 476us/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 2s 477us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 2s 477us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 16/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3556/3556 [==============================] - 2s 480us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 2s 477us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 483us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 2s 477us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 2s 477us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 2s 478us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 2s 476us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 2s 477us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 2s 477us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 8s 2ms/step - loss: 0.0684 - val_loss: 0.0340\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 481us/step - loss: 0.0145 - val_loss: 0.0171\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 2s 475us/step - loss: 0.0062 - val_loss: 0.0051\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 478us/step - loss: 0.0038 - val_loss: 0.0060\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 2s 477us/step - loss: 0.0028 - val_loss: 0.0017\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 2s 476us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 477us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 474us/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 2s 475us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 2s 478us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 2s 480us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 476us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 475us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 2s 476us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 2s 476us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 2s 475us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 2s 477us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 481us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 2s 482us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 2s 486us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 2s 477us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 2s 478us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 2s 475us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 2s 477us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 8s 2ms/step - loss: 0.0672 - val_loss: 0.0406\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 477us/step - loss: 0.0142 - val_loss: 0.0143\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 2s 479us/step - loss: 0.0057 - val_loss: 0.0047\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 482us/step - loss: 0.0034 - val_loss: 0.0047\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 2s 484us/step - loss: 0.0027 - val_loss: 0.0016\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 2s 478us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 477us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 478us/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 2s 476us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 2s 476us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 2s 475us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 476us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 478us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 2s 478us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 2s 480us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 2s 477us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 2s 477us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 475us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 2s 476us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 2s 474us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 2s 478us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 2s 482us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 2s 476us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 2s 479us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 8s 2ms/step - loss: 0.0644 - val_loss: 0.0299\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 508us/step - loss: 0.0109 - val_loss: 0.0072\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 2s 507us/step - loss: 0.0046 - val_loss: 0.0021\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 507us/step - loss: 0.0030 - val_loss: 0.0017\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 2s 511us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 2s 509us/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 509us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 512us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 2s 511us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 2s 509us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 2s 505us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 508us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 507us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 2s 508us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 2s 508us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 2s 507us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 2s 510us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 514us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 2s 508us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 2s 506us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 21/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3556/3556 [==============================] - 2s 508us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 2s 513us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 2s 507us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 2s 507us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "\n",
      "GENERATION 8\n",
      "\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 7s 2ms/step - loss: 0.0329 - val_loss: 0.3043\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 194us/step - loss: 0.0771 - val_loss: 0.1928\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 193us/step - loss: 0.0499 - val_loss: 0.0655\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 193us/step - loss: 0.0269 - val_loss: 0.0105\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 194us/step - loss: 0.0166 - val_loss: 0.0039\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 201us/step - loss: 0.0047 - val_loss: 0.0012\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 194us/step - loss: 0.0013 - val_loss: 8.4991e-04\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 194us/step - loss: 9.1583e-04 - val_loss: 8.1710e-04\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 192us/step - loss: 9.2323e-04 - val_loss: 8.0172e-04\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 193us/step - loss: 9.6605e-04 - val_loss: 7.9432e-04\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 196us/step - loss: 0.0010 - val_loss: 8.0599e-04\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 194us/step - loss: 0.0011 - val_loss: 8.3982e-04\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 193us/step - loss: 0.0012 - val_loss: 8.9039e-04\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 199us/step - loss: 0.0013 - val_loss: 9.4952e-04\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 199us/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 195us/step - loss: 0.0015 - val_loss: 0.0011207e-\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 193us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 194us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 193us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 195us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 195us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 193us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 194us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 194us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 7s 2ms/step - loss: 0.0196 - val_loss: 0.0086\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 188us/step - loss: 0.0116 - val_loss: 0.0149\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 186us/step - loss: 0.0227 - val_loss: 0.0024\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 187us/step - loss: 0.0362 - val_loss: 0.0023\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 187us/step - loss: 0.0511 - val_loss: 0.0434\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 190us/step - loss: 0.0025 - val_loss: 0.0067\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 187us/step - loss: 0.0051 - val_loss: 8.9921e-04\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 187us/step - loss: 0.0047 - val_loss: 0.0013\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 187us/step - loss: 0.0046 - val_loss: 0.0034\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 187us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 192us/step - loss: 9.8426e-04 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 191us/step - loss: 7.9892e-04 - val_loss: 7.3943e-04\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 187us/step - loss: 8.7039e-04 - val_loss: 7.3924e-04\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 188us/step - loss: 6.9837e-04 - val_loss: 9.1439e-04\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 186us/step - loss: 6.6070e-04 - val_loss: 6.9494e-04\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 187us/step - loss: 6.4228e-04 - val_loss: 7.1687e-04\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 187us/step - loss: 6.3700e-04 - val_loss: 7.4108e-04\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 187us/step - loss: 6.3860e-04 - val_loss: 6.9306e-04\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 187us/step - loss: 6.2465e-04 - val_loss: 7.2735e-04\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 187us/step - loss: 6.2367e-04 - val_loss: 6.9547e-04\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 186us/step - loss: 6.1832e-04 - val_loss: 7.0360e-04\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 187us/step - loss: 6.1548e-04 - val_loss: 6.9653e-04\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 186us/step - loss: 6.1326e-04 - val_loss: 6.9187e-04\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 187us/step - loss: 6.0915e-04 - val_loss: 6.9169e-04\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 8s 2ms/step - loss: 0.4062 - val_loss: 0.0106\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 385us/step - loss: 0.1698 - val_loss: 0.0317\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 381us/step - loss: 0.1636 - val_loss: 0.0766\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 380us/step - loss: 0.0355 - val_loss: 0.0073\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 376us/step - loss: 0.0158 - val_loss: 0.0118\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 376us/step - loss: 0.0077 - val_loss: 0.0024\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 376us/step - loss: 0.0063 - val_loss: 0.0038\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 377us/step - loss: 0.0064 - val_loss: 0.0021\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 377us/step - loss: 0.0047 - val_loss: 0.0053\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 376us/step - loss: 0.0066 - val_loss: 0.0020\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 375us/step - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 373us/step - loss: 0.0058 - val_loss: 0.0019\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 379us/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 382us/step - loss: 0.0065 - val_loss: 0.0019\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 378us/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 376us/step - loss: 0.0060 - val_loss: 0.0018\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 377us/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 376us/step - loss: 0.0060 - val_loss: 0.0018\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 374us/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 377us/step - loss: 0.0058 - val_loss: 0.0017\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 376us/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 375us/step - loss: 0.0059 - val_loss: 0.0017\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 377us/step - loss: 0.0045 - val_loss: 0.0040\n",
      "Epoch 24/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3556/3556 [==============================] - 1s 377us/step - loss: 0.0061 - val_loss: 0.0016\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 9s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 395us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 395us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 397us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 395us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 396us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 397us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 397us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 397us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 404us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 397us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 402us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 398us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 395us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 394us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 394us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 395us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 395us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 396us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 393us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 395us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 392us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 399us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 394us/step - loss: nan - val_loss: nan\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 9s 2ms/step - loss: 0.5713 - val_loss: 0.0030\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 395us/step - loss: 0.0723 - val_loss: 0.0134\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 396us/step - loss: 0.0280 - val_loss: 0.0126\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 397us/step - loss: 0.0143 - val_loss: 0.0017\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 396us/step - loss: 0.0075 - val_loss: 0.0017\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 397us/step - loss: 0.0047 - val_loss: 0.0019\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 396us/step - loss: 0.0033 - val_loss: 0.0024\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 399us/step - loss: 0.0029 - val_loss: 0.0015\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 396us/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 397us/step - loss: 0.0025 - val_loss: 0.0015\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 394us/step - loss: 0.0024 - val_loss: 0.0015\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 399us/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 396us/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 397us/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 400us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 400us/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 397us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 397us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 395us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 403us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 395us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 397us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 396us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 396us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 9s 3ms/step - loss: 0.0585 - val_loss: 0.0282\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 413us/step - loss: 0.0153 - val_loss: 0.0205\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 414us/step - loss: 0.0064 - val_loss: 0.0022\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 417us/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 420us/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 417us/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 417us/step - loss: 0.0021 - val_loss: 0.0035\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 416us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 413us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 415us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 416us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 413us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 416us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 415us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 416us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 415us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 413us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 416us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 420us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 418us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 415us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 415us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 413us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 415us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 9s 3ms/step - loss: 0.0662 - val_loss: 0.0471\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 420us/step - loss: 0.0180 - val_loss: 0.0240\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 417us/step - loss: 0.0071 - val_loss: 0.0040\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 414us/step - loss: 0.0044 - val_loss: 0.0094\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 415us/step - loss: 0.0032 - val_loss: 0.0016\n",
      "Epoch 6/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3556/3556 [==============================] - 1s 414us/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 414us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 415us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 416us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 413us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 421us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 415us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 415us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 413us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 414us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 414us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 413us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 413us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 415us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 415us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 417us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 418us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 418us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 415us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 10s 3ms/step - loss: 0.0561 - val_loss: 0.0019\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 485us/step - loss: 0.0080 - val_loss: 0.0081\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 2s 482us/step - loss: 0.0053 - val_loss: 0.0066\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 484us/step - loss: 0.0031 - val_loss: 0.0027\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 2s 495us/step - loss: 0.0025 - val_loss: 0.0015\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 2s 485us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 484us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 484us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 2s 485us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 2s 485us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 2s 488us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 487us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 484us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 2s 489us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 2s 483us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 2s 483us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 2s 485us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 484us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 2s 484us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 2s 485us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 2s 484us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 2s 490us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 2s 485us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 2s 486us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 10s 3ms/step - loss: 0.0808 - val_loss: 0.0257\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 487us/step - loss: 0.0119 - val_loss: 0.0018\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 2s 485us/step - loss: 0.0057 - val_loss: 0.0067\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 491us/step - loss: 0.0038 - val_loss: 0.0024\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 2s 487us/step - loss: 0.0031 - val_loss: 0.0062\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 2s 489us/step - loss: 0.0024 - val_loss: 0.0015\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 487us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 488us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 2s 486us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 2s 485us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 2s 485us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 486us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 485us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 2s 486us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 2s 489us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 2s 485us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 2s 486us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 486us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 2s 484us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 2s 484us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 2s 491us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 2s 484us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 2s 485us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 2s 487us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "\n",
      "GENERATION 9\n",
      "\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 8s 2ms/step - loss: 0.0131 - val_loss: 0.0022\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 188us/step - loss: 0.0086 - val_loss: 0.0024\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 192us/step - loss: 0.0126 - val_loss: 9.0154e-04\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 186us/step - loss: 0.0215 - val_loss: 0.0119\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 188us/step - loss: 0.0024 - val_loss: 0.0056\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 189us/step - loss: 0.0022 - val_loss: 9.4368e-04\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 194us/step - loss: 8.9699e-04 - val_loss: 0.0011\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 191us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 188us/step - loss: 0.0012 - val_loss: 8.6856e-04\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 189us/step - loss: 0.0012 - val_loss: 0.0013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 186us/step - loss: 0.0016 - val_loss: 8.0915e-04\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 188us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 188us/step - loss: 0.0020 - val_loss: 8.5181e-04\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 189us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 188us/step - loss: 0.0017 - val_loss: 8.5488e-04\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 188us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 190us/step - loss: 0.0011 - val_loss: 7.7771e-04\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 187us/step - loss: 8.7279e-04 - val_loss: 0.0013\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 191us/step - loss: 8.5294e-04 - val_loss: 7.8533e-04\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 191us/step - loss: 7.5361e-04 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 189us/step - loss: 7.5901e-04 - val_loss: 8.0441e-04\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 187us/step - loss: 7.0433e-04 - val_loss: 9.3363e-04\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 193us/step - loss: 7.2072e-04 - val_loss: 8.0528e-04\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 188us/step - loss: 6.8224e-04 - val_loss: 8.3810e-04\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 9s 2ms/step - loss: 0.0192 - val_loss: 0.0058\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 189us/step - loss: 0.0069 - val_loss: 0.0124\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 187us/step - loss: 0.0100 - val_loss: 0.0066\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 187us/step - loss: 0.0101 - val_loss: 0.0038\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 187us/step - loss: 0.0389 - val_loss: 0.0106\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 187us/step - loss: 0.0205 - val_loss: 0.0090\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 187us/step - loss: 0.0192 - val_loss: 0.0118\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 185us/step - loss: 0.0030 - val_loss: 0.0058\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 186us/step - loss: 0.0023 - val_loss: 0.0010\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 186us/step - loss: 0.0016 - val_loss: 8.5409e-04\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 188us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 187us/step - loss: 7.7313e-04 - val_loss: 7.3545e-04\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 186us/step - loss: 7.4392e-04 - val_loss: 7.9796e-04\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 197us/step - loss: 7.3232e-04 - val_loss: 9.1255e-04\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 188us/step - loss: 7.1630e-04 - val_loss: 7.2259e-04\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 186us/step - loss: 6.7187e-04 - val_loss: 8.3143e-04\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 188us/step - loss: 6.7188e-04 - val_loss: 7.5766e-04\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 187us/step - loss: 6.6876e-04 - val_loss: 7.5428e-04\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 187us/step - loss: 6.5999e-04 - val_loss: 7.7588e-04\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 187us/step - loss: 6.6059e-04 - val_loss: 7.4065e-04\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 187us/step - loss: 6.5196e-04 - val_loss: 7.6006e-04\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 185us/step - loss: 6.5063e-04 - val_loss: 7.3715e-04\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 187us/step - loss: 6.4481e-04 - val_loss: 7.4215e-04\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 185us/step - loss: 6.4206e-04 - val_loss: 7.3051e-04\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 9s 3ms/step - loss: 0.2196 - val_loss: 0.0099\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 193us/step - loss: 0.1512 - val_loss: 0.0310\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 191us/step - loss: 0.2475 - val_loss: 0.0012\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 190us/step - loss: 0.1092 - val_loss: 0.0619\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 200us/step - loss: 0.0739 - val_loss: 0.0570\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 192us/step - loss: 0.0057 - val_loss: 0.0091\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 190us/step - loss: 0.0155 - val_loss: 0.0189\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 193us/step - loss: 0.0036 - val_loss: 0.0014\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 189us/step - loss: 0.0044 - val_loss: 0.0020\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 191us/step - loss: 0.0028 - val_loss: 0.0069\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 192us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 190us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 191us/step - loss: 0.0011 - val_loss: 0.0029\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 191us/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 192us/step - loss: 9.2803e-04 - val_loss: 0.0015\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 190us/step - loss: 8.6915e-04 - val_loss: 0.0019\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 190us/step - loss: 8.1280e-04 - val_loss: 0.0014\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 190us/step - loss: 7.6557e-04 - val_loss: 0.0015\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 192us/step - loss: 7.3454e-04 - val_loss: 0.0015\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 191us/step - loss: 7.1025e-04 - val_loss: 0.0013\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 189us/step - loss: 6.8615e-04 - val_loss: 0.0014\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 191us/step - loss: 6.7009e-04 - val_loss: 0.0013\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 193us/step - loss: 6.5584e-04 - val_loss: 0.0013\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 193us/step - loss: 6.4353e-04 - val_loss: 0.0012\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 10s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 381us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 379us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 381us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 378us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 381us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 378us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 381us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 380us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 396us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 379us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 383us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 380us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3556/3556 [==============================] - 1s 379us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 379us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 380us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 381us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 382us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 384us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 379us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 381us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 386us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 379us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 380us/step - loss: nan - val_loss: nan\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 11s 3ms/step - loss: 0.1711 - val_loss: 0.1216\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 438us/step - loss: 0.0458 - val_loss: 0.0043\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 2s 439us/step - loss: 0.0234 - val_loss: 0.0029\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 444us/step - loss: 0.0068 - val_loss: 0.0043\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 2s 443us/step - loss: 0.0039 - val_loss: 0.0062\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 2s 438us/step - loss: 0.0031 - val_loss: 0.0049\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 439us/step - loss: 0.0030 - val_loss: 0.0077\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 440us/step - loss: 0.0027 - val_loss: 0.0058\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 2s 440us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 2s 439us/step - loss: 0.0042 - val_loss: 0.0191\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 2s 439us/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 448us/step - loss: 0.0024 - val_loss: 0.0052\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 438us/step - loss: 0.0023 - val_loss: 0.0062\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 2s 440us/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 2s 444us/step - loss: 0.0022 - val_loss: 0.0052\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 2s 440us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 2s 439us/step - loss: 0.0032 - val_loss: 0.0077\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 440us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 2s 439us/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 2s 441us/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 2s 438us/step - loss: 0.0018 - val_loss: 0.0033\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 2s 439us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 2s 439us/step - loss: 0.0021 - val_loss: 0.0067\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 2s 440us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 11s 3ms/step - loss: 0.2409 - val_loss: 0.0077\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 461us/step - loss: 0.0310 - val_loss: 0.0189\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 2s 459us/step - loss: 0.0089 - val_loss: 0.0061\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 459us/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 2s 458us/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 2s 458us/step - loss: 0.0022 - val_loss: 0.0057\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 463us/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 459us/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 2s 459us/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 2s 457us/step - loss: 0.0019 - val_loss: 0.0035\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 2s 464us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 461us/step - loss: 0.0025 - val_loss: 0.0056\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 459us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 2s 458us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 2s 460us/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 2s 463us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 2s 461us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 462us/step - loss: 0.0019 - val_loss: 0.0058\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 2s 462us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 2s 458us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 2s 459us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 2s 461us/step - loss: 0.0016 - val_loss: 0.0033\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 2s 459us/step - loss: 0.0015 - val_loss: 0.0029\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 2s 459us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 11s 3ms/step - loss: 0.1719 - val_loss: 0.0241\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 459us/step - loss: 0.0285 - val_loss: 0.0329\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 2s 459us/step - loss: 0.0105 - val_loss: 0.0076\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 458us/step - loss: 0.0028 - val_loss: 0.0060\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 2s 459us/step - loss: 0.0027 - val_loss: 0.0058\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 2s 459us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 458us/step - loss: 0.0025 - val_loss: 0.0042\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 462us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 2s 458us/step - loss: 0.0027 - val_loss: 0.0043\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 2s 464us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 2s 457us/step - loss: 0.0020 - val_loss: 0.0050\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 456us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 457us/step - loss: 0.0028 - val_loss: 0.0095\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 2s 458us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 2s 458us/step - loss: 0.0023 - val_loss: 0.0097\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 2s 457us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 2s 459us/step - loss: 0.0020 - val_loss: 0.0062\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 461us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 19/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3556/3556 [==============================] - 2s 463us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 2s 460us/step - loss: 0.0021 - val_loss: 0.0057\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 2s 461us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 2s 457us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 2s 459us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 2s 461us/step - loss: 0.0020 - val_loss: 0.0072\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 11s 3ms/step - loss: 0.0666 - val_loss: 0.0067\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 461us/step - loss: 0.0095 - val_loss: 0.0154\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 2s 457us/step - loss: 0.0057 - val_loss: 0.0025\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 459us/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 2s 459us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 2s 460us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 459us/step - loss: 0.0020 - val_loss: 0.0032\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 462us/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 2s 471us/step - loss: 0.0019 - val_loss: 0.0035\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 2s 458us/step - loss: 0.0018 - val_loss: 0.0035\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 2s 459us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 460us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 459us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 2s 459us/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 2s 463us/step - loss: 0.0016 - val_loss: 0.0026\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 2s 464us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 2s 460us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 461us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 2s 463us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 2s 459us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 2s 459us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 2s 458us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 2s 459us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 2s 459us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 11s 3ms/step - loss: 0.0587 - val_loss: 0.0028\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 461us/step - loss: 0.0111 - val_loss: 0.0098\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 2s 460us/step - loss: 0.0074 - val_loss: 0.0018\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 460us/step - loss: 0.0048 - val_loss: 0.0035\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 2s 459us/step - loss: 0.0030 - val_loss: 0.0085\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 2s 463us/step - loss: 0.0022 - val_loss: 0.0036\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 467us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 459us/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 2s 465us/step - loss: 0.0019 - val_loss: 0.0037\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 2s 462us/step - loss: 0.0018 - val_loss: 0.0034\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 2s 459us/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 458us/step - loss: 0.0017 - val_loss: 0.0026\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 461us/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 2s 459us/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 2s 462us/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 2s 462us/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 2s 462us/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 459us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 2s 462us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 2s 459us/step - loss: 0.0016 - val_loss: 0.0030\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 2s 462us/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 2s 459us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 2s 460us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 2s 458us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "\n",
      "GENERATION 10\n",
      "\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 10s 3ms/step - loss: 0.0286 - val_loss: 0.0015\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 186us/step - loss: 0.0058 - val_loss: 0.0064\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 189us/step - loss: 0.0244 - val_loss: 0.0027\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 190us/step - loss: 0.0491 - val_loss: 0.0043\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 189us/step - loss: 0.0614 - val_loss: 0.0507\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 186us/step - loss: 0.0048 - val_loss: 0.0123\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 187us/step - loss: 0.0051 - val_loss: 8.2498e-04\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 188us/step - loss: 0.0063 - val_loss: 0.0024\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 189us/step - loss: 0.0032 - val_loss: 0.0048\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 188us/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 188us/step - loss: 0.0010 - val_loss: 7.5227e-04\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 197us/step - loss: 9.9655e-04 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 186us/step - loss: 7.9166e-04 - val_loss: 7.2587e-04\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 187us/step - loss: 7.1301e-04 - val_loss: 8.3974e-04\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 188us/step - loss: 7.1139e-04 - val_loss: 8.8604e-04\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 188us/step - loss: 7.1005e-04 - val_loss: 7.3318e-04\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 188us/step - loss: 6.7362e-04 - val_loss: 8.3273e-04\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 189us/step - loss: 6.7202e-04 - val_loss: 7.6923e-04\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 188us/step - loss: 6.6807e-04 - val_loss: 7.6030e-04\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 190us/step - loss: 6.5848e-04 - val_loss: 7.7913e-04\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 189us/step - loss: 6.5715e-04 - val_loss: 7.4496e-04\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 187us/step - loss: 6.4849e-04 - val_loss: 7.5755e-04\n",
      "Epoch 23/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3556/3556 [==============================] - 1s 189us/step - loss: 6.4528e-04 - val_loss: 7.3908e-04\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 195us/step - loss: 6.3966e-04 - val_loss: 7.3752e-04\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 10s 3ms/step - loss: 0.0168 - val_loss: 0.0078\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 189us/step - loss: 0.0129 - val_loss: 0.0155\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 192us/step - loss: 0.0412 - val_loss: 0.0019\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 188us/step - loss: 0.0428 - val_loss: 0.0098\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 191us/step - loss: 0.0318 - val_loss: 0.0313\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 190us/step - loss: 0.0023 - val_loss: 0.0056\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 188us/step - loss: 0.0053 - val_loss: 0.0018\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 190us/step - loss: 0.0040 - val_loss: 0.0035\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 190us/step - loss: 8.1500e-04 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 188us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 188us/step - loss: 9.1729e-04 - val_loss: 7.7878e-04\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 190us/step - loss: 6.7941e-04 - val_loss: 8.6234e-04\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 194us/step - loss: 7.0849e-04 - val_loss: 9.9809e-04\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 189us/step - loss: 6.5530e-04 - val_loss: 6.6961e-04\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 190us/step - loss: 6.0953e-04 - val_loss: 8.0332e-04\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 191us/step - loss: 6.1017e-04 - val_loss: 7.9485e-04\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 188us/step - loss: 6.1135e-04 - val_loss: 7.0477e-04\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 188us/step - loss: 5.9565e-04 - val_loss: 7.7467e-04\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 190us/step - loss: 5.9426e-04 - val_loss: 7.3615e-04\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 190us/step - loss: 5.9235e-04 - val_loss: 7.2549e-04\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 187us/step - loss: 5.8717e-04 - val_loss: 7.4156e-04\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 188us/step - loss: 5.8564e-04 - val_loss: 7.1702e-04\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 190us/step - loss: 5.8160e-04 - val_loss: 7.2296e-04\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 188us/step - loss: 5.7888e-04 - val_loss: 7.1397e-04\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 10s 3ms/step - loss: 0.0263 - val_loss: 0.0041\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 197us/step - loss: 0.0050 - val_loss: 0.0055\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 192us/step - loss: 0.0050 - val_loss: 0.0013\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 190us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 190us/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 190us/step - loss: 0.0079 - val_loss: 0.0045\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 190us/step - loss: 0.0245 - val_loss: 0.0044\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 192us/step - loss: 0.0745 - val_loss: 0.0381\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 191us/step - loss: 0.0182 - val_loss: 0.0108\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 191us/step - loss: 0.0114 - val_loss: 0.0067\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 190us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 192us/step - loss: 0.0017 - val_loss: 6.7929e-04\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 189us/step - loss: 0.0013 - val_loss: 7.8039e-04\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 192us/step - loss: 9.0240e-04 - val_loss: 0.0014\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 190us/step - loss: 6.8345e-04 - val_loss: 6.9569e-04\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 191us/step - loss: 7.2967e-04 - val_loss: 6.9560e-04\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 192us/step - loss: 6.7549e-04 - val_loss: 8.8313e-04\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 192us/step - loss: 6.6228e-04 - val_loss: 6.8321e-04\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 190us/step - loss: 6.4091e-04 - val_loss: 7.3599e-04\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 191us/step - loss: 6.3584e-04 - val_loss: 7.4006e-04\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 192us/step - loss: 6.3476e-04 - val_loss: 6.9659e-04\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 192us/step - loss: 6.2266e-04 - val_loss: 7.2949e-04\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 190us/step - loss: 6.1945e-04 - val_loss: 7.0040e-04\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 192us/step - loss: 6.1398e-04 - val_loss: 7.0175e-04\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 11s 3ms/step - loss: 0.0253 - val_loss: 0.0035\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 260us/step - loss: 0.0069 - val_loss: 0.0111\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 0.0186 - val_loss: 0.0036\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 0.0285 - val_loss: 9.1129e-04\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 250us/step - loss: 0.0508 - val_loss: 0.0329\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 251us/step - loss: 0.0039 - val_loss: 0.0078\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 0.0042 - val_loss: 0.0016\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 251us/step - loss: 6.3489e-04 - val_loss: 0.0011\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 7.3211e-04 - val_loss: 6.8581e-04\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 261us/step - loss: 8.0207e-04 - val_loss: 6.6890e-04\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 256us/step - loss: 8.7362e-04 - val_loss: 8.3417e-04\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 0.0011 - val_loss: 6.0737e-04\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 0.0011 - val_loss: 8.6326e-04\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 0.0016 - val_loss: 5.9327e-04\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 251us/step - loss: 0.0017 - val_loss: 9.8555e-04\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 0.0024 - val_loss: 6.7494e-04\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 0.0025 - val_loss: 0.0014\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 251us/step - loss: 0.0030 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 0.0017 - val_loss: 9.7195e-04\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 8.1208e-04 - val_loss: 0.0013\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 256us/step - loss: 6.7134e-04 - val_loss: 5.8375e-04\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 254us/step - loss: 5.6135e-04 - val_loss: 7.0511e-04\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 256us/step - loss: 5.6443e-04 - val_loss: 6.5443e-04\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3556/3556 [==============================] - 11s 3ms/step - loss: 0.0537 - val_loss: 0.0406\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 259us/step - loss: 0.0124 - val_loss: 0.0185\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 250us/step - loss: 0.0049 - val_loss: 0.0058\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 0.0016 - val_loss: 8.0830e-04\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 251us/step - loss: 0.0011 - val_loss: 9.1007e-04\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 250us/step - loss: 8.2716e-04 - val_loss: 8.2269e-04\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 249us/step - loss: 7.4393e-04 - val_loss: 7.2857e-04\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 6.8381e-04 - val_loss: 8.3156e-04\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 6.6067e-04 - val_loss: 7.2825e-04\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 250us/step - loss: 6.3912e-04 - val_loss: 7.7415e-04\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 6.2732e-04 - val_loss: 7.2254e-04\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 255us/step - loss: 6.2106e-04 - val_loss: 7.2737e-04\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 251us/step - loss: 6.1448e-04 - val_loss: 7.2511e-04\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 251us/step - loss: 6.0715e-04 - val_loss: 6.8919e-04\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 250us/step - loss: 6.0198e-04 - val_loss: 7.0360e-04\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 250us/step - loss: 5.9482e-04 - val_loss: 6.8855e-04\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 251us/step - loss: 5.8736e-04 - val_loss: 6.8672e-04\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 249us/step - loss: 5.8215e-04 - val_loss: 6.7021e-04\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 251us/step - loss: 5.7619e-04 - val_loss: 6.4348e-04\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 250us/step - loss: 5.6993e-04 - val_loss: 6.4689e-04\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 250us/step - loss: 5.6444e-04 - val_loss: 6.4038e-04\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 251us/step - loss: 5.5875e-04 - val_loss: 6.1519e-04\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 251us/step - loss: 5.5331e-04 - val_loss: 6.4952e-04\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 12s 4ms/step - loss: 0.1138 - val_loss: 0.0757\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 560us/step - loss: 0.0219 - val_loss: 0.0243\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 2s 558us/step - loss: 0.0090 - val_loss: 0.0090\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 552us/step - loss: 0.0055 - val_loss: 0.0082\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 2s 551us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 2s 556us/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 553us/step - loss: 0.0027 - val_loss: 0.0014\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 551us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 2s 551us/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 2s 550us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 2s 551us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 553us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 552us/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 2s 554us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 2s 555us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 2s 558us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 2s 553us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 554us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 2s 554us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 2s 554us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 2s 554us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 2s 553us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 2s 558us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 2s 557us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 13s 4ms/step - loss: 0.0459 - val_loss: 0.0041\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 554us/step - loss: 0.0079 - val_loss: 0.0097\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 2s 550us/step - loss: 0.0056 - val_loss: 0.0039\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 555us/step - loss: 0.0035 - val_loss: 0.0016\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 2s 553us/step - loss: 0.0030 - val_loss: 0.0015\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 2s 553us/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 554us/step - loss: 0.0024 - val_loss: 0.0013\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 552us/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 2s 552us/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 2s 555us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 2s 554us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 556us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 553us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 2s 553us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 2s 552us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 2s 555us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 2s 553us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 552us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 2s 551us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 2s 552us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 2s 552us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 2s 552us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 2s 564us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 2s 552us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 13s 4ms/step - loss: 0.1793 - val_loss: 0.0025\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 555us/step - loss: 0.0067 - val_loss: 0.0457\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 2s 551us/step - loss: 0.0123 - val_loss: 0.0095\n",
      "Epoch 4/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3556/3556 [==============================] - 2s 556us/step - loss: 0.0122 - val_loss: 0.0096\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 2s 563us/step - loss: 0.0094 - val_loss: 0.0160\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 2s 554us/step - loss: 0.0109 - val_loss: 0.0164\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 551us/step - loss: 0.0107 - val_loss: 0.0169\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 551us/step - loss: 0.0125 - val_loss: 0.0134\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 2s 553us/step - loss: 0.0120 - val_loss: 0.0160\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 2s 558us/step - loss: 0.0115 - val_loss: 0.0076\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 2s 556us/step - loss: 0.0070 - val_loss: 0.0084\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 553us/step - loss: 0.0115 - val_loss: 0.0456\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 556us/step - loss: 0.0124 - val_loss: 0.0026\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 2s 553us/step - loss: 0.0032 - val_loss: 0.0091\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 2s 553us/step - loss: 0.0084 - val_loss: 0.0105\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 2s 552us/step - loss: 0.0093 - val_loss: 0.0181\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 2s 553us/step - loss: 0.0083 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 553us/step - loss: 0.0031 - val_loss: 0.0097\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 2s 553us/step - loss: 0.0113 - val_loss: 0.0126\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 2s 556us/step - loss: 0.0047 - val_loss: 0.0010\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 2s 558us/step - loss: 0.0025 - val_loss: 0.0157\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 2s 552us/step - loss: 0.0138 - val_loss: 0.0024\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 2s 554us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 2s 553us/step - loss: 0.0039 - val_loss: 0.0140\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 12s 4ms/step - loss: 0.0989 - val_loss: 0.0021\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 380us/step - loss: 0.0048 - val_loss: 0.0037\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 379us/step - loss: 0.0106 - val_loss: 0.0191\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 376us/step - loss: 0.0116 - val_loss: 0.0079\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 376us/step - loss: 0.0117 - val_loss: 0.0071\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 375us/step - loss: 0.0108 - val_loss: 0.0083\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 377us/step - loss: 0.0091 - val_loss: 0.0212\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 374us/step - loss: 0.0105 - val_loss: 0.0101\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 378us/step - loss: 0.0093 - val_loss: 0.0063\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 381us/step - loss: 0.0083 - val_loss: 0.0072\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 383us/step - loss: 0.0088 - val_loss: 0.0122\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 377us/step - loss: 0.0082 - val_loss: 0.0049\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 377us/step - loss: 0.0063 - val_loss: 0.0105\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 379us/step - loss: 0.0086 - val_loss: 0.0137\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 376us/step - loss: 0.0064 - val_loss: 0.0042\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 377us/step - loss: 0.0064 - val_loss: 0.0078\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 375us/step - loss: 0.0065 - val_loss: 0.0062\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 387us/step - loss: 0.0073 - val_loss: 0.0045ETA: 0s - loss: 0.0\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 377us/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 378us/step - loss: 0.0085 - val_loss: 0.0109\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 376us/step - loss: 0.0047 - val_loss: 0.0010\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 378us/step - loss: 0.0039 - val_loss: 0.0113\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 386us/step - loss: 0.0058 - val_loss: 0.0022\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 378us/step - loss: 0.0054 - val_loss: 0.0065\n",
      "\n",
      "GENERATION 11\n",
      "\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 13s 4ms/step - loss: 0.1202 - val_loss: 0.0103\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 512us/step - loss: 0.0129 - val_loss: 0.0028\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 2s 519us/step - loss: 0.0063 - val_loss: 0.0055\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 514us/step - loss: 0.0032 - val_loss: 0.0056\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 2s 512us/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 2s 512us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 510us/step - loss: 0.0017 - val_loss: 0.0031\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 511us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 2s 510us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 2s 518us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 2s 514us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 512us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 522us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 2s 512us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 2s 511us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 2s 512us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 2s 510us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 511us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 2s 517us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 2s 511us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 2s 513us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 2s 512us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 2s 513us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 2s 510us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 12s 3ms/step - loss: 0.1121 - val_loss: 0.0137\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 251us/step - loss: 0.0185 - val_loss: 0.0029\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 0.0078 - val_loss: 0.0021\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 0.0019 - val_loss: 0.0049\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 0.0015 - val_loss: 8.1801e-04\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 0.0012 - val_loss: 9.3272e-04\n",
      "Epoch 8/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3556/3556 [==============================] - 1s 251us/step - loss: 9.4174e-04 - val_loss: 0.0014\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 251us/step - loss: 8.5469e-04 - val_loss: 7.4318e-04\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 250us/step - loss: 7.9363e-04 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 251us/step - loss: 7.7425e-04 - val_loss: 7.7973e-04\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 7.5434e-04 - val_loss: 9.7275e-04\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 255us/step - loss: 7.3781e-04 - val_loss: 8.2935e-04\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 7.2127e-04 - val_loss: 8.6801e-04\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 257us/step - loss: 7.0847e-04 - val_loss: 8.4147e-04\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 6.9768e-04 - val_loss: 8.0765e-04\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 6.8841e-04 - val_loss: 8.1987e-04\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 6.7825e-04 - val_loss: 7.8209e-04\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 251us/step - loss: 6.6992e-04 - val_loss: 8.0214e-04\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 6.6074e-04 - val_loss: 7.5432e-04\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 6.5257e-04 - val_loss: 7.6810e-04\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 6.4452e-04 - val_loss: 7.2669e-04\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 6.3749e-04 - val_loss: 7.5535e-04\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 6.3019e-04 - val_loss: 7.0333e-04\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 12s 3ms/step - loss: 0.1009 - val_loss: 0.0409\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 0.0097 - val_loss: 0.0131\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 0.0063 - val_loss: 9.0756e-04\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 251us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 255us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 254us/step - loss: 8.3344e-04 - val_loss: 8.3008e-04\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 8.5632e-04 - val_loss: 8.4860e-04\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 255us/step - loss: 7.5399e-04 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 7.6696e-04 - val_loss: 9.6053e-04\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 7.3884e-04 - val_loss: 8.7515e-04\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 255us/step - loss: 7.3607e-04 - val_loss: 9.0962e-04\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 254us/step - loss: 7.3195e-04 - val_loss: 9.5071e-04\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 7.2985e-04 - val_loss: 9.0035e-04\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 7.2708e-04 - val_loss: 8.8956e-04\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 7.2581e-04 - val_loss: 9.2176e-04\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 7.2153e-04 - val_loss: 8.8341e-04\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 251us/step - loss: 7.1927e-04 - val_loss: 8.8120e-04\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 7.1676e-04 - val_loss: 9.0021e-04\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 7.1465e-04 - val_loss: 8.9394e-04\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 7.1241e-04 - val_loss: 8.7311e-04\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 257us/step - loss: 7.1004e-04 - val_loss: 8.8194e-04\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 251us/step - loss: 7.0790e-04 - val_loss: 8.7943e-04\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 254us/step - loss: 7.0533e-04 - val_loss: 8.6125e-04\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 12s 3ms/step - loss: 1.7670 - val_loss: 0.1376\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 259us/step - loss: 0.0760 - val_loss: 0.0973\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 260us/step - loss: 0.0249 - val_loss: 0.0289\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 258us/step - loss: 0.0136 - val_loss: 0.0307\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 257us/step - loss: 0.0087 - val_loss: 0.0041\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 0.0030 - val_loss: 0.0019\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 0.0022 - val_loss: 0.0053\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 257us/step - loss: 0.0019 - val_loss: 0.0033\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 259us/step - loss: 0.0012 - val_loss: 8.4464e-04\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 259us/step - loss: 0.0011 - val_loss: 0.0024\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 0.0010 - val_loss: 0.0027\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 257us/step - loss: 9.1798e-04 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 257us/step - loss: 8.7709e-04 - val_loss: 0.0018\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 258us/step - loss: 8.3360e-04 - val_loss: 0.0019\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 259us/step - loss: 8.0146e-04 - val_loss: 0.0015\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 258us/step - loss: 7.8117e-04 - val_loss: 0.0016\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 260us/step - loss: 7.6300e-04 - val_loss: 0.0016\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 259us/step - loss: 7.4955e-04 - val_loss: 0.0015\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 257us/step - loss: 7.3915e-04 - val_loss: 0.0014\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 261us/step - loss: 7.2898e-04 - val_loss: 0.0015\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 259us/step - loss: 7.2128e-04 - val_loss: 0.0014\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 258us/step - loss: 7.1465e-04 - val_loss: 0.0013\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 259us/step - loss: 7.0782e-04 - val_loss: 0.0014\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 258us/step - loss: 7.0164e-04 - val_loss: 0.0013\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 14s 4ms/step - loss: 2.7800 - val_loss: 0.3393\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 532us/step - loss: 0.1326 - val_loss: 0.1326\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 2s 532us/step - loss: 0.0520 - val_loss: 0.0259\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 537us/step - loss: 0.0219 - val_loss: 0.0206\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 2s 530us/step - loss: 0.0077 - val_loss: 0.0021\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 2s 532us/step - loss: 0.0055 - val_loss: 0.0115\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 532us/step - loss: 0.0043 - val_loss: 0.0077\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 539us/step - loss: 0.0027 - val_loss: 0.0022\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 2s 531us/step - loss: 0.0024 - val_loss: 0.0050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 2s 532us/step - loss: 0.0020 - val_loss: 0.0063\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 2s 531us/step - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 537us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 533us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 2s 537us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 2s 534us/step - loss: 0.0014 - val_loss: 0.0038\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 2s 532us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 2s 530us/step - loss: 0.0014 - val_loss: 0.0037\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 531us/step - loss: 0.0014 - val_loss: 0.0036\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 2s 531us/step - loss: 0.0013 - val_loss: 0.0037\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 2s 530us/step - loss: 0.0013 - val_loss: 0.0035\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 2s 535us/step - loss: 0.0013 - val_loss: 0.0034\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 2s 530us/step - loss: 0.0013 - val_loss: 0.0035\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 2s 533us/step - loss: 0.0013 - val_loss: 0.0033\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 2s 538us/step - loss: 0.0013 - val_loss: 0.0033\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 14s 4ms/step - loss: 1.5789 - val_loss: 0.0128\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 388us/step - loss: 0.0676 - val_loss: 0.0201\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 389us/step - loss: 0.0270 - val_loss: 0.0032\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 388us/step - loss: 0.0121 - val_loss: 0.0028\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 388us/step - loss: 0.0045 - val_loss: 0.0019\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 389us/step - loss: 0.0022 - val_loss: 0.0061\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 395us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 388us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 389us/step - loss: 0.0017 - val_loss: 0.0032\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 388us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 389us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 388us/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 388us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 390us/step - loss: 0.0016 - val_loss: 0.0026\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 390us/step - loss: 0.0015 - val_loss: 0.0024\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 388us/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 389us/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 390us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 397us/step - loss: 0.0015 - val_loss: 0.0024\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 397us/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 388us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 389us/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 387us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 388us/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 14s 4ms/step - loss: 2.0924 - val_loss: 0.0046\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 388us/step - loss: 0.0861 - val_loss: 0.0040\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 392us/step - loss: 0.0321 - val_loss: 0.0167\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 388us/step - loss: 0.0072 - val_loss: 0.0225\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 389us/step - loss: 0.0069 - val_loss: 0.0049\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 388us/step - loss: 0.0030 - val_loss: 0.0016\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 395us/step - loss: 0.0024 - val_loss: 0.0057\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 388us/step - loss: 0.0020 - val_loss: 0.0048\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 388us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 386us/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 386us/step - loss: 0.0014 - val_loss: 0.0032\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 387us/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 386us/step - loss: 0.0014 - val_loss: 0.0026\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 388us/step - loss: 0.0013 - val_loss: 0.0029\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 389us/step - loss: 0.0013 - val_loss: 0.0026\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 387us/step - loss: 0.0013 - val_loss: 0.0026\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 394us/step - loss: 0.0013 - val_loss: 0.0026\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 389us/step - loss: 0.0013 - val_loss: 0.0026\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 394us/step - loss: 0.0013 - val_loss: 0.0025\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 388us/step - loss: 0.0013 - val_loss: 0.0025\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 387us/step - loss: 0.0013 - val_loss: 0.0025\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 388us/step - loss: 0.0013 - val_loss: 0.0025\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 389us/step - loss: 0.0012 - val_loss: 0.0025\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 388us/step - loss: 0.0012 - val_loss: 0.0025\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 15s 4ms/step - loss: 0.3828 - val_loss: 0.0387\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 542us/step - loss: 0.0278 - val_loss: 0.0143\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 2s 539us/step - loss: 0.0114 - val_loss: 0.0183\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 540us/step - loss: 0.0067 - val_loss: 0.0028\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 2s 544us/step - loss: 0.0038 - val_loss: 0.0016\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 2s 540us/step - loss: 0.0025 - val_loss: 0.0077\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 538us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 541us/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 2s 538us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 2s 543us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 2s 539us/step - loss: 0.0014 - val_loss: 0.0027\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 538us/step - loss: 0.0013 - val_loss: 0.0026\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 540us/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 2s 543us/step - loss: 0.0012 - val_loss: 0.0024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 2s 539us/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 2s 538us/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 2s 540us/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 539us/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 2s 537us/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 2s 539us/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 2s 539us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 2s 542us/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 2s 538us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 2s 539us/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 15s 4ms/step - loss: 0.8967 - val_loss: 0.0686\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 561us/step - loss: 0.0423 - val_loss: 0.0371\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 2s 562us/step - loss: 0.0195 - val_loss: 0.0041\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 561us/step - loss: 0.0130 - val_loss: 0.0044\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 2s 563us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 2s 564us/step - loss: 0.0052 - val_loss: 0.0087\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 560us/step - loss: 0.0034 - val_loss: 0.0025\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 562us/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 2s 562us/step - loss: 0.0028 - val_loss: 0.0039\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 2s 562us/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 2s 563us/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 564us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 561us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 2s 567us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 2s 563us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 2s 567us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 2s 563us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 563us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 2s 561us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 2s 560us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 2s 560us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 2s 567us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 2s 561us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 2s 562us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "\n",
      "GENERATION 12\n",
      "\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 14s 4ms/step - loss: 0.7030 - val_loss: 0.0107\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 257us/step - loss: 0.0976 - val_loss: 0.0700\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 257us/step - loss: 0.0332 - val_loss: 0.0302\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 256us/step - loss: 0.0178 - val_loss: 0.0346\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 259us/step - loss: 0.0086 - val_loss: 0.0048\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 257us/step - loss: 0.0045 - val_loss: 0.0061\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 258us/step - loss: 0.0029 - val_loss: 9.2793e-04\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 258us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 257us/step - loss: 0.0013 - val_loss: 8.0163e-04\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 258us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 261us/step - loss: 9.2393e-04 - val_loss: 8.0434e-04\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 257us/step - loss: 8.4444e-04 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 258us/step - loss: 8.0751e-04 - val_loss: 8.1936e-04\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 269us/step - loss: 7.7176e-04 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 257us/step - loss: 7.3309e-04 - val_loss: 9.4742e-04\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 257us/step - loss: 7.1422e-04 - val_loss: 8.5243e-04\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 257us/step - loss: 6.9770e-04 - val_loss: 0.0010\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 258us/step - loss: 6.8242e-04 - val_loss: 8.5230e-04\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 258us/step - loss: 6.7032e-04 - val_loss: 8.2287e-04\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 258us/step - loss: 6.6355e-04 - val_loss: 0.0010\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 257us/step - loss: 6.5028e-04 - val_loss: 8.2969e-04\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 257us/step - loss: 6.3837e-04 - val_loss: 7.9706e-04\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 258us/step - loss: 6.2965e-04 - val_loss: 8.4311e-04\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 257us/step - loss: 6.2399e-04 - val_loss: 8.9183e-04\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 14s 4ms/step - loss: 0.0807 - val_loss: 0.0221\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 254us/step - loss: 0.0157 - val_loss: 0.0051\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 254us/step - loss: 0.0067 - val_loss: 8.2607e-04\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 0.0032 - val_loss: 0.0017\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 256us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 256us/step - loss: 8.5608e-04 - val_loss: 7.9617e-04\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 255us/step - loss: 7.5149e-04 - val_loss: 7.3595e-04\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 7.3050e-04 - val_loss: 9.2460e-04\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 6.9823e-04 - val_loss: 7.1645e-04\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 254us/step - loss: 6.8826e-04 - val_loss: 8.6329e-04\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 6.6645e-04 - val_loss: 7.1170e-04\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 6.5887e-04 - val_loss: 8.1596e-04\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 254us/step - loss: 6.5279e-04 - val_loss: 7.1071e-04\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 260us/step - loss: 6.4386e-04 - val_loss: 7.5590e-04\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 254us/step - loss: 6.3680e-04 - val_loss: 7.0384e-04\n",
      "Epoch 18/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3556/3556 [==============================] - 1s 254us/step - loss: 6.2728e-04 - val_loss: 7.2398e-04\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 6.1873e-04 - val_loss: 6.9353e-04\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 6.1198e-04 - val_loss: 6.9771e-04\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 258us/step - loss: 6.0580e-04 - val_loss: 6.7403e-04\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 257us/step - loss: 5.9885e-04 - val_loss: 6.7167e-04\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 5.9270e-04 - val_loss: 6.5763e-04\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 254us/step - loss: 5.8661e-04 - val_loss: 6.6413e-04\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 16s 5ms/step - loss: 0.0550 - val_loss: 0.0137\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 316us/step - loss: 0.0073 - val_loss: 0.0065\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 319us/step - loss: 0.0059 - val_loss: 0.0099\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 312us/step - loss: 0.0056 - val_loss: 0.0046\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 317us/step - loss: 0.0046 - val_loss: 0.0110\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 314us/step - loss: 0.0070 - val_loss: 0.0086\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 314us/step - loss: 0.0066 - val_loss: 0.0099\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 313us/step - loss: 0.0055 - val_loss: 0.0057\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 315us/step - loss: 0.0053 - val_loss: 0.0088\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 314us/step - loss: 0.0052 - val_loss: 0.0065\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 314us/step - loss: 0.0063 - val_loss: 0.0089\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 314us/step - loss: 0.0051 - val_loss: 0.0065\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 317us/step - loss: 0.0043 - val_loss: 0.0068\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 313us/step - loss: 0.0048 - val_loss: 0.0068\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 313us/step - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 314us/step - loss: 0.0050 - val_loss: 0.0063\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 313us/step - loss: 0.0045 - val_loss: 0.0060\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 314us/step - loss: 0.0040 - val_loss: 0.0049\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 318us/step - loss: 0.0047 - val_loss: 0.0076\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 321us/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 316us/step - loss: 0.0050 - val_loss: 0.0113\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 313us/step - loss: 0.0055 - val_loss: 0.0058\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 313us/step - loss: 0.0038 - val_loss: 0.0075\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 322us/step - loss: 0.0045 - val_loss: 0.0062\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 15s 4ms/step - loss: 0.2901 - val_loss: 0.1943\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 335us/step - loss: 0.1032 - val_loss: 0.0728\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 328us/step - loss: 0.0710 - val_loss: 0.0426\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 326us/step - loss: 0.0666 - val_loss: 0.0343\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 326us/step - loss: 0.0654 - val_loss: 0.0324\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 327us/step - loss: 0.0642 - val_loss: 0.0308\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 329us/step - loss: 0.0627 - val_loss: 0.0294\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 327us/step - loss: 0.0604 - val_loss: 0.0284\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 326us/step - loss: 0.0565 - val_loss: 0.0253\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 327us/step - loss: 0.0487 - val_loss: 0.0165\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 326us/step - loss: 0.0366 - val_loss: 0.0076\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 329us/step - loss: 0.0271 - val_loss: 0.0060\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 326us/step - loss: 0.0211 - val_loss: 0.0081\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 327us/step - loss: 0.0171 - val_loss: 0.0114\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 328us/step - loss: 0.0144 - val_loss: 0.0155\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 335us/step - loss: 0.0125 - val_loss: 0.0228\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 330us/step - loss: 0.0115 - val_loss: 0.0234\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 328us/step - loss: 0.0098 - val_loss: 0.0287\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 334us/step - loss: 0.0088 - val_loss: 0.0350\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 328us/step - loss: 0.0080 - val_loss: 0.0210\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 327us/step - loss: 0.0074 - val_loss: 0.0348\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 327us/step - loss: 0.0070 - val_loss: 0.0248\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 328us/step - loss: 0.0064 - val_loss: 0.0299\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 328us/step - loss: 0.0057 - val_loss: 0.0153\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 15s 4ms/step - loss: 0.0709 - val_loss: 0.0447\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 382us/step - loss: 0.0706 - val_loss: 0.0382\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 387us/step - loss: 0.0704 - val_loss: 0.0360\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 384us/step - loss: 0.0702 - val_loss: 0.0325\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 383us/step - loss: 0.0702 - val_loss: 0.0321\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 383us/step - loss: 0.0700 - val_loss: 0.0350\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 381us/step - loss: 0.0698 - val_loss: 0.0384\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 382us/step - loss: 0.0696 - val_loss: 0.0278\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 384us/step - loss: 0.0693 - val_loss: 0.0324\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 384us/step - loss: 0.0687 - val_loss: 0.0332\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 390us/step - loss: 0.0682 - val_loss: 0.0321\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 384us/step - loss: 0.0678 - val_loss: 0.0389\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 384us/step - loss: 0.0670 - val_loss: 0.0276\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 386us/step - loss: 0.0656 - val_loss: 0.0410\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 397us/step - loss: 0.0638 - val_loss: 0.0271\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 385us/step - loss: 0.0603 - val_loss: 0.0258\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 382us/step - loss: 0.0544 - val_loss: 0.0177\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 383us/step - loss: 0.0452 - val_loss: 0.0108\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 382us/step - loss: 0.0346 - val_loss: 0.0065\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 385us/step - loss: 0.0244 - val_loss: 0.0069\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 386us/step - loss: 0.0170 - val_loss: 0.0173\n",
      "Epoch 22/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3556/3556 [==============================] - 1s 384us/step - loss: 0.0131 - val_loss: 0.0273\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 385us/step - loss: 0.0136 - val_loss: 0.0344\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 383us/step - loss: 0.0099 - val_loss: 0.0333\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 16s 4ms/step - loss: 0.6659 - val_loss: 0.6472\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 376us/step - loss: 0.3688 - val_loss: 0.3746\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 386us/step - loss: 0.2097 - val_loss: 0.2187\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 378us/step - loss: 0.1304 - val_loss: 0.1329\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 378us/step - loss: 0.0943 - val_loss: 0.0871\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 379us/step - loss: 0.0794 - val_loss: 0.0627\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 380us/step - loss: 0.0737 - val_loss: 0.0501\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 378us/step - loss: 0.0717 - val_loss: 0.0435\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 385us/step - loss: 0.0710 - val_loss: 0.0396\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 382us/step - loss: 0.0708 - val_loss: 0.0375\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 379us/step - loss: 0.0707 - val_loss: 0.0358\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 380us/step - loss: 0.0706 - val_loss: 0.0354\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 381us/step - loss: 0.0706 - val_loss: 0.0350\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 379us/step - loss: 0.0706 - val_loss: 0.0351\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 377us/step - loss: 0.0706 - val_loss: 0.0354\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 381us/step - loss: 0.0705 - val_loss: 0.0360\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 385us/step - loss: 0.0705 - val_loss: 0.0358\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 378us/step - loss: 0.0705 - val_loss: 0.0346\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 379us/step - loss: 0.0705 - val_loss: 0.0353\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 378us/step - loss: 0.0704 - val_loss: 0.0347\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 380us/step - loss: 0.0704 - val_loss: 0.0325\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 379us/step - loss: 0.0704 - val_loss: 0.0340\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 380us/step - loss: 0.0703 - val_loss: 0.0342\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 383us/step - loss: 0.0702 - val_loss: 0.0368\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 16s 4ms/step - loss: 0.8980 - val_loss: 0.0036\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 379us/step - loss: 0.0162 - val_loss: 0.0025\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 378us/step - loss: 0.0071 - val_loss: 0.0021\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 383us/step - loss: 0.0035 - val_loss: 0.0026\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 376us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 378us/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 379us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 379us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 379us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 384us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 379us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 379us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 379us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 378us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 379us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 379us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 378us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 377us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 384us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 380us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 378us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 384us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 378us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 380us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 16s 5ms/step - loss: 1.1652 - val_loss: 0.0032\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 380us/step - loss: 0.0098 - val_loss: 0.0026\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 379us/step - loss: 0.0049 - val_loss: 0.0026\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 381us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 383us/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 379us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 386us/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 381us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 381us/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 380us/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 381us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 381us/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 378us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 381us/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 387us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 391us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 380us/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 381us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 385us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 388us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 381us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 381us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 384us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 379us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 17s 5ms/step - loss: 1.0221 - val_loss: 0.0030\n",
      "Epoch 2/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3556/3556 [==============================] - 1s 382us/step - loss: 0.0077 - val_loss: 0.0028\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 385us/step - loss: 0.0045 - val_loss: 0.0032\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 378us/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 380us/step - loss: 0.0035 - val_loss: 0.0033\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 381us/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 383us/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 381us/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 381us/step - loss: 0.0033 - val_loss: 0.0029\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 380us/step - loss: 0.0032 - val_loss: 0.0026\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 379us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 379us/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 383us/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 385us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 385us/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 381us/step - loss: 0.0029 - val_loss: 0.0027\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 380us/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 380us/step - loss: 0.0029 - val_loss: 0.0026\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 381us/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 381us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 381us/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 385us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 381us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 380us/step - loss: 0.0028 - val_loss: 0.0024\n",
      "\n",
      "GENERATION 13\n",
      "\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 16s 5ms/step - loss: 0.1286 - val_loss: 0.0096\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 254us/step - loss: 0.0166 - val_loss: 0.0053\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 0.0090 - val_loss: 0.0073\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 254us/step - loss: 0.0045 - val_loss: 0.0018\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 254us/step - loss: 0.0030 - val_loss: 0.0060\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 254us/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 0.0015 - val_loss: 0.0029\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 254us/step - loss: 0.0012 - val_loss: 9.4482e-04\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 254us/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 259us/step - loss: 9.3653e-04 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 8.8995e-04 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 255us/step - loss: 8.4910e-04 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 254us/step - loss: 8.2838e-04 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 254us/step - loss: 8.0916e-04 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 254us/step - loss: 7.8644e-04 - val_loss: 0.0010\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 254us/step - loss: 7.7015e-04 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 257us/step - loss: 7.4754e-04 - val_loss: 0.0010\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 256us/step - loss: 7.3021e-04 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 254us/step - loss: 7.1769e-04 - val_loss: 9.4679e-04\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 254us/step - loss: 7.0558e-04 - val_loss: 9.5657e-04\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 254us/step - loss: 6.9722e-04 - val_loss: 9.9356e-04\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 254us/step - loss: 6.8537e-04 - val_loss: 9.4786e-04\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 6.7309e-04 - val_loss: 8.8173e-04\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 6.6457e-04 - val_loss: 8.6613e-04\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 16s 4ms/step - loss: 0.0874 - val_loss: 0.0208\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 0.0167 - val_loss: 0.0027\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 251us/step - loss: 0.0071 - val_loss: 0.0014\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 251us/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 255us/step - loss: 0.0013 - val_loss: 9.7152e-04\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 251us/step - loss: 8.4080e-04 - val_loss: 8.1781e-04\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 7.1587e-04 - val_loss: 6.8843e-04\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 254us/step - loss: 6.7281e-04 - val_loss: 9.2179e-04\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 254us/step - loss: 6.5809e-04 - val_loss: 6.7994e-04\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 257us/step - loss: 6.4455e-04 - val_loss: 8.3776e-04\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 6.3598e-04 - val_loss: 6.9201e-04\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 6.2419e-04 - val_loss: 7.5669e-04\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 6.1703e-04 - val_loss: 6.9920e-04\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 6.0845e-04 - val_loss: 7.1631e-04\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 251us/step - loss: 6.0256e-04 - val_loss: 6.9491e-04\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 5.9592e-04 - val_loss: 6.9696e-04\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 5.9019e-04 - val_loss: 6.6784e-04\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 5.8443e-04 - val_loss: 6.7735e-04\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 5.7937e-04 - val_loss: 6.6402e-04\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 5.7410e-04 - val_loss: 6.4926e-04\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 254us/step - loss: 5.6905e-04 - val_loss: 6.4358e-04\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 5.6430e-04 - val_loss: 6.4954e-04\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 16s 5ms/step - loss: 0.0734 - val_loss: 0.0013\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 257us/step - loss: 0.0029 - val_loss: 0.0017\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 255us/step - loss: 0.0027 - val_loss: 0.0015\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 258us/step - loss: 0.0026 - val_loss: 0.0037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 257us/step - loss: 0.0024 - val_loss: 0.0011\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 257us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 258us/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 258us/step - loss: 0.0032 - val_loss: 0.0016\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 256us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 256us/step - loss: 0.0017 - val_loss: 8.9044e-04\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 259us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 259us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 259us/step - loss: 0.0033 - val_loss: 0.0015\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 269us/step - loss: 0.0015 - val_loss: 8.2187e-04\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 272us/step - loss: 0.0013 - val_loss: 9.1288e-04\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 270us/step - loss: 0.0013 - val_loss: 7.8828e-04\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 270us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 273us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 0.0020 - val_loss: 0.0010\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 0.0012 - val_loss: 7.4149e-04\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 275us/step - loss: 0.0011 - val_loss: 7.2839e-04\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 0.0011 - val_loss: 8.8676e-04\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 260us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 259us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 17s 5ms/step - loss: 0.0688 - val_loss: 0.0205\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 0.0091 - val_loss: 0.0096\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 0.0034 - val_loss: 7.9486e-04\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 251us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 0.0015 - val_loss: 7.7334e-04\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 0.0015 - val_loss: 7.3865e-04\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 251us/step - loss: 0.0013 - val_loss: 8.0897e-04\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 0.0013 - val_loss: 7.4147e-04\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 0.0013 - val_loss: 8.0637e-04\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 0.0013 - val_loss: 8.2070e-04\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 0.0012 - val_loss: 7.5989e-04\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 256us/step - loss: 0.0012 - val_loss: 7.6685e-04\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 0.0013 - val_loss: 7.6474e-04\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 255us/step - loss: 0.0012 - val_loss: 7.5861e-04\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 255us/step - loss: 0.0013 - val_loss: 7.5552e-04\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 254us/step - loss: 0.0012 - val_loss: 8.0830e-04\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 0.0012 - val_loss: 7.6940e-04\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 0.0012 - val_loss: 7.5201e-04\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 0.0012 - val_loss: 7.5652e-04\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 0.0012 - val_loss: 7.5778e-04\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 0.0011 - val_loss: 7.2991e-04\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 258us/step - loss: 0.0012 - val_loss: 7.7140e-04\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 18s 5ms/step - loss: 0.3260 - val_loss: 0.0371\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 556us/step - loss: 0.0227 - val_loss: 0.0080\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 2s 551us/step - loss: 0.0107 - val_loss: 0.0110\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 553us/step - loss: 0.0069 - val_loss: 0.0079\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 2s 554us/step - loss: 0.0057 - val_loss: 0.0029\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 2s 556us/step - loss: 0.0039 - val_loss: 0.0017\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 554us/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 552us/step - loss: 0.0034 - val_loss: 0.0029\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 2s 556us/step - loss: 0.0032 - val_loss: 0.0020\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 2s 556us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 2s 554us/step - loss: 0.0032 - val_loss: 0.0027\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 552us/step - loss: 0.0031 - val_loss: 0.0024\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 553us/step - loss: 0.0029 - val_loss: 0.0027\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 2s 552us/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 2s 557us/step - loss: 0.0029 - val_loss: 0.0023\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 2s 554us/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 2s 555us/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 556us/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 2s 552us/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 2s 553us/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 2s 553us/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 2s 557us/step - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 2s 553us/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 2s 554us/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 18s 5ms/step - loss: 0.0675 - val_loss: 0.1611\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 555us/step - loss: 0.0258 - val_loss: 0.0046\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 2s 553us/step - loss: 0.0066 - val_loss: 0.0104\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 551us/step - loss: 0.0055 - val_loss: 0.0040\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 2s 554us/step - loss: 0.0070 - val_loss: 0.0146\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 2s 555us/step - loss: 0.0079 - val_loss: 0.0058\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 554us/step - loss: 0.0055 - val_loss: 0.0118\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 558us/step - loss: 0.0054 - val_loss: 0.0059\n",
      "Epoch 9/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3556/3556 [==============================] - 2s 554us/step - loss: 0.0075 - val_loss: 0.0116\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 2s 555us/step - loss: 0.0075 - val_loss: 0.0082\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 2s 554us/step - loss: 0.0067 - val_loss: 0.0096\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 552us/step - loss: 0.0057 - val_loss: 0.0099\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 554us/step - loss: 0.0076 - val_loss: 0.0106\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 2s 557us/step - loss: 0.0060 - val_loss: 0.0096\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 2s 553us/step - loss: 0.0077 - val_loss: 0.0084\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 2s 556us/step - loss: 0.0048 - val_loss: 0.0055\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 2s 553us/step - loss: 0.0070 - val_loss: 0.0076\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 559us/step - loss: 0.0046 - val_loss: 0.0071\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 2s 555us/step - loss: 0.0053 - val_loss: 0.0090\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 2s 554us/step - loss: 0.0057 - val_loss: 0.0038\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 2s 554us/step - loss: 0.0042 - val_loss: 0.0052\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 2s 559us/step - loss: 0.0040 - val_loss: 0.0048\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 2s 560us/step - loss: 0.0055 - val_loss: 0.0091\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 2s 551us/step - loss: 0.0055 - val_loss: 0.0056\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 19s 5ms/step - loss: 0.0842 - val_loss: 0.0063\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 557us/step - loss: 0.0099 - val_loss: 0.0189\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 2s 554us/step - loss: 0.0107 - val_loss: 0.0088\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 554us/step - loss: 0.0072 - val_loss: 0.0061\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 2s 553us/step - loss: 0.0068 - val_loss: 0.0107\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 2s 555us/step - loss: 0.0059 - val_loss: 0.0046\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 555us/step - loss: 0.0044 - val_loss: 0.0064\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 554us/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 2s 560us/step - loss: 0.0049 - val_loss: 0.0072\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 2s 559us/step - loss: 0.0045 - val_loss: 0.0036\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 2s 556us/step - loss: 0.0037 - val_loss: 0.0057\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 553us/step - loss: 0.0043 - val_loss: 0.0065\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 554us/step - loss: 0.0060 - val_loss: 0.0062\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 2s 553us/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 2s 553us/step - loss: 0.0033 - val_loss: 0.0059\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 2s 555us/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 2s 554us/step - loss: 0.0037 - val_loss: 0.0047\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 556us/step - loss: 0.0037 - val_loss: 0.0057\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 2s 556us/step - loss: 0.0054 - val_loss: 0.0085\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 2s 554us/step - loss: 0.0042 - val_loss: 0.0029\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 2s 554us/step - loss: 0.0030 - val_loss: 0.0056\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 2s 555us/step - loss: 0.0039 - val_loss: 0.0034\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 2s 556us/step - loss: 0.0041 - val_loss: 0.0063\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 2s 559us/step - loss: 0.0038 - val_loss: 0.0027\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 19s 5ms/step - loss: 0.1563 - val_loss: 0.1078\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 553us/step - loss: 0.0629 - val_loss: 0.0401\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 2s 549us/step - loss: 0.0382 - val_loss: 0.0185\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 552us/step - loss: 0.0305 - val_loss: 0.0112\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 2s 553us/step - loss: 0.0266 - val_loss: 0.0083\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 2s 553us/step - loss: 0.0236 - val_loss: 0.0066\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 552us/step - loss: 0.0210 - val_loss: 0.0055\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 552us/step - loss: 0.0182 - val_loss: 0.0045\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 2s 551us/step - loss: 0.0159 - val_loss: 0.0038\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 2s 554us/step - loss: 0.0139 - val_loss: 0.0034\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 2s 551us/step - loss: 0.0120 - val_loss: 0.0030\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 549us/step - loss: 0.0103 - val_loss: 0.0028\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 549us/step - loss: 0.0091 - val_loss: 0.0025\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 2s 554us/step - loss: 0.0081 - val_loss: 0.0024\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 2s 550us/step - loss: 0.0071 - val_loss: 0.0023\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 2s 553us/step - loss: 0.0062 - val_loss: 0.0022\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 2s 549us/step - loss: 0.0055 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 550us/step - loss: 0.0048 - val_loss: 0.0022\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 2s 551us/step - loss: 0.0044 - val_loss: 0.0022\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 2s 549us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 2s 551us/step - loss: 0.0037 - val_loss: 0.0023\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 2s 554us/step - loss: 0.0034 - val_loss: 0.0023\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 2s 554us/step - loss: 0.0033 - val_loss: 0.0024\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 2s 551us/step - loss: 0.0031 - val_loss: 0.0025\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 19s 5ms/step - loss: 0.3804 - val_loss: 0.1857\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 559us/step - loss: 0.0963 - val_loss: 0.0476\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 2s 555us/step - loss: 0.0723 - val_loss: 0.0200\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 552us/step - loss: 0.0751 - val_loss: 0.0163\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 2s 553us/step - loss: 0.0754 - val_loss: 0.0195\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 2s 554us/step - loss: 0.0731 - val_loss: 0.0255\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 555us/step - loss: 0.0715 - val_loss: 0.0318\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 556us/step - loss: 0.0710 - val_loss: 0.0363\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 2s 556us/step - loss: 0.0710 - val_loss: 0.0382\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 2s 559us/step - loss: 0.0710 - val_loss: 0.0384\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 2s 558us/step - loss: 0.0710 - val_loss: 0.0375\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 554us/step - loss: 0.0710 - val_loss: 0.0366\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 557us/step - loss: 0.0710 - val_loss: 0.0358\n",
      "Epoch 14/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3556/3556 [==============================] - 2s 553us/step - loss: 0.0710 - val_loss: 0.0353\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 2s 554us/step - loss: 0.0710 - val_loss: 0.0352\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 2s 557us/step - loss: 0.0710 - val_loss: 0.0352\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 2s 554us/step - loss: 0.0710 - val_loss: 0.0353\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 558us/step - loss: 0.0710 - val_loss: 0.0352\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 2s 553us/step - loss: 0.0710 - val_loss: 0.0356\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 2s 555us/step - loss: 0.0710 - val_loss: 0.0356\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 2s 556us/step - loss: 0.0710 - val_loss: 0.0354\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 2s 557us/step - loss: 0.0710 - val_loss: 0.0353\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 2s 555us/step - loss: 0.0710 - val_loss: 0.0356\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 2s 556us/step - loss: 0.0710 - val_loss: 0.0356\n",
      "\n",
      "GENERATION 14\n",
      "\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 19s 5ms/step - loss: 0.0469 - val_loss: 0.0017\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 528us/step - loss: 0.0055 - val_loss: 0.0073\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 2s 530us/step - loss: 0.0039 - val_loss: 0.0066\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 528us/step - loss: 0.0024 - val_loss: 0.0014\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 2s 533us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 2s 530us/step - loss: 0.0014 - val_loss: 0.0022\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 529us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 528us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 2s 528us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 2s 532us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 2s 530us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 534us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 528us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 2s 533us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 2s 528us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 2s 538us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 2s 530us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 528us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 2s 529us/step - loss: 9.9240e-04 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 2s 528us/step - loss: 9.7956e-04 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 2s 530us/step - loss: 9.6380e-04 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 2s 534us/step - loss: 9.5315e-04 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 2s 528us/step - loss: 9.4290e-04 - val_loss: 0.0010\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 2s 529us/step - loss: 9.2991e-04 - val_loss: 0.0010\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 18s 5ms/step - loss: 0.0709 - val_loss: 0.0198\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 0.0150 - val_loss: 0.0039\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 0.0061 - val_loss: 0.0011\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 256us/step - loss: 0.0028 - val_loss: 0.0020\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 251us/step - loss: 0.0012 - val_loss: 8.5651e-04\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 8.8354e-04 - val_loss: 9.6750e-04\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 7.6192e-04 - val_loss: 7.1198e-04\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 7.2060e-04 - val_loss: 0.0010\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 6.9081e-04 - val_loss: 7.2002e-04\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 6.7145e-04 - val_loss: 9.1002e-04\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 254us/step - loss: 6.6018e-04 - val_loss: 7.4218e-04\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 6.5446e-04 - val_loss: 8.2364e-04\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 6.4285e-04 - val_loss: 7.3384e-04\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 6.3794e-04 - val_loss: 7.6838e-04\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 6.2713e-04 - val_loss: 7.2445e-04\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 6.2176e-04 - val_loss: 7.5956e-04\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 251us/step - loss: 6.1481e-04 - val_loss: 6.9232e-04\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 6.0822e-04 - val_loss: 7.3503e-04\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 6.0492e-04 - val_loss: 6.7317e-04\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 256us/step - loss: 5.9550e-04 - val_loss: 7.0688e-04\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 5.9151e-04 - val_loss: 6.5342e-04\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 261us/step - loss: 5.8558e-04 - val_loss: 6.7453e-04\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 19s 5ms/step - loss: 0.2427 - val_loss: 0.1161\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 0.0591 - val_loss: 0.0177\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 258us/step - loss: 0.0146 - val_loss: 0.0066\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 268us/step - loss: 0.0062 - val_loss: 0.0038\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 257us/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 255us/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 255us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 255us/step - loss: 0.0012 - val_loss: 9.6647e-04\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 255us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 257us/step - loss: 0.0011 - val_loss: 9.6385e-04\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 254us/step - loss: 0.0010 - val_loss: 9.0127e-04\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 9.9573e-04 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 9.7273e-04 - val_loss: 9.4019e-04\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 258us/step - loss: 9.4530e-04 - val_loss: 8.7246e-04\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 261us/step - loss: 9.3331e-04 - val_loss: 9.9362e-04\n",
      "Epoch 17/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3556/3556 [==============================] - 1s 255us/step - loss: 9.1128e-04 - val_loss: 9.1709e-04\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 8.9152e-04 - val_loss: 8.8007e-04\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 260us/step - loss: 8.7047e-04 - val_loss: 9.1861e-04\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 8.5482e-04 - val_loss: 8.2248e-04\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 254us/step - loss: 8.3764e-04 - val_loss: 8.4723e-04\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 251us/step - loss: 8.2368e-04 - val_loss: 8.5791e-04\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 260us/step - loss: 8.0743e-04 - val_loss: 7.9286e-04\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 7.9789e-04 - val_loss: 8.0314e-04\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 23s 6ms/step - loss: 0.0373 - val_loss: 0.0136\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 498us/step - loss: 0.0088 - val_loss: 0.0027\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 2s 498us/step - loss: 0.0032 - val_loss: 0.0020\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 515us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 2s 505us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 2s 504us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 510us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 499us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 2s 508us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 2s 509us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 2s 504us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 525us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 496us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 2s 518us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 2s 505us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 2s 513us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 2s 497us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 503us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 2s 504us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 2s 527us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 2s 523us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 2s 512us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 2s 526us/step - loss: 9.8978e-04 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 2s 517us/step - loss: 9.8314e-04 - val_loss: 0.0011\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 23s 7ms/step - loss: 0.4438 - val_loss: 0.1222\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 528us/step - loss: 0.1425 - val_loss: 0.0137\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 2s 518us/step - loss: 0.0729 - val_loss: 0.0917\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 527us/step - loss: 0.0735 - val_loss: 0.0360\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 2s 530us/step - loss: 0.0572 - val_loss: 0.0054\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 2s 531us/step - loss: 0.0378 - val_loss: 0.0083\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 537us/step - loss: 0.0087 - val_loss: 0.0381\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 563us/step - loss: 0.0086 - val_loss: 0.0089\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 2s 536us/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 2s 529us/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 2s 530us/step - loss: 0.0037 - val_loss: 0.0065\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 491us/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 487us/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 2s 556us/step - loss: 0.0031 - val_loss: 0.0027\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 2s 542us/step - loss: 0.0030 - val_loss: 0.0026\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 2s 554us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 2s 548us/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 544us/step - loss: 0.0029 - val_loss: 0.0027\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 2s 544us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 2s 536us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 2s 527us/step - loss: 0.0026 - val_loss: 0.0048\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 2s 523us/step - loss: 0.0026 - val_loss: 0.0041\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 2s 520us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 2s 535us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 20s 6ms/step - loss: 3.5615 - val_loss: 0.0740\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 376us/step - loss: 0.4326 - val_loss: 0.0438\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 372us/step - loss: 0.1081 - val_loss: 0.2314\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 371us/step - loss: 0.1319 - val_loss: 0.0628\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 370us/step - loss: 0.0786 - val_loss: 0.0062\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 370us/step - loss: 0.0795 - val_loss: 0.0355\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 371us/step - loss: 0.0690 - val_loss: 0.0598\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 370us/step - loss: 0.0629 - val_loss: 0.0170\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 370us/step - loss: 0.0540 - val_loss: 0.0104\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 369us/step - loss: 0.0375 - val_loss: 0.0086\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 369us/step - loss: 0.0170 - val_loss: 0.0131\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 374us/step - loss: 0.0072 - val_loss: 0.0313\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 372us/step - loss: 0.0069 - val_loss: 0.0354\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 370us/step - loss: 0.0065 - val_loss: 0.0117\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 371us/step - loss: 0.0055 - val_loss: 0.0063\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 370us/step - loss: 0.0055 - val_loss: 0.0064\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 370us/step - loss: 0.0048 - val_loss: 0.0055\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 370us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 371us/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 370us/step - loss: 0.0038 - val_loss: 0.0047\n",
      "Epoch 21/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3556/3556 [==============================] - 1s 371us/step - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 372us/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 370us/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 379us/step - loss: 0.0037 - val_loss: 0.0031\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 20s 5ms/step - loss: 0.0449 - val_loss: 0.0100\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 368us/step - loss: 0.0098 - val_loss: 0.0074\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 372us/step - loss: 0.0053 - val_loss: 0.0023\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 372us/step - loss: 0.0045 - val_loss: 0.0054\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 369us/step - loss: 0.0039 - val_loss: 0.0042\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 367us/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 370us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 370us/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 369us/step - loss: 0.0027 - val_loss: 0.0021\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 370us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 371us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 376us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 371us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 369us/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 371us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 374us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 371us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 370us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 371us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 370us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 369us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 369us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 369us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 370us/step - loss: 0.0018 - val_loss: 0.0034\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 21s 6ms/step - loss: 0.1032 - val_loss: 0.0154\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 557us/step - loss: 0.0230 - val_loss: 0.0387\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 2s 561us/step - loss: 0.0092 - val_loss: 0.0081\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 560us/step - loss: 0.0050 - val_loss: 0.0054\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 2s 560us/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 2s 558us/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 581us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 628us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 2s 602us/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 2s 594us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 2s 615us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 627us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 626us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 2s 607us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 2s 622us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 2s 606us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 2s 604us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 597us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 2s 606us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 2s 609us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 2s 627us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 2s 632us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 2s 628us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 2s 633us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 25s 7ms/step - loss: 0.2370 - val_loss: 0.0280\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 595us/step - loss: 0.0975 - val_loss: 0.0872\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 2s 618us/step - loss: 0.0713 - val_loss: 0.0054\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 604us/step - loss: 0.0432 - val_loss: 0.0412\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 2s 591us/step - loss: 0.0155 - val_loss: 0.0583\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 2s 601us/step - loss: 0.0085 - val_loss: 0.0177\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 602us/step - loss: 0.0052 - val_loss: 0.0239\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 595us/step - loss: 0.0039 - val_loss: 0.0159\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 2s 597us/step - loss: 0.0035 - val_loss: 0.0134\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 2s 601us/step - loss: 0.0030 - val_loss: 0.0061\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 2s 602us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 601us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 593us/step - loss: 0.0024 - val_loss: 0.0038\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 2s 601us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 2s 594us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 2s 595us/step - loss: 0.0022 - val_loss: 0.0050\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 2s 591us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 596us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 2s 593us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 2s 594us/step - loss: 0.0019 - val_loss: 0.0033\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 2s 599us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 2s 596us/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 2s 593us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 2s 594us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "\n",
      "GENERATION 15\n",
      "\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3556/3556 [==============================] - 22s 6ms/step - loss: 1.1766 - val_loss: 0.0031\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 226us/step - loss: 0.1142 - val_loss: 0.1425\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 227us/step - loss: 0.0636 - val_loss: 0.0846\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 226us/step - loss: 0.0246 - val_loss: 0.0207\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 225us/step - loss: 0.0125 - val_loss: 0.0299\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 227us/step - loss: 0.0069 - val_loss: 0.0021\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 225us/step - loss: 0.0037 - val_loss: 0.0078\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 229us/step - loss: 0.0024 - val_loss: 8.1563e-04\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 228us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 226us/step - loss: 0.0011 - val_loss: 9.4169e-04\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 227us/step - loss: 9.7977e-04 - val_loss: 0.0029\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 226us/step - loss: 8.5778e-04 - val_loss: 0.0010\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 225us/step - loss: 7.9433e-04 - val_loss: 0.0020\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 226us/step - loss: 7.5542e-04 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 227us/step - loss: 7.4158e-04 - val_loss: 0.0017\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 232us/step - loss: 7.1758e-04 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 248us/step - loss: 7.0839e-04 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 255us/step - loss: 6.9288e-04 - val_loss: 0.0014\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 256us/step - loss: 6.8078e-04 - val_loss: 0.0010\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 255us/step - loss: 6.6929e-04 - val_loss: 0.0012\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 255us/step - loss: 6.6268e-04 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 242us/step - loss: 6.5201e-04 - val_loss: 0.0010\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 243us/step - loss: 6.4313e-04 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 241us/step - loss: 6.3623e-04 - val_loss: 0.0010\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 23s 6ms/step - loss: 0.0380 - val_loss: 0.0285\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 270us/step - loss: 0.0086 - val_loss: 0.0104\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 272us/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 272us/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 270us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 272us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 270us/step - loss: 8.2717e-04 - val_loss: 9.0126e-04\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 273us/step - loss: 7.6001e-04 - val_loss: 0.0011\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 272us/step - loss: 7.0669e-04 - val_loss: 7.2459e-04\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 271us/step - loss: 6.6961e-04 - val_loss: 8.2087e-04\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 272us/step - loss: 6.5169e-04 - val_loss: 7.0565e-04\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 270us/step - loss: 6.3922e-04 - val_loss: 7.4689e-04\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 273us/step - loss: 6.3278e-04 - val_loss: 7.1138e-04\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 273us/step - loss: 6.2261e-04 - val_loss: 6.9993e-04\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 272us/step - loss: 6.1539e-04 - val_loss: 6.9452e-04\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 275us/step - loss: 6.0858e-04 - val_loss: 6.8731e-04\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 272us/step - loss: 6.0229e-04 - val_loss: 6.7681e-04\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 271us/step - loss: 5.9916e-04 - val_loss: 6.9428e-04\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 275us/step - loss: 5.9196e-04 - val_loss: 6.4899e-04\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 275us/step - loss: 5.8590e-04 - val_loss: 6.4477e-04\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 272us/step - loss: 5.8110e-04 - val_loss: 6.9188e-04\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 273us/step - loss: 5.7725e-04 - val_loss: 6.2243e-04\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 270us/step - loss: 5.6845e-04 - val_loss: 6.2027e-04\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 271us/step - loss: 5.6372e-04 - val_loss: 6.4661e-04\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 23s 7ms/step - loss: 0.1904 - val_loss: 0.0215\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 205us/step - loss: 0.0162 - val_loss: 9.5471e-04\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 216us/step - loss: 0.0090 - val_loss: 0.0121\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 197us/step - loss: 0.0061 - val_loss: 0.0014\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 196us/step - loss: 0.0038 - val_loss: 0.0070\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 194us/step - loss: 0.0022 - val_loss: 9.7536e-04\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 193us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 194us/step - loss: 0.0012 - val_loss: 8.9793e-04\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 194us/step - loss: 9.9203e-04 - val_loss: 0.0019\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 194us/step - loss: 8.7568e-04 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 194us/step - loss: 8.0264e-04 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 192us/step - loss: 7.6990e-04 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 194us/step - loss: 7.4598e-04 - val_loss: 9.3820e-04\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 195us/step - loss: 7.1728e-04 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 194us/step - loss: 7.0390e-04 - val_loss: 0.0010\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 195us/step - loss: 6.9253e-04 - val_loss: 8.8486e-04\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 193us/step - loss: 6.7729e-04 - val_loss: 9.8656e-04\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 193us/step - loss: 6.6454e-04 - val_loss: 9.6131e-04\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 194us/step - loss: 6.5737e-04 - val_loss: 9.7795e-04\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 195us/step - loss: 6.5084e-04 - val_loss: 8.8285e-04\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 195us/step - loss: 6.3733e-04 - val_loss: 0.0010\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 194us/step - loss: 6.3181e-04 - val_loss: 9.0911e-04\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 192us/step - loss: 6.2132e-04 - val_loss: 7.8696e-04\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 194us/step - loss: 6.1432e-04 - val_loss: 8.5838e-04\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 23s 7ms/step - loss: 0.1027 - val_loss: 0.0733\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 200us/step - loss: 0.0243 - val_loss: 0.0397\n",
      "Epoch 3/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3556/3556 [==============================] - 1s 194us/step - loss: 0.0089 - val_loss: 0.0083\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 192us/step - loss: 0.0048 - val_loss: 0.0127\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 194us/step - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 193us/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 194us/step - loss: 0.0015 - val_loss: 9.0280e-04\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 193us/step - loss: 0.0012 - val_loss: 0.0026\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 195us/step - loss: 0.0011 - val_loss: 8.9080e-04\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 192us/step - loss: 9.9024e-04 - val_loss: 0.0018\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 194us/step - loss: 9.0297e-04 - val_loss: 9.0620e-04\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 194us/step - loss: 8.6020e-04 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 194us/step - loss: 8.2488e-04 - val_loss: 9.2466e-04\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 194us/step - loss: 7.9092e-04 - val_loss: 9.0401e-04\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 195us/step - loss: 7.5947e-04 - val_loss: 9.3834e-04\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 193us/step - loss: 7.3651e-04 - val_loss: 8.2635e-04\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 197us/step - loss: 7.1172e-04 - val_loss: 8.6644e-04\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 196us/step - loss: 6.9407e-04 - val_loss: 7.6804e-04\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 196us/step - loss: 6.7409e-04 - val_loss: 7.5041e-04\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 193us/step - loss: 6.5858e-04 - val_loss: 7.2163e-04\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 192us/step - loss: 6.4356e-04 - val_loss: 7.5547e-04\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 194us/step - loss: 6.3070e-04 - val_loss: 6.8016e-04\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 193us/step - loss: 6.1929e-04 - val_loss: 7.3000e-04\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 194us/step - loss: 6.1322e-04 - val_loss: 7.2225e-04\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 24s 7ms/step - loss: 0.5333 - val_loss: 0.0018\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 251us/step - loss: 0.0048 - val_loss: 0.0011\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 251us/step - loss: 0.0040 - val_loss: 0.0010\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 0.0039 - val_loss: 0.0010\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 0.0038 - val_loss: 0.0011\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 258us/step - loss: 0.0036 - val_loss: 9.8315e-04\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 251us/step - loss: 0.0034 - val_loss: 9.1695e-04\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 251us/step - loss: 0.0034 - val_loss: 9.1795e-04\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 0.0034 - val_loss: 9.3530e-04\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 0.0050 - val_loss: 0.0113\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 0.0230 - val_loss: 0.0416\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 259us/step - loss: 0.0277 - val_loss: 0.0164\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 250us/step - loss: 0.0087 - val_loss: 0.0036\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 0.0052 - val_loss: 0.0058\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 0.0139 - val_loss: 0.0266\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 257us/step - loss: 0.0232 - val_loss: 0.0290\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 0.0134 - val_loss: 0.0076\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 0.0065 - val_loss: 0.0076\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 0.0081 - val_loss: 0.0111\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 0.0139 - val_loss: 0.0253\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 0.0173 - val_loss: 0.0142\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 0.0086 - val_loss: 0.0091\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 258us/step - loss: 0.0070 - val_loss: 0.0038\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 0.0047 - val_loss: 0.0077\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 23s 7ms/step - loss: 0.1344 - val_loss: 0.0040\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 502us/step - loss: 0.0175 - val_loss: 0.0071\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 2s 502us/step - loss: 0.0057 - val_loss: 0.0037\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 500us/step - loss: 0.0038 - val_loss: 0.0027\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 2s 501us/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 2s 503us/step - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 502us/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 501us/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 2s 501us/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 2s 501us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 2s 500us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 501us/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 499us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 2s 505us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 2s 507us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 2s 501us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 2s 500us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 500us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 2s 500us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 2s 503us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 2s 501us/step - loss: 0.0022 - val_loss: 0.0032\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 2s 501us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 2s 501us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 2s 503us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 23s 7ms/step - loss: 0.1408 - val_loss: 0.1030\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 501us/step - loss: 0.0581 - val_loss: 0.0114\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 2s 502us/step - loss: 0.0207 - val_loss: 0.0678\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 501us/step - loss: 0.0176 - val_loss: 0.0367\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 2s 501us/step - loss: 0.0198 - val_loss: 0.0929\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 2s 503us/step - loss: 0.0198 - val_loss: 0.0374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 501us/step - loss: 0.0071 - val_loss: 0.0156\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 500us/step - loss: 0.0279 - val_loss: 0.0417\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 2s 501us/step - loss: 0.0040 - val_loss: 0.0192\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 2s 501us/step - loss: 0.0262 - val_loss: 0.0743\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 2s 502us/step - loss: 0.0108 - val_loss: 0.0291\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 506us/step - loss: 0.0036 - val_loss: 0.0048\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 502us/step - loss: 0.0221 - val_loss: 0.0298\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 2s 503us/step - loss: 0.0034 - val_loss: 0.0066\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 2s 505us/step - loss: 0.0235 - val_loss: 0.0311\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 2s 501us/step - loss: 0.0036 - val_loss: 0.0183\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 2s 501us/step - loss: 0.0083 - val_loss: 0.0254\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 501us/step - loss: 0.0130 - val_loss: 0.0334\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 2s 501us/step - loss: 0.0054 - val_loss: 0.0258\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 2s 501us/step - loss: 0.0148 - val_loss: 0.0398\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 2s 503us/step - loss: 0.0060 - val_loss: 0.0095\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 2s 503us/step - loss: 0.0108 - val_loss: 0.0421\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 2s 502us/step - loss: 0.0080 - val_loss: 0.0219\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 2s 506us/step - loss: 0.0097 - val_loss: 0.0345\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 24s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 502us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 2s 503us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 500us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 2s 501us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 2s 502us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 505us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 501us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 2s 508us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 2s 504us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 2s 507us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 506us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 511us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 2s 510us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 2s 511us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 2s 514us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 2s 517us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 507us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 2s 504us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 2s 510us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 2s 505us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 2s 504us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 2s 505us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 2s 509us/step - loss: nan - val_loss: nan\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 25s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 475us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 2s 471us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 479us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 2s 489us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 2s 479us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 486us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 471us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 2s 472us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 2s 469us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 2s 478us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 481us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 469us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 2s 468us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 2s 480us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 2s 480us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 2s 469us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 468us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 2s 471us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 2s 469us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 2s 472us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 2s 479us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 2s 470us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 2s 473us/step - loss: nan - val_loss: nan\n",
      "\n",
      "GENERATION 16\n",
      "\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 24s 7ms/step - loss: 0.0620 - val_loss: 0.0303\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 270us/step - loss: 0.0128 - val_loss: 0.0112\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 260us/step - loss: 0.0052 - val_loss: 0.0025\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 0.0030 - val_loss: 9.6897e-04\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 279us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 292us/step - loss: 0.0011 - val_loss: 8.1751e-04\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 271us/step - loss: 8.7837e-04 - val_loss: 0.0014\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 298us/step - loss: 7.6115e-04 - val_loss: 7.4005e-04\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 293us/step - loss: 7.4962e-04 - val_loss: 0.0010\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 297us/step - loss: 6.9966e-04 - val_loss: 6.9778e-04\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 290us/step - loss: 6.7406e-04 - val_loss: 8.3139e-04\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 275us/step - loss: 6.6641e-04 - val_loss: 7.0064e-04\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 277us/step - loss: 6.5215e-04 - val_loss: 7.5131e-04\n",
      "Epoch 14/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3556/3556 [==============================] - 1s 273us/step - loss: 6.4438e-04 - val_loss: 7.0580e-04\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 277us/step - loss: 6.3650e-04 - val_loss: 6.9978e-04\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 276us/step - loss: 6.2840e-04 - val_loss: 7.1096e-04\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 274us/step - loss: 6.2150e-04 - val_loss: 6.9066e-04\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 274us/step - loss: 6.1437e-04 - val_loss: 6.7601e-04\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 275us/step - loss: 6.0872e-04 - val_loss: 6.6470e-04\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 273us/step - loss: 6.0290e-04 - val_loss: 6.7498e-04\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 273us/step - loss: 5.9733e-04 - val_loss: 6.4753e-04\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 273us/step - loss: 5.9142e-04 - val_loss: 6.6277e-04\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 273us/step - loss: 5.8797e-04 - val_loss: 6.5098e-04\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 272us/step - loss: 5.8101e-04 - val_loss: 6.3589e-04\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 26s 7ms/step - loss: 0.0713 - val_loss: 0.0296\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 273us/step - loss: 0.0123 - val_loss: 0.0150\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 275us/step - loss: 0.0053 - val_loss: 0.0033\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 273us/step - loss: 0.0028 - val_loss: 0.0021\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 275us/step - loss: 0.0017 - val_loss: 8.9547e-04\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 274us/step - loss: 0.0011 - val_loss: 7.7343e-04\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 272us/step - loss: 8.6505e-04 - val_loss: 0.0013\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 280us/step - loss: 7.5565e-04 - val_loss: 7.3878e-04\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 290us/step - loss: 7.2811e-04 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 276us/step - loss: 7.0651e-04 - val_loss: 7.5369e-04\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 279us/step - loss: 6.8436e-04 - val_loss: 9.4734e-04\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 273us/step - loss: 6.6861e-04 - val_loss: 7.6344e-04\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 273us/step - loss: 6.5668e-04 - val_loss: 8.8739e-04\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 273us/step - loss: 6.5165e-04 - val_loss: 7.6176e-04\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 274us/step - loss: 6.4085e-04 - val_loss: 8.0431e-04\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 273us/step - loss: 6.3271e-04 - val_loss: 7.5732e-04\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 273us/step - loss: 6.2543e-04 - val_loss: 7.7033e-04\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 274us/step - loss: 6.1861e-04 - val_loss: 7.5308e-04\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 274us/step - loss: 6.1155e-04 - val_loss: 7.4766e-04\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 275us/step - loss: 6.0581e-04 - val_loss: 6.9805e-04\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 272us/step - loss: 5.9933e-04 - val_loss: 7.7291e-04\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 273us/step - loss: 5.9892e-04 - val_loss: 6.8054e-04\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 276us/step - loss: 5.8732e-04 - val_loss: 6.8502e-04\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 274us/step - loss: 5.7969e-04 - val_loss: 6.9203e-04\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 26s 7ms/step - loss: 0.0822 - val_loss: 0.0513\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 275us/step - loss: 0.0203 - val_loss: 0.0164\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 272us/step - loss: 0.0101 - val_loss: 0.0057\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 275us/step - loss: 0.0067 - val_loss: 8.0734e-04\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 277us/step - loss: 0.0040 - val_loss: 0.0011\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 278us/step - loss: 0.0031 - val_loss: 0.0014\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 274us/step - loss: 0.0028 - val_loss: 0.0011\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 276us/step - loss: 0.0026 - val_loss: 8.2142e-04\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 275us/step - loss: 0.0023 - val_loss: 7.3364e-04\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 278us/step - loss: 0.0023 - val_loss: 7.3051e-04\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 276us/step - loss: 0.0021 - val_loss: 7.1542e-04\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 274us/step - loss: 0.0020 - val_loss: 7.1199e-04\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 275us/step - loss: 0.0019 - val_loss: 7.1025e-04\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 271us/step - loss: 0.0018 - val_loss: 7.0181e-04\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 275us/step - loss: 0.0018 - val_loss: 7.0350e-04\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 273us/step - loss: 0.0019 - val_loss: 7.0099e-04\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 278us/step - loss: 0.0017 - val_loss: 6.8366e-04\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 278us/step - loss: 0.0016 - val_loss: 6.9480e-04\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 273us/step - loss: 0.0017 - val_loss: 6.7274e-04\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 273us/step - loss: 0.0016 - val_loss: 6.7299e-04\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 274us/step - loss: 0.0015 - val_loss: 6.8167e-04\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 281us/step - loss: 0.0015 - val_loss: 6.6445e-04\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 273us/step - loss: 0.0015 - val_loss: 7.1465e-04\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 274us/step - loss: 0.0015 - val_loss: 6.5274e-04\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 26s 7ms/step - loss: 0.1499 - val_loss: 0.0045\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 238us/step - loss: 0.0246 - val_loss: 0.0275\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 238us/step - loss: 0.0122 - val_loss: 0.0121\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 233us/step - loss: 0.0088 - val_loss: 0.0028\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 234us/step - loss: 0.0059 - val_loss: 0.0015\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 233us/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 233us/step - loss: 0.0036 - val_loss: 0.0011\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 233us/step - loss: 0.0033 - val_loss: 8.9006e-04\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 237us/step - loss: 0.0032 - val_loss: 8.7388e-04\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 232us/step - loss: 0.0028 - val_loss: 8.3695e-04\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 232us/step - loss: 0.0025 - val_loss: 8.4640e-04\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 234us/step - loss: 0.0025 - val_loss: 7.7472e-04\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 233us/step - loss: 0.0023 - val_loss: 8.0173e-04\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 234us/step - loss: 0.0023 - val_loss: 7.7338e-04\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 233us/step - loss: 0.0022 - val_loss: 7.7064e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 233us/step - loss: 0.0021 - val_loss: 7.5473e-04\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 233us/step - loss: 0.0021 - val_loss: 8.3789e-04\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 232us/step - loss: 0.0020 - val_loss: 7.4369e-04\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 234us/step - loss: 0.0019 - val_loss: 7.4410e-04\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 234us/step - loss: 0.0018 - val_loss: 7.6879e-04\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 238us/step - loss: 0.0018 - val_loss: 7.5352e-04\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 235us/step - loss: 0.0018 - val_loss: 7.6265e-04\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 234us/step - loss: 0.0018 - val_loss: 7.3860e-04\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 234us/step - loss: 0.0016 - val_loss: 7.3721e-04\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 27s 7ms/step - loss: 0.0455 - val_loss: 0.0023\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 217us/step - loss: 0.0105 - val_loss: 0.0173\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 216us/step - loss: 0.0106 - val_loss: 0.0013\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 213us/step - loss: 0.0055 - val_loss: 0.0031\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 216us/step - loss: 0.0047 - val_loss: 0.0012\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 214us/step - loss: 0.0069 - val_loss: 0.0167\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 211us/step - loss: 0.0139 - val_loss: 0.0072\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 212us/step - loss: 0.0081 - val_loss: 0.0027\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 210us/step - loss: 0.0043 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 210us/step - loss: 0.0041 - val_loss: 0.0068\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 214us/step - loss: 0.0071 - val_loss: 0.0068\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 213us/step - loss: 0.0081 - val_loss: 0.0056\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 212us/step - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 211us/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 213us/step - loss: 0.0055 - val_loss: 0.0059\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 213us/step - loss: 0.0074 - val_loss: 0.0081\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 210us/step - loss: 0.0060 - val_loss: 0.0049\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 214us/step - loss: 0.0046 - val_loss: 0.0022\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 211us/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 213us/step - loss: 0.0048 - val_loss: 0.0029\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 211us/step - loss: 0.0032 - val_loss: 0.0025\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 211us/step - loss: 0.0044 - val_loss: 0.0057\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 216us/step - loss: 0.0061 - val_loss: 0.0044\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 215us/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 27s 8ms/step - loss: 0.0705 - val_loss: 0.0015\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 219us/step - loss: 0.0056 - val_loss: 0.0011\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 212us/step - loss: 0.0053 - val_loss: 0.0021\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 212us/step - loss: 0.0046 - val_loss: 0.0010\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 212us/step - loss: 0.0047 - val_loss: 0.0023\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 211us/step - loss: 0.0052 - val_loss: 0.0047\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 210us/step - loss: 0.0108 - val_loss: 0.0106\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 212us/step - loss: 0.0073 - val_loss: 0.0035\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 210us/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 213us/step - loss: 0.0034 - val_loss: 8.5005e-04\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 211us/step - loss: 0.0034 - val_loss: 0.0051\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 214us/step - loss: 0.0060 - val_loss: 0.0067\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 212us/step - loss: 0.0063 - val_loss: 0.0045\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 212us/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 212us/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 210us/step - loss: 0.0061 - val_loss: 0.0063\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 214us/step - loss: 0.0042 - val_loss: 0.0024\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 219us/step - loss: 0.0030 - val_loss: 0.0017\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 210us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 211us/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 211us/step - loss: 0.0050 - val_loss: 0.0084\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 212us/step - loss: 0.0069 - val_loss: 0.0056\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 218us/step - loss: 0.0043 - val_loss: 0.0016\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 214us/step - loss: 0.0027 - val_loss: 8.6457e-04\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 29s 8ms/step - loss: 0.0730 - val_loss: 0.0084\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 601us/step - loss: 0.0293 - val_loss: 0.0340\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 2s 598us/step - loss: 0.0208 - val_loss: 0.0253\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 599us/step - loss: 0.0164 - val_loss: 0.0270\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 2s 602us/step - loss: 0.0111 - val_loss: 0.0074\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 2s 597us/step - loss: 0.0087 - val_loss: 0.0196\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 598us/step - loss: 0.0096 - val_loss: 0.0076\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 605us/step - loss: 0.0090 - val_loss: 0.0166\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 2s 598us/step - loss: 0.0084 - val_loss: 0.0082\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 2s 599us/step - loss: 0.0084 - val_loss: 0.0133\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 2s 606us/step - loss: 0.0072 - val_loss: 0.0068\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 599us/step - loss: 0.0090 - val_loss: 0.0117\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 598us/step - loss: 0.0068 - val_loss: 0.0042\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 2s 600us/step - loss: 0.0058 - val_loss: 0.0089\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 2s 602us/step - loss: 0.0051 - val_loss: 0.0054\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 2s 601us/step - loss: 0.0084 - val_loss: 0.0187\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 2s 601us/step - loss: 0.0126 - val_loss: 0.0092\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 601us/step - loss: 0.0112 - val_loss: 0.0211\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 2s 600us/step - loss: 0.0125 - val_loss: 0.0120\n",
      "Epoch 20/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3556/3556 [==============================] - 2s 602us/step - loss: 0.0113 - val_loss: 0.0143\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 2s 612us/step - loss: 0.0103 - val_loss: 0.0109\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 2s 615us/step - loss: 0.0119 - val_loss: 0.0146\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 2s 584us/step - loss: 0.0079 - val_loss: 0.0064\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 2s 586us/step - loss: 0.0107 - val_loss: 0.0190\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 27s 7ms/step - loss: 0.0644 - val_loss: 0.0080\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 570us/step - loss: 0.0087 - val_loss: 0.0058\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 2s 568us/step - loss: 0.0083 - val_loss: 0.0100\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 565us/step - loss: 0.0087 - val_loss: 0.0076\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 2s 574us/step - loss: 0.0065 - val_loss: 0.0062\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 2s 574us/step - loss: 0.0060 - val_loss: 0.0045\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 596us/step - loss: 0.0052 - val_loss: 0.0077\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 563us/step - loss: 0.0076 - val_loss: 0.0115\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 2s 565us/step - loss: 0.0064 - val_loss: 0.0083\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 2s 565us/step - loss: 0.0071 - val_loss: 0.0075\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 2s 564us/step - loss: 0.0081 - val_loss: 0.0091\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 568us/step - loss: 0.0071 - val_loss: 0.0044\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 593us/step - loss: 0.0047 - val_loss: 0.0065\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 2s 570us/step - loss: 0.0053 - val_loss: 0.0039\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 2s 565us/step - loss: 0.0053 - val_loss: 0.0113\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 2s 582us/step - loss: 0.0077 - val_loss: 0.0088\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 2s 568us/step - loss: 0.0056 - val_loss: 0.0044\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 564us/step - loss: 0.0040 - val_loss: 0.0034\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 2s 572us/step - loss: 0.0033 - val_loss: 0.0046\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 2s 565us/step - loss: 0.0038 - val_loss: 0.0054\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 2s 574us/step - loss: 0.0068 - val_loss: 0.0054\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 2s 595us/step - loss: 0.0054 - val_loss: 0.0049\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 2s 579us/step - loss: 0.0049 - val_loss: 0.0064\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 2s 582us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 32s 9ms/step - loss: 0.0492 - val_loss: 0.0049\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 454us/step - loss: 0.0088 - val_loss: 0.0151\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 2s 452us/step - loss: 0.0111 - val_loss: 0.0068\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 493us/step - loss: 0.0063 - val_loss: 0.0069\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 2s 462us/step - loss: 0.0061 - val_loss: 0.0029\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 2s 454us/step - loss: 0.0066 - val_loss: 0.0132\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 456us/step - loss: 0.0090 - val_loss: 0.0071\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 453us/step - loss: 0.0063 - val_loss: 0.0040\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 2s 457us/step - loss: 0.0043 - val_loss: 0.0020\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 2s 458us/step - loss: 0.0050 - val_loss: 0.0072\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 2s 489us/step - loss: 0.0069 - val_loss: 0.0056\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 509us/step - loss: 0.0058 - val_loss: 0.0069\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 467us/step - loss: 0.0073 - val_loss: 0.0083\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 2s 467us/step - loss: 0.0065 - val_loss: 0.0064\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 2s 484us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 2s 513us/step - loss: 0.0039 - val_loss: 0.0033\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 2s 479us/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 515us/step - loss: 0.0063 - val_loss: 0.0109\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 2s 507us/step - loss: 0.0077 - val_loss: 0.0051\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 2s 457us/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 2s 455us/step - loss: 0.0032 - val_loss: 0.0015\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 2s 428us/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 2s 485us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 2s 468us/step - loss: 0.0054 - val_loss: 0.0059\n",
      "\n",
      "GENERATION 17\n",
      "\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 25s 7ms/step - loss: 0.0692 - val_loss: 0.0319\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 261us/step - loss: 0.0165 - val_loss: 0.0127\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 260us/step - loss: 0.0082 - val_loss: 0.0033\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 261us/step - loss: 0.0054 - val_loss: 7.5462e-04\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 259us/step - loss: 0.0035 - val_loss: 0.0012\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 260us/step - loss: 0.0028 - val_loss: 9.9161e-04\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 261us/step - loss: 0.0026 - val_loss: 0.0011\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 0.0022 - val_loss: 7.0835e-04\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 258us/step - loss: 0.0020 - val_loss: 9.1206e-04\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 261us/step - loss: 0.0019 - val_loss: 6.5420e-04\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 260us/step - loss: 0.0019 - val_loss: 6.9947e-04\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 261us/step - loss: 0.0018 - val_loss: 6.4537e-04\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 0.0018 - val_loss: 6.7877e-04\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 0.0017 - val_loss: 6.4346e-04\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 260us/step - loss: 0.0016 - val_loss: 6.4886e-04\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 259us/step - loss: 0.0016 - val_loss: 6.3205e-04\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 258us/step - loss: 0.0016 - val_loss: 6.4667e-04\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 259us/step - loss: 0.0016 - val_loss: 6.2877e-04\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 258us/step - loss: 0.0015 - val_loss: 6.6066e-04\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 259us/step - loss: 0.0015 - val_loss: 6.2625e-04\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 274us/step - loss: 0.0014 - val_loss: 6.3705e-04\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 298us/step - loss: 0.0014 - val_loss: 6.1459e-04\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 267us/step - loss: 0.0013 - val_loss: 6.1950e-04\n",
      "Epoch 24/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3556/3556 [==============================] - 1s 308us/step - loss: 0.0014 - val_loss: 6.2063e-04\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 27s 8ms/step - loss: 0.0577 - val_loss: 0.0376\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 0.0138 - val_loss: 0.0164\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 0.0055 - val_loss: 0.0035\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 0.0032 - val_loss: 0.0014\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 261us/step - loss: 0.0012 - val_loss: 8.0834e-04\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 260us/step - loss: 9.4082e-04 - val_loss: 0.0017\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 260us/step - loss: 8.2818e-04 - val_loss: 7.3885e-04\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 259us/step - loss: 7.7309e-04 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 258us/step - loss: 7.2661e-04 - val_loss: 7.3975e-04\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 261us/step - loss: 7.0844e-04 - val_loss: 9.1407e-04\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 6.8396e-04 - val_loss: 7.5916e-04\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 6.7074e-04 - val_loss: 8.0925e-04\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 261us/step - loss: 6.5959e-04 - val_loss: 7.5869e-04\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 259us/step - loss: 6.5104e-04 - val_loss: 7.5989e-04\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 260us/step - loss: 6.4260e-04 - val_loss: 7.4874e-04\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 6.3453e-04 - val_loss: 7.4121e-04\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 6.2770e-04 - val_loss: 7.1025e-04\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 6.2209e-04 - val_loss: 7.1982e-04\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 282us/step - loss: 6.1394e-04 - val_loss: 6.9154e-04\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 301us/step - loss: 6.0849e-04 - val_loss: 6.9505e-04\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 275us/step - loss: 6.0275e-04 - val_loss: 6.8726e-04\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 293us/step - loss: 5.9741e-04 - val_loss: 6.6714e-04\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 280us/step - loss: 5.9301e-04 - val_loss: 6.7545e-04\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 26s 7ms/step - loss: 0.3818 - val_loss: 0.0491\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 254us/step - loss: 0.0332 - val_loss: 0.0108\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 0.0145 - val_loss: 0.0089\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 255us/step - loss: 0.0085 - val_loss: 0.0141\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 250us/step - loss: 0.0052 - val_loss: 0.0070\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 252us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 260us/step - loss: 0.0016 - val_loss: 8.5495e-04\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 256us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 247us/step - loss: 0.0010 - val_loss: 9.6147e-04\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 248us/step - loss: 8.6212e-04 - val_loss: 8.6485e-04\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 248us/step - loss: 7.7185e-04 - val_loss: 9.9702e-04\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 246us/step - loss: 7.3251e-04 - val_loss: 8.0510e-04\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 250us/step - loss: 7.0921e-04 - val_loss: 8.0352e-04\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 257us/step - loss: 6.9412e-04 - val_loss: 8.7116e-04\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 251us/step - loss: 6.7854e-04 - val_loss: 8.5223e-04\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 250us/step - loss: 6.6196e-04 - val_loss: 8.1295e-04\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 247us/step - loss: 6.4895e-04 - val_loss: 7.8905e-04\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 249us/step - loss: 6.3739e-04 - val_loss: 7.4927e-04\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 253us/step - loss: 6.3187e-04 - val_loss: 7.5137e-04\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 249us/step - loss: 6.1797e-04 - val_loss: 7.8099e-04\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 250us/step - loss: 6.1049e-04 - val_loss: 7.8584e-04\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 249us/step - loss: 6.0256e-04 - val_loss: 7.3284e-04\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 250us/step - loss: 5.9827e-04 - val_loss: 7.0074e-04\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 247us/step - loss: 5.9729e-04 - val_loss: 6.9468e-04\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 27s 7ms/step - loss: 0.1089 - val_loss: 0.0416\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 247us/step - loss: 0.0230 - val_loss: 0.0173\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 246us/step - loss: 0.0118 - val_loss: 0.0017\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 246us/step - loss: 0.0073 - val_loss: 0.0011\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 247us/step - loss: 0.0049 - val_loss: 0.0055\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 248us/step - loss: 0.0040 - val_loss: 9.3219e-04\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 250us/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 248us/step - loss: 0.0032 - val_loss: 0.0010\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 250us/step - loss: 0.0030 - val_loss: 0.0019\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 251us/step - loss: 0.0027 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 249us/step - loss: 0.0025 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 256us/step - loss: 0.0025 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 254us/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 248us/step - loss: 0.0022 - val_loss: 0.0010\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 248us/step - loss: 0.0023 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 250us/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 257us/step - loss: 0.0020 - val_loss: 9.2435e-04\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 250us/step - loss: 0.0020 - val_loss: 9.8265e-04\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 249us/step - loss: 0.0020 - val_loss: 8.1761e-04\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 248us/step - loss: 0.0019 - val_loss: 9.3013e-04\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 249us/step - loss: 0.0017 - val_loss: 8.2102e-04\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 248us/step - loss: 0.0017 - val_loss: 7.8976e-04\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 247us/step - loss: 0.0017 - val_loss: 8.5405e-04\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 246us/step - loss: 0.0017 - val_loss: 8.1082e-04\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3556/3556 [==============================] - 29s 8ms/step - loss: 0.0859 - val_loss: 0.0175\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 535us/step - loss: 0.0140 - val_loss: 0.0056\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 2s 527us/step - loss: 0.0073 - val_loss: 0.0104\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 524us/step - loss: 0.0054 - val_loss: 0.0016\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 2s 530us/step - loss: 0.0044 - val_loss: 0.0056\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 2s 531us/step - loss: 0.0035 - val_loss: 0.0015\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 546us/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 530us/step - loss: 0.0029 - val_loss: 0.0017\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 2s 526us/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 2s 543us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 2s 539us/step - loss: 0.0025 - val_loss: 0.0015\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 534us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 526us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 2s 535us/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 2s 530us/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 2s 528us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 2s 531us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 526us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 2s 529us/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 2s 530us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 2s 529us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 2s 531us/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 2s 531us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 2s 528us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 29s 8ms/step - loss: 0.1410 - val_loss: 0.0119\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 527us/step - loss: 0.0209 - val_loss: 0.0030\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 2s 527us/step - loss: 0.0168 - val_loss: 0.0029\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 527us/step - loss: 0.0135 - val_loss: 0.0025\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 2s 527us/step - loss: 0.0134 - val_loss: 0.0029\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 2s 526us/step - loss: 0.0116 - val_loss: 0.0035\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 528us/step - loss: 0.0114 - val_loss: 0.0032\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 526us/step - loss: 0.0106 - val_loss: 0.0033\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 2s 527us/step - loss: 0.0106 - val_loss: 0.0026\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 2s 530us/step - loss: 0.0097 - val_loss: 0.0022\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 2s 528us/step - loss: 0.0088 - val_loss: 0.0024\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 540us/step - loss: 0.0090 - val_loss: 0.0023\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 566us/step - loss: 0.0089 - val_loss: 0.0023\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 2s 538us/step - loss: 0.0084 - val_loss: 0.0028\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 2s 535us/step - loss: 0.0078 - val_loss: 0.0024\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 2s 532us/step - loss: 0.0078 - val_loss: 0.0026\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 2s 534us/step - loss: 0.0076 - val_loss: 0.0021\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 524us/step - loss: 0.0069 - val_loss: 0.0024\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 2s 541us/step - loss: 0.0072 - val_loss: 0.0023\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 2s 532us/step - loss: 0.0069 - val_loss: 0.0024\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 2s 534us/step - loss: 0.0071 - val_loss: 0.0022\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 2s 561us/step - loss: 0.0069 - val_loss: 0.0025\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 2s 538us/step - loss: 0.0066 - val_loss: 0.0021\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 2s 531us/step - loss: 0.0064 - val_loss: 0.0020\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 29s 8ms/step - loss: 0.3692 - val_loss: 0.0086\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 424us/step - loss: 0.0180 - val_loss: 0.0074\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 2s 422us/step - loss: 0.0157 - val_loss: 0.0077\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 425us/step - loss: 0.0138 - val_loss: 0.0098\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 421us/step - loss: 0.0138 - val_loss: 0.0068\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 2s 423us/step - loss: 0.0129 - val_loss: 0.0048\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 431us/step - loss: 0.0114 - val_loss: 0.0058\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 425us/step - loss: 0.0110 - val_loss: 0.0064\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 2s 426us/step - loss: 0.0103 - val_loss: 0.0051\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 2s 425us/step - loss: 0.0099 - val_loss: 0.0070\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 2s 423us/step - loss: 0.0095 - val_loss: 0.0050\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 423us/step - loss: 0.0087 - val_loss: 0.0051\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 426us/step - loss: 0.0092 - val_loss: 0.0047\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 2s 423us/step - loss: 0.0089 - val_loss: 0.0045\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 2s 422us/step - loss: 0.0082 - val_loss: 0.0042\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 2s 424us/step - loss: 0.0078 - val_loss: 0.0044\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 421us/step - loss: 0.0076 - val_loss: 0.0031\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 423us/step - loss: 0.0074 - val_loss: 0.0037\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 420us/step - loss: 0.0072 - val_loss: 0.0029\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 2s 431us/step - loss: 0.0069 - val_loss: 0.0029\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 420us/step - loss: 0.0070 - val_loss: 0.0034\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 419us/step - loss: 0.0065 - val_loss: 0.0032\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 421us/step - loss: 0.0070 - val_loss: 0.0036\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 2s 424us/step - loss: 0.0065 - val_loss: 0.0023\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 29s 8ms/step - loss: 0.5851 - val_loss: 0.0072\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 427us/step - loss: 0.0136 - val_loss: 0.0023\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 2s 442us/step - loss: 0.0071 - val_loss: 0.0020\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 425us/step - loss: 0.0055 - val_loss: 0.0021\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 2s 425us/step - loss: 0.0050 - val_loss: 0.0022\n",
      "Epoch 6/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3556/3556 [==============================] - 2s 446us/step - loss: 0.0046 - val_loss: 0.0022\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 435us/step - loss: 0.0048 - val_loss: 0.0024\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 435us/step - loss: 0.0045 - val_loss: 0.0021\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 2s 436us/step - loss: 0.0045 - val_loss: 0.0023\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 2s 434us/step - loss: 0.0044 - val_loss: 0.0023\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 2s 428us/step - loss: 0.0042 - val_loss: 0.0024\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 428us/step - loss: 0.0042 - val_loss: 0.0022\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 434us/step - loss: 0.0040 - val_loss: 0.0020\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 2s 438us/step - loss: 0.0041 - val_loss: 0.0021\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 2s 439us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 2s 434us/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 2s 439us/step - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 432us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 2s 441us/step - loss: 0.0040 - val_loss: 0.0021\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 2s 436us/step - loss: 0.0038 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 2s 433us/step - loss: 0.0036 - val_loss: 0.0021\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 2s 431us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 2s 435us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 2s 431us/step - loss: 0.0036 - val_loss: 0.0023\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 29s 8ms/step - loss: 0.1477 - val_loss: 0.0045\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 430us/step - loss: 0.0130 - val_loss: 0.0021\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 2s 429us/step - loss: 0.0081 - val_loss: 0.0022\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 431us/step - loss: 0.0069 - val_loss: 0.0024\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 2s 434us/step - loss: 0.0061 - val_loss: 0.0020\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 2s 430us/step - loss: 0.0061 - val_loss: 0.0025\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 427us/step - loss: 0.0058 - val_loss: 0.0022\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 432us/step - loss: 0.0054 - val_loss: 0.0023\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 2s 435us/step - loss: 0.0050 - val_loss: 0.0022\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 2s 430us/step - loss: 0.0051 - val_loss: 0.0022\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 2s 431us/step - loss: 0.0048 - val_loss: 0.0021\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 427us/step - loss: 0.0046 - val_loss: 0.0021\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 434us/step - loss: 0.0050 - val_loss: 0.0021\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 2s 438us/step - loss: 0.0046 - val_loss: 0.0020\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 2s 431us/step - loss: 0.0045 - val_loss: 0.0021\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 2s 434us/step - loss: 0.0042 - val_loss: 0.0021\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 2s 429us/step - loss: 0.0042 - val_loss: 0.0020\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 431us/step - loss: 0.0043 - val_loss: 0.0021\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 2s 432us/step - loss: 0.0041 - val_loss: 0.0023\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 2s 432us/step - loss: 0.0039 - val_loss: 0.0023\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 2s 434us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 2s 432us/step - loss: 0.0040 - val_loss: 0.0023\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 2s 434us/step - loss: 0.0039 - val_loss: 0.0020\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 2s 438us/step - loss: 0.0037 - val_loss: 0.0021\n",
      "\n",
      "GENERATION 18\n",
      "\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 29s 8ms/step - loss: 0.0439 - val_loss: 0.0038\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 533us/step - loss: 0.0066 - val_loss: 0.0082\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 2s 535us/step - loss: 0.0040 - val_loss: 0.0034\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 536us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 2s 535us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 2s 535us/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 535us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 534us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 2s 534us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 2s 534us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 2s 537us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 537us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 534us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 2s 535us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 2s 540us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 2s 535us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 2s 537us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 536us/step - loss: 9.9755e-04 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 2s 537us/step - loss: 9.8467e-04 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 2s 536us/step - loss: 9.7013e-04 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 2s 539us/step - loss: 9.5085e-04 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 2s 537us/step - loss: 9.3970e-04 - val_loss: 0.0010\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 2s 535us/step - loss: 9.2420e-04 - val_loss: 0.0010\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 2s 538us/step - loss: 9.1264e-04 - val_loss: 9.8926e-04\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 28s 8ms/step - loss: 0.0548 - val_loss: 0.0390\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 268us/step - loss: 0.0129 - val_loss: 0.0161\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 270us/step - loss: 0.0054 - val_loss: 0.0038\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 0.0032 - val_loss: 0.0015\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 267us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 0.0011 - val_loss: 7.5429e-04\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 261us/step - loss: 8.6368e-04 - val_loss: 0.0015\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 7.8590e-04 - val_loss: 7.2824e-04\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 273us/step - loss: 7.4202e-04 - val_loss: 0.0011\n",
      "Epoch 10/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3556/3556 [==============================] - 1s 266us/step - loss: 7.0043e-04 - val_loss: 7.1428e-04\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 272us/step - loss: 6.7547e-04 - val_loss: 9.1329e-04\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 261us/step - loss: 6.6236e-04 - val_loss: 7.2895e-04\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 261us/step - loss: 6.4918e-04 - val_loss: 7.9953e-04\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 6.4008e-04 - val_loss: 7.3664e-04\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 267us/step - loss: 6.3206e-04 - val_loss: 7.4862e-04\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 268us/step - loss: 6.2651e-04 - val_loss: 7.1620e-04\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 259us/step - loss: 6.1833e-04 - val_loss: 7.1420e-04\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 6.1110e-04 - val_loss: 7.0988e-04\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 259us/step - loss: 6.0541e-04 - val_loss: 6.8223e-04\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 261us/step - loss: 5.9872e-04 - val_loss: 6.7998e-04\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 277us/step - loss: 5.9354e-04 - val_loss: 6.9426e-04\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 272us/step - loss: 5.8653e-04 - val_loss: 6.6449e-04\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 5.8046e-04 - val_loss: 6.7867e-04\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 259us/step - loss: 5.7746e-04 - val_loss: 6.4729e-04\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 29s 8ms/step - loss: 0.0638 - val_loss: 0.0352\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 243us/step - loss: 0.0147 - val_loss: 0.0127\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 239us/step - loss: 0.0079 - val_loss: 0.0050\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 238us/step - loss: 0.0058 - val_loss: 8.7446e-04\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 236us/step - loss: 0.0040 - val_loss: 7.7359e-04\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 238us/step - loss: 0.0030 - val_loss: 0.0011\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 241us/step - loss: 0.0025 - val_loss: 0.0012\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 250us/step - loss: 0.0024 - val_loss: 9.4975e-04\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 245us/step - loss: 0.0022 - val_loss: 7.3297e-04\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 244us/step - loss: 0.0020 - val_loss: 7.8833e-04\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 241us/step - loss: 0.0020 - val_loss: 6.5972e-04\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 238us/step - loss: 0.0020 - val_loss: 6.6730e-04\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 241us/step - loss: 0.0018 - val_loss: 6.8735e-04\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 236us/step - loss: 0.0018 - val_loss: 6.4306e-04\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 238us/step - loss: 0.0017 - val_loss: 7.1015e-04\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 248us/step - loss: 0.0016 - val_loss: 6.3404e-04\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 245us/step - loss: 0.0016 - val_loss: 7.2423e-04\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 244us/step - loss: 0.0016 - val_loss: 6.2517e-04\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 243us/step - loss: 0.0015 - val_loss: 7.7173e-04\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 249us/step - loss: 0.0014 - val_loss: 6.5501e-04\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 242us/step - loss: 0.0014 - val_loss: 6.6621e-04\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 246us/step - loss: 0.0014 - val_loss: 7.3309e-04\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 251us/step - loss: 0.0013 - val_loss: 6.4180e-04\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 243us/step - loss: 0.0014 - val_loss: 7.4547e-04\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 29s 8ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 238us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 238us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 239us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 238us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 242us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 240us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 239us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 239us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 243us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 240us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 239us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 239us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 242us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 243us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 238us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 238us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 243us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 240us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 239us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 240us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 239us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 238us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 239us/step - loss: nan - val_loss: nan\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 31s 9ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 504us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 2s 508us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 505us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 2s 507us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 2s 505us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 509us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 507us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 2s 508us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 2s 509us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 2s 507us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 515us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 520us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 2s 536us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3556/3556 [==============================] - 2s 524us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 2s 549us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 2s 577us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 572us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 2s 568us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 2s 538us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 2s 517us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 2s 541us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 2s 535us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 2s 530us/step - loss: nan - val_loss: nan\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 32s 9ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 509us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 2s 503us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 515us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 2s 508us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 2s 515us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 515us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 516us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 2s 508us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 2s 503us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 2s 500us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 503us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 502us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 2s 555us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 2s 541us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 2s 516us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 2s 519us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 516us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 2s 521us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 2s 526us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 2s 533us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 2s 537us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 2s 514us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 2s 534us/step - loss: nan - val_loss: nan\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 32s 9ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 510us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 2s 517us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 510us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 2s 512us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 2s 509us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 516us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 512us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 2s 513us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 2s 517us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 2s 514us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 507us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 506us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 2s 510us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 2s 511us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 2s 508us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 2s 509us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 505us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 2s 507us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 2s 516us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 2s 514us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 2s 511us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 2s 507us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 2s 512us/step - loss: nan - val_loss: nan\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 33s 9ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 509us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 2s 507us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 511us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 2s 505us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 2s 505us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 507us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 505us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 2s 509us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 2s 504us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 2s 505us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 510us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 506us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 2s 509us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 2s 510us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 2s 513us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 2s 506us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 513us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 2s 510us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 2s 507us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 2s 515us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 2s 510us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 2s 512us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3556/3556 [==============================] - 2s 511us/step - loss: nan - val_loss: nan\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 32s 9ms/step - loss: 1.1102 - val_loss: 0.0224\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 508us/step - loss: 0.0700 - val_loss: 0.0169\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 2s 508us/step - loss: 0.0691 - val_loss: 0.0862\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 507us/step - loss: 0.0578 - val_loss: 0.0131\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 2s 505us/step - loss: 0.0388 - val_loss: 0.0175\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 2s 504us/step - loss: 0.0084 - val_loss: 0.0466\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 511us/step - loss: 0.0081 - val_loss: 0.0149\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 505us/step - loss: 0.0096 - val_loss: 0.0342\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 2s 506us/step - loss: 0.0075 - val_loss: 0.0165\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 2s 506us/step - loss: 0.0060 - val_loss: 0.0300\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 2s 508us/step - loss: 0.0077 - val_loss: 0.0238\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 508us/step - loss: 0.0084 - val_loss: 0.0317\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 507us/step - loss: 0.0042 - val_loss: 0.0093\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 2s 521us/step - loss: 0.0057 - val_loss: 0.0491\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 2s 539us/step - loss: 0.0069 - val_loss: 0.0138\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 2s 516us/step - loss: 0.0034 - val_loss: 0.0054\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 2s 508us/step - loss: 0.0060 - val_loss: 0.0446\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 526us/step - loss: 0.0066 - val_loss: 0.0092\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 2s 512us/step - loss: 0.0033 - val_loss: 0.0090\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 2s 512us/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 2s 508us/step - loss: 0.0075 - val_loss: 0.0259\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 2s 512us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 2s 538us/step - loss: 0.0038 - val_loss: 0.0100\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 2s 562us/step - loss: 0.0032 - val_loss: 0.0034\n",
      "\n",
      "GENERATION 19\n",
      "\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 33s 9ms/step - loss: 0.4094 - val_loss: 0.0794\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 343us/step - loss: 0.0655 - val_loss: 0.0868\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 342us/step - loss: 0.0302 - val_loss: 0.0150\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 335us/step - loss: 0.0121 - val_loss: 0.0065\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 334us/step - loss: 0.0082 - val_loss: 0.0083\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 335us/step - loss: 0.0054 - val_loss: 0.0027\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 333us/step - loss: 0.0048 - val_loss: 0.0039\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 338us/step - loss: 0.0043 - val_loss: 0.0018\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 333us/step - loss: 0.0042 - val_loss: 0.0028\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 335us/step - loss: 0.0039 - val_loss: 0.0017\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 335us/step - loss: 0.0034 - val_loss: 0.0019\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 335us/step - loss: 0.0036 - val_loss: 0.0017\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 334us/step - loss: 0.0032 - val_loss: 0.0018\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 335us/step - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 334us/step - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 336us/step - loss: 0.0033 - val_loss: 0.0018\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 340us/step - loss: 0.0031 - val_loss: 0.0017\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 333us/step - loss: 0.0031 - val_loss: 0.0016\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 335us/step - loss: 0.0030 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 335us/step - loss: 0.0032 - val_loss: 0.0016\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 337us/step - loss: 0.0029 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 338us/step - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 334us/step - loss: 0.0028 - val_loss: 0.0017\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 334us/step - loss: 0.0027 - val_loss: 0.0016\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 31s 9ms/step - loss: 0.0626 - val_loss: 0.0479\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 0.0136 - val_loss: 0.0155\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 0.0055 - val_loss: 0.0052\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 261us/step - loss: 0.0031 - val_loss: 0.0018\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 261us/step - loss: 0.0018 - val_loss: 8.0887e-04\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 261us/step - loss: 0.0011 - val_loss: 7.8335e-04\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 8.3846e-04 - val_loss: 0.0011\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 261us/step - loss: 7.5264e-04 - val_loss: 7.9138e-04\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 261us/step - loss: 7.0995e-04 - val_loss: 9.1569e-04\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 6.9311e-04 - val_loss: 7.2599e-04\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 6.6613e-04 - val_loss: 8.0548e-04\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 6.5279e-04 - val_loss: 7.1436e-04\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 6.4720e-04 - val_loss: 7.5674e-04\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 261us/step - loss: 6.3986e-04 - val_loss: 7.0254e-04\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 6.3424e-04 - val_loss: 7.2607e-04\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 271us/step - loss: 6.2702e-04 - val_loss: 7.0066e-04\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 261us/step - loss: 6.2038e-04 - val_loss: 6.8997e-04\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 261us/step - loss: 6.1359e-04 - val_loss: 6.8949e-04\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 6.0829e-04 - val_loss: 6.7286e-04\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 6.0337e-04 - val_loss: 6.8808e-04\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 6.0061e-04 - val_loss: 6.5713e-04\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 5.9144e-04 - val_loss: 6.6235e-04\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 5.8549e-04 - val_loss: 6.4551e-04\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 261us/step - loss: 5.8002e-04 - val_loss: 6.4020e-04\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 32s 9ms/step - loss: 0.0499 - val_loss: 0.0365\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 0.0121 - val_loss: 0.0183\n",
      "Epoch 3/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3556/3556 [==============================] - 1s 264us/step - loss: 0.0048 - val_loss: 0.0055\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 261us/step - loss: 0.0028 - val_loss: 0.0048\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 9.5319e-04 - val_loss: 7.7990e-04\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 8.4634e-04 - val_loss: 9.7277e-04\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 7.7348e-04 - val_loss: 8.0961e-04\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 7.3289e-04 - val_loss: 9.2281e-04\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 269us/step - loss: 7.1462e-04 - val_loss: 7.7744e-04\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 6.9426e-04 - val_loss: 8.6787e-04\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 6.8153e-04 - val_loss: 7.7102e-04\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 6.7084e-04 - val_loss: 7.8786e-04\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 261us/step - loss: 6.6115e-04 - val_loss: 7.5364e-04\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 6.5445e-04 - val_loss: 7.3553e-04\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 6.4451e-04 - val_loss: 7.4830e-04\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 6.3435e-04 - val_loss: 7.3418e-04\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 6.2636e-04 - val_loss: 7.1075e-04\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 6.1846e-04 - val_loss: 6.8984e-04\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 6.1119e-04 - val_loss: 6.9883e-04\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 6.0174e-04 - val_loss: 6.6402e-04\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 5.9393e-04 - val_loss: 6.7855e-04\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 5.8603e-04 - val_loss: 6.4528e-04\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 34s 9ms/step - loss: 0.0781 - val_loss: 0.0354\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 565us/step - loss: 0.0139 - val_loss: 0.0029\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 2s 562us/step - loss: 0.0068 - val_loss: 0.0023\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 564us/step - loss: 0.0049 - val_loss: 0.0022\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 2s 560us/step - loss: 0.0037 - val_loss: 0.0014\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 2s 562us/step - loss: 0.0032 - val_loss: 0.0015\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 562us/step - loss: 0.0030 - val_loss: 0.0015\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 562us/step - loss: 0.0028 - val_loss: 0.0013\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 2s 563us/step - loss: 0.0027 - val_loss: 0.0016\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 2s 561us/step - loss: 0.0024 - val_loss: 0.0013\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 2s 560us/step - loss: 0.0024 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 560us/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 560us/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 2s 563us/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 2s 566us/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 2s 565us/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 2s 565us/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 565us/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 2s 566us/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 2s 563us/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 2s 561us/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 2s 562us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 2s 563us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 2s 565us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 35s 10ms/step - loss: 0.0531 - val_loss: 0.0016\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 567us/step - loss: 0.0074 - val_loss: 0.0070\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 2s 564us/step - loss: 0.0057 - val_loss: 0.0039\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 564us/step - loss: 0.0036 - val_loss: 0.0017\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 2s 563us/step - loss: 0.0032 - val_loss: 0.0014\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 2s 565us/step - loss: 0.0028 - val_loss: 0.0016\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 562us/step - loss: 0.0024 - val_loss: 0.0014\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 565us/step - loss: 0.0025 - val_loss: 0.0012\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 2s 567us/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 2s 563us/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 2s 564us/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 565us/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 565us/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 2s 569us/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 2s 563us/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 2s 567us/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 2s 565us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 564us/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 2s 564us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 2s 564us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 2s 565us/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 2s 561us/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 2s 566us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 2s 566us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 34s 10ms/step - loss: 0.0564 - val_loss: 0.0315\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 424us/step - loss: 0.0141 - val_loss: 0.0092\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 420us/step - loss: 0.0076 - val_loss: 0.0040\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 416us/step - loss: 0.0054 - val_loss: 0.0027\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 414us/step - loss: 0.0042 - val_loss: 0.0015\n",
      "Epoch 6/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3556/3556 [==============================] - 1s 415us/step - loss: 0.0036 - val_loss: 0.0015\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 415us/step - loss: 0.0034 - val_loss: 0.0020\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 414us/step - loss: 0.0032 - val_loss: 0.0014\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 414us/step - loss: 0.0030 - val_loss: 0.0018\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 416us/step - loss: 0.0029 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 414us/step - loss: 0.0028 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 412us/step - loss: 0.0027 - val_loss: 0.0015\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 419us/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 415us/step - loss: 0.0026 - val_loss: 0.0014\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 421us/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 415us/step - loss: 0.0026 - val_loss: 0.0013\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 415us/step - loss: 0.0024 - val_loss: 0.0013\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 415us/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 415us/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 414us/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 413us/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 414us/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 413us/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 419us/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 35s 10ms/step - loss: 0.3203 - val_loss: 0.0419\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 1s 419us/step - loss: 0.0861 - val_loss: 0.0117\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 1s 415us/step - loss: 0.0182 - val_loss: 0.0051\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 1s 416us/step - loss: 0.0094 - val_loss: 0.0031\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 1s 416us/step - loss: 0.0060 - val_loss: 0.0030\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 1s 412us/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 1s 416us/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 1s 418us/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 1s 413us/step - loss: 0.0030 - val_loss: 0.0019\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 1s 416us/step - loss: 0.0028 - val_loss: 0.0020\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 1s 416us/step - loss: 0.0027 - val_loss: 0.0021\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 1s 418us/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 1s 415us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 1s 416us/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 1s 415us/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 1s 414us/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 1s 415us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 1s 416us/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 1s 420us/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 1s 415us/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 1s 414us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 1s 415us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 1s 417us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 1s 417us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 35s 10ms/step - loss: 0.0799 - val_loss: 0.0515\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 527us/step - loss: 0.0168 - val_loss: 0.0173\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 2s 521us/step - loss: 0.0076 - val_loss: 0.0080\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 519us/step - loss: 0.0050 - val_loss: 0.0060\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 2s 522us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 2s 523us/step - loss: 0.0031 - val_loss: 0.0026\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 526us/step - loss: 0.0027 - val_loss: 0.0014\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 522us/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 2s 526us/step - loss: 0.0024 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 2s 520us/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "3556/3556 [==============================] - 2s 520us/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 523us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 521us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 2s 521us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 2s 522us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 2s 523us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 2s 524us/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 525us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 2s 527us/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 2s 521us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 2s 525us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 2s 522us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 2s 524us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 2s 523us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/24\n",
      "3556/3556 [==============================] - 38s 11ms/step - loss: 0.0822 - val_loss: 0.0508\n",
      "Epoch 2/24\n",
      "3556/3556 [==============================] - 2s 534us/step - loss: 0.0159 - val_loss: 0.0089\n",
      "Epoch 3/24\n",
      "3556/3556 [==============================] - 2s 530us/step - loss: 0.0070 - val_loss: 0.0051\n",
      "Epoch 4/24\n",
      "3556/3556 [==============================] - 2s 530us/step - loss: 0.0042 - val_loss: 0.0053\n",
      "Epoch 5/24\n",
      "3556/3556 [==============================] - 2s 531us/step - loss: 0.0028 - val_loss: 0.0020\n",
      "Epoch 6/24\n",
      "3556/3556 [==============================] - 2s 529us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 7/24\n",
      "3556/3556 [==============================] - 2s 528us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 8/24\n",
      "3556/3556 [==============================] - 2s 528us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 9/24\n",
      "3556/3556 [==============================] - 2s 531us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "3556/3556 [==============================] - 2s 529us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 11/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3556/3556 [==============================] - 2s 530us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "3556/3556 [==============================] - 2s 527us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 13/24\n",
      "3556/3556 [==============================] - 2s 527us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 14/24\n",
      "3556/3556 [==============================] - 2s 529us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 15/24\n",
      "3556/3556 [==============================] - 2s 536us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 16/24\n",
      "3556/3556 [==============================] - 2s 528us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 17/24\n",
      "3556/3556 [==============================] - 2s 527us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 18/24\n",
      "3556/3556 [==============================] - 2s 542us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 19/24\n",
      "3556/3556 [==============================] - 2s 538us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 20/24\n",
      "3556/3556 [==============================] - 2s 527us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 21/24\n",
      "3556/3556 [==============================] - 2s 528us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "3556/3556 [==============================] - 2s 529us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 23/24\n",
      "3556/3556 [==============================] - 2s 536us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 24/24\n",
      "3556/3556 [==============================] - 2s 537us/step - loss: 0.0015 - val_loss: 0.0012\n"
     ]
    }
   ],
   "source": [
    "best_models = breed_population(X_train, Y_train, generations=20, population_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.04064037278294563,\n",
       " 0.018480343744158745,\n",
       " 0.005804229993373156,\n",
       " 0.003724922426044941,\n",
       " 0.000808300101198256,\n",
       " 0.0009100708994083107,\n",
       " 0.0008226894424296916,\n",
       " 0.0007285691099241376,\n",
       " 0.0008315611048601568,\n",
       " 0.0007282497826963663,\n",
       " 0.0007741482695564628,\n",
       " 0.0007225354202091694,\n",
       " 0.0007273679948411882,\n",
       " 0.0007251087226904929,\n",
       " 0.0006891863304190338,\n",
       " 0.0007036002352833748,\n",
       " 0.0006885534385219216,\n",
       " 0.000686720188241452,\n",
       " 0.0006702071405015886,\n",
       " 0.0006434829556383193,\n",
       " 0.0006468871142715216,\n",
       " 0.0006403768202289939,\n",
       " 0.0006151939742267132,\n",
       " 0.0006495241541415453]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models[0][1].history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal parameters\n",
      "_______________________\n",
      "lstmsize: 170\n",
      "activation: selu\n",
      "twice: False\n",
      "density: 200\n",
      "optimizer: adam\n",
      "shuffle: True\n"
     ]
    }
   ],
   "source": [
    "print('optimal parameters')\n",
    "print('_______________________')\n",
    "for key,val in best_models[0][2].items():\n",
    "    if key != 'x' and key != 'y': print(f'{key}: {val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_96\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_157 (LSTM)              (None, 170)               119680    \n",
      "_________________________________________________________________\n",
      "dense_346 (Dense)            (None, 200)               34200     \n",
      "_________________________________________________________________\n",
      "dense_347 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 154,081\n",
      "Trainable params: 154,081\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_models[0][0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibm_checkpoint = ModelCheckpoint(\n",
    "    filepath='./checkpoints/IBM.{epoch}-{val_loss}.hdf5',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = best_models[0][2]\n",
    "params['x'] = X_train\n",
    "params['y'] = Y_train\n",
    "params['epochs'] = 2000\n",
    "params['callbacks'] = [ibm_checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3556 samples, validate on 396 samples\n",
      "Epoch 1/2000\n",
      "3556/3556 [==============================] - 34s 10ms/step - loss: 0.0653 - val_loss: 0.0253\n",
      "Epoch 2/2000\n",
      "3556/3556 [==============================] - 1s 273us/step - loss: 0.0124 - val_loss: 0.0123\n",
      "Epoch 3/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 0.0050 - val_loss: 0.0026\n",
      "Epoch 4/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 0.0028 - val_loss: 0.0018\n",
      "Epoch 5/2000\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 6/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 0.0010 - val_loss: 7.1229e-04\n",
      "Epoch 7/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 8.5293e-04 - val_loss: 0.0014\n",
      "Epoch 8/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 7.5314e-04 - val_loss: 6.9488e-04\n",
      "Epoch 9/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 7.2286e-04 - val_loss: 0.0011\n",
      "Epoch 10/2000\n",
      "3556/3556 [==============================] - 1s 267us/step - loss: 6.8987e-04 - val_loss: 7.0958e-04\n",
      "Epoch 11/2000\n",
      "3556/3556 [==============================] - 1s 277us/step - loss: 6.6539e-04 - val_loss: 9.5970e-04\n",
      "Epoch 12/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 6.5150e-04 - val_loss: 7.2586e-04\n",
      "Epoch 13/2000\n",
      "3556/3556 [==============================] - 1s 276us/step - loss: 6.4321e-04 - val_loss: 8.6064e-04\n",
      "Epoch 14/2000\n",
      "3556/3556 [==============================] - 1s 267us/step - loss: 6.3285e-04 - val_loss: 7.4139e-04\n",
      "Epoch 15/2000\n",
      "3556/3556 [==============================] - 1s 269us/step - loss: 6.2437e-04 - val_loss: 7.4697e-04\n",
      "Epoch 16/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 6.1437e-04 - val_loss: 7.2631e-04\n",
      "Epoch 17/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 6.0713e-04 - val_loss: 7.2361e-04\n",
      "Epoch 18/2000\n",
      "3556/3556 [==============================] - 1s 271us/step - loss: 5.9956e-04 - val_loss: 7.1665e-04\n",
      "Epoch 19/2000\n",
      "3556/3556 [==============================] - 1s 269us/step - loss: 5.9432e-04 - val_loss: 6.7797e-04\n",
      "Epoch 20/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 5.8699e-04 - val_loss: 6.8796e-04\n",
      "Epoch 21/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 5.7862e-04 - val_loss: 6.7644e-04\n",
      "Epoch 22/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 5.7273e-04 - val_loss: 6.7884e-04\n",
      "Epoch 23/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 5.6645e-04 - val_loss: 6.3704e-04\n",
      "Epoch 24/2000\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 5.6076e-04 - val_loss: 6.9307e-04\n",
      "Epoch 25/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 5.5786e-04 - val_loss: 6.3999e-04\n",
      "Epoch 26/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 5.5244e-04 - val_loss: 6.0808e-04\n",
      "Epoch 27/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 5.4503e-04 - val_loss: 6.3377e-04\n",
      "Epoch 28/2000\n",
      "3556/3556 [==============================] - 1s 267us/step - loss: 5.3903e-04 - val_loss: 6.1539e-04\n",
      "Epoch 29/2000\n",
      "3556/3556 [==============================] - 1s 268us/step - loss: 5.3385e-04 - val_loss: 6.0317e-04\n",
      "Epoch 30/2000\n",
      "3556/3556 [==============================] - 1s 272us/step - loss: 5.2981e-04 - val_loss: 5.9094e-04\n",
      "Epoch 31/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 5.2532e-04 - val_loss: 6.0773e-04\n",
      "Epoch 32/2000\n",
      "3556/3556 [==============================] - 1s 267us/step - loss: 5.2447e-04 - val_loss: 6.1491e-04\n",
      "Epoch 33/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 5.1579e-04 - val_loss: 5.6937e-04\n",
      "Epoch 34/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 5.1261e-04 - val_loss: 6.3415e-04\n",
      "Epoch 35/2000\n",
      "3556/3556 [==============================] - 1s 270us/step - loss: 5.1150e-04 - val_loss: 5.6450e-04\n",
      "Epoch 36/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 5.0402e-04 - val_loss: 5.5537e-04\n",
      "Epoch 37/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 5.0044e-04 - val_loss: 5.6747e-04\n",
      "Epoch 38/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 4.9649e-04 - val_loss: 5.5343e-04\n",
      "Epoch 39/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 4.9521e-04 - val_loss: 5.3179e-04\n",
      "Epoch 40/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 4.8905e-04 - val_loss: 5.4123e-04\n",
      "Epoch 41/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 4.8658e-04 - val_loss: 5.5191e-04\n",
      "Epoch 42/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 4.8122e-04 - val_loss: 5.3681e-04\n",
      "Epoch 43/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 4.7905e-04 - val_loss: 5.3293e-04\n",
      "Epoch 44/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 4.7852e-04 - val_loss: 5.1526e-04\n",
      "Epoch 45/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 4.7725e-04 - val_loss: 5.0918e-04\n",
      "Epoch 46/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 4.7130e-04 - val_loss: 5.0739e-04\n",
      "Epoch 47/2000\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 4.7025e-04 - val_loss: 5.1275e-04\n",
      "Epoch 48/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 4.6728e-04 - val_loss: 5.0350e-04\n",
      "Epoch 49/2000\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 4.6304e-04 - val_loss: 5.5684e-04\n",
      "Epoch 50/2000\n",
      "3556/3556 [==============================] - 1s 271us/step - loss: 4.6174e-04 - val_loss: 4.9688e-04\n",
      "Epoch 51/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 4.5749e-04 - val_loss: 4.9136e-04\n",
      "Epoch 52/2000\n",
      "3556/3556 [==============================] - 1s 269us/step - loss: 4.5625e-04 - val_loss: 4.8790e-04\n",
      "Epoch 53/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 4.5245e-04 - val_loss: 4.8723e-04\n",
      "Epoch 54/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 4.5088e-04 - val_loss: 4.9136e-04\n",
      "Epoch 55/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 4.4983e-04 - val_loss: 4.9596e-04\n",
      "Epoch 56/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 4.4793e-04 - val_loss: 4.9818e-04\n",
      "Epoch 57/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 4.4761e-04 - val_loss: 5.0052e-04\n",
      "Epoch 58/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 4.4392e-04 - val_loss: 5.0773e-04\n",
      "Epoch 59/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 4.3944e-04 - val_loss: 4.8153e-04\n",
      "Epoch 60/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 4.3963e-04 - val_loss: 4.6931e-04\n",
      "Epoch 61/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 4.3446e-04 - val_loss: 4.7564e-04\n",
      "Epoch 62/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 4.3362e-04 - val_loss: 4.7162e-04\n",
      "Epoch 63/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 4.3166e-04 - val_loss: 4.6354e-04\n",
      "Epoch 64/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 4.3167e-04 - val_loss: 4.6129e-04\n",
      "Epoch 65/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 4.2706e-04 - val_loss: 4.7273e-04\n",
      "Epoch 66/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 4.2372e-04 - val_loss: 4.6149e-04\n",
      "Epoch 67/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 4.2157e-04 - val_loss: 4.5641e-04\n",
      "Epoch 68/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 4.2077e-04 - val_loss: 4.6294e-04\n",
      "Epoch 69/2000\n",
      "3556/3556 [==============================] - 1s 269us/step - loss: 4.1980e-04 - val_loss: 4.6073e-04\n",
      "Epoch 70/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 4.2072e-04 - val_loss: 4.5039e-04\n",
      "Epoch 71/2000\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 4.1595e-04 - val_loss: 4.4669e-04\n",
      "Epoch 72/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3556/3556 [==============================] - 1s 271us/step - loss: 4.1205e-04 - val_loss: 4.6301e-04\n",
      "Epoch 73/2000\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 4.1028e-04 - val_loss: 4.5237e-04\n",
      "Epoch 74/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 4.1032e-04 - val_loss: 4.4548e-04\n",
      "Epoch 75/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 4.1402e-04 - val_loss: 4.4103e-04\n",
      "Epoch 76/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 4.1850e-04 - val_loss: 4.4556e-04\n",
      "Epoch 77/2000\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 4.2563e-04 - val_loss: 4.8490e-04\n",
      "Epoch 78/2000\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 4.1254e-04 - val_loss: 4.7157e-04\n",
      "Epoch 79/2000\n",
      "3556/3556 [==============================] - ETA: 0s - loss: 3.9755e-0 - 1s 264us/step - loss: 4.0690e-04 - val_loss: 4.5540e-04\n",
      "Epoch 80/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 4.0867e-04 - val_loss: 4.3321e-04\n",
      "Epoch 81/2000\n",
      "3556/3556 [==============================] - 1s 268us/step - loss: 3.9995e-04 - val_loss: 4.3221e-04\n",
      "Epoch 82/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.9571e-04 - val_loss: 4.3208e-04\n",
      "Epoch 83/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 3.9744e-04 - val_loss: 4.3565e-04\n",
      "Epoch 84/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 3.9459e-04 - val_loss: 4.6539e-04\n",
      "Epoch 85/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 3.9677e-04 - val_loss: 4.4046e-04\n",
      "Epoch 86/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 3.9082e-04 - val_loss: 4.3338e-04\n",
      "Epoch 87/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.8943e-04 - val_loss: 4.3287e-04\n",
      "Epoch 88/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.9075e-04 - val_loss: 4.2009e-04\n",
      "Epoch 89/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 3.8800e-04 - val_loss: 4.3061e-04\n",
      "Epoch 90/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.8410e-04 - val_loss: 4.1841e-04\n",
      "Epoch 91/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.8271e-04 - val_loss: 4.2894e-04\n",
      "Epoch 92/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.8100e-04 - val_loss: 4.2948e-04\n",
      "Epoch 93/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.8453e-04 - val_loss: 4.3355e-04\n",
      "Epoch 94/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.7987e-04 - val_loss: 4.2625e-04\n",
      "Epoch 95/2000\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 3.7702e-04 - val_loss: 4.1570e-04\n",
      "Epoch 96/2000\n",
      "3556/3556 [==============================] - 1s 260us/step - loss: 3.8059e-04 - val_loss: 4.3972e-04\n",
      "Epoch 97/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 3.8385e-04 - val_loss: 4.1720e-04\n",
      "Epoch 98/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.8953e-04 - val_loss: 4.3538e-04\n",
      "Epoch 99/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 4.1251e-04 - val_loss: 4.1094e-04\n",
      "Epoch 100/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 3.7885e-04 - val_loss: 4.3512e-04\n",
      "Epoch 101/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 3.7802e-04 - val_loss: 4.3797e-04\n",
      "Epoch 102/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 3.7704e-04 - val_loss: 4.1133e-04\n",
      "Epoch 103/2000\n",
      "3556/3556 [==============================] - 1s 268us/step - loss: 3.7797e-04 - val_loss: 4.0514e-04\n",
      "Epoch 104/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.7313e-04 - val_loss: 4.9601e-04\n",
      "Epoch 105/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 3.7874e-04 - val_loss: 4.0516e-04\n",
      "Epoch 106/2000\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 3.7481e-04 - val_loss: 4.0919e-04\n",
      "Epoch 107/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.6968e-04 - val_loss: 4.0812e-04\n",
      "Epoch 108/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.6723e-04 - val_loss: 4.3648e-04\n",
      "Epoch 109/2000\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 3.6339e-04 - val_loss: 4.0686e-04\n",
      "Epoch 110/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 3.6525e-04 - val_loss: 4.0065e-04\n",
      "Epoch 111/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 3.6097e-04 - val_loss: 4.3342e-04\n",
      "Epoch 112/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.6011e-04 - val_loss: 4.4337e-04\n",
      "Epoch 113/2000\n",
      "3556/3556 [==============================] - 1s 269us/step - loss: 3.6331e-04 - val_loss: 3.9554e-04\n",
      "Epoch 114/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.6131e-04 - val_loss: 4.4557e-04\n",
      "Epoch 115/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 3.5826e-04 - val_loss: 3.9918e-04\n",
      "Epoch 116/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 3.5779e-04 - val_loss: 3.9727e-04\n",
      "Epoch 117/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.6081e-04 - val_loss: 4.2606e-04\n",
      "Epoch 118/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.5408e-04 - val_loss: 3.9211e-04\n",
      "Epoch 119/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 3.5472e-04 - val_loss: 3.8938e-04\n",
      "Epoch 120/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 3.6350e-04 - val_loss: 4.6903e-04\n",
      "Epoch 121/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 3.6749e-04 - val_loss: 3.9280e-04\n",
      "Epoch 122/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.5938e-04 - val_loss: 3.9722e-04\n",
      "Epoch 123/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.6839e-04 - val_loss: 4.5409e-04\n",
      "Epoch 124/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.6824e-04 - val_loss: 3.8686e-04\n",
      "Epoch 125/2000\n",
      "3556/3556 [==============================] - 1s 261us/step - loss: 3.4978e-04 - val_loss: 4.1733e-04\n",
      "Epoch 126/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 3.4689e-04 - val_loss: 4.3852e-04\n",
      "Epoch 127/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.5387e-04 - val_loss: 3.8597e-04\n",
      "Epoch 128/2000\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 3.4509e-04 - val_loss: 4.1420e-04\n",
      "Epoch 129/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 3.4295e-04 - val_loss: 4.0014e-04\n",
      "Epoch 130/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.4280e-04 - val_loss: 3.8777e-04\n",
      "Epoch 131/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.4290e-04 - val_loss: 3.8983e-04\n",
      "Epoch 132/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.4322e-04 - val_loss: 4.4121e-04\n",
      "Epoch 133/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 3.5755e-04 - val_loss: 3.8505e-04\n",
      "Epoch 134/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 3.6730e-04 - val_loss: 4.7904e-04\n",
      "Epoch 135/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 3.5771e-04 - val_loss: 3.8058e-04\n",
      "Epoch 136/2000\n",
      "3556/3556 [==============================] - 1s 269us/step - loss: 3.4020e-04 - val_loss: 3.8038e-04\n",
      "Epoch 137/2000\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 3.4285e-04 - val_loss: 4.9710e-04\n",
      "Epoch 138/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 3.5938e-04 - val_loss: 3.7951e-04\n",
      "Epoch 139/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.4689e-04 - val_loss: 4.2333e-04\n",
      "Epoch 140/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 3.3735e-04 - val_loss: 3.8234e-04\n",
      "Epoch 141/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.3392e-04 - val_loss: 3.7707e-04\n",
      "Epoch 142/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 3.3861e-04 - val_loss: 3.7855e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 3.4201e-04 - val_loss: 3.8205e-04\n",
      "Epoch 144/2000\n",
      "3556/3556 [==============================] - 1s 270us/step - loss: 3.3991e-04 - val_loss: 3.7533e-04\n",
      "Epoch 145/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.3393e-04 - val_loss: 3.7373e-04\n",
      "Epoch 146/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.3769e-04 - val_loss: 4.8180e-04\n",
      "Epoch 147/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 3.4557e-04 - val_loss: 3.7961e-04\n",
      "Epoch 148/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.3172e-04 - val_loss: 4.0212e-04\n",
      "Epoch 149/2000\n",
      "3556/3556 [==============================] - 1s 261us/step - loss: 3.2889e-04 - val_loss: 3.7600e-04\n",
      "Epoch 150/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.2893e-04 - val_loss: 3.8095e-04\n",
      "Epoch 151/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 3.2645e-04 - val_loss: 3.7146e-04\n",
      "Epoch 152/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.3255e-04 - val_loss: 3.7498e-04\n",
      "Epoch 153/2000\n",
      "3556/3556 [==============================] - 1s 270us/step - loss: 3.2933e-04 - val_loss: 4.0389e-04\n",
      "Epoch 154/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.3058e-04 - val_loss: 3.7206e-04\n",
      "Epoch 155/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 3.2546e-04 - val_loss: 3.7619e-04\n",
      "Epoch 156/2000\n",
      "3556/3556 [==============================] - 1s 267us/step - loss: 3.3056e-04 - val_loss: 3.8629e-04\n",
      "Epoch 157/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 3.3128e-04 - val_loss: 3.7069e-04\n",
      "Epoch 158/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 3.2646e-04 - val_loss: 3.7030e-04\n",
      "Epoch 159/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 3.2368e-04 - val_loss: 4.0914e-04\n",
      "Epoch 160/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 3.3493e-04 - val_loss: 3.7215e-04\n",
      "Epoch 161/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 3.6355e-04 - val_loss: 5.6700e-04\n",
      "Epoch 162/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.5867e-04 - val_loss: 3.7212e-04\n",
      "Epoch 163/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 3.4354e-04 - val_loss: 3.8329e-04\n",
      "Epoch 164/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 3.3266e-04 - val_loss: 3.8857e-04\n",
      "Epoch 165/2000\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 3.2009e-04 - val_loss: 3.6896e-04\n",
      "Epoch 166/2000\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 3.2209e-04 - val_loss: 4.0642e-04\n",
      "Epoch 167/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 3.3043e-04 - val_loss: 3.7743e-04\n",
      "Epoch 168/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.6610e-04 - val_loss: 4.1075e-04\n",
      "Epoch 169/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.4683e-04 - val_loss: 3.7828e-04\n",
      "Epoch 170/2000\n",
      "3556/3556 [==============================] - 1s 270us/step - loss: 3.4956e-04 - val_loss: 4.0854e-04\n",
      "Epoch 171/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 3.3611e-04 - val_loss: 3.6712e-04\n",
      "Epoch 172/2000\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 3.2324e-04 - val_loss: 3.9549e-04\n",
      "Epoch 173/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 3.2332e-04 - val_loss: 3.7409e-04\n",
      "Epoch 174/2000\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 3.1848e-04 - val_loss: 3.6589e-04\n",
      "Epoch 175/2000\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 3.2800e-04 - val_loss: 4.4245e-04\n",
      "Epoch 176/2000\n",
      "3556/3556 [==============================] - 1s 270us/step - loss: 3.3437e-04 - val_loss: 3.6712e-04\n",
      "Epoch 177/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.3359e-04 - val_loss: 4.8132e-04\n",
      "Epoch 178/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 3.4081e-04 - val_loss: 3.6810e-04\n",
      "Epoch 179/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 3.1359e-04 - val_loss: 3.6980e-04\n",
      "Epoch 180/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 3.1734e-04 - val_loss: 3.7098e-04\n",
      "Epoch 181/2000\n",
      "3556/3556 [==============================] - ETA: 0s - loss: 3.0863e-0 - 1s 264us/step - loss: 3.1536e-04 - val_loss: 3.8525e-04\n",
      "Epoch 182/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.1204e-04 - val_loss: 3.6650e-04\n",
      "Epoch 183/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 3.1325e-04 - val_loss: 4.4110e-04\n",
      "Epoch 184/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 3.2294e-04 - val_loss: 3.6779e-04\n",
      "Epoch 185/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.2601e-04 - val_loss: 4.1115e-04\n",
      "Epoch 186/2000\n",
      "3556/3556 [==============================] - 1s 267us/step - loss: 3.2999e-04 - val_loss: 3.9946e-04\n",
      "Epoch 187/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 3.1486e-04 - val_loss: 3.6316e-04\n",
      "Epoch 188/2000\n",
      "3556/3556 [==============================] - 1s 261us/step - loss: 3.1569e-04 - val_loss: 3.8108e-04\n",
      "Epoch 189/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 3.2417e-04 - val_loss: 4.1217e-04\n",
      "Epoch 190/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 3.2508e-04 - val_loss: 3.6411e-04\n",
      "Epoch 191/2000\n",
      "3556/3556 [==============================] - ETA: 0s - loss: 3.1669e-0 - 1s 264us/step - loss: 3.1557e-04 - val_loss: 3.7671e-04\n",
      "Epoch 192/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 3.1525e-04 - val_loss: 3.9685e-04\n",
      "Epoch 193/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.1292e-04 - val_loss: 3.7080e-04\n",
      "Epoch 194/2000\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 3.0910e-04 - val_loss: 3.9669e-04\n",
      "Epoch 195/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 3.1871e-04 - val_loss: 3.6838e-04\n",
      "Epoch 196/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.1276e-04 - val_loss: 3.6806e-04\n",
      "Epoch 197/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.1161e-04 - val_loss: 4.1041e-04\n",
      "Epoch 198/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.1204e-04 - val_loss: 3.6154e-04\n",
      "Epoch 199/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 3.0832e-04 - val_loss: 3.8992e-04\n",
      "Epoch 200/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 3.0786e-04 - val_loss: 3.8217e-04\n",
      "Epoch 201/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 3.0624e-04 - val_loss: 3.6117e-04\n",
      "Epoch 202/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 3.1103e-04 - val_loss: 3.8166e-04\n",
      "Epoch 203/2000\n",
      "3556/3556 [==============================] - 1s 269us/step - loss: 3.0610e-04 - val_loss: 3.8203e-04\n",
      "Epoch 204/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 3.0403e-04 - val_loss: 3.6061e-04\n",
      "Epoch 205/2000\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 3.0380e-04 - val_loss: 3.7658e-04\n",
      "Epoch 206/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 3.0351e-04 - val_loss: 3.6545e-04\n",
      "Epoch 207/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 3.0523e-04 - val_loss: 3.6747e-04\n",
      "Epoch 208/2000\n",
      "3556/3556 [==============================] - 1s 268us/step - loss: 3.1204e-04 - val_loss: 4.4863e-04\n",
      "Epoch 209/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 3.2759e-04 - val_loss: 3.7427e-04\n",
      "Epoch 210/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.0531e-04 - val_loss: 3.6043e-04\n",
      "Epoch 211/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 3.0715e-04 - val_loss: 3.5994e-04\n",
      "Epoch 212/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.1337e-04 - val_loss: 3.9941e-04\n",
      "Epoch 213/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3556/3556 [==============================] - 1s 273us/step - loss: 3.0862e-04 - val_loss: 3.9503e-04\n",
      "Epoch 214/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 3.1491e-04 - val_loss: 3.8239e-04\n",
      "Epoch 215/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.2433e-04 - val_loss: 4.1795e-04\n",
      "Epoch 216/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 3.3725e-04 - val_loss: 3.6016e-04\n",
      "Epoch 217/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 3.2178e-04 - val_loss: 4.5725e-04\n",
      "Epoch 218/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.2554e-04 - val_loss: 3.5997e-04\n",
      "Epoch 219/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.0378e-04 - val_loss: 3.6137e-04\n",
      "Epoch 220/2000\n",
      "3556/3556 [==============================] - 1s 269us/step - loss: 3.0483e-04 - val_loss: 3.8215e-04\n",
      "Epoch 221/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 3.0075e-04 - val_loss: 3.7343e-04\n",
      "Epoch 222/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.0031e-04 - val_loss: 3.6578e-04\n",
      "Epoch 223/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.0642e-04 - val_loss: 3.8204e-04\n",
      "Epoch 224/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 3.2502e-04 - val_loss: 3.6277e-04\n",
      "Epoch 225/2000\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 3.1924e-04 - val_loss: 5.4990e-04\n",
      "Epoch 226/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 3.4582e-04 - val_loss: 3.5935e-04\n",
      "Epoch 227/2000\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 3.1084e-04 - val_loss: 3.6584e-04\n",
      "Epoch 228/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 3.0796e-04 - val_loss: 3.5928e-04\n",
      "Epoch 229/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9772e-04 - val_loss: 3.7817e-04\n",
      "Epoch 230/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.0237e-04 - val_loss: 3.5888e-04\n",
      "Epoch 231/2000\n",
      "3556/3556 [==============================] - 1s 261us/step - loss: 3.0733e-04 - val_loss: 3.9497e-04\n",
      "Epoch 232/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.3158e-04 - val_loss: 3.6744e-04\n",
      "Epoch 233/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 3.0173e-04 - val_loss: 3.9603e-04\n",
      "Epoch 234/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.0057e-04 - val_loss: 3.5845e-04\n",
      "Epoch 235/2000\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 3.0288e-04 - val_loss: 3.6883e-04\n",
      "Epoch 236/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.0429e-04 - val_loss: 3.9051e-04\n",
      "Epoch 237/2000\n",
      "3556/3556 [==============================] - 1s 269us/step - loss: 2.9666e-04 - val_loss: 3.6081e-04\n",
      "Epoch 238/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 3.0052e-04 - val_loss: 3.5871e-04\n",
      "Epoch 239/2000\n",
      "3556/3556 [==============================] - 1s 268us/step - loss: 2.9926e-04 - val_loss: 3.6239e-04\n",
      "Epoch 240/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 3.0521e-04 - val_loss: 3.8349e-04\n",
      "Epoch 241/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.0924e-04 - val_loss: 4.6868e-04\n",
      "Epoch 242/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.0711e-04 - val_loss: 3.7355e-04\n",
      "Epoch 243/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.9638e-04 - val_loss: 4.0952e-04\n",
      "Epoch 244/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.2154e-04 - val_loss: 4.5689e-04\n",
      "Epoch 245/2000\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 3.3559e-04 - val_loss: 3.7520e-04\n",
      "Epoch 246/2000\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 3.4028e-04 - val_loss: 4.0910e-04\n",
      "Epoch 247/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 3.3275e-04 - val_loss: 3.8125e-04\n",
      "Epoch 248/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 3.4252e-04 - val_loss: 5.7526e-04\n",
      "Epoch 249/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 3.5416e-04 - val_loss: 3.8924e-04\n",
      "Epoch 250/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.2587e-04 - val_loss: 3.6417e-04\n",
      "Epoch 251/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 3.0151e-04 - val_loss: 3.7965e-04\n",
      "Epoch 252/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.0088e-04 - val_loss: 3.8601e-04\n",
      "Epoch 253/2000\n",
      "3556/3556 [==============================] - 1s 261us/step - loss: 2.9464e-04 - val_loss: 3.7026e-04\n",
      "Epoch 254/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.9955e-04 - val_loss: 3.9491e-04\n",
      "Epoch 255/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 3.0280e-04 - val_loss: 3.7717e-04\n",
      "Epoch 256/2000\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 3.0563e-04 - val_loss: 3.6121e-04\n",
      "Epoch 257/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 3.0387e-04 - val_loss: 3.5964e-04\n",
      "Epoch 258/2000\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 3.0460e-04 - val_loss: 5.1436e-04\n",
      "Epoch 259/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 3.2041e-04 - val_loss: 4.3864e-04\n",
      "Epoch 260/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 3.2372e-04 - val_loss: 4.1288e-04\n",
      "Epoch 261/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 3.0388e-04 - val_loss: 3.6646e-04\n",
      "Epoch 262/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.9599e-04 - val_loss: 3.7179e-04\n",
      "Epoch 263/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 3.1371e-04 - val_loss: 3.8216e-04\n",
      "Epoch 264/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.0725e-04 - val_loss: 3.7871e-04\n",
      "Epoch 265/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.9644e-04 - val_loss: 3.6120e-04\n",
      "Epoch 266/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.9979e-04 - val_loss: 3.5865e-04\n",
      "Epoch 267/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.9684e-04 - val_loss: 3.9785e-04\n",
      "Epoch 268/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.9526e-04 - val_loss: 3.6152e-04\n",
      "Epoch 269/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.9875e-04 - val_loss: 3.7889e-04\n",
      "Epoch 270/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9359e-04 - val_loss: 3.8756e-04\n",
      "Epoch 271/2000\n",
      "3556/3556 [==============================] - 1s 274us/step - loss: 2.9907e-04 - val_loss: 3.8880e-04\n",
      "Epoch 272/2000\n",
      "3556/3556 [==============================] - 1s 268us/step - loss: 3.0201e-04 - val_loss: 3.9663e-04\n",
      "Epoch 273/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 3.0377e-04 - val_loss: 4.1109e-04\n",
      "Epoch 274/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.9962e-04 - val_loss: 3.6075e-04\n",
      "Epoch 275/2000\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 2.9644e-04 - val_loss: 3.5786e-04\n",
      "Epoch 276/2000\n",
      "3556/3556 [==============================] - 1s 261us/step - loss: 2.9290e-04 - val_loss: 4.0371e-04\n",
      "Epoch 277/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.0415e-04 - val_loss: 3.6100e-04\n",
      "Epoch 278/2000\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 2.9848e-04 - val_loss: 3.6410e-04\n",
      "Epoch 279/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 3.0850e-04 - val_loss: 3.7691e-04\n",
      "Epoch 280/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.2875e-04 - val_loss: 3.9875e-04\n",
      "Epoch 281/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.9750e-04 - val_loss: 3.6643e-04\n",
      "Epoch 282/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.9253e-04 - val_loss: 3.5979e-04\n",
      "Epoch 283/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.9863e-04 - val_loss: 3.5673e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 284/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 3.0013e-04 - val_loss: 4.9160e-04\n",
      "Epoch 285/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 3.1660e-04 - val_loss: 3.6709e-04\n",
      "Epoch 286/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.2909e-04 - val_loss: 4.1694e-04\n",
      "Epoch 287/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 3.2784e-04 - val_loss: 4.9067e-04\n",
      "Epoch 288/2000\n",
      "3556/3556 [==============================] - 1s 268us/step - loss: 3.3277e-04 - val_loss: 3.5869e-04\n",
      "Epoch 289/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 3.1062e-04 - val_loss: 3.7432e-04\n",
      "Epoch 290/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9558e-04 - val_loss: 4.5939e-04\n",
      "Epoch 291/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.9756e-04 - val_loss: 3.5894e-04\n",
      "Epoch 292/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.9669e-04 - val_loss: 3.5715e-04\n",
      "Epoch 293/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.9702e-04 - val_loss: 3.9654e-04\n",
      "Epoch 294/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.9154e-04 - val_loss: 3.6527e-04\n",
      "Epoch 295/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.2024e-04 - val_loss: 3.6127e-04\n",
      "Epoch 296/2000\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 3.0623e-04 - val_loss: 3.9731e-04\n",
      "Epoch 297/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9366e-04 - val_loss: 3.5789e-04\n",
      "Epoch 298/2000\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 2.9243e-04 - val_loss: 3.6834e-04\n",
      "Epoch 299/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9095e-04 - val_loss: 3.6454e-04\n",
      "Epoch 300/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.9987e-04 - val_loss: 3.6342e-04\n",
      "Epoch 301/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.8911e-04 - val_loss: 3.6473e-04\n",
      "Epoch 302/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8925e-04 - val_loss: 3.6635e-04\n",
      "Epoch 303/2000\n",
      "3556/3556 [==============================] - 1s 270us/step - loss: 2.9418e-04 - val_loss: 3.6197e-04\n",
      "Epoch 304/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.0178e-04 - val_loss: 3.5937e-04\n",
      "Epoch 305/2000\n",
      "3556/3556 [==============================] - 1s 268us/step - loss: 3.1610e-04 - val_loss: 4.4271e-04\n",
      "Epoch 306/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 3.0618e-04 - val_loss: 3.5978e-04\n",
      "Epoch 307/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9091e-04 - val_loss: 3.6163e-04\n",
      "Epoch 308/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8892e-04 - val_loss: 3.5848e-04\n",
      "Epoch 309/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8861e-04 - val_loss: 3.6396e-04\n",
      "Epoch 310/2000\n",
      "3556/3556 [==============================] - ETA: 0s - loss: 2.9017e-0 - 1s 263us/step - loss: 2.9101e-04 - val_loss: 3.5943e-04\n",
      "Epoch 311/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.0408e-04 - val_loss: 4.7086e-04\n",
      "Epoch 312/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.1137e-04 - val_loss: 3.6538e-04\n",
      "Epoch 313/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 3.0745e-04 - val_loss: 3.6521e-04\n",
      "Epoch 314/2000\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 3.0404e-04 - val_loss: 3.7049e-04\n",
      "Epoch 315/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9845e-04 - val_loss: 3.6885e-04\n",
      "Epoch 316/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 3.0273e-04 - val_loss: 4.4773e-04\n",
      "Epoch 317/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 3.1917e-04 - val_loss: 3.5837e-04\n",
      "Epoch 318/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 3.0460e-04 - val_loss: 3.6841e-04\n",
      "Epoch 319/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.9744e-04 - val_loss: 3.9813e-04\n",
      "Epoch 320/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 3.1180e-04 - val_loss: 4.7066e-04\n",
      "Epoch 321/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 3.2465e-04 - val_loss: 3.7963e-04\n",
      "Epoch 322/2000\n",
      "3556/3556 [==============================] - 1s 268us/step - loss: 3.4770e-04 - val_loss: 4.9958e-04\n",
      "Epoch 323/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 3.3544e-04 - val_loss: 3.9014e-04\n",
      "Epoch 324/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 3.0895e-04 - val_loss: 3.8834e-04\n",
      "Epoch 325/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.2372e-04 - val_loss: 4.5876e-04\n",
      "Epoch 326/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 3.4757e-04 - val_loss: 3.8971e-04\n",
      "Epoch 327/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 3.2441e-04 - val_loss: 4.0079e-04\n",
      "Epoch 328/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.1843e-04 - val_loss: 3.7205e-04\n",
      "Epoch 329/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 3.1026e-04 - val_loss: 3.6458e-04\n",
      "Epoch 330/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 3.0238e-04 - val_loss: 4.2458e-04\n",
      "Epoch 331/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 3.0398e-04 - val_loss: 3.6198e-04\n",
      "Epoch 332/2000\n",
      "3556/3556 [==============================] - 1s 271us/step - loss: 2.8833e-04 - val_loss: 3.5922e-04\n",
      "Epoch 333/2000\n",
      "3556/3556 [==============================] - 1s 276us/step - loss: 2.8911e-04 - val_loss: 3.9509e-04\n",
      "Epoch 334/2000\n",
      "3556/3556 [==============================] - 1s 267us/step - loss: 3.0451e-04 - val_loss: 3.6707e-04\n",
      "Epoch 335/2000\n",
      "3556/3556 [==============================] - 1s 279us/step - loss: 3.0394e-04 - val_loss: 3.5695e-04\n",
      "Epoch 336/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.9449e-04 - val_loss: 4.1713e-04\n",
      "Epoch 337/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.0079e-04 - val_loss: 3.5583e-04\n",
      "Epoch 338/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.8750e-04 - val_loss: 3.6294e-04\n",
      "Epoch 339/2000\n",
      "3556/3556 [==============================] - 1s 270us/step - loss: 3.0545e-04 - val_loss: 3.5790e-04\n",
      "Epoch 340/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9268e-04 - val_loss: 3.6487e-04\n",
      "Epoch 341/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.0591e-04 - val_loss: 3.6234e-04\n",
      "Epoch 342/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.9354e-04 - val_loss: 3.5947e-04\n",
      "Epoch 343/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.9836e-04 - val_loss: 3.6068e-04\n",
      "Epoch 344/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.9595e-04 - val_loss: 3.7601e-04\n",
      "Epoch 345/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.9150e-04 - val_loss: 3.7844e-04\n",
      "Epoch 346/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 3.0986e-04 - val_loss: 3.7430e-04\n",
      "Epoch 347/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.1567e-04 - val_loss: 4.3828e-04\n",
      "Epoch 348/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.9366e-04 - val_loss: 3.5673e-04\n",
      "Epoch 349/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8867e-04 - val_loss: 3.7105e-04\n",
      "Epoch 350/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8868e-04 - val_loss: 4.1275e-04\n",
      "Epoch 351/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 3.1570e-04 - val_loss: 4.0434e-04\n",
      "Epoch 352/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.0179e-04 - val_loss: 3.8073e-04\n",
      "Epoch 353/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9774e-04 - val_loss: 3.9610e-04\n",
      "Epoch 354/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.9673e-04 - val_loss: 3.6536e-04\n",
      "Epoch 355/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 3.0154e-04 - val_loss: 3.7734e-04\n",
      "Epoch 356/2000\n",
      "3556/3556 [==============================] - 1s 271us/step - loss: 2.9604e-04 - val_loss: 4.1146e-04\n",
      "Epoch 357/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9665e-04 - val_loss: 3.6341e-04\n",
      "Epoch 358/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9138e-04 - val_loss: 3.5875e-04\n",
      "Epoch 359/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8850e-04 - val_loss: 3.6443e-04\n",
      "Epoch 360/2000\n",
      "3556/3556 [==============================] - 1s 267us/step - loss: 2.9614e-04 - val_loss: 3.5677e-04\n",
      "Epoch 361/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.9075e-04 - val_loss: 3.6629e-04\n",
      "Epoch 362/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.8985e-04 - val_loss: 3.8277e-04\n",
      "Epoch 363/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9572e-04 - val_loss: 4.4791e-04\n",
      "Epoch 364/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.2262e-04 - val_loss: 3.7216e-04\n",
      "Epoch 365/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 3.0087e-04 - val_loss: 3.6064e-04\n",
      "Epoch 366/2000\n",
      "3556/3556 [==============================] - 1s 269us/step - loss: 2.9343e-04 - val_loss: 3.7777e-04\n",
      "Epoch 367/2000\n",
      "3556/3556 [==============================] - 1s 267us/step - loss: 2.9717e-04 - val_loss: 3.8397e-04\n",
      "Epoch 368/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.9335e-04 - val_loss: 3.5852e-04\n",
      "Epoch 369/2000\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 2.9892e-04 - val_loss: 3.5879e-04\n",
      "Epoch 370/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9021e-04 - val_loss: 3.8400e-04\n",
      "Epoch 371/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9546e-04 - val_loss: 3.5988e-04\n",
      "Epoch 372/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9690e-04 - val_loss: 3.8472e-04\n",
      "Epoch 373/2000\n",
      "3556/3556 [==============================] - 1s 268us/step - loss: 3.0981e-04 - val_loss: 3.6131e-04\n",
      "Epoch 374/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.9074e-04 - val_loss: 3.9466e-04\n",
      "Epoch 375/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8995e-04 - val_loss: 3.5998e-04\n",
      "Epoch 376/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8472e-04 - val_loss: 3.6085e-04\n",
      "Epoch 377/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.9227e-04 - val_loss: 3.7288e-04\n",
      "Epoch 378/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9015e-04 - val_loss: 3.6835e-04\n",
      "Epoch 379/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.9193e-04 - val_loss: 4.5881e-04\n",
      "Epoch 380/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.9368e-04 - val_loss: 3.6959e-04\n",
      "Epoch 381/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 3.0364e-04 - val_loss: 3.6048e-04\n",
      "Epoch 382/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9640e-04 - val_loss: 3.8233e-04\n",
      "Epoch 383/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8952e-04 - val_loss: 3.8098e-04\n",
      "Epoch 384/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.8482e-04 - val_loss: 3.7601e-04\n",
      "Epoch 385/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9114e-04 - val_loss: 3.6245e-04\n",
      "Epoch 386/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9639e-04 - val_loss: 3.7478e-04\n",
      "Epoch 387/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.9355e-04 - val_loss: 4.0501e-04\n",
      "Epoch 388/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.9842e-04 - val_loss: 3.9198e-04\n",
      "Epoch 389/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 3.0470e-04 - val_loss: 3.6533e-04\n",
      "Epoch 390/2000\n",
      "3556/3556 [==============================] - 1s 268us/step - loss: 2.9624e-04 - val_loss: 3.5927e-04\n",
      "Epoch 391/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9307e-04 - val_loss: 3.5731e-04\n",
      "Epoch 392/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9173e-04 - val_loss: 3.6156e-04\n",
      "Epoch 393/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.9278e-04 - val_loss: 3.6462e-04\n",
      "Epoch 394/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.9713e-04 - val_loss: 3.6182e-04\n",
      "Epoch 395/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.8569e-04 - val_loss: 3.6312e-04\n",
      "Epoch 396/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8605e-04 - val_loss: 3.7554e-04\n",
      "Epoch 397/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9132e-04 - val_loss: 3.5727e-04\n",
      "Epoch 398/2000\n",
      "3556/3556 [==============================] - 1s 271us/step - loss: 2.9715e-04 - val_loss: 3.7479e-04\n",
      "Epoch 399/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9234e-04 - val_loss: 3.6045e-04\n",
      "Epoch 400/2000\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 2.9474e-04 - val_loss: 4.0805e-04\n",
      "Epoch 401/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9537e-04 - val_loss: 4.0910e-04\n",
      "Epoch 402/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.9071e-04 - val_loss: 3.6263e-04\n",
      "Epoch 403/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8367e-04 - val_loss: 3.8281e-04\n",
      "Epoch 404/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.9011e-04 - val_loss: 3.7994e-04\n",
      "Epoch 405/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8939e-04 - val_loss: 3.9566e-04\n",
      "Epoch 406/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.9079e-04 - val_loss: 3.5756e-04\n",
      "Epoch 407/2000\n",
      "3556/3556 [==============================] - 1s 269us/step - loss: 2.8456e-04 - val_loss: 3.8204e-04\n",
      "Epoch 408/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.8580e-04 - val_loss: 3.5870e-04\n",
      "Epoch 409/2000\n",
      "3556/3556 [==============================] - 1s 268us/step - loss: 3.0027e-04 - val_loss: 3.5611e-04\n",
      "Epoch 410/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.0435e-04 - val_loss: 4.6117e-04\n",
      "Epoch 411/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.9830e-04 - val_loss: 3.7079e-04\n",
      "Epoch 412/2000\n",
      "3556/3556 [==============================] - 1s 275us/step - loss: 2.8546e-04 - val_loss: 4.0024e-04\n",
      "Epoch 413/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9296e-04 - val_loss: 3.5851e-04\n",
      "Epoch 414/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8585e-04 - val_loss: 3.7798e-04\n",
      "Epoch 415/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.8730e-04 - val_loss: 3.7359e-04\n",
      "Epoch 416/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.8780e-04 - val_loss: 3.8289e-04\n",
      "Epoch 417/2000\n",
      "3556/3556 [==============================] - 1s 275us/step - loss: 2.8544e-04 - val_loss: 3.5993e-04\n",
      "Epoch 418/2000\n",
      "3556/3556 [==============================] - 1s 273us/step - loss: 2.8662e-04 - val_loss: 4.3922e-04\n",
      "Epoch 419/2000\n",
      "3556/3556 [==============================] - 1s 269us/step - loss: 2.9726e-04 - val_loss: 3.6227e-04\n",
      "Epoch 420/2000\n",
      "3556/3556 [==============================] - 1s 269us/step - loss: 3.0493e-04 - val_loss: 3.6277e-04\n",
      "Epoch 421/2000\n",
      "3556/3556 [==============================] - 1s 271us/step - loss: 2.8500e-04 - val_loss: 3.9910e-04\n",
      "Epoch 422/2000\n",
      "3556/3556 [==============================] - 1s 277us/step - loss: 2.9169e-04 - val_loss: 3.6539e-04\n",
      "Epoch 423/2000\n",
      "3556/3556 [==============================] - 1s 277us/step - loss: 3.0482e-04 - val_loss: 4.9855e-04\n",
      "Epoch 424/2000\n",
      "3556/3556 [==============================] - 1s 284us/step - loss: 3.3004e-04 - val_loss: 4.0087e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 425/2000\n",
      "3556/3556 [==============================] - 1s 269us/step - loss: 2.9935e-04 - val_loss: 3.5842e-04\n",
      "Epoch 426/2000\n",
      "3556/3556 [==============================] - 1s 272us/step - loss: 2.8335e-04 - val_loss: 3.6357e-04\n",
      "Epoch 427/2000\n",
      "3556/3556 [==============================] - 1s 267us/step - loss: 2.8763e-04 - val_loss: 3.5896e-04\n",
      "Epoch 428/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8967e-04 - val_loss: 3.7802e-04\n",
      "Epoch 429/2000\n",
      "3556/3556 [==============================] - 1s 268us/step - loss: 2.8741e-04 - val_loss: 3.6526e-04\n",
      "Epoch 430/2000\n",
      "3556/3556 [==============================] - 1s 267us/step - loss: 2.8874e-04 - val_loss: 3.5789e-04\n",
      "Epoch 431/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8463e-04 - val_loss: 3.7339e-04\n",
      "Epoch 432/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8326e-04 - val_loss: 3.6931e-04\n",
      "Epoch 433/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8227e-04 - val_loss: 3.5997e-04\n",
      "Epoch 434/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9225e-04 - val_loss: 3.5813e-04\n",
      "Epoch 435/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8477e-04 - val_loss: 3.5756e-04\n",
      "Epoch 436/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8237e-04 - val_loss: 3.6047e-04\n",
      "Epoch 437/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 3.0253e-04 - val_loss: 3.5793e-04\n",
      "Epoch 438/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8885e-04 - val_loss: 3.8518e-04\n",
      "Epoch 439/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.8235e-04 - val_loss: 3.6650e-04\n",
      "Epoch 440/2000\n",
      "3556/3556 [==============================] - 1s 271us/step - loss: 2.8872e-04 - val_loss: 3.8817e-04\n",
      "Epoch 441/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8906e-04 - val_loss: 3.6121e-04\n",
      "Epoch 442/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8606e-04 - val_loss: 3.7289e-04\n",
      "Epoch 443/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8925e-04 - val_loss: 3.7040e-04\n",
      "Epoch 444/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8809e-04 - val_loss: 3.9827e-04\n",
      "Epoch 445/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.9131e-04 - val_loss: 3.7267e-04\n",
      "Epoch 446/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8605e-04 - val_loss: 3.5845e-04\n",
      "Epoch 447/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8429e-04 - val_loss: 3.6020e-04\n",
      "Epoch 448/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.8528e-04 - val_loss: 3.6318e-04\n",
      "Epoch 449/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9061e-04 - val_loss: 3.6324e-04\n",
      "Epoch 450/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9855e-04 - val_loss: 3.6685e-04\n",
      "Epoch 451/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9127e-04 - val_loss: 3.6951e-04\n",
      "Epoch 452/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.9286e-04 - val_loss: 3.7689e-04\n",
      "Epoch 453/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8389e-04 - val_loss: 3.5834e-04\n",
      "Epoch 454/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9628e-04 - val_loss: 3.6024e-04\n",
      "Epoch 455/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 3.0910e-04 - val_loss: 3.6104e-04\n",
      "Epoch 456/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 3.1367e-04 - val_loss: 3.6182e-04\n",
      "Epoch 457/2000\n",
      "3556/3556 [==============================] - 1s 272us/step - loss: 2.8996e-04 - val_loss: 3.8192e-04\n",
      "Epoch 458/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9152e-04 - val_loss: 4.2840e-04\n",
      "Epoch 459/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 3.1720e-04 - val_loss: 4.8287e-04\n",
      "Epoch 460/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 3.3317e-04 - val_loss: 3.6344e-04\n",
      "Epoch 461/2000\n",
      "3556/3556 [==============================] - 1s 272us/step - loss: 3.3743e-04 - val_loss: 3.7509e-04\n",
      "Epoch 462/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.1623e-04 - val_loss: 3.7549e-04\n",
      "Epoch 463/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9398e-04 - val_loss: 3.6325e-04\n",
      "Epoch 464/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8746e-04 - val_loss: 3.5726e-04\n",
      "Epoch 465/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.8828e-04 - val_loss: 3.6218e-04\n",
      "Epoch 466/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 3.0551e-04 - val_loss: 3.7155e-04\n",
      "Epoch 467/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 3.1027e-04 - val_loss: 4.1863e-04\n",
      "Epoch 468/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 3.1099e-04 - val_loss: 4.3779e-04\n",
      "Epoch 469/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9800e-04 - val_loss: 3.8704e-04\n",
      "Epoch 470/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.0577e-04 - val_loss: 3.6641e-04\n",
      "Epoch 471/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 3.4883e-04 - val_loss: 5.1842e-04\n",
      "Epoch 472/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 3.5783e-04 - val_loss: 3.5911e-04\n",
      "Epoch 473/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.9617e-04 - val_loss: 3.7189e-04\n",
      "Epoch 474/2000\n",
      "3556/3556 [==============================] - 1s 270us/step - loss: 2.8502e-04 - val_loss: 3.7447e-04\n",
      "Epoch 475/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.0395e-04 - val_loss: 3.7339e-04\n",
      "Epoch 476/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.9196e-04 - val_loss: 3.6625e-04\n",
      "Epoch 477/2000\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 2.9994e-04 - val_loss: 3.6964e-04\n",
      "Epoch 478/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 3.0301e-04 - val_loss: 3.5904e-04\n",
      "Epoch 479/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.9200e-04 - val_loss: 3.9732e-04\n",
      "Epoch 480/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.9138e-04 - val_loss: 3.9062e-04\n",
      "Epoch 481/2000\n",
      "3556/3556 [==============================] - 1s 267us/step - loss: 2.8705e-04 - val_loss: 3.6133e-04\n",
      "Epoch 482/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8847e-04 - val_loss: 3.5619e-04\n",
      "Epoch 483/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.9414e-04 - val_loss: 4.1760e-04\n",
      "Epoch 484/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.6314e-04 - val_loss: 4.3697e-04\n",
      "Epoch 485/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 3.5433e-04 - val_loss: 4.0060e-04\n",
      "Epoch 486/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.1181e-04 - val_loss: 5.1087e-04\n",
      "Epoch 487/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.3086e-04 - val_loss: 3.7123e-04\n",
      "Epoch 488/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 3.1476e-04 - val_loss: 3.6114e-04\n",
      "Epoch 489/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.1941e-04 - val_loss: 4.8340e-04\n",
      "Epoch 490/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 3.0298e-04 - val_loss: 3.6363e-04\n",
      "Epoch 491/2000\n",
      "3556/3556 [==============================] - 1s 268us/step - loss: 3.0024e-04 - val_loss: 4.6218e-04\n",
      "Epoch 492/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 3.2641e-04 - val_loss: 4.5620e-04\n",
      "Epoch 493/2000\n",
      "3556/3556 [==============================] - 1s 270us/step - loss: 3.0821e-04 - val_loss: 3.8112e-04\n",
      "Epoch 494/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9983e-04 - val_loss: 3.6972e-04\n",
      "Epoch 495/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.0098e-04 - val_loss: 3.6068e-04\n",
      "Epoch 496/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.9587e-04 - val_loss: 3.8733e-04\n",
      "Epoch 497/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.0441e-04 - val_loss: 3.8461e-04\n",
      "Epoch 498/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9882e-04 - val_loss: 3.6937e-04\n",
      "Epoch 499/2000\n",
      "3556/3556 [==============================] - 1s 268us/step - loss: 3.0947e-04 - val_loss: 4.0016e-04\n",
      "Epoch 500/2000\n",
      "3556/3556 [==============================] - 1s 268us/step - loss: 3.0268e-04 - val_loss: 3.6194e-04\n",
      "Epoch 501/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.9390e-04 - val_loss: 4.0188e-04\n",
      "Epoch 502/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9443e-04 - val_loss: 3.9909e-04\n",
      "Epoch 503/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9009e-04 - val_loss: 3.5882e-04\n",
      "Epoch 504/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8599e-04 - val_loss: 3.5646e-04\n",
      "Epoch 505/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.8258e-04 - val_loss: 3.5864e-04\n",
      "Epoch 506/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.8181e-04 - val_loss: 3.6321e-04\n",
      "Epoch 507/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.7971e-04 - val_loss: 3.8483e-04\n",
      "Epoch 508/2000\n",
      "3556/3556 [==============================] - 1s 271us/step - loss: 2.9568e-04 - val_loss: 3.5655e-04\n",
      "Epoch 509/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.8999e-04 - val_loss: 3.5803e-04\n",
      "Epoch 510/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8522e-04 - val_loss: 3.8187e-04\n",
      "Epoch 511/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.8859e-04 - val_loss: 3.5631e-04\n",
      "Epoch 512/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8384e-04 - val_loss: 3.8159e-04\n",
      "Epoch 513/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8177e-04 - val_loss: 3.5857e-04\n",
      "Epoch 514/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8021e-04 - val_loss: 4.0198e-04\n",
      "Epoch 515/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.0707e-04 - val_loss: 3.5661e-04\n",
      "Epoch 516/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.3750e-04 - val_loss: 5.0119e-04\n",
      "Epoch 517/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 3.4832e-04 - val_loss: 3.5837e-04\n",
      "Epoch 518/2000\n",
      "3556/3556 [==============================] - 1s 268us/step - loss: 2.9169e-04 - val_loss: 4.0100e-04\n",
      "Epoch 519/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.9842e-04 - val_loss: 4.0993e-04\n",
      "Epoch 520/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8725e-04 - val_loss: 3.5804e-04\n",
      "Epoch 521/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.9419e-04 - val_loss: 3.6506e-04\n",
      "Epoch 522/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8452e-04 - val_loss: 3.9166e-04\n",
      "Epoch 523/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8467e-04 - val_loss: 3.5917e-04\n",
      "Epoch 524/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.9482e-04 - val_loss: 3.6127e-04\n",
      "Epoch 525/2000\n",
      "3556/3556 [==============================] - 1s 276us/step - loss: 2.8875e-04 - val_loss: 3.6129e-04\n",
      "Epoch 526/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8397e-04 - val_loss: 3.8680e-04\n",
      "Epoch 527/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8309e-04 - val_loss: 3.6829e-04\n",
      "Epoch 528/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.8591e-04 - val_loss: 3.6055e-04\n",
      "Epoch 529/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.0483e-04 - val_loss: 3.8011e-04\n",
      "Epoch 530/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.9104e-04 - val_loss: 3.7273e-04\n",
      "Epoch 531/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.8819e-04 - val_loss: 3.5840e-04\n",
      "Epoch 532/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.9186e-04 - val_loss: 4.0504e-04\n",
      "Epoch 533/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9145e-04 - val_loss: 4.4302e-04\n",
      "Epoch 534/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 3.0281e-04 - val_loss: 3.5555e-04\n",
      "Epoch 535/2000\n",
      "3556/3556 [==============================] - 1s 268us/step - loss: 2.8690e-04 - val_loss: 3.5722e-04\n",
      "Epoch 536/2000\n",
      "3556/3556 [==============================] - 1s 277us/step - loss: 2.8282e-04 - val_loss: 3.7360e-04\n",
      "Epoch 537/2000\n",
      "3556/3556 [==============================] - 1s 282us/step - loss: 2.8309e-04 - val_loss: 3.7770e-04\n",
      "Epoch 538/2000\n",
      "3556/3556 [==============================] - 1s 274us/step - loss: 2.8492e-04 - val_loss: 3.9433e-04\n",
      "Epoch 539/2000\n",
      "3556/3556 [==============================] - 1s 284us/step - loss: 2.8411e-04 - val_loss: 3.9569e-04\n",
      "Epoch 540/2000\n",
      "3556/3556 [==============================] - 1s 286us/step - loss: 2.9545e-04 - val_loss: 3.7503e-04\n",
      "Epoch 541/2000\n",
      "3556/3556 [==============================] - 1s 284us/step - loss: 2.8724e-04 - val_loss: 3.5800e-04\n",
      "Epoch 542/2000\n",
      "3556/3556 [==============================] - 1s 279us/step - loss: 2.8386e-04 - val_loss: 3.9264e-04\n",
      "Epoch 543/2000\n",
      "3556/3556 [==============================] - 1s 281us/step - loss: 3.0216e-04 - val_loss: 3.8445e-04\n",
      "Epoch 544/2000\n",
      "3556/3556 [==============================] - 1s 287us/step - loss: 2.9106e-04 - val_loss: 4.1658e-04\n",
      "Epoch 545/2000\n",
      "3556/3556 [==============================] - 1s 282us/step - loss: 2.9488e-04 - val_loss: 3.6542e-04\n",
      "Epoch 546/2000\n",
      "3556/3556 [==============================] - 1s 287us/step - loss: 2.8640e-04 - val_loss: 3.8016e-04\n",
      "Epoch 547/2000\n",
      "3556/3556 [==============================] - 1s 289us/step - loss: 3.0803e-04 - val_loss: 3.5846e-04\n",
      "Epoch 548/2000\n",
      "3556/3556 [==============================] - 1s 291us/step - loss: 2.9288e-04 - val_loss: 3.6940e-04\n",
      "Epoch 549/2000\n",
      "3556/3556 [==============================] - 1s 283us/step - loss: 2.9430e-04 - val_loss: 3.7517e-04\n",
      "Epoch 550/2000\n",
      "3556/3556 [==============================] - 1s 307us/step - loss: 3.0604e-04 - val_loss: 4.1668e-04\n",
      "Epoch 551/2000\n",
      "3556/3556 [==============================] - 1s 294us/step - loss: 2.9419e-04 - val_loss: 3.8758e-04\n",
      "Epoch 552/2000\n",
      "3556/3556 [==============================] - 1s 279us/step - loss: 2.9474e-04 - val_loss: 3.5913e-04\n",
      "Epoch 553/2000\n",
      "3556/3556 [==============================] - 1s 286us/step - loss: 2.8300e-04 - val_loss: 3.5769e-04\n",
      "Epoch 554/2000\n",
      "3556/3556 [==============================] - 1s 280us/step - loss: 2.8420e-04 - val_loss: 3.6110e-04\n",
      "Epoch 555/2000\n",
      "3556/3556 [==============================] - 1s 280us/step - loss: 2.9589e-04 - val_loss: 3.8943e-04\n",
      "Epoch 556/2000\n",
      "3556/3556 [==============================] - 1s 268us/step - loss: 2.9868e-04 - val_loss: 4.6669e-04\n",
      "Epoch 557/2000\n",
      "3556/3556 [==============================] - 1s 273us/step - loss: 3.2547e-04 - val_loss: 3.9454e-04\n",
      "Epoch 558/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.0565e-04 - val_loss: 3.6317e-04\n",
      "Epoch 559/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 3.0637e-04 - val_loss: 3.8815e-04\n",
      "Epoch 560/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.9334e-04 - val_loss: 4.0795e-04\n",
      "Epoch 561/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.8771e-04 - val_loss: 3.6811e-04\n",
      "Epoch 562/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 3.0348e-04 - val_loss: 3.5980e-04\n",
      "Epoch 563/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8721e-04 - val_loss: 3.6380e-04\n",
      "Epoch 564/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9736e-04 - val_loss: 3.7313e-04\n",
      "Epoch 565/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8735e-04 - val_loss: 3.6697e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 566/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8891e-04 - val_loss: 4.5276e-04\n",
      "Epoch 567/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 3.1044e-04 - val_loss: 3.5945e-04\n",
      "Epoch 568/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.9021e-04 - val_loss: 3.5639e-04\n",
      "Epoch 569/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8299e-04 - val_loss: 3.6066e-04\n",
      "Epoch 570/2000\n",
      "3556/3556 [==============================] - ETA: 0s - loss: 2.8725e-0 - 1s 263us/step - loss: 2.8555e-04 - val_loss: 3.5892e-04\n",
      "Epoch 571/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8662e-04 - val_loss: 3.6813e-04\n",
      "Epoch 572/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8114e-04 - val_loss: 3.6022e-04\n",
      "Epoch 573/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8481e-04 - val_loss: 3.6517e-04\n",
      "Epoch 574/2000\n",
      "3556/3556 [==============================] - 1s 270us/step - loss: 2.8461e-04 - val_loss: 3.5953e-04\n",
      "Epoch 575/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.9234e-04 - val_loss: 3.6355e-04\n",
      "Epoch 576/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8117e-04 - val_loss: 3.8070e-04\n",
      "Epoch 577/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8193e-04 - val_loss: 3.6195e-04\n",
      "Epoch 578/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8283e-04 - val_loss: 3.8479e-04\n",
      "Epoch 579/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8568e-04 - val_loss: 3.5736e-04\n",
      "Epoch 580/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8842e-04 - val_loss: 3.5659e-04\n",
      "Epoch 581/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8753e-04 - val_loss: 3.6092e-04\n",
      "Epoch 582/2000\n",
      "3556/3556 [==============================] - 1s 267us/step - loss: 2.8786e-04 - val_loss: 3.5884e-04\n",
      "Epoch 583/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9018e-04 - val_loss: 4.0286e-04\n",
      "Epoch 584/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.9868e-04 - val_loss: 3.6486e-04\n",
      "Epoch 585/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8716e-04 - val_loss: 4.2166e-04\n",
      "Epoch 586/2000\n",
      "3556/3556 [==============================] - 1s 268us/step - loss: 2.9006e-04 - val_loss: 4.2416e-04\n",
      "Epoch 587/2000\n",
      "3556/3556 [==============================] - 1s 268us/step - loss: 2.8606e-04 - val_loss: 3.5509e-04\n",
      "Epoch 588/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.9556e-04 - val_loss: 3.9210e-04\n",
      "Epoch 589/2000\n",
      "3556/3556 [==============================] - 1s 268us/step - loss: 2.8405e-04 - val_loss: 3.6649e-04\n",
      "Epoch 590/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.8620e-04 - val_loss: 3.6379e-04\n",
      "Epoch 591/2000\n",
      "3556/3556 [==============================] - 1s 271us/step - loss: 2.8107e-04 - val_loss: 3.6070e-04\n",
      "Epoch 592/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.8458e-04 - val_loss: 4.4018e-04\n",
      "Epoch 593/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 3.0895e-04 - val_loss: 4.1867e-04\n",
      "Epoch 594/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9088e-04 - val_loss: 3.5874e-04\n",
      "Epoch 595/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.9787e-04 - val_loss: 3.7246e-04\n",
      "Epoch 596/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 3.1470e-04 - val_loss: 3.7033e-04\n",
      "Epoch 597/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.2802e-04 - val_loss: 3.6684e-04\n",
      "Epoch 598/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9663e-04 - val_loss: 4.2038e-04\n",
      "Epoch 599/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.8338e-04 - val_loss: 3.5732e-04\n",
      "Epoch 600/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.8526e-04 - val_loss: 3.9483e-04\n",
      "Epoch 601/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.8480e-04 - val_loss: 3.5825e-04\n",
      "Epoch 602/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 3.0290e-04 - val_loss: 3.5895e-04\n",
      "Epoch 603/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 3.2543e-04 - val_loss: 4.4241e-04\n",
      "Epoch 604/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 3.1181e-04 - val_loss: 3.6153e-04\n",
      "Epoch 605/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.8185e-04 - val_loss: 3.8709e-04\n",
      "Epoch 606/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8811e-04 - val_loss: 3.5777e-04\n",
      "Epoch 607/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.7915e-04 - val_loss: 3.5783e-04\n",
      "Epoch 608/2000\n",
      "3556/3556 [==============================] - 1s 269us/step - loss: 2.8043e-04 - val_loss: 3.6846e-04\n",
      "Epoch 609/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8340e-04 - val_loss: 3.5552e-04\n",
      "Epoch 610/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8090e-04 - val_loss: 3.5591e-04\n",
      "Epoch 611/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8105e-04 - val_loss: 4.4821e-04\n",
      "Epoch 612/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.0342e-04 - val_loss: 4.2058e-04\n",
      "Epoch 613/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.9234e-04 - val_loss: 3.6281e-04\n",
      "Epoch 614/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 3.0434e-04 - val_loss: 4.0028e-04\n",
      "Epoch 615/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 3.1332e-04 - val_loss: 3.6806e-04\n",
      "Epoch 616/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 3.0411e-04 - val_loss: 4.4077e-04\n",
      "Epoch 617/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 3.1835e-04 - val_loss: 4.8090e-04\n",
      "Epoch 618/2000\n",
      "3556/3556 [==============================] - 1s 268us/step - loss: 3.2362e-04 - val_loss: 3.5638e-04\n",
      "Epoch 619/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.9311e-04 - val_loss: 3.7455e-04\n",
      "Epoch 620/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9006e-04 - val_loss: 3.5906e-04\n",
      "Epoch 621/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9527e-04 - val_loss: 3.5885e-04\n",
      "Epoch 622/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 3.0318e-04 - val_loss: 3.6882e-04\n",
      "Epoch 623/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 3.3003e-04 - val_loss: 3.5928e-04\n",
      "Epoch 624/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.9254e-04 - val_loss: 3.6574e-04\n",
      "Epoch 625/2000\n",
      "3556/3556 [==============================] - 1s 270us/step - loss: 2.8256e-04 - val_loss: 3.7224e-04\n",
      "Epoch 626/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.7930e-04 - val_loss: 3.5814e-04\n",
      "Epoch 627/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8686e-04 - val_loss: 4.0809e-04\n",
      "Epoch 628/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8244e-04 - val_loss: 3.6489e-04\n",
      "Epoch 629/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8278e-04 - val_loss: 3.5615e-04\n",
      "Epoch 630/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.9216e-04 - val_loss: 3.6337e-04\n",
      "Epoch 631/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8451e-04 - val_loss: 4.0705e-04\n",
      "Epoch 632/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8688e-04 - val_loss: 3.6135e-04\n",
      "Epoch 633/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9631e-04 - val_loss: 4.2405e-04\n",
      "Epoch 634/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 3.2154e-04 - val_loss: 3.7915e-04\n",
      "Epoch 635/2000\n",
      "3556/3556 [==============================] - 1s 267us/step - loss: 3.1563e-04 - val_loss: 3.8264e-04\n",
      "Epoch 636/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.0380e-04 - val_loss: 4.8608e-04\n",
      "Epoch 637/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.3579e-04 - val_loss: 3.5898e-04\n",
      "Epoch 638/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 3.0072e-04 - val_loss: 3.7952e-04\n",
      "Epoch 639/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 3.1179e-04 - val_loss: 4.5531e-04\n",
      "Epoch 640/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9697e-04 - val_loss: 3.6010e-04\n",
      "Epoch 641/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8901e-04 - val_loss: 3.6335e-04\n",
      "Epoch 642/2000\n",
      "3556/3556 [==============================] - 1s 271us/step - loss: 3.0269e-04 - val_loss: 3.5618e-04\n",
      "Epoch 643/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9282e-04 - val_loss: 3.8241e-04\n",
      "Epoch 644/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.9271e-04 - val_loss: 3.6504e-04\n",
      "Epoch 645/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.8380e-04 - val_loss: 4.3606e-04\n",
      "Epoch 646/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.9788e-04 - val_loss: 3.6336e-04\n",
      "Epoch 647/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8358e-04 - val_loss: 3.6099e-04\n",
      "Epoch 648/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.7989e-04 - val_loss: 3.6367e-04\n",
      "Epoch 649/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8297e-04 - val_loss: 3.7223e-04\n",
      "Epoch 650/2000\n",
      "3556/3556 [==============================] - 1s 270us/step - loss: 2.8444e-04 - val_loss: 3.7955e-04\n",
      "Epoch 651/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.7865e-04 - val_loss: 3.6076e-04\n",
      "Epoch 652/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.7908e-04 - val_loss: 3.7286e-04\n",
      "Epoch 653/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.8223e-04 - val_loss: 3.5882e-04\n",
      "Epoch 654/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.7964e-04 - val_loss: 3.5612e-04\n",
      "Epoch 655/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8311e-04 - val_loss: 3.7804e-04\n",
      "Epoch 656/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9478e-04 - val_loss: 3.6461e-04\n",
      "Epoch 657/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.8600e-04 - val_loss: 3.9061e-04\n",
      "Epoch 658/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.8943e-04 - val_loss: 4.7127e-04\n",
      "Epoch 659/2000\n",
      "3556/3556 [==============================] - 1s 267us/step - loss: 3.1038e-04 - val_loss: 4.0287e-04\n",
      "Epoch 660/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.1726e-04 - val_loss: 3.8852e-04\n",
      "Epoch 661/2000\n",
      "3556/3556 [==============================] - 1s 267us/step - loss: 3.2161e-04 - val_loss: 4.0046e-04\n",
      "Epoch 662/2000\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 3.1650e-04 - val_loss: 3.7152e-04\n",
      "Epoch 663/2000\n",
      "3556/3556 [==============================] - 1s 268us/step - loss: 3.2165e-04 - val_loss: 7.2369e-04\n",
      "Epoch 664/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.8059e-04 - val_loss: 3.8957e-04\n",
      "Epoch 665/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 3.3619e-04 - val_loss: 3.9672e-04\n",
      "Epoch 666/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 3.0688e-04 - val_loss: 4.1034e-04\n",
      "Epoch 667/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 3.1286e-04 - val_loss: 3.5585e-04\n",
      "Epoch 668/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.1293e-04 - val_loss: 3.6453e-04\n",
      "Epoch 669/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.0883e-04 - val_loss: 4.7601e-04\n",
      "Epoch 670/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.1210e-04 - val_loss: 3.6039e-04\n",
      "Epoch 671/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 3.0161e-04 - val_loss: 3.5812e-04\n",
      "Epoch 672/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.8210e-04 - val_loss: 3.6491e-04\n",
      "Epoch 673/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8239e-04 - val_loss: 3.6581e-04\n",
      "Epoch 674/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9047e-04 - val_loss: 3.5615e-04\n",
      "Epoch 675/2000\n",
      "3556/3556 [==============================] - 1s 268us/step - loss: 2.7944e-04 - val_loss: 3.9400e-04\n",
      "Epoch 676/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.9108e-04 - val_loss: 3.8359e-04\n",
      "Epoch 677/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9118e-04 - val_loss: 3.6594e-04\n",
      "Epoch 678/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9254e-04 - val_loss: 4.2295e-04\n",
      "Epoch 679/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.9240e-04 - val_loss: 3.7939e-04\n",
      "Epoch 680/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9754e-04 - val_loss: 3.5905e-04\n",
      "Epoch 681/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8491e-04 - val_loss: 3.5847e-04\n",
      "Epoch 682/2000\n",
      "3556/3556 [==============================] - 1s 270us/step - loss: 2.8378e-04 - val_loss: 3.6132e-04\n",
      "Epoch 683/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8742e-04 - val_loss: 4.6226e-04\n",
      "Epoch 684/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.9806e-04 - val_loss: 3.8387e-04\n",
      "Epoch 685/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9332e-04 - val_loss: 3.6896e-04\n",
      "Epoch 686/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8120e-04 - val_loss: 3.5457e-04\n",
      "Epoch 687/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8178e-04 - val_loss: 3.5573e-04\n",
      "Epoch 688/2000\n",
      "3556/3556 [==============================] - 1s 267us/step - loss: 2.8816e-04 - val_loss: 3.5680e-04\n",
      "Epoch 689/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8297e-04 - val_loss: 3.6880e-04\n",
      "Epoch 690/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9357e-04 - val_loss: 3.8120e-04\n",
      "Epoch 691/2000\n",
      "3556/3556 [==============================] - 1s 267us/step - loss: 2.7849e-04 - val_loss: 3.5679e-04\n",
      "Epoch 692/2000\n",
      "3556/3556 [==============================] - 1s 269us/step - loss: 2.8030e-04 - val_loss: 3.5739e-04\n",
      "Epoch 693/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.7934e-04 - val_loss: 3.6512e-04\n",
      "Epoch 694/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 3.0092e-04 - val_loss: 3.7524e-04\n",
      "Epoch 695/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.9268e-04 - val_loss: 3.6290e-04\n",
      "Epoch 696/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.7999e-04 - val_loss: 3.5932e-04\n",
      "Epoch 697/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.7989e-04 - val_loss: 3.5852e-04\n",
      "Epoch 698/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.7868e-04 - val_loss: 3.5671e-04\n",
      "Epoch 699/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8245e-04 - val_loss: 3.7360e-04\n",
      "Epoch 700/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8709e-04 - val_loss: 3.6329e-04\n",
      "Epoch 701/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9423e-04 - val_loss: 4.4493e-04\n",
      "Epoch 702/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.9068e-04 - val_loss: 3.5751e-04\n",
      "Epoch 703/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8878e-04 - val_loss: 3.8038e-04\n",
      "Epoch 704/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.9205e-04 - val_loss: 3.5980e-04\n",
      "Epoch 705/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 3.0480e-04 - val_loss: 4.7050e-04\n",
      "Epoch 706/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 3.1174e-04 - val_loss: 3.8704e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 707/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.9994e-04 - val_loss: 3.7119e-04\n",
      "Epoch 708/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8994e-04 - val_loss: 3.5872e-04\n",
      "Epoch 709/2000\n",
      "3556/3556 [==============================] - 1s 270us/step - loss: 2.8042e-04 - val_loss: 3.5993e-04\n",
      "Epoch 710/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8727e-04 - val_loss: 3.5927e-04\n",
      "Epoch 711/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8285e-04 - val_loss: 3.7161e-04\n",
      "Epoch 712/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 3.0415e-04 - val_loss: 3.5584e-04\n",
      "Epoch 713/2000\n",
      "3556/3556 [==============================] - 1s 272us/step - loss: 2.8914e-04 - val_loss: 4.0590e-04\n",
      "Epoch 714/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9114e-04 - val_loss: 3.9626e-04\n",
      "Epoch 715/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8972e-04 - val_loss: 3.7393e-04\n",
      "Epoch 716/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8788e-04 - val_loss: 3.6660e-04\n",
      "Epoch 717/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8030e-04 - val_loss: 3.8790e-04\n",
      "Epoch 718/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.8474e-04 - val_loss: 3.6498e-04\n",
      "Epoch 719/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.8692e-04 - val_loss: 3.5447e-04\n",
      "Epoch 720/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8108e-04 - val_loss: 4.4286e-04\n",
      "Epoch 721/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 3.0181e-04 - val_loss: 3.9358e-04\n",
      "Epoch 722/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.9479e-04 - val_loss: 3.6583e-04\n",
      "Epoch 723/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8752e-04 - val_loss: 3.5748e-04\n",
      "Epoch 724/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.8316e-04 - val_loss: 3.5988e-04\n",
      "Epoch 725/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.9468e-04 - val_loss: 4.0302e-04\n",
      "Epoch 726/2000\n",
      "3556/3556 [==============================] - 1s 269us/step - loss: 3.0178e-04 - val_loss: 3.8211e-04\n",
      "Epoch 727/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8925e-04 - val_loss: 3.8662e-04\n",
      "Epoch 728/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9367e-04 - val_loss: 3.7383e-04\n",
      "Epoch 729/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.9712e-04 - val_loss: 3.6656e-04\n",
      "Epoch 730/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8542e-04 - val_loss: 3.9614e-04\n",
      "Epoch 731/2000\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 3.0658e-04 - val_loss: 3.6661e-04\n",
      "Epoch 732/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8070e-04 - val_loss: 3.6108e-04\n",
      "Epoch 733/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8514e-04 - val_loss: 3.6859e-04\n",
      "Epoch 734/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8576e-04 - val_loss: 3.9187e-04\n",
      "Epoch 735/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8168e-04 - val_loss: 3.5858e-04\n",
      "Epoch 736/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.8062e-04 - val_loss: 3.5879e-04\n",
      "Epoch 737/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.9041e-04 - val_loss: 4.7235e-04\n",
      "Epoch 738/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.0477e-04 - val_loss: 3.7306e-04\n",
      "Epoch 739/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.9654e-04 - val_loss: 3.6398e-04\n",
      "Epoch 740/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.9722e-04 - val_loss: 3.7183e-04\n",
      "Epoch 741/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8683e-04 - val_loss: 3.9755e-04\n",
      "Epoch 742/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.8749e-04 - val_loss: 3.6828e-04\n",
      "Epoch 743/2000\n",
      "3556/3556 [==============================] - 1s 271us/step - loss: 2.8265e-04 - val_loss: 3.6774e-04\n",
      "Epoch 744/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8007e-04 - val_loss: 3.7120e-04\n",
      "Epoch 745/2000\n",
      "3556/3556 [==============================] - 1s 272us/step - loss: 2.7919e-04 - val_loss: 3.5696e-04\n",
      "Epoch 746/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.7769e-04 - val_loss: 3.6387e-04\n",
      "Epoch 747/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8433e-04 - val_loss: 3.7051e-04\n",
      "Epoch 748/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8077e-04 - val_loss: 3.5751e-04\n",
      "Epoch 749/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.7767e-04 - val_loss: 3.6045e-04\n",
      "Epoch 750/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8143e-04 - val_loss: 3.6401e-04\n",
      "Epoch 751/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8177e-04 - val_loss: 3.5985e-04\n",
      "Epoch 752/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.7754e-04 - val_loss: 3.5810e-04\n",
      "Epoch 753/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.9134e-04 - val_loss: 3.5759e-04\n",
      "Epoch 754/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8135e-04 - val_loss: 3.5656e-04\n",
      "Epoch 755/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.7987e-04 - val_loss: 3.5594e-04\n",
      "Epoch 756/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8258e-04 - val_loss: 3.7268e-04\n",
      "Epoch 757/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8597e-04 - val_loss: 3.6147e-04\n",
      "Epoch 758/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.9691e-04 - val_loss: 3.9574e-04\n",
      "Epoch 759/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.0483e-04 - val_loss: 3.5707e-04\n",
      "Epoch 760/2000\n",
      "3556/3556 [==============================] - 1s 269us/step - loss: 2.8228e-04 - val_loss: 3.6246e-04\n",
      "Epoch 761/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8388e-04 - val_loss: 3.5634e-04\n",
      "Epoch 762/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.9877e-04 - val_loss: 4.4015e-04\n",
      "Epoch 763/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.1981e-04 - val_loss: 4.4694e-04\n",
      "Epoch 764/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.0906e-04 - val_loss: 3.6485e-04\n",
      "Epoch 765/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.9940e-04 - val_loss: 3.7683e-04\n",
      "Epoch 766/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8649e-04 - val_loss: 3.6264e-04\n",
      "Epoch 767/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8287e-04 - val_loss: 3.7273e-04\n",
      "Epoch 768/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.7615e-04 - val_loss: 3.5760e-04\n",
      "Epoch 769/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8278e-04 - val_loss: 3.5621e-04\n",
      "Epoch 770/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.7913e-04 - val_loss: 3.8050e-04\n",
      "Epoch 771/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8543e-04 - val_loss: 3.6344e-04\n",
      "Epoch 772/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8317e-04 - val_loss: 3.5726e-04\n",
      "Epoch 773/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8302e-04 - val_loss: 3.6886e-04\n",
      "Epoch 774/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.7862e-04 - val_loss: 4.0120e-04\n",
      "Epoch 775/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.8897e-04 - val_loss: 3.8894e-04\n",
      "Epoch 776/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.8093e-04 - val_loss: 4.1681e-04\n",
      "Epoch 777/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3556/3556 [==============================] - 1s 277us/step - loss: 2.8735e-04 - val_loss: 3.5645e-04\n",
      "Epoch 778/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8578e-04 - val_loss: 3.5902e-04\n",
      "Epoch 779/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.8176e-04 - val_loss: 3.6309e-04\n",
      "Epoch 780/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8776e-04 - val_loss: 3.5419e-04\n",
      "Epoch 781/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.8534e-04 - val_loss: 3.6334e-04\n",
      "Epoch 782/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.7765e-04 - val_loss: 3.5651e-04\n",
      "Epoch 783/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8749e-04 - val_loss: 3.6810e-04\n",
      "Epoch 784/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.0556e-04 - val_loss: 4.4648e-04\n",
      "Epoch 785/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 3.0606e-04 - val_loss: 3.5729e-04\n",
      "Epoch 786/2000\n",
      "3556/3556 [==============================] - ETA: 0s - loss: 3.1065e-0 - 1s 265us/step - loss: 3.0511e-04 - val_loss: 3.6124e-04\n",
      "Epoch 787/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8814e-04 - val_loss: 3.7938e-04\n",
      "Epoch 788/2000\n",
      "3556/3556 [==============================] - 1s 268us/step - loss: 2.8938e-04 - val_loss: 4.0015e-04\n",
      "Epoch 789/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8090e-04 - val_loss: 3.7886e-04\n",
      "Epoch 790/2000\n",
      "3556/3556 [==============================] - 1s 267us/step - loss: 2.8204e-04 - val_loss: 3.9278e-04\n",
      "Epoch 791/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.9202e-04 - val_loss: 5.2544e-04\n",
      "Epoch 792/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 3.5534e-04 - val_loss: 3.7966e-04\n",
      "Epoch 793/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.2253e-04 - val_loss: 4.2373e-04\n",
      "Epoch 794/2000\n",
      "3556/3556 [==============================] - 1s 270us/step - loss: 3.1433e-04 - val_loss: 4.8226e-04\n",
      "Epoch 795/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 3.5635e-04 - val_loss: 5.3094e-04\n",
      "Epoch 796/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 3.5846e-04 - val_loss: 4.8046e-04\n",
      "Epoch 797/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 3.4303e-04 - val_loss: 3.6112e-04\n",
      "Epoch 798/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8513e-04 - val_loss: 3.5669e-04\n",
      "Epoch 799/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.8205e-04 - val_loss: 3.6588e-04\n",
      "Epoch 800/2000\n",
      "3556/3556 [==============================] - 1s 269us/step - loss: 2.8404e-04 - val_loss: 3.5553e-04\n",
      "Epoch 801/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.9073e-04 - val_loss: 4.5308e-04\n",
      "Epoch 802/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.9720e-04 - val_loss: 3.6724e-04\n",
      "Epoch 803/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8960e-04 - val_loss: 3.6026e-04\n",
      "Epoch 804/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8797e-04 - val_loss: 3.8196e-04\n",
      "Epoch 805/2000\n",
      "3556/3556 [==============================] - 1s 274us/step - loss: 2.8259e-04 - val_loss: 3.5546e-04\n",
      "Epoch 806/2000\n",
      "3556/3556 [==============================] - 1s 268us/step - loss: 2.7513e-04 - val_loss: 3.5951e-04\n",
      "Epoch 807/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.7587e-04 - val_loss: 3.6015e-04\n",
      "Epoch 808/2000\n",
      "3556/3556 [==============================] - 1s 268us/step - loss: 2.7886e-04 - val_loss: 3.6983e-04\n",
      "Epoch 809/2000\n",
      "3556/3556 [==============================] - 1s 268us/step - loss: 2.7772e-04 - val_loss: 3.5899e-04\n",
      "Epoch 810/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.7912e-04 - val_loss: 3.9715e-04\n",
      "Epoch 811/2000\n",
      "3556/3556 [==============================] - 1s 268us/step - loss: 2.8626e-04 - val_loss: 3.5865e-04\n",
      "Epoch 812/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8369e-04 - val_loss: 3.5358e-04\n",
      "Epoch 813/2000\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 2.8997e-04 - val_loss: 3.6688e-04\n",
      "Epoch 814/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.8387e-04 - val_loss: 3.6288e-04\n",
      "Epoch 815/2000\n",
      "3556/3556 [==============================] - 1s 269us/step - loss: 2.8007e-04 - val_loss: 3.7901e-04\n",
      "Epoch 816/2000\n",
      "3556/3556 [==============================] - 1s 269us/step - loss: 2.7889e-04 - val_loss: 3.5907e-04\n",
      "Epoch 817/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.7735e-04 - val_loss: 3.6288e-04\n",
      "Epoch 818/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8611e-04 - val_loss: 3.6292e-04\n",
      "Epoch 819/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.8390e-04 - val_loss: 3.6521e-04\n",
      "Epoch 820/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.7837e-04 - val_loss: 3.5973e-04\n",
      "Epoch 821/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.7818e-04 - val_loss: 3.5759e-04\n",
      "Epoch 822/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.7775e-04 - val_loss: 3.6830e-04\n",
      "Epoch 823/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.7896e-04 - val_loss: 4.0099e-04\n",
      "Epoch 824/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8426e-04 - val_loss: 4.3235e-04\n",
      "Epoch 825/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 3.0524e-04 - val_loss: 3.8477e-04\n",
      "Epoch 826/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.0120e-04 - val_loss: 3.6284e-04\n",
      "Epoch 827/2000\n",
      "3556/3556 [==============================] - 1s 267us/step - loss: 2.8738e-04 - val_loss: 4.0390e-04\n",
      "Epoch 828/2000\n",
      "3556/3556 [==============================] - 1s 269us/step - loss: 2.8635e-04 - val_loss: 3.6059e-04\n",
      "Epoch 829/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.7969e-04 - val_loss: 3.5999e-04\n",
      "Epoch 830/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.7661e-04 - val_loss: 3.5665e-04\n",
      "Epoch 831/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.7822e-04 - val_loss: 3.6172e-04\n",
      "Epoch 832/2000\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 2.8152e-04 - val_loss: 3.6266e-04\n",
      "Epoch 833/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.7492e-04 - val_loss: 3.6196e-04\n",
      "Epoch 834/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.7805e-04 - val_loss: 3.5628e-04\n",
      "Epoch 835/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.7709e-04 - val_loss: 3.6003e-04\n",
      "Epoch 836/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.7833e-04 - val_loss: 3.5499e-04\n",
      "Epoch 837/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.7854e-04 - val_loss: 3.7371e-04\n",
      "Epoch 838/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.7789e-04 - val_loss: 3.7175e-04\n",
      "Epoch 839/2000\n",
      "3556/3556 [==============================] - 1s 267us/step - loss: 2.7964e-04 - val_loss: 3.7096e-04\n",
      "Epoch 840/2000\n",
      "3556/3556 [==============================] - 1s 273us/step - loss: 2.8254e-04 - val_loss: 3.6473e-04\n",
      "Epoch 841/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8552e-04 - val_loss: 4.1056e-04\n",
      "Epoch 842/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.9238e-04 - val_loss: 4.3474e-04\n",
      "Epoch 843/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 3.0118e-04 - val_loss: 3.5909e-04\n",
      "Epoch 844/2000\n",
      "3556/3556 [==============================] - 1s 267us/step - loss: 2.8075e-04 - val_loss: 3.9420e-04\n",
      "Epoch 845/2000\n",
      "3556/3556 [==============================] - 1s 268us/step - loss: 2.9541e-04 - val_loss: 4.0247e-04\n",
      "Epoch 846/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.0400e-04 - val_loss: 3.6448e-04\n",
      "Epoch 847/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.9038e-04 - val_loss: 3.5699e-04\n",
      "Epoch 848/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9268e-04 - val_loss: 3.9142e-04\n",
      "Epoch 849/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.9861e-04 - val_loss: 3.7585e-04\n",
      "Epoch 850/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.8590e-04 - val_loss: 3.5798e-04\n",
      "Epoch 851/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.7532e-04 - val_loss: 3.9407e-04\n",
      "Epoch 852/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8923e-04 - val_loss: 3.5754e-04\n",
      "Epoch 853/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.9017e-04 - val_loss: 4.3134e-04\n",
      "Epoch 854/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8693e-04 - val_loss: 3.5848e-04\n",
      "Epoch 855/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.7663e-04 - val_loss: 3.5853e-04\n",
      "Epoch 856/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8096e-04 - val_loss: 3.5507e-04\n",
      "Epoch 857/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8368e-04 - val_loss: 3.5754e-04\n",
      "Epoch 858/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8473e-04 - val_loss: 3.6320e-04\n",
      "Epoch 859/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8195e-04 - val_loss: 3.7602e-04\n",
      "Epoch 860/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8268e-04 - val_loss: 3.7892e-04\n",
      "Epoch 861/2000\n",
      "3556/3556 [==============================] - 1s 269us/step - loss: 2.8904e-04 - val_loss: 3.5609e-04\n",
      "Epoch 862/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.7835e-04 - val_loss: 3.5765e-04\n",
      "Epoch 863/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.7507e-04 - val_loss: 3.7743e-04\n",
      "Epoch 864/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.7460e-04 - val_loss: 3.5709e-04\n",
      "Epoch 865/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8056e-04 - val_loss: 3.6270e-04\n",
      "Epoch 866/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.9660e-04 - val_loss: 4.0330e-04\n",
      "Epoch 867/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 3.0637e-04 - val_loss: 3.9687e-04\n",
      "Epoch 868/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.9983e-04 - val_loss: 3.5492e-04\n",
      "Epoch 869/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8285e-04 - val_loss: 4.2161e-04\n",
      "Epoch 870/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8774e-04 - val_loss: 3.6576e-04\n",
      "Epoch 871/2000\n",
      "3556/3556 [==============================] - 1s 267us/step - loss: 2.8874e-04 - val_loss: 3.5825e-04\n",
      "Epoch 872/2000\n",
      "3556/3556 [==============================] - 1s 270us/step - loss: 2.7923e-04 - val_loss: 3.6281e-04\n",
      "Epoch 873/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.8582e-04 - val_loss: 3.7597e-04\n",
      "Epoch 874/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.9597e-04 - val_loss: 3.9327e-04\n",
      "Epoch 875/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8854e-04 - val_loss: 3.5420e-04\n",
      "Epoch 876/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.7738e-04 - val_loss: 3.7726e-04\n",
      "Epoch 877/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.0001e-04 - val_loss: 3.8346e-04\n",
      "Epoch 878/2000\n",
      "3556/3556 [==============================] - 1s 268us/step - loss: 3.2643e-04 - val_loss: 3.5639e-04\n",
      "Epoch 879/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.0799e-04 - val_loss: 4.6862e-04\n",
      "Epoch 880/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9597e-04 - val_loss: 3.7397e-04\n",
      "Epoch 881/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8691e-04 - val_loss: 3.6033e-04\n",
      "Epoch 882/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.8036e-04 - val_loss: 3.5516e-04\n",
      "Epoch 883/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.7707e-04 - val_loss: 3.5418e-04\n",
      "Epoch 884/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.7427e-04 - val_loss: 3.5535e-04\n",
      "Epoch 885/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.7596e-04 - val_loss: 3.5455e-04\n",
      "Epoch 886/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8039e-04 - val_loss: 3.9687e-04\n",
      "Epoch 887/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8269e-04 - val_loss: 3.8006e-04\n",
      "Epoch 888/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.8546e-04 - val_loss: 3.6269e-04\n",
      "Epoch 889/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.7392e-04 - val_loss: 3.8225e-04\n",
      "Epoch 890/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9462e-04 - val_loss: 3.9428e-04\n",
      "Epoch 891/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 3.2475e-04 - val_loss: 4.2481e-04\n",
      "Epoch 892/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8518e-04 - val_loss: 3.5907e-04\n",
      "Epoch 893/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8359e-04 - val_loss: 3.5895e-04\n",
      "Epoch 894/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8138e-04 - val_loss: 3.6538e-04\n",
      "Epoch 895/2000\n",
      "3556/3556 [==============================] - 1s 268us/step - loss: 2.8023e-04 - val_loss: 3.6073e-04\n",
      "Epoch 896/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8153e-04 - val_loss: 3.5990e-04\n",
      "Epoch 897/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.7647e-04 - val_loss: 3.5614e-04\n",
      "Epoch 898/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.7484e-04 - val_loss: 3.6165e-04\n",
      "Epoch 899/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.7871e-04 - val_loss: 3.7942e-04\n",
      "Epoch 900/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8725e-04 - val_loss: 3.8627e-04\n",
      "Epoch 901/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.7717e-04 - val_loss: 3.8929e-04\n",
      "Epoch 902/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8175e-04 - val_loss: 3.6340e-04\n",
      "Epoch 903/2000\n",
      "3556/3556 [==============================] - 1s 268us/step - loss: 2.7378e-04 - val_loss: 3.5963e-04\n",
      "Epoch 904/2000\n",
      "3556/3556 [==============================] - 1s 268us/step - loss: 2.7757e-04 - val_loss: 3.6009e-04\n",
      "Epoch 905/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.7997e-04 - val_loss: 3.5822e-04\n",
      "Epoch 906/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.7320e-04 - val_loss: 3.8067e-04\n",
      "Epoch 907/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.7506e-04 - val_loss: 3.6219e-04\n",
      "Epoch 908/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.7446e-04 - val_loss: 3.5766e-04\n",
      "Epoch 909/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8217e-04 - val_loss: 3.5752e-04\n",
      "Epoch 910/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.7988e-04 - val_loss: 4.0683e-04\n",
      "Epoch 911/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9459e-04 - val_loss: 4.0687e-04\n",
      "Epoch 912/2000\n",
      "3556/3556 [==============================] - 1s 270us/step - loss: 3.0519e-04 - val_loss: 3.9012e-04\n",
      "Epoch 913/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8801e-04 - val_loss: 3.5741e-04\n",
      "Epoch 914/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.8322e-04 - val_loss: 3.8441e-04\n",
      "Epoch 915/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.9456e-04 - val_loss: 3.9998e-04\n",
      "Epoch 916/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 3.0575e-04 - val_loss: 5.1352e-04\n",
      "Epoch 917/2000\n",
      "3556/3556 [==============================] - 1s 269us/step - loss: 2.9464e-04 - val_loss: 3.5727e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 918/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8984e-04 - val_loss: 3.6431e-04\n",
      "Epoch 919/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.7712e-04 - val_loss: 3.8271e-04\n",
      "Epoch 920/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8289e-04 - val_loss: 3.8811e-04\n",
      "Epoch 921/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8325e-04 - val_loss: 3.7097e-04\n",
      "Epoch 922/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.7964e-04 - val_loss: 3.9170e-04\n",
      "Epoch 923/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9758e-04 - val_loss: 3.7112e-04\n",
      "Epoch 924/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.8681e-04 - val_loss: 3.6563e-04\n",
      "Epoch 925/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.8071e-04 - val_loss: 3.9649e-04\n",
      "Epoch 926/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.7444e-04 - val_loss: 3.6008e-04\n",
      "Epoch 927/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.7794e-04 - val_loss: 3.6624e-04\n",
      "Epoch 928/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.7602e-04 - val_loss: 4.0458e-04\n",
      "Epoch 929/2000\n",
      "3556/3556 [==============================] - 1s 268us/step - loss: 2.8311e-04 - val_loss: 3.6100e-04\n",
      "Epoch 930/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8218e-04 - val_loss: 3.6119e-04\n",
      "Epoch 931/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.9008e-04 - val_loss: 3.8698e-04\n",
      "Epoch 932/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8892e-04 - val_loss: 3.7012e-04\n",
      "Epoch 933/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.7540e-04 - val_loss: 3.5900e-04\n",
      "Epoch 934/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.7253e-04 - val_loss: 3.6628e-04\n",
      "Epoch 935/2000\n",
      "3556/3556 [==============================] - 1s 270us/step - loss: 2.7197e-04 - val_loss: 3.5834e-04\n",
      "Epoch 936/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.7331e-04 - val_loss: 3.5583e-04\n",
      "Epoch 937/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.8282e-04 - val_loss: 3.5783e-04\n",
      "Epoch 938/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.7422e-04 - val_loss: 3.6322e-04\n",
      "Epoch 939/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9716e-04 - val_loss: 3.7153e-04\n",
      "Epoch 940/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8116e-04 - val_loss: 3.5680e-04\n",
      "Epoch 941/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.7277e-04 - val_loss: 3.8877e-04\n",
      "Epoch 942/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.8194e-04 - val_loss: 3.5933e-04\n",
      "Epoch 943/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.0053e-04 - val_loss: 3.7024e-04\n",
      "Epoch 944/2000\n",
      "3556/3556 [==============================] - 1s 267us/step - loss: 3.2702e-04 - val_loss: 5.5312e-04\n",
      "Epoch 945/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 3.0551e-04 - val_loss: 3.7484e-04\n",
      "Epoch 946/2000\n",
      "3556/3556 [==============================] - 1s 270us/step - loss: 2.8080e-04 - val_loss: 4.0509e-04\n",
      "Epoch 947/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.7926e-04 - val_loss: 3.6518e-04\n",
      "Epoch 948/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8096e-04 - val_loss: 3.5721e-04\n",
      "Epoch 949/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.7769e-04 - val_loss: 3.6316e-04\n",
      "Epoch 950/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.7741e-04 - val_loss: 3.7487e-04\n",
      "Epoch 951/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.7726e-04 - val_loss: 3.6448e-04\n",
      "Epoch 952/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.7762e-04 - val_loss: 3.5988e-04\n",
      "Epoch 953/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.7240e-04 - val_loss: 3.6336e-04\n",
      "Epoch 954/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 3.0626e-04 - val_loss: 3.7375e-04\n",
      "Epoch 955/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 3.1905e-04 - val_loss: 3.6967e-04\n",
      "Epoch 956/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 3.1174e-04 - val_loss: 4.6834e-04\n",
      "Epoch 957/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 3.1551e-04 - val_loss: 3.5474e-04\n",
      "Epoch 958/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.9710e-04 - val_loss: 4.5861e-04\n",
      "Epoch 959/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 3.0930e-04 - val_loss: 3.5803e-04\n",
      "Epoch 960/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.8489e-04 - val_loss: 4.6373e-04\n",
      "Epoch 961/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.8869e-04 - val_loss: 3.5603e-04\n",
      "Epoch 962/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.7287e-04 - val_loss: 3.6016e-04\n",
      "Epoch 963/2000\n",
      "3556/3556 [==============================] - 1s 270us/step - loss: 2.7458e-04 - val_loss: 3.6674e-04\n",
      "Epoch 964/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.7921e-04 - val_loss: 3.9118e-04\n",
      "Epoch 965/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.7699e-04 - val_loss: 3.5675e-04\n",
      "Epoch 966/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.9297e-04 - val_loss: 4.3686e-04\n",
      "Epoch 967/2000\n",
      "3556/3556 [==============================] - 1s 271us/step - loss: 3.1724e-04 - val_loss: 3.5914e-04\n",
      "Epoch 968/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.0310e-04 - val_loss: 4.5848e-04\n",
      "Epoch 969/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 3.1077e-04 - val_loss: 3.7693e-04\n",
      "Epoch 970/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.9096e-04 - val_loss: 4.2677e-04\n",
      "Epoch 971/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.1029e-04 - val_loss: 3.6045e-04\n",
      "Epoch 972/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9730e-04 - val_loss: 4.4342e-04\n",
      "Epoch 973/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 3.1300e-04 - val_loss: 3.6038e-04\n",
      "Epoch 974/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.7936e-04 - val_loss: 3.5909e-04\n",
      "Epoch 975/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.7903e-04 - val_loss: 3.5713e-04\n",
      "Epoch 976/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.7449e-04 - val_loss: 4.0210e-04\n",
      "Epoch 977/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9295e-04 - val_loss: 3.5494e-04\n",
      "Epoch 978/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8876e-04 - val_loss: 4.1612e-04\n",
      "Epoch 979/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.8333e-04 - val_loss: 3.6349e-04\n",
      "Epoch 980/2000\n",
      "3556/3556 [==============================] - 1s 271us/step - loss: 2.7620e-04 - val_loss: 3.6937e-04\n",
      "Epoch 981/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.7269e-04 - val_loss: 3.7011e-04\n",
      "Epoch 982/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8543e-04 - val_loss: 4.2965e-04\n",
      "Epoch 983/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.7997e-04 - val_loss: 3.5956e-04\n",
      "Epoch 984/2000\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 2.7997e-04 - val_loss: 3.6027e-04\n",
      "Epoch 985/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.7373e-04 - val_loss: 3.5987e-04\n",
      "Epoch 986/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.7580e-04 - val_loss: 3.8534e-04\n",
      "Epoch 987/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.7892e-04 - val_loss: 3.9283e-04\n",
      "Epoch 988/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.7480e-04 - val_loss: 3.5744e-04\n",
      "Epoch 989/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.7242e-04 - val_loss: 3.5483e-04\n",
      "Epoch 990/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.6927e-04 - val_loss: 4.0156e-04\n",
      "Epoch 991/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.7198e-04 - val_loss: 3.7650e-04\n",
      "Epoch 992/2000\n",
      "3556/3556 [==============================] - ETA: 0s - loss: 2.6641e-0 - 1s 265us/step - loss: 2.6989e-04 - val_loss: 3.6140e-04\n",
      "Epoch 993/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.7247e-04 - val_loss: 3.6187e-04\n",
      "Epoch 994/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.7523e-04 - val_loss: 3.5868e-04\n",
      "Epoch 995/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.7162e-04 - val_loss: 3.5659e-04\n",
      "Epoch 996/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.6723e-04 - val_loss: 3.7103e-04\n",
      "Epoch 997/2000\n",
      "3556/3556 [==============================] - 1s 271us/step - loss: 2.7038e-04 - val_loss: 3.8029e-04\n",
      "Epoch 998/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8181e-04 - val_loss: 4.3900e-04\n",
      "Epoch 999/2000\n",
      "3556/3556 [==============================] - 1s 270us/step - loss: 2.8767e-04 - val_loss: 3.6913e-04\n",
      "Epoch 1000/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.7608e-04 - val_loss: 3.5935e-04\n",
      "Epoch 1001/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.7056e-04 - val_loss: 4.0394e-04\n",
      "Epoch 1002/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.8666e-04 - val_loss: 3.6719e-04\n",
      "Epoch 1003/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9301e-04 - val_loss: 3.8213e-04\n",
      "Epoch 1004/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8146e-04 - val_loss: 3.6151e-04\n",
      "Epoch 1005/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.6678e-04 - val_loss: 3.5954e-04\n",
      "Epoch 1006/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.7596e-04 - val_loss: 3.9404e-04\n",
      "Epoch 1007/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.0367e-04 - val_loss: 4.3162e-04\n",
      "Epoch 1008/2000\n",
      "3556/3556 [==============================] - 1s 267us/step - loss: 2.9422e-04 - val_loss: 3.6679e-04\n",
      "Epoch 1009/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.7857e-04 - val_loss: 4.6278e-04\n",
      "Epoch 1010/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.2956e-04 - val_loss: 3.6183e-04\n",
      "Epoch 1011/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 3.1299e-04 - val_loss: 4.1963e-04\n",
      "Epoch 1012/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9115e-04 - val_loss: 3.6130e-04\n",
      "Epoch 1013/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.8567e-04 - val_loss: 4.0568e-04\n",
      "Epoch 1014/2000\n",
      "3556/3556 [==============================] - 1s 271us/step - loss: 2.7899e-04 - val_loss: 3.6319e-04\n",
      "Epoch 1015/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8210e-04 - val_loss: 3.7339e-04\n",
      "Epoch 1016/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8569e-04 - val_loss: 3.6014e-04\n",
      "Epoch 1017/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8418e-04 - val_loss: 3.7585e-04\n",
      "Epoch 1018/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 3.0123e-04 - val_loss: 5.9073e-04\n",
      "Epoch 1019/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 3.2372e-04 - val_loss: 3.6119e-04\n",
      "Epoch 1020/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.7540e-04 - val_loss: 3.7389e-04\n",
      "Epoch 1021/2000\n",
      "3556/3556 [==============================] - 1s 269us/step - loss: 2.7539e-04 - val_loss: 4.0291e-04\n",
      "Epoch 1022/2000\n",
      "3556/3556 [==============================] - 1s 267us/step - loss: 2.7944e-04 - val_loss: 3.6858e-04\n",
      "Epoch 1023/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.7831e-04 - val_loss: 3.6194e-04\n",
      "Epoch 1024/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.7949e-04 - val_loss: 3.8145e-04\n",
      "Epoch 1025/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.7143e-04 - val_loss: 3.7625e-04\n",
      "Epoch 1026/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.7368e-04 - val_loss: 3.6716e-04\n",
      "Epoch 1027/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.6697e-04 - val_loss: 3.6326e-04\n",
      "Epoch 1028/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.7010e-04 - val_loss: 3.6432e-04\n",
      "Epoch 1029/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.7951e-04 - val_loss: 3.9267e-04\n",
      "Epoch 1030/2000\n",
      "3556/3556 [==============================] - 1s 273us/step - loss: 2.7323e-04 - val_loss: 3.6602e-04\n",
      "Epoch 1031/2000\n",
      "3556/3556 [==============================] - 1s 272us/step - loss: 2.7144e-04 - val_loss: 3.6490e-04\n",
      "Epoch 1032/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.7081e-04 - val_loss: 3.8725e-04\n",
      "Epoch 1033/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8369e-04 - val_loss: 4.1374e-04\n",
      "Epoch 1034/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9693e-04 - val_loss: 4.2639e-04\n",
      "Epoch 1035/2000\n",
      "3556/3556 [==============================] - 1s 267us/step - loss: 3.0674e-04 - val_loss: 3.9202e-04\n",
      "Epoch 1036/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9459e-04 - val_loss: 3.6450e-04\n",
      "Epoch 1037/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.7508e-04 - val_loss: 3.6624e-04\n",
      "Epoch 1038/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.7093e-04 - val_loss: 3.6078e-04\n",
      "Epoch 1039/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.6872e-04 - val_loss: 3.7161e-04\n",
      "Epoch 1040/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.6821e-04 - val_loss: 3.6849e-04\n",
      "Epoch 1041/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8547e-04 - val_loss: 3.8525e-04\n",
      "Epoch 1042/2000\n",
      "3556/3556 [==============================] - 1s 269us/step - loss: 2.7813e-04 - val_loss: 4.1253e-04\n",
      "Epoch 1043/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.7316e-04 - val_loss: 3.6203e-04\n",
      "Epoch 1044/2000\n",
      "3556/3556 [==============================] - 1s 269us/step - loss: 2.7807e-04 - val_loss: 3.8478e-04\n",
      "Epoch 1045/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.7076e-04 - val_loss: 3.6518e-04\n",
      "Epoch 1046/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.6907e-04 - val_loss: 3.6336e-04\n",
      "Epoch 1047/2000\n",
      "3556/3556 [==============================] - 1s 269us/step - loss: 2.7011e-04 - val_loss: 3.6181e-04\n",
      "Epoch 1048/2000\n",
      "3556/3556 [==============================] - 1s 267us/step - loss: 2.6910e-04 - val_loss: 3.6461e-04\n",
      "Epoch 1049/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.7521e-04 - val_loss: 3.6363e-04\n",
      "Epoch 1050/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.6350e-04 - val_loss: 3.7096e-04\n",
      "Epoch 1051/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.7245e-04 - val_loss: 3.6494e-04\n",
      "Epoch 1052/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.6406e-04 - val_loss: 3.5953e-04\n",
      "Epoch 1053/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.6411e-04 - val_loss: 3.6948e-04\n",
      "Epoch 1054/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.6521e-04 - val_loss: 3.5766e-04\n",
      "Epoch 1055/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.6760e-04 - val_loss: 3.7129e-04\n",
      "Epoch 1056/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.6841e-04 - val_loss: 3.7437e-04\n",
      "Epoch 1057/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.7197e-04 - val_loss: 3.6006e-04\n",
      "Epoch 1058/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.7023e-04 - val_loss: 3.7501e-04\n",
      "Epoch 1059/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.8641e-04 - val_loss: 4.2221e-04\n",
      "Epoch 1060/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8383e-04 - val_loss: 3.7123e-04\n",
      "Epoch 1061/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.7496e-04 - val_loss: 3.6505e-04\n",
      "Epoch 1062/2000\n",
      "3556/3556 [==============================] - 1s 272us/step - loss: 2.6818e-04 - val_loss: 3.6299e-04\n",
      "Epoch 1063/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.7036e-04 - val_loss: 4.0178e-04\n",
      "Epoch 1064/2000\n",
      "3556/3556 [==============================] - 1s 267us/step - loss: 2.7593e-04 - val_loss: 3.6387e-04\n",
      "Epoch 1065/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.6556e-04 - val_loss: 3.7068e-04\n",
      "Epoch 1066/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.6517e-04 - val_loss: 3.6082e-04\n",
      "Epoch 1067/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.6246e-04 - val_loss: 3.7620e-04\n",
      "Epoch 1068/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8356e-04 - val_loss: 4.1138e-04\n",
      "Epoch 1069/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9305e-04 - val_loss: 3.7821e-04\n",
      "Epoch 1070/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.9671e-04 - val_loss: 3.8154e-04\n",
      "Epoch 1071/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8629e-04 - val_loss: 3.7624e-04\n",
      "Epoch 1072/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.6765e-04 - val_loss: 3.7837e-04\n",
      "Epoch 1073/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.7067e-04 - val_loss: 3.7934e-04\n",
      "Epoch 1074/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.6773e-04 - val_loss: 3.6680e-04\n",
      "Epoch 1075/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.7156e-04 - val_loss: 3.7986e-04\n",
      "Epoch 1076/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.7656e-04 - val_loss: 3.6289e-04\n",
      "Epoch 1077/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.7200e-04 - val_loss: 3.8712e-04\n",
      "Epoch 1078/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.6425e-04 - val_loss: 3.5885e-04\n",
      "Epoch 1079/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.6449e-04 - val_loss: 3.8150e-04\n",
      "Epoch 1080/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.6847e-04 - val_loss: 3.7064e-04\n",
      "Epoch 1081/2000\n",
      "3556/3556 [==============================] - 1s 268us/step - loss: 2.9200e-04 - val_loss: 3.8782e-04\n",
      "Epoch 1082/2000\n",
      "3556/3556 [==============================] - 1s 267us/step - loss: 2.9193e-04 - val_loss: 3.7599e-04\n",
      "Epoch 1083/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.6858e-04 - val_loss: 3.6316e-04\n",
      "Epoch 1084/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.7008e-04 - val_loss: 4.0304e-04\n",
      "Epoch 1085/2000\n",
      "3556/3556 [==============================] - 1s 267us/step - loss: 2.7193e-04 - val_loss: 3.7795e-04\n",
      "Epoch 1086/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8033e-04 - val_loss: 4.0090e-04\n",
      "Epoch 1087/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.7911e-04 - val_loss: 3.8283e-04\n",
      "Epoch 1088/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.8324e-04 - val_loss: 4.3600e-04\n",
      "Epoch 1089/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.7808e-04 - val_loss: 3.6612e-04\n",
      "Epoch 1090/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9025e-04 - val_loss: 3.7005e-04\n",
      "Epoch 1091/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.7699e-04 - val_loss: 3.6848e-04\n",
      "Epoch 1092/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.7602e-04 - val_loss: 3.7153e-04\n",
      "Epoch 1093/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.7368e-04 - val_loss: 3.6616e-04\n",
      "Epoch 1094/2000\n",
      "3556/3556 [==============================] - 1s 271us/step - loss: 2.6512e-04 - val_loss: 3.6847e-04\n",
      "Epoch 1095/2000\n",
      "3556/3556 [==============================] - 1s 268us/step - loss: 2.6612e-04 - val_loss: 3.6429e-04\n",
      "Epoch 1096/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.6504e-04 - val_loss: 3.6363e-04\n",
      "Epoch 1097/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.6702e-04 - val_loss: 3.6092e-04\n",
      "Epoch 1098/2000\n",
      "3556/3556 [==============================] - 1s 271us/step - loss: 2.6573e-04 - val_loss: 3.7069e-04\n",
      "Epoch 1099/2000\n",
      "3556/3556 [==============================] - ETA: 0s - loss: 2.8056e-0 - 1s 265us/step - loss: 2.7560e-04 - val_loss: 3.6303e-04\n",
      "Epoch 1100/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.6082e-04 - val_loss: 3.7065e-04\n",
      "Epoch 1101/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.7091e-04 - val_loss: 3.6666e-04\n",
      "Epoch 1102/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.6582e-04 - val_loss: 3.6081e-04\n",
      "Epoch 1103/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.6991e-04 - val_loss: 3.7077e-04\n",
      "Epoch 1104/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.6644e-04 - val_loss: 3.7966e-04\n",
      "Epoch 1105/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.6850e-04 - val_loss: 3.9145e-04\n",
      "Epoch 1106/2000\n",
      "3556/3556 [==============================] - 1s 267us/step - loss: 2.7416e-04 - val_loss: 3.9892e-04\n",
      "Epoch 1107/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.6618e-04 - val_loss: 3.7264e-04\n",
      "Epoch 1108/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.6913e-04 - val_loss: 3.8627e-04\n",
      "Epoch 1109/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.7578e-04 - val_loss: 4.2596e-04\n",
      "Epoch 1110/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.7413e-04 - val_loss: 3.8653e-04\n",
      "Epoch 1111/2000\n",
      "3556/3556 [==============================] - 1s 269us/step - loss: 2.6911e-04 - val_loss: 3.6596e-04\n",
      "Epoch 1112/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.6360e-04 - val_loss: 3.7239e-04\n",
      "Epoch 1113/2000\n",
      "3556/3556 [==============================] - 1s 267us/step - loss: 2.6191e-04 - val_loss: 3.6547e-04\n",
      "Epoch 1114/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.6501e-04 - val_loss: 3.9632e-04\n",
      "Epoch 1115/2000\n",
      "3556/3556 [==============================] - 1s 270us/step - loss: 2.7419e-04 - val_loss: 3.8870e-04\n",
      "Epoch 1116/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.7109e-04 - val_loss: 4.0101e-04\n",
      "Epoch 1117/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.7226e-04 - val_loss: 3.7292e-04\n",
      "Epoch 1118/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.7112e-04 - val_loss: 4.9298e-04\n",
      "Epoch 1119/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.8153e-04 - val_loss: 3.6684e-04\n",
      "Epoch 1120/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.6092e-04 - val_loss: 3.8581e-04\n",
      "Epoch 1121/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.6815e-04 - val_loss: 3.6984e-04\n",
      "Epoch 1122/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.6541e-04 - val_loss: 3.6496e-04\n",
      "Epoch 1123/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.6544e-04 - val_loss: 3.9150e-04\n",
      "Epoch 1124/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.7125e-04 - val_loss: 4.1937e-04\n",
      "Epoch 1125/2000\n",
      "3556/3556 [==============================] - 1s 268us/step - loss: 2.7209e-04 - val_loss: 3.9053e-04\n",
      "Epoch 1126/2000\n",
      "3556/3556 [==============================] - 1s 267us/step - loss: 2.8374e-04 - val_loss: 4.0864e-04\n",
      "Epoch 1127/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.8127e-04 - val_loss: 3.6405e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1128/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.6581e-04 - val_loss: 3.6691e-04\n",
      "Epoch 1129/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.6833e-04 - val_loss: 3.6860e-04\n",
      "Epoch 1130/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.7490e-04 - val_loss: 4.0617e-04\n",
      "Epoch 1131/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8222e-04 - val_loss: 4.3878e-04\n",
      "Epoch 1132/2000\n",
      "3556/3556 [==============================] - 1s 269us/step - loss: 3.2180e-04 - val_loss: 3.7362e-04\n",
      "Epoch 1133/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 3.4666e-04 - val_loss: 3.8486e-04\n",
      "Epoch 1134/2000\n",
      "3556/3556 [==============================] - 1s 269us/step - loss: 3.3873e-04 - val_loss: 4.0827e-04\n",
      "Epoch 1135/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.9738e-04 - val_loss: 4.1560e-04\n",
      "Epoch 1136/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.9764e-04 - val_loss: 4.3574e-04\n",
      "Epoch 1137/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8584e-04 - val_loss: 3.6772e-04\n",
      "Epoch 1138/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.7133e-04 - val_loss: 3.6620e-04\n",
      "Epoch 1139/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.6594e-04 - val_loss: 3.7087e-04\n",
      "Epoch 1140/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.6714e-04 - val_loss: 3.6704e-04\n",
      "Epoch 1141/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.7005e-04 - val_loss: 3.9387e-04\n",
      "Epoch 1142/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.6973e-04 - val_loss: 3.7089e-04\n",
      "Epoch 1143/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.7364e-04 - val_loss: 3.7568e-04\n",
      "Epoch 1144/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.7479e-04 - val_loss: 4.5277e-04\n",
      "Epoch 1145/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.7827e-04 - val_loss: 3.6947e-04\n",
      "Epoch 1146/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.6185e-04 - val_loss: 3.6562e-04\n",
      "Epoch 1147/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.6871e-04 - val_loss: 4.1885e-04\n",
      "Epoch 1148/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.7397e-04 - val_loss: 3.7471e-04\n",
      "Epoch 1149/2000\n",
      "3556/3556 [==============================] - 1s 271us/step - loss: 2.7805e-04 - val_loss: 3.7503e-04\n",
      "Epoch 1150/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.8200e-04 - val_loss: 5.0683e-04\n",
      "Epoch 1151/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.9641e-04 - val_loss: 3.7059e-04\n",
      "Epoch 1152/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.7029e-04 - val_loss: 3.6506e-04\n",
      "Epoch 1153/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.6936e-04 - val_loss: 3.8072e-04\n",
      "Epoch 1154/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.6697e-04 - val_loss: 3.9175e-04\n",
      "Epoch 1155/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.6241e-04 - val_loss: 3.6915e-04\n",
      "Epoch 1156/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.6317e-04 - val_loss: 3.7566e-04\n",
      "Epoch 1157/2000\n",
      "3556/3556 [==============================] - 1s 271us/step - loss: 2.6917e-04 - val_loss: 3.7064e-04\n",
      "Epoch 1158/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.6232e-04 - val_loss: 3.7093e-04\n",
      "Epoch 1159/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.6431e-04 - val_loss: 3.7329e-04\n",
      "Epoch 1160/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.5972e-04 - val_loss: 3.7778e-04\n",
      "Epoch 1161/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.6536e-04 - val_loss: 3.7264e-04\n",
      "Epoch 1162/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.6102e-04 - val_loss: 3.7456e-04\n",
      "Epoch 1163/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.6947e-04 - val_loss: 4.5771e-04\n",
      "Epoch 1164/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.7737e-04 - val_loss: 3.7059e-04\n",
      "Epoch 1165/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.8820e-04 - val_loss: 4.2503e-04\n",
      "Epoch 1166/2000\n",
      "3556/3556 [==============================] - 1s 271us/step - loss: 3.0555e-04 - val_loss: 3.8025e-04\n",
      "Epoch 1167/2000\n",
      "3556/3556 [==============================] - 1s 267us/step - loss: 2.7362e-04 - val_loss: 4.1944e-04\n",
      "Epoch 1168/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.7875e-04 - val_loss: 3.8138e-04\n",
      "Epoch 1169/2000\n",
      "3556/3556 [==============================] - 1s 267us/step - loss: 2.5610e-04 - val_loss: 3.9573e-04\n",
      "Epoch 1170/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.6929e-04 - val_loss: 3.8907e-04\n",
      "Epoch 1171/2000\n",
      "3556/3556 [==============================] - 1s 268us/step - loss: 2.6377e-04 - val_loss: 3.8994e-04\n",
      "Epoch 1172/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.7197e-04 - val_loss: 3.7245e-04\n",
      "Epoch 1173/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.7087e-04 - val_loss: 4.0912e-04\n",
      "Epoch 1174/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.7694e-04 - val_loss: 3.6521e-04\n",
      "Epoch 1175/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.7356e-04 - val_loss: 4.0404e-04\n",
      "Epoch 1176/2000\n",
      "3556/3556 [==============================] - 1s 267us/step - loss: 2.8840e-04 - val_loss: 3.7029e-04\n",
      "Epoch 1177/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.6481e-04 - val_loss: 3.8283e-04\n",
      "Epoch 1178/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.7423e-04 - val_loss: 4.3098e-04\n",
      "Epoch 1179/2000\n",
      "3556/3556 [==============================] - ETA: 0s - loss: 2.7415e-0 - 1s 266us/step - loss: 2.7498e-04 - val_loss: 3.8053e-04\n",
      "Epoch 1180/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.6225e-04 - val_loss: 3.7804e-04\n",
      "Epoch 1181/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.5807e-04 - val_loss: 3.6572e-04\n",
      "Epoch 1182/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.6703e-04 - val_loss: 3.8226e-04\n",
      "Epoch 1183/2000\n",
      "3556/3556 [==============================] - 1s 269us/step - loss: 2.5671e-04 - val_loss: 3.7253e-04\n",
      "Epoch 1184/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.6516e-04 - val_loss: 3.6500e-04\n",
      "Epoch 1185/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.6553e-04 - val_loss: 4.5882e-04\n",
      "Epoch 1186/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.6089e-04 - val_loss: 3.9802e-04\n",
      "Epoch 1187/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.5851e-04 - val_loss: 3.7888e-04\n",
      "Epoch 1188/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.5761e-04 - val_loss: 3.8559e-04\n",
      "Epoch 1189/2000\n",
      "3556/3556 [==============================] - 1s 271us/step - loss: 2.6922e-04 - val_loss: 4.2560e-04\n",
      "Epoch 1190/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.9481e-04 - val_loss: 4.5078e-04\n",
      "Epoch 1191/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 3.0000e-04 - val_loss: 4.4969e-04\n",
      "Epoch 1192/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.7354e-04 - val_loss: 3.7833e-04\n",
      "Epoch 1193/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.6137e-04 - val_loss: 3.8688e-04\n",
      "Epoch 1194/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.5785e-04 - val_loss: 3.7358e-04\n",
      "Epoch 1195/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.6627e-04 - val_loss: 4.0800e-04\n",
      "Epoch 1196/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.9172e-04 - val_loss: 4.3857e-04\n",
      "Epoch 1197/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.6493e-04 - val_loss: 3.7075e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1198/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.5915e-04 - val_loss: 3.7310e-04\n",
      "Epoch 1199/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.5593e-04 - val_loss: 3.7246e-04\n",
      "Epoch 1200/2000\n",
      "3556/3556 [==============================] - 1s 271us/step - loss: 2.6148e-04 - val_loss: 3.7705e-04\n",
      "Epoch 1201/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.6156e-04 - val_loss: 3.7764e-04\n",
      "Epoch 1202/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.6143e-04 - val_loss: 3.7676e-04\n",
      "Epoch 1203/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.5604e-04 - val_loss: 3.7830e-04\n",
      "Epoch 1204/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.5878e-04 - val_loss: 3.7719e-04\n",
      "Epoch 1205/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.6650e-04 - val_loss: 4.2721e-04\n",
      "Epoch 1206/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8907e-04 - val_loss: 4.6020e-04\n",
      "Epoch 1207/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.8264e-04 - val_loss: 3.7132e-04\n",
      "Epoch 1208/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.6797e-04 - val_loss: 4.4706e-04\n",
      "Epoch 1209/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.7972e-04 - val_loss: 3.7272e-04\n",
      "Epoch 1210/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.6048e-04 - val_loss: 3.7150e-04\n",
      "Epoch 1211/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.5580e-04 - val_loss: 3.9296e-04\n",
      "Epoch 1212/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.5739e-04 - val_loss: 3.7620e-04\n",
      "Epoch 1213/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.5528e-04 - val_loss: 3.7491e-04\n",
      "Epoch 1214/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.5258e-04 - val_loss: 3.7384e-04\n",
      "Epoch 1215/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.5882e-04 - val_loss: 3.7529e-04\n",
      "Epoch 1216/2000\n",
      "3556/3556 [==============================] - 1s 267us/step - loss: 2.5108e-04 - val_loss: 4.0118e-04\n",
      "Epoch 1217/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.5413e-04 - val_loss: 3.7977e-04\n",
      "Epoch 1218/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.5485e-04 - val_loss: 4.0384e-04\n",
      "Epoch 1219/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.5815e-04 - val_loss: 3.7532e-04\n",
      "Epoch 1220/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.7357e-04 - val_loss: 3.8295e-04\n",
      "Epoch 1221/2000\n",
      "3556/3556 [==============================] - 1s 270us/step - loss: 2.7049e-04 - val_loss: 4.2579e-04\n",
      "Epoch 1222/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.8807e-04 - val_loss: 3.9721e-04\n",
      "Epoch 1223/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.8652e-04 - val_loss: 3.8174e-04\n",
      "Epoch 1224/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.5457e-04 - val_loss: 3.7602e-04\n",
      "Epoch 1225/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.5396e-04 - val_loss: 4.1768e-04\n",
      "Epoch 1226/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.6507e-04 - val_loss: 3.9788e-04\n",
      "Epoch 1227/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.5941e-04 - val_loss: 3.9858e-04\n",
      "Epoch 1228/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.5994e-04 - val_loss: 3.8479e-04\n",
      "Epoch 1229/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.7242e-04 - val_loss: 4.0396e-04\n",
      "Epoch 1230/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.7357e-04 - val_loss: 4.4775e-04\n",
      "Epoch 1231/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.7501e-04 - val_loss: 3.8338e-04\n",
      "Epoch 1232/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.7367e-04 - val_loss: 3.6826e-04\n",
      "Epoch 1233/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.6150e-04 - val_loss: 3.9187e-04\n",
      "Epoch 1234/2000\n",
      "3556/3556 [==============================] - 1s 269us/step - loss: 2.6061e-04 - val_loss: 4.0335e-04\n",
      "Epoch 1235/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.5181e-04 - val_loss: 3.8386e-04\n",
      "Epoch 1236/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.5395e-04 - val_loss: 3.7574e-04\n",
      "Epoch 1237/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.6044e-04 - val_loss: 3.8841e-04\n",
      "Epoch 1238/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.5770e-04 - val_loss: 3.8478e-04\n",
      "Epoch 1239/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.5165e-04 - val_loss: 3.7433e-04\n",
      "Epoch 1240/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.6313e-04 - val_loss: 3.7580e-04\n",
      "Epoch 1241/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.7155e-04 - val_loss: 4.0162e-04\n",
      "Epoch 1242/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.5921e-04 - val_loss: 3.8196e-04\n",
      "Epoch 1243/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.4689e-04 - val_loss: 3.7951e-04\n",
      "Epoch 1244/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.4945e-04 - val_loss: 4.2616e-04\n",
      "Epoch 1245/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.6790e-04 - val_loss: 3.8150e-04\n",
      "Epoch 1246/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.5557e-04 - val_loss: 3.7190e-04\n",
      "Epoch 1247/2000\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 2.7250e-04 - val_loss: 4.5922e-04\n",
      "Epoch 1248/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.6525e-04 - val_loss: 4.1267e-04\n",
      "Epoch 1249/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.5195e-04 - val_loss: 3.7692e-04\n",
      "Epoch 1250/2000\n",
      "3556/3556 [==============================] - 1s 268us/step - loss: 2.5204e-04 - val_loss: 3.8920e-04\n",
      "Epoch 1251/2000\n",
      "3556/3556 [==============================] - 1s 268us/step - loss: 2.5773e-04 - val_loss: 4.4317e-04\n",
      "Epoch 1252/2000\n",
      "3556/3556 [==============================] - 1s 270us/step - loss: 2.6893e-04 - val_loss: 3.8731e-04\n",
      "Epoch 1253/2000\n",
      "3556/3556 [==============================] - 1s 269us/step - loss: 2.7329e-04 - val_loss: 3.9972e-04\n",
      "Epoch 1254/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.6080e-04 - val_loss: 3.7677e-04\n",
      "Epoch 1255/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.4459e-04 - val_loss: 3.9393e-04\n",
      "Epoch 1256/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.4865e-04 - val_loss: 3.8503e-04\n",
      "Epoch 1257/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.5379e-04 - val_loss: 3.8189e-04\n",
      "Epoch 1258/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.5064e-04 - val_loss: 3.7367e-04\n",
      "Epoch 1259/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.4814e-04 - val_loss: 3.9138e-04\n",
      "Epoch 1260/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.4831e-04 - val_loss: 3.8653e-04\n",
      "Epoch 1261/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.5836e-04 - val_loss: 3.7147e-04\n",
      "Epoch 1262/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.6312e-04 - val_loss: 3.9872e-04\n",
      "Epoch 1263/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.5729e-04 - val_loss: 3.8450e-04\n",
      "Epoch 1264/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.4834e-04 - val_loss: 3.7688e-04\n",
      "Epoch 1265/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.4558e-04 - val_loss: 3.8008e-04\n",
      "Epoch 1266/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.5010e-04 - val_loss: 3.9339e-04\n",
      "Epoch 1267/2000\n",
      "3556/3556 [==============================] - 1s 267us/step - loss: 2.5567e-04 - val_loss: 3.8063e-04\n",
      "Epoch 1268/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.5251e-04 - val_loss: 4.1864e-04\n",
      "Epoch 1269/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.6161e-04 - val_loss: 4.3601e-04\n",
      "Epoch 1270/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.6264e-04 - val_loss: 3.9358e-04\n",
      "Epoch 1271/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.7004e-04 - val_loss: 3.8840e-04\n",
      "Epoch 1272/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.4575e-04 - val_loss: 3.7515e-04\n",
      "Epoch 1273/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.5009e-04 - val_loss: 3.8005e-04\n",
      "Epoch 1274/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.5310e-04 - val_loss: 3.9985e-04\n",
      "Epoch 1275/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.5265e-04 - val_loss: 3.8705e-04\n",
      "Epoch 1276/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.6444e-04 - val_loss: 3.9802e-04\n",
      "Epoch 1277/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.6408e-04 - val_loss: 3.8935e-04\n",
      "Epoch 1278/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.6158e-04 - val_loss: 3.8225e-04\n",
      "Epoch 1279/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.5113e-04 - val_loss: 4.0419e-04\n",
      "Epoch 1280/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.5665e-04 - val_loss: 3.8576e-04\n",
      "Epoch 1281/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.6272e-04 - val_loss: 3.8485e-04\n",
      "Epoch 1282/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.5469e-04 - val_loss: 3.7602e-04\n",
      "Epoch 1283/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.6377e-04 - val_loss: 4.0434e-04\n",
      "Epoch 1284/2000\n",
      "3556/3556 [==============================] - 1s 276us/step - loss: 2.5644e-04 - val_loss: 3.7218e-04\n",
      "Epoch 1285/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.5164e-04 - val_loss: 3.8486e-04\n",
      "Epoch 1286/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.4517e-04 - val_loss: 3.9560e-04\n",
      "Epoch 1287/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.4880e-04 - val_loss: 3.8856e-04\n",
      "Epoch 1288/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.5572e-04 - val_loss: 3.9252e-04\n",
      "Epoch 1289/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.6058e-04 - val_loss: 3.6208e-04\n",
      "Epoch 1290/2000\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 2.5977e-04 - val_loss: 3.9881e-04\n",
      "Epoch 1291/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.5793e-04 - val_loss: 3.7857e-04\n",
      "Epoch 1292/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.4856e-04 - val_loss: 3.9218e-04\n",
      "Epoch 1293/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.4707e-04 - val_loss: 4.0122e-04\n",
      "Epoch 1294/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.5636e-04 - val_loss: 3.8716e-04\n",
      "Epoch 1295/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.6228e-04 - val_loss: 4.0769e-04\n",
      "Epoch 1296/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.6096e-04 - val_loss: 3.8255e-04\n",
      "Epoch 1297/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.4887e-04 - val_loss: 3.8054e-04\n",
      "Epoch 1298/2000\n",
      "3556/3556 [==============================] - 1s 268us/step - loss: 2.4772e-04 - val_loss: 3.8173e-04\n",
      "Epoch 1299/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.5102e-04 - val_loss: 3.8072e-04\n",
      "Epoch 1300/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.6550e-04 - val_loss: 3.7221e-04\n",
      "Epoch 1301/2000\n",
      "3556/3556 [==============================] - 1s 269us/step - loss: 2.5214e-04 - val_loss: 3.7050e-04\n",
      "Epoch 1302/2000\n",
      "3556/3556 [==============================] - 1s 268us/step - loss: 2.4974e-04 - val_loss: 3.8917e-04\n",
      "Epoch 1303/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.5242e-04 - val_loss: 3.9239e-04\n",
      "Epoch 1304/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.5365e-04 - val_loss: 4.3868e-04\n",
      "Epoch 1305/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.5589e-04 - val_loss: 3.9695e-04\n",
      "Epoch 1306/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.5474e-04 - val_loss: 4.2571e-04\n",
      "Epoch 1307/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.5400e-04 - val_loss: 4.1605e-04\n",
      "Epoch 1308/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.6114e-04 - val_loss: 3.9133e-04\n",
      "Epoch 1309/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.5524e-04 - val_loss: 4.0067e-04\n",
      "Epoch 1310/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.4805e-04 - val_loss: 3.7755e-04\n",
      "Epoch 1311/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.4929e-04 - val_loss: 3.7772e-04\n",
      "Epoch 1312/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.4844e-04 - val_loss: 3.8884e-04\n",
      "Epoch 1313/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.5052e-04 - val_loss: 4.0595e-04\n",
      "Epoch 1314/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.8130e-04 - val_loss: 3.8398e-04\n",
      "Epoch 1315/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.6831e-04 - val_loss: 3.6840e-04\n",
      "Epoch 1316/2000\n",
      "3556/3556 [==============================] - 1s 269us/step - loss: 2.5327e-04 - val_loss: 3.7411e-04\n",
      "Epoch 1317/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.4921e-04 - val_loss: 3.7193e-04\n",
      "Epoch 1318/2000\n",
      "3556/3556 [==============================] - 1s 272us/step - loss: 2.4859e-04 - val_loss: 3.7562e-04\n",
      "Epoch 1319/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.4055e-04 - val_loss: 3.8353e-04\n",
      "Epoch 1320/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.3750e-04 - val_loss: 3.8580e-04\n",
      "Epoch 1321/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.3791e-04 - val_loss: 4.0144e-04\n",
      "Epoch 1322/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.4136e-04 - val_loss: 3.9547e-04\n",
      "Epoch 1323/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.4719e-04 - val_loss: 3.7447e-04\n",
      "Epoch 1324/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.6357e-04 - val_loss: 4.3295e-04\n",
      "Epoch 1325/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.6657e-04 - val_loss: 3.9275e-04\n",
      "Epoch 1326/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.4704e-04 - val_loss: 4.2515e-04\n",
      "Epoch 1327/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.5462e-04 - val_loss: 4.1194e-04\n",
      "Epoch 1328/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.5473e-04 - val_loss: 4.4638e-04\n",
      "Epoch 1329/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.5805e-04 - val_loss: 3.6891e-04\n",
      "Epoch 1330/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.4832e-04 - val_loss: 3.9759e-04\n",
      "Epoch 1331/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.5046e-04 - val_loss: 3.8257e-04\n",
      "Epoch 1332/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.7009e-04 - val_loss: 3.9270e-04\n",
      "Epoch 1333/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.5163e-04 - val_loss: 3.7805e-04\n",
      "Epoch 1334/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.4054e-04 - val_loss: 3.9616e-04\n",
      "Epoch 1335/2000\n",
      "3556/3556 [==============================] - 1s 270us/step - loss: 2.3466e-04 - val_loss: 3.8732e-04\n",
      "Epoch 1336/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.3887e-04 - val_loss: 4.1426e-04\n",
      "Epoch 1337/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.3963e-04 - val_loss: 3.8582e-04\n",
      "Epoch 1338/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.4830e-04 - val_loss: 4.1132e-04\n",
      "Epoch 1339/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.4852e-04 - val_loss: 4.2166e-04\n",
      "Epoch 1340/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.4483e-04 - val_loss: 3.8419e-04\n",
      "Epoch 1341/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.4096e-04 - val_loss: 3.8533e-04\n",
      "Epoch 1342/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.4351e-04 - val_loss: 3.9803e-04\n",
      "Epoch 1343/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.3639e-04 - val_loss: 3.8900e-04\n",
      "Epoch 1344/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.4725e-04 - val_loss: 4.0543e-04\n",
      "Epoch 1345/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.6033e-04 - val_loss: 3.8427e-04\n",
      "Epoch 1346/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.4904e-04 - val_loss: 4.3035e-04\n",
      "Epoch 1347/2000\n",
      "3556/3556 [==============================] - 1s 269us/step - loss: 2.4584e-04 - val_loss: 3.7093e-04\n",
      "Epoch 1348/2000\n",
      "3556/3556 [==============================] - 1s 268us/step - loss: 2.3700e-04 - val_loss: 4.1080e-04\n",
      "Epoch 1349/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.4696e-04 - val_loss: 4.1343e-04\n",
      "Epoch 1350/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.4798e-04 - val_loss: 3.7929e-04\n",
      "Epoch 1351/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.6066e-04 - val_loss: 3.9196e-04\n",
      "Epoch 1352/2000\n",
      "3556/3556 [==============================] - 1s 270us/step - loss: 2.4928e-04 - val_loss: 3.8210e-04\n",
      "Epoch 1353/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.4673e-04 - val_loss: 3.7522e-04\n",
      "Epoch 1354/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.4391e-04 - val_loss: 4.0387e-04\n",
      "Epoch 1355/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.5163e-04 - val_loss: 3.8518e-04\n",
      "Epoch 1356/2000\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 2.4648e-04 - val_loss: 4.2543e-04\n",
      "Epoch 1357/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.5307e-04 - val_loss: 4.4014e-04\n",
      "Epoch 1358/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.4902e-04 - val_loss: 3.7518e-04\n",
      "Epoch 1359/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.4452e-04 - val_loss: 4.0741e-04\n",
      "Epoch 1360/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.4165e-04 - val_loss: 4.0474e-04\n",
      "Epoch 1361/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.5082e-04 - val_loss: 3.7811e-04\n",
      "Epoch 1362/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.4671e-04 - val_loss: 4.2794e-04\n",
      "Epoch 1363/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.5273e-04 - val_loss: 4.4311e-04\n",
      "Epoch 1364/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.4119e-04 - val_loss: 3.8694e-04\n",
      "Epoch 1365/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.5513e-04 - val_loss: 4.0380e-04\n",
      "Epoch 1366/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.3724e-04 - val_loss: 3.7603e-04\n",
      "Epoch 1367/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.3473e-04 - val_loss: 3.9488e-04\n",
      "Epoch 1368/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.2797e-04 - val_loss: 3.9056e-04\n",
      "Epoch 1369/2000\n",
      "3556/3556 [==============================] - 1s 272us/step - loss: 2.3463e-04 - val_loss: 3.8982e-04\n",
      "Epoch 1370/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.3775e-04 - val_loss: 3.9094e-04\n",
      "Epoch 1371/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.4034e-04 - val_loss: 3.7647e-04\n",
      "Epoch 1372/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.4326e-04 - val_loss: 4.0872e-04\n",
      "Epoch 1373/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.3443e-04 - val_loss: 4.0101e-04\n",
      "Epoch 1374/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.4635e-04 - val_loss: 4.1562e-04\n",
      "Epoch 1375/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.4457e-04 - val_loss: 4.1382e-04\n",
      "Epoch 1376/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.4161e-04 - val_loss: 3.9665e-04\n",
      "Epoch 1377/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.5613e-04 - val_loss: 3.9491e-04\n",
      "Epoch 1378/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.4578e-04 - val_loss: 3.9733e-04\n",
      "Epoch 1379/2000\n",
      "3556/3556 [==============================] - 1s 269us/step - loss: 2.5319e-04 - val_loss: 3.9909e-04\n",
      "Epoch 1380/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.3793e-04 - val_loss: 3.9350e-04\n",
      "Epoch 1381/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.3826e-04 - val_loss: 3.8743e-04\n",
      "Epoch 1382/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.4171e-04 - val_loss: 4.0363e-04\n",
      "Epoch 1383/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.5113e-04 - val_loss: 4.5819e-04\n",
      "Epoch 1384/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.4430e-04 - val_loss: 4.1123e-04\n",
      "Epoch 1385/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.4733e-04 - val_loss: 3.9695e-04\n",
      "Epoch 1386/2000\n",
      "3556/3556 [==============================] - 1s 270us/step - loss: 2.6884e-04 - val_loss: 4.5375e-04\n",
      "Epoch 1387/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.4183e-04 - val_loss: 4.0261e-04\n",
      "Epoch 1388/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.3768e-04 - val_loss: 4.0916e-04\n",
      "Epoch 1389/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.4147e-04 - val_loss: 3.9310e-04\n",
      "Epoch 1390/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.4234e-04 - val_loss: 3.7808e-04\n",
      "Epoch 1391/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.4076e-04 - val_loss: 3.8797e-04\n",
      "Epoch 1392/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.3781e-04 - val_loss: 3.9759e-04\n",
      "Epoch 1393/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.3922e-04 - val_loss: 4.5978e-04\n",
      "Epoch 1394/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.3924e-04 - val_loss: 4.3527e-04\n",
      "Epoch 1395/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.4322e-04 - val_loss: 4.3713e-04\n",
      "Epoch 1396/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.6437e-04 - val_loss: 4.5467e-04\n",
      "Epoch 1397/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.4711e-04 - val_loss: 3.9896e-04\n",
      "Epoch 1398/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.4235e-04 - val_loss: 4.1421e-04\n",
      "Epoch 1399/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.4425e-04 - val_loss: 4.8169e-04\n",
      "Epoch 1400/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.6074e-04 - val_loss: 3.7644e-04\n",
      "Epoch 1401/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.4647e-04 - val_loss: 4.0724e-04\n",
      "Epoch 1402/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.4173e-04 - val_loss: 4.2120e-04\n",
      "Epoch 1403/2000\n",
      "3556/3556 [==============================] - 1s 270us/step - loss: 2.3220e-04 - val_loss: 4.1861e-04\n",
      "Epoch 1404/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.3466e-04 - val_loss: 3.9590e-04\n",
      "Epoch 1405/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.4271e-04 - val_loss: 4.1337e-04\n",
      "Epoch 1406/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.3844e-04 - val_loss: 4.0632e-04\n",
      "Epoch 1407/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.3856e-04 - val_loss: 4.1074e-04\n",
      "Epoch 1408/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.4572e-04 - val_loss: 4.1950e-04\n",
      "Epoch 1409/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.4550e-04 - val_loss: 4.3960e-04\n",
      "Epoch 1410/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.4102e-04 - val_loss: 3.9974e-04\n",
      "Epoch 1411/2000\n",
      "3556/3556 [==============================] - 1s 270us/step - loss: 2.3009e-04 - val_loss: 4.1261e-04\n",
      "Epoch 1412/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.4194e-04 - val_loss: 4.0067e-04\n",
      "Epoch 1413/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.3405e-04 - val_loss: 4.0904e-04\n",
      "Epoch 1414/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.4259e-04 - val_loss: 4.8198e-04\n",
      "Epoch 1415/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.4378e-04 - val_loss: 3.9118e-04\n",
      "Epoch 1416/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.2835e-04 - val_loss: 4.1998e-04\n",
      "Epoch 1417/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.2936e-04 - val_loss: 4.1846e-04\n",
      "Epoch 1418/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.2971e-04 - val_loss: 4.3236e-04\n",
      "Epoch 1419/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.2553e-04 - val_loss: 4.3965e-04\n",
      "Epoch 1420/2000\n",
      "3556/3556 [==============================] - 1s 270us/step - loss: 2.2939e-04 - val_loss: 4.0026e-04\n",
      "Epoch 1421/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.2904e-04 - val_loss: 3.9087e-04\n",
      "Epoch 1422/2000\n",
      "3556/3556 [==============================] - 1s 268us/step - loss: 2.3435e-04 - val_loss: 5.4977e-04\n",
      "Epoch 1423/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.5035e-04 - val_loss: 5.0950e-04\n",
      "Epoch 1424/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.5614e-04 - val_loss: 3.8739e-04\n",
      "Epoch 1425/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.4282e-04 - val_loss: 3.8367e-04\n",
      "Epoch 1426/2000\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 2.3385e-04 - val_loss: 4.0977e-04\n",
      "Epoch 1427/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.2928e-04 - val_loss: 3.9961e-04\n",
      "Epoch 1428/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.2521e-04 - val_loss: 4.1161e-04\n",
      "Epoch 1429/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.2496e-04 - val_loss: 4.2029e-04\n",
      "Epoch 1430/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.2941e-04 - val_loss: 4.0268e-04\n",
      "Epoch 1431/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.2366e-04 - val_loss: 4.4666e-04\n",
      "Epoch 1432/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.2369e-04 - val_loss: 4.2477e-04\n",
      "Epoch 1433/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.1693e-04 - val_loss: 4.1213e-04\n",
      "Epoch 1434/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.1700e-04 - val_loss: 4.2926e-04\n",
      "Epoch 1435/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.2760e-04 - val_loss: 3.9521e-04\n",
      "Epoch 1436/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.1787e-04 - val_loss: 4.3752e-04\n",
      "Epoch 1437/2000\n",
      "3556/3556 [==============================] - 1s 267us/step - loss: 2.2402e-04 - val_loss: 4.4120e-04\n",
      "Epoch 1438/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.2431e-04 - val_loss: 4.1700e-04\n",
      "Epoch 1439/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.1786e-04 - val_loss: 4.5179e-04\n",
      "Epoch 1440/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.1815e-04 - val_loss: 4.0695e-04\n",
      "Epoch 1441/2000\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 2.2592e-04 - val_loss: 5.6074e-04\n",
      "Epoch 1442/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.3555e-04 - val_loss: 4.7600e-04\n",
      "Epoch 1443/2000\n",
      "3556/3556 [==============================] - 1s 269us/step - loss: 2.2223e-04 - val_loss: 4.3912e-04\n",
      "Epoch 1444/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.1279e-04 - val_loss: 4.1811e-04\n",
      "Epoch 1445/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.2188e-04 - val_loss: 4.7091e-04\n",
      "Epoch 1446/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.3301e-04 - val_loss: 4.8520e-04\n",
      "Epoch 1447/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.5384e-04 - val_loss: 4.8089e-04\n",
      "Epoch 1448/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.3363e-04 - val_loss: 4.1245e-04\n",
      "Epoch 1449/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.2812e-04 - val_loss: 4.5212e-04\n",
      "Epoch 1450/2000\n",
      "3556/3556 [==============================] - 1s 269us/step - loss: 2.4885e-04 - val_loss: 4.0053e-04\n",
      "Epoch 1451/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.4582e-04 - val_loss: 4.0937e-04\n",
      "Epoch 1452/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.3347e-04 - val_loss: 3.9686e-04\n",
      "Epoch 1453/2000\n",
      "3556/3556 [==============================] - 1s 267us/step - loss: 2.1956e-04 - val_loss: 4.2331e-04\n",
      "Epoch 1454/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.2002e-04 - val_loss: 4.1938e-04\n",
      "Epoch 1455/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.2402e-04 - val_loss: 4.3724e-04\n",
      "Epoch 1456/2000\n",
      "3556/3556 [==============================] - 1s 267us/step - loss: 2.3765e-04 - val_loss: 4.4009e-04\n",
      "Epoch 1457/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.4169e-04 - val_loss: 4.1036e-04\n",
      "Epoch 1458/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.3732e-04 - val_loss: 4.0160e-04\n",
      "Epoch 1459/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.2205e-04 - val_loss: 4.5344e-04\n",
      "Epoch 1460/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.3115e-04 - val_loss: 4.1068e-04\n",
      "Epoch 1461/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.3145e-04 - val_loss: 4.1904e-04\n",
      "Epoch 1462/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.2379e-04 - val_loss: 4.2710e-04\n",
      "Epoch 1463/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.1935e-04 - val_loss: 4.3505e-04\n",
      "Epoch 1464/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.2071e-04 - val_loss: 4.2535e-04\n",
      "Epoch 1465/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.2761e-04 - val_loss: 4.5142e-04\n",
      "Epoch 1466/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.2283e-04 - val_loss: 4.4420e-04\n",
      "Epoch 1467/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.3634e-04 - val_loss: 4.2265e-04\n",
      "Epoch 1468/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.3247e-04 - val_loss: 4.5504e-04\n",
      "Epoch 1469/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.2189e-04 - val_loss: 4.0790e-04\n",
      "Epoch 1470/2000\n",
      "3556/3556 [==============================] - 1s 268us/step - loss: 2.1465e-04 - val_loss: 4.4835e-04\n",
      "Epoch 1471/2000\n",
      "3556/3556 [==============================] - 1s 267us/step - loss: 2.2239e-04 - val_loss: 4.6453e-04\n",
      "Epoch 1472/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.3893e-04 - val_loss: 3.9791e-04\n",
      "Epoch 1473/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.4686e-04 - val_loss: 4.0150e-04\n",
      "Epoch 1474/2000\n",
      "3556/3556 [==============================] - 1s 272us/step - loss: 2.3180e-04 - val_loss: 4.0830e-04\n",
      "Epoch 1475/2000\n",
      "3556/3556 [==============================] - 1s 270us/step - loss: 2.2978e-04 - val_loss: 4.9762e-04\n",
      "Epoch 1476/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.3394e-04 - val_loss: 3.9543e-04\n",
      "Epoch 1477/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.2842e-04 - val_loss: 5.1824e-04\n",
      "Epoch 1478/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.4290e-04 - val_loss: 4.1452e-04\n",
      "Epoch 1479/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.3398e-04 - val_loss: 4.3935e-04\n",
      "Epoch 1480/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.4006e-04 - val_loss: 3.9864e-04\n",
      "Epoch 1481/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.2561e-04 - val_loss: 4.0564e-04\n",
      "Epoch 1482/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.3108e-04 - val_loss: 4.2402e-04\n",
      "Epoch 1483/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.3138e-04 - val_loss: 4.0259e-04\n",
      "Epoch 1484/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.3336e-04 - val_loss: 4.5212e-04\n",
      "Epoch 1485/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.2784e-04 - val_loss: 4.2501e-04\n",
      "Epoch 1486/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.1354e-04 - val_loss: 4.7592e-04\n",
      "Epoch 1487/2000\n",
      "3556/3556 [==============================] - 1s 269us/step - loss: 2.1657e-04 - val_loss: 5.0206e-04\n",
      "Epoch 1488/2000\n",
      "3556/3556 [==============================] - 1s 267us/step - loss: 2.1955e-04 - val_loss: 4.3834e-04\n",
      "Epoch 1489/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.1245e-04 - val_loss: 4.5314e-04\n",
      "Epoch 1490/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.0971e-04 - val_loss: 4.3162e-04\n",
      "Epoch 1491/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.1776e-04 - val_loss: 4.7545e-04\n",
      "Epoch 1492/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.4137e-04 - val_loss: 4.3989e-04\n",
      "Epoch 1493/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.4135e-04 - val_loss: 4.1044e-04\n",
      "Epoch 1494/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.2111e-04 - val_loss: 4.2472e-04\n",
      "Epoch 1495/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.2328e-04 - val_loss: 4.2779e-04\n",
      "Epoch 1496/2000\n",
      "3556/3556 [==============================] - 1s 267us/step - loss: 2.2779e-04 - val_loss: 4.5794e-04\n",
      "Epoch 1497/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.3438e-04 - val_loss: 4.7054e-04\n",
      "Epoch 1498/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.1797e-04 - val_loss: 4.3001e-04\n",
      "Epoch 1499/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.1434e-04 - val_loss: 4.2383e-04\n",
      "Epoch 1500/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.1664e-04 - val_loss: 4.5437e-04\n",
      "Epoch 1501/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.2338e-04 - val_loss: 4.3955e-04\n",
      "Epoch 1502/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.2007e-04 - val_loss: 4.3364e-04\n",
      "Epoch 1503/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.3273e-04 - val_loss: 4.6354e-04\n",
      "Epoch 1504/2000\n",
      "3556/3556 [==============================] - 1s 268us/step - loss: 2.5335e-04 - val_loss: 4.3064e-04\n",
      "Epoch 1505/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.3628e-04 - val_loss: 4.6112e-04\n",
      "Epoch 1506/2000\n",
      "3556/3556 [==============================] - 1s 270us/step - loss: 2.2098e-04 - val_loss: 4.1552e-04\n",
      "Epoch 1507/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.1011e-04 - val_loss: 4.7362e-04\n",
      "Epoch 1508/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.0935e-04 - val_loss: 4.9855e-04\n",
      "Epoch 1509/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.1121e-04 - val_loss: 4.4981e-04\n",
      "Epoch 1510/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.0901e-04 - val_loss: 6.9982e-04\n",
      "Epoch 1511/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.3211e-04 - val_loss: 5.2031e-04\n",
      "Epoch 1512/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.2617e-04 - val_loss: 4.4618e-04\n",
      "Epoch 1513/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.1649e-04 - val_loss: 4.5509e-04\n",
      "Epoch 1514/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.1025e-04 - val_loss: 4.9257e-04\n",
      "Epoch 1515/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.0335e-04 - val_loss: 4.5613e-04\n",
      "Epoch 1516/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.0714e-04 - val_loss: 4.5575e-04\n",
      "Epoch 1517/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.0577e-04 - val_loss: 4.7150e-04\n",
      "Epoch 1518/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.0580e-04 - val_loss: 5.0220e-04\n",
      "Epoch 1519/2000\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 2.0173e-04 - val_loss: 5.5719e-04\n",
      "Epoch 1520/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.1290e-04 - val_loss: 4.9624e-04\n",
      "Epoch 1521/2000\n",
      "3556/3556 [==============================] - 1s 270us/step - loss: 2.2175e-04 - val_loss: 5.0651e-04\n",
      "Epoch 1522/2000\n",
      "3556/3556 [==============================] - 1s 268us/step - loss: 2.2070e-04 - val_loss: 4.6839e-04\n",
      "Epoch 1523/2000\n",
      "3556/3556 [==============================] - 1s 267us/step - loss: 2.1806e-04 - val_loss: 4.5935e-04\n",
      "Epoch 1524/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.2320e-04 - val_loss: 4.3125e-04\n",
      "Epoch 1525/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.1390e-04 - val_loss: 5.2510e-04\n",
      "Epoch 1526/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.2195e-04 - val_loss: 4.7169e-04\n",
      "Epoch 1527/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.0646e-04 - val_loss: 4.7921e-04\n",
      "Epoch 1528/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.0739e-04 - val_loss: 4.6893e-04\n",
      "Epoch 1529/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.0743e-04 - val_loss: 4.7290e-04\n",
      "Epoch 1530/2000\n",
      "3556/3556 [==============================] - 1s 267us/step - loss: 2.0097e-04 - val_loss: 5.0103e-04\n",
      "Epoch 1531/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.9726e-04 - val_loss: 5.8310e-04\n",
      "Epoch 1532/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.0497e-04 - val_loss: 6.4869e-04\n",
      "Epoch 1533/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.2307e-04 - val_loss: 4.8392e-04\n",
      "Epoch 1534/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.1093e-04 - val_loss: 4.6088e-04\n",
      "Epoch 1535/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.1151e-04 - val_loss: 4.7827e-04\n",
      "Epoch 1536/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.0588e-04 - val_loss: 5.4456e-04\n",
      "Epoch 1537/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.0362e-04 - val_loss: 5.5848e-04\n",
      "Epoch 1538/2000\n",
      "3556/3556 [==============================] - 1s 280us/step - loss: 2.0598e-04 - val_loss: 4.7268e-04\n",
      "Epoch 1539/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.9818e-04 - val_loss: 4.7087e-04\n",
      "Epoch 1540/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.9940e-04 - val_loss: 4.8946e-04\n",
      "Epoch 1541/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 1.9607e-04 - val_loss: 5.0162e-04\n",
      "Epoch 1542/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.9243e-04 - val_loss: 5.2737e-04\n",
      "Epoch 1543/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.1654e-04 - val_loss: 4.8484e-04\n",
      "Epoch 1544/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.1612e-04 - val_loss: 6.0318e-04\n",
      "Epoch 1545/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.1736e-04 - val_loss: 4.9300e-04\n",
      "Epoch 1546/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.0246e-04 - val_loss: 4.9367e-04\n",
      "Epoch 1547/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.0596e-04 - val_loss: 5.2163e-04\n",
      "Epoch 1548/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.1124e-04 - val_loss: 4.8981e-04\n",
      "Epoch 1549/2000\n",
      "3556/3556 [==============================] - 1s 268us/step - loss: 2.1132e-04 - val_loss: 5.2265e-04\n",
      "Epoch 1550/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.3165e-04 - val_loss: 5.0310e-04\n",
      "Epoch 1551/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.2931e-04 - val_loss: 5.2034e-04\n",
      "Epoch 1552/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.1962e-04 - val_loss: 5.3699e-04\n",
      "Epoch 1553/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.3524e-04 - val_loss: 4.4783e-04\n",
      "Epoch 1554/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.3171e-04 - val_loss: 4.8216e-04\n",
      "Epoch 1555/2000\n",
      "3556/3556 [==============================] - 1s 270us/step - loss: 2.1560e-04 - val_loss: 5.1974e-04\n",
      "Epoch 1556/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.1489e-04 - val_loss: 4.4634e-04\n",
      "Epoch 1557/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.0487e-04 - val_loss: 4.3133e-04\n",
      "Epoch 1558/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.9967e-04 - val_loss: 5.0489e-04\n",
      "Epoch 1559/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 1.9981e-04 - val_loss: 5.2136e-04\n",
      "Epoch 1560/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.9555e-04 - val_loss: 5.5304e-04\n",
      "Epoch 1561/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.0369e-04 - val_loss: 5.0105e-04\n",
      "Epoch 1562/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.0752e-04 - val_loss: 5.1110e-04\n",
      "Epoch 1563/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.0889e-04 - val_loss: 5.1337e-04\n",
      "Epoch 1564/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.0177e-04 - val_loss: 5.1040e-04\n",
      "Epoch 1565/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.9417e-04 - val_loss: 5.3000e-04\n",
      "Epoch 1566/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.9757e-04 - val_loss: 5.5967e-04\n",
      "Epoch 1567/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.1525e-04 - val_loss: 4.7875e-04\n",
      "Epoch 1568/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.0367e-04 - val_loss: 5.0078e-04\n",
      "Epoch 1569/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.0406e-04 - val_loss: 6.1321e-04\n",
      "Epoch 1570/2000\n",
      "3556/3556 [==============================] - 1s 269us/step - loss: 2.0377e-04 - val_loss: 5.4483e-04\n",
      "Epoch 1571/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.9802e-04 - val_loss: 4.6485e-04\n",
      "Epoch 1572/2000\n",
      "3556/3556 [==============================] - 1s 270us/step - loss: 2.0725e-04 - val_loss: 5.3724e-04\n",
      "Epoch 1573/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.2204e-04 - val_loss: 4.9561e-04\n",
      "Epoch 1574/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.9578e-04 - val_loss: 5.4051e-04\n",
      "Epoch 1575/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.1006e-04 - val_loss: 5.0127e-04\n",
      "Epoch 1576/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.2046e-04 - val_loss: 6.5863e-04\n",
      "Epoch 1577/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.0579e-04 - val_loss: 4.6692e-04\n",
      "Epoch 1578/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.0511e-04 - val_loss: 5.3886e-04\n",
      "Epoch 1579/2000\n",
      "3556/3556 [==============================] - ETA: 0s - loss: 2.1090e-0 - 1s 266us/step - loss: 2.1374e-04 - val_loss: 4.9963e-04\n",
      "Epoch 1580/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.2176e-04 - val_loss: 5.6520e-04\n",
      "Epoch 1581/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.2039e-04 - val_loss: 6.1630e-04\n",
      "Epoch 1582/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.3247e-04 - val_loss: 4.8959e-04\n",
      "Epoch 1583/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.1388e-04 - val_loss: 4.7425e-04\n",
      "Epoch 1584/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.0943e-04 - val_loss: 5.2377e-04\n",
      "Epoch 1585/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.0077e-04 - val_loss: 5.4223e-04\n",
      "Epoch 1586/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.9844e-04 - val_loss: 5.2014e-04\n",
      "Epoch 1587/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.0518e-04 - val_loss: 5.5326e-04\n",
      "Epoch 1588/2000\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 1.9777e-04 - val_loss: 5.8123e-04\n",
      "Epoch 1589/2000\n",
      "3556/3556 [==============================] - 1s 269us/step - loss: 1.9160e-04 - val_loss: 6.2063e-04\n",
      "Epoch 1590/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.9888e-04 - val_loss: 5.2647e-04\n",
      "Epoch 1591/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.9111e-04 - val_loss: 5.0377e-04\n",
      "Epoch 1592/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 1.9056e-04 - val_loss: 5.3798e-04\n",
      "Epoch 1593/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 1.9309e-04 - val_loss: 5.3257e-04\n",
      "Epoch 1594/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 1.9132e-04 - val_loss: 6.7552e-04\n",
      "Epoch 1595/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.0335e-04 - val_loss: 5.4643e-04\n",
      "Epoch 1596/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.8909e-04 - val_loss: 5.7276e-04\n",
      "Epoch 1597/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.0466e-04 - val_loss: 5.9608e-04\n",
      "Epoch 1598/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.1329e-04 - val_loss: 5.2934e-04\n",
      "Epoch 1599/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.1221e-04 - val_loss: 5.4939e-04\n",
      "Epoch 1600/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.3641e-04 - val_loss: 5.6725e-04\n",
      "Epoch 1601/2000\n",
      "3556/3556 [==============================] - 1s 270us/step - loss: 2.2572e-04 - val_loss: 5.6753e-04\n",
      "Epoch 1602/2000\n",
      "3556/3556 [==============================] - 1s 267us/step - loss: 2.0460e-04 - val_loss: 5.0557e-04\n",
      "Epoch 1603/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.8922e-04 - val_loss: 5.4000e-04\n",
      "Epoch 1604/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 1.8961e-04 - val_loss: 5.8345e-04\n",
      "Epoch 1605/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.8543e-04 - val_loss: 5.9203e-04\n",
      "Epoch 1606/2000\n",
      "3556/3556 [==============================] - 1s 271us/step - loss: 1.9143e-04 - val_loss: 5.8912e-04\n",
      "Epoch 1607/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.9617e-04 - val_loss: 5.9085e-04\n",
      "Epoch 1608/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.0554e-04 - val_loss: 6.8471e-04\n",
      "Epoch 1609/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.9911e-04 - val_loss: 5.1976e-04\n",
      "Epoch 1610/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 1.9447e-04 - val_loss: 5.5638e-04\n",
      "Epoch 1611/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.8231e-04 - val_loss: 5.5866e-04\n",
      "Epoch 1612/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.8571e-04 - val_loss: 6.1210e-04\n",
      "Epoch 1613/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.9578e-04 - val_loss: 6.6124e-04\n",
      "Epoch 1614/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.0673e-04 - val_loss: 5.6606e-04\n",
      "Epoch 1615/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.3219e-04 - val_loss: 6.2124e-04\n",
      "Epoch 1616/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.0865e-04 - val_loss: 6.0495e-04\n",
      "Epoch 1617/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.0506e-04 - val_loss: 5.5677e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1618/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.9752e-04 - val_loss: 5.1405e-04\n",
      "Epoch 1619/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.0061e-04 - val_loss: 6.1706e-04\n",
      "Epoch 1620/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.1248e-04 - val_loss: 5.5817e-04\n",
      "Epoch 1621/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.0986e-04 - val_loss: 5.4108e-04\n",
      "Epoch 1622/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 1.9587e-04 - val_loss: 5.1945e-04\n",
      "Epoch 1623/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 1.9180e-04 - val_loss: 5.2594e-04\n",
      "Epoch 1624/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.9282e-04 - val_loss: 6.0531e-04\n",
      "Epoch 1625/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.0813e-04 - val_loss: 7.1210e-04\n",
      "Epoch 1626/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.0740e-04 - val_loss: 5.4523e-04\n",
      "Epoch 1627/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.9304e-04 - val_loss: 5.5685e-04\n",
      "Epoch 1628/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.8952e-04 - val_loss: 5.9558e-04\n",
      "Epoch 1629/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.9884e-04 - val_loss: 5.7929e-04\n",
      "Epoch 1630/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.9115e-04 - val_loss: 7.1567e-04\n",
      "Epoch 1631/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 1.9530e-04 - val_loss: 7.2065e-04\n",
      "Epoch 1632/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 1.9435e-04 - val_loss: 7.0789e-04\n",
      "Epoch 1633/2000\n",
      "3556/3556 [==============================] - 1s 270us/step - loss: 1.9262e-04 - val_loss: 7.3912e-04\n",
      "Epoch 1634/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.8438e-04 - val_loss: 6.0037e-04\n",
      "Epoch 1635/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 1.8301e-04 - val_loss: 6.0046e-04\n",
      "Epoch 1636/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.9138e-04 - val_loss: 6.3759e-04\n",
      "Epoch 1637/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.8714e-04 - val_loss: 6.1926e-04\n",
      "Epoch 1638/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.8157e-04 - val_loss: 5.8517e-04\n",
      "Epoch 1639/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.8441e-04 - val_loss: 5.8177e-04\n",
      "Epoch 1640/2000\n",
      "3556/3556 [==============================] - 1s 270us/step - loss: 1.8426e-04 - val_loss: 6.4116e-04\n",
      "Epoch 1641/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.8681e-04 - val_loss: 5.6075e-04\n",
      "Epoch 1642/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 1.8785e-04 - val_loss: 5.6443e-04\n",
      "Epoch 1643/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.8307e-04 - val_loss: 6.7112e-04\n",
      "Epoch 1644/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 1.8831e-04 - val_loss: 6.1775e-04\n",
      "Epoch 1645/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.9112e-04 - val_loss: 5.8526e-04\n",
      "Epoch 1646/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 1.8348e-04 - val_loss: 6.1712e-04\n",
      "Epoch 1647/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.8493e-04 - val_loss: 6.2354e-04\n",
      "Epoch 1648/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.7628e-04 - val_loss: 6.7941e-04\n",
      "Epoch 1649/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.8252e-04 - val_loss: 6.4348e-04\n",
      "Epoch 1650/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 1.8755e-04 - val_loss: 5.9594e-04\n",
      "Epoch 1651/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.0152e-04 - val_loss: 6.2556e-04\n",
      "Epoch 1652/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.0176e-04 - val_loss: 6.6926e-04\n",
      "Epoch 1653/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.9861e-04 - val_loss: 6.1815e-04\n",
      "Epoch 1654/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 1.9883e-04 - val_loss: 7.2618e-04\n",
      "Epoch 1655/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 2.0340e-04 - val_loss: 5.9101e-04\n",
      "Epoch 1656/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.0526e-04 - val_loss: 6.2628e-04\n",
      "Epoch 1657/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.0072e-04 - val_loss: 6.0029e-04\n",
      "Epoch 1658/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.8875e-04 - val_loss: 5.8585e-04\n",
      "Epoch 1659/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 1.9263e-04 - val_loss: 5.8306e-04\n",
      "Epoch 1660/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.0795e-04 - val_loss: 6.0046e-04\n",
      "Epoch 1661/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.1681e-04 - val_loss: 7.0693e-04\n",
      "Epoch 1662/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.9177e-04 - val_loss: 7.4315e-04\n",
      "Epoch 1663/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.8168e-04 - val_loss: 6.0206e-04\n",
      "Epoch 1664/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.7912e-04 - val_loss: 6.9585e-04\n",
      "Epoch 1665/2000\n",
      "3556/3556 [==============================] - 1s 272us/step - loss: 1.8153e-04 - val_loss: 5.4349e-04\n",
      "Epoch 1666/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 1.8350e-04 - val_loss: 6.8955e-04\n",
      "Epoch 1667/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 1.7910e-04 - val_loss: 7.0687e-04\n",
      "Epoch 1668/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 1.8134e-04 - val_loss: 6.7359e-04\n",
      "Epoch 1669/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 1.7669e-04 - val_loss: 7.5437e-04\n",
      "Epoch 1670/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.7477e-04 - val_loss: 6.7230e-04\n",
      "Epoch 1671/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.7608e-04 - val_loss: 7.1279e-04\n",
      "Epoch 1672/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.7622e-04 - val_loss: 6.5905e-04\n",
      "Epoch 1673/2000\n",
      "3556/3556 [==============================] - 1s 268us/step - loss: 1.7431e-04 - val_loss: 7.1298e-04\n",
      "Epoch 1674/2000\n",
      "3556/3556 [==============================] - 1s 268us/step - loss: 1.7901e-04 - val_loss: 6.7611e-04\n",
      "Epoch 1675/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.7276e-04 - val_loss: 7.0344e-04\n",
      "Epoch 1676/2000\n",
      "3556/3556 [==============================] - 1s 268us/step - loss: 1.8277e-04 - val_loss: 7.1926e-04\n",
      "Epoch 1677/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.7815e-04 - val_loss: 7.8876e-04\n",
      "Epoch 1678/2000\n",
      "3556/3556 [==============================] - 1s 269us/step - loss: 1.8139e-04 - val_loss: 7.1967e-04\n",
      "Epoch 1679/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 1.9125e-04 - val_loss: 6.1815e-04\n",
      "Epoch 1680/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.9030e-04 - val_loss: 5.5201e-04\n",
      "Epoch 1681/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 1.9140e-04 - val_loss: 6.6138e-04\n",
      "Epoch 1682/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.7849e-04 - val_loss: 6.5023e-04\n",
      "Epoch 1683/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.7442e-04 - val_loss: 6.7102e-04\n",
      "Epoch 1684/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.7184e-04 - val_loss: 6.8414e-04\n",
      "Epoch 1685/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.7092e-04 - val_loss: 7.4525e-04\n",
      "Epoch 1686/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 1.8049e-04 - val_loss: 6.8812e-04\n",
      "Epoch 1687/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.7280e-04 - val_loss: 6.3336e-04\n",
      "Epoch 1688/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3556/3556 [==============================] - 1s 263us/step - loss: 1.7011e-04 - val_loss: 7.5658e-04\n",
      "Epoch 1689/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.8223e-04 - val_loss: 6.1977e-04\n",
      "Epoch 1690/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 1.8527e-04 - val_loss: 6.8868e-04\n",
      "Epoch 1691/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 1.8359e-04 - val_loss: 8.3189e-04\n",
      "Epoch 1692/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.7676e-04 - val_loss: 7.5215e-04\n",
      "Epoch 1693/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 1.7850e-04 - val_loss: 7.3985e-04\n",
      "Epoch 1694/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 1.7913e-04 - val_loss: 6.7593e-04\n",
      "Epoch 1695/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 1.8537e-04 - val_loss: 7.1782e-04\n",
      "Epoch 1696/2000\n",
      "3556/3556 [==============================] - 1s 268us/step - loss: 1.8796e-04 - val_loss: 6.6330e-04\n",
      "Epoch 1697/2000\n",
      "3556/3556 [==============================] - 1s 268us/step - loss: 1.9075e-04 - val_loss: 7.6261e-04\n",
      "Epoch 1698/2000\n",
      "3556/3556 [==============================] - 1s 267us/step - loss: 1.9256e-04 - val_loss: 6.5108e-04\n",
      "Epoch 1699/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 2.1019e-04 - val_loss: 7.2659e-04\n",
      "Epoch 1700/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.8720e-04 - val_loss: 7.0051e-04\n",
      "Epoch 1701/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.8642e-04 - val_loss: 7.8778e-04\n",
      "Epoch 1702/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.9404e-04 - val_loss: 6.7146e-04\n",
      "Epoch 1703/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.7556e-04 - val_loss: 6.6537e-04\n",
      "Epoch 1704/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 1.6880e-04 - val_loss: 7.2324e-04\n",
      "Epoch 1705/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.7347e-04 - val_loss: 7.4170e-04\n",
      "Epoch 1706/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.7579e-04 - val_loss: 6.9609e-04\n",
      "Epoch 1707/2000\n",
      "3556/3556 [==============================] - 1s 269us/step - loss: 1.7796e-04 - val_loss: 6.7530e-04\n",
      "Epoch 1708/2000\n",
      "3556/3556 [==============================] - 1s 268us/step - loss: 1.6827e-04 - val_loss: 7.2135e-04\n",
      "Epoch 1709/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.6690e-04 - val_loss: 7.0715e-04\n",
      "Epoch 1710/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 1.6027e-04 - val_loss: 7.4768e-04\n",
      "Epoch 1711/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.7262e-04 - val_loss: 7.8067e-04\n",
      "Epoch 1712/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.7034e-04 - val_loss: 6.8703e-04\n",
      "Epoch 1713/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.6750e-04 - val_loss: 7.8396e-04\n",
      "Epoch 1714/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 1.7549e-04 - val_loss: 7.1055e-04\n",
      "Epoch 1715/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.7094e-04 - val_loss: 7.2738e-04\n",
      "Epoch 1716/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.7672e-04 - val_loss: 7.3978e-04\n",
      "Epoch 1717/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 1.8954e-04 - val_loss: 7.4791e-04\n",
      "Epoch 1718/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 1.7689e-04 - val_loss: 6.9797e-04\n",
      "Epoch 1719/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 1.7046e-04 - val_loss: 6.9723e-04\n",
      "Epoch 1720/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 1.7181e-04 - val_loss: 6.8458e-04\n",
      "Epoch 1721/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.7157e-04 - val_loss: 8.1255e-04\n",
      "Epoch 1722/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.7051e-04 - val_loss: 7.1733e-04\n",
      "Epoch 1723/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.8074e-04 - val_loss: 7.2273e-04\n",
      "Epoch 1724/2000\n",
      "3556/3556 [==============================] - 1s 269us/step - loss: 1.7907e-04 - val_loss: 7.4475e-04\n",
      "Epoch 1725/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 1.8470e-04 - val_loss: 7.8315e-04\n",
      "Epoch 1726/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.7990e-04 - val_loss: 7.3966e-04\n",
      "Epoch 1727/2000\n",
      "3556/3556 [==============================] - 1s 267us/step - loss: 1.6682e-04 - val_loss: 7.7459e-04\n",
      "Epoch 1728/2000\n",
      "3556/3556 [==============================] - 1s 271us/step - loss: 1.6595e-04 - val_loss: 7.3445e-04\n",
      "Epoch 1729/2000\n",
      "3556/3556 [==============================] - 1s 267us/step - loss: 1.6703e-04 - val_loss: 7.6279e-04\n",
      "Epoch 1730/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.7339e-04 - val_loss: 6.9809e-04\n",
      "Epoch 1731/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.7795e-04 - val_loss: 7.4553e-04\n",
      "Epoch 1732/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 1.8663e-04 - val_loss: 7.9292e-04\n",
      "Epoch 1733/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.7467e-04 - val_loss: 8.7009e-04\n",
      "Epoch 1734/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.7455e-04 - val_loss: 6.8796e-04\n",
      "Epoch 1735/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.7289e-04 - val_loss: 7.6716e-04\n",
      "Epoch 1736/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.8933e-04 - val_loss: 7.7350e-04\n",
      "Epoch 1737/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.1220e-04 - val_loss: 6.5692e-04\n",
      "Epoch 1738/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.1201e-04 - val_loss: 7.2349e-04\n",
      "Epoch 1739/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 2.2311e-04 - val_loss: 6.5236e-04\n",
      "Epoch 1740/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 1.9209e-04 - val_loss: 7.5190e-04\n",
      "Epoch 1741/2000\n",
      "3556/3556 [==============================] - 1s 270us/step - loss: 1.8320e-04 - val_loss: 7.9397e-04\n",
      "Epoch 1742/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.7904e-04 - val_loss: 7.7115e-04\n",
      "Epoch 1743/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.6838e-04 - val_loss: 7.1061e-04\n",
      "Epoch 1744/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.6474e-04 - val_loss: 7.5190e-04\n",
      "Epoch 1745/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.6611e-04 - val_loss: 8.2896e-04\n",
      "Epoch 1746/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 1.6059e-04 - val_loss: 7.5848e-04\n",
      "Epoch 1747/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.5686e-04 - val_loss: 7.6218e-04\n",
      "Epoch 1748/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.5666e-04 - val_loss: 7.7785e-04\n",
      "Epoch 1749/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.6372e-04 - val_loss: 7.8665e-04\n",
      "Epoch 1750/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.6605e-04 - val_loss: 7.2737e-04\n",
      "Epoch 1751/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 1.7893e-04 - val_loss: 7.3391e-04\n",
      "Epoch 1752/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.7313e-04 - val_loss: 7.5383e-04\n",
      "Epoch 1753/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.7046e-04 - val_loss: 6.9357e-04\n",
      "Epoch 1754/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 1.7384e-04 - val_loss: 7.9635e-04\n",
      "Epoch 1755/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.6363e-04 - val_loss: 7.9053e-04\n",
      "Epoch 1756/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.7215e-04 - val_loss: 7.3234e-04\n",
      "Epoch 1757/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.8112e-04 - val_loss: 7.9971e-04\n",
      "Epoch 1758/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3556/3556 [==============================] - 1s 271us/step - loss: 1.6485e-04 - val_loss: 7.4761e-04\n",
      "Epoch 1759/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 1.6206e-04 - val_loss: 7.4887e-04\n",
      "Epoch 1760/2000\n",
      "3556/3556 [==============================] - 1s 270us/step - loss: 1.6159e-04 - val_loss: 7.7176e-04\n",
      "Epoch 1761/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.5636e-04 - val_loss: 7.5335e-04\n",
      "Epoch 1762/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.5944e-04 - val_loss: 8.8688e-04\n",
      "Epoch 1763/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 1.7035e-04 - val_loss: 7.7042e-04\n",
      "Epoch 1764/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.7227e-04 - val_loss: 6.9868e-04\n",
      "Epoch 1765/2000\n",
      "3556/3556 [==============================] - 1s 267us/step - loss: 1.6450e-04 - val_loss: 8.0506e-04\n",
      "Epoch 1766/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 1.9433e-04 - val_loss: 7.8029e-04\n",
      "Epoch 1767/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.8453e-04 - val_loss: 7.2190e-04\n",
      "Epoch 1768/2000\n",
      "3556/3556 [==============================] - 1s 277us/step - loss: 1.7053e-04 - val_loss: 7.6541e-04\n",
      "Epoch 1769/2000\n",
      "3556/3556 [==============================] - 1s 267us/step - loss: 1.7162e-04 - val_loss: 6.8225e-04\n",
      "Epoch 1770/2000\n",
      "3556/3556 [==============================] - 1s 273us/step - loss: 1.6565e-04 - val_loss: 8.8154e-04\n",
      "Epoch 1771/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 1.7282e-04 - val_loss: 7.3352e-04\n",
      "Epoch 1772/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 1.7819e-04 - val_loss: 7.9609e-04\n",
      "Epoch 1773/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 1.7693e-04 - val_loss: 7.0841e-04\n",
      "Epoch 1774/2000\n",
      "3556/3556 [==============================] - 1s 267us/step - loss: 1.6777e-04 - val_loss: 7.6245e-04\n",
      "Epoch 1775/2000\n",
      "3556/3556 [==============================] - 1s 272us/step - loss: 1.7387e-04 - val_loss: 8.5688e-04\n",
      "Epoch 1776/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.7854e-04 - val_loss: 6.9337e-04\n",
      "Epoch 1777/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.6869e-04 - val_loss: 8.3765e-04\n",
      "Epoch 1778/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 1.6056e-04 - val_loss: 7.7911e-04\n",
      "Epoch 1779/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.6227e-04 - val_loss: 8.0828e-04\n",
      "Epoch 1780/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.6568e-04 - val_loss: 7.3981e-04\n",
      "Epoch 1781/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 1.5332e-04 - val_loss: 8.2270e-04\n",
      "Epoch 1782/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 1.5781e-04 - val_loss: 7.8971e-04\n",
      "Epoch 1783/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 1.5917e-04 - val_loss: 8.1083e-04\n",
      "Epoch 1784/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.6231e-04 - val_loss: 8.2456e-04\n",
      "Epoch 1785/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.6071e-04 - val_loss: 8.5552e-04\n",
      "Epoch 1786/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 1.6609e-04 - val_loss: 8.4501e-04\n",
      "Epoch 1787/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.5968e-04 - val_loss: 8.6403e-04\n",
      "Epoch 1788/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.6423e-04 - val_loss: 8.9224e-04\n",
      "Epoch 1789/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.8892e-04 - val_loss: 8.6430e-04\n",
      "Epoch 1790/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 1.8306e-04 - val_loss: 7.2578e-04\n",
      "Epoch 1791/2000\n",
      "3556/3556 [==============================] - 1s 268us/step - loss: 1.8796e-04 - val_loss: 8.9939e-04\n",
      "Epoch 1792/2000\n",
      "3556/3556 [==============================] - 1s 274us/step - loss: 1.8103e-04 - val_loss: 7.2292e-04\n",
      "Epoch 1793/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.8197e-04 - val_loss: 7.5370e-04\n",
      "Epoch 1794/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.7265e-04 - val_loss: 8.2241e-04\n",
      "Epoch 1795/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 1.6667e-04 - val_loss: 8.8401e-04\n",
      "Epoch 1796/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.6370e-04 - val_loss: 9.2268e-04\n",
      "Epoch 1797/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 1.6341e-04 - val_loss: 7.8924e-04\n",
      "Epoch 1798/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.6337e-04 - val_loss: 8.0554e-04\n",
      "Epoch 1799/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 1.6600e-04 - val_loss: 7.4843e-04\n",
      "Epoch 1800/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.6821e-04 - val_loss: 7.1498e-04\n",
      "Epoch 1801/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 1.7095e-04 - val_loss: 7.3388e-04\n",
      "Epoch 1802/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.6966e-04 - val_loss: 8.2373e-04\n",
      "Epoch 1803/2000\n",
      "3556/3556 [==============================] - 1s 271us/step - loss: 1.6611e-04 - val_loss: 6.9052e-04\n",
      "Epoch 1804/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.6745e-04 - val_loss: 8.3037e-04\n",
      "Epoch 1805/2000\n",
      "3556/3556 [==============================] - 1s 267us/step - loss: 1.5607e-04 - val_loss: 7.4273e-04\n",
      "Epoch 1806/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.5705e-04 - val_loss: 8.0088e-04\n",
      "Epoch 1807/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.6164e-04 - val_loss: 9.5419e-04\n",
      "Epoch 1808/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 1.5884e-04 - val_loss: 7.8959e-04\n",
      "Epoch 1809/2000\n",
      "3556/3556 [==============================] - 1s 268us/step - loss: 1.5880e-04 - val_loss: 8.1385e-04\n",
      "Epoch 1810/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.6734e-04 - val_loss: 6.9310e-04\n",
      "Epoch 1811/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.5081e-04 - val_loss: 8.5533e-04\n",
      "Epoch 1812/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.4372e-04 - val_loss: 7.7276e-04\n",
      "Epoch 1813/2000\n",
      "3556/3556 [==============================] - 1s 267us/step - loss: 1.4775e-04 - val_loss: 8.6042e-04\n",
      "Epoch 1814/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.4917e-04 - val_loss: 8.0052e-04\n",
      "Epoch 1815/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.5235e-04 - val_loss: 8.6637e-04\n",
      "Epoch 1816/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.5277e-04 - val_loss: 8.8800e-04\n",
      "Epoch 1817/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.6270e-04 - val_loss: 7.6408e-04\n",
      "Epoch 1818/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.6561e-04 - val_loss: 7.9561e-04\n",
      "Epoch 1819/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 1.6358e-04 - val_loss: 7.6502e-04\n",
      "Epoch 1820/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.6018e-04 - val_loss: 8.1832e-04\n",
      "Epoch 1821/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.5997e-04 - val_loss: 7.2628e-04\n",
      "Epoch 1822/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.5751e-04 - val_loss: 8.6207e-04\n",
      "Epoch 1823/2000\n",
      "3556/3556 [==============================] - 1s 270us/step - loss: 1.6152e-04 - val_loss: 8.3320e-04\n",
      "Epoch 1824/2000\n",
      "3556/3556 [==============================] - 1s 267us/step - loss: 1.6245e-04 - val_loss: 8.1416e-04\n",
      "Epoch 1825/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 1.5602e-04 - val_loss: 8.1497e-04\n",
      "Epoch 1826/2000\n",
      "3556/3556 [==============================] - 1s 267us/step - loss: 1.4967e-04 - val_loss: 8.2385e-04\n",
      "Epoch 1827/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.4990e-04 - val_loss: 8.4275e-04\n",
      "Epoch 1828/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3556/3556 [==============================] - 1s 266us/step - loss: 1.4733e-04 - val_loss: 8.5817e-04\n",
      "Epoch 1829/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.5443e-04 - val_loss: 7.6506e-04\n",
      "Epoch 1830/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.5891e-04 - val_loss: 9.0283e-04\n",
      "Epoch 1831/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.6310e-04 - val_loss: 7.7762e-04\n",
      "Epoch 1832/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.6429e-04 - val_loss: 8.9606e-04\n",
      "Epoch 1833/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.8567e-04 - val_loss: 7.3451e-04\n",
      "Epoch 1834/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 2.0032e-04 - val_loss: 9.7566e-04\n",
      "Epoch 1835/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.9171e-04 - val_loss: 8.2583e-04\n",
      "Epoch 1836/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.7160e-04 - val_loss: 7.2948e-04\n",
      "Epoch 1837/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 1.5844e-04 - val_loss: 7.7458e-04\n",
      "Epoch 1838/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 1.5514e-04 - val_loss: 7.8922e-04\n",
      "Epoch 1839/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.5395e-04 - val_loss: 8.8522e-04\n",
      "Epoch 1840/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.5529e-04 - val_loss: 8.9132e-04\n",
      "Epoch 1841/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 1.5069e-04 - val_loss: 9.0162e-04\n",
      "Epoch 1842/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 1.5482e-04 - val_loss: 7.5299e-04\n",
      "Epoch 1843/2000\n",
      "3556/3556 [==============================] - 1s 270us/step - loss: 1.5807e-04 - val_loss: 7.5520e-04\n",
      "Epoch 1844/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 1.5868e-04 - val_loss: 9.3271e-04\n",
      "Epoch 1845/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.4463e-04 - val_loss: 8.0142e-04\n",
      "Epoch 1846/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 1.4915e-04 - val_loss: 8.0267e-04\n",
      "Epoch 1847/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.4864e-04 - val_loss: 8.9829e-04\n",
      "Epoch 1848/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 1.4892e-04 - val_loss: 8.4080e-04\n",
      "Epoch 1849/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.4815e-04 - val_loss: 9.5530e-04\n",
      "Epoch 1850/2000\n",
      "3556/3556 [==============================] - 1s 268us/step - loss: 1.4392e-04 - val_loss: 8.5364e-04\n",
      "Epoch 1851/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.5150e-04 - val_loss: 8.3548e-04\n",
      "Epoch 1852/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 1.5027e-04 - val_loss: 8.8145e-04\n",
      "Epoch 1853/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.4386e-04 - val_loss: 8.5275e-04\n",
      "Epoch 1854/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 1.4223e-04 - val_loss: 0.0010\n",
      "Epoch 1855/2000\n",
      "3556/3556 [==============================] - 1s 274us/step - loss: 1.4527e-04 - val_loss: 8.7870e-04\n",
      "Epoch 1856/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 1.4807e-04 - val_loss: 9.9177e-04\n",
      "Epoch 1857/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.7110e-04 - val_loss: 0.0010\n",
      "Epoch 1858/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 1.8603e-04 - val_loss: 9.2843e-04\n",
      "Epoch 1859/2000\n",
      "3556/3556 [==============================] - 1s 268us/step - loss: 1.7615e-04 - val_loss: 8.2896e-04\n",
      "Epoch 1860/2000\n",
      "3556/3556 [==============================] - 1s 267us/step - loss: 1.5513e-04 - val_loss: 9.3795e-04\n",
      "Epoch 1861/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.5238e-04 - val_loss: 0.0011\n",
      "Epoch 1862/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.5875e-04 - val_loss: 8.7345e-04\n",
      "Epoch 1863/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 1.7371e-04 - val_loss: 0.0010\n",
      "Epoch 1864/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 1.7562e-04 - val_loss: 8.2783e-04\n",
      "Epoch 1865/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 1.6998e-04 - val_loss: 9.1972e-04\n",
      "Epoch 1866/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.5896e-04 - val_loss: 7.3537e-04\n",
      "Epoch 1867/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 1.5236e-04 - val_loss: 7.8485e-04\n",
      "Epoch 1868/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.3975e-04 - val_loss: 9.3395e-04\n",
      "Epoch 1869/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 1.5439e-04 - val_loss: 8.2243e-04\n",
      "Epoch 1870/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 1.5761e-04 - val_loss: 9.9881e-04\n",
      "Epoch 1871/2000\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 1.6084e-04 - val_loss: 8.0875e-04\n",
      "Epoch 1872/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.5351e-04 - val_loss: 8.6349e-04\n",
      "Epoch 1873/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.5390e-04 - val_loss: 8.3773e-04\n",
      "Epoch 1874/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.5059e-04 - val_loss: 9.0444e-04\n",
      "Epoch 1875/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.6069e-04 - val_loss: 8.5686e-04\n",
      "Epoch 1876/2000\n",
      "3556/3556 [==============================] - 1s 268us/step - loss: 1.4095e-04 - val_loss: 8.8650e-04\n",
      "Epoch 1877/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.4393e-04 - val_loss: 8.7880e-04\n",
      "Epoch 1878/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.4207e-04 - val_loss: 9.5694e-04\n",
      "Epoch 1879/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.4147e-04 - val_loss: 9.4746e-04\n",
      "Epoch 1880/2000\n",
      "3556/3556 [==============================] - 1s 267us/step - loss: 1.4529e-04 - val_loss: 9.4027e-04\n",
      "Epoch 1881/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.4437e-04 - val_loss: 0.0010\n",
      "Epoch 1882/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 1.4101e-04 - val_loss: 8.8684e-04\n",
      "Epoch 1883/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.4626e-04 - val_loss: 8.6935e-04\n",
      "Epoch 1884/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.4169e-04 - val_loss: 8.9966e-04\n",
      "Epoch 1885/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.3965e-04 - val_loss: 8.7180e-04\n",
      "Epoch 1886/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.3560e-04 - val_loss: 9.9626e-04\n",
      "Epoch 1887/2000\n",
      "3556/3556 [==============================] - 1s 269us/step - loss: 1.4629e-04 - val_loss: 8.8473e-04\n",
      "Epoch 1888/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.4351e-04 - val_loss: 9.7880e-04\n",
      "Epoch 1889/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.4892e-04 - val_loss: 8.6312e-04\n",
      "Epoch 1890/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.4597e-04 - val_loss: 8.9061e-04\n",
      "Epoch 1891/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.6428e-04 - val_loss: 9.1729e-04\n",
      "Epoch 1892/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.5540e-04 - val_loss: 9.0413e-04\n",
      "Epoch 1893/2000\n",
      "3556/3556 [==============================] - 1s 271us/step - loss: 1.4803e-04 - val_loss: 9.0130e-04\n",
      "Epoch 1894/2000\n",
      "3556/3556 [==============================] - ETA: 0s - loss: 1.5159e-0 - 1s 266us/step - loss: 1.5157e-04 - val_loss: 9.5593e-04\n",
      "Epoch 1895/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 1.4897e-04 - val_loss: 9.5849e-04\n",
      "Epoch 1896/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.5559e-04 - val_loss: 0.0010\n",
      "Epoch 1897/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.4532e-04 - val_loss: 0.0010\n",
      "Epoch 1898/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.4530e-04 - val_loss: 9.6287e-04\n",
      "Epoch 1899/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.4260e-04 - val_loss: 9.1423e-04\n",
      "Epoch 1900/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.3371e-04 - val_loss: 8.9044e-04\n",
      "Epoch 1901/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.2988e-04 - val_loss: 0.0010\n",
      "Epoch 1902/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.3777e-04 - val_loss: 9.3349e-04\n",
      "Epoch 1903/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 1.3298e-04 - val_loss: 0.0010\n",
      "Epoch 1904/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 1.4109e-04 - val_loss: 8.5657e-04\n",
      "Epoch 1905/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.4987e-04 - val_loss: 0.0011\n",
      "Epoch 1906/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 1.6027e-04 - val_loss: 9.4980e-04\n",
      "Epoch 1907/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.5680e-04 - val_loss: 8.8820e-04\n",
      "Epoch 1908/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.5402e-04 - val_loss: 9.1968e-04\n",
      "Epoch 1909/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.5104e-04 - val_loss: 8.8774e-04\n",
      "Epoch 1910/2000\n",
      "3556/3556 [==============================] - 1s 270us/step - loss: 1.5574e-04 - val_loss: 9.8922e-04\n",
      "Epoch 1911/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.4176e-04 - val_loss: 9.0845e-04\n",
      "Epoch 1912/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.4666e-04 - val_loss: 8.9069e-04\n",
      "Epoch 1913/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.4315e-04 - val_loss: 9.1293e-04\n",
      "Epoch 1914/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.4404e-04 - val_loss: 0.0010\n",
      "Epoch 1915/2000\n",
      "3556/3556 [==============================] - 1s 267us/step - loss: 1.4386e-04 - val_loss: 9.4713e-04\n",
      "Epoch 1916/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 1.4121e-04 - val_loss: 9.3949e-04\n",
      "Epoch 1917/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 1.4772e-04 - val_loss: 9.0287e-04\n",
      "Epoch 1918/2000\n",
      "3556/3556 [==============================] - 1s 270us/step - loss: 1.4639e-04 - val_loss: 8.5414e-04\n",
      "Epoch 1919/2000\n",
      "3556/3556 [==============================] - 1s 269us/step - loss: 1.5111e-04 - val_loss: 9.7658e-04\n",
      "Epoch 1920/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.5124e-04 - val_loss: 9.7522e-04\n",
      "Epoch 1921/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 1.4611e-04 - val_loss: 8.7836e-04\n",
      "Epoch 1922/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.3860e-04 - val_loss: 9.0225e-04\n",
      "Epoch 1923/2000\n",
      "3556/3556 [==============================] - 1s 267us/step - loss: 1.3632e-04 - val_loss: 8.5250e-04\n",
      "Epoch 1924/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.3724e-04 - val_loss: 9.4810e-04\n",
      "Epoch 1925/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 1.4299e-04 - val_loss: 9.3486e-04\n",
      "Epoch 1926/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.4084e-04 - val_loss: 8.2527e-04\n",
      "Epoch 1927/2000\n",
      "3556/3556 [==============================] - 1s 273us/step - loss: 1.3281e-04 - val_loss: 8.6984e-04\n",
      "Epoch 1928/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.3409e-04 - val_loss: 9.1668e-04\n",
      "Epoch 1929/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.4561e-04 - val_loss: 0.0010\n",
      "Epoch 1930/2000\n",
      "3556/3556 [==============================] - 1s 268us/step - loss: 1.3987e-04 - val_loss: 9.1651e-04\n",
      "Epoch 1931/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 1.3653e-04 - val_loss: 9.1268e-04\n",
      "Epoch 1932/2000\n",
      "3556/3556 [==============================] - 1s 268us/step - loss: 1.3224e-04 - val_loss: 0.0010\n",
      "Epoch 1933/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.3465e-04 - val_loss: 9.3421e-04\n",
      "Epoch 1934/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.4635e-04 - val_loss: 9.6216e-04\n",
      "Epoch 1935/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.4157e-04 - val_loss: 9.6852e-04\n",
      "Epoch 1936/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.3651e-04 - val_loss: 9.9994e-04\n",
      "Epoch 1937/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.3178e-04 - val_loss: 9.4352e-04\n",
      "Epoch 1938/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.2858e-04 - val_loss: 9.5342e-04\n",
      "Epoch 1939/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 1.2850e-04 - val_loss: 9.5589e-04\n",
      "Epoch 1940/2000\n",
      "3556/3556 [==============================] - ETA: 0s - loss: 1.3319e-0 - 1s 266us/step - loss: 1.3205e-04 - val_loss: 9.0271e-04\n",
      "Epoch 1941/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.3886e-04 - val_loss: 9.8901e-04\n",
      "Epoch 1942/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 1.4041e-04 - val_loss: 9.8318e-04\n",
      "Epoch 1943/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.4029e-04 - val_loss: 9.6569e-04\n",
      "Epoch 1944/2000\n",
      "3556/3556 [==============================] - 1s 271us/step - loss: 1.4113e-04 - val_loss: 9.9533e-04\n",
      "Epoch 1945/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.3092e-04 - val_loss: 9.0690e-04\n",
      "Epoch 1946/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 1.3019e-04 - val_loss: 0.0011\n",
      "Epoch 1947/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.3305e-04 - val_loss: 9.0972e-04\n",
      "Epoch 1948/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.2910e-04 - val_loss: 0.0010\n",
      "Epoch 1949/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 1.3087e-04 - val_loss: 9.7914e-04\n",
      "Epoch 1950/2000\n",
      "3556/3556 [==============================] - 1s 270us/step - loss: 1.2673e-04 - val_loss: 9.6860e-04\n",
      "Epoch 1951/2000\n",
      "3556/3556 [==============================] - 1s 262us/step - loss: 1.3476e-04 - val_loss: 9.7204e-04\n",
      "Epoch 1952/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.4741e-04 - val_loss: 0.0010\n",
      "Epoch 1953/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.5321e-04 - val_loss: 9.3674e-04\n",
      "Epoch 1954/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.5249e-04 - val_loss: 8.2443e-04\n",
      "Epoch 1955/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 1.5414e-04 - val_loss: 9.8044e-04\n",
      "Epoch 1956/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.4798e-04 - val_loss: 8.7823e-04\n",
      "Epoch 1957/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.4664e-04 - val_loss: 0.0011\n",
      "Epoch 1958/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.5039e-04 - val_loss: 9.0291e-04\n",
      "Epoch 1959/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.4262e-04 - val_loss: 9.4510e-04\n",
      "Epoch 1960/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.4597e-04 - val_loss: 9.2560e-04\n",
      "Epoch 1961/2000\n",
      "3556/3556 [==============================] - 1s 271us/step - loss: 1.5592e-04 - val_loss: 0.0011\n",
      "Epoch 1962/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.4814e-04 - val_loss: 8.6911e-04\n",
      "Epoch 1963/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.3632e-04 - val_loss: 9.4176e-04\n",
      "Epoch 1964/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.3204e-04 - val_loss: 9.9337e-04\n",
      "Epoch 1965/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.3011e-04 - val_loss: 9.9741e-04\n",
      "Epoch 1966/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.3449e-04 - val_loss: 0.0010\n",
      "Epoch 1967/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.4205e-04 - val_loss: 9.8511e-04\n",
      "Epoch 1968/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3556/3556 [==============================] - 1s 266us/step - loss: 1.3126e-04 - val_loss: 9.8250e-04\n",
      "Epoch 1969/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.3716e-04 - val_loss: 9.7745e-04\n",
      "Epoch 1970/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.3764e-04 - val_loss: 0.0011\n",
      "Epoch 1971/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.4477e-04 - val_loss: 0.0010\n",
      "Epoch 1972/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.3592e-04 - val_loss: 9.2087e-04\n",
      "Epoch 1973/2000\n",
      "3556/3556 [==============================] - 1s 269us/step - loss: 1.2381e-04 - val_loss: 0.0010\n",
      "Epoch 1974/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.2583e-04 - val_loss: 0.0010\n",
      "Epoch 1975/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 1.2858e-04 - val_loss: 0.0010\n",
      "Epoch 1976/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.2873e-04 - val_loss: 0.0010\n",
      "Epoch 1977/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 1.4075e-04 - val_loss: 9.7609e-04\n",
      "Epoch 1978/2000\n",
      "3556/3556 [==============================] - 1s 270us/step - loss: 1.4827e-04 - val_loss: 0.0011\n",
      "Epoch 1979/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 1.4125e-04 - val_loss: 9.9249e-04\n",
      "Epoch 1980/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.4214e-04 - val_loss: 0.0010\n",
      "Epoch 1981/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 1.6428e-04 - val_loss: 0.0010\n",
      "Epoch 1982/2000\n",
      "3556/3556 [==============================] - 1s 273us/step - loss: 1.4569e-04 - val_loss: 8.7166e-04\n",
      "Epoch 1983/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.3633e-04 - val_loss: 0.0010\n",
      "Epoch 1984/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.3803e-04 - val_loss: 0.0010\n",
      "Epoch 1985/2000\n",
      "3556/3556 [==============================] - 1s 267us/step - loss: 1.4519e-04 - val_loss: 9.5613e-04\n",
      "Epoch 1986/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.3984e-04 - val_loss: 9.9736e-04\n",
      "Epoch 1987/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.4493e-04 - val_loss: 0.0010\n",
      "Epoch 1988/2000\n",
      "3556/3556 [==============================] - 1s 263us/step - loss: 1.4849e-04 - val_loss: 9.4040e-04\n",
      "Epoch 1989/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.4149e-04 - val_loss: 0.0011\n",
      "Epoch 1990/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 1.5108e-04 - val_loss: 0.0011\n",
      "Epoch 1991/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.5935e-04 - val_loss: 0.0011\n",
      "Epoch 1992/2000\n",
      "3556/3556 [==============================] - 1s 267us/step - loss: 1.4219e-04 - val_loss: 9.3616e-04\n",
      "Epoch 1993/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.3365e-04 - val_loss: 9.8106e-04\n",
      "Epoch 1994/2000\n",
      "3556/3556 [==============================] - 1s 266us/step - loss: 1.2355e-04 - val_loss: 9.8086e-04\n",
      "Epoch 1995/2000\n",
      "3556/3556 [==============================] - 1s 268us/step - loss: 1.2455e-04 - val_loss: 0.0011\n",
      "Epoch 1996/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.2820e-04 - val_loss: 0.0011\n",
      "Epoch 1997/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.4057e-04 - val_loss: 9.5603e-04\n",
      "Epoch 1998/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.3389e-04 - val_loss: 0.0011\n",
      "Epoch 1999/2000\n",
      "3556/3556 [==============================] - 1s 265us/step - loss: 1.2938e-04 - val_loss: 9.7555e-04\n",
      "Epoch 2000/2000\n",
      "3556/3556 [==============================] - 1s 264us/step - loss: 1.3435e-04 - val_loss: 0.0011\n"
     ]
    }
   ],
   "source": [
    "final_model = build_lstm(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lstmsize': 170,\n",
       " 'activation': 'selu',\n",
       " 'twice': False,\n",
       " 'density': 200,\n",
       " 'optimizer': 'adam',\n",
       " 'shuffle': True,\n",
       " 'callbacks': [<keras.callbacks.callbacks.ModelCheckpoint at 0x21e28c617c8>]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_182\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_297 (LSTM)              (None, 170)               119680    \n",
      "_________________________________________________________________\n",
      "dense_668 (Dense)            (None, 200)               34200     \n",
      "_________________________________________________________________\n",
      "dense_669 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 154,081\n",
      "Trainable params: 154,081\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model[0].load_weights('./checkpoints/IBM_3days/IBM.(best).hdf5')\n",
    "y_predicted = final_model[0].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y_test = y_normaliser.inverse_transform(y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE is 10.85\n",
      "Medium error is 2.25\n"
     ]
    }
   ],
   "source": [
    "loss = np.mean((unscaled_y_test - predicted_y_test)**2)\n",
    "medium_error = np.mean(abs(unscaled_y_test - predicted_y_test))\n",
    "print(f'MSE is {loss:.2f}\\nMedium error is {medium_error:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_down_test = []\n",
    "up_down_predicted = []\n",
    "\n",
    "for y,x in zip(Y_test,X_test):\n",
    "    if y[0] > x[-1][0]: up_down_test.append(1)\n",
    "    elif y[0] < x[-1][0]: up_down_test.append(-1)\n",
    "    else: up_down_test.append(0)\n",
    "        \n",
    "for y,x in zip(y_predicted,X_test):\n",
    "    if y[0] > x[-1][0]: up_down_predicted.append(1)\n",
    "    elif y[0] < x[-1][0]: up_down_predicted.append(-1)\n",
    "    else: up_down_predicted.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trend accuracy is: 62.79%\n"
     ]
    }
   ],
   "source": [
    "print(f'Trend accuracy is: {(sum(1 for r,p in zip(up_down_test,up_down_predicted) if r == p)/len(up_down_test))*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for upward trend is: 56.68%\n",
      "Accuracy for downward trend is: 69.59%\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy for upward trend is: {(sum(1 for r,p in zip(up_down_test,up_down_predicted) if r == 1 and p == 1)/sum(1 for v in up_down_test if v == 1))*100:.2f}%')\n",
    "print(f'Accuracy for downward trend is: {(sum(1 for r,p in zip(up_down_test,up_down_predicted) if r == -1 and p == -1)/sum(1 for v in up_down_test if v == -1))*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predictions over the last 92 days in test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 3200x2400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "figure(num=None, figsize=(40, 30), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "plt.plot(range(92), unscaled_y_test[-92:])\n",
    "plt.plot(range(92), predicted_y_test[-92:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Last 2 days + prediction of next 2 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 3200x2400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure(num=None, figsize=(40, 30), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "plt.plot(range(6), unscaled_y_test[-6:])\n",
    "plt.plot(range(6), np.append(unscaled_y_test[-6:-3], predicted_y_test[-3:]))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
