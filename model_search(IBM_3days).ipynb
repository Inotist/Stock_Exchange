{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from joblib import load\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./datasets/IBM_daily.csv').sort_values(by='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>1. open</th>\n",
       "      <th>2. high</th>\n",
       "      <th>3. low</th>\n",
       "      <th>4. close</th>\n",
       "      <th>5. volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5217</th>\n",
       "      <td>1999-11-01</td>\n",
       "      <td>98.50</td>\n",
       "      <td>98.8100</td>\n",
       "      <td>96.37</td>\n",
       "      <td>96.75</td>\n",
       "      <td>9551800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5216</th>\n",
       "      <td>1999-11-02</td>\n",
       "      <td>96.75</td>\n",
       "      <td>96.8100</td>\n",
       "      <td>93.69</td>\n",
       "      <td>94.81</td>\n",
       "      <td>11105400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5215</th>\n",
       "      <td>1999-11-03</td>\n",
       "      <td>95.87</td>\n",
       "      <td>95.9400</td>\n",
       "      <td>93.50</td>\n",
       "      <td>94.37</td>\n",
       "      <td>10369100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5214</th>\n",
       "      <td>1999-11-04</td>\n",
       "      <td>94.44</td>\n",
       "      <td>94.4400</td>\n",
       "      <td>90.00</td>\n",
       "      <td>91.56</td>\n",
       "      <td>16697600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5213</th>\n",
       "      <td>1999-11-05</td>\n",
       "      <td>92.75</td>\n",
       "      <td>92.9400</td>\n",
       "      <td>90.19</td>\n",
       "      <td>90.25</td>\n",
       "      <td>13737600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-07-22</td>\n",
       "      <td>125.90</td>\n",
       "      <td>129.4700</td>\n",
       "      <td>125.80</td>\n",
       "      <td>128.67</td>\n",
       "      <td>8195366.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-07-23</td>\n",
       "      <td>129.10</td>\n",
       "      <td>129.3700</td>\n",
       "      <td>127.15</td>\n",
       "      <td>127.33</td>\n",
       "      <td>4220136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-07-24</td>\n",
       "      <td>126.48</td>\n",
       "      <td>127.6459</td>\n",
       "      <td>125.50</td>\n",
       "      <td>125.79</td>\n",
       "      <td>3531076.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-07-27</td>\n",
       "      <td>124.86</td>\n",
       "      <td>126.3200</td>\n",
       "      <td>124.71</td>\n",
       "      <td>126.21</td>\n",
       "      <td>3733547.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-28</td>\n",
       "      <td>125.82</td>\n",
       "      <td>126.3400</td>\n",
       "      <td>124.15</td>\n",
       "      <td>124.47</td>\n",
       "      <td>4157538.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5218 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  1. open   2. high  3. low  4. close   5. volume\n",
       "5217  1999-11-01    98.50   98.8100   96.37     96.75   9551800.0\n",
       "5216  1999-11-02    96.75   96.8100   93.69     94.81  11105400.0\n",
       "5215  1999-11-03    95.87   95.9400   93.50     94.37  10369100.0\n",
       "5214  1999-11-04    94.44   94.4400   90.00     91.56  16697600.0\n",
       "5213  1999-11-05    92.75   92.9400   90.19     90.25  13737600.0\n",
       "...          ...      ...       ...     ...       ...         ...\n",
       "4     2020-07-22   125.90  129.4700  125.80    128.67   8195366.0\n",
       "3     2020-07-23   129.10  129.3700  127.15    127.33   4220136.0\n",
       "2     2020-07-24   126.48  127.6459  125.50    125.79   3531076.0\n",
       "1     2020-07-27   124.86  126.3200  124.71    126.21   3733547.0\n",
       "0     2020-07-28   125.82  126.3400  124.15    124.47   4157538.0\n",
       "\n",
       "[5218 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1. open</th>\n",
       "      <th>2. high</th>\n",
       "      <th>3. low</th>\n",
       "      <th>4. close</th>\n",
       "      <th>5. volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5217</th>\n",
       "      <td>98.50</td>\n",
       "      <td>98.8100</td>\n",
       "      <td>96.37</td>\n",
       "      <td>96.75</td>\n",
       "      <td>9551800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5216</th>\n",
       "      <td>96.75</td>\n",
       "      <td>96.8100</td>\n",
       "      <td>93.69</td>\n",
       "      <td>94.81</td>\n",
       "      <td>11105400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5215</th>\n",
       "      <td>95.87</td>\n",
       "      <td>95.9400</td>\n",
       "      <td>93.50</td>\n",
       "      <td>94.37</td>\n",
       "      <td>10369100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5214</th>\n",
       "      <td>94.44</td>\n",
       "      <td>94.4400</td>\n",
       "      <td>90.00</td>\n",
       "      <td>91.56</td>\n",
       "      <td>16697600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5213</th>\n",
       "      <td>92.75</td>\n",
       "      <td>92.9400</td>\n",
       "      <td>90.19</td>\n",
       "      <td>90.25</td>\n",
       "      <td>13737600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>125.90</td>\n",
       "      <td>129.4700</td>\n",
       "      <td>125.80</td>\n",
       "      <td>128.67</td>\n",
       "      <td>8195366.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>129.10</td>\n",
       "      <td>129.3700</td>\n",
       "      <td>127.15</td>\n",
       "      <td>127.33</td>\n",
       "      <td>4220136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>126.48</td>\n",
       "      <td>127.6459</td>\n",
       "      <td>125.50</td>\n",
       "      <td>125.79</td>\n",
       "      <td>3531076.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>124.86</td>\n",
       "      <td>126.3200</td>\n",
       "      <td>124.71</td>\n",
       "      <td>126.21</td>\n",
       "      <td>3733547.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>125.82</td>\n",
       "      <td>126.3400</td>\n",
       "      <td>124.15</td>\n",
       "      <td>124.47</td>\n",
       "      <td>4157538.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5218 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      1. open   2. high  3. low  4. close   5. volume\n",
       "5217    98.50   98.8100   96.37     96.75   9551800.0\n",
       "5216    96.75   96.8100   93.69     94.81  11105400.0\n",
       "5215    95.87   95.9400   93.50     94.37  10369100.0\n",
       "5214    94.44   94.4400   90.00     91.56  16697600.0\n",
       "5213    92.75   92.9400   90.19     90.25  13737600.0\n",
       "...       ...       ...     ...       ...         ...\n",
       "4      125.90  129.4700  125.80    128.67   8195366.0\n",
       "3      129.10  129.3700  127.15    127.33   4220136.0\n",
       "2      126.48  127.6459  125.50    125.79   3531076.0\n",
       "1      124.86  126.3200  124.71    126.21   3733547.0\n",
       "0      125.82  126.3400  124.15    124.47   4157538.0\n",
       "\n",
       "[5218 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(columns='date')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequence for the LSTM network\n",
    "backlook = 92\n",
    "\n",
    "# Days to predict\n",
    "days = 3\n",
    "\n",
    "# Size of data split for testing\n",
    "train_size = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test split\n",
    "split = int(len(data) * train_size)\n",
    "\n",
    "train = data.to_numpy()[:split]\n",
    "test = data.to_numpy()[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load normalisers\n",
    "normaliser = load('./normalisers/x_normaliser.joblib')\n",
    "y_normaliser = load('./normalisers/y_normaliser.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise data\n",
    "train_norm = normaliser.transform(train)\n",
    "test_norm = normaliser.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now I get indexes for chunks from 3 in 3 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = []\n",
    "\n",
    "for i in range(days):\n",
    "    index.append(np.arange(i,len(train),days))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_index = []\n",
    "\n",
    "for i in range(len(index[0]) - backlook):\n",
    "    for e in range(days):\n",
    "        try: ordered_index.append(index[e][i:i+backlook])\n",
    "        except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalised train chunks\n",
    "X_train = np.array([train_norm[ix].copy() for ix in ordered_index])\n",
    "Y_train = np.array([train_norm[ordered_index[i+days][-1],0].copy() for i in range(len(ordered_index) - days)])\n",
    "Y_train = np.expand_dims(Y_train, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete those sequences that doesn't have a -th day in the results\n",
    "X_train = X_train[:Y_train.shape[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Same for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = []\n",
    "\n",
    "for i in range(days):\n",
    "    index.append(np.arange(i,len(test),days))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_index = []\n",
    "\n",
    "for i in range(len(index[0]) - backlook):\n",
    "    for e in range(days):\n",
    "        try: ordered_index.append(index[e][i:i+backlook])\n",
    "        except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalised train chunks\n",
    "X_test = np.array([test_norm[ix].copy() for ix in ordered_index])\n",
    "Y_test = np.array([test_norm[ordered_index[i+days][-1],0].copy() for i in range(len(ordered_index) - days)])\n",
    "Y_test = np.expand_dims(Y_test, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete those sequences that doesn't have a -th day in the results\n",
    "X_test = X_test[:Y_test.shape[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm(x, y, batch_size=512, epochs=24, **params):\n",
    "    \n",
    "    # List of parameters\n",
    "    if 'lstmsize' not in params: params['lstmsize'] = x.shape[1]\n",
    "    if 'density' not in params: params['density'] = int((params['lstmsize']//1.5)*2)\n",
    "    if 'activation' not in params: params['activation'] = 'relu'\n",
    "    if 'twice' not in params: params['twice'] = False\n",
    "    if 'optimizer' not in params: params['optimizer'] = 'adam'\n",
    "    if 'shuffle' not in params: params['shuffle'] = False\n",
    "    \n",
    "    # Model definition\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(params['lstmsize'], input_shape=x.shape[1:], return_sequences=params['twice']))\n",
    "    \n",
    "    if 'dropout' in params:\n",
    "        model.add(Dropout(params['dropout']))\n",
    "    \n",
    "    if params['twice']:\n",
    "        model.add(LSTM(params['lstmsize']))\n",
    "        \n",
    "        if 'dropout' in params:\n",
    "            model.add(Dropout(params['dropout']))\n",
    "            \n",
    "    model.add(Dense(params['density'], activation=params['activation']))\n",
    "    \n",
    "    if 'full_density' in params and params['full_density']:\n",
    "        density = params['density']//2\n",
    "        while density >= 12:\n",
    "            model.add(Dense(density, activation=params['activation']))\n",
    "            density //= 2\n",
    "            \n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    \n",
    "    model.compile(loss='mse', optimizer=params['optimizer'])\n",
    "    \n",
    "    if 'callbacks' in params:\n",
    "        callback = model.fit(x=x, y=y, validation_split=0.1, batch_size=batch_size, epochs=epochs, shuffle=params['shuffle'],\n",
    "                            callbacks=params['callbacks'])\n",
    "    else:\n",
    "        callback = model.fit(x=x, y=y, validation_split=0.1, batch_size=batch_size, epochs=epochs, shuffle=params['shuffle'])\n",
    "    \n",
    "    return [model, callback, params]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evolutive algorith to search for the most optimal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_genes(x, y, population_size, population=[]):\n",
    "    if population_size-len(population) < 0:\n",
    "        print('population size must be greater or equal than actual population')\n",
    "        return\n",
    "    \n",
    "    if len(population) > 0:\n",
    "        if len(population) < 3:\n",
    "            print('population should be empty or 3 at least')\n",
    "            return\n",
    "        \n",
    "        population[2] = breed_genes(x, y, population[0][2].copy())\n",
    "        population[1] = breed_genes(x, y, combine=(population[0][2], population[1][2]))\n",
    "        population = population[:3]\n",
    "    \n",
    "    for _ in range(population_size-len(population)):\n",
    "        subject = breed_genes(x, y)\n",
    "        population.append(subject)\n",
    "        \n",
    "    return population\n",
    "\n",
    "def breed_genes(x, y, genes={}, combine=None):\n",
    "    genes['x'] = x\n",
    "    genes['y'] = y\n",
    "    \n",
    "    if type(combine) is list or type(combine) is tuple:\n",
    "        genes['lstmsize'] = combine[np.random.randint(0,2)]['lstmsize']\n",
    "        genes['density'] = combine[np.random.randint(0,2)]['density']\n",
    "        genes['activation'] = combine[np.random.randint(0,2)]['activation']\n",
    "        genes['twice'] = combine[np.random.randint(0,2)]['twice']\n",
    "        genes['optimizer'] = combine[np.random.randint(0,2)]['optimizer']\n",
    "        genes['shuffle'] = combine[np.random.randint(0,2)]['shuffle']\n",
    "        \n",
    "        genes['dropout'] = combine[np.random.randint(0,2)].get('dropout')\n",
    "        if genes['dropout'] is None: del genes['dropout']\n",
    "        genes['full_density'] = combine[np.random.randint(0,2)].get('full_density')\n",
    "        if genes['full_density'] is None: del genes['full_density']\n",
    "            \n",
    "    else:\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['lstmsize'] = int((np.random.randint(x.shape[1],x.shape[1]*2)//2)*2)\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['density'] = int((np.random.randint(x.shape[1]//2,x.shape[1]*2.66)//2)*2)\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            activation = [\n",
    "                'relu',\n",
    "                'sigmoid',\n",
    "                'softplus',\n",
    "                'softsign',\n",
    "                'tanh',\n",
    "                'selu',\n",
    "                'elu',\n",
    "                'exponential'\n",
    "            ]\n",
    "            genes['activation'] = activation[np.random.randint(0,8)]\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['twice'] = True\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            optimizer = [\n",
    "                'sgd',\n",
    "                'rmsprop',\n",
    "                'adam',\n",
    "                'adadelta',\n",
    "                'adagrad',\n",
    "                'adamax',\n",
    "                'nadam'\n",
    "            ]\n",
    "            genes['optimizer'] = optimizer[np.random.randint(0,7)]\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['shuffle'] = True\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['dropout'] = np.random.randint(1,4)/10\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['full_density'] = True\n",
    "            \n",
    "    new_model = build_lstm(**genes)\n",
    "        \n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def breed_population(x, y, generations, population_size, population=[]):\n",
    "    \n",
    "    if generations > 1 and population_size < 3:\n",
    "        print('population size should be of a minimum of 3 for more than one generation')\n",
    "        return\n",
    "    \n",
    "    for g in range(generations):\n",
    "        print(f'\\nGENERATION {g}\\n')\n",
    "        population = set_genes(x, y, population_size, population)\n",
    "        population = sorted(population, key=lambda x: x[1].history['val_loss'][-1]+x[1].history['loss'][-1])\n",
    "        \n",
    "    return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GENERATION 0\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 2s 566us/step - loss: 0.0239 - val_loss: 0.0171\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 297us/step - loss: 0.0233 - val_loss: 0.0127\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 295us/step - loss: 0.0249 - val_loss: 0.0284\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 297us/step - loss: 0.0638 - val_loss: 0.0101\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 302us/step - loss: 0.0145 - val_loss: 0.0061\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 297us/step - loss: 0.0268 - val_loss: 0.0024\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 296us/step - loss: 0.0243 - val_loss: 0.0015\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 298us/step - loss: 0.0308 - val_loss: 0.0183\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 302us/step - loss: 0.0024 - val_loss: 0.0079\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 299us/step - loss: 0.0042 - val_loss: 0.0013\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 298us/step - loss: 0.0036 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 298us/step - loss: 0.0028 - val_loss: 0.0023\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 296us/step - loss: 0.0029 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 295us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 300us/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 294us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 295us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 296us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 299us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 296us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 297us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 297us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 316us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 297us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 2s 496us/step - loss: 0.0399 - val_loss: 0.0710\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 306us/step - loss: 0.0229 - val_loss: 0.0059\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 304us/step - loss: 0.0156 - val_loss: 0.0208\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 308us/step - loss: 0.0398 - val_loss: 0.0069\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 301us/step - loss: 0.0211 - val_loss: 0.0059\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 302us/step - loss: 0.0044 - val_loss: 0.0140\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 304us/step - loss: 0.0037 - val_loss: 0.0016\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 302us/step - loss: 0.0029 - val_loss: 0.0015\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 300us/step - loss: 0.0058 - val_loss: 0.0137\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 302us/step - loss: 0.0081 - val_loss: 0.0018\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 300us/step - loss: 0.0025 - val_loss: 0.0045\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 299us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 303us/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 300us/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 305us/step - loss: 0.0027 - val_loss: 0.0054\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 301us/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 299us/step - loss: 0.0036 - val_loss: 0.0074\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 301us/step - loss: 0.0032 - val_loss: 0.0027\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 300us/step - loss: 0.0047 - val_loss: 0.0092\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 300us/step - loss: 0.0049 - val_loss: 0.0053\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 298us/step - loss: 0.0100 - val_loss: 0.0113\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 299us/step - loss: 0.0127 - val_loss: 0.0115\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 301us/step - loss: 0.0317 - val_loss: 0.0016\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 299us/step - loss: 0.0228 - val_loss: 0.0035\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 3s 689us/step - loss: 0.1061 - val_loss: 0.0077\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 496us/step - loss: 0.0122 - val_loss: 0.0103\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0072 - val_loss: 0.0138\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0038 - val_loss: 0.0015\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0021 - val_loss: 0.0034\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 494us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 499us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 495us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 497us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 496us/step - loss: 9.9972e-04 - val_loss: 0.0010\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 9.7869e-04 - val_loss: 0.0010\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 9.6400e-04 - val_loss: 9.7189e-04\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 9.5449e-04 - val_loss: 9.8519e-04\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 485us/step - loss: 9.5680e-04 - val_loss: 0.0010\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 9.4678e-04 - val_loss: 9.3448e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 9.2508e-04 - val_loss: 9.2182e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 3s 717us/step - loss: 0.0815 - val_loss: 0.0019\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0123 - val_loss: 0.0119\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0060 - val_loss: 0.0038\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0033 - val_loss: 0.0065\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0026 - val_loss: 0.0015\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 493us/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 506us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 504us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 496us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 497us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 499us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 9.9744e-04 - val_loss: 0.0010\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 9.8085e-04 - val_loss: 9.7766e-04\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 9.6315e-04 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 9.6006e-04 - val_loss: 9.7329e-04\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 494us/step - loss: 9.4238e-04 - val_loss: 9.2985e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 495us/step - loss: 9.1208e-04 - val_loss: 9.3305e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 494us/step - loss: 9.1469e-04 - val_loss: 8.9150e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 3s 715us/step - loss: 0.0759 - val_loss: 0.0388\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0131 - val_loss: 0.0082\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 0.0057 - val_loss: 0.0026\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 492us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 499us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 492us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 491us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 493us/step - loss: 0.0010 - val_loss: 9.8270e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 497us/step - loss: 9.8424e-04 - val_loss: 9.6718e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 3s 730us/step - loss: 0.6910 - val_loss: 0.0015\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 496us/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0143 - val_loss: 0.0022\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0262 - val_loss: 0.0049\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 491us/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0246 - val_loss: 0.1249\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0169 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 496us/step - loss: 0.0057 - val_loss: 0.0244\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0131 - val_loss: 0.0111\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0109 - val_loss: 0.0295\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0159 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 503us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 496us/step - loss: 0.0163 - val_loss: 0.0244\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0109 - val_loss: 0.0030\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0051 - val_loss: 0.0251\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 493us/step - loss: 0.0054 - val_loss: 0.0135\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0070 - val_loss: 0.0201\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0149 - val_loss: 0.0061\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0064 - val_loss: 0.0145\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0047 - val_loss: 0.0075\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 492us/step - loss: 0.0060 - val_loss: 0.0186\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 3s 742us/step - loss: 0.8892 - val_loss: 0.0014\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0018 - val_loss: 0.0023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0058 - val_loss: 0.0972\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0232 - val_loss: 0.0029\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 491us/step - loss: 0.0020 - val_loss: 0.0134\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0345 - val_loss: 0.0337\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 492us/step - loss: 0.0057 - val_loss: 0.0038\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 491us/step - loss: 0.0100 - val_loss: 0.0646\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0344 - val_loss: 0.0040\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 0.0017 - val_loss: 0.0053\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0127 - val_loss: 0.0238\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0063 - val_loss: 0.0121\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0101 - val_loss: 0.0327\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0215 - val_loss: 0.0107\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0021 - val_loss: 0.0057\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 485us/step - loss: 0.0063 - val_loss: 0.0147\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0076 - val_loss: 0.0202\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 0.0184 - val_loss: 0.0071\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 0.0024 - val_loss: 0.0070\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 0.0045 - val_loss: 0.0075\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0056 - val_loss: 0.0147\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 494us/step - loss: 0.0049 - val_loss: 0.0129\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0072 - val_loss: 0.0234\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 3s 754us/step - loss: 0.4564 - val_loss: 0.0018\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0038 - val_loss: 0.0142\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 0.0055 - val_loss: 0.0114\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0102 - val_loss: 0.0112\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0082 - val_loss: 0.0163\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0125 - val_loss: 0.0194\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 485us/step - loss: 0.0355 - val_loss: 0.0152\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0087 - val_loss: 0.0040\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0052 - val_loss: 0.0435\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0248 - val_loss: 0.0075\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 0.0039 - val_loss: 0.0154\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 492us/step - loss: 0.0084 - val_loss: 0.0131\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 491us/step - loss: 0.0094 - val_loss: 0.0319\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0252 - val_loss: 0.0043\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0021 - val_loss: 0.0084\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0097 - val_loss: 0.0121\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0042 - val_loss: 0.0113\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0076 - val_loss: 0.0190\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 500us/step - loss: 0.0118 - val_loss: 0.0104\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 508us/step - loss: 0.0031 - val_loss: 0.0082\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 497us/step - loss: 0.0076 - val_loss: 0.0201\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 495us/step - loss: 0.0056 - val_loss: 0.0044\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0059 - val_loss: 0.0214\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 3s 759us/step - loss: 0.1177 - val_loss: 0.0163\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 0.0427 - val_loss: 0.0121\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 0.0339 - val_loss: 0.0082\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 554us/step - loss: 0.0259 - val_loss: 0.0061\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 506us/step - loss: 0.0204 - val_loss: 0.0046\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 0.0165 - val_loss: 0.0032\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 505us/step - loss: 0.0131 - val_loss: 0.0026\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 507us/step - loss: 0.0107 - val_loss: 0.0023\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 502us/step - loss: 0.0096 - val_loss: 0.0023\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0083 - val_loss: 0.0025\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 0.0074 - val_loss: 0.0026\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0068 - val_loss: 0.0029\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0063 - val_loss: 0.0031\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 0.0064 - val_loss: 0.0036\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 0.0062 - val_loss: 0.0038\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 0.0059 - val_loss: 0.0041\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0059 - val_loss: 0.0043\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 528us/step - loss: 0.0057 - val_loss: 0.0048\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 0.0055 - val_loss: 0.0045\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0053 - val_loss: 0.0045\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 3s 844us/step - loss: 0.1446 - val_loss: 0.0378\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0539 - val_loss: 0.0190\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 0.0452 - val_loss: 0.0150\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 0.0382 - val_loss: 0.0129\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 0.0330 - val_loss: 0.0109\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 0.0287 - val_loss: 0.0089\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0246 - val_loss: 0.0075\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 0.0215 - val_loss: 0.0060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0181 - val_loss: 0.0049\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 0.0154 - val_loss: 0.0040\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 0.0134 - val_loss: 0.0033\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0117 - val_loss: 0.0028\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0103 - val_loss: 0.0025\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 0.0091 - val_loss: 0.0023\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 0.0081 - val_loss: 0.0023\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0078 - val_loss: 0.0024\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 0.0068 - val_loss: 0.0024\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0065 - val_loss: 0.0027\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 541us/step - loss: 0.0061 - val_loss: 0.0028\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 0.0058 - val_loss: 0.0030\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 0.0055 - val_loss: 0.0032\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0055 - val_loss: 0.0034\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 0.0054 - val_loss: 0.0036\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 510us/step - loss: 0.0050 - val_loss: 0.0037\n",
      "\n",
      "GENERATION 1\n",
      "\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 3s 851us/step - loss: 0.1260 - val_loss: 0.0018\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0156 - val_loss: 0.0017\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 491us/step - loss: 0.0030 - val_loss: 0.0186\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0089 - val_loss: 0.0082\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0049 - val_loss: 0.0040\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 494us/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 491us/step - loss: 0.0049 - val_loss: 0.0032\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0040 - val_loss: 0.0054\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 0.0060 - val_loss: 0.0079\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 0.0047 - val_loss: 0.0016\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 0.0033 - val_loss: 0.0051\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 491us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 493us/step - loss: 0.0041 - val_loss: 0.0029\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 0.0039 - val_loss: 0.0055\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 0.0043 - val_loss: 0.0061\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 485us/step - loss: 0.0045 - val_loss: 0.0059\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 485us/step - loss: 0.0043 - val_loss: 0.0034\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 485us/step - loss: 0.0033 - val_loss: 0.0018\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 493us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 3s 865us/step - loss: 0.0587 - val_loss: 0.0183\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0096 - val_loss: 0.0028\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 492us/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 501us/step - loss: 0.0016 - val_loss: 0.0025\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 492us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 485us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 9.9999e-04 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 500us/step - loss: 9.8047e-04 - val_loss: 9.9461e-04\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 9.5882e-04 - val_loss: 9.5078e-04\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 9.4418e-04 - val_loss: 9.3448e-04\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 493us/step - loss: 9.3464e-04 - val_loss: 9.1779e-04\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 9.4218e-04 - val_loss: 0.0010\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 495us/step - loss: 9.3515e-04 - val_loss: 9.7050e-04\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 9.0857e-04 - val_loss: 9.0339e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 8.8665e-04 - val_loss: 8.8768e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 484us/step - loss: 8.7728e-04 - val_loss: 8.5718e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 3s 875us/step - loss: 0.0649 - val_loss: 0.0027\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 0.0082 - val_loss: 0.0037\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 493us/step - loss: 0.0040 - val_loss: 0.0016\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 0.0021 - val_loss: 0.0036\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 485us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 492us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 495us/step - loss: 0.0010 - val_loss: 9.8806e-04\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 9.7653e-04 - val_loss: 9.7028e-04\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 9.6066e-04 - val_loss: 9.8279e-04\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 9.5196e-04 - val_loss: 9.3526e-04\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 9.2872e-04 - val_loss: 9.3876e-04\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 491us/step - loss: 9.6535e-04 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 484us/step - loss: 9.8465e-04 - val_loss: 9.5531e-04\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 9.2397e-04 - val_loss: 9.6529e-04\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 9.2192e-04 - val_loss: 9.1420e-04\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 8.8369e-04 - val_loss: 8.4748e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 499us/step - loss: 8.7856e-04 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 8.9068e-04 - val_loss: 8.2306e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 4s 1ms/step - loss: 0.0782 - val_loss: 0.0018\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 337us/step - loss: 0.0083 - val_loss: 0.0232\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 338us/step - loss: 0.0078 - val_loss: 0.0033\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 340us/step - loss: 0.0048 - val_loss: 0.0084\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 338us/step - loss: 0.0078 - val_loss: 0.0024\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 340us/step - loss: 0.0060 - val_loss: 0.0054\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 340us/step - loss: 0.0078 - val_loss: 0.0028\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 389us/step - loss: 0.0046 - val_loss: 0.0029\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 342us/step - loss: 0.0057 - val_loss: 0.0044\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 333us/step - loss: 0.0067 - val_loss: 0.0041\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 341us/step - loss: 0.0058 - val_loss: 0.0021\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 345us/step - loss: 0.0047 - val_loss: 0.0036\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 331us/step - loss: 0.0061 - val_loss: 0.0030\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 333us/step - loss: 0.0034 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 333us/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 333us/step - loss: 0.0051 - val_loss: 0.0053\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 334us/step - loss: 0.0055 - val_loss: 0.0036\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 358us/step - loss: 0.0038 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 332us/step - loss: 0.0028 - val_loss: 0.0014\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 376us/step - loss: 0.0035 - val_loss: 0.0034\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 323us/step - loss: 0.0050 - val_loss: 0.0035\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 323us/step - loss: 0.0042 - val_loss: 0.0021\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 327us/step - loss: 0.0032 - val_loss: 0.0013\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 323us/step - loss: 0.0028 - val_loss: 0.0017\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 3s 767us/step - loss: 0.0663 - val_loss: 0.0024\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 322us/step - loss: 0.0213 - val_loss: 0.0020\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 330us/step - loss: 0.0057 - val_loss: 0.0125\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 321us/step - loss: 0.0119 - val_loss: 0.0066\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 319us/step - loss: 0.0057 - val_loss: 0.0024\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 321us/step - loss: 0.0052 - val_loss: 0.0044\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 318us/step - loss: 0.0086 - val_loss: 0.0102\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 325us/step - loss: 0.0081 - val_loss: 0.0041\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 322us/step - loss: 0.0048 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 321us/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 323us/step - loss: 0.0037 - val_loss: 0.0018\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 317us/step - loss: 0.0059 - val_loss: 0.0061\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 318us/step - loss: 0.0067 - val_loss: 0.0065\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 322us/step - loss: 0.0069 - val_loss: 0.0018\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 320us/step - loss: 0.0035 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 321us/step - loss: 0.0029 - val_loss: 0.0010\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 318us/step - loss: 0.0028 - val_loss: 0.0014\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 317us/step - loss: 0.0037 - val_loss: 0.0073\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 317us/step - loss: 0.0066 - val_loss: 0.0041\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 320us/step - loss: 0.0030 - val_loss: 0.0014\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 327us/step - loss: 0.0020 - val_loss: 0.0010\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 318us/step - loss: 0.0019 - val_loss: 9.9727e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 320us/step - loss: 0.0040 - val_loss: 0.0061\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 320us/step - loss: 0.0050 - val_loss: 0.0015\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 3s 801us/step - loss: 0.0938 - val_loss: 0.0037\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 324us/step - loss: 0.1308 - val_loss: 0.0028\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 332us/step - loss: 0.0076 - val_loss: 0.0105\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 353us/step - loss: 0.0203 - val_loss: 0.0300\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 329us/step - loss: 0.0121 - val_loss: 0.0148\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 325us/step - loss: 0.0085 - val_loss: 0.0178\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 336us/step - loss: 0.0159 - val_loss: 0.0472\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 332us/step - loss: 0.0223 - val_loss: 0.0256\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 331us/step - loss: 0.0107 - val_loss: 0.0202\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 331us/step - loss: 0.0097 - val_loss: 0.0207\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 326us/step - loss: 0.0133 - val_loss: 0.0316\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 336us/step - loss: 0.0135 - val_loss: 0.0178\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 346us/step - loss: 0.0110 - val_loss: 0.0247\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 326us/step - loss: 0.0109 - val_loss: 0.0161\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 358us/step - loss: 0.0056 - val_loss: 0.0102\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 330us/step - loss: 0.0050 - val_loss: 0.0144\n",
      "Epoch 17/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 1s 333us/step - loss: 0.0118 - val_loss: 0.0324\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 332us/step - loss: 0.0156 - val_loss: 0.0182\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 329us/step - loss: 0.0053 - val_loss: 0.0032\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 318us/step - loss: 0.0029 - val_loss: 0.0025\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 329us/step - loss: 0.0028 - val_loss: 0.0019\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 316us/step - loss: 0.0075 - val_loss: 0.0153\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 314us/step - loss: 0.0183 - val_loss: 0.0082\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 314us/step - loss: 0.0066 - val_loss: 0.0019\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 3s 776us/step - loss: 0.0990 - val_loss: 0.0035\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 319us/step - loss: 0.0378 - val_loss: 0.0093\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 317us/step - loss: 0.0095 - val_loss: 0.0130\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 322us/step - loss: 0.0066 - val_loss: 0.0025\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 317us/step - loss: 0.0045 - val_loss: 0.0025\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 328us/step - loss: 0.0033 - val_loss: 0.0051\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 315us/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 316us/step - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 316us/step - loss: 0.0026 - val_loss: 0.0021\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 315us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 317us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 317us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 316us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 321us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 317us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 321us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 319us/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 315us/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 318us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 316us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 317us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 316us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 317us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 317us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 3s 804us/step - loss: 0.1365 - val_loss: 0.0665\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 316us/step - loss: 0.0646 - val_loss: 0.0129\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 315us/step - loss: 0.0345 - val_loss: 0.0046\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 316us/step - loss: 0.0107 - val_loss: 0.0314\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 317us/step - loss: 0.0072 - val_loss: 0.0164\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 317us/step - loss: 0.0048 - val_loss: 0.0030\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 315us/step - loss: 0.0040 - val_loss: 0.0036\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 314us/step - loss: 0.0033 - val_loss: 0.0040\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 314us/step - loss: 0.0031 - val_loss: 0.0027\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 314us/step - loss: 0.0029 - val_loss: 0.0025\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 317us/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 324us/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 316us/step - loss: 0.0026 - val_loss: 0.0021\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 315us/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 325us/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 315us/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 316us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 313us/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 314us/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 317us/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 317us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 315us/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 315us/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 320us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 3s 809us/step - loss: 0.0704 - val_loss: 0.0047\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 315us/step - loss: 0.0230 - val_loss: 0.0135\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 316us/step - loss: 0.0079 - val_loss: 0.0134\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 316us/step - loss: 0.0046 - val_loss: 0.0026\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 314us/step - loss: 0.0041 - val_loss: 0.0022\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 318us/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 317us/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 321us/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 323us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 319us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 318us/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 316us/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 317us/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 315us/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 314us/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 316us/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 316us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 315us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 316us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 315us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 317us/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 22/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 1s 323us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 318us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 314us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "\n",
      "GENERATION 2\n",
      "\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 4s 971us/step - loss: 0.1656 - val_loss: 0.0025\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0042 - val_loss: 0.0020\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0095 - val_loss: 0.0016\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0067 - val_loss: 0.0302\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 485us/step - loss: 0.0100 - val_loss: 0.0150\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0139 - val_loss: 0.0064\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 485us/step - loss: 0.0110 - val_loss: 0.0098\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 0.0112 - val_loss: 0.0167\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 485us/step - loss: 0.0099 - val_loss: 0.0111\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0090 - val_loss: 0.0198\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0107 - val_loss: 0.0019\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0057 - val_loss: 0.0132\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 0.0089 - val_loss: 0.0106\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 0.0073 - val_loss: 0.0048\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 0.0068 - val_loss: 0.0124\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 0.0080 - val_loss: 0.0028\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 485us/step - loss: 0.0041 - val_loss: 0.0115\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0078 - val_loss: 0.0213\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0066 - val_loss: 0.0010\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0032 - val_loss: 0.0110\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0075 - val_loss: 0.0046\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 0.0037 - val_loss: 0.0106\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 0.0062 - val_loss: 0.0028\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0036 - val_loss: 0.0070\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 4s 1ms/step - loss: 0.0649 - val_loss: 0.0054\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0094 - val_loss: 0.0079\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 0.0044 - val_loss: 0.0015\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 0.0028 - val_loss: 0.0063\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 491us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 484us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 485us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 485us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 9.7314e-04 - val_loss: 9.7590e-04\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 9.4936e-04 - val_loss: 9.6531e-04\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 9.4232e-04 - val_loss: 9.4098e-04\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 9.2653e-04 - val_loss: 9.8935e-04\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 9.1519e-04 - val_loss: 9.3330e-04\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 9.1800e-04 - val_loss: 9.9669e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 8.9834e-04 - val_loss: 8.9370e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 485us/step - loss: 8.8527e-04 - val_loss: 9.2975e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 4s 1ms/step - loss: 0.1438 - val_loss: 0.0084\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 507us/step - loss: 0.0234 - val_loss: 0.0042\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 508us/step - loss: 0.0135 - val_loss: 0.0167\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 508us/step - loss: 0.0083 - val_loss: 0.0386\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 508us/step - loss: 0.0134 - val_loss: 0.0232\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 509us/step - loss: 0.0103 - val_loss: 0.0262\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 0.0150 - val_loss: 0.0231\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 509us/step - loss: 0.0067 - val_loss: 0.0245\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 510us/step - loss: 0.0084 - val_loss: 0.0294\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 509us/step - loss: 0.0078 - val_loss: 0.0171\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 508us/step - loss: 0.0090 - val_loss: 0.0155\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 510us/step - loss: 0.0069 - val_loss: 0.0244\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 509us/step - loss: 0.0076 - val_loss: 0.0109\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 508us/step - loss: 0.0063 - val_loss: 0.0161\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 511us/step - loss: 0.0079 - val_loss: 0.0215\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 508us/step - loss: 0.0044 - val_loss: 0.0205\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 507us/step - loss: 0.0062 - val_loss: 0.0156\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 508us/step - loss: 0.0059 - val_loss: 0.0134\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 509us/step - loss: 0.0050 - val_loss: 0.0157\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 507us/step - loss: 0.0060 - val_loss: 0.0137\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 506us/step - loss: 0.0043 - val_loss: 0.0188\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 507us/step - loss: 0.0052 - val_loss: 0.0111\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 511us/step - loss: 0.0045 - val_loss: 0.0137\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 0.0061 - val_loss: 0.0070\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 4s 1ms/step - loss: 0.3107 - val_loss: 0.0030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0138 - val_loss: 0.0143\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0100 - val_loss: 0.0227\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0138 - val_loss: 0.0223\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0136 - val_loss: 0.0220\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0159 - val_loss: 0.0237\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0139 - val_loss: 0.0250\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0137 - val_loss: 0.0093\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0144 - val_loss: 0.0200\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0113 - val_loss: 0.0141\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 535us/step - loss: 0.0124 - val_loss: 0.0128\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 540us/step - loss: 0.0103 - val_loss: 0.0060\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 545us/step - loss: 0.0110 - val_loss: 0.0076\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 547us/step - loss: 0.0084 - val_loss: 0.0140\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 0.0100 - val_loss: 0.0090\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 537us/step - loss: 0.0092 - val_loss: 0.0095\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 535us/step - loss: 0.0074 - val_loss: 0.0081\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0080 - val_loss: 0.0105\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 536us/step - loss: 0.0070 - val_loss: 0.0128\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0076 - val_loss: 0.0054\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 0.0070 - val_loss: 0.0066\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0075 - val_loss: 0.0069\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0055 - val_loss: 0.0061\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0066 - val_loss: 0.0065\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 5s 1ms/step - loss: 0.5870 - val_loss: 0.0030\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 0.0087 - val_loss: 0.0089\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 0.0117 - val_loss: 0.0440\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0112 - val_loss: 0.0031\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0042 - val_loss: 0.0029\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 0.0038 - val_loss: 0.0033\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 0.0036 - val_loss: 0.0056\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 0.0048 - val_loss: 0.0160\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 0.0058 - val_loss: 0.0047\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 0.0032 - val_loss: 0.0037\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 0.0030 - val_loss: 0.0035\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 0.0028 - val_loss: 0.0018\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 0.0026 - val_loss: 0.0015\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 0.0029 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 0.0030 - val_loss: 0.0017\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 0.0064 - val_loss: 0.0014\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0024 - val_loss: 0.0010\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 5s 1ms/step - loss: 0.8656 - val_loss: 0.0019\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 0.0091 - val_loss: 0.0030\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 0.0064 - val_loss: 0.0020\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 0.0072 - val_loss: 0.0397\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0141 - val_loss: 0.0021\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 0.0039 - val_loss: 0.0030\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 0.0034 - val_loss: 0.0013\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 0.0034 - val_loss: 0.0019\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 0.0032 - val_loss: 0.0019\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 0.0030 - val_loss: 0.0015\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 0.0028 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0032 - val_loss: 0.0062\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0119 - val_loss: 0.0022\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 0.0035 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 0.0028 - val_loss: 0.0020\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 0.0026 - val_loss: 0.0013\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 0.0025 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 0.0052 - val_loss: 0.0110\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 0.0051 - val_loss: 0.0035\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 0.0025 - val_loss: 0.0014\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 5s 1ms/step - loss: 0.7185 - val_loss: 0.0017\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 0.0069 - val_loss: 0.0024\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 0.0052 - val_loss: 0.0043\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 0.0065 - val_loss: 0.0378\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 567us/step - loss: 0.0196 - val_loss: 0.0066\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 573us/step - loss: 0.0106 - val_loss: 0.0421\n",
      "Epoch 7/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 2s 562us/step - loss: 0.0550 - val_loss: 0.0021\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 0.0038 - val_loss: 0.0145\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 0.0184 - val_loss: 0.0170\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 0.0100 - val_loss: 0.0325\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 0.0171 - val_loss: 0.0423\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 542us/step - loss: 0.0405 - val_loss: 0.0030\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 0.0093 - val_loss: 0.0220\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 0.0064 - val_loss: 0.0262\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 0.0121 - val_loss: 0.0223\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 0.0092 - val_loss: 0.0142\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 0.0083 - val_loss: 0.0246\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 0.0219 - val_loss: 0.0243\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0049 - val_loss: 0.0039\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 0.0069 - val_loss: 0.0317\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 0.0066 - val_loss: 0.0161\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 535us/step - loss: 0.0067 - val_loss: 0.0261\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 536us/step - loss: 0.0110 - val_loss: 0.0194\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 5s 1ms/step - loss: 1.3017 - val_loss: 0.0024\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 0.0078 - val_loss: 0.0029\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0063 - val_loss: 0.0322\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 0.0391 - val_loss: 0.0027\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 566us/step - loss: 0.0168 - val_loss: 0.0458\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 0.0316 - val_loss: 0.0052\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0166 - val_loss: 0.0362\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.1012 - val_loss: 0.0016\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 568us/step - loss: 0.0028 - val_loss: 0.0112\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 0.0118 - val_loss: 0.0095\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 0.0145 - val_loss: 0.0422\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 0.0415 - val_loss: 0.0105\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 0.0051 - val_loss: 0.0127\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 0.0111 - val_loss: 0.0270\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0099 - val_loss: 0.0260\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 0.0247 - val_loss: 0.0207\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0058 - val_loss: 0.0188\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0111 - val_loss: 0.0349\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 0.0105 - val_loss: 0.0268\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0091 - val_loss: 0.0237\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 0.0112 - val_loss: 0.0235\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 0.0087 - val_loss: 0.0240\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0083 - val_loss: 0.0326\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 0.0105 - val_loss: 0.0106\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 5s 1ms/step - loss: 2.5443 - val_loss: 0.0015\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 0.0083 - val_loss: 0.0018\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0071 - val_loss: 0.0015\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 540us/step - loss: 0.0059 - val_loss: 0.0118\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0413 - val_loss: 0.0013\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 0.0039 - val_loss: 0.0012\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0489 - val_loss: 0.3100\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 0.0667 - val_loss: 0.0016\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0030 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 0.0199 - val_loss: 0.0277\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0151 - val_loss: 0.0118\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 0.0184 - val_loss: 0.0978\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 0.0985 - val_loss: 0.0032\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 0.0026 - val_loss: 0.0169\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 0.0180 - val_loss: 0.0208\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 0.0074 - val_loss: 0.0309\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 0.0225 - val_loss: 0.1427\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 0.0544 - val_loss: 0.0052\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0094 - val_loss: 0.0094\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 0.0153 - val_loss: 0.0155\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 0.0052 - val_loss: 0.0214\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 0.0165 - val_loss: 0.0099\n",
      "\n",
      "GENERATION 3\n",
      "\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 5s 1ms/step - loss: 0.0529 - val_loss: 0.0092\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0088 - val_loss: 0.0014\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 498us/step - loss: 0.0039 - val_loss: 0.0028\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0031 - val_loss: 0.0013\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 499us/step - loss: 0.0021 - val_loss: 0.0036\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 494us/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 491us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 493us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 494us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0011 - val_loss: 0.0011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0010 - val_loss: 9.9395e-04\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0010 - val_loss: 9.7816e-04\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 9.8881e-04 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 9.7128e-04 - val_loss: 9.4092e-04\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 9.3606e-04 - val_loss: 9.3092e-04\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 491us/step - loss: 9.2115e-04 - val_loss: 9.2529e-04\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 9.1665e-04 - val_loss: 9.0161e-04\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 9.0272e-04 - val_loss: 9.6464e-04\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 497us/step - loss: 9.1384e-04 - val_loss: 8.7513e-04\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 495us/step - loss: 9.0902e-04 - val_loss: 8.9009e-04\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 8.8395e-04 - val_loss: 9.4637e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 8.7251e-04 - val_loss: 8.3369e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 8.4234e-04 - val_loss: 8.4862e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 5s 1ms/step - loss: 0.0861 - val_loss: 0.0022\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0122 - val_loss: 0.0161\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0036 - val_loss: 0.0021\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 491us/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 493us/step - loss: 0.0021 - val_loss: 0.0035\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 495us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 492us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 496us/step - loss: 9.8186e-04 - val_loss: 9.9486e-04\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 9.6591e-04 - val_loss: 9.4816e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 9.4709e-04 - val_loss: 9.3349e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 494us/step - loss: 9.3072e-04 - val_loss: 9.1822e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 5s 1ms/step - loss: 0.0608 - val_loss: 0.0025\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 511us/step - loss: 0.0091 - val_loss: 0.0068\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 0.0066 - val_loss: 0.0074\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 0.0043 - val_loss: 0.0024\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 510us/step - loss: 0.0034 - val_loss: 0.0012\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 510us/step - loss: 0.0029 - val_loss: 0.0023\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 0.0026 - val_loss: 0.0013\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0025 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 511us/step - loss: 0.0024 - val_loss: 0.0015\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 511us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 511us/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 511us/step - loss: 0.0019 - val_loss: 0.0010\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 511us/step - loss: 0.0019 - val_loss: 0.0010\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 510us/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 0.0018 - val_loss: 9.8053e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 511us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 5s 1ms/step - loss: 0.6754 - val_loss: 0.0078\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 0.0608 - val_loss: 0.0277\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 0.0301 - val_loss: 0.0046\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 0.0116 - val_loss: 0.0040\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 0.0061 - val_loss: 0.0017\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 0.0042 - val_loss: 0.0073\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 511us/step - loss: 0.0036 - val_loss: 0.0013\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 0.0032 - val_loss: 0.0028\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 0.0030 - val_loss: 0.0016\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 511us/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 511us/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 510us/step - loss: 0.0024 - val_loss: 0.0015\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 0.0023 - val_loss: 0.0015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 511us/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 511us/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 0.0023 - val_loss: 0.0013\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 510us/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 511us/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 511us/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 5s 1ms/step - loss: 0.3795 - val_loss: 0.0483\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 407us/step - loss: 0.0503 - val_loss: 0.0212\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 408us/step - loss: 0.0132 - val_loss: 0.0121\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 405us/step - loss: 0.0071 - val_loss: 0.0093\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 409us/step - loss: 0.0040 - val_loss: 0.0016\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 409us/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 408us/step - loss: 0.0024 - val_loss: 0.0013\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 407us/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 412us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 406us/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 408us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 407us/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 408us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 407us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 412us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 408us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 407us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 407us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 411us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 408us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 406us/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 407us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 407us/step - loss: 0.0015 - val_loss: 9.8687e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 407us/step - loss: 0.0015 - val_loss: 9.5895e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 5s 1ms/step - loss: 0.2132 - val_loss: 0.0123\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 407us/step - loss: 0.0230 - val_loss: 0.0019\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 410us/step - loss: 0.0091 - val_loss: 0.0033\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 406us/step - loss: 0.0069 - val_loss: 0.0040\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 407us/step - loss: 0.0042 - val_loss: 0.0083\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 407us/step - loss: 0.0033 - val_loss: 0.0022\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 406us/step - loss: 0.0027 - val_loss: 0.0016\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 408us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 407us/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 407us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 407us/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 407us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 407us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 413us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 406us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 405us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 407us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 410us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 411us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 408us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 408us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 411us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 407us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 406us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 6s 1ms/step - loss: 0.2010 - val_loss: 0.0031\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 510us/step - loss: 0.0081 - val_loss: 0.0017\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 0.0055 - val_loss: 0.0019\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 511us/step - loss: 0.0044 - val_loss: 0.0022\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 511us/step - loss: 0.0041 - val_loss: 0.0022\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 511us/step - loss: 0.0040 - val_loss: 0.0021\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 0.0037 - val_loss: 0.0023\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 510us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 0.0036 - val_loss: 0.0022\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 0.0035 - val_loss: 0.0021\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 0.0035 - val_loss: 0.0021\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 511us/step - loss: 0.0034 - val_loss: 0.0021\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 0.0035 - val_loss: 0.0023\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 510us/step - loss: 0.0035 - val_loss: 0.0023\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 511us/step - loss: 0.0032 - val_loss: 0.0018\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 510us/step - loss: 0.0033 - val_loss: 0.0020\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 509us/step - loss: 0.0032 - val_loss: 0.0022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 510us/step - loss: 0.0031 - val_loss: 0.0019\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 0.0031 - val_loss: 0.0022\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 0.0031 - val_loss: 0.0020\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 511us/step - loss: 0.0031 - val_loss: 0.0018\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 6s 1ms/step - loss: 0.3605 - val_loss: 0.0028\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 451us/step - loss: 0.0087 - val_loss: 0.0018\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 450us/step - loss: 0.0060 - val_loss: 0.0020\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 452us/step - loss: 0.0050 - val_loss: 0.0020\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 451us/step - loss: 0.0049 - val_loss: 0.0020\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 450us/step - loss: 0.0048 - val_loss: 0.0025\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 452us/step - loss: 0.0045 - val_loss: 0.0024\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 455us/step - loss: 0.0045 - val_loss: 0.0023\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 455us/step - loss: 0.0042 - val_loss: 0.0022\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 457us/step - loss: 0.0043 - val_loss: 0.0019\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 451us/step - loss: 0.0042 - val_loss: 0.0024\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 452us/step - loss: 0.0040 - val_loss: 0.0022\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 453us/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 452us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 452us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 453us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 453us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 451us/step - loss: 0.0037 - val_loss: 0.0023\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 456us/step - loss: 0.0038 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 452us/step - loss: 0.0037 - val_loss: 0.0022\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 449us/step - loss: 0.0037 - val_loss: 0.0018\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 452us/step - loss: 0.0035 - val_loss: 0.0020\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 451us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 450us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 5s 1ms/step - loss: 0.3616 - val_loss: 0.0038\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 360us/step - loss: 0.0103 - val_loss: 0.0024\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 361us/step - loss: 0.0073 - val_loss: 0.0024\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 361us/step - loss: 0.0064 - val_loss: 0.0024\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 360us/step - loss: 0.0064 - val_loss: 0.0026\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 361us/step - loss: 0.0060 - val_loss: 0.0024\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 361us/step - loss: 0.0058 - val_loss: 0.0024\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 362us/step - loss: 0.0053 - val_loss: 0.0024\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 364us/step - loss: 0.0056 - val_loss: 0.0025\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 362us/step - loss: 0.0055 - val_loss: 0.0024\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 362us/step - loss: 0.0053 - val_loss: 0.0024\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 363us/step - loss: 0.0054 - val_loss: 0.0025\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 362us/step - loss: 0.0051 - val_loss: 0.0026\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 361us/step - loss: 0.0051 - val_loss: 0.0024\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 362us/step - loss: 0.0048 - val_loss: 0.0026\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 362us/step - loss: 0.0048 - val_loss: 0.0026\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 362us/step - loss: 0.0050 - val_loss: 0.0027\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 365us/step - loss: 0.0048 - val_loss: 0.0026\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 361us/step - loss: 0.0047 - val_loss: 0.0023\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 366us/step - loss: 0.0045 - val_loss: 0.0022\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 362us/step - loss: 0.0046 - val_loss: 0.0024\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 363us/step - loss: 0.0045 - val_loss: 0.0026\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 361us/step - loss: 0.0044 - val_loss: 0.0024\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 361us/step - loss: 0.0045 - val_loss: 0.0028\n",
      "\n",
      "GENERATION 4\n",
      "\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 6s 2ms/step - loss: 0.0798 - val_loss: 0.0031\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 491us/step - loss: 0.0075 - val_loss: 0.0090\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 491us/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 491us/step - loss: 0.0025 - val_loss: 0.0043\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 494us/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 491us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 494us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 495us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 492us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 491us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 491us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 491us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 495us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 500us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 494us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 497us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 492us/step - loss: 9.9726e-04 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 492us/step - loss: 9.7431e-04 - val_loss: 9.5784e-04\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 492us/step - loss: 9.5587e-04 - val_loss: 9.6105e-04\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 493us/step - loss: 9.4952e-04 - val_loss: 9.2605e-04\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 497us/step - loss: 9.4362e-04 - val_loss: 9.5632e-04\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 493us/step - loss: 9.2997e-04 - val_loss: 9.3383e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 494us/step - loss: 9.2479e-04 - val_loss: 9.3600e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 496us/step - loss: 9.2304e-04 - val_loss: 9.6566e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 6s 2ms/step - loss: 0.0822 - val_loss: 0.0037\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0103 - val_loss: 0.0114\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 494us/step - loss: 0.0061 - val_loss: 0.0100\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 491us/step - loss: 0.0031 - val_loss: 0.0025\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 492us/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 496us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 492us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 491us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 495us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 491us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 491us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 491us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 491us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 491us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 493us/step - loss: 9.8673e-04 - val_loss: 0.0010\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 493us/step - loss: 9.7289e-04 - val_loss: 9.8186e-04\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 492us/step - loss: 9.5646e-04 - val_loss: 0.0010\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 496us/step - loss: 9.6288e-04 - val_loss: 9.3935e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 491us/step - loss: 9.3171e-04 - val_loss: 9.3002e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 491us/step - loss: 9.2023e-04 - val_loss: 9.4164e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 6s 2ms/step - loss: 0.0338 - val_loss: 0.0066\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 0.0141 - val_loss: 0.0045\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 0.0093 - val_loss: 0.0026\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 0.0064 - val_loss: 0.0022\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 0.0050 - val_loss: 0.0020\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 0.0042 - val_loss: 0.0020\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0040 - val_loss: 0.0021\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0038 - val_loss: 0.0024\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 0.0037 - val_loss: 0.0024\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 0.0037 - val_loss: 0.0023\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0036 - val_loss: 0.0024\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 511us/step - loss: 0.0034 - val_loss: 0.0025\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 0.0034 - val_loss: 0.0025\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0034 - val_loss: 0.0025\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 0.0033 - val_loss: 0.0025\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 0.0034 - val_loss: 0.0025\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 511us/step - loss: 0.0033 - val_loss: 0.0024\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 0.0033 - val_loss: 0.0025\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 6s 2ms/step - loss: 0.1476 - val_loss: 0.0017\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 0.0068 - val_loss: 0.0144\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 0.0072 - val_loss: 0.0263\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 0.0105 - val_loss: 0.0180\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0123 - val_loss: 0.0131\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 0.0125 - val_loss: 0.0246\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 0.0141 - val_loss: 0.0098\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 0.0076 - val_loss: 0.0183\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 0.0110 - val_loss: 0.0245\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0105 - val_loss: 0.0094\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 0.0066 - val_loss: 0.0178\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 0.0137 - val_loss: 0.0219\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0048 - val_loss: 0.0032\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0070 - val_loss: 0.0166\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0093 - val_loss: 0.0081\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 0.0046 - val_loss: 0.0128\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 0.0082 - val_loss: 0.0280\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 0.0083 - val_loss: 0.0020\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 0.0038 - val_loss: 0.0135\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 0.0058 - val_loss: 0.0103\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 0.0066 - val_loss: 0.0136\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 0.0054 - val_loss: 0.0030\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0045 - val_loss: 0.0095\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 0.0065 - val_loss: 0.0046\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 7s 2ms/step - loss: 0.1584 - val_loss: 0.0018\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 0.0044 - val_loss: 0.0230\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0100 - val_loss: 0.0128\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0113 - val_loss: 0.0118\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0098 - val_loss: 0.0158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 0.0110 - val_loss: 0.0163\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 0.0105 - val_loss: 0.0128\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0105 - val_loss: 0.0244\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 0.0131 - val_loss: 0.0035\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 0.0053 - val_loss: 0.0176\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 0.0134 - val_loss: 0.0060\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0039 - val_loss: 0.0115\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 0.0100 - val_loss: 0.0109\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 0.0076 - val_loss: 0.0040\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0054 - val_loss: 0.0138\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 0.0100 - val_loss: 0.0053\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 0.0034 - val_loss: 0.0155\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 0.0079 - val_loss: 0.0081\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0058 - val_loss: 0.0067\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 0.0051 - val_loss: 0.0149\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 0.0076 - val_loss: 0.0034\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 0.0036 - val_loss: 0.0140\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 0.0052 - val_loss: 0.0077\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 0.0065 - val_loss: 0.0120\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 7s 2ms/step - loss: 0.1757 - val_loss: 0.0018\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 0.0054 - val_loss: 0.0042\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 0.0094 - val_loss: 0.0050\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 0.0093 - val_loss: 0.0141\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 0.0113 - val_loss: 0.0145\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 0.0120 - val_loss: 0.0119\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 0.0107 - val_loss: 0.0237\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0112 - val_loss: 0.0178\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 0.0143 - val_loss: 0.0106\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0084 - val_loss: 0.0070\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 0.0096 - val_loss: 0.0176\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0107 - val_loss: 0.0029\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 0.0073 - val_loss: 0.0154\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 0.0083 - val_loss: 0.0112\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 0.0090 - val_loss: 0.0035\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 0.0057 - val_loss: 0.0052\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 0.0102 - val_loss: 0.0077\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0054 - val_loss: 0.0029\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 0.0057 - val_loss: 0.0108\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0075 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0047 - val_loss: 0.0089\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 0.0072 - val_loss: 0.0043\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0045 - val_loss: 0.0058\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 0.0074 - val_loss: 0.0046\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 7s 2ms/step - loss: 0.4637 - val_loss: 0.0015\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 0.0046 - val_loss: 0.0020\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 0.0131 - val_loss: 0.0015\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 0.0081 - val_loss: 0.0281\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 0.0123 - val_loss: 0.0066\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0155 - val_loss: 0.0102\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 0.0131 - val_loss: 0.0470\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 0.0251 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 0.0030 - val_loss: 0.0060\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 0.0197 - val_loss: 0.0311\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 0.0101 - val_loss: 0.0015\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 0.0091 - val_loss: 0.0055\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 0.0098 - val_loss: 0.0661\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 0.0166 - val_loss: 0.0013\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 0.0044 - val_loss: 0.0165\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 0.0103 - val_loss: 0.0148\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0095 - val_loss: 0.0031\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 0.0056 - val_loss: 0.0089\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 0.0140 - val_loss: 0.0111\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 0.0038 - val_loss: 9.2845e-04\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 0.0072 - val_loss: 0.0052\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 0.0057 - val_loss: 0.0087\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 0.0108 - val_loss: 0.0048\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 7s 2ms/step - loss: 0.1699 - val_loss: 0.0019\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 0.0070 - val_loss: 0.0645\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 0.0093 - val_loss: 0.0140\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0128 - val_loss: 0.0125\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0106 - val_loss: 0.0153\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 0.0133 - val_loss: 0.0130\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 0.0130 - val_loss: 0.0132\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 0.0129 - val_loss: 0.0233\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 0.0171 - val_loss: 0.0059\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 0.0067 - val_loss: 0.0146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 0.0103 - val_loss: 0.0183\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 0.0111 - val_loss: 0.0161\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 0.0084 - val_loss: 0.0092\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 0.0071 - val_loss: 0.0081\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0130 - val_loss: 0.0041\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 0.0022 - val_loss: 0.0082\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 0.0100 - val_loss: 0.0074\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 0.0058 - val_loss: 0.0114\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 0.0091 - val_loss: 0.0098\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 0.0043 - val_loss: 0.0094\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 0.0064 - val_loss: 0.0183\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 0.0084 - val_loss: 0.0032\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 0.0043 - val_loss: 0.0103\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 0.0057 - val_loss: 0.0107\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 7s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: nan - val_loss: nan\n",
      "\n",
      "GENERATION 5\n",
      "\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 7s 2ms/step - loss: 0.0410 - val_loss: 0.0177\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 493us/step - loss: 0.0101 - val_loss: 0.0029\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 496us/step - loss: 0.0063 - val_loss: 0.0056\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 492us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 491us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 496us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 493us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 492us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 494us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 492us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 492us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 493us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 492us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 493us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 498us/step - loss: 9.9804e-04 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 493us/step - loss: 9.6111e-04 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 494us/step - loss: 9.4279e-04 - val_loss: 9.7437e-04\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 493us/step - loss: 9.4905e-04 - val_loss: 0.0010\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 492us/step - loss: 9.0874e-04 - val_loss: 9.4692e-04\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 493us/step - loss: 8.9754e-04 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 493us/step - loss: 8.8303e-04 - val_loss: 9.5125e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 493us/step - loss: 8.4146e-04 - val_loss: 8.3491e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 495us/step - loss: 8.6385e-04 - val_loss: 0.0015\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 7s 2ms/step - loss: 0.0518 - val_loss: 0.0199\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 496us/step - loss: 0.0090 - val_loss: 0.0015\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 494us/step - loss: 0.0035 - val_loss: 0.0026\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 496us/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 492us/step - loss: 0.0018 - val_loss: 0.0034\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 494us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 495us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 493us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 496us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 493us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 492us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 493us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 492us/step - loss: 0.0010 - val_loss: 9.9958e-04\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 493us/step - loss: 9.8061e-04 - val_loss: 9.8325e-04\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 495us/step - loss: 9.6605e-04 - val_loss: 9.6438e-04\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 494us/step - loss: 9.4946e-04 - val_loss: 0.0010\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 499us/step - loss: 9.6821e-04 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 495us/step - loss: 9.4705e-04 - val_loss: 9.0406e-04\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 493us/step - loss: 9.0433e-04 - val_loss: 8.8271e-04\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 494us/step - loss: 8.8958e-04 - val_loss: 8.6573e-04\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 494us/step - loss: 8.9053e-04 - val_loss: 8.8022e-04\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 495us/step - loss: 8.7462e-04 - val_loss: 8.3985e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 497us/step - loss: 8.5409e-04 - val_loss: 8.2401e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 493us/step - loss: 8.5052e-04 - val_loss: 8.5765e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 7s 2ms/step - loss: 0.0535 - val_loss: 0.0018\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 311us/step - loss: 0.0084 - val_loss: 0.0073\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 308us/step - loss: 0.0056 - val_loss: 0.0064\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 307us/step - loss: 0.0031 - val_loss: 0.0048\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 304us/step - loss: 0.0025 - val_loss: 0.0014\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 304us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 304us/step - loss: 0.0018 - val_loss: 0.0030\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 305us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 303us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 305us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 303us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 305us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 305us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 306us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 303us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 308us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 308us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 305us/step - loss: 9.9692e-04 - val_loss: 0.0010\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 304us/step - loss: 9.9431e-04 - val_loss: 9.9246e-04\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 304us/step - loss: 9.7461e-04 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 305us/step - loss: 9.5885e-04 - val_loss: 0.0010\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 314us/step - loss: 9.4929e-04 - val_loss: 9.5443e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 303us/step - loss: 9.1525e-04 - val_loss: 9.2362e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 305us/step - loss: 9.0340e-04 - val_loss: 9.0764e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 7s 2ms/step - loss: 0.0567 - val_loss: 0.0071\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 0.0156 - val_loss: 0.0042\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 0.0094 - val_loss: 0.0030\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 0.0059 - val_loss: 0.0022\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 0.0040 - val_loss: 0.0020\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 0.0030 - val_loss: 0.0019\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 511us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 8s 2ms/step - loss: 424611.5286 - val_loss: 193.0525\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 196.4198 - val_loss: 221.5316\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 189.3190 - val_loss: 185.8750\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 148.6255 - val_loss: 138.1889\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 112.7180 - val_loss: 100.3146\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 89.9818 - val_loss: 76.2757\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 75.5268 - val_loss: 60.9716\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 63.8017 - val_loss: 49.1789\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 51.8736 - val_loss: 38.0158\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 37.6608 - val_loss: 25.7429\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 19.7023 - val_loss: 11.0339\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 4.7010 - val_loss: 0.7210\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 4.6982 - val_loss: 0.6073\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 1.4050 - val_loss: 1.6697\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.8499 - val_loss: 0.6084\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 0.2514 - val_loss: 0.0087\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 0.1974 - val_loss: 0.0153\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 0.0983 - val_loss: 0.0793\n",
      "Epoch 19/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0938 - val_loss: 0.0248\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 0.0769 - val_loss: 0.0108\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 0.0746 - val_loss: 0.0153\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0704 - val_loss: 0.0191\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0677 - val_loss: 0.0126\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0647 - val_loss: 0.0127\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 8s 2ms/step - loss: 0.0880 - val_loss: 0.0492\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 545us/step - loss: 0.0180 - val_loss: 0.0119\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 537us/step - loss: 0.0080 - val_loss: 0.0056\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 539us/step - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 541us/step - loss: 0.0034 - val_loss: 0.0021\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 546us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 540us/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 540us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 537us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 542us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 536us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 539us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 539us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 540us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 539us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 542us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 539us/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 8s 2ms/step - loss: 0.1028 - val_loss: 0.0929\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.0367 - val_loss: 0.0026\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 543us/step - loss: 0.0117 - val_loss: 0.0021\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 540us/step - loss: 0.0072 - val_loss: 0.0036\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.0033 - val_loss: 0.0019\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 537us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 539us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 539us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 543us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 537us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 540us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 541us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 539us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 540us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 540us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 540us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 540us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 539us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 536us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 9s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 541us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 537us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 537us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 539us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 542us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 539us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 537us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 541us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 536us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 540us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 544us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 537us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 537us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 537us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 539us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 542us/step - loss: nan - val_loss: nan\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 8s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 539us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 540us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 539us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 539us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 543us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 539us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 541us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 540us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 539us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 542us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 539us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 540us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 540us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 540us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 536us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 540us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 546us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 542us/step - loss: nan - val_loss: nan\n",
      "\n",
      "GENERATION 6\n",
      "\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 9s 2ms/step - loss: 0.7664 - val_loss: 0.1065\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 0.0628 - val_loss: 0.0045\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 0.0134 - val_loss: 0.0013\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 0.0087 - val_loss: 0.0015\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 0.0066 - val_loss: 0.0027\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 0.0046 - val_loss: 0.0014\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 0.0040 - val_loss: 0.0016\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 0.0037 - val_loss: 0.0015\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 0.0035 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0034 - val_loss: 0.0016\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 0.0030 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 0.0029 - val_loss: 0.0015\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 0.0029 - val_loss: 0.0014\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0028 - val_loss: 0.0014\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 0.0028 - val_loss: 0.0015\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 0.0027 - val_loss: 0.0016\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 0.0028 - val_loss: 0.0015\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 0.0026 - val_loss: 0.0014\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 0.0026 - val_loss: 0.0014\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 0.0024 - val_loss: 0.0013\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 0.0024 - val_loss: 0.0013\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 9s 2ms/step - loss: 0.0667 - val_loss: 0.0039\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 497us/step - loss: 0.0094 - val_loss: 0.0069\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 499us/step - loss: 0.0055 - val_loss: 0.0107\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 496us/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 502us/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 497us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 495us/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 552us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 542us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 508us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 9.9921e-04 - val_loss: 0.0010\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 9.8031e-04 - val_loss: 9.9566e-04\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 9.5942e-04 - val_loss: 9.5979e-04\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 9.4732e-04 - val_loss: 9.3638e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 9.4640e-04 - val_loss: 9.8744e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 535us/step - loss: 9.3492e-04 - val_loss: 9.1833e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 9s 2ms/step - loss: 0.0631 - val_loss: 0.0068\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0087 - val_loss: 0.0015\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0043 - val_loss: 0.0019\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 0.0036 - val_loss: 0.0014\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0025 - val_loss: 0.0031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 0.0015 - val_loss: 9.8074e-04\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0014 - val_loss: 9.6420e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0014 - val_loss: 9.6286e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 9s 2ms/step - loss: 0.2427 - val_loss: 0.0020\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 0.0059 - val_loss: 0.0018\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 0.0179 - val_loss: 0.0016\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0097 - val_loss: 0.0491\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0136 - val_loss: 0.0346\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0162 - val_loss: 0.0188\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0158 - val_loss: 0.0134\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 0.0168 - val_loss: 0.0069\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 0.0096 - val_loss: 0.0181\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 0.0180 - val_loss: 0.0184\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 0.0078 - val_loss: 0.0026\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 0.0127 - val_loss: 0.0245\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 0.0142 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 0.0050 - val_loss: 0.0316\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 0.0113 - val_loss: 0.0077\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 0.0105 - val_loss: 0.0039\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 0.0061 - val_loss: 0.0092\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 0.0155 - val_loss: 0.0020\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 0.0027 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 0.0099 - val_loss: 0.0153\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 0.0049 - val_loss: 0.0028\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 0.0083 - val_loss: 0.0045\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0062 - val_loss: 0.0051\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 0.0083 - val_loss: 0.0035\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 9s 2ms/step - loss: 0.3813 - val_loss: 0.0019\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0066 - val_loss: 0.0076\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 0.0128 - val_loss: 0.0047\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0123 - val_loss: 0.0085\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 0.0144 - val_loss: 0.0187\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 0.0153 - val_loss: 0.0279\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 541us/step - loss: 0.0136 - val_loss: 0.0438\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0233 - val_loss: 0.0301\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 0.0226 - val_loss: 0.0021\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 0.0190 - val_loss: 0.0144\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 0.0142 - val_loss: 0.0050\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0101 - val_loss: 0.0128\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 0.0187 - val_loss: 0.0060\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 539us/step - loss: 0.0052 - val_loss: 0.0036\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 579us/step - loss: 0.0091 - val_loss: 0.0070\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 528us/step - loss: 0.0128 - val_loss: 0.0205\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 545us/step - loss: 0.0072 - val_loss: 0.0057\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0080 - val_loss: 0.0111\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 554us/step - loss: 0.0107 - val_loss: 0.0022\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 0.0040 - val_loss: 0.0155\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 0.0103 - val_loss: 0.0048\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0048 - val_loss: 0.0065\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0093 - val_loss: 0.0145\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 10s 2ms/step - loss: 0.0595 - val_loss: 0.0115\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0107 - val_loss: 0.0022\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 0.0053 - val_loss: 0.0021\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 0.0029 - val_loss: 0.0012\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 0.0020 - val_loss: 0.0012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 0.0016 - val_loss: 9.9282e-04\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 0.0016 - val_loss: 9.8280e-04\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 0.0016 - val_loss: 9.6369e-04\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 0.0014 - val_loss: 9.5416e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 10s 2ms/step - loss: 0.1724 - val_loss: 0.0021\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 0.0173 - val_loss: 0.0142\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 0.0098 - val_loss: 0.0112\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 0.0058 - val_loss: 0.0029\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 0.0041 - val_loss: 0.0024\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 0.0035 - val_loss: 0.0015\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 0.0030 - val_loss: 0.0013\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 0.0028 - val_loss: 0.0018\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0027 - val_loss: 0.0013\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 0.0024 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 9s 2ms/step - loss: 0.1854 - val_loss: 0.0044\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 370us/step - loss: 0.0341 - val_loss: 0.0334\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 368us/step - loss: 0.0136 - val_loss: 0.0063\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 369us/step - loss: 0.0060 - val_loss: 0.0020\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 371us/step - loss: 0.0040 - val_loss: 0.0023\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 369us/step - loss: 0.0036 - val_loss: 0.0033\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 370us/step - loss: 0.0033 - val_loss: 0.0019\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 368us/step - loss: 0.0030 - val_loss: 0.0022\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 371us/step - loss: 0.0029 - val_loss: 0.0019\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 376us/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 368us/step - loss: 0.0027 - val_loss: 0.0020\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 370us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 369us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 369us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 369us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 376us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 372us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 386us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 374us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 382us/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 407us/step - loss: 0.0021 - val_loss: 0.0039\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 374us/step - loss: 0.0021 - val_loss: 0.0034\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 411us/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 412us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 10s 3ms/step - loss: 0.1089 - val_loss: 0.0211\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 506us/step - loss: 0.0188 - val_loss: 0.0195\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 0.0092 - val_loss: 0.0063\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 511us/step - loss: 0.0050 - val_loss: 0.0032\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 501us/step - loss: 0.0032 - val_loss: 0.0019\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 503us/step - loss: 0.0028 - val_loss: 0.0020\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 503us/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 504us/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 503us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 508us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 501us/step - loss: 0.0022 - val_loss: 0.0022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 502us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 502us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 501us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 501us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 501us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 499us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 498us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 504us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "\n",
      "GENERATION 7\n",
      "\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 10s 3ms/step - loss: 0.7719 - val_loss: 0.6780\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 496us/step - loss: 0.3382 - val_loss: 0.3093\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 496us/step - loss: 0.1479 - val_loss: 0.1289\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 500us/step - loss: 0.0794 - val_loss: 0.0511\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 509us/step - loss: 0.0675 - val_loss: 0.0246\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 497us/step - loss: 0.0699 - val_loss: 0.0195\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 498us/step - loss: 0.0701 - val_loss: 0.0236\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 500us/step - loss: 0.0682 - val_loss: 0.0311\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 496us/step - loss: 0.0672 - val_loss: 0.0381\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 496us/step - loss: 0.0670 - val_loss: 0.0413\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 497us/step - loss: 0.0670 - val_loss: 0.0414\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 498us/step - loss: 0.0670 - val_loss: 0.0401\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 501us/step - loss: 0.0670 - val_loss: 0.0387\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 502us/step - loss: 0.0670 - val_loss: 0.0375\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 496us/step - loss: 0.0670 - val_loss: 0.0372\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 506us/step - loss: 0.0670 - val_loss: 0.0378\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 494us/step - loss: 0.0670 - val_loss: 0.0390\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 494us/step - loss: 0.0670 - val_loss: 0.0386\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 501us/step - loss: 0.0670 - val_loss: 0.0385\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 499us/step - loss: 0.0670 - val_loss: 0.0383\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 496us/step - loss: 0.0670 - val_loss: 0.0385\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 501us/step - loss: 0.0670 - val_loss: 0.0378\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 505us/step - loss: 0.0670 - val_loss: 0.0385\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 500us/step - loss: 0.0670 - val_loss: 0.0383\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 10s 3ms/step - loss: 0.0639 - val_loss: 0.0071\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 0.0089 - val_loss: 0.0015\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 502us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 497us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 498us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 511us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 541us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 537us/step - loss: 9.9542e-04 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 9.8473e-04 - val_loss: 0.0010\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 9.5095e-04 - val_loss: 9.4734e-04\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 9.3717e-04 - val_loss: 9.7151e-04\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 9.1911e-04 - val_loss: 9.3481e-04\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 528us/step - loss: 9.1364e-04 - val_loss: 9.0292e-04\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 8.9363e-04 - val_loss: 8.9431e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 8.8586e-04 - val_loss: 8.8728e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 8.7991e-04 - val_loss: 8.5358e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 11s 3ms/step - loss: 0.0599 - val_loss: 0.0071\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 0.0113 - val_loss: 0.0046\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 480us/step - loss: 0.0057 - val_loss: 0.0015\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 0.0042 - val_loss: 0.0055\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 481us/step - loss: 0.0034 - val_loss: 0.0022\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 480us/step - loss: 0.0031 - val_loss: 0.0016\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 483us/step - loss: 0.0028 - val_loss: 0.0017\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 483us/step - loss: 0.0027 - val_loss: 0.0015\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0026 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 482us/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 482us/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 483us/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 494us/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 494us/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 493us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 485us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 484us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 480us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 483us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 11s 3ms/step - loss: 0.0488 - val_loss: 0.0242\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0093 - val_loss: 0.0105\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 480us/step - loss: 0.0055 - val_loss: 0.0013\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 485us/step - loss: 0.0037 - val_loss: 0.0013\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 483us/step - loss: 0.0033 - val_loss: 0.0028\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 484us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 482us/step - loss: 0.0027 - val_loss: 0.0021\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 481us/step - loss: 0.0026 - val_loss: 0.0014\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 483us/step - loss: 0.0024 - val_loss: 0.0013\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 485us/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 481us/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 481us/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 481us/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 481us/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 492us/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 485us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 483us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 482us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 483us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 481us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 484us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 11s 3ms/step - loss: 0.0589 - val_loss: 0.0015\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 363us/step - loss: 0.0103 - val_loss: 0.0084\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 362us/step - loss: 0.0074 - val_loss: 0.0041\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 361us/step - loss: 0.0049 - val_loss: 0.0048\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 365us/step - loss: 0.0040 - val_loss: 0.0013\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 359us/step - loss: 0.0038 - val_loss: 0.0017\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 363us/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 364us/step - loss: 0.0031 - val_loss: 0.0025\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 362us/step - loss: 0.0031 - val_loss: 0.0016\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 360us/step - loss: 0.0028 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 364us/step - loss: 0.0027 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 362us/step - loss: 0.0027 - val_loss: 0.0015\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 365us/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 361us/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 360us/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 366us/step - loss: 0.0023 - val_loss: 0.0013\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 362us/step - loss: 0.0023 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 364us/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 365us/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 361us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 360us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 361us/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 360us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 359us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 11s 3ms/step - loss: 0.0547 - val_loss: 0.0018\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 359us/step - loss: 0.0105 - val_loss: 0.0083\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 359us/step - loss: 0.0051 - val_loss: 0.0017\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 360us/step - loss: 0.0034 - val_loss: 0.0072\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 358us/step - loss: 0.0028 - val_loss: 0.0015\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 359us/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 358us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 360us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 365us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 358us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 361us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 358us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 361us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 360us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 360us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 359us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 359us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 359us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 359us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 365us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 363us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 359us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 360us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 360us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 11s 3ms/step - loss: 0.0439 - val_loss: 0.0300\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 362us/step - loss: 0.0125 - val_loss: 0.0118\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 358us/step - loss: 0.0054 - val_loss: 0.0021\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 357us/step - loss: 0.0033 - val_loss: 0.0025\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 357us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 358us/step - loss: 0.0024 - val_loss: 0.0014\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 357us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 358us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 359us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 358us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 358us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 358us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 363us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 357us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 357us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 357us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 358us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 359us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 358us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 358us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 358us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 362us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 357us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 361us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 12s 3ms/step - loss: 0.0760 - val_loss: 0.0412\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0142 - val_loss: 0.0131\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 0.0064 - val_loss: 0.0053\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0036 - val_loss: 0.0049\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0026 - val_loss: 0.0013\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 485us/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 484us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 484us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 484us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 484us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 483us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 484us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 484us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 484us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 484us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 484us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 484us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 483us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 12s 3ms/step - loss: 0.7252 - val_loss: 0.6545\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.3281 - val_loss: 0.3002\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.1451 - val_loss: 0.1282\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 485us/step - loss: 0.0804 - val_loss: 0.0545\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0675 - val_loss: 0.0282\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0689 - val_loss: 0.0217\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 0.0695 - val_loss: 0.0238\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 485us/step - loss: 0.0683 - val_loss: 0.0297\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0673 - val_loss: 0.0358\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0670 - val_loss: 0.0399\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 491us/step - loss: 0.0670 - val_loss: 0.0410\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0670 - val_loss: 0.0403\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 0.0670 - val_loss: 0.0392\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0670 - val_loss: 0.0382\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0670 - val_loss: 0.0378\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 0.0670 - val_loss: 0.0377\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0670 - val_loss: 0.0380\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0670 - val_loss: 0.0385\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0670 - val_loss: 0.0382\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0670 - val_loss: 0.0382\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0670 - val_loss: 0.0385\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0670 - val_loss: 0.0381\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0670 - val_loss: 0.0384\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 0.0670 - val_loss: 0.0379\n",
      "\n",
      "GENERATION 8\n",
      "\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 12s 3ms/step - loss: 0.0701 - val_loss: 0.0214\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 0.0088 - val_loss: 0.0072\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0049 - val_loss: 0.0018\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 0.0027 - val_loss: 0.0017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 528us/step - loss: 0.0015 - val_loss: 0.0055\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 0.0014 - val_loss: 0.0064\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 0.0013 - val_loss: 0.0071\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 13s 3ms/step - loss: 0.0658 - val_loss: 0.0066\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 498us/step - loss: 0.0103 - val_loss: 0.0055\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 498us/step - loss: 0.0045 - val_loss: 0.0017\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 499us/step - loss: 0.0035 - val_loss: 0.0063\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 499us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 500us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 502us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 498us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 498us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 499us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 504us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 505us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 499us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 502us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 503us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 498us/step - loss: 9.9858e-04 - val_loss: 0.0010\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 499us/step - loss: 9.9055e-04 - val_loss: 0.0010\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 501us/step - loss: 9.7464e-04 - val_loss: 9.7505e-04\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 498us/step - loss: 9.6325e-04 - val_loss: 9.7322e-04\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 499us/step - loss: 9.4554e-04 - val_loss: 9.4755e-04\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 498us/step - loss: 9.2896e-04 - val_loss: 9.3025e-04\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 498us/step - loss: 9.3911e-04 - val_loss: 0.0010\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 503us/step - loss: 9.4095e-04 - val_loss: 9.5391e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 498us/step - loss: 9.0207e-04 - val_loss: 9.5708e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 13s 3ms/step - loss: 0.1262 - val_loss: 0.0016\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0093 - val_loss: 0.0538\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0095 - val_loss: 0.0025\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 528us/step - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 0.0025 - val_loss: 0.0042\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0069 - val_loss: 0.0119\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0051 - val_loss: 0.0068\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0052 - val_loss: 0.0083\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 0.0036 - val_loss: 0.0051\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0043 - val_loss: 0.0085\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 0.0051 - val_loss: 0.0084\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0051 - val_loss: 0.0081\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 0.0032 - val_loss: 0.0045\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0037 - val_loss: 0.0145\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 0.0034 - val_loss: 0.0071\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 0.0029 - val_loss: 0.0053\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 0.0035 - val_loss: 0.0069\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 0.0044 - val_loss: 0.0073\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0051 - val_loss: 0.0055\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0025 - val_loss: 0.0045\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 13s 3ms/step - loss: 0.1079 - val_loss: 0.0016\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0035 - val_loss: 0.0041\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 0.0065 - val_loss: 0.0044\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0037 - val_loss: 0.0066\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 0.0044 - val_loss: 0.0074\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0080 - val_loss: 0.0079\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 0.0039 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0024 - val_loss: 0.0041\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0055 - val_loss: 0.0052\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 0.0048 - val_loss: 0.0029\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0026 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0037 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0039 - val_loss: 0.0025\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 14s 3ms/step - loss: 0.1717 - val_loss: 0.0019\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 0.0040 - val_loss: 0.0016\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0058 - val_loss: 0.0048\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 0.0050 - val_loss: 0.0026\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0048 - val_loss: 0.0016\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 0.0033 - val_loss: 0.0014\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0026 - val_loss: 0.0015\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0045 - val_loss: 0.0021\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 0.0040 - val_loss: 0.0017\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0053 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 529us/step - loss: 0.0023 - val_loss: 0.0058\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0059 - val_loss: 0.0060\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 0.0028 - val_loss: 0.0015\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0033 - val_loss: 0.0039\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 0.0031 - val_loss: 0.0014\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 0.0025 - val_loss: 0.0012\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 14s 3ms/step - loss: 0.0579 - val_loss: 0.0029\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0207 - val_loss: 0.0020\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0051 - val_loss: 0.0031\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 0.0027 - val_loss: 0.0108\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0255 - val_loss: 0.0039\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 0.0057 - val_loss: 0.0043\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0039 - val_loss: 0.0148\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0019 - val_loss: 0.0113\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 0.0052 - val_loss: 0.0054\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0017 - val_loss: 0.0033\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0031 - val_loss: 0.0118\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 0.0038 - val_loss: 0.0082\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 0.0021 - val_loss: 0.0055\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 528us/step - loss: 0.0025 - val_loss: 0.0089\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0034 - val_loss: 0.0066\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0015 - val_loss: 0.0052\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 14s 4ms/step - loss: 0.0628 - val_loss: 0.0166\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 416us/step - loss: 0.0110 - val_loss: 0.0028\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 417us/step - loss: 0.0114 - val_loss: 0.0053\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 417us/step - loss: 0.0049 - val_loss: 0.0024\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 423us/step - loss: 0.0044 - val_loss: 0.0184\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 418us/step - loss: 0.0064 - val_loss: 0.0016\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 418us/step - loss: 0.0028 - val_loss: 0.0016\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 417us/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 418us/step - loss: 0.0046 - val_loss: 0.0017\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 419us/step - loss: 0.0025 - val_loss: 0.0015\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 418us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 418us/step - loss: 0.0046 - val_loss: 0.0025\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 416us/step - loss: 0.0032 - val_loss: 0.0014\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 420us/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 15/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 2s 431us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 429us/step - loss: 0.0053 - val_loss: 0.0015\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 422us/step - loss: 0.0028 - val_loss: 0.0019\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 417us/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 419us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 418us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 419us/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 418us/step - loss: 0.0027 - val_loss: 0.0014\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 417us/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 421us/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 15s 4ms/step - loss: 0.1507 - val_loss: 0.0155\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 549us/step - loss: 0.0972 - val_loss: 0.0304\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 548us/step - loss: 0.0245 - val_loss: 0.0025\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 550us/step - loss: 0.0044 - val_loss: 0.0023\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 550us/step - loss: 0.0030 - val_loss: 0.0024\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 554us/step - loss: 0.0084 - val_loss: 0.0108\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 552us/step - loss: 0.0057 - val_loss: 0.0020\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 555us/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 550us/step - loss: 0.0053 - val_loss: 0.0092\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 548us/step - loss: 0.0061 - val_loss: 0.0019\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 549us/step - loss: 0.0027 - val_loss: 0.0020\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 550us/step - loss: 0.0047 - val_loss: 0.0111\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 563us/step - loss: 0.0057 - val_loss: 0.0027\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 549us/step - loss: 0.0031 - val_loss: 0.0016\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 552us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 551us/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 554us/step - loss: 0.0048 - val_loss: 0.0042\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 549us/step - loss: 0.0039 - val_loss: 0.0016\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 549us/step - loss: 0.0031 - val_loss: 0.0077\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 554us/step - loss: 0.0058 - val_loss: 0.0052\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 549us/step - loss: 0.0040 - val_loss: 0.0026\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 550us/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 553us/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 547us/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 15s 4ms/step - loss: 0.0700 - val_loss: 0.0318\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 551us/step - loss: 0.0129 - val_loss: 0.0029\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 549us/step - loss: 0.0058 - val_loss: 0.0105\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 547us/step - loss: 0.0036 - val_loss: 0.0026\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 549us/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 552us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 547us/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 549us/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 553us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 551us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 549us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 549us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 548us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 550us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 552us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 547us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 547us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 550us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 549us/step - loss: 0.0013 - val_loss: 9.9368e-04\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 549us/step - loss: 0.0013 - val_loss: 9.6561e-04\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 549us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 549us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 553us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 549us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "\n",
      "GENERATION 9\n",
      "\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 14s 4ms/step - loss: 0.0666 - val_loss: 0.0115\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 500us/step - loss: 0.0071 - val_loss: 0.0013\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 498us/step - loss: 0.0039 - val_loss: 0.0028\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 502us/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 502us/step - loss: 0.0019 - val_loss: 0.0035\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 500us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 500us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 499us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 498us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 498us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 501us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 501us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 506us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 499us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 500us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 502us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 505us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 506us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 502us/step - loss: 9.9204e-04 - val_loss: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 502us/step - loss: 9.7670e-04 - val_loss: 0.0010\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 505us/step - loss: 9.5948e-04 - val_loss: 9.5784e-04\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 499us/step - loss: 9.4677e-04 - val_loss: 9.3579e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 501us/step - loss: 9.3662e-04 - val_loss: 9.4021e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 503us/step - loss: 9.3026e-04 - val_loss: 9.7711e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 15s 4ms/step - loss: 0.0805 - val_loss: 0.0073\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 501us/step - loss: 0.0097 - val_loss: 0.0074\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 504us/step - loss: 0.0063 - val_loss: 0.0122\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 510us/step - loss: 0.0036 - val_loss: 0.0026\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 505us/step - loss: 0.0025 - val_loss: 0.0015\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 507us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 502us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 501us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 501us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 501us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 503us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 500us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 505us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 502us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 501us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 501us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 499us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 502us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 504us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 501us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 505us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 500us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 499us/step - loss: 9.7690e-04 - val_loss: 9.6763e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 499us/step - loss: 9.5953e-04 - val_loss: 9.5764e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 15s 4ms/step - loss: 0.0627 - val_loss: 0.0129\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 460us/step - loss: 0.0089 - val_loss: 0.0021\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 459us/step - loss: 0.0050 - val_loss: 0.0017\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 461us/step - loss: 0.0036 - val_loss: 0.0043\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 463us/step - loss: 0.0024 - val_loss: 0.0045\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 462us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 461us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 466us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 463us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 459us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 460us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 459us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 460us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 465us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 459us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 459us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 458us/step - loss: 9.9843e-04 - val_loss: 0.0010\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 461us/step - loss: 9.5744e-04 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 460us/step - loss: 9.5468e-04 - val_loss: 0.0010\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 461us/step - loss: 9.6424e-04 - val_loss: 9.5806e-04\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 464us/step - loss: 9.8405e-04 - val_loss: 0.0013\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 463us/step - loss: 0.0010 - val_loss: 9.4012e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 462us/step - loss: 9.0956e-04 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 459us/step - loss: 9.1434e-04 - val_loss: 8.5987e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 15s 4ms/step - loss: 0.0664 - val_loss: 0.0162\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 471us/step - loss: 0.0089 - val_loss: 0.0026\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 462us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 461us/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 477us/step - loss: 0.0027 - val_loss: 0.0013\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 459us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 462us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 460us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 460us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 462us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 462us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 462us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 461us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 460us/step - loss: 9.9696e-04 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 463us/step - loss: 9.8712e-04 - val_loss: 0.0010\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 479us/step - loss: 9.6848e-04 - val_loss: 0.0010\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 470us/step - loss: 9.5849e-04 - val_loss: 9.8407e-04\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 473us/step - loss: 9.2510e-04 - val_loss: 9.7175e-04\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 460us/step - loss: 9.0847e-04 - val_loss: 9.2073e-04\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 460us/step - loss: 8.9523e-04 - val_loss: 9.2379e-04\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 460us/step - loss: 8.8231e-04 - val_loss: 9.1203e-04\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 461us/step - loss: 8.7811e-04 - val_loss: 9.2141e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 477us/step - loss: 9.1404e-04 - val_loss: 0.0013\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 466us/step - loss: 9.1074e-04 - val_loss: 9.1569e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 15s 4ms/step - loss: 0.3341 - val_loss: 0.0099\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 399us/step - loss: 0.0161 - val_loss: 0.0037\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0075 - val_loss: 0.0281\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0069 - val_loss: 0.0032\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 406us/step - loss: 0.0032 - val_loss: 0.0019\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 401us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 402us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 401us/step - loss: 0.0024 - val_loss: 0.0065\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0030 - val_loss: 0.0048\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 398us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 401us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 401us/step - loss: 0.0028 - val_loss: 0.0017\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 401us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 402us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0019 - val_loss: 0.0032\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 402us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 402us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0028 - val_loss: 0.0045\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 401us/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 15s 4ms/step - loss: 0.4439 - val_loss: 0.0089\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 421us/step - loss: 0.0168 - val_loss: 0.0023\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 421us/step - loss: 0.0092 - val_loss: 0.0016\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 422us/step - loss: 0.0058 - val_loss: 0.0017\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 423us/step - loss: 0.0061 - val_loss: 0.0025\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 423us/step - loss: 0.0037 - val_loss: 0.0040\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 421us/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 420us/step - loss: 0.0033 - val_loss: 0.0014\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 422us/step - loss: 0.0049 - val_loss: 0.0017\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 427us/step - loss: 0.0032 - val_loss: 0.0025\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 423us/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 422us/step - loss: 0.0028 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 421us/step - loss: 0.0036 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 425us/step - loss: 0.0031 - val_loss: 0.0015\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 420us/step - loss: 0.0031 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 422us/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 421us/step - loss: 0.0026 - val_loss: 0.0013\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 422us/step - loss: 0.0027 - val_loss: 0.0014\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 421us/step - loss: 0.0027 - val_loss: 0.0022\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 421us/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 420us/step - loss: 0.0026 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 424us/step - loss: 0.0027 - val_loss: 0.0014\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 421us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 425us/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 15s 4ms/step - loss: 6.5430 - val_loss: 0.0045\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 418us/step - loss: 0.0076 - val_loss: 0.0036\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 420us/step - loss: 0.0069 - val_loss: 0.0032\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 418us/step - loss: 0.0067 - val_loss: 0.0032\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 418us/step - loss: 0.0063 - val_loss: 0.0029\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 419us/step - loss: 0.0062 - val_loss: 0.0038\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 417us/step - loss: 0.0060 - val_loss: 0.0030\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 420us/step - loss: 0.0055 - val_loss: 0.0028\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 423us/step - loss: 0.0056 - val_loss: 0.0026\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 418us/step - loss: 0.0053 - val_loss: 0.0028\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 418us/step - loss: 0.0053 - val_loss: 0.0024\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 419us/step - loss: 0.0052 - val_loss: 0.0026\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 419us/step - loss: 0.0050 - val_loss: 0.0029\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 421us/step - loss: 0.0049 - val_loss: 0.0024\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 416us/step - loss: 0.0048 - val_loss: 0.0023\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 419us/step - loss: 0.0046 - val_loss: 0.0025\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 422us/step - loss: 0.0045 - val_loss: 0.0023\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 420us/step - loss: 0.0045 - val_loss: 0.0023\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 419us/step - loss: 0.0044 - val_loss: 0.0024\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 418us/step - loss: 0.0043 - val_loss: 0.0027\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 419us/step - loss: 0.0041 - val_loss: 0.0023\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 420us/step - loss: 0.0042 - val_loss: 0.0024\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 419us/step - loss: 0.0040 - val_loss: 0.0021\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 417us/step - loss: 0.0041 - val_loss: 0.0023\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 17s 4ms/step - loss: 3.0032 - val_loss: 0.0396\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 572us/step - loss: 0.0670 - val_loss: 0.0385\n",
      "Epoch 3/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 2s 574us/step - loss: 0.0670 - val_loss: 0.0364\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 574us/step - loss: 0.0668 - val_loss: 0.0460\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 574us/step - loss: 0.0669 - val_loss: 0.0363\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 574us/step - loss: 0.0664 - val_loss: 0.0338\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 575us/step - loss: 0.0657 - val_loss: 0.0353\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 577us/step - loss: 0.0656 - val_loss: 0.0315\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 572us/step - loss: 0.0637 - val_loss: 0.0497\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 573us/step - loss: 0.0934 - val_loss: 0.0341\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 573us/step - loss: 0.0657 - val_loss: 0.0368\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 572us/step - loss: 0.0657 - val_loss: 0.0366\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 575us/step - loss: 0.0636 - val_loss: 0.0421\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 577us/step - loss: 0.0625 - val_loss: 0.0395\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 577us/step - loss: 0.0633 - val_loss: 0.0320\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 574us/step - loss: 0.0653 - val_loss: 0.0253\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 574us/step - loss: 0.0602 - val_loss: 0.0130\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 574us/step - loss: 0.0602 - val_loss: 0.0724\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 572us/step - loss: 0.0592 - val_loss: 0.0533\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 576us/step - loss: 0.0551 - val_loss: 0.0044\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 574us/step - loss: 0.0673 - val_loss: 0.0343\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 575us/step - loss: 0.0537 - val_loss: 0.0050\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 574us/step - loss: 0.0406 - val_loss: 0.0039\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 574us/step - loss: 0.0139 - val_loss: 0.0934\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 16s 4ms/step - loss: 0.2122 - val_loss: 0.0125\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 494us/step - loss: 0.0518 - val_loss: 0.0315\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0567 - val_loss: 0.2309\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0906 - val_loss: 0.0620\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 0.0451 - val_loss: 0.0779\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 496us/step - loss: 0.0489 - val_loss: 0.0296\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0273 - val_loss: 0.0367\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0289 - val_loss: 0.0220\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 0.0256 - val_loss: 0.0124\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 474us/step - loss: 0.0208 - val_loss: 0.0125\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 481us/step - loss: 0.0142 - val_loss: 0.0087\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 484us/step - loss: 0.0221 - val_loss: 0.0240\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 0.0210 - val_loss: 0.0110\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0179 - val_loss: 0.0072\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 0.0137 - val_loss: 0.0110\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 510us/step - loss: 0.0173 - val_loss: 0.0100\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 506us/step - loss: 0.0178 - val_loss: 0.0159\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 477us/step - loss: 0.0250 - val_loss: 0.0110\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 478us/step - loss: 0.0142 - val_loss: 0.0045\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 474us/step - loss: 0.0094 - val_loss: 0.0060\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 475us/step - loss: 0.0186 - val_loss: 0.0163\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 473us/step - loss: 0.0206 - val_loss: 0.0100\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 473us/step - loss: 0.0150 - val_loss: 0.0057\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 473us/step - loss: 0.0117 - val_loss: 0.0044\n",
      "\n",
      "GENERATION 10\n",
      "\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 16s 4ms/step - loss: 0.0502 - val_loss: 0.0182\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 401us/step - loss: 0.0086 - val_loss: 0.0030\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 408us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 406us/step - loss: 0.0029 - val_loss: 0.0048\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 406us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 401us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 407us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 407us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 404us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 405us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 404us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 403us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 408us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 407us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 404us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 403us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 405us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 404us/step - loss: 0.0010 - val_loss: 9.9823e-04\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 403us/step - loss: 9.8911e-04 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 402us/step - loss: 9.7711e-04 - val_loss: 9.7041e-04\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 405us/step - loss: 9.5254e-04 - val_loss: 9.5815e-04\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 406us/step - loss: 9.5905e-04 - val_loss: 9.3812e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 414us/step - loss: 9.3421e-04 - val_loss: 9.2903e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 416us/step - loss: 9.2373e-04 - val_loss: 9.0962e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 17s 4ms/step - loss: 0.0480 - val_loss: 0.0047\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 510us/step - loss: 0.0074 - val_loss: 0.0018\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 510us/step - loss: 0.0052 - val_loss: 0.0015\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 507us/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 0.0024 - val_loss: 0.0036\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 553us/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 506us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 503us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 505us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 506us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 511us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 503us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 507us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 504us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 503us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 505us/step - loss: 9.9138e-04 - val_loss: 9.8830e-04\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 505us/step - loss: 9.6735e-04 - val_loss: 0.0014\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 502us/step - loss: 9.9404e-04 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 503us/step - loss: 9.5110e-04 - val_loss: 9.2248e-04\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 501us/step - loss: 9.1821e-04 - val_loss: 9.1101e-04\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 509us/step - loss: 8.9813e-04 - val_loss: 8.8875e-04\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 8.7207e-04 - val_loss: 8.7903e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 507us/step - loss: 8.4882e-04 - val_loss: 8.5558e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 503us/step - loss: 8.6772e-04 - val_loss: 9.0386e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 17s 4ms/step - loss: 0.0615 - val_loss: 0.0087\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 507us/step - loss: 0.0081 - val_loss: 0.0015\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 0.0046 - val_loss: 0.0018\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 504us/step - loss: 0.0032 - val_loss: 0.0019\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 508us/step - loss: 0.0022 - val_loss: 0.0033\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 503us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 510us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 503us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 506us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 502us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 509us/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 508us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 505us/step - loss: 9.7865e-04 - val_loss: 0.0010\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 511us/step - loss: 9.6021e-04 - val_loss: 9.7364e-04\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 503us/step - loss: 9.2642e-04 - val_loss: 9.8611e-04\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 502us/step - loss: 9.0779e-04 - val_loss: 9.5222e-04\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 506us/step - loss: 9.0871e-04 - val_loss: 0.0010\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 8.9645e-04 - val_loss: 8.9773e-04\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 507us/step - loss: 8.6800e-04 - val_loss: 8.3852e-04\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 504us/step - loss: 8.3705e-04 - val_loss: 8.9622e-04\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 504us/step - loss: 8.7551e-04 - val_loss: 8.1264e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 503us/step - loss: 8.1841e-04 - val_loss: 9.1064e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 504us/step - loss: 8.4987e-04 - val_loss: 7.8597e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 18s 5ms/step - loss: 0.0816 - val_loss: 0.0214\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 0.0124 - val_loss: 0.0018\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 0.0069 - val_loss: 0.0151\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 0.0049 - val_loss: 0.0024\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 0.0036 - val_loss: 0.0017\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 529us/step - loss: 0.0032 - val_loss: 0.0045\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 528us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 529us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 528us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 18s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 528us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 528us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 2s 524us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 528us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 528us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: nan - val_loss: nan\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 19s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 537us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 528us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 529us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 528us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 528us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 535us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: nan - val_loss: nan\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 19s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 529us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 567us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 550us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 556us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 575us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 567us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 561us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 541us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 528us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: nan - val_loss: nan\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 19s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 549us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 547us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 551us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 549us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 549us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 549us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 560us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 549us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 549us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 547us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 551us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 550us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 549us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 553us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 548us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 549us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 548us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 551us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 547us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 546us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 548us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 547us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 546us/step - loss: nan - val_loss: nan\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 19s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 549us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 548us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 550us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 548us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 545us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 548us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 547us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 549us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 551us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 546us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 551us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 549us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 546us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 547us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 549us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 550us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 548us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 546us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 547us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 548us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 548us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 546us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 551us/step - loss: nan - val_loss: nan\n",
      "\n",
      "GENERATION 11\n",
      "\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 19s 5ms/step - loss: 0.0502 - val_loss: 0.0024\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 506us/step - loss: 0.0085 - val_loss: 0.0017\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 502us/step - loss: 0.0046 - val_loss: 0.0016\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 503us/step - loss: 0.0036 - val_loss: 0.0032\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 503us/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 502us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 508us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 505us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 511us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 509us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 504us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 505us/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 505us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 507us/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 506us/step - loss: 9.9006e-04 - val_loss: 9.4505e-04\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 507us/step - loss: 9.4278e-04 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 508us/step - loss: 9.6241e-04 - val_loss: 0.0010\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 503us/step - loss: 9.4700e-04 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 503us/step - loss: 9.5820e-04 - val_loss: 9.7945e-04\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 505us/step - loss: 8.8847e-04 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 506us/step - loss: 8.8801e-04 - val_loss: 8.3805e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 509us/step - loss: 8.5964e-04 - val_loss: 8.2823e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 508us/step - loss: 8.6627e-04 - val_loss: 8.4199e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 26s 6ms/step - loss: 0.0806 - val_loss: 0.0299\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0132 - val_loss: 0.0019\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0057 - val_loss: 0.0107\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 507us/step - loss: 0.0037 - val_loss: 0.0014\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 506us/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 506us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 505us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 511us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 505us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 511us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 529us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 3s 679us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 3s 657us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 550us/step - loss: 0.0010 - val_loss: 9.5244e-04\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 535us/step - loss: 9.6161e-04 - val_loss: 9.3441e-04\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 536us/step - loss: 9.4669e-04 - val_loss: 9.9045e-04\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 543us/step - loss: 9.4492e-04 - val_loss: 9.0615e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 541us/step - loss: 9.1689e-04 - val_loss: 9.0554e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 541us/step - loss: 8.9492e-04 - val_loss: 8.8171e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 21s 5ms/step - loss: 0.0401 - val_loss: 0.0086\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 478us/step - loss: 0.0063 - val_loss: 0.0020\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 477us/step - loss: 0.0038 - val_loss: 0.0075\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 481us/step - loss: 0.0027 - val_loss: 0.0014\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 476us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 479us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 479us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 477us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 481us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 477us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 475us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 479us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 484us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 485us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 479us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 478us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 476us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 479us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 477us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 478us/step - loss: 9.9920e-04 - val_loss: 9.9642e-04\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 479us/step - loss: 9.7849e-04 - val_loss: 0.0010\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 480us/step - loss: 9.9452e-04 - val_loss: 0.0010\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 485us/step - loss: 9.9329e-04 - val_loss: 9.5530e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 23s 6ms/step - loss: 0.0638 - val_loss: 0.0261\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 562us/step - loss: 0.0107 - val_loss: 0.0021\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 562us/step - loss: 0.0049 - val_loss: 0.0023\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 564us/step - loss: 0.0028 - val_loss: 0.0014\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 563us/step - loss: 0.0023 - val_loss: 0.0048\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 565us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 570us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 565us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 562us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 567us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 565us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 565us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 566us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 572us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 562us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 562us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 564us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 562us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 566us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 563us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 570us/step - loss: 0.0010 - val_loss: 9.8927e-04\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 563us/step - loss: 9.8637e-04 - val_loss: 9.8045e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 563us/step - loss: 9.7225e-04 - val_loss: 9.7694e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 568us/step - loss: 9.6211e-04 - val_loss: 9.4465e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 22s 5ms/step - loss: 0.0763 - val_loss: 0.0386\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 493us/step - loss: 0.0133 - val_loss: 0.0125\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0052 - val_loss: 0.0019\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 495us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 493us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 493us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 492us/step - loss: 0.0017 - val_loss: 0.0027\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 492us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 495us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 491us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 493us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 492us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 501us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 493us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 499us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 493us/step - loss: 0.0010 - val_loss: 9.8067e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 23s 6ms/step - loss: 0.0604 - val_loss: 0.0019\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 498us/step - loss: 0.0080 - val_loss: 0.0065\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 492us/step - loss: 0.0049 - val_loss: 0.0025\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 498us/step - loss: 0.0029 - val_loss: 0.0056\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0024 - val_loss: 0.0014\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 498us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 500us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 504us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 492us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 492us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 498us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 498us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 550us/step - loss: 9.8775e-04 - val_loss: 0.0010\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 9.7175e-04 - val_loss: 9.9133e-04\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 545us/step - loss: 9.6147e-04 - val_loss: 9.9860e-04\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 507us/step - loss: 9.7327e-04 - val_loss: 9.6668e-04\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 9.8403e-04 - val_loss: 0.0010\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 9.7192e-04 - val_loss: 9.2909e-04\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 508us/step - loss: 9.1698e-04 - val_loss: 9.2955e-04\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 509us/step - loss: 9.2372e-04 - val_loss: 8.9812e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 510us/step - loss: 9.0908e-04 - val_loss: 8.8785e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 507us/step - loss: 8.9111e-04 - val_loss: 8.6928e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 22s 6ms/step - loss: 0.0608 - val_loss: 0.0136\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 501us/step - loss: 0.0267 - val_loss: 0.0083\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 493us/step - loss: 0.0205 - val_loss: 0.0074\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 492us/step - loss: 0.0161 - val_loss: 0.0049\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 492us/step - loss: 0.0123 - val_loss: 0.0036\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 491us/step - loss: 0.0097 - val_loss: 0.0030\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 493us/step - loss: 0.0080 - val_loss: 0.0023\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 495us/step - loss: 0.0066 - val_loss: 0.0022\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 493us/step - loss: 0.0056 - val_loss: 0.0021\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 495us/step - loss: 0.0053 - val_loss: 0.0022\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 492us/step - loss: 0.0047 - val_loss: 0.0023\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 496us/step - loss: 0.0044 - val_loss: 0.0024\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 493us/step - loss: 0.0045 - val_loss: 0.0024\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 494us/step - loss: 0.0043 - val_loss: 0.0027\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 492us/step - loss: 0.0044 - val_loss: 0.0029\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 494us/step - loss: 0.0040 - val_loss: 0.0027\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 495us/step - loss: 0.0041 - val_loss: 0.0028\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 497us/step - loss: 0.0042 - val_loss: 0.0028\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 493us/step - loss: 0.0039 - val_loss: 0.0028\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 495us/step - loss: 0.0041 - val_loss: 0.0029\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 493us/step - loss: 0.0040 - val_loss: 0.0028\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 495us/step - loss: 0.0039 - val_loss: 0.0028\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 492us/step - loss: 0.0040 - val_loss: 0.0028\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 495us/step - loss: 0.0039 - val_loss: 0.0028\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 25s 6ms/step - loss: 1.5606 - val_loss: 0.0089\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 617us/step - loss: 0.0324 - val_loss: 0.0036\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 3s 664us/step - loss: 0.0149 - val_loss: 0.0021\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 624us/step - loss: 0.0091 - val_loss: 0.0017\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 620us/step - loss: 0.0067 - val_loss: 0.0017\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 617us/step - loss: 0.0056 - val_loss: 0.0018\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 615us/step - loss: 0.0055 - val_loss: 0.0022\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 614us/step - loss: 0.0051 - val_loss: 0.0025\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 615us/step - loss: 0.0052 - val_loss: 0.0019\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 617us/step - loss: 0.0049 - val_loss: 0.0021\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 614us/step - loss: 0.0050 - val_loss: 0.0026\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 611us/step - loss: 0.0049 - val_loss: 0.0020\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 612us/step - loss: 0.0047 - val_loss: 0.0019\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 614us/step - loss: 0.0045 - val_loss: 0.0020\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 611us/step - loss: 0.0044 - val_loss: 0.0023\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 612us/step - loss: 0.0042 - val_loss: 0.0023\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 614us/step - loss: 0.0043 - val_loss: 0.0020\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 614us/step - loss: 0.0039 - val_loss: 0.0020\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 621us/step - loss: 0.0040 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 628us/step - loss: 0.0041 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 618us/step - loss: 0.0040 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 613us/step - loss: 0.0037 - val_loss: 0.0017\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 619us/step - loss: 0.0037 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 614us/step - loss: 0.0038 - val_loss: 0.0019\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 23s 6ms/step - loss: 0.5654 - val_loss: 0.0048\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 581us/step - loss: 0.0125 - val_loss: 0.0024\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 582us/step - loss: 0.0079 - val_loss: 0.0020\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 581us/step - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 613us/step - loss: 0.0055 - val_loss: 0.0018\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 595us/step - loss: 0.0054 - val_loss: 0.0019\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 589us/step - loss: 0.0052 - val_loss: 0.0018\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 583us/step - loss: 0.0051 - val_loss: 0.0021\n",
      "Epoch 9/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 2s 581us/step - loss: 0.0046 - val_loss: 0.0018\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 581us/step - loss: 0.0047 - val_loss: 0.0018\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 585us/step - loss: 0.0047 - val_loss: 0.0019\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 583us/step - loss: 0.0045 - val_loss: 0.0018\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 580us/step - loss: 0.0047 - val_loss: 0.0020\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 583us/step - loss: 0.0044 - val_loss: 0.0018\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 584us/step - loss: 0.0043 - val_loss: 0.0018\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 582us/step - loss: 0.0043 - val_loss: 0.0017\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 579us/step - loss: 0.0042 - val_loss: 0.0017\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 581us/step - loss: 0.0040 - val_loss: 0.0017\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 581us/step - loss: 0.0041 - val_loss: 0.0017\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 581us/step - loss: 0.0037 - val_loss: 0.0017\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 580us/step - loss: 0.0038 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 584us/step - loss: 0.0038 - val_loss: 0.0017\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 591us/step - loss: 0.0037 - val_loss: 0.0017\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 585us/step - loss: 0.0038 - val_loss: 0.0017\n",
      "\n",
      "GENERATION 12\n",
      "\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 24s 6ms/step - loss: 0.0468 - val_loss: 0.0052\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 0.0067 - val_loss: 0.0015\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 511us/step - loss: 0.0050 - val_loss: 0.0016\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 0.0037 - val_loss: 0.0025\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 509us/step - loss: 0.0024 - val_loss: 0.0045\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 507us/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 508us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 508us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 509us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 508us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 540us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 0.0010 - val_loss: 9.8394e-04\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 510us/step - loss: 9.7914e-04 - val_loss: 9.6515e-04\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 510us/step - loss: 9.4394e-04 - val_loss: 0.0010\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 9.4224e-04 - val_loss: 9.6062e-04\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 9.2272e-04 - val_loss: 8.8983e-04\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 510us/step - loss: 9.1592e-04 - val_loss: 8.8416e-04\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 510us/step - loss: 8.8766e-04 - val_loss: 8.4962e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 509us/step - loss: 8.4838e-04 - val_loss: 8.6776e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 8.3445e-04 - val_loss: 8.6017e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 23s 6ms/step - loss: 0.0601 - val_loss: 0.0041\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 511us/step - loss: 0.0088 - val_loss: 0.0022\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 508us/step - loss: 0.0051 - val_loss: 0.0014\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 508us/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 509us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 510us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 511us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 509us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 508us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 510us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 511us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 511us/step - loss: 9.8820e-04 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 511us/step - loss: 9.6719e-04 - val_loss: 9.6445e-04\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 9.3419e-04 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 9.4156e-04 - val_loss: 0.0010\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 8.9270e-04 - val_loss: 9.5752e-04\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 8.8802e-04 - val_loss: 9.2361e-04\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 8.7386e-04 - val_loss: 9.4000e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 548us/step - loss: 8.6536e-04 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 570us/step - loss: 9.1671e-04 - val_loss: 0.0010\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 24s 6ms/step - loss: 0.0468 - val_loss: 0.0024\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 0.0033 - val_loss: 0.0070\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 0.0099 - val_loss: 0.0115\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 0.0059 - val_loss: 0.0059\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 0.0045 - val_loss: 0.0100\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0068 - val_loss: 0.0115\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 0.0077 - val_loss: 0.0131\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0058 - val_loss: 0.0088\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 0.0054 - val_loss: 0.0074\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0046 - val_loss: 0.0110\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 0.0063 - val_loss: 0.0084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 0.0050 - val_loss: 0.0099\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 0.0062 - val_loss: 0.0085\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 0.0050 - val_loss: 0.0098\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 0.0060 - val_loss: 0.0125\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 542us/step - loss: 0.0061 - val_loss: 0.0090\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 0.0056 - val_loss: 0.0099\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 553us/step - loss: 0.0048 - val_loss: 0.0092\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 0.0044 - val_loss: 0.0074\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 0.0040 - val_loss: 0.0068\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 0.0043 - val_loss: 0.0095\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 509us/step - loss: 0.0052 - val_loss: 0.0115\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 510us/step - loss: 0.0062 - val_loss: 0.0082\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 23s 6ms/step - loss: 0.0558 - val_loss: 0.0043\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 393us/step - loss: 0.0085 - val_loss: 0.0033\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 384us/step - loss: 0.0056 - val_loss: 0.0024\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 387us/step - loss: 0.0066 - val_loss: 0.0030\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 385us/step - loss: 0.0084 - val_loss: 0.0034\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 383us/step - loss: 0.0069 - val_loss: 0.0025\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 385us/step - loss: 0.0057 - val_loss: 0.0027\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 384us/step - loss: 0.0059 - val_loss: 0.0021\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 385us/step - loss: 0.0050 - val_loss: 0.0022\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 386us/step - loss: 0.0072 - val_loss: 0.0039\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 385us/step - loss: 0.0055 - val_loss: 0.0019\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 384us/step - loss: 0.0037 - val_loss: 0.0021\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 384us/step - loss: 0.0059 - val_loss: 0.0033\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 385us/step - loss: 0.0054 - val_loss: 0.0023\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 389us/step - loss: 0.0046 - val_loss: 0.0018\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 387us/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 385us/step - loss: 0.0052 - val_loss: 0.0020\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 385us/step - loss: 0.0040 - val_loss: 0.0018\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 385us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 385us/step - loss: 0.0040 - val_loss: 0.0026\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 389us/step - loss: 0.0050 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 388us/step - loss: 0.0031 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 393us/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 396us/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 24s 6ms/step - loss: 0.0393 - val_loss: 0.0030\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 406us/step - loss: 0.0107 - val_loss: 0.0159\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 402us/step - loss: 0.0084 - val_loss: 0.0083\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 402us/step - loss: 0.0073 - val_loss: 0.0167\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 404us/step - loss: 0.0080 - val_loss: 0.0113\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 402us/step - loss: 0.0070 - val_loss: 0.0104\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 403us/step - loss: 0.0070 - val_loss: 0.0125\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 406us/step - loss: 0.0072 - val_loss: 0.0103\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 405us/step - loss: 0.0055 - val_loss: 0.0112\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 403us/step - loss: 0.0078 - val_loss: 0.0152\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 405us/step - loss: 0.0066 - val_loss: 0.0117\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 403us/step - loss: 0.0059 - val_loss: 0.0106\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 401us/step - loss: 0.0062 - val_loss: 0.0109\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 402us/step - loss: 0.0060 - val_loss: 0.0117\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 402us/step - loss: 0.0064 - val_loss: 0.0110\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 402us/step - loss: 0.0054 - val_loss: 0.0130\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 403us/step - loss: 0.0065 - val_loss: 0.0174\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 407us/step - loss: 0.0067 - val_loss: 0.0099\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 402us/step - loss: 0.0055 - val_loss: 0.0099\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 403us/step - loss: 0.0051 - val_loss: 0.0099\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 408us/step - loss: 0.0054 - val_loss: 0.0110\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 403us/step - loss: 0.0058 - val_loss: 0.0124\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 402us/step - loss: 0.0065 - val_loss: 0.0096\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 409us/step - loss: 0.0036 - val_loss: 0.0077\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 24s 6ms/step - loss: 0.0671 - val_loss: 0.0169\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 405us/step - loss: 0.0107 - val_loss: 0.0048\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 403us/step - loss: 0.0052 - val_loss: 0.0054\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 401us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0032 - val_loss: 0.0026\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0029 - val_loss: 0.0020\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 401us/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0027 - val_loss: 0.0020\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 406us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 405us/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 404us/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 401us/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 402us/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 401us/step - loss: 0.0022 - val_loss: 0.0017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 402us/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 404us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 408us/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 404us/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 402us/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 402us/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 401us/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 24s 6ms/step - loss: 0.0697 - val_loss: 0.0081\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 409us/step - loss: 0.0093 - val_loss: 0.0014\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 406us/step - loss: 0.0057 - val_loss: 0.0016\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 403us/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 404us/step - loss: 0.0034 - val_loss: 0.0041\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 405us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 404us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 403us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 404us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 404us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 405us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 407us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 405us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 405us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 441us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 437us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 452us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 432us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 413us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 405us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 406us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 408us/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 405us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 406us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 25s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 409us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 409us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 404us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 416us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 443us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 421us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 418us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 414us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 443us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 450us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 443us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 423us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 427us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 480us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 492us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 464us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 462us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 458us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 458us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 457us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 453us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 460us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 453us/step - loss: nan - val_loss: nan\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 31s 8ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 3s 658us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 3s 645us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 3s 649us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 3s 650us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 3s 651us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 3s 653us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 3s 653us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 3s 648us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 3s 654us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 3s 646us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 3s 653us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 3s 649us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 3s 652us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 3s 658us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 3s 650us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 3s 646us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 3s 650us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 3s 646us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 3s 655us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 3s 648us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 3s 642us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 3s 654us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 3s 652us/step - loss: nan - val_loss: nan\n",
      "\n",
      "GENERATION 13\n",
      "\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 31s 8ms/step - loss: 0.7013 - val_loss: 0.1410\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 430us/step - loss: 0.1260 - val_loss: 0.1825\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 424us/step - loss: 0.1079 - val_loss: 0.0467\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 423us/step - loss: 0.0713 - val_loss: 0.0067\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 421us/step - loss: 0.0636 - val_loss: 0.0554\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 422us/step - loss: 0.0501 - val_loss: 0.0036\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 423us/step - loss: 0.0235 - val_loss: 0.0034\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 423us/step - loss: 0.0074 - val_loss: 0.0055\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 419us/step - loss: 0.0056 - val_loss: 0.0037\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 431us/step - loss: 0.0040 - val_loss: 0.0034\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 429us/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 430us/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 423us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 423us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 427us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 423us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 430us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 423us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 421us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 429us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 423us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 424us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 422us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 421us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 32s 8ms/step - loss: 0.0702 - val_loss: 0.0265\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 569us/step - loss: 0.0138 - val_loss: 0.0104\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 583us/step - loss: 0.0066 - val_loss: 0.0053\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 571us/step - loss: 0.0044 - val_loss: 0.0015\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 569us/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 590us/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 567us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 548us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 579us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 540us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 510us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 510us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 506us/step - loss: 9.9490e-04 - val_loss: 0.0014\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 507us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 506us/step - loss: 9.6873e-04 - val_loss: 9.9168e-04\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 507us/step - loss: 9.3668e-04 - val_loss: 9.4721e-04\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 529us/step - loss: 9.2461e-04 - val_loss: 0.0010\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 8.9985e-04 - val_loss: 9.7970e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 9.4613e-04 - val_loss: 9.7548e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 535us/step - loss: 9.3987e-04 - val_loss: 0.0012\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 30s 7ms/step - loss: 0.0517 - val_loss: 0.0033\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 579us/step - loss: 0.0053 - val_loss: 0.0016\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 580us/step - loss: 0.0032 - val_loss: 0.0015\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 578us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 571us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 572us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 581us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 573us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 595us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 587us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 574us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 584us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 580us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 567us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 543us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 554us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 574us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 573us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 574us/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 577us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 572us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 559us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 32s 8ms/step - loss: 0.0584 - val_loss: 0.0067\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 561us/step - loss: 0.0079 - val_loss: 0.0074\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.0043 - val_loss: 0.0018\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 576us/step - loss: 0.0027 - val_loss: 0.0020\n",
      "Epoch 5/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 2s 577us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 560us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 547us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 537us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 558us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 540us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 540us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 539us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 536us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 540us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 539us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 541us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 544us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 536us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 537us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 550us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 544us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 539us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 535us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 540us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 30s 8ms/step - loss: 0.0716 - val_loss: 0.0077\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0114 - val_loss: 0.0033\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0054 - val_loss: 0.0082\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0040 - val_loss: 0.0018\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 536us/step - loss: 0.0031 - val_loss: 0.0027\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 539us/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 535us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 535us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 537us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 547us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 563us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 544us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 506us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 505us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 504us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 540us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 29s 7ms/step - loss: 0.2171 - val_loss: 0.0409\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 562us/step - loss: 0.0660 - val_loss: 0.0430\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 584us/step - loss: 0.0657 - val_loss: 0.0327\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 608us/step - loss: 0.0653 - val_loss: 0.0348\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 554us/step - loss: 0.0653 - val_loss: 0.0339\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 587us/step - loss: 0.0650 - val_loss: 0.0395\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 549us/step - loss: 0.0647 - val_loss: 0.0434\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 554us/step - loss: 0.0644 - val_loss: 0.0417\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 581us/step - loss: 0.0641 - val_loss: 0.0309\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 549us/step - loss: 0.0640 - val_loss: 0.0347\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 549us/step - loss: 0.0635 - val_loss: 0.0318\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 556us/step - loss: 0.0636 - val_loss: 0.0277\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 541us/step - loss: 0.0630 - val_loss: 0.0359\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 537us/step - loss: 0.0627 - val_loss: 0.0397\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0624 - val_loss: 0.0384\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0622 - val_loss: 0.0381\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0621 - val_loss: 0.0371\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 539us/step - loss: 0.0617 - val_loss: 0.0293\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0618 - val_loss: 0.0323\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 536us/step - loss: 0.0610 - val_loss: 0.0362\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0608 - val_loss: 0.0292\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 0.0606 - val_loss: 0.0296\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0602 - val_loss: 0.0305\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.0598 - val_loss: 0.0331\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 28s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 427us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 428us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 428us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 427us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 429us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 439us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 432us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 429us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 447us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 428us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 428us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 431us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 431us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 431us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 440us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 427us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 435us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 437us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 436us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 454us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 434us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 426us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 433us/step - loss: nan - val_loss: nan\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 28s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 491us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 480us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 478us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 476us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 485us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 485us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 501us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 479us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 475us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 482us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 474us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 491us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 485us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 477us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 479us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 476us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 479us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 476us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 479us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 485us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: nan - val_loss: nan\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 28s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 477us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 476us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 473us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 479us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 477us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 475us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 475us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 474us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 476us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 473us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 476us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 478us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 477us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 474us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 478us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 473us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 474us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 477us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 475us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 480us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 477us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 474us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 482us/step - loss: nan - val_loss: nan\n",
      "\n",
      "GENERATION 14\n",
      "\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 29s 7ms/step - loss: 0.0869 - val_loss: 0.0385\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 391us/step - loss: 0.0204 - val_loss: 0.0098\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 391us/step - loss: 0.0080 - val_loss: 0.0015\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 391us/step - loss: 0.0047 - val_loss: 0.0021\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 390us/step - loss: 0.0032 - val_loss: 0.0045\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 404us/step - loss: 0.0025 - val_loss: 0.0015\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 393us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 392us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 393us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 408us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 393us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 393us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 392us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 391us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 392us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 390us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 391us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 18/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 2s 390us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 391us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 391us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 397us/step - loss: 9.8235e-04 - val_loss: 9.8758e-04\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 392us/step - loss: 9.5175e-04 - val_loss: 0.0010\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 394us/step - loss: 9.7182e-04 - val_loss: 9.6854e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 392us/step - loss: 9.2287e-04 - val_loss: 9.3356e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 30s 8ms/step - loss: 0.0548 - val_loss: 0.0032\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 511us/step - loss: 0.0072 - val_loss: 0.0106\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 510us/step - loss: 0.0044 - val_loss: 0.0053\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0033 - val_loss: 0.0016\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 508us/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 508us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 511us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 511us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 509us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 510us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 511us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 510us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 510us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 510us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 510us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 510us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 30s 8ms/step - loss: 0.0425 - val_loss: 0.0022\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 0.0053 - val_loss: 0.0125\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 0.0121 - val_loss: 0.0028\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 510us/step - loss: 0.0055 - val_loss: 0.0027\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 510us/step - loss: 0.0070 - val_loss: 0.0057\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 510us/step - loss: 0.0068 - val_loss: 0.0052\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 511us/step - loss: 0.0085 - val_loss: 0.0084\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 0.0069 - val_loss: 0.0065\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 510us/step - loss: 0.0076 - val_loss: 0.0038\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 0.0064 - val_loss: 0.0067\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 511us/step - loss: 0.0072 - val_loss: 0.0031\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 511us/step - loss: 0.0062 - val_loss: 0.0049\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 0.0069 - val_loss: 0.0037\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 510us/step - loss: 0.0071 - val_loss: 0.0056\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 511us/step - loss: 0.0072 - val_loss: 0.0038\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 510us/step - loss: 0.0048 - val_loss: 0.0036\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 0.0041 - val_loss: 0.0023\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 0.0052 - val_loss: 0.0046\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 0.0068 - val_loss: 0.0030\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 511us/step - loss: 0.0047 - val_loss: 0.0017\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 0.0055 - val_loss: 0.0038\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 511us/step - loss: 0.0058 - val_loss: 0.0032\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 511us/step - loss: 0.0051 - val_loss: 0.0030\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 30s 8ms/step - loss: 0.0388 - val_loss: 0.0026\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 0.0067 - val_loss: 0.0282\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0106 - val_loss: 0.0064\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 0.0042 - val_loss: 0.0081\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 0.0058 - val_loss: 0.0120\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 0.0073 - val_loss: 0.0143\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 0.0093 - val_loss: 0.0129\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 0.0061 - val_loss: 0.0078\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 0.0045 - val_loss: 0.0089\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 0.0053 - val_loss: 0.0117\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 0.0067 - val_loss: 0.0104\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 0.0063 - val_loss: 0.0092\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0051 - val_loss: 0.0117\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 0.0067 - val_loss: 0.0118\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 0.0046 - val_loss: 0.0068\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 0.0034 - val_loss: 0.0091\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 510us/step - loss: 0.0056 - val_loss: 0.0130\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 511us/step - loss: 0.0062 - val_loss: 0.0116\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 0.0055 - val_loss: 0.0069\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 0.0032 - val_loss: 0.0071\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 0.0043 - val_loss: 0.0111\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 0.0042 - val_loss: 0.0093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 0.0056 - val_loss: 0.0121\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 0.0056 - val_loss: 0.0101\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 31s 8ms/step - loss: 0.0859 - val_loss: 0.0917\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 536us/step - loss: 0.0236 - val_loss: 0.0242\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.0165 - val_loss: 0.0176\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 551us/step - loss: 0.0125 - val_loss: 0.0171\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 543us/step - loss: 0.0106 - val_loss: 0.0178\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 537us/step - loss: 0.0088 - val_loss: 0.0106\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 536us/step - loss: 0.0080 - val_loss: 0.0094\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 540us/step - loss: 0.0064 - val_loss: 0.0056\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 545us/step - loss: 0.0061 - val_loss: 0.0103\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 552us/step - loss: 0.0079 - val_loss: 0.0051\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 543us/step - loss: 0.0050 - val_loss: 0.0061\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 551us/step - loss: 0.0063 - val_loss: 0.0064\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 539us/step - loss: 0.0069 - val_loss: 0.0063\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 537us/step - loss: 0.0065 - val_loss: 0.0073\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 537us/step - loss: 0.0059 - val_loss: 0.0061\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 536us/step - loss: 0.0052 - val_loss: 0.0111\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 535us/step - loss: 0.0066 - val_loss: 0.0041\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 535us/step - loss: 0.0040 - val_loss: 0.0051\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 542us/step - loss: 0.0048 - val_loss: 0.0095\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 547us/step - loss: 0.0056 - val_loss: 0.0057\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 543us/step - loss: 0.0041 - val_loss: 0.0034\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 537us/step - loss: 0.0032 - val_loss: 0.0051\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 537us/step - loss: 0.0050 - val_loss: 0.0123\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.0072 - val_loss: 0.0055\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 31s 8ms/step - loss: 0.1028 - val_loss: 0.0066\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 535us/step - loss: 0.0104 - val_loss: 0.0064\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 535us/step - loss: 0.0087 - val_loss: 0.0140\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0070 - val_loss: 0.0091\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 541us/step - loss: 0.0064 - val_loss: 0.0077\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0058 - val_loss: 0.0096\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 535us/step - loss: 0.0063 - val_loss: 0.0097\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 535us/step - loss: 0.0061 - val_loss: 0.0063\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 537us/step - loss: 0.0054 - val_loss: 0.0072\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 535us/step - loss: 0.0047 - val_loss: 0.0064\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 535us/step - loss: 0.0041 - val_loss: 0.0049\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 537us/step - loss: 0.0038 - val_loss: 0.0097\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0053 - val_loss: 0.0037\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 535us/step - loss: 0.0039 - val_loss: 0.0077\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 542us/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 539us/step - loss: 0.0037 - val_loss: 0.0056\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 537us/step - loss: 0.0034 - val_loss: 0.0062\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 536us/step - loss: 0.0049 - val_loss: 0.0079\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 537us/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 535us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.0031 - val_loss: 0.0045\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 535us/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 536us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 547us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 33s 8ms/step - loss: 0.0991 - val_loss: 0.0078\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 541us/step - loss: 0.0084 - val_loss: 0.0118\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 542us/step - loss: 0.0091 - val_loss: 0.0132\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 537us/step - loss: 0.0059 - val_loss: 0.0103\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 541us/step - loss: 0.0053 - val_loss: 0.0133\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 545us/step - loss: 0.0071 - val_loss: 0.0072\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 542us/step - loss: 0.0048 - val_loss: 0.0081\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 536us/step - loss: 0.0048 - val_loss: 0.0127\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 537us/step - loss: 0.0069 - val_loss: 0.0132\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 544us/step - loss: 0.0057 - val_loss: 0.0061\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.0038 - val_loss: 0.0047\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.0044 - val_loss: 0.0055\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 537us/step - loss: 0.0042 - val_loss: 0.0059\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.0040 - val_loss: 0.0051\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 549us/step - loss: 0.0041 - val_loss: 0.0055\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 541us/step - loss: 0.0043 - val_loss: 0.0069\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 545us/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 547us/step - loss: 0.0029 - val_loss: 0.0053\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 551us/step - loss: 0.0047 - val_loss: 0.0075\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 537us/step - loss: 0.0048 - val_loss: 0.0059\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 547us/step - loss: 0.0038 - val_loss: 0.0041\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 549us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 544us/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 562us/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 32s 8ms/step - loss: 0.0920 - val_loss: 0.0018\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 359us/step - loss: 0.0043 - val_loss: 0.0350\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 344us/step - loss: 0.0089 - val_loss: 0.0015\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 344us/step - loss: 0.0026 - val_loss: 0.0015\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 348us/step - loss: 0.0056 - val_loss: 0.0078\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 349us/step - loss: 0.0052 - val_loss: 0.0031\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 345us/step - loss: 0.0036 - val_loss: 0.0043\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 345us/step - loss: 0.0065 - val_loss: 0.0030\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 344us/step - loss: 0.0031 - val_loss: 0.0019\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 354us/step - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 352us/step - loss: 0.0054 - val_loss: 0.0068\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 369us/step - loss: 0.0055 - val_loss: 0.0037\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 358us/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 349us/step - loss: 0.0045 - val_loss: 0.0067\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 344us/step - loss: 0.0050 - val_loss: 0.0023\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 347us/step - loss: 0.0032 - val_loss: 0.0020\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 371us/step - loss: 0.0039 - val_loss: 0.0031\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 359us/step - loss: 0.0027 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 345us/step - loss: 0.0027 - val_loss: 0.0019\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 359us/step - loss: 0.0031 - val_loss: 0.0068\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 347us/step - loss: 0.0062 - val_loss: 0.0053\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 348us/step - loss: 0.0045 - val_loss: 0.0018\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 347us/step - loss: 0.0025 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 347us/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 34s 8ms/step - loss: 0.8420 - val_loss: 0.0041\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 367us/step - loss: 0.0265 - val_loss: 0.1947\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 345us/step - loss: 0.0270 - val_loss: 0.0170\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 344us/step - loss: 0.0179 - val_loss: 0.0626\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 347us/step - loss: 0.0158 - val_loss: 0.0218\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 349us/step - loss: 0.0077 - val_loss: 0.0285\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 351us/step - loss: 0.0138 - val_loss: 0.0424\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 354us/step - loss: 0.0162 - val_loss: 0.0239\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 343us/step - loss: 0.0069 - val_loss: 0.0194\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 346us/step - loss: 0.0122 - val_loss: 0.0367\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 349us/step - loss: 0.0161 - val_loss: 0.0361\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 346us/step - loss: 0.0116 - val_loss: 0.0266\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 346us/step - loss: 0.0105 - val_loss: 0.0300\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 346us/step - loss: 0.0128 - val_loss: 0.0225\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 346us/step - loss: 0.0069 - val_loss: 0.0176\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 344us/step - loss: 0.0104 - val_loss: 0.0267\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 345us/step - loss: 0.0100 - val_loss: 0.0214\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 346us/step - loss: 0.0115 - val_loss: 0.0295\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 350us/step - loss: 0.0115 - val_loss: 0.0151\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 353us/step - loss: 0.0060 - val_loss: 0.0127\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 346us/step - loss: 0.0058 - val_loss: 0.0133\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 359us/step - loss: 0.0068 - val_loss: 0.0224\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 362us/step - loss: 0.0094 - val_loss: 0.0171\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 343us/step - loss: 0.0087 - val_loss: 0.0126\n",
      "\n",
      "GENERATION 15\n",
      "\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 35s 9ms/step - loss: 0.2958 - val_loss: 0.0028\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 577us/step - loss: 0.0067 - val_loss: 0.0152\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0089 - val_loss: 0.0059\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 539us/step - loss: 0.0082 - val_loss: 0.0085\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 540us/step - loss: 0.0120 - val_loss: 0.0170\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 539us/step - loss: 0.0128 - val_loss: 0.0193\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 549us/step - loss: 0.0156 - val_loss: 0.0188\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 559us/step - loss: 0.0128 - val_loss: 0.0208\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 539us/step - loss: 0.0159 - val_loss: 0.0192\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 540us/step - loss: 0.0115 - val_loss: 0.0233\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 556us/step - loss: 0.0120 - val_loss: 0.0165\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 535us/step - loss: 0.0105 - val_loss: 0.0223\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 553us/step - loss: 0.0101 - val_loss: 0.0171\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 549us/step - loss: 0.0095 - val_loss: 0.0244\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 540us/step - loss: 0.0109 - val_loss: 0.0080\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 566us/step - loss: 0.0077 - val_loss: 0.0148\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 539us/step - loss: 0.0081 - val_loss: 0.0155\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 536us/step - loss: 0.0084 - val_loss: 0.0119\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 545us/step - loss: 0.0076 - val_loss: 0.0139\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 550us/step - loss: 0.0075 - val_loss: 0.0070\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 549us/step - loss: 0.0073 - val_loss: 0.0180\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 569us/step - loss: 0.0064 - val_loss: 0.0080\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 562us/step - loss: 0.0065 - val_loss: 0.0112\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 544us/step - loss: 0.0062 - val_loss: 0.0081\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 36s 9ms/step - loss: 0.0675 - val_loss: 0.0020\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 0.0096 - val_loss: 0.0034\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 539us/step - loss: 0.0066 - val_loss: 0.0064\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0040 - val_loss: 0.0036\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 0.0030 - val_loss: 0.0013\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 0.0017 - val_loss: 0.0018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 541us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 528us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 9.9626e-04 - val_loss: 0.0013\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 9.7810e-04 - val_loss: 9.3552e-04\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 9.3290e-04 - val_loss: 9.3150e-04\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 9.2744e-04 - val_loss: 9.0855e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 541us/step - loss: 8.9940e-04 - val_loss: 8.7953e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 539us/step - loss: 8.9107e-04 - val_loss: 0.0010\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 35s 9ms/step - loss: 0.0518 - val_loss: 0.0033\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 544us/step - loss: 0.0076 - val_loss: 0.0016\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 528us/step - loss: 0.0048 - val_loss: 0.0020\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0035 - val_loss: 0.0027\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 529us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 537us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 9.9589e-04 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 9.7942e-04 - val_loss: 0.0010\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 9.5195e-04 - val_loss: 9.5179e-04\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 9.7521e-04 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 9.6579e-04 - val_loss: 0.0010\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 9.3194e-04 - val_loss: 8.9524e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 8.9220e-04 - val_loss: 8.9401e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 8.9164e-04 - val_loss: 8.5676e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 36s 9ms/step - loss: 0.0446 - val_loss: 0.0082\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 552us/step - loss: 0.0151 - val_loss: 0.0140\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 541us/step - loss: 0.0079 - val_loss: 0.0191\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 542us/step - loss: 0.0097 - val_loss: 0.0119\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 541us/step - loss: 0.0075 - val_loss: 0.0126\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 543us/step - loss: 0.0073 - val_loss: 0.0126\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 542us/step - loss: 0.0061 - val_loss: 0.0103\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 544us/step - loss: 0.0065 - val_loss: 0.0135\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 542us/step - loss: 0.0091 - val_loss: 0.0162\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 553us/step - loss: 0.0088 - val_loss: 0.0139\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 542us/step - loss: 0.0053 - val_loss: 0.0074\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 543us/step - loss: 0.0047 - val_loss: 0.0104\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 542us/step - loss: 0.0067 - val_loss: 0.0169\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 544us/step - loss: 0.0077 - val_loss: 0.0134\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 547us/step - loss: 0.0062 - val_loss: 0.0138\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 545us/step - loss: 0.0066 - val_loss: 0.0128\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 539us/step - loss: 0.0062 - val_loss: 0.0149\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 541us/step - loss: 0.0062 - val_loss: 0.0095\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 543us/step - loss: 0.0045 - val_loss: 0.0100\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 544us/step - loss: 0.0057 - val_loss: 0.0092\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 540us/step - loss: 0.0046 - val_loss: 0.0105\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 545us/step - loss: 0.0060 - val_loss: 0.0126\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 544us/step - loss: 0.0051 - val_loss: 0.0104\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 543us/step - loss: 0.0037 - val_loss: 0.0079\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 38s 10ms/step - loss: 0.1164 - val_loss: 0.0453\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 479us/step - loss: 0.0244 - val_loss: 0.0335\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 475us/step - loss: 0.0208 - val_loss: 0.0183\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 475us/step - loss: 0.0144 - val_loss: 0.0141\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0111 - val_loss: 0.0175\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 0.0123 - val_loss: 0.0062\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 477us/step - loss: 0.0066 - val_loss: 0.0092\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 478us/step - loss: 0.0089 - val_loss: 0.0066\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0075 - val_loss: 0.0095\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 506us/step - loss: 0.0068 - val_loss: 0.0071\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 484us/step - loss: 0.0073 - val_loss: 0.0110\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 485us/step - loss: 0.0069 - val_loss: 0.0088\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 504us/step - loss: 0.0071 - val_loss: 0.0045\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 502us/step - loss: 0.0066 - val_loss: 0.0039\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 478us/step - loss: 0.0044 - val_loss: 0.0069\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 481us/step - loss: 0.0065 - val_loss: 0.0058\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 484us/step - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 481us/step - loss: 0.0057 - val_loss: 0.0041\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 478us/step - loss: 0.0053 - val_loss: 0.0082\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 479us/step - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 476us/step - loss: 0.0056 - val_loss: 0.0089\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 477us/step - loss: 0.0047 - val_loss: 0.0054\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 484us/step - loss: 0.0050 - val_loss: 0.0069\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 477us/step - loss: 0.0046 - val_loss: 0.0034\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 36s 9ms/step - loss: 0.1040 - val_loss: 0.0092\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 492us/step - loss: 0.0196 - val_loss: 0.0196\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 481us/step - loss: 0.0194 - val_loss: 0.0260\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 480us/step - loss: 0.0174 - val_loss: 0.0104\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 483us/step - loss: 0.0113 - val_loss: 0.0134\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 481us/step - loss: 0.0099 - val_loss: 0.0094\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 482us/step - loss: 0.0077 - val_loss: 0.0093\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 0.0072 - val_loss: 0.0061\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0074 - val_loss: 0.0071\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 483us/step - loss: 0.0082 - val_loss: 0.0058\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 482us/step - loss: 0.0057 - val_loss: 0.0043\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 0.0058 - val_loss: 0.0065\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 492us/step - loss: 0.0079 - val_loss: 0.0105\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 482us/step - loss: 0.0079 - val_loss: 0.0045\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0066 - val_loss: 0.0054\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 0.0053 - val_loss: 0.0058\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 483us/step - loss: 0.0060 - val_loss: 0.0039\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 479us/step - loss: 0.0055 - val_loss: 0.0056\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 485us/step - loss: 0.0077 - val_loss: 0.0053\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 494us/step - loss: 0.0057 - val_loss: 0.0024\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 482us/step - loss: 0.0043 - val_loss: 0.0027\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 484us/step - loss: 0.0052 - val_loss: 0.0043\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 481us/step - loss: 0.0055 - val_loss: 0.0035\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 37s 9ms/step - loss: 0.0699 - val_loss: 0.0421\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 478us/step - loss: 0.0213 - val_loss: 0.0219\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 476us/step - loss: 0.0147 - val_loss: 0.0286\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 478us/step - loss: 0.0152 - val_loss: 0.0246\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 479us/step - loss: 0.0112 - val_loss: 0.0183\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 480us/step - loss: 0.0113 - val_loss: 0.0124\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 481us/step - loss: 0.0075 - val_loss: 0.0122\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 484us/step - loss: 0.0090 - val_loss: 0.0079\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 482us/step - loss: 0.0061 - val_loss: 0.0090\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 480us/step - loss: 0.0048 - val_loss: 0.0061\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 479us/step - loss: 0.0070 - val_loss: 0.0116\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 479us/step - loss: 0.0093 - val_loss: 0.0139\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 480us/step - loss: 0.0070 - val_loss: 0.0097\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 481us/step - loss: 0.0069 - val_loss: 0.0071\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 481us/step - loss: 0.0063 - val_loss: 0.0113\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 482us/step - loss: 0.0064 - val_loss: 0.0073\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 483us/step - loss: 0.0053 - val_loss: 0.0064\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 479us/step - loss: 0.0042 - val_loss: 0.0091\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 477us/step - loss: 0.0066 - val_loss: 0.0086\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 480us/step - loss: 0.0049 - val_loss: 0.0103\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 478us/step - loss: 0.0060 - val_loss: 0.0059\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 481us/step - loss: 0.0043 - val_loss: 0.0058\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 481us/step - loss: 0.0062 - val_loss: 0.0100\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 37s 9ms/step - loss: 0.0897 - val_loss: 0.0394\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 481us/step - loss: 0.0173 - val_loss: 0.0067\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 484us/step - loss: 0.0081 - val_loss: 0.0023\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 484us/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 480us/step - loss: 0.0041 - val_loss: 0.0018\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 482us/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 482us/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 480us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 482us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 480us/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 483us/step - loss: 0.0024 - val_loss: 0.0036\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 483us/step - loss: 0.0023 - val_loss: 0.0036\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0023 - val_loss: 0.0046\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 481us/step - loss: 0.0022 - val_loss: 0.0056\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 497us/step - loss: 0.0023 - val_loss: 0.0085\n",
      "Epoch 17/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 2s 480us/step - loss: 0.0022 - val_loss: 0.0073\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 485us/step - loss: 0.0021 - val_loss: 0.0062\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 481us/step - loss: 0.0019 - val_loss: 0.0056\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0019 - val_loss: 0.0090\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 483us/step - loss: 0.0019 - val_loss: 0.0080\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 482us/step - loss: 0.0018 - val_loss: 0.0108\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 485us/step - loss: 0.0018 - val_loss: 0.0096\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 483us/step - loss: 0.0018 - val_loss: 0.0127\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 39s 10ms/step - loss: 0.4606 - val_loss: 0.0473\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 0.1067 - val_loss: 0.1854\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 0.1001 - val_loss: 0.0369\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 0.0703 - val_loss: 0.0074\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0513 - val_loss: 0.0043\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 0.0152 - val_loss: 0.0073\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 529us/step - loss: 0.0095 - val_loss: 0.0037\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0051 - val_loss: 0.0029\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 537us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 542us/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 497us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0032 - val_loss: 0.0020\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 484us/step - loss: 0.0032 - val_loss: 0.0019\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 484us/step - loss: 0.0028 - val_loss: 0.0021\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0028 - val_loss: 0.0019\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 484us/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 496us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 491us/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 497us/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 511us/step - loss: 0.0024 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 502us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "\n",
      "GENERATION 16\n",
      "\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 44s 11ms/step - loss: 0.0629 - val_loss: 0.0143\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 594us/step - loss: 0.0102 - val_loss: 0.0022\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 593us/step - loss: 0.0069 - val_loss: 0.0052\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 592us/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 592us/step - loss: 0.0033 - val_loss: 0.0015\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 588us/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 591us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 590us/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 590us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 593us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 592us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 591us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 588us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 597us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 591us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 595us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 594us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 592us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 590us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 590us/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 592us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 590us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 591us/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 592us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 44s 11ms/step - loss: 0.0959 - val_loss: 0.0154\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 567us/step - loss: 0.0093 - val_loss: 0.0022\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 573us/step - loss: 0.0056 - val_loss: 0.0123\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 566us/step - loss: 0.0039 - val_loss: 0.0020\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 570us/step - loss: 0.0029 - val_loss: 0.0014\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 575us/step - loss: 0.0025 - val_loss: 0.0039\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 570us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 571us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 566us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 569us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 569us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 573us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 551us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 9.9899e-04 - val_loss: 0.0010\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 9.7997e-04 - val_loss: 9.9941e-04\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 9.9297e-04 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 9.8547e-04 - val_loss: 0.0010\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 9.3619e-04 - val_loss: 0.0010\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 9.3706e-04 - val_loss: 9.4698e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 43s 11ms/step - loss: 0.0572 - val_loss: 0.0279\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 579us/step - loss: 0.0116 - val_loss: 0.0050\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 569us/step - loss: 0.0056 - val_loss: 0.0079\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 566us/step - loss: 0.0041 - val_loss: 0.0016\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 567us/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 573us/step - loss: 0.0021 - val_loss: 0.0035\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 566us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 566us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 571us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 568us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 568us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 571us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 575us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 574us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 575us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 570us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 585us/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 568us/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 570us/step - loss: 0.0011 - val_loss: 9.5109e-04\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 577us/step - loss: 9.7654e-04 - val_loss: 9.6515e-04\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 570us/step - loss: 9.5517e-04 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 572us/step - loss: 9.2295e-04 - val_loss: 9.1449e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 570us/step - loss: 9.2100e-04 - val_loss: 9.7870e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 571us/step - loss: 9.1987e-04 - val_loss: 8.6429e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 39s 10ms/step - loss: 1.3035 - val_loss: 0.0028\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 568us/step - loss: 0.0137 - val_loss: 0.0130\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 565us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 564us/step - loss: 0.0023 - val_loss: 0.0041\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 566us/step - loss: 0.0021 - val_loss: 0.0048\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 564us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 562us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 562us/step - loss: 0.0024 - val_loss: 0.0055\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 567us/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 566us/step - loss: 0.0020 - val_loss: 0.0034\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 565us/step - loss: 0.0020 - val_loss: 0.0041\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 565us/step - loss: 0.0021 - val_loss: 0.0049\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 565us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 567us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 571us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 566us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 566us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 567us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 565us/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 565us/step - loss: 0.0017 - val_loss: 0.0027\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 563us/step - loss: 0.0017 - val_loss: 0.0034\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 564us/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 564us/step - loss: 0.0016 - val_loss: 0.0036\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 565us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 39s 10ms/step - loss: 0.1276 - val_loss: 0.0016\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 378us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 377us/step - loss: 0.0064 - val_loss: 0.0099\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 378us/step - loss: 0.0057 - val_loss: 0.0184\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 379us/step - loss: 0.0099 - val_loss: 0.0214\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 382us/step - loss: 0.0092 - val_loss: 0.0159\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 381us/step - loss: 0.0105 - val_loss: 0.0096\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 383us/step - loss: 0.0081 - val_loss: 0.0113\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 378us/step - loss: 0.0077 - val_loss: 0.0143\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 379us/step - loss: 0.0079 - val_loss: 0.0078\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 379us/step - loss: 0.0065 - val_loss: 0.0095\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 378us/step - loss: 0.0076 - val_loss: 0.0089\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 379us/step - loss: 0.0055 - val_loss: 0.0087\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 376us/step - loss: 0.0087 - val_loss: 0.0080\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 378us/step - loss: 0.0030 - val_loss: 0.0076\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 378us/step - loss: 0.0061 - val_loss: 0.0087\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 383us/step - loss: 0.0069 - val_loss: 0.0052\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 379us/step - loss: 0.0029 - val_loss: 0.0082\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 378us/step - loss: 0.0083 - val_loss: 0.0105\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 379us/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 378us/step - loss: 0.0051 - val_loss: 0.0119\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 377us/step - loss: 0.0047 - val_loss: 0.0043\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 377us/step - loss: 0.0040 - val_loss: 0.0095\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 378us/step - loss: 0.0060 - val_loss: 0.0036\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 39s 10ms/step - loss: 0.6404 - val_loss: 0.0029\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 373us/step - loss: 0.0059 - val_loss: 0.0059\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 373us/step - loss: 0.0260 - val_loss: 0.2265\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 372us/step - loss: 0.0294 - val_loss: 0.0025\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 373us/step - loss: 0.0409 - val_loss: 0.0238\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 372us/step - loss: 0.0135 - val_loss: 0.0637\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 372us/step - loss: 0.0318 - val_loss: 0.0147\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 374us/step - loss: 0.0286 - val_loss: 0.0313\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 379us/step - loss: 0.0197 - val_loss: 0.0403\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 373us/step - loss: 0.0227 - val_loss: 0.0285\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 371us/step - loss: 0.0238 - val_loss: 0.0159\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 372us/step - loss: 0.0177 - val_loss: 0.0366\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 373us/step - loss: 0.0185 - val_loss: 0.0135\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 374us/step - loss: 0.0175 - val_loss: 0.0134\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 373us/step - loss: 0.0153 - val_loss: 0.0141\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 374us/step - loss: 0.0178 - val_loss: 0.0136\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 373us/step - loss: 0.0133 - val_loss: 0.0210\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 374us/step - loss: 0.0152 - val_loss: 0.0103\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 372us/step - loss: 0.0146 - val_loss: 0.0126\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 378us/step - loss: 0.0134 - val_loss: 0.0105\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 372us/step - loss: 0.0130 - val_loss: 0.0171\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 373us/step - loss: 0.0116 - val_loss: 0.0108\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 373us/step - loss: 0.0133 - val_loss: 0.0095\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 373us/step - loss: 0.0106 - val_loss: 0.0072\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 40s 10ms/step - loss: 0.4302 - val_loss: 0.0017\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 395us/step - loss: 0.0107 - val_loss: 0.0014\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 387us/step - loss: 0.0083 - val_loss: 0.0016\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 389us/step - loss: 0.0085 - val_loss: 0.0510\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 391us/step - loss: 0.0232 - val_loss: 0.0013\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 389us/step - loss: 0.0052 - val_loss: 0.0089\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 387us/step - loss: 0.0289 - val_loss: 0.0043\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 396us/step - loss: 0.0047 - val_loss: 0.0067\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 388us/step - loss: 0.0179 - val_loss: 0.0068\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 386us/step - loss: 0.0109 - val_loss: 0.0307\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 393us/step - loss: 0.0136 - val_loss: 0.0053\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 388us/step - loss: 0.0103 - val_loss: 0.0307\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 391us/step - loss: 0.0135 - val_loss: 0.0053\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 388us/step - loss: 0.0074 - val_loss: 0.0136\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 389us/step - loss: 0.0107 - val_loss: 0.0158\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 389us/step - loss: 0.0089 - val_loss: 0.0068\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 389us/step - loss: 0.0071 - val_loss: 0.0179\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 387us/step - loss: 0.0100 - val_loss: 0.0072\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 389us/step - loss: 0.0039 - val_loss: 0.0180\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 390us/step - loss: 0.0105 - val_loss: 0.0077\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 398us/step - loss: 0.0053 - val_loss: 0.0110\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 388us/step - loss: 0.0067 - val_loss: 0.0178\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 388us/step - loss: 0.0069 - val_loss: 0.0109\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 388us/step - loss: 0.0053 - val_loss: 0.0110\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 40s 10ms/step - loss: 416.2997 - val_loss: 0.0261\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 388us/step - loss: 0.7004 - val_loss: 0.0183\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 386us/step - loss: 0.5258 - val_loss: 0.0653\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 383us/step - loss: 0.4098 - val_loss: 0.1344\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 387us/step - loss: 0.3429 - val_loss: 0.1684\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 385us/step - loss: 0.3031 - val_loss: 0.1630\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 386us/step - loss: 0.2572 - val_loss: 0.1352\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 389us/step - loss: 0.2005 - val_loss: 0.1148\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 388us/step - loss: 0.1522 - val_loss: 0.0567\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 386us/step - loss: 0.1017 - val_loss: 0.0342\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 392us/step - loss: 0.0621 - val_loss: 0.0163\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 385us/step - loss: 0.0501 - val_loss: 0.2016\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 386us/step - loss: 0.3625 - val_loss: 0.0213\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 388us/step - loss: 0.0584 - val_loss: 0.2768\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 386us/step - loss: 0.3412 - val_loss: 0.0088\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 388us/step - loss: 0.0210 - val_loss: 0.0088\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 391us/step - loss: 0.3126 - val_loss: 0.0103\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 386us/step - loss: 0.0177 - val_loss: 0.0040\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 386us/step - loss: 0.0192 - val_loss: 0.1138\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 388us/step - loss: 0.1672 - val_loss: 0.0057\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 390us/step - loss: 0.0208 - val_loss: 0.0408\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 389us/step - loss: 0.0720 - val_loss: 0.0044\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 389us/step - loss: 0.0634 - val_loss: 0.0039\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 386us/step - loss: 0.0330 - val_loss: 0.0494\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 41s 10ms/step - loss: 0.9375 - val_loss: 0.0018\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 385us/step - loss: 0.0109 - val_loss: 0.0032\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 386us/step - loss: 0.0077 - val_loss: 0.0016\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 385us/step - loss: 0.0072 - val_loss: 0.0142\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 387us/step - loss: 0.0226 - val_loss: 0.0031\n",
      "Epoch 6/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 2s 384us/step - loss: 0.0118 - val_loss: 0.0581\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 385us/step - loss: 0.0242 - val_loss: 0.0143\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 384us/step - loss: 0.0338 - val_loss: 0.1838\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 384us/step - loss: 0.0366 - val_loss: 0.0028\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 384us/step - loss: 0.0086 - val_loss: 0.0136\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 394us/step - loss: 0.0140 - val_loss: 0.0167\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 385us/step - loss: 0.0225 - val_loss: 0.0426\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 387us/step - loss: 0.0252 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 387us/step - loss: 0.0033 - val_loss: 0.0027\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 385us/step - loss: 0.0183 - val_loss: 0.0407\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 385us/step - loss: 0.0119 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 385us/step - loss: 0.0087 - val_loss: 0.0273\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 385us/step - loss: 0.0227 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 386us/step - loss: 0.0030 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 384us/step - loss: 0.0112 - val_loss: 0.0176\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 395us/step - loss: 0.0069 - val_loss: 0.0054\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 389us/step - loss: 0.0127 - val_loss: 0.0092\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 385us/step - loss: 0.0064 - val_loss: 0.0019\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 387us/step - loss: 0.0098 - val_loss: 0.0140\n",
      "\n",
      "GENERATION 17\n",
      "\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 40s 10ms/step - loss: 0.0646 - val_loss: 0.0166\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 508us/step - loss: 0.0098 - val_loss: 0.0031\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 509us/step - loss: 0.0060 - val_loss: 0.0074\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 0.0034 - val_loss: 0.0041\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 509us/step - loss: 0.0028 - val_loss: 0.0013\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 508us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 509us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 510us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 508us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 510us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 509us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 510us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 510us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 509us/step - loss: 9.8896e-04 - val_loss: 0.0010\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 510us/step - loss: 9.7303e-04 - val_loss: 0.0010\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 9.9813e-04 - val_loss: 9.5475e-04\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 511us/step - loss: 9.6288e-04 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 509us/step - loss: 9.4347e-04 - val_loss: 9.6064e-04\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 510us/step - loss: 9.0652e-04 - val_loss: 9.0834e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 509us/step - loss: 8.9614e-04 - val_loss: 9.6625e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 8.9250e-04 - val_loss: 9.5531e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 40s 10ms/step - loss: 0.0600 - val_loss: 0.0201\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 0.0103 - val_loss: 0.0017\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 509us/step - loss: 0.0056 - val_loss: 0.0067\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 506us/step - loss: 0.0035 - val_loss: 0.0052\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 507us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 510us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 508us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 510us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 509us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 508us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 509us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 510us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 509us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 509us/step - loss: 9.9415e-04 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 9.8269e-04 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 508us/step - loss: 9.5605e-04 - val_loss: 0.0010\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 508us/step - loss: 9.3680e-04 - val_loss: 0.0010\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 511us/step - loss: 9.1596e-04 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 509us/step - loss: 9.4735e-04 - val_loss: 9.1605e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 509us/step - loss: 0.0010 - val_loss: 8.9267e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 9.6625e-04 - val_loss: 8.8182e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 41s 10ms/step - loss: 0.1470 - val_loss: 0.0606\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 399us/step - loss: 0.0592 - val_loss: 0.0286\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0521 - val_loss: 0.0219\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 402us/step - loss: 0.0471 - val_loss: 0.0183\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0436 - val_loss: 0.0166\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0398 - val_loss: 0.0148\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 401us/step - loss: 0.0367 - val_loss: 0.0136\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 401us/step - loss: 0.0331 - val_loss: 0.0119\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 398us/step - loss: 0.0300 - val_loss: 0.0106\n",
      "Epoch 10/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 2s 399us/step - loss: 0.0269 - val_loss: 0.0089\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0243 - val_loss: 0.0079\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0216 - val_loss: 0.0066\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0192 - val_loss: 0.0052\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 403us/step - loss: 0.0172 - val_loss: 0.0046\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 413us/step - loss: 0.0150 - val_loss: 0.0037\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0131 - val_loss: 0.0032\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 402us/step - loss: 0.0116 - val_loss: 0.0027\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 401us/step - loss: 0.0104 - val_loss: 0.0025\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0093 - val_loss: 0.0023\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 403us/step - loss: 0.0084 - val_loss: 0.0023\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 398us/step - loss: 0.0075 - val_loss: 0.0024\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0072 - val_loss: 0.0025\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 402us/step - loss: 0.0066 - val_loss: 0.0028\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 401us/step - loss: 0.0063 - val_loss: 0.0029\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 41s 10ms/step - loss: 0.0637 - val_loss: 0.0125\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 404us/step - loss: 0.0298 - val_loss: 0.0074\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 414us/step - loss: 0.0229 - val_loss: 0.0047\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 401us/step - loss: 0.0180 - val_loss: 0.0033\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0145 - val_loss: 0.0024\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 399us/step - loss: 0.0114 - val_loss: 0.0022\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0098 - val_loss: 0.0022\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0086 - val_loss: 0.0025\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 401us/step - loss: 0.0075 - val_loss: 0.0028\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 401us/step - loss: 0.0069 - val_loss: 0.0032\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 402us/step - loss: 0.0068 - val_loss: 0.0035\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 398us/step - loss: 0.0066 - val_loss: 0.0038\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 404us/step - loss: 0.0063 - val_loss: 0.0041\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 399us/step - loss: 0.0061 - val_loss: 0.0044\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 398us/step - loss: 0.0063 - val_loss: 0.0045\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0061 - val_loss: 0.0045\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0059 - val_loss: 0.0045\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0056 - val_loss: 0.0046\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0057 - val_loss: 0.0048\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 401us/step - loss: 0.0058 - val_loss: 0.0053\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 398us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 404us/step - loss: 0.0053 - val_loss: 0.0051\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 42s 11ms/step - loss: 0.1826 - val_loss: 0.1051\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.0741 - val_loss: 0.0523\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0672 - val_loss: 0.0412\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 0.0668 - val_loss: 0.0388\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 529us/step - loss: 0.0667 - val_loss: 0.0376\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0667 - val_loss: 0.0381\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 529us/step - loss: 0.0667 - val_loss: 0.0373\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0667 - val_loss: 0.0387\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 0.0667 - val_loss: 0.0372\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0667 - val_loss: 0.0376\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 529us/step - loss: 0.0667 - val_loss: 0.0374\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 0.0667 - val_loss: 0.0372\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 529us/step - loss: 0.0666 - val_loss: 0.0373\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 0.0666 - val_loss: 0.0383\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 529us/step - loss: 0.0666 - val_loss: 0.0383\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0666 - val_loss: 0.0380\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0666 - val_loss: 0.0386\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 529us/step - loss: 0.0666 - val_loss: 0.0390\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 0.0666 - val_loss: 0.0385\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 529us/step - loss: 0.0666 - val_loss: 0.0378\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 0.0666 - val_loss: 0.0369\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 528us/step - loss: 0.0666 - val_loss: 0.0379\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0665 - val_loss: 0.0378\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0666 - val_loss: 0.0376\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 43s 11ms/step - loss: 0.0660 - val_loss: 0.0157\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 528us/step - loss: 0.0340 - val_loss: 0.0096\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 0.0272 - val_loss: 0.0067\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 535us/step - loss: 0.0214 - val_loss: 0.0048\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 529us/step - loss: 0.0169 - val_loss: 0.0037\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 529us/step - loss: 0.0138 - val_loss: 0.0027\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 0.0120 - val_loss: 0.0023\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 0.0098 - val_loss: 0.0022\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 528us/step - loss: 0.0089 - val_loss: 0.0023\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 529us/step - loss: 0.0078 - val_loss: 0.0026\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0068 - val_loss: 0.0027\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 0.0064 - val_loss: 0.0030\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 0.0063 - val_loss: 0.0031\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 0.0060 - val_loss: 0.0033\n",
      "Epoch 15/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0059 - val_loss: 0.0036\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 0.0060 - val_loss: 0.0039\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 528us/step - loss: 0.0057 - val_loss: 0.0039\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 528us/step - loss: 0.0056 - val_loss: 0.0040\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0057 - val_loss: 0.0042\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 529us/step - loss: 0.0056 - val_loss: 0.0044\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 529us/step - loss: 0.0052 - val_loss: 0.0042\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 0.0052 - val_loss: 0.0043\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 0.0053 - val_loss: 0.0045\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 528us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 42s 10ms/step - loss: 0.1180 - val_loss: 0.0527\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 575us/step - loss: 0.0474 - val_loss: 0.0220\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 571us/step - loss: 0.0387 - val_loss: 0.0153\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 574us/step - loss: 0.0357 - val_loss: 0.0123\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 570us/step - loss: 0.0329 - val_loss: 0.0106\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 576us/step - loss: 0.0297 - val_loss: 0.0093\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 576us/step - loss: 0.0270 - val_loss: 0.0083\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 572us/step - loss: 0.0247 - val_loss: 0.0072\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 570us/step - loss: 0.0226 - val_loss: 0.0063\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 574us/step - loss: 0.0202 - val_loss: 0.0054\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 589us/step - loss: 0.0184 - val_loss: 0.0048\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 576us/step - loss: 0.0163 - val_loss: 0.0041\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 572us/step - loss: 0.0151 - val_loss: 0.0035\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 572us/step - loss: 0.0133 - val_loss: 0.0031\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 572us/step - loss: 0.0119 - val_loss: 0.0028\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 570us/step - loss: 0.0113 - val_loss: 0.0025\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 578us/step - loss: 0.0098 - val_loss: 0.0024\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 573us/step - loss: 0.0089 - val_loss: 0.0023\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 570us/step - loss: 0.0081 - val_loss: 0.0024\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 573us/step - loss: 0.0076 - val_loss: 0.0024\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 572us/step - loss: 0.0072 - val_loss: 0.0025\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 572us/step - loss: 0.0068 - val_loss: 0.0027\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 571us/step - loss: 0.0064 - val_loss: 0.0028\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 574us/step - loss: 0.0061 - val_loss: 0.0030\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 44s 11ms/step - loss: 0.0380 - val_loss: 0.0072\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 572us/step - loss: 0.0075 - val_loss: 0.0172\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 573us/step - loss: 0.0119 - val_loss: 0.0164\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 573us/step - loss: 0.0050 - val_loss: 0.0045\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 571us/step - loss: 0.0039 - val_loss: 0.0030\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 573us/step - loss: 0.0061 - val_loss: 0.0065\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 573us/step - loss: 0.0093 - val_loss: 0.0058\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 571us/step - loss: 0.0067 - val_loss: 0.0017\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 572us/step - loss: 0.0041 - val_loss: 0.0019\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 570us/step - loss: 0.0067 - val_loss: 0.0048\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 571us/step - loss: 0.0088 - val_loss: 0.0037\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 572us/step - loss: 0.0062 - val_loss: 0.0016\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 572us/step - loss: 0.0050 - val_loss: 0.0017\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 574us/step - loss: 0.0052 - val_loss: 0.0015\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 574us/step - loss: 0.0040 - val_loss: 0.0015\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 575us/step - loss: 0.0042 - val_loss: 0.0020\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 573us/step - loss: 0.0064 - val_loss: 0.0050\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 571us/step - loss: 0.0078 - val_loss: 0.0022\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 570us/step - loss: 0.0045 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 570us/step - loss: 0.0050 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 573us/step - loss: 0.0041 - val_loss: 0.0014\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 571us/step - loss: 0.0039 - val_loss: 0.0019\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 570us/step - loss: 0.0054 - val_loss: 0.0017\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 571us/step - loss: 0.0033 - val_loss: 0.0013\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 44s 11ms/step - loss: 0.0739 - val_loss: 0.0190\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 583us/step - loss: 0.0103 - val_loss: 0.0045\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 583us/step - loss: 0.0056 - val_loss: 0.0117\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 584us/step - loss: 0.0048 - val_loss: 0.0014\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 580us/step - loss: 0.0038 - val_loss: 0.0032\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 581us/step - loss: 0.0030 - val_loss: 0.0048\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 582us/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 584us/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 583us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 585us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 584us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 581us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 582us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 583us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 582us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 584us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 584us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 582us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 589us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 20/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 2s 581us/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 583us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 581us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 580us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 586us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "\n",
      "GENERATION 18\n",
      "\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 48s 12ms/step - loss: 0.0786 - val_loss: 0.0078\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 0.0178 - val_loss: 0.0058\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 0.0066 - val_loss: 0.0112\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 509us/step - loss: 0.0041 - val_loss: 0.0051\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 506us/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 508us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 508us/step - loss: 0.0021 - val_loss: 0.0035\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 506us/step - loss: 0.0020 - val_loss: 0.0030\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 506us/step - loss: 0.0019 - val_loss: 0.0030\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 509us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 508us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 509us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 510us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 507us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 511us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 507us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 508us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 46s 12ms/step - loss: 0.0629 - val_loss: 0.0270\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 539us/step - loss: 0.0108 - val_loss: 0.0016\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 617us/step - loss: 0.0058 - val_loss: 0.0031\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 3s 649us/step - loss: 0.0035 - val_loss: 0.0056\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 567us/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 548us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 545us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 547us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 543us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 540us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 542us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 547us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 542us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 541us/step - loss: 9.8690e-04 - val_loss: 0.0010\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 544us/step - loss: 9.6046e-04 - val_loss: 0.0010\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 541us/step - loss: 0.0010 - val_loss: 9.5036e-04\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 542us/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 552us/step - loss: 0.0010 - val_loss: 9.1522e-04\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 543us/step - loss: 0.0011 - val_loss: 9.2686e-04\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 540us/step - loss: 9.2454e-04 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 547us/step - loss: 9.0969e-04 - val_loss: 8.6691e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 552us/step - loss: 9.2644e-04 - val_loss: 8.4625e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 539us/step - loss: 8.3926e-04 - val_loss: 8.4845e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 49s 12ms/step - loss: 0.1030 - val_loss: 0.0673\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 582us/step - loss: 0.0310 - val_loss: 0.0245\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 567us/step - loss: 0.0127 - val_loss: 0.0127\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 567us/step - loss: 0.0075 - val_loss: 0.0032\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 565us/step - loss: 0.0046 - val_loss: 0.0017\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 561us/step - loss: 0.0036 - val_loss: 0.0023\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 547us/step - loss: 0.0033 - val_loss: 0.0021\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 553us/step - loss: 0.0030 - val_loss: 0.0016\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 551us/step - loss: 0.0029 - val_loss: 0.0018\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 550us/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 558us/step - loss: 0.0026 - val_loss: 0.0015\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 555us/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 554us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 559us/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 552us/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 551us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 555us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 555us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 553us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 578us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 563us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 567us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 553us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 563us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 51s 13ms/step - loss: 0.0791 - val_loss: 0.0448\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 580us/step - loss: 0.0159 - val_loss: 0.0039\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 567us/step - loss: 0.0078 - val_loss: 0.0043\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 555us/step - loss: 0.0051 - val_loss: 0.0053\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 552us/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 565us/step - loss: 0.0032 - val_loss: 0.0017\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 557us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 550us/step - loss: 0.0026 - val_loss: 0.0041\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 556us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 548us/step - loss: 0.0023 - val_loss: 0.0041\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 549us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 548us/step - loss: 0.0022 - val_loss: 0.0059\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 549us/step - loss: 0.0023 - val_loss: 0.0042\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 548us/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 546us/step - loss: 0.0020 - val_loss: 0.0058\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 549us/step - loss: 0.0020 - val_loss: 0.0065\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 548us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 546us/step - loss: 0.0019 - val_loss: 0.0067\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 547us/step - loss: 0.0019 - val_loss: 0.0072\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 547us/step - loss: 0.0019 - val_loss: 0.0054\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 550us/step - loss: 0.0018 - val_loss: 0.0100\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 549us/step - loss: 0.0018 - val_loss: 0.0075\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 556us/step - loss: 0.0017 - val_loss: 0.0101\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 550us/step - loss: 0.0017 - val_loss: 0.0105\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 47s 12ms/step - loss: 0.1105 - val_loss: 0.0160\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 547us/step - loss: 0.0661 - val_loss: 0.0387\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 549us/step - loss: 0.0636 - val_loss: 0.0836\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 548us/step - loss: 0.0618 - val_loss: 0.0254\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 544us/step - loss: 0.0227 - val_loss: 0.0040\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 551us/step - loss: 0.0079 - val_loss: 0.0438\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 545us/step - loss: 0.0110 - val_loss: 0.0202\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 549us/step - loss: 0.0068 - val_loss: 0.0215\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 547us/step - loss: 0.0056 - val_loss: 0.0127\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 547us/step - loss: 0.0055 - val_loss: 0.0105\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 548us/step - loss: 0.0042 - val_loss: 0.0151\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 546us/step - loss: 0.0035 - val_loss: 0.0139\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 545us/step - loss: 0.0037 - val_loss: 0.0051\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 546us/step - loss: 0.0041 - val_loss: 0.0085\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 544us/step - loss: 0.0033 - val_loss: 0.0058\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 546us/step - loss: 0.0033 - val_loss: 0.0121\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 546us/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 547us/step - loss: 0.0026 - val_loss: 0.0043\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 548us/step - loss: 0.0025 - val_loss: 0.0043\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 547us/step - loss: 0.0023 - val_loss: 0.0056\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 546us/step - loss: 0.0027 - val_loss: 0.0161\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 546us/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 546us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 549us/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 48s 12ms/step - loss: 0.1246 - val_loss: 0.0468\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 548us/step - loss: 0.0547 - val_loss: 0.1104\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 554us/step - loss: 0.0293 - val_loss: 0.0093\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 549us/step - loss: 0.0139 - val_loss: 0.0092\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 548us/step - loss: 0.0115 - val_loss: 0.0054\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 547us/step - loss: 0.0112 - val_loss: 0.0231\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 551us/step - loss: 0.0248 - val_loss: 0.0619\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 550us/step - loss: 0.0204 - val_loss: 0.0028\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 553us/step - loss: 0.0079 - val_loss: 0.0377\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 554us/step - loss: 0.0079 - val_loss: 0.0256\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 551us/step - loss: 0.0054 - val_loss: 0.0045\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 551us/step - loss: 0.0046 - val_loss: 0.0191\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 550us/step - loss: 0.0063 - val_loss: 0.0053\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 552us/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 556us/step - loss: 0.0029 - val_loss: 0.0053\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 551us/step - loss: 0.0032 - val_loss: 0.0144\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 553us/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 553us/step - loss: 0.0033 - val_loss: 0.0081\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 551us/step - loss: 0.0032 - val_loss: 0.0059\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 549us/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 550us/step - loss: 0.0026 - val_loss: 0.0020\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 549us/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 551us/step - loss: 0.0031 - val_loss: 0.0016\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 548us/step - loss: 0.0031 - val_loss: 0.0014\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 48s 12ms/step - loss: 0.1743 - val_loss: 0.0389\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 509us/step - loss: 0.0668 - val_loss: 0.0472\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 0.0669 - val_loss: 0.0392\n",
      "Epoch 4/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 2s 512us/step - loss: 0.0668 - val_loss: 0.0361\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 508us/step - loss: 0.0669 - val_loss: 0.0386\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 511us/step - loss: 0.0669 - val_loss: 0.0355\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 511us/step - loss: 0.0660 - val_loss: 0.0333\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 511us/step - loss: 0.0664 - val_loss: 0.0379\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 510us/step - loss: 0.0629 - val_loss: 0.0187\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 509us/step - loss: 0.0543 - val_loss: 0.0348\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 0.0663 - val_loss: 0.0388\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 510us/step - loss: 0.0629 - val_loss: 0.0863\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 510us/step - loss: 0.0575 - val_loss: 0.0150\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 0.0234 - val_loss: 0.0041\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 510us/step - loss: 0.0146 - val_loss: 0.0028\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 511us/step - loss: 0.0125 - val_loss: 0.0041\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 508us/step - loss: 0.0066 - val_loss: 0.0017\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 511us/step - loss: 0.0078 - val_loss: 0.0019\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 0.0041 - val_loss: 0.0059\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 509us/step - loss: 0.0067 - val_loss: 0.0015\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 511us/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 511us/step - loss: 0.0061 - val_loss: 0.0023\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 510us/step - loss: 0.0032 - val_loss: 0.0023\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 510us/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 47s 12ms/step - loss: 0.2082 - val_loss: 0.0335\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 354us/step - loss: 0.0657 - val_loss: 0.0549\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 356us/step - loss: 0.0640 - val_loss: 0.0166\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 352us/step - loss: 0.0234 - val_loss: 0.0042\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 355us/step - loss: 0.0155 - val_loss: 0.0041\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 355us/step - loss: 0.0102 - val_loss: 0.0023\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 358us/step - loss: 0.0081 - val_loss: 0.0026\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 354us/step - loss: 0.0053 - val_loss: 0.0021\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 354us/step - loss: 0.0050 - val_loss: 0.0030\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 354us/step - loss: 0.0046 - val_loss: 0.0021\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 358us/step - loss: 0.0041 - val_loss: 0.0022\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 352us/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 353us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 353us/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 354us/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 353us/step - loss: 0.0047 - val_loss: 0.0019\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 354us/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 359us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 352us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 365us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 355us/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 354us/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 351us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 354us/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 48s 12ms/step - loss: 0.8389 - val_loss: 0.0073\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 358us/step - loss: 0.0109 - val_loss: 0.0031\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 358us/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 357us/step - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 358us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 357us/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 365us/step - loss: 0.0033 - val_loss: 0.0022\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 357us/step - loss: 0.0030 - val_loss: 0.0017\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 358us/step - loss: 0.0031 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 359us/step - loss: 0.0027 - val_loss: 0.0013\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 358us/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 359us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 359us/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 356us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 360us/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 365us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 359us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 361us/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 361us/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 360us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 359us/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 357us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 359us/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 359us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "\n",
      "GENERATION 19\n",
      "\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 49s 12ms/step - loss: 0.0658 - val_loss: 0.0199\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 0.0097 - val_loss: 0.0020\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 0.0059 - val_loss: 0.0034\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0012 - val_loss: 0.0014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 9.9286e-04 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 9.7930e-04 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 9.5541e-04 - val_loss: 9.4692e-04\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 9.4732e-04 - val_loss: 9.5102e-04\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 9.0551e-04 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 0.0010 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0011 - val_loss: 9.8487e-04\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 9.1306e-04 - val_loss: 8.6488e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 8.6751e-04 - val_loss: 9.5401e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 8.4996e-04 - val_loss: 0.0012\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 50s 13ms/step - loss: 0.0567 - val_loss: 0.0023\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 529us/step - loss: 0.0073 - val_loss: 0.0024\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 0.0042 - val_loss: 0.0018\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 0.0032 - val_loss: 0.0017\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 528us/step - loss: 0.0024 - val_loss: 0.0043\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 528us/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 529us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 9.6944e-04 - val_loss: 0.0010\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 9.6665e-04 - val_loss: 0.0010\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 9.5524e-04 - val_loss: 0.0010\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 9.4252e-04 - val_loss: 9.3809e-04\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 9.2250e-04 - val_loss: 9.0356e-04\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 9.0779e-04 - val_loss: 9.0246e-04\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 8.8099e-04 - val_loss: 9.0496e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 8.8232e-04 - val_loss: 8.5949e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 528us/step - loss: 8.4908e-04 - val_loss: 9.6751e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 49s 12ms/step - loss: 0.0621 - val_loss: 0.0284\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 395us/step - loss: 0.0111 - val_loss: 0.0029\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 391us/step - loss: 0.0052 - val_loss: 0.0111\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 387us/step - loss: 0.0037 - val_loss: 0.0015\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 388us/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 388us/step - loss: 0.0020 - val_loss: 0.0032\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 389us/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 387us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 388us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 387us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 388us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 389us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 392us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 388us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 389us/step - loss: 0.0010 - val_loss: 9.8772e-04\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 389us/step - loss: 9.7397e-04 - val_loss: 9.8365e-04\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 387us/step - loss: 9.6395e-04 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 388us/step - loss: 9.8641e-04 - val_loss: 9.4279e-04\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 389us/step - loss: 9.4610e-04 - val_loss: 9.4760e-04\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 388us/step - loss: 9.1641e-04 - val_loss: 9.2549e-04\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 395us/step - loss: 9.3917e-04 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 388us/step - loss: 9.4421e-04 - val_loss: 8.7021e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 396us/step - loss: 8.9276e-04 - val_loss: 8.7972e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 389us/step - loss: 8.8975e-04 - val_loss: 0.0011\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 50s 13ms/step - loss: 0.0611 - val_loss: 0.0048\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 560us/step - loss: 0.0105 - val_loss: 0.0053\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 557us/step - loss: 0.0055 - val_loss: 0.0014\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 559us/step - loss: 0.0044 - val_loss: 0.0065\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 556us/step - loss: 0.0035 - val_loss: 0.0016\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 556us/step - loss: 0.0031 - val_loss: 0.0013\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 561us/step - loss: 0.0029 - val_loss: 0.0018\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 557us/step - loss: 0.0026 - val_loss: 0.0020\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 557us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 556us/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 556us/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 557us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 554us/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 561us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 560us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 559us/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 556us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 555us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 557us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 555us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 559us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 556us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 557us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 557us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 52s 13ms/step - loss: 0.1008 - val_loss: 0.0273\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0438 - val_loss: 0.0070\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.0122 - val_loss: 0.0534\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 535us/step - loss: 0.0215 - val_loss: 0.0114\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0067 - val_loss: 0.0144\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 535us/step - loss: 0.0071 - val_loss: 0.0133\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 541us/step - loss: 0.0066 - val_loss: 0.0145\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 535us/step - loss: 0.0084 - val_loss: 0.0245\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 536us/step - loss: 0.0082 - val_loss: 0.0131\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 536us/step - loss: 0.0063 - val_loss: 0.0127\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 540us/step - loss: 0.0051 - val_loss: 0.0154\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 536us/step - loss: 0.0079 - val_loss: 0.0171\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 535us/step - loss: 0.0094 - val_loss: 0.0193\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.0081 - val_loss: 0.0133\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 539us/step - loss: 0.0068 - val_loss: 0.0143\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.0077 - val_loss: 0.0147\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 537us/step - loss: 0.0073 - val_loss: 0.0140\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 539us/step - loss: 0.0082 - val_loss: 0.0177\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.0075 - val_loss: 0.0147\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 536us/step - loss: 0.0070 - val_loss: 0.0112\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 542us/step - loss: 0.0068 - val_loss: 0.0131\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 537us/step - loss: 0.0066 - val_loss: 0.0162\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 536us/step - loss: 0.0084 - val_loss: 0.0160\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 537us/step - loss: 0.0088 - val_loss: 0.0187\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 52s 13ms/step - loss: 0.1755 - val_loss: 0.0092\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 543us/step - loss: 0.0465 - val_loss: 0.0037\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 541us/step - loss: 0.0725 - val_loss: 0.0234\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 541us/step - loss: 0.0539 - val_loss: 0.0340\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 541us/step - loss: 0.0434 - val_loss: 0.0402\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 540us/step - loss: 0.0281 - val_loss: 0.0411\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 543us/step - loss: 0.0249 - val_loss: 0.0360\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 543us/step - loss: 0.0165 - val_loss: 0.0295\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.0131 - val_loss: 0.0264\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.0167 - val_loss: 0.0405\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 542us/step - loss: 0.0174 - val_loss: 0.0364\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 540us/step - loss: 0.0159 - val_loss: 0.0312\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 544us/step - loss: 0.0147 - val_loss: 0.0390\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 539us/step - loss: 0.0180 - val_loss: 0.0269\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 542us/step - loss: 0.0088 - val_loss: 0.0216\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 543us/step - loss: 0.0130 - val_loss: 0.0397\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 541us/step - loss: 0.0199 - val_loss: 0.0352\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 539us/step - loss: 0.0133 - val_loss: 0.0277\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 541us/step - loss: 0.0124 - val_loss: 0.0292\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 540us/step - loss: 0.0145 - val_loss: 0.0320\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 542us/step - loss: 0.0111 - val_loss: 0.0329\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 544us/step - loss: 0.0137 - val_loss: 0.0304\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 540us/step - loss: 0.0122 - val_loss: 0.0210\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 542us/step - loss: 0.0101 - val_loss: 0.0364\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 52s 13ms/step - loss: 0.3035 - val_loss: 0.0016\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 537us/step - loss: 0.0066 - val_loss: 0.0015\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 543us/step - loss: 0.0058 - val_loss: 0.0016\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 542us/step - loss: 0.0050 - val_loss: 0.0017\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 539us/step - loss: 0.0048 - val_loss: 0.0015\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 540us/step - loss: 0.0041 - val_loss: 0.0021\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 539us/step - loss: 0.0050 - val_loss: 0.0127\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 541us/step - loss: 0.0131 - val_loss: 0.0063\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 539us/step - loss: 0.0040 - val_loss: 0.0022\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 540us/step - loss: 0.0060 - val_loss: 0.0248\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 544us/step - loss: 0.0177 - val_loss: 0.0100\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.0072 - val_loss: 0.0053\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.0082 - val_loss: 0.0146\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.0109 - val_loss: 0.0082\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.0097 - val_loss: 0.0194\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.0202 - val_loss: 0.0173\n",
      "Epoch 17/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.0066 - val_loss: 0.0076\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 546us/step - loss: 0.0032 - val_loss: 0.0039\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.0069 - val_loss: 0.0195\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.0083 - val_loss: 0.0140\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 536us/step - loss: 0.0086 - val_loss: 0.0100\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.0079 - val_loss: 0.0118\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 540us/step - loss: 0.0067 - val_loss: 0.0099\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.0069 - val_loss: 0.0154\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 53s 13ms/step - loss: 1.9529 - val_loss: 0.0066\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 439us/step - loss: 0.0166 - val_loss: 0.0040\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 437us/step - loss: 0.0135 - val_loss: 0.0025\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 440us/step - loss: 0.0114 - val_loss: 0.0039\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 439us/step - loss: 0.0101 - val_loss: 0.0016\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 441us/step - loss: 0.0093 - val_loss: 0.0017\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 443us/step - loss: 0.0082 - val_loss: 0.0022\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 438us/step - loss: 0.0245 - val_loss: 0.0992\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 440us/step - loss: 0.0603 - val_loss: 0.0136\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 439us/step - loss: 0.0098 - val_loss: 0.0042\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 443us/step - loss: 0.0060 - val_loss: 0.0031\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 440us/step - loss: 0.0166 - val_loss: 0.1011\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 439us/step - loss: 0.0995 - val_loss: 0.0632\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 440us/step - loss: 0.0181 - val_loss: 0.0035\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 442us/step - loss: 0.0040 - val_loss: 0.0021\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 452us/step - loss: 0.0037 - val_loss: 0.0022\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 444us/step - loss: 0.0041 - val_loss: 0.0095\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 440us/step - loss: 0.0480 - val_loss: 0.1091\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 439us/step - loss: 0.2341 - val_loss: 0.1010\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 439us/step - loss: 0.0157 - val_loss: 0.0032\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 441us/step - loss: 0.0035 - val_loss: 0.0034\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 440us/step - loss: 0.0032 - val_loss: 0.0025\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 439us/step - loss: 0.0031 - val_loss: 0.0026\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 438us/step - loss: 0.0030 - val_loss: 0.0018\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 53s 13ms/step - loss: 0.9722 - val_loss: 0.0027\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 442us/step - loss: 0.0104 - val_loss: 0.0024\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 442us/step - loss: 0.0093 - val_loss: 0.0019\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 446us/step - loss: 0.0076 - val_loss: 0.0015\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 440us/step - loss: 0.0068 - val_loss: 0.0014\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 444us/step - loss: 0.0061 - val_loss: 0.0013\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 444us/step - loss: 0.0065 - val_loss: 0.0038\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 440us/step - loss: 0.0130 - val_loss: 0.0177\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 440us/step - loss: 0.0131 - val_loss: 0.0076\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 442us/step - loss: 0.0088 - val_loss: 0.0098\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 443us/step - loss: 0.0213 - val_loss: 0.0408\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 440us/step - loss: 0.0433 - val_loss: 0.0223\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 443us/step - loss: 0.0063 - val_loss: 0.0045\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 442us/step - loss: 0.0037 - val_loss: 0.0013\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 440us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 445us/step - loss: 0.0123 - val_loss: 0.0730\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 441us/step - loss: 0.1806 - val_loss: 0.3128\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 440us/step - loss: 0.0961 - val_loss: 0.0029\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 441us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 442us/step - loss: 0.0031 - val_loss: 0.0017\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 446us/step - loss: 0.0031 - val_loss: 0.0013\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 443us/step - loss: 0.0029 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 441us/step - loss: 0.0030 - val_loss: 0.0013\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 442us/step - loss: 0.0029 - val_loss: 0.0021\n"
     ]
    }
   ],
   "source": [
    "best_models = breed_population(X_train, Y_train, generations=20, population_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.008704171516001225,\n",
       " 0.0014979593688622117,\n",
       " 0.001774270087480545,\n",
       " 0.0018782139522954822,\n",
       " 0.0033186464570462704,\n",
       " 0.002082518534734845,\n",
       " 0.0017565811285749078,\n",
       " 0.00133451446890831,\n",
       " 0.001206367858685553,\n",
       " 0.0013581846142187715,\n",
       " 0.0010819032322615385,\n",
       " 0.0012914488324895501,\n",
       " 0.0012309554731473327,\n",
       " 0.0010158492950722575,\n",
       " 0.0009736364590935409,\n",
       " 0.0009861082071438432,\n",
       " 0.0009522227919660509,\n",
       " 0.00100131263025105,\n",
       " 0.0008977294201031327,\n",
       " 0.0008385175606235862,\n",
       " 0.0008962243446148932,\n",
       " 0.0008126437896862626,\n",
       " 0.0009106394718401134,\n",
       " 0.0007859669276513159]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models[0][1].history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal parameters\n",
      "_______________________\n",
      "density: 186\n",
      "activation: softsign\n",
      "twice: True\n",
      "full_density: True\n",
      "lstmsize: 158\n",
      "shuffle: True\n",
      "optimizer: adam\n"
     ]
    }
   ],
   "source": [
    "print('optimal parameters')\n",
    "print('_______________________')\n",
    "for key,val in best_models[0][2].items():\n",
    "    if key != 'x' and key != 'y': print(f'{key}: {val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_94\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_187 (LSTM)              (None, 92, 158)           103648    \n",
      "_________________________________________________________________\n",
      "lstm_188 (LSTM)              (None, 158)               200344    \n",
      "_________________________________________________________________\n",
      "dense_478 (Dense)            (None, 186)               29574     \n",
      "_________________________________________________________________\n",
      "dense_479 (Dense)            (None, 93)                17391     \n",
      "_________________________________________________________________\n",
      "dense_480 (Dense)            (None, 46)                4324      \n",
      "_________________________________________________________________\n",
      "dense_481 (Dense)            (None, 23)                1081      \n",
      "_________________________________________________________________\n",
      "dense_482 (Dense)            (None, 1)                 24        \n",
      "=================================================================\n",
      "Total params: 356,386\n",
      "Trainable params: 356,386\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_models[0][0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibm_checkpoint = ModelCheckpoint(\n",
    "    filepath='./checkpoints/IBM.{epoch}-{val_loss}.hdf5',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = best_models[0][2]\n",
    "params['x'] = X_train\n",
    "params['y'] = Y_train\n",
    "params['epochs'] = 2000\n",
    "params['callbacks'] = [ibm_checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/2000\n",
      "3977/3977 [==============================] - 53s 13ms/step - loss: 0.0701 - val_loss: 0.0102\n",
      "Epoch 2/2000\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 0.0102 - val_loss: 0.0044\n",
      "Epoch 3/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 0.0061 - val_loss: 0.0027\n",
      "Epoch 4/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 0.0037 - val_loss: 0.0057\n",
      "Epoch 5/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 0.0030 - val_loss: 0.0016\n",
      "Epoch 6/2000\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 7/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 8/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 9/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 10/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 11/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 12/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 13/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 14/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 15/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 16/2000\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 17/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 18/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 9.9854e-04 - val_loss: 0.0012\n",
      "Epoch 19/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 9.7812e-04 - val_loss: 9.6236e-04\n",
      "Epoch 20/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 9.7994e-04 - val_loss: 9.9980e-04\n",
      "Epoch 21/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 9.3610e-04 - val_loss: 9.4802e-04\n",
      "Epoch 22/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 9.2440e-04 - val_loss: 9.9628e-04\n",
      "Epoch 23/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 8.9644e-04 - val_loss: 9.3231e-04\n",
      "Epoch 24/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 8.8505e-04 - val_loss: 9.0174e-04\n",
      "Epoch 25/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 8.7163e-04 - val_loss: 8.6501e-04\n",
      "Epoch 26/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 8.6205e-04 - val_loss: 8.4356e-04\n",
      "Epoch 27/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 8.5806e-04 - val_loss: 8.2264e-04\n",
      "Epoch 28/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 8.3419e-04 - val_loss: 9.4605e-04\n",
      "Epoch 29/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 8.4737e-04 - val_loss: 0.0010\n",
      "Epoch 30/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 8.3636e-04 - val_loss: 7.8515e-04\n",
      "Epoch 31/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 8.1605e-04 - val_loss: 7.7237e-04\n",
      "Epoch 32/2000\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 7.8005e-04 - val_loss: 7.7468e-04\n",
      "Epoch 33/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 7.7933e-04 - val_loss: 8.6266e-04\n",
      "Epoch 34/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 8.7676e-04 - val_loss: 7.4029e-04\n",
      "Epoch 35/2000\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 7.9420e-04 - val_loss: 8.6822e-04\n",
      "Epoch 36/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 8.0772e-04 - val_loss: 7.1121e-04\n",
      "Epoch 37/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 7.8472e-04 - val_loss: 7.1791e-04\n",
      "Epoch 38/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 7.9478e-04 - val_loss: 7.2799e-04\n",
      "Epoch 39/2000\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 7.2993e-04 - val_loss: 6.8456e-04\n",
      "Epoch 40/2000\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 7.1296e-04 - val_loss: 6.8693e-04\n",
      "Epoch 41/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 7.3758e-04 - val_loss: 7.1800e-04\n",
      "Epoch 42/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 7.2164e-04 - val_loss: 8.1822e-04\n",
      "Epoch 43/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 7.0103e-04 - val_loss: 6.6403e-04\n",
      "Epoch 44/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 6.7057e-04 - val_loss: 6.5162e-04\n",
      "Epoch 45/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 6.8022e-04 - val_loss: 6.6633e-04\n",
      "Epoch 46/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 7.3465e-04 - val_loss: 8.0301e-04\n",
      "Epoch 47/2000\n",
      "3977/3977 [==============================] - 2s 537us/step - loss: 6.6193e-04 - val_loss: 8.2859e-04\n",
      "Epoch 48/2000\n",
      "3977/3977 [==============================] - 2s 548us/step - loss: 7.3411e-04 - val_loss: 9.5577e-04\n",
      "Epoch 49/2000\n",
      "3977/3977 [==============================] - 2s 551us/step - loss: 7.6723e-04 - val_loss: 0.0010\n",
      "Epoch 50/2000\n",
      "3977/3977 [==============================] - 2s 541us/step - loss: 6.6985e-04 - val_loss: 6.4720e-04\n",
      "Epoch 51/2000\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 6.6910e-04 - val_loss: 6.2577e-04\n",
      "Epoch 52/2000\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 6.3243e-04 - val_loss: 5.9280e-04\n",
      "Epoch 53/2000\n",
      "3977/3977 [==============================] - 2s 529us/step - loss: 6.2442e-04 - val_loss: 6.3248e-04\n",
      "Epoch 54/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 6.1767e-04 - val_loss: 6.2685e-04\n",
      "Epoch 55/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 5.8877e-04 - val_loss: 6.2247e-04\n",
      "Epoch 56/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 6.6178e-04 - val_loss: 7.6561e-04\n",
      "Epoch 57/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 6.1179e-04 - val_loss: 7.4030e-04\n",
      "Epoch 58/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 6.7155e-04 - val_loss: 0.0015\n",
      "Epoch 59/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 8.3007e-04 - val_loss: 5.7880e-04\n",
      "Epoch 60/2000\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 6.7052e-04 - val_loss: 5.7834e-04\n",
      "Epoch 61/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 5.7258e-04 - val_loss: 5.7171e-04\n",
      "Epoch 62/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 5.8891e-04 - val_loss: 5.9205e-04\n",
      "Epoch 63/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 5.6176e-04 - val_loss: 6.4472e-04\n",
      "Epoch 64/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 5.3987e-04 - val_loss: 6.1296e-04\n",
      "Epoch 65/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 5.7823e-04 - val_loss: 5.6165e-04\n",
      "Epoch 66/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 5.3469e-04 - val_loss: 5.4435e-04\n",
      "Epoch 67/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 5.2563e-04 - val_loss: 6.0001e-04\n",
      "Epoch 68/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 6.6597e-04 - val_loss: 0.0010\n",
      "Epoch 69/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 6.8137e-04 - val_loss: 6.3608e-04\n",
      "Epoch 70/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 6.9679e-04 - val_loss: 6.3609e-04\n",
      "Epoch 71/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 5.8150e-04 - val_loss: 5.3450e-04\n",
      "Epoch 72/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 5.2138e-04 - val_loss: 5.4427e-04\n",
      "Epoch 73/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 5.1996e-04 - val_loss: 5.7385e-04\n",
      "Epoch 74/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 5.9197e-04 - val_loss: 6.4322e-04\n",
      "Epoch 75/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 5.5775e-04 - val_loss: 7.8917e-04\n",
      "Epoch 76/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 5.1159e-04 - val_loss: 6.9250e-04\n",
      "Epoch 77/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 5.2488e-04 - val_loss: 5.9187e-04\n",
      "Epoch 78/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 5.2499e-04 - val_loss: 5.8180e-04\n",
      "Epoch 79/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 4.9802e-04 - val_loss: 5.8016e-04\n",
      "Epoch 80/2000\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 4.7502e-04 - val_loss: 4.8708e-04\n",
      "Epoch 81/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 4.9021e-04 - val_loss: 5.4334e-04\n",
      "Epoch 82/2000\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 4.8964e-04 - val_loss: 4.9304e-04\n",
      "Epoch 83/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 4.8039e-04 - val_loss: 5.6552e-04\n",
      "Epoch 84/2000\n",
      "3977/3977 [==============================] - 2s 528us/step - loss: 5.1471e-04 - val_loss: 4.7335e-04\n",
      "Epoch 85/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 4.8194e-04 - val_loss: 5.2731e-04\n",
      "Epoch 86/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 4.9370e-04 - val_loss: 5.4955e-04\n",
      "Epoch 87/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 4.9116e-04 - val_loss: 5.4090e-04\n",
      "Epoch 88/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 4.7806e-04 - val_loss: 5.1443e-04\n",
      "Epoch 89/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 5.0632e-04 - val_loss: 5.3795e-04\n",
      "Epoch 90/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 4.8652e-04 - val_loss: 9.0841e-04\n",
      "Epoch 91/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 4.8147e-04 - val_loss: 4.6466e-04\n",
      "Epoch 92/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 4.3257e-04 - val_loss: 4.5324e-04\n",
      "Epoch 93/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 4.3622e-04 - val_loss: 4.5686e-04\n",
      "Epoch 94/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 4.2528e-04 - val_loss: 4.4612e-04\n",
      "Epoch 95/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 4.2693e-04 - val_loss: 6.1814e-04\n",
      "Epoch 96/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 4.4399e-04 - val_loss: 6.7843e-04\n",
      "Epoch 97/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 4.4474e-04 - val_loss: 4.6195e-04\n",
      "Epoch 98/2000\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 4.2736e-04 - val_loss: 9.3969e-04\n",
      "Epoch 99/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 5.0112e-04 - val_loss: 6.7548e-04\n",
      "Epoch 100/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 5.1156e-04 - val_loss: 5.7571e-04\n",
      "Epoch 101/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 5.2257e-04 - val_loss: 5.1132e-04\n",
      "Epoch 102/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 5.2362e-04 - val_loss: 4.8135e-04\n",
      "Epoch 103/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 5.0887e-04 - val_loss: 4.3136e-04\n",
      "Epoch 104/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 5.3005e-04 - val_loss: 6.6260e-04\n",
      "Epoch 105/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 4.7435e-04 - val_loss: 4.9310e-04\n",
      "Epoch 106/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 4.2374e-04 - val_loss: 4.3605e-04\n",
      "Epoch 107/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 4.5352e-04 - val_loss: 5.4381e-04\n",
      "Epoch 108/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 4.1092e-04 - val_loss: 4.1824e-04\n",
      "Epoch 109/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 4.1361e-04 - val_loss: 5.4144e-04\n",
      "Epoch 110/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 4.0347e-04 - val_loss: 5.1814e-04\n",
      "Epoch 111/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 4.4732e-04 - val_loss: 5.8232e-04\n",
      "Epoch 112/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 4.2751e-04 - val_loss: 4.8027e-04\n",
      "Epoch 113/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 5.0835e-04 - val_loss: 6.3112e-04\n",
      "Epoch 114/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 4.8625e-04 - val_loss: 4.7227e-04\n",
      "Epoch 115/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 4.5802e-04 - val_loss: 4.0671e-04\n",
      "Epoch 116/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 4.1795e-04 - val_loss: 4.6552e-04\n",
      "Epoch 117/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 4.1626e-04 - val_loss: 4.6919e-04\n",
      "Epoch 118/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 4.0180e-04 - val_loss: 3.9339e-04\n",
      "Epoch 119/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 4.3135e-04 - val_loss: 4.4026e-04\n",
      "Epoch 120/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.8786e-04 - val_loss: 3.8870e-04\n",
      "Epoch 121/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 4.2247e-04 - val_loss: 4.4429e-04\n",
      "Epoch 122/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.8493e-04 - val_loss: 3.9037e-04\n",
      "Epoch 123/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 3.9691e-04 - val_loss: 5.2200e-04\n",
      "Epoch 124/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 4.3552e-04 - val_loss: 4.1308e-04\n",
      "Epoch 125/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 3.7973e-04 - val_loss: 5.2043e-04\n",
      "Epoch 126/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 4.1619e-04 - val_loss: 3.9645e-04\n",
      "Epoch 127/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 4.0056e-04 - val_loss: 4.6381e-04\n",
      "Epoch 128/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.8563e-04 - val_loss: 3.7356e-04\n",
      "Epoch 129/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.9943e-04 - val_loss: 3.8386e-04\n",
      "Epoch 130/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 3.7630e-04 - val_loss: 3.9127e-04\n",
      "Epoch 131/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.8938e-04 - val_loss: 3.7465e-04\n",
      "Epoch 132/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.8167e-04 - val_loss: 3.7323e-04\n",
      "Epoch 133/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.8036e-04 - val_loss: 3.6244e-04\n",
      "Epoch 134/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 3.7378e-04 - val_loss: 3.8913e-04\n",
      "Epoch 135/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 4.6270e-04 - val_loss: 3.7996e-04\n",
      "Epoch 136/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 4.5974e-04 - val_loss: 3.7239e-04\n",
      "Epoch 137/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 3.9617e-04 - val_loss: 4.0783e-04\n",
      "Epoch 138/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 4.0435e-04 - val_loss: 3.5573e-04\n",
      "Epoch 139/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.8050e-04 - val_loss: 5.0057e-04\n",
      "Epoch 140/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.9117e-04 - val_loss: 3.5237e-04\n",
      "Epoch 141/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.9712e-04 - val_loss: 4.3215e-04\n",
      "Epoch 142/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.7212e-04 - val_loss: 4.4318e-04\n",
      "Epoch 143/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.7571e-04 - val_loss: 3.4629e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.5926e-04 - val_loss: 3.9259e-04\n",
      "Epoch 145/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.8230e-04 - val_loss: 5.0881e-04\n",
      "Epoch 146/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 4.1905e-04 - val_loss: 6.5761e-04\n",
      "Epoch 147/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.9713e-04 - val_loss: 3.6195e-04\n",
      "Epoch 148/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 3.5923e-04 - val_loss: 3.8039e-04\n",
      "Epoch 149/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.6128e-04 - val_loss: 3.5836e-04\n",
      "Epoch 150/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 4.4839e-04 - val_loss: 0.0013\n",
      "Epoch 151/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 5.0416e-04 - val_loss: 4.9390e-04\n",
      "Epoch 152/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 4.0140e-04 - val_loss: 3.4868e-04\n",
      "Epoch 153/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.7016e-04 - val_loss: 3.3404e-04\n",
      "Epoch 154/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 3.4444e-04 - val_loss: 3.4411e-04\n",
      "Epoch 155/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 3.4002e-04 - val_loss: 3.4178e-04\n",
      "Epoch 156/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.6485e-04 - val_loss: 3.7987e-04\n",
      "Epoch 157/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 3.6416e-04 - val_loss: 3.4721e-04\n",
      "Epoch 158/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.6594e-04 - val_loss: 3.4409e-04\n",
      "Epoch 159/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 3.7779e-04 - val_loss: 4.3071e-04\n",
      "Epoch 160/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 3.5927e-04 - val_loss: 3.6764e-04\n",
      "Epoch 161/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.3913e-04 - val_loss: 4.4343e-04\n",
      "Epoch 162/2000\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 3.7064e-04 - val_loss: 3.2205e-04\n",
      "Epoch 163/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.4128e-04 - val_loss: 3.1991e-04\n",
      "Epoch 164/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 3.3117e-04 - val_loss: 3.2028e-04\n",
      "Epoch 165/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 3.3590e-04 - val_loss: 3.2570e-04\n",
      "Epoch 166/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.5247e-04 - val_loss: 3.1191e-04\n",
      "Epoch 167/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 3.3336e-04 - val_loss: 3.1298e-04\n",
      "Epoch 168/2000\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 3.3254e-04 - val_loss: 3.1433e-04\n",
      "Epoch 169/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.2853e-04 - val_loss: 4.0727e-04\n",
      "Epoch 170/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.4544e-04 - val_loss: 3.2186e-04\n",
      "Epoch 171/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 3.4040e-04 - val_loss: 3.1752e-04\n",
      "Epoch 172/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.4882e-04 - val_loss: 4.7866e-04\n",
      "Epoch 173/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.5315e-04 - val_loss: 3.1935e-04\n",
      "Epoch 174/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.2533e-04 - val_loss: 3.2881e-04\n",
      "Epoch 175/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.4888e-04 - val_loss: 3.9093e-04\n",
      "Epoch 176/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.4145e-04 - val_loss: 3.0387e-04\n",
      "Epoch 177/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.2670e-04 - val_loss: 3.0745e-04\n",
      "Epoch 178/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.3361e-04 - val_loss: 3.1602e-04\n",
      "Epoch 179/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.1692e-04 - val_loss: 3.0594e-04\n",
      "Epoch 180/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.3855e-04 - val_loss: 4.0685e-04\n",
      "Epoch 181/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.6219e-04 - val_loss: 3.8113e-04\n",
      "Epoch 182/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.7980e-04 - val_loss: 3.0370e-04\n",
      "Epoch 183/2000\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 3.9658e-04 - val_loss: 6.7381e-04\n",
      "Epoch 184/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 4.2115e-04 - val_loss: 3.2956e-04\n",
      "Epoch 185/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 3.5321e-04 - val_loss: 3.2799e-04\n",
      "Epoch 186/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.2226e-04 - val_loss: 3.0576e-04\n",
      "Epoch 187/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 3.2045e-04 - val_loss: 3.2123e-04\n",
      "Epoch 188/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.2858e-04 - val_loss: 3.0795e-04\n",
      "Epoch 189/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 3.1690e-04 - val_loss: 4.2744e-04\n",
      "Epoch 190/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 3.3124e-04 - val_loss: 3.2408e-04\n",
      "Epoch 191/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.2822e-04 - val_loss: 3.1828e-04\n",
      "Epoch 192/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.2653e-04 - val_loss: 3.5619e-04\n",
      "Epoch 193/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.3286e-04 - val_loss: 3.1036e-04\n",
      "Epoch 194/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.3493e-04 - val_loss: 3.0406e-04\n",
      "Epoch 195/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.3161e-04 - val_loss: 4.2304e-04\n",
      "Epoch 196/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.5951e-04 - val_loss: 4.8067e-04\n",
      "Epoch 197/2000\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 3.6002e-04 - val_loss: 3.0164e-04\n",
      "Epoch 198/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 3.4821e-04 - val_loss: 6.5311e-04\n",
      "Epoch 199/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.5495e-04 - val_loss: 3.1149e-04\n",
      "Epoch 200/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.4122e-04 - val_loss: 4.3993e-04\n",
      "Epoch 201/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 3.3344e-04 - val_loss: 3.4390e-04\n",
      "Epoch 202/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.6253e-04 - val_loss: 3.9500e-04\n",
      "Epoch 203/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.6253e-04 - val_loss: 3.7369e-04\n",
      "Epoch 204/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 3.1963e-04 - val_loss: 2.9863e-04\n",
      "Epoch 205/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.1152e-04 - val_loss: 3.0054e-04\n",
      "Epoch 206/2000\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 3.3456e-04 - val_loss: 2.9920e-04\n",
      "Epoch 207/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.3415e-04 - val_loss: 2.9903e-04\n",
      "Epoch 208/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.2103e-04 - val_loss: 2.9888e-04\n",
      "Epoch 209/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.2081e-04 - val_loss: 3.5754e-04\n",
      "Epoch 210/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.3181e-04 - val_loss: 4.9959e-04\n",
      "Epoch 211/2000\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 3.6537e-04 - val_loss: 3.4417e-04\n",
      "Epoch 212/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.6801e-04 - val_loss: 3.4077e-04\n",
      "Epoch 213/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 3.6866e-04 - val_loss: 3.1263e-04\n",
      "Epoch 214/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.7323e-04 - val_loss: 3.4423e-04\n",
      "Epoch 215/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 3.4214e-04 - val_loss: 3.7145e-04\n",
      "Epoch 216/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.2923e-04 - val_loss: 3.0000e-04\n",
      "Epoch 217/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.2613e-04 - val_loss: 3.0321e-04\n",
      "Epoch 218/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.1280e-04 - val_loss: 3.5302e-04\n",
      "Epoch 219/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.6679e-04 - val_loss: 3.8883e-04\n",
      "Epoch 220/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.6357e-04 - val_loss: 3.9863e-04\n",
      "Epoch 221/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 3.8708e-04 - val_loss: 4.3236e-04\n",
      "Epoch 222/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.5102e-04 - val_loss: 3.0210e-04\n",
      "Epoch 223/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.5562e-04 - val_loss: 3.0553e-04\n",
      "Epoch 224/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.1694e-04 - val_loss: 3.3342e-04\n",
      "Epoch 225/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.2980e-04 - val_loss: 3.0128e-04\n",
      "Epoch 226/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.4415e-04 - val_loss: 4.3908e-04\n",
      "Epoch 227/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.9422e-04 - val_loss: 7.5935e-04\n",
      "Epoch 228/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 3.8001e-04 - val_loss: 2.9969e-04\n",
      "Epoch 229/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 3.0981e-04 - val_loss: 2.9785e-04\n",
      "Epoch 230/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.1264e-04 - val_loss: 3.0781e-04\n",
      "Epoch 231/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 3.1075e-04 - val_loss: 3.5704e-04\n",
      "Epoch 232/2000\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 3.3088e-04 - val_loss: 3.1808e-04\n",
      "Epoch 233/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.6673e-04 - val_loss: 3.2985e-04\n",
      "Epoch 234/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.5284e-04 - val_loss: 3.3744e-04\n",
      "Epoch 235/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.0812e-04 - val_loss: 2.9658e-04\n",
      "Epoch 236/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.1650e-04 - val_loss: 2.9757e-04\n",
      "Epoch 237/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.3974e-04 - val_loss: 2.9684e-04\n",
      "Epoch 238/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.4543e-04 - val_loss: 4.1160e-04\n",
      "Epoch 239/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.5014e-04 - val_loss: 3.6839e-04\n",
      "Epoch 240/2000\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 3.1932e-04 - val_loss: 2.9950e-04\n",
      "Epoch 241/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.0650e-04 - val_loss: 3.0944e-04\n",
      "Epoch 242/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 3.0808e-04 - val_loss: 3.0229e-04\n",
      "Epoch 243/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.1561e-04 - val_loss: 2.9466e-04\n",
      "Epoch 244/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 3.2307e-04 - val_loss: 3.1980e-04\n",
      "Epoch 245/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.2890e-04 - val_loss: 3.1340e-04\n",
      "Epoch 246/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.0851e-04 - val_loss: 2.9530e-04\n",
      "Epoch 247/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.0530e-04 - val_loss: 3.0726e-04\n",
      "Epoch 248/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.1099e-04 - val_loss: 3.7569e-04\n",
      "Epoch 249/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.4883e-04 - val_loss: 3.4369e-04\n",
      "Epoch 250/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.4077e-04 - val_loss: 3.2341e-04\n",
      "Epoch 251/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.4770e-04 - val_loss: 2.9610e-04\n",
      "Epoch 252/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 3.0560e-04 - val_loss: 2.9449e-04\n",
      "Epoch 253/2000\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 3.1703e-04 - val_loss: 3.1197e-04\n",
      "Epoch 254/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.1339e-04 - val_loss: 2.9401e-04\n",
      "Epoch 255/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 3.0953e-04 - val_loss: 3.5432e-04\n",
      "Epoch 256/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.6030e-04 - val_loss: 4.4212e-04\n",
      "Epoch 257/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.3147e-04 - val_loss: 3.0905e-04\n",
      "Epoch 258/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.1339e-04 - val_loss: 2.9457e-04\n",
      "Epoch 259/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 3.0386e-04 - val_loss: 2.9800e-04\n",
      "Epoch 260/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.0801e-04 - val_loss: 3.0199e-04\n",
      "Epoch 261/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.0928e-04 - val_loss: 3.1932e-04\n",
      "Epoch 262/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.2141e-04 - val_loss: 3.1644e-04\n",
      "Epoch 263/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 3.1685e-04 - val_loss: 4.1558e-04\n",
      "Epoch 264/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.3476e-04 - val_loss: 2.9354e-04\n",
      "Epoch 265/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.2890e-04 - val_loss: 4.5479e-04\n",
      "Epoch 266/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.8872e-04 - val_loss: 6.6569e-04\n",
      "Epoch 267/2000\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 4.1039e-04 - val_loss: 3.2701e-04\n",
      "Epoch 268/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.1910e-04 - val_loss: 2.9302e-04\n",
      "Epoch 269/2000\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 3.0373e-04 - val_loss: 3.0562e-04\n",
      "Epoch 270/2000\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 3.3902e-04 - val_loss: 3.1868e-04\n",
      "Epoch 271/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 3.2849e-04 - val_loss: 2.9403e-04\n",
      "Epoch 272/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.1442e-04 - val_loss: 3.1216e-04\n",
      "Epoch 273/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.0844e-04 - val_loss: 2.9376e-04\n",
      "Epoch 274/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.1293e-04 - val_loss: 4.5486e-04\n",
      "Epoch 275/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 3.5268e-04 - val_loss: 3.1931e-04\n",
      "Epoch 276/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.1967e-04 - val_loss: 4.4337e-04\n",
      "Epoch 277/2000\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 3.3295e-04 - val_loss: 3.2426e-04\n",
      "Epoch 278/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.3008e-04 - val_loss: 3.2748e-04\n",
      "Epoch 279/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.0832e-04 - val_loss: 2.9393e-04\n",
      "Epoch 280/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 3.0358e-04 - val_loss: 3.0439e-04\n",
      "Epoch 281/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.0814e-04 - val_loss: 3.2660e-04\n",
      "Epoch 282/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.1672e-04 - val_loss: 3.0536e-04\n",
      "Epoch 283/2000\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 3.1319e-04 - val_loss: 3.1503e-04\n",
      "Epoch 284/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 3.1614e-04 - val_loss: 3.0783e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 285/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.4859e-04 - val_loss: 5.0760e-04\n",
      "Epoch 286/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.7957e-04 - val_loss: 2.9736e-04\n",
      "Epoch 287/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.3700e-04 - val_loss: 2.9588e-04\n",
      "Epoch 288/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.2369e-04 - val_loss: 2.9960e-04\n",
      "Epoch 289/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.0336e-04 - val_loss: 2.9279e-04\n",
      "Epoch 290/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 3.0553e-04 - val_loss: 2.9629e-04\n",
      "Epoch 291/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 3.0484e-04 - val_loss: 3.1387e-04\n",
      "Epoch 292/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 3.2758e-04 - val_loss: 4.5395e-04\n",
      "Epoch 293/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.3899e-04 - val_loss: 3.8480e-04\n",
      "Epoch 294/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.5725e-04 - val_loss: 3.9584e-04\n",
      "Epoch 295/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 3.1713e-04 - val_loss: 3.4363e-04\n",
      "Epoch 296/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.2002e-04 - val_loss: 3.6030e-04\n",
      "Epoch 297/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.3044e-04 - val_loss: 3.2588e-04\n",
      "Epoch 298/2000\n",
      "3977/3977 [==============================] - 2s 528us/step - loss: 3.1122e-04 - val_loss: 3.1203e-04\n",
      "Epoch 299/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 3.1378e-04 - val_loss: 3.0624e-04\n",
      "Epoch 300/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.2468e-04 - val_loss: 2.9598e-04\n",
      "Epoch 301/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.2075e-04 - val_loss: 4.4172e-04\n",
      "Epoch 302/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.4044e-04 - val_loss: 3.8322e-04\n",
      "Epoch 303/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.6129e-04 - val_loss: 3.3129e-04\n",
      "Epoch 304/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.4912e-04 - val_loss: 2.9502e-04\n",
      "Epoch 305/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 3.1884e-04 - val_loss: 3.1318e-04\n",
      "Epoch 306/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 3.0685e-04 - val_loss: 3.0215e-04\n",
      "Epoch 307/2000\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 3.1147e-04 - val_loss: 3.0179e-04\n",
      "Epoch 308/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.0532e-04 - val_loss: 2.9288e-04\n",
      "Epoch 309/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.0036e-04 - val_loss: 2.9154e-04\n",
      "Epoch 310/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 3.1133e-04 - val_loss: 4.4647e-04\n",
      "Epoch 311/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.3416e-04 - val_loss: 3.0519e-04\n",
      "Epoch 312/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 3.0950e-04 - val_loss: 2.9583e-04\n",
      "Epoch 313/2000\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 2.9888e-04 - val_loss: 3.0659e-04\n",
      "Epoch 314/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.1375e-04 - val_loss: 2.9260e-04\n",
      "Epoch 315/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.9683e-04 - val_loss: 2.9265e-04\n",
      "Epoch 316/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.1022e-04 - val_loss: 3.6097e-04\n",
      "Epoch 317/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 3.1997e-04 - val_loss: 4.7327e-04\n",
      "Epoch 318/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.1283e-04 - val_loss: 3.0381e-04\n",
      "Epoch 319/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 3.0371e-04 - val_loss: 3.4370e-04\n",
      "Epoch 320/2000\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 3.0910e-04 - val_loss: 2.9536e-04\n",
      "Epoch 321/2000\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 2.9861e-04 - val_loss: 3.1691e-04\n",
      "Epoch 322/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.0016e-04 - val_loss: 2.9469e-04\n",
      "Epoch 323/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.2218e-04 - val_loss: 3.7126e-04\n",
      "Epoch 324/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.3577e-04 - val_loss: 3.3327e-04\n",
      "Epoch 325/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.4533e-04 - val_loss: 3.1975e-04\n",
      "Epoch 326/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 3.3451e-04 - val_loss: 3.6089e-04\n",
      "Epoch 327/2000\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 3.6149e-04 - val_loss: 2.9319e-04\n",
      "Epoch 328/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 3.2566e-04 - val_loss: 3.0221e-04\n",
      "Epoch 329/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 3.0367e-04 - val_loss: 2.9182e-04\n",
      "Epoch 330/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.0534e-04 - val_loss: 2.9818e-04\n",
      "Epoch 331/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.0745e-04 - val_loss: 3.3050e-04\n",
      "Epoch 332/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.0915e-04 - val_loss: 3.4210e-04\n",
      "Epoch 333/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.1795e-04 - val_loss: 3.0477e-04\n",
      "Epoch 334/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.9498e-04 - val_loss: 2.9545e-04\n",
      "Epoch 335/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.9692e-04 - val_loss: 3.0275e-04\n",
      "Epoch 336/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.9878e-04 - val_loss: 2.9322e-04\n",
      "Epoch 337/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.9950e-04 - val_loss: 3.0631e-04\n",
      "Epoch 338/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 3.2604e-04 - val_loss: 2.9792e-04\n",
      "Epoch 339/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.1080e-04 - val_loss: 3.7754e-04\n",
      "Epoch 340/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.1629e-04 - val_loss: 3.8581e-04\n",
      "Epoch 341/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.3985e-04 - val_loss: 3.7534e-04\n",
      "Epoch 342/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.5103e-04 - val_loss: 3.7000e-04\n",
      "Epoch 343/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.6134e-04 - val_loss: 3.5074e-04\n",
      "Epoch 344/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 3.2288e-04 - val_loss: 3.0641e-04\n",
      "Epoch 345/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.1321e-04 - val_loss: 2.9525e-04\n",
      "Epoch 346/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 3.1087e-04 - val_loss: 3.0909e-04\n",
      "Epoch 347/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.2590e-04 - val_loss: 5.3320e-04\n",
      "Epoch 348/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.4707e-04 - val_loss: 2.9498e-04\n",
      "Epoch 349/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.1788e-04 - val_loss: 3.5134e-04\n",
      "Epoch 350/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.5723e-04 - val_loss: 3.0633e-04\n",
      "Epoch 351/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 3.8293e-04 - val_loss: 2.9271e-04\n",
      "Epoch 352/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 3.1844e-04 - val_loss: 2.9197e-04\n",
      "Epoch 353/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.2502e-04 - val_loss: 2.9766e-04\n",
      "Epoch 354/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.6961e-04 - val_loss: 4.1111e-04\n",
      "Epoch 355/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 3.3417e-04 - val_loss: 3.5105e-04\n",
      "Epoch 356/2000\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 3.1247e-04 - val_loss: 3.1199e-04\n",
      "Epoch 357/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.1938e-04 - val_loss: 2.9272e-04\n",
      "Epoch 358/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.0291e-04 - val_loss: 2.9626e-04\n",
      "Epoch 359/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.9673e-04 - val_loss: 3.0442e-04\n",
      "Epoch 360/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.1456e-04 - val_loss: 3.3190e-04\n",
      "Epoch 361/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.4022e-04 - val_loss: 2.9615e-04\n",
      "Epoch 362/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.4754e-04 - val_loss: 4.4393e-04\n",
      "Epoch 363/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.7194e-04 - val_loss: 3.3491e-04\n",
      "Epoch 364/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.2017e-04 - val_loss: 3.1338e-04\n",
      "Epoch 365/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.5488e-04 - val_loss: 3.0842e-04\n",
      "Epoch 366/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.2589e-04 - val_loss: 3.6591e-04\n",
      "Epoch 367/2000\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 3.2370e-04 - val_loss: 3.7459e-04\n",
      "Epoch 368/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.5056e-04 - val_loss: 5.5409e-04\n",
      "Epoch 369/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.8465e-04 - val_loss: 3.0808e-04\n",
      "Epoch 370/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 3.4448e-04 - val_loss: 3.8273e-04\n",
      "Epoch 371/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.1482e-04 - val_loss: 2.9529e-04\n",
      "Epoch 372/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 3.2575e-04 - val_loss: 3.9937e-04\n",
      "Epoch 373/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.1162e-04 - val_loss: 2.9881e-04\n",
      "Epoch 374/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.2052e-04 - val_loss: 3.6539e-04\n",
      "Epoch 375/2000\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 3.1314e-04 - val_loss: 2.9378e-04\n",
      "Epoch 376/2000\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 2.9604e-04 - val_loss: 2.9231e-04\n",
      "Epoch 377/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.9630e-04 - val_loss: 3.1006e-04\n",
      "Epoch 378/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.9401e-04 - val_loss: 2.9950e-04\n",
      "Epoch 379/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 2.9636e-04 - val_loss: 2.9212e-04\n",
      "Epoch 380/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 2.9274e-04 - val_loss: 2.9259e-04\n",
      "Epoch 381/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.9842e-04 - val_loss: 3.2197e-04\n",
      "Epoch 382/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 3.2226e-04 - val_loss: 2.9413e-04\n",
      "Epoch 383/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 3.0234e-04 - val_loss: 3.5286e-04\n",
      "Epoch 384/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.1220e-04 - val_loss: 3.0515e-04\n",
      "Epoch 385/2000\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 3.1052e-04 - val_loss: 3.1120e-04\n",
      "Epoch 386/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.0605e-04 - val_loss: 3.5085e-04\n",
      "Epoch 387/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 3.0459e-04 - val_loss: 3.0842e-04\n",
      "Epoch 388/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.0964e-04 - val_loss: 3.3873e-04\n",
      "Epoch 389/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.1423e-04 - val_loss: 2.9449e-04\n",
      "Epoch 390/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.9516e-04 - val_loss: 2.9957e-04\n",
      "Epoch 391/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.9819e-04 - val_loss: 3.2268e-04\n",
      "Epoch 392/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 3.0820e-04 - val_loss: 2.9381e-04\n",
      "Epoch 393/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.0289e-04 - val_loss: 2.9991e-04\n",
      "Epoch 394/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.1007e-04 - val_loss: 3.1967e-04\n",
      "Epoch 395/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.9598e-04 - val_loss: 2.9447e-04\n",
      "Epoch 396/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.0335e-04 - val_loss: 3.4773e-04\n",
      "Epoch 397/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.0086e-04 - val_loss: 2.9560e-04\n",
      "Epoch 398/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 3.1184e-04 - val_loss: 3.3923e-04\n",
      "Epoch 399/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 3.0641e-04 - val_loss: 3.1366e-04\n",
      "Epoch 400/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 3.0115e-04 - val_loss: 3.1641e-04\n",
      "Epoch 401/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.9379e-04 - val_loss: 3.9357e-04\n",
      "Epoch 402/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.5143e-04 - val_loss: 3.4941e-04\n",
      "Epoch 403/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.3680e-04 - val_loss: 3.2305e-04\n",
      "Epoch 404/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.5470e-04 - val_loss: 2.9669e-04\n",
      "Epoch 405/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.2175e-04 - val_loss: 2.9981e-04\n",
      "Epoch 406/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 3.1262e-04 - val_loss: 4.6874e-04\n",
      "Epoch 407/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.6324e-04 - val_loss: 3.3105e-04\n",
      "Epoch 408/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.2790e-04 - val_loss: 2.9574e-04\n",
      "Epoch 409/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.0313e-04 - val_loss: 2.9631e-04\n",
      "Epoch 410/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.0413e-04 - val_loss: 3.2123e-04\n",
      "Epoch 411/2000\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 3.0152e-04 - val_loss: 3.4028e-04\n",
      "Epoch 412/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.0458e-04 - val_loss: 3.0698e-04\n",
      "Epoch 413/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.9706e-04 - val_loss: 2.9459e-04\n",
      "Epoch 414/2000\n",
      "3977/3977 [==============================] - 2s 529us/step - loss: 2.9178e-04 - val_loss: 3.1872e-04\n",
      "Epoch 415/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.9564e-04 - val_loss: 2.9240e-04\n",
      "Epoch 416/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.1249e-04 - val_loss: 2.9783e-04\n",
      "Epoch 417/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 3.1896e-04 - val_loss: 3.0259e-04\n",
      "Epoch 418/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 3.0136e-04 - val_loss: 2.9234e-04\n",
      "Epoch 419/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 3.1081e-04 - val_loss: 3.5455e-04\n",
      "Epoch 420/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.1736e-04 - val_loss: 2.9251e-04\n",
      "Epoch 421/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 3.0116e-04 - val_loss: 3.0427e-04\n",
      "Epoch 422/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.0148e-04 - val_loss: 2.9925e-04\n",
      "Epoch 423/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.2027e-04 - val_loss: 2.9398e-04\n",
      "Epoch 424/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.1582e-04 - val_loss: 3.1002e-04\n",
      "Epoch 425/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.1221e-04 - val_loss: 3.0590e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 426/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.9346e-04 - val_loss: 3.2134e-04\n",
      "Epoch 427/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 3.0221e-04 - val_loss: 2.9397e-04\n",
      "Epoch 428/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 3.0561e-04 - val_loss: 3.7393e-04\n",
      "Epoch 429/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 3.0760e-04 - val_loss: 2.9492e-04\n",
      "Epoch 430/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.0544e-04 - val_loss: 3.1399e-04\n",
      "Epoch 431/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.0457e-04 - val_loss: 2.9966e-04\n",
      "Epoch 432/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 3.1088e-04 - val_loss: 3.5310e-04\n",
      "Epoch 433/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 3.0098e-04 - val_loss: 2.9406e-04\n",
      "Epoch 434/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.0819e-04 - val_loss: 3.1299e-04\n",
      "Epoch 435/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 2.9460e-04 - val_loss: 3.6346e-04\n",
      "Epoch 436/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.0155e-04 - val_loss: 3.8964e-04\n",
      "Epoch 437/2000\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 3.1052e-04 - val_loss: 2.9810e-04\n",
      "Epoch 438/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.9211e-04 - val_loss: 3.1072e-04\n",
      "Epoch 439/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.9859e-04 - val_loss: 3.2800e-04\n",
      "Epoch 440/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.0391e-04 - val_loss: 3.3584e-04\n",
      "Epoch 441/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.9991e-04 - val_loss: 2.9169e-04\n",
      "Epoch 442/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.0426e-04 - val_loss: 3.0534e-04\n",
      "Epoch 443/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 3.1590e-04 - val_loss: 2.9670e-04\n",
      "Epoch 444/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 3.0893e-04 - val_loss: 4.4710e-04\n",
      "Epoch 445/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.6453e-04 - val_loss: 6.6366e-04\n",
      "Epoch 446/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 4.4654e-04 - val_loss: 6.9774e-04\n",
      "Epoch 447/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.6275e-04 - val_loss: 3.5170e-04\n",
      "Epoch 448/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.0978e-04 - val_loss: 2.9271e-04\n",
      "Epoch 449/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.9762e-04 - val_loss: 2.9736e-04\n",
      "Epoch 450/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.9746e-04 - val_loss: 3.0304e-04\n",
      "Epoch 451/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.9268e-04 - val_loss: 2.9031e-04\n",
      "Epoch 452/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.9210e-04 - val_loss: 3.1553e-04\n",
      "Epoch 453/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.0600e-04 - val_loss: 4.4505e-04\n",
      "Epoch 454/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 3.3605e-04 - val_loss: 5.7695e-04\n",
      "Epoch 455/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.3420e-04 - val_loss: 3.6283e-04\n",
      "Epoch 456/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.0664e-04 - val_loss: 2.9879e-04\n",
      "Epoch 457/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 3.0013e-04 - val_loss: 3.3426e-04\n",
      "Epoch 458/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.0047e-04 - val_loss: 3.7778e-04\n",
      "Epoch 459/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.0265e-04 - val_loss: 2.9749e-04\n",
      "Epoch 460/2000\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 2.9416e-04 - val_loss: 3.0938e-04\n",
      "Epoch 461/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.1588e-04 - val_loss: 2.9933e-04\n",
      "Epoch 462/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.5036e-04 - val_loss: 3.2744e-04\n",
      "Epoch 463/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.4069e-04 - val_loss: 3.3220e-04\n",
      "Epoch 464/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.9761e-04 - val_loss: 2.9370e-04\n",
      "Epoch 465/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.9720e-04 - val_loss: 2.9659e-04\n",
      "Epoch 466/2000\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 2.8899e-04 - val_loss: 3.2104e-04\n",
      "Epoch 467/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.9443e-04 - val_loss: 3.0380e-04\n",
      "Epoch 468/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 2.9466e-04 - val_loss: 3.6968e-04\n",
      "Epoch 469/2000\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 3.0264e-04 - val_loss: 3.0190e-04\n",
      "Epoch 470/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.0499e-04 - val_loss: 3.0550e-04\n",
      "Epoch 471/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 3.0556e-04 - val_loss: 2.9086e-04\n",
      "Epoch 472/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.9503e-04 - val_loss: 3.1805e-04\n",
      "Epoch 473/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.9578e-04 - val_loss: 3.0549e-04\n",
      "Epoch 474/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 3.0642e-04 - val_loss: 3.6416e-04\n",
      "Epoch 475/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 3.1460e-04 - val_loss: 3.0900e-04\n",
      "Epoch 476/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.9101e-04 - val_loss: 2.9653e-04\n",
      "Epoch 477/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 3.0559e-04 - val_loss: 2.9458e-04\n",
      "Epoch 478/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.9418e-04 - val_loss: 3.0040e-04\n",
      "Epoch 479/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 3.0671e-04 - val_loss: 3.8590e-04\n",
      "Epoch 480/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.0823e-04 - val_loss: 3.6501e-04\n",
      "Epoch 481/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.3228e-04 - val_loss: 2.9232e-04\n",
      "Epoch 482/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.0229e-04 - val_loss: 3.3212e-04\n",
      "Epoch 483/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 3.0683e-04 - val_loss: 3.0362e-04\n",
      "Epoch 484/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 3.1893e-04 - val_loss: 2.9276e-04\n",
      "Epoch 485/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.1516e-04 - val_loss: 2.9210e-04\n",
      "Epoch 486/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.9584e-04 - val_loss: 3.1277e-04\n",
      "Epoch 487/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.9254e-04 - val_loss: 3.0021e-04\n",
      "Epoch 488/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.9967e-04 - val_loss: 3.0770e-04\n",
      "Epoch 489/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.9430e-04 - val_loss: 3.3337e-04\n",
      "Epoch 490/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.2546e-04 - val_loss: 2.9975e-04\n",
      "Epoch 491/2000\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 2.9806e-04 - val_loss: 2.9981e-04\n",
      "Epoch 492/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.9336e-04 - val_loss: 2.9602e-04\n",
      "Epoch 493/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.8822e-04 - val_loss: 2.9421e-04\n",
      "Epoch 494/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.0493e-04 - val_loss: 3.4053e-04\n",
      "Epoch 495/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.1662e-04 - val_loss: 3.1655e-04\n",
      "Epoch 496/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.9988e-04 - val_loss: 2.9946e-04\n",
      "Epoch 497/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.9633e-04 - val_loss: 3.3548e-04\n",
      "Epoch 498/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.9784e-04 - val_loss: 3.2204e-04\n",
      "Epoch 499/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 3.0479e-04 - val_loss: 3.4325e-04\n",
      "Epoch 500/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 3.2936e-04 - val_loss: 3.7505e-04\n",
      "Epoch 501/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 3.2036e-04 - val_loss: 3.9693e-04\n",
      "Epoch 502/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.1938e-04 - val_loss: 2.9816e-04\n",
      "Epoch 503/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.9738e-04 - val_loss: 3.3192e-04\n",
      "Epoch 504/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.9326e-04 - val_loss: 3.9983e-04\n",
      "Epoch 505/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.9405e-04 - val_loss: 4.1294e-04\n",
      "Epoch 506/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 4.3516e-04 - val_loss: 5.7806e-04\n",
      "Epoch 507/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 3.7836e-04 - val_loss: 6.9335e-04\n",
      "Epoch 508/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 4.0138e-04 - val_loss: 4.7758e-04\n",
      "Epoch 509/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 4.0203e-04 - val_loss: 3.0064e-04\n",
      "Epoch 510/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.3457e-04 - val_loss: 3.3026e-04\n",
      "Epoch 511/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.5428e-04 - val_loss: 4.7953e-04\n",
      "Epoch 512/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 4.0279e-04 - val_loss: 4.5213e-04\n",
      "Epoch 513/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.4649e-04 - val_loss: 3.1752e-04\n",
      "Epoch 514/2000\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 3.3548e-04 - val_loss: 3.4013e-04\n",
      "Epoch 515/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 3.2675e-04 - val_loss: 4.1469e-04\n",
      "Epoch 516/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.2893e-04 - val_loss: 2.9455e-04\n",
      "Epoch 517/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.9789e-04 - val_loss: 3.0839e-04\n",
      "Epoch 518/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.9288e-04 - val_loss: 3.6330e-04\n",
      "Epoch 519/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 2.9608e-04 - val_loss: 3.7384e-04\n",
      "Epoch 520/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.1470e-04 - val_loss: 3.7860e-04\n",
      "Epoch 521/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.9802e-04 - val_loss: 3.7532e-04\n",
      "Epoch 522/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.0496e-04 - val_loss: 2.9555e-04\n",
      "Epoch 523/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.8620e-04 - val_loss: 3.0550e-04\n",
      "Epoch 524/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 2.9133e-04 - val_loss: 3.1744e-04\n",
      "Epoch 525/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 2.9951e-04 - val_loss: 3.3312e-04\n",
      "Epoch 526/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.0338e-04 - val_loss: 3.5861e-04\n",
      "Epoch 527/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.0328e-04 - val_loss: 3.0524e-04\n",
      "Epoch 528/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.9255e-04 - val_loss: 3.0462e-04\n",
      "Epoch 529/2000\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 3.3510e-04 - val_loss: 4.2443e-04\n",
      "Epoch 530/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.2444e-04 - val_loss: 4.1378e-04\n",
      "Epoch 531/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.3080e-04 - val_loss: 2.9643e-04\n",
      "Epoch 532/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.0549e-04 - val_loss: 3.3209e-04\n",
      "Epoch 533/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.0654e-04 - val_loss: 4.0147e-04\n",
      "Epoch 534/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.7043e-04 - val_loss: 3.9620e-04\n",
      "Epoch 535/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 3.4356e-04 - val_loss: 3.5333e-04\n",
      "Epoch 536/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.1331e-04 - val_loss: 3.0249e-04\n",
      "Epoch 537/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 3.2063e-04 - val_loss: 3.4083e-04\n",
      "Epoch 538/2000\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 2.9504e-04 - val_loss: 3.5876e-04\n",
      "Epoch 539/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.0114e-04 - val_loss: 3.2532e-04\n",
      "Epoch 540/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.0877e-04 - val_loss: 3.0224e-04\n",
      "Epoch 541/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.9628e-04 - val_loss: 3.2069e-04\n",
      "Epoch 542/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.8622e-04 - val_loss: 2.9925e-04\n",
      "Epoch 543/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.8769e-04 - val_loss: 3.4417e-04\n",
      "Epoch 544/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 3.1131e-04 - val_loss: 3.3605e-04\n",
      "Epoch 545/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.8995e-04 - val_loss: 3.2383e-04\n",
      "Epoch 546/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.9735e-04 - val_loss: 3.2921e-04\n",
      "Epoch 547/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.0608e-04 - val_loss: 3.4219e-04\n",
      "Epoch 548/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.0470e-04 - val_loss: 4.0725e-04\n",
      "Epoch 549/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.2272e-04 - val_loss: 5.1569e-04\n",
      "Epoch 550/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.5580e-04 - val_loss: 3.1538e-04\n",
      "Epoch 551/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.2293e-04 - val_loss: 3.0679e-04\n",
      "Epoch 552/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 3.2542e-04 - val_loss: 3.0407e-04\n",
      "Epoch 553/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.9021e-04 - val_loss: 3.0145e-04\n",
      "Epoch 554/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.9499e-04 - val_loss: 4.5493e-04\n",
      "Epoch 555/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.4758e-04 - val_loss: 2.9524e-04\n",
      "Epoch 556/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.1542e-04 - val_loss: 3.7252e-04\n",
      "Epoch 557/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 2.9441e-04 - val_loss: 3.1297e-04\n",
      "Epoch 558/2000\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 2.8639e-04 - val_loss: 3.1348e-04\n",
      "Epoch 559/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 2.9914e-04 - val_loss: 3.3717e-04\n",
      "Epoch 560/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 3.1136e-04 - val_loss: 3.0343e-04\n",
      "Epoch 561/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.0026e-04 - val_loss: 3.5237e-04\n",
      "Epoch 562/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.9923e-04 - val_loss: 3.4499e-04\n",
      "Epoch 563/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 2.9347e-04 - val_loss: 3.1959e-04\n",
      "Epoch 564/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.9243e-04 - val_loss: 3.5249e-04\n",
      "Epoch 565/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.2016e-04 - val_loss: 2.9959e-04\n",
      "Epoch 566/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.8921e-04 - val_loss: 3.1727e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 567/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.9395e-04 - val_loss: 3.0174e-04\n",
      "Epoch 568/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 2.9400e-04 - val_loss: 3.2206e-04\n",
      "Epoch 569/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.9277e-04 - val_loss: 3.1605e-04\n",
      "Epoch 570/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.9441e-04 - val_loss: 3.0326e-04\n",
      "Epoch 571/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.9433e-04 - val_loss: 3.0636e-04\n",
      "Epoch 572/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.9931e-04 - val_loss: 4.1190e-04\n",
      "Epoch 573/2000\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 3.2128e-04 - val_loss: 3.1982e-04\n",
      "Epoch 574/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 3.1685e-04 - val_loss: 3.4614e-04\n",
      "Epoch 575/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.1405e-04 - val_loss: 5.2173e-04\n",
      "Epoch 576/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 3.4745e-04 - val_loss: 3.7332e-04\n",
      "Epoch 577/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 3.3472e-04 - val_loss: 3.2210e-04\n",
      "Epoch 578/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 2.9827e-04 - val_loss: 3.0229e-04\n",
      "Epoch 579/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.9069e-04 - val_loss: 3.2932e-04\n",
      "Epoch 580/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 3.1337e-04 - val_loss: 3.2121e-04\n",
      "Epoch 581/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.8707e-04 - val_loss: 3.1407e-04\n",
      "Epoch 582/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.0702e-04 - val_loss: 3.4951e-04\n",
      "Epoch 583/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 3.0528e-04 - val_loss: 4.5463e-04\n",
      "Epoch 584/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.3941e-04 - val_loss: 4.4947e-04\n",
      "Epoch 585/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.2733e-04 - val_loss: 4.1920e-04\n",
      "Epoch 586/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.4875e-04 - val_loss: 2.9955e-04\n",
      "Epoch 587/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 3.0597e-04 - val_loss: 3.1904e-04\n",
      "Epoch 588/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.0875e-04 - val_loss: 3.0333e-04\n",
      "Epoch 589/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.8390e-04 - val_loss: 3.0437e-04\n",
      "Epoch 590/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.0744e-04 - val_loss: 3.1302e-04\n",
      "Epoch 591/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 2.9061e-04 - val_loss: 3.0515e-04\n",
      "Epoch 592/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.8994e-04 - val_loss: 3.2406e-04\n",
      "Epoch 593/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 2.8311e-04 - val_loss: 3.4314e-04\n",
      "Epoch 594/2000\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 2.9118e-04 - val_loss: 3.0928e-04\n",
      "Epoch 595/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 2.8173e-04 - val_loss: 3.3505e-04\n",
      "Epoch 596/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.0416e-04 - val_loss: 3.1610e-04\n",
      "Epoch 597/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 2.9627e-04 - val_loss: 3.2071e-04\n",
      "Epoch 598/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.9698e-04 - val_loss: 3.1517e-04\n",
      "Epoch 599/2000\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 2.9065e-04 - val_loss: 3.2259e-04\n",
      "Epoch 600/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.8361e-04 - val_loss: 3.2324e-04\n",
      "Epoch 601/2000\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 2.8326e-04 - val_loss: 3.0914e-04\n",
      "Epoch 602/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 2.8353e-04 - val_loss: 3.6186e-04\n",
      "Epoch 603/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.3218e-04 - val_loss: 3.5685e-04\n",
      "Epoch 604/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.4147e-04 - val_loss: 3.1425e-04\n",
      "Epoch 605/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.9496e-04 - val_loss: 3.5111e-04\n",
      "Epoch 606/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.9244e-04 - val_loss: 3.1507e-04\n",
      "Epoch 607/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.8848e-04 - val_loss: 3.3523e-04\n",
      "Epoch 608/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.8837e-04 - val_loss: 3.5088e-04\n",
      "Epoch 609/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.9310e-04 - val_loss: 3.3428e-04\n",
      "Epoch 610/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.8234e-04 - val_loss: 3.2376e-04\n",
      "Epoch 611/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.8918e-04 - val_loss: 3.6251e-04\n",
      "Epoch 612/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.9372e-04 - val_loss: 4.1615e-04\n",
      "Epoch 613/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 3.0523e-04 - val_loss: 3.1797e-04\n",
      "Epoch 614/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.8395e-04 - val_loss: 3.2318e-04\n",
      "Epoch 615/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.0016e-04 - val_loss: 4.7404e-04\n",
      "Epoch 616/2000\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 3.2622e-04 - val_loss: 3.3395e-04\n",
      "Epoch 617/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.8672e-04 - val_loss: 3.8516e-04\n",
      "Epoch 618/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.1550e-04 - val_loss: 3.5687e-04\n",
      "Epoch 619/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.1040e-04 - val_loss: 5.9308e-04\n",
      "Epoch 620/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.2350e-04 - val_loss: 3.0849e-04\n",
      "Epoch 621/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.0807e-04 - val_loss: 3.8905e-04\n",
      "Epoch 622/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 3.0442e-04 - val_loss: 3.0729e-04\n",
      "Epoch 623/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.8301e-04 - val_loss: 3.0872e-04\n",
      "Epoch 624/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.8706e-04 - val_loss: 3.1007e-04\n",
      "Epoch 625/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.8834e-04 - val_loss: 3.1782e-04\n",
      "Epoch 626/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.8093e-04 - val_loss: 3.2435e-04\n",
      "Epoch 627/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.8750e-04 - val_loss: 3.3668e-04\n",
      "Epoch 628/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.9403e-04 - val_loss: 3.6325e-04\n",
      "Epoch 629/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.2732e-04 - val_loss: 3.5186e-04\n",
      "Epoch 630/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.9004e-04 - val_loss: 3.5299e-04\n",
      "Epoch 631/2000\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 2.9741e-04 - val_loss: 3.0355e-04\n",
      "Epoch 632/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 2.9361e-04 - val_loss: 3.3313e-04\n",
      "Epoch 633/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 2.8282e-04 - val_loss: 3.0930e-04\n",
      "Epoch 634/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 2.8328e-04 - val_loss: 3.1114e-04\n",
      "Epoch 635/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.9778e-04 - val_loss: 4.0276e-04\n",
      "Epoch 636/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.3489e-04 - val_loss: 3.0773e-04\n",
      "Epoch 637/2000\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 2.8927e-04 - val_loss: 3.8326e-04\n",
      "Epoch 638/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.1120e-04 - val_loss: 4.7414e-04\n",
      "Epoch 639/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.0118e-04 - val_loss: 3.0981e-04\n",
      "Epoch 640/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 2.9417e-04 - val_loss: 3.4531e-04\n",
      "Epoch 641/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 2.9309e-04 - val_loss: 3.2677e-04\n",
      "Epoch 642/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 2.8679e-04 - val_loss: 3.1420e-04\n",
      "Epoch 643/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.8857e-04 - val_loss: 3.3145e-04\n",
      "Epoch 644/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.8705e-04 - val_loss: 3.0951e-04\n",
      "Epoch 645/2000\n",
      "3977/3977 [==============================] - 2s 528us/step - loss: 2.8059e-04 - val_loss: 4.1588e-04\n",
      "Epoch 646/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.1302e-04 - val_loss: 6.0850e-04\n",
      "Epoch 647/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.6129e-04 - val_loss: 3.5801e-04\n",
      "Epoch 648/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.3279e-04 - val_loss: 3.1334e-04\n",
      "Epoch 649/2000\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 2.7753e-04 - val_loss: 3.3364e-04\n",
      "Epoch 650/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.0315e-04 - val_loss: 3.2567e-04\n",
      "Epoch 651/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.9984e-04 - val_loss: 3.1263e-04\n",
      "Epoch 652/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.9764e-04 - val_loss: 3.3267e-04\n",
      "Epoch 653/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 3.0166e-04 - val_loss: 4.1473e-04\n",
      "Epoch 654/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.0466e-04 - val_loss: 3.3997e-04\n",
      "Epoch 655/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.9969e-04 - val_loss: 3.1682e-04\n",
      "Epoch 656/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.4204e-04 - val_loss: 3.7372e-04\n",
      "Epoch 657/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.3633e-04 - val_loss: 3.2741e-04\n",
      "Epoch 658/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 3.0009e-04 - val_loss: 3.1259e-04\n",
      "Epoch 659/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.8812e-04 - val_loss: 3.1085e-04\n",
      "Epoch 660/2000\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 2.8685e-04 - val_loss: 3.1116e-04\n",
      "Epoch 661/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 2.9059e-04 - val_loss: 3.3811e-04\n",
      "Epoch 662/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.1213e-04 - val_loss: 3.4918e-04\n",
      "Epoch 663/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.8724e-04 - val_loss: 3.1177e-04\n",
      "Epoch 664/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.8561e-04 - val_loss: 3.5167e-04\n",
      "Epoch 665/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.9327e-04 - val_loss: 3.2500e-04\n",
      "Epoch 666/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 2.8836e-04 - val_loss: 3.0728e-04\n",
      "Epoch 667/2000\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 2.9996e-04 - val_loss: 3.3455e-04\n",
      "Epoch 668/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 2.9511e-04 - val_loss: 3.8296e-04\n",
      "Epoch 669/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.0593e-04 - val_loss: 3.6006e-04\n",
      "Epoch 670/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.9849e-04 - val_loss: 3.1157e-04\n",
      "Epoch 671/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.8886e-04 - val_loss: 3.5235e-04\n",
      "Epoch 672/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.0178e-04 - val_loss: 3.0563e-04\n",
      "Epoch 673/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.8510e-04 - val_loss: 3.1493e-04\n",
      "Epoch 674/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 3.1880e-04 - val_loss: 5.0145e-04\n",
      "Epoch 675/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.2886e-04 - val_loss: 3.4627e-04\n",
      "Epoch 676/2000\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 2.9188e-04 - val_loss: 3.3940e-04\n",
      "Epoch 677/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.8914e-04 - val_loss: 4.5695e-04\n",
      "Epoch 678/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.4322e-04 - val_loss: 4.7694e-04\n",
      "Epoch 679/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 5.2762e-04 - val_loss: 4.6750e-04\n",
      "Epoch 680/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 4.0228e-04 - val_loss: 3.5626e-04\n",
      "Epoch 681/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 3.3082e-04 - val_loss: 3.0368e-04\n",
      "Epoch 682/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.0154e-04 - val_loss: 2.9951e-04\n",
      "Epoch 683/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 3.1297e-04 - val_loss: 3.7391e-04\n",
      "Epoch 684/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 3.2463e-04 - val_loss: 4.0265e-04\n",
      "Epoch 685/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.1314e-04 - val_loss: 3.0757e-04\n",
      "Epoch 686/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.0376e-04 - val_loss: 3.0743e-04\n",
      "Epoch 687/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 3.0529e-04 - val_loss: 3.1241e-04\n",
      "Epoch 688/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.0025e-04 - val_loss: 3.8880e-04\n",
      "Epoch 689/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 3.0089e-04 - val_loss: 3.4745e-04\n",
      "Epoch 690/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.0269e-04 - val_loss: 3.4321e-04\n",
      "Epoch 691/2000\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 2.8542e-04 - val_loss: 3.1398e-04\n",
      "Epoch 692/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.8533e-04 - val_loss: 3.0685e-04\n",
      "Epoch 693/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 2.7665e-04 - val_loss: 3.0374e-04\n",
      "Epoch 694/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.8096e-04 - val_loss: 3.1872e-04\n",
      "Epoch 695/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.8892e-04 - val_loss: 3.0964e-04\n",
      "Epoch 696/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.9239e-04 - val_loss: 4.6165e-04\n",
      "Epoch 697/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.3427e-04 - val_loss: 3.4654e-04\n",
      "Epoch 698/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.6223e-04 - val_loss: 6.2776e-04\n",
      "Epoch 699/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 3.3002e-04 - val_loss: 3.1883e-04\n",
      "Epoch 700/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.9246e-04 - val_loss: 3.0314e-04\n",
      "Epoch 701/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.8750e-04 - val_loss: 3.1744e-04\n",
      "Epoch 702/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 2.8406e-04 - val_loss: 3.1220e-04\n",
      "Epoch 703/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 2.8704e-04 - val_loss: 3.1725e-04\n",
      "Epoch 704/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.7670e-04 - val_loss: 3.0444e-04\n",
      "Epoch 705/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.8677e-04 - val_loss: 4.5237e-04\n",
      "Epoch 706/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.1292e-04 - val_loss: 3.1041e-04\n",
      "Epoch 707/2000\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 2.8506e-04 - val_loss: 3.5414e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 708/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.9916e-04 - val_loss: 3.0472e-04\n",
      "Epoch 709/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.8320e-04 - val_loss: 3.2235e-04\n",
      "Epoch 710/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.9211e-04 - val_loss: 3.1775e-04\n",
      "Epoch 711/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.8066e-04 - val_loss: 3.0595e-04\n",
      "Epoch 712/2000\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 2.7856e-04 - val_loss: 3.1041e-04\n",
      "Epoch 713/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.7723e-04 - val_loss: 3.5561e-04\n",
      "Epoch 714/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 2.8154e-04 - val_loss: 3.0864e-04\n",
      "Epoch 715/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.7919e-04 - val_loss: 3.0923e-04\n",
      "Epoch 716/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.8132e-04 - val_loss: 3.3214e-04\n",
      "Epoch 717/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.8533e-04 - val_loss: 3.1382e-04\n",
      "Epoch 718/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.7949e-04 - val_loss: 3.0971e-04\n",
      "Epoch 719/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.8830e-04 - val_loss: 3.2227e-04\n",
      "Epoch 720/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.9938e-04 - val_loss: 3.3156e-04\n",
      "Epoch 721/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.7865e-04 - val_loss: 3.2091e-04\n",
      "Epoch 722/2000\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 2.8266e-04 - val_loss: 3.8296e-04\n",
      "Epoch 723/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.9491e-04 - val_loss: 3.3617e-04\n",
      "Epoch 724/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.0959e-04 - val_loss: 3.1165e-04\n",
      "Epoch 725/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.0334e-04 - val_loss: 3.4319e-04\n",
      "Epoch 726/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.0024e-04 - val_loss: 3.1560e-04\n",
      "Epoch 727/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.9949e-04 - val_loss: 3.1204e-04\n",
      "Epoch 728/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 3.1230e-04 - val_loss: 3.7238e-04\n",
      "Epoch 729/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.9281e-04 - val_loss: 3.1388e-04\n",
      "Epoch 730/2000\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 2.8199e-04 - val_loss: 3.1689e-04\n",
      "Epoch 731/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.8153e-04 - val_loss: 3.1210e-04\n",
      "Epoch 732/2000\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 2.8682e-04 - val_loss: 3.1636e-04\n",
      "Epoch 733/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.8701e-04 - val_loss: 3.7105e-04\n",
      "Epoch 734/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 3.1060e-04 - val_loss: 3.6725e-04\n",
      "Epoch 735/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.1231e-04 - val_loss: 3.4888e-04\n",
      "Epoch 736/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.9319e-04 - val_loss: 3.2820e-04\n",
      "Epoch 737/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.9579e-04 - val_loss: 3.7366e-04\n",
      "Epoch 738/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 3.0066e-04 - val_loss: 3.6006e-04\n",
      "Epoch 739/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.1473e-04 - val_loss: 3.3772e-04\n",
      "Epoch 740/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.2023e-04 - val_loss: 4.5885e-04\n",
      "Epoch 741/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.0580e-04 - val_loss: 3.2768e-04\n",
      "Epoch 742/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.8137e-04 - val_loss: 3.1913e-04\n",
      "Epoch 743/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.7675e-04 - val_loss: 3.1880e-04\n",
      "Epoch 744/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.7660e-04 - val_loss: 3.2478e-04\n",
      "Epoch 745/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.7745e-04 - val_loss: 3.7296e-04\n",
      "Epoch 746/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 2.9294e-04 - val_loss: 3.1723e-04\n",
      "Epoch 747/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 3.4641e-04 - val_loss: 4.8008e-04\n",
      "Epoch 748/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.6556e-04 - val_loss: 3.1016e-04\n",
      "Epoch 749/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 3.3128e-04 - val_loss: 4.3492e-04\n",
      "Epoch 750/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.0967e-04 - val_loss: 3.2499e-04\n",
      "Epoch 751/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.8585e-04 - val_loss: 3.1714e-04\n",
      "Epoch 752/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.8329e-04 - val_loss: 3.2045e-04\n",
      "Epoch 753/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 2.8380e-04 - val_loss: 3.3955e-04\n",
      "Epoch 754/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.8789e-04 - val_loss: 3.1107e-04\n",
      "Epoch 755/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.0655e-04 - val_loss: 3.1167e-04\n",
      "Epoch 756/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.8446e-04 - val_loss: 3.2890e-04\n",
      "Epoch 757/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 2.8925e-04 - val_loss: 3.3005e-04\n",
      "Epoch 758/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.7747e-04 - val_loss: 3.3754e-04\n",
      "Epoch 759/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.9710e-04 - val_loss: 3.2976e-04\n",
      "Epoch 760/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.0258e-04 - val_loss: 3.8289e-04\n",
      "Epoch 761/2000\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 2.8645e-04 - val_loss: 3.2194e-04\n",
      "Epoch 762/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.7648e-04 - val_loss: 3.7885e-04\n",
      "Epoch 763/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.9722e-04 - val_loss: 3.2870e-04\n",
      "Epoch 764/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.7356e-04 - val_loss: 3.2609e-04\n",
      "Epoch 765/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 2.7970e-04 - val_loss: 3.3076e-04\n",
      "Epoch 766/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.9468e-04 - val_loss: 3.3447e-04\n",
      "Epoch 767/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.8326e-04 - val_loss: 3.2493e-04\n",
      "Epoch 768/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.7733e-04 - val_loss: 3.3204e-04\n",
      "Epoch 769/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 3.0088e-04 - val_loss: 5.4406e-04\n",
      "Epoch 770/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.1837e-04 - val_loss: 3.2595e-04\n",
      "Epoch 771/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 3.0531e-04 - val_loss: 3.6329e-04\n",
      "Epoch 772/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.9986e-04 - val_loss: 3.2734e-04\n",
      "Epoch 773/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.0121e-04 - val_loss: 3.1320e-04\n",
      "Epoch 774/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.8552e-04 - val_loss: 3.5627e-04\n",
      "Epoch 775/2000\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 3.3004e-04 - val_loss: 4.7770e-04\n",
      "Epoch 776/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 3.1471e-04 - val_loss: 3.4012e-04\n",
      "Epoch 777/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.9851e-04 - val_loss: 3.2994e-04\n",
      "Epoch 778/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.8605e-04 - val_loss: 3.1304e-04\n",
      "Epoch 779/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.7753e-04 - val_loss: 3.2145e-04\n",
      "Epoch 780/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.8321e-04 - val_loss: 3.1617e-04\n",
      "Epoch 781/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.8738e-04 - val_loss: 3.1569e-04\n",
      "Epoch 782/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.7784e-04 - val_loss: 3.3741e-04\n",
      "Epoch 783/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.8262e-04 - val_loss: 3.5045e-04\n",
      "Epoch 784/2000\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 2.9380e-04 - val_loss: 3.1280e-04\n",
      "Epoch 785/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.7891e-04 - val_loss: 3.7544e-04\n",
      "Epoch 786/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.8299e-04 - val_loss: 3.7961e-04\n",
      "Epoch 787/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.9279e-04 - val_loss: 3.3379e-04\n",
      "Epoch 788/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.9054e-04 - val_loss: 3.7739e-04\n",
      "Epoch 789/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.9321e-04 - val_loss: 3.0998e-04\n",
      "Epoch 790/2000\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 2.9506e-04 - val_loss: 3.9937e-04\n",
      "Epoch 791/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 3.4211e-04 - val_loss: 3.3550e-04\n",
      "Epoch 792/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 3.1327e-04 - val_loss: 6.0162e-04\n",
      "Epoch 793/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.3341e-04 - val_loss: 3.2180e-04\n",
      "Epoch 794/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.0733e-04 - val_loss: 3.2086e-04\n",
      "Epoch 795/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 3.1725e-04 - val_loss: 3.3559e-04\n",
      "Epoch 796/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.9082e-04 - val_loss: 4.2565e-04\n",
      "Epoch 797/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 3.2501e-04 - val_loss: 3.2733e-04\n",
      "Epoch 798/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.9524e-04 - val_loss: 3.2703e-04\n",
      "Epoch 799/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 2.8483e-04 - val_loss: 3.1528e-04\n",
      "Epoch 800/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.7673e-04 - val_loss: 3.4560e-04\n",
      "Epoch 801/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 2.9723e-04 - val_loss: 3.6107e-04\n",
      "Epoch 802/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.9888e-04 - val_loss: 4.0980e-04\n",
      "Epoch 803/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 3.0349e-04 - val_loss: 3.5607e-04\n",
      "Epoch 804/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.8514e-04 - val_loss: 3.5715e-04\n",
      "Epoch 805/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.8122e-04 - val_loss: 3.8301e-04\n",
      "Epoch 806/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.8897e-04 - val_loss: 3.5172e-04\n",
      "Epoch 807/2000\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 2.7587e-04 - val_loss: 3.3008e-04\n",
      "Epoch 808/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.7290e-04 - val_loss: 3.5463e-04\n",
      "Epoch 809/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.8550e-04 - val_loss: 3.8225e-04\n",
      "Epoch 810/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.9279e-04 - val_loss: 3.2396e-04\n",
      "Epoch 811/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.8120e-04 - val_loss: 3.8042e-04\n",
      "Epoch 812/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 2.9835e-04 - val_loss: 3.1455e-04\n",
      "Epoch 813/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.0614e-04 - val_loss: 3.6570e-04\n",
      "Epoch 814/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 3.1019e-04 - val_loss: 3.5141e-04\n",
      "Epoch 815/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.9587e-04 - val_loss: 3.5581e-04\n",
      "Epoch 816/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.9600e-04 - val_loss: 3.1774e-04\n",
      "Epoch 817/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.1542e-04 - val_loss: 5.5084e-04\n",
      "Epoch 818/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.1200e-04 - val_loss: 3.1528e-04\n",
      "Epoch 819/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 2.8668e-04 - val_loss: 3.0305e-04\n",
      "Epoch 820/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.8904e-04 - val_loss: 3.2632e-04\n",
      "Epoch 821/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.1847e-04 - val_loss: 3.3414e-04\n",
      "Epoch 822/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.3734e-04 - val_loss: 4.3793e-04\n",
      "Epoch 823/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.4892e-04 - val_loss: 5.0936e-04\n",
      "Epoch 824/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.3134e-04 - val_loss: 3.2033e-04\n",
      "Epoch 825/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 2.8232e-04 - val_loss: 3.6216e-04\n",
      "Epoch 826/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.8998e-04 - val_loss: 3.2555e-04\n",
      "Epoch 827/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.7341e-04 - val_loss: 3.1730e-04\n",
      "Epoch 828/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.7138e-04 - val_loss: 3.1958e-04\n",
      "Epoch 829/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.7755e-04 - val_loss: 3.2431e-04\n",
      "Epoch 830/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.9179e-04 - val_loss: 3.3422e-04\n",
      "Epoch 831/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.8966e-04 - val_loss: 3.3697e-04\n",
      "Epoch 832/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.7238e-04 - val_loss: 3.2059e-04\n",
      "Epoch 833/2000\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 2.7424e-04 - val_loss: 3.2323e-04\n",
      "Epoch 834/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.7361e-04 - val_loss: 3.4180e-04\n",
      "Epoch 835/2000\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 2.7806e-04 - val_loss: 3.3555e-04\n",
      "Epoch 836/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.7198e-04 - val_loss: 3.2278e-04\n",
      "Epoch 837/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 2.7566e-04 - val_loss: 3.6604e-04\n",
      "Epoch 838/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 2.9424e-04 - val_loss: 3.1652e-04\n",
      "Epoch 839/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.8045e-04 - val_loss: 3.3818e-04\n",
      "Epoch 840/2000\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 2.6816e-04 - val_loss: 3.2985e-04\n",
      "Epoch 841/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 2.7265e-04 - val_loss: 3.5073e-04\n",
      "Epoch 842/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.7490e-04 - val_loss: 3.2819e-04\n",
      "Epoch 843/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.8539e-04 - val_loss: 3.2766e-04\n",
      "Epoch 844/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.6957e-04 - val_loss: 3.2764e-04\n",
      "Epoch 845/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.7590e-04 - val_loss: 3.5312e-04\n",
      "Epoch 846/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 2.7481e-04 - val_loss: 3.2260e-04\n",
      "Epoch 847/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.7122e-04 - val_loss: 3.2820e-04\n",
      "Epoch 848/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.7948e-04 - val_loss: 3.2152e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 849/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.7566e-04 - val_loss: 3.3070e-04\n",
      "Epoch 850/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 2.7302e-04 - val_loss: 3.5063e-04\n",
      "Epoch 851/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.7982e-04 - val_loss: 3.3523e-04\n",
      "Epoch 852/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.7074e-04 - val_loss: 3.3902e-04\n",
      "Epoch 853/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.7095e-04 - val_loss: 4.1574e-04\n",
      "Epoch 854/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.7443e-04 - val_loss: 3.3401e-04\n",
      "Epoch 855/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.6738e-04 - val_loss: 3.3124e-04\n",
      "Epoch 856/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 2.7871e-04 - val_loss: 3.7193e-04\n",
      "Epoch 857/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.0494e-04 - val_loss: 3.5232e-04\n",
      "Epoch 858/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.0426e-04 - val_loss: 5.0700e-04\n",
      "Epoch 859/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 3.0702e-04 - val_loss: 3.4818e-04\n",
      "Epoch 860/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.8935e-04 - val_loss: 3.3223e-04\n",
      "Epoch 861/2000\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 2.9864e-04 - val_loss: 3.8980e-04\n",
      "Epoch 862/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 2.8509e-04 - val_loss: 3.4693e-04\n",
      "Epoch 863/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 2.8868e-04 - val_loss: 3.3711e-04\n",
      "Epoch 864/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.7443e-04 - val_loss: 3.4200e-04\n",
      "Epoch 865/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.7102e-04 - val_loss: 3.7925e-04\n",
      "Epoch 866/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.8441e-04 - val_loss: 3.9436e-04\n",
      "Epoch 867/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.8584e-04 - val_loss: 3.4706e-04\n",
      "Epoch 868/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.8224e-04 - val_loss: 3.2179e-04\n",
      "Epoch 869/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 2.8224e-04 - val_loss: 3.9635e-04\n",
      "Epoch 870/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.9019e-04 - val_loss: 3.4937e-04\n",
      "Epoch 871/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.9571e-04 - val_loss: 3.9131e-04\n",
      "Epoch 872/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.8924e-04 - val_loss: 3.8976e-04\n",
      "Epoch 873/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.8758e-04 - val_loss: 3.5553e-04\n",
      "Epoch 874/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.9773e-04 - val_loss: 3.4223e-04\n",
      "Epoch 875/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.8355e-04 - val_loss: 3.4426e-04\n",
      "Epoch 876/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.7063e-04 - val_loss: 3.3047e-04\n",
      "Epoch 877/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 2.6893e-04 - val_loss: 3.3612e-04\n",
      "Epoch 878/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 2.8369e-04 - val_loss: 3.3729e-04\n",
      "Epoch 879/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.7127e-04 - val_loss: 3.4335e-04\n",
      "Epoch 880/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 2.6380e-04 - val_loss: 3.3394e-04\n",
      "Epoch 881/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.6856e-04 - val_loss: 3.4847e-04\n",
      "Epoch 882/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.6860e-04 - val_loss: 3.3202e-04\n",
      "Epoch 883/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.7296e-04 - val_loss: 3.8302e-04\n",
      "Epoch 884/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 2.6805e-04 - val_loss: 3.2742e-04\n",
      "Epoch 885/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.6755e-04 - val_loss: 3.4625e-04\n",
      "Epoch 886/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.7245e-04 - val_loss: 3.5981e-04\n",
      "Epoch 887/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.9710e-04 - val_loss: 3.5049e-04\n",
      "Epoch 888/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.1080e-04 - val_loss: 4.8168e-04\n",
      "Epoch 889/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.2249e-04 - val_loss: 3.5053e-04\n",
      "Epoch 890/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.7840e-04 - val_loss: 3.1531e-04\n",
      "Epoch 891/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 3.4818e-04 - val_loss: 6.0581e-04\n",
      "Epoch 892/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 3.7804e-04 - val_loss: 5.2281e-04\n",
      "Epoch 893/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.6537e-04 - val_loss: 3.3415e-04\n",
      "Epoch 894/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.0252e-04 - val_loss: 3.2366e-04\n",
      "Epoch 895/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.8011e-04 - val_loss: 3.6136e-04\n",
      "Epoch 896/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.8425e-04 - val_loss: 3.3248e-04\n",
      "Epoch 897/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.9201e-04 - val_loss: 3.2193e-04\n",
      "Epoch 898/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.0346e-04 - val_loss: 3.4678e-04\n",
      "Epoch 899/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 2.8670e-04 - val_loss: 3.7887e-04\n",
      "Epoch 900/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.8433e-04 - val_loss: 3.7270e-04\n",
      "Epoch 901/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.8618e-04 - val_loss: 3.2959e-04\n",
      "Epoch 902/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.7239e-04 - val_loss: 3.3081e-04\n",
      "Epoch 903/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 2.8154e-04 - val_loss: 3.4521e-04\n",
      "Epoch 904/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 2.8234e-04 - val_loss: 3.3490e-04\n",
      "Epoch 905/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 2.7595e-04 - val_loss: 3.7007e-04\n",
      "Epoch 906/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.7558e-04 - val_loss: 3.3967e-04\n",
      "Epoch 907/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.7242e-04 - val_loss: 3.2535e-04\n",
      "Epoch 908/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 2.8866e-04 - val_loss: 3.2943e-04\n",
      "Epoch 909/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.7922e-04 - val_loss: 3.3017e-04\n",
      "Epoch 910/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.7503e-04 - val_loss: 3.4072e-04\n",
      "Epoch 911/2000\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 2.7727e-04 - val_loss: 3.4885e-04\n",
      "Epoch 912/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.8014e-04 - val_loss: 3.6308e-04\n",
      "Epoch 913/2000\n",
      "3977/3977 [==============================] - 2s 529us/step - loss: 3.1208e-04 - val_loss: 3.9612e-04\n",
      "Epoch 914/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.4523e-04 - val_loss: 6.0437e-04\n",
      "Epoch 915/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 3.2328e-04 - val_loss: 3.4639e-04\n",
      "Epoch 916/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 3.1424e-04 - val_loss: 5.0330e-04\n",
      "Epoch 917/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.9113e-04 - val_loss: 3.3847e-04\n",
      "Epoch 918/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.0085e-04 - val_loss: 3.5151e-04\n",
      "Epoch 919/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 2.8180e-04 - val_loss: 3.4351e-04\n",
      "Epoch 920/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 2.6711e-04 - val_loss: 3.6914e-04\n",
      "Epoch 921/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.7534e-04 - val_loss: 3.9909e-04\n",
      "Epoch 922/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.7998e-04 - val_loss: 3.8020e-04\n",
      "Epoch 923/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.8950e-04 - val_loss: 3.7507e-04\n",
      "Epoch 924/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 3.0110e-04 - val_loss: 3.9476e-04\n",
      "Epoch 925/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.8739e-04 - val_loss: 3.9617e-04\n",
      "Epoch 926/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.8587e-04 - val_loss: 3.7087e-04\n",
      "Epoch 927/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.0973e-04 - val_loss: 4.2156e-04\n",
      "Epoch 928/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.9886e-04 - val_loss: 3.5231e-04\n",
      "Epoch 929/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.7951e-04 - val_loss: 3.3807e-04\n",
      "Epoch 930/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.7440e-04 - val_loss: 3.7565e-04\n",
      "Epoch 931/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.7103e-04 - val_loss: 3.6199e-04\n",
      "Epoch 932/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.6699e-04 - val_loss: 3.5080e-04\n",
      "Epoch 933/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.7383e-04 - val_loss: 4.1776e-04\n",
      "Epoch 934/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 2.7574e-04 - val_loss: 4.4304e-04\n",
      "Epoch 935/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 3.2306e-04 - val_loss: 5.2681e-04\n",
      "Epoch 936/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.4031e-04 - val_loss: 4.7333e-04\n",
      "Epoch 937/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.2058e-04 - val_loss: 3.6538e-04\n",
      "Epoch 938/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 2.8406e-04 - val_loss: 3.7875e-04\n",
      "Epoch 939/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.0287e-04 - val_loss: 3.8369e-04\n",
      "Epoch 940/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.0618e-04 - val_loss: 3.5358e-04\n",
      "Epoch 941/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.9662e-04 - val_loss: 3.6923e-04\n",
      "Epoch 942/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 2.6426e-04 - val_loss: 3.5829e-04\n",
      "Epoch 943/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.6421e-04 - val_loss: 3.5954e-04\n",
      "Epoch 944/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.6964e-04 - val_loss: 3.8020e-04\n",
      "Epoch 945/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.6474e-04 - val_loss: 3.4669e-04\n",
      "Epoch 946/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 2.7070e-04 - val_loss: 5.3760e-04\n",
      "Epoch 947/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.8565e-04 - val_loss: 3.7635e-04\n",
      "Epoch 948/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.7873e-04 - val_loss: 3.5700e-04\n",
      "Epoch 949/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 2.6624e-04 - val_loss: 3.8007e-04\n",
      "Epoch 950/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.5815e-04 - val_loss: 3.9057e-04\n",
      "Epoch 951/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.8096e-04 - val_loss: 3.9029e-04\n",
      "Epoch 952/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.7515e-04 - val_loss: 4.5037e-04\n",
      "Epoch 953/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.8721e-04 - val_loss: 4.4596e-04\n",
      "Epoch 954/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.7094e-04 - val_loss: 4.0239e-04\n",
      "Epoch 955/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.6596e-04 - val_loss: 4.2209e-04\n",
      "Epoch 956/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.6477e-04 - val_loss: 4.0001e-04\n",
      "Epoch 957/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.6490e-04 - val_loss: 3.9307e-04\n",
      "Epoch 958/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.7619e-04 - val_loss: 3.4949e-04\n",
      "Epoch 959/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.6586e-04 - val_loss: 4.0297e-04\n",
      "Epoch 960/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.7744e-04 - val_loss: 4.0451e-04\n",
      "Epoch 961/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 2.6855e-04 - val_loss: 3.8985e-04\n",
      "Epoch 962/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.6403e-04 - val_loss: 3.9426e-04\n",
      "Epoch 963/2000\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 2.6135e-04 - val_loss: 3.8257e-04\n",
      "Epoch 964/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.7791e-04 - val_loss: 3.9757e-04\n",
      "Epoch 965/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.6610e-04 - val_loss: 3.9474e-04\n",
      "Epoch 966/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.0523e-04 - val_loss: 3.9853e-04\n",
      "Epoch 967/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 2.7986e-04 - val_loss: 4.3875e-04\n",
      "Epoch 968/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 3.0356e-04 - val_loss: 3.9593e-04\n",
      "Epoch 969/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 2.7864e-04 - val_loss: 4.2207e-04\n",
      "Epoch 970/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.7316e-04 - val_loss: 4.0641e-04\n",
      "Epoch 971/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.8561e-04 - val_loss: 3.9959e-04\n",
      "Epoch 972/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.7990e-04 - val_loss: 5.3918e-04\n",
      "Epoch 973/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.1500e-04 - val_loss: 4.6381e-04\n",
      "Epoch 974/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.8968e-04 - val_loss: 4.4667e-04\n",
      "Epoch 975/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 3.1080e-04 - val_loss: 3.8352e-04\n",
      "Epoch 976/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.9563e-04 - val_loss: 4.5671e-04\n",
      "Epoch 977/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 3.1172e-04 - val_loss: 3.9711e-04\n",
      "Epoch 978/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 2.6746e-04 - val_loss: 3.4442e-04\n",
      "Epoch 979/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 2.5338e-04 - val_loss: 3.9898e-04\n",
      "Epoch 980/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.5442e-04 - val_loss: 3.8210e-04\n",
      "Epoch 981/2000\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 2.6327e-04 - val_loss: 4.1124e-04\n",
      "Epoch 982/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.7252e-04 - val_loss: 3.9899e-04\n",
      "Epoch 983/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 2.6954e-04 - val_loss: 4.5814e-04\n",
      "Epoch 984/2000\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 2.7478e-04 - val_loss: 3.8761e-04\n",
      "Epoch 985/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.8575e-04 - val_loss: 3.6872e-04\n",
      "Epoch 986/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.9865e-04 - val_loss: 4.2023e-04\n",
      "Epoch 987/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.9675e-04 - val_loss: 3.5672e-04\n",
      "Epoch 988/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.0695e-04 - val_loss: 4.6287e-04\n",
      "Epoch 989/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.9985e-04 - val_loss: 5.0104e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 990/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 3.0084e-04 - val_loss: 5.4961e-04\n",
      "Epoch 991/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.7014e-04 - val_loss: 4.4476e-04\n",
      "Epoch 992/2000\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 2.6418e-04 - val_loss: 3.8819e-04\n",
      "Epoch 993/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.5533e-04 - val_loss: 3.9627e-04\n",
      "Epoch 994/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.6161e-04 - val_loss: 3.7376e-04\n",
      "Epoch 995/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.7974e-04 - val_loss: 4.9477e-04\n",
      "Epoch 996/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.9198e-04 - val_loss: 5.7111e-04\n",
      "Epoch 997/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 2.8899e-04 - val_loss: 4.2532e-04\n",
      "Epoch 998/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.6286e-04 - val_loss: 4.0849e-04\n",
      "Epoch 999/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.6917e-04 - val_loss: 3.6613e-04\n",
      "Epoch 1000/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 2.6305e-04 - val_loss: 4.4420e-04\n",
      "Epoch 1001/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.6892e-04 - val_loss: 4.0937e-04\n",
      "Epoch 1002/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.8486e-04 - val_loss: 5.2296e-04\n",
      "Epoch 1003/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.9602e-04 - val_loss: 4.4625e-04\n",
      "Epoch 1004/2000\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 2.7502e-04 - val_loss: 4.3963e-04\n",
      "Epoch 1005/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 2.7487e-04 - val_loss: 4.0682e-04\n",
      "Epoch 1006/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.7335e-04 - val_loss: 5.0074e-04\n",
      "Epoch 1007/2000\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 2.9449e-04 - val_loss: 5.1445e-04\n",
      "Epoch 1008/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 3.0105e-04 - val_loss: 4.5232e-04\n",
      "Epoch 1009/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.8880e-04 - val_loss: 4.1497e-04\n",
      "Epoch 1010/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.5880e-04 - val_loss: 4.3054e-04\n",
      "Epoch 1011/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.9390e-04 - val_loss: 4.7704e-04\n",
      "Epoch 1012/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.9666e-04 - val_loss: 4.6035e-04\n",
      "Epoch 1013/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.6957e-04 - val_loss: 4.6907e-04\n",
      "Epoch 1014/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 2.5642e-04 - val_loss: 4.4265e-04\n",
      "Epoch 1015/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 2.6720e-04 - val_loss: 4.4228e-04\n",
      "Epoch 1016/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.5440e-04 - val_loss: 4.6324e-04\n",
      "Epoch 1017/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.5575e-04 - val_loss: 4.7406e-04\n",
      "Epoch 1018/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.5635e-04 - val_loss: 4.6763e-04\n",
      "Epoch 1019/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.5402e-04 - val_loss: 4.4085e-04\n",
      "Epoch 1020/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.5843e-04 - val_loss: 5.2579e-04\n",
      "Epoch 1021/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 2.7662e-04 - val_loss: 4.1047e-04\n",
      "Epoch 1022/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.8172e-04 - val_loss: 4.9987e-04\n",
      "Epoch 1023/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 2.8628e-04 - val_loss: 4.9300e-04\n",
      "Epoch 1024/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.9580e-04 - val_loss: 5.2309e-04\n",
      "Epoch 1025/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 3.0585e-04 - val_loss: 4.5862e-04\n",
      "Epoch 1026/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.7359e-04 - val_loss: 3.8397e-04\n",
      "Epoch 1027/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.6779e-04 - val_loss: 3.8935e-04\n",
      "Epoch 1028/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.6052e-04 - val_loss: 4.0424e-04\n",
      "Epoch 1029/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.5237e-04 - val_loss: 4.2535e-04\n",
      "Epoch 1030/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 2.5425e-04 - val_loss: 4.4532e-04\n",
      "Epoch 1031/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 2.4927e-04 - val_loss: 4.3049e-04\n",
      "Epoch 1032/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.4874e-04 - val_loss: 4.7237e-04\n",
      "Epoch 1033/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.5368e-04 - val_loss: 4.9179e-04\n",
      "Epoch 1034/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.6294e-04 - val_loss: 4.7920e-04\n",
      "Epoch 1035/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.5381e-04 - val_loss: 5.5074e-04\n",
      "Epoch 1036/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.5322e-04 - val_loss: 4.7590e-04\n",
      "Epoch 1037/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.6389e-04 - val_loss: 4.6569e-04\n",
      "Epoch 1038/2000\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 2.5597e-04 - val_loss: 4.8178e-04\n",
      "Epoch 1039/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.5121e-04 - val_loss: 5.3096e-04\n",
      "Epoch 1040/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.5581e-04 - val_loss: 4.6979e-04\n",
      "Epoch 1041/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.4991e-04 - val_loss: 5.0810e-04\n",
      "Epoch 1042/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.4497e-04 - val_loss: 4.9099e-04\n",
      "Epoch 1043/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.5890e-04 - val_loss: 5.7418e-04\n",
      "Epoch 1044/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.7181e-04 - val_loss: 6.1624e-04\n",
      "Epoch 1045/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.6120e-04 - val_loss: 5.0111e-04\n",
      "Epoch 1046/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.5654e-04 - val_loss: 4.7268e-04\n",
      "Epoch 1047/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.5501e-04 - val_loss: 4.6474e-04\n",
      "Epoch 1048/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.5385e-04 - val_loss: 4.9378e-04\n",
      "Epoch 1049/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.5918e-04 - val_loss: 5.1345e-04\n",
      "Epoch 1050/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 2.5262e-04 - val_loss: 5.4524e-04\n",
      "Epoch 1051/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.5351e-04 - val_loss: 6.0692e-04\n",
      "Epoch 1052/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 2.5565e-04 - val_loss: 5.0921e-04\n",
      "Epoch 1053/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.5131e-04 - val_loss: 5.5488e-04\n",
      "Epoch 1054/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.4355e-04 - val_loss: 5.2839e-04\n",
      "Epoch 1055/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.4317e-04 - val_loss: 6.5150e-04\n",
      "Epoch 1056/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.5260e-04 - val_loss: 5.1061e-04\n",
      "Epoch 1057/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.7563e-04 - val_loss: 5.1874e-04\n",
      "Epoch 1058/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.8470e-04 - val_loss: 4.7338e-04\n",
      "Epoch 1059/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.6011e-04 - val_loss: 4.9589e-04\n",
      "Epoch 1060/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.6455e-04 - val_loss: 4.9791e-04\n",
      "Epoch 1061/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.5438e-04 - val_loss: 4.9478e-04\n",
      "Epoch 1062/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 2.5856e-04 - val_loss: 5.1730e-04\n",
      "Epoch 1063/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.5936e-04 - val_loss: 5.7324e-04\n",
      "Epoch 1064/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.5790e-04 - val_loss: 5.0454e-04\n",
      "Epoch 1065/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 2.6539e-04 - val_loss: 5.8165e-04\n",
      "Epoch 1066/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.4923e-04 - val_loss: 6.4905e-04\n",
      "Epoch 1067/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.4248e-04 - val_loss: 7.0047e-04\n",
      "Epoch 1068/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.4986e-04 - val_loss: 5.3581e-04\n",
      "Epoch 1069/2000\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 2.4865e-04 - val_loss: 6.4472e-04\n",
      "Epoch 1070/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.4785e-04 - val_loss: 5.9408e-04\n",
      "Epoch 1071/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.4753e-04 - val_loss: 5.7628e-04\n",
      "Epoch 1072/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.6750e-04 - val_loss: 6.3341e-04\n",
      "Epoch 1073/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.1361e-04 - val_loss: 6.2135e-04\n",
      "Epoch 1074/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 3.1773e-04 - val_loss: 5.6816e-04\n",
      "Epoch 1075/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.7099e-04 - val_loss: 5.2876e-04\n",
      "Epoch 1076/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 2.6777e-04 - val_loss: 5.7962e-04\n",
      "Epoch 1077/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 2.5757e-04 - val_loss: 4.4369e-04\n",
      "Epoch 1078/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.5377e-04 - val_loss: 5.4913e-04\n",
      "Epoch 1079/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 2.6459e-04 - val_loss: 6.0483e-04\n",
      "Epoch 1080/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.5444e-04 - val_loss: 4.6977e-04\n",
      "Epoch 1081/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.5010e-04 - val_loss: 5.1081e-04\n",
      "Epoch 1082/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.4513e-04 - val_loss: 5.0248e-04\n",
      "Epoch 1083/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.4534e-04 - val_loss: 6.4345e-04\n",
      "Epoch 1084/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.6611e-04 - val_loss: 5.6975e-04\n",
      "Epoch 1085/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.5604e-04 - val_loss: 5.3915e-04\n",
      "Epoch 1086/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.5741e-04 - val_loss: 6.1591e-04\n",
      "Epoch 1087/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.5416e-04 - val_loss: 4.9309e-04\n",
      "Epoch 1088/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 2.5037e-04 - val_loss: 5.5063e-04\n",
      "Epoch 1089/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.4691e-04 - val_loss: 5.7758e-04\n",
      "Epoch 1090/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.6157e-04 - val_loss: 5.7150e-04\n",
      "Epoch 1091/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.5597e-04 - val_loss: 6.1393e-04\n",
      "Epoch 1092/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.5036e-04 - val_loss: 5.6338e-04\n",
      "Epoch 1093/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 2.6002e-04 - val_loss: 4.8345e-04\n",
      "Epoch 1094/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.5190e-04 - val_loss: 5.0055e-04\n",
      "Epoch 1095/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.4738e-04 - val_loss: 6.8980e-04\n",
      "Epoch 1096/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.5983e-04 - val_loss: 5.6892e-04\n",
      "Epoch 1097/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.5393e-04 - val_loss: 6.5671e-04\n",
      "Epoch 1098/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.3846e-04 - val_loss: 6.0530e-04\n",
      "Epoch 1099/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 2.3969e-04 - val_loss: 7.2978e-04\n",
      "Epoch 1100/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.3888e-04 - val_loss: 6.3119e-04\n",
      "Epoch 1101/2000\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 2.6265e-04 - val_loss: 5.9400e-04\n",
      "Epoch 1102/2000\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 2.7001e-04 - val_loss: 5.7553e-04\n",
      "Epoch 1103/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.6755e-04 - val_loss: 4.9312e-04\n",
      "Epoch 1104/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.4051e-04 - val_loss: 5.5652e-04\n",
      "Epoch 1105/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.4568e-04 - val_loss: 5.7881e-04\n",
      "Epoch 1106/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.6372e-04 - val_loss: 7.0604e-04\n",
      "Epoch 1107/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 2.5018e-04 - val_loss: 6.4547e-04\n",
      "Epoch 1108/2000\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 2.4303e-04 - val_loss: 6.3617e-04\n",
      "Epoch 1109/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.3479e-04 - val_loss: 7.7457e-04\n",
      "Epoch 1110/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.6769e-04 - val_loss: 6.0651e-04\n",
      "Epoch 1111/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.7440e-04 - val_loss: 4.8035e-04\n",
      "Epoch 1112/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.4744e-04 - val_loss: 5.6641e-04\n",
      "Epoch 1113/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.3641e-04 - val_loss: 5.5666e-04\n",
      "Epoch 1114/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.5119e-04 - val_loss: 6.6452e-04\n",
      "Epoch 1115/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.6547e-04 - val_loss: 7.2097e-04\n",
      "Epoch 1116/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 2.6978e-04 - val_loss: 5.4201e-04\n",
      "Epoch 1117/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.6639e-04 - val_loss: 5.8413e-04\n",
      "Epoch 1118/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.4822e-04 - val_loss: 6.6456e-04\n",
      "Epoch 1119/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.4866e-04 - val_loss: 6.1099e-04\n",
      "Epoch 1120/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 2.4297e-04 - val_loss: 7.0482e-04\n",
      "Epoch 1121/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.6684e-04 - val_loss: 6.8779e-04\n",
      "Epoch 1122/2000\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 2.3971e-04 - val_loss: 6.5181e-04\n",
      "Epoch 1123/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.4637e-04 - val_loss: 6.8877e-04\n",
      "Epoch 1124/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.4599e-04 - val_loss: 5.6549e-04\n",
      "Epoch 1125/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.3749e-04 - val_loss: 6.6650e-04\n",
      "Epoch 1126/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.3466e-04 - val_loss: 6.7525e-04\n",
      "Epoch 1127/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.3275e-04 - val_loss: 7.2812e-04\n",
      "Epoch 1128/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.4767e-04 - val_loss: 6.5748e-04\n",
      "Epoch 1129/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.4585e-04 - val_loss: 7.2075e-04\n",
      "Epoch 1130/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.2600e-04 - val_loss: 7.0673e-04\n",
      "Epoch 1131/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 2.2601e-04 - val_loss: 6.4755e-04\n",
      "Epoch 1132/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.3193e-04 - val_loss: 7.3916e-04\n",
      "Epoch 1133/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.3707e-04 - val_loss: 8.0307e-04\n",
      "Epoch 1134/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.5073e-04 - val_loss: 6.1356e-04\n",
      "Epoch 1135/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.6150e-04 - val_loss: 5.5205e-04\n",
      "Epoch 1136/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.4806e-04 - val_loss: 5.6059e-04\n",
      "Epoch 1137/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 2.3798e-04 - val_loss: 6.6588e-04\n",
      "Epoch 1138/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.5313e-04 - val_loss: 7.5897e-04\n",
      "Epoch 1139/2000\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 2.5212e-04 - val_loss: 6.4474e-04\n",
      "Epoch 1140/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 2.5543e-04 - val_loss: 5.6552e-04\n",
      "Epoch 1141/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.6318e-04 - val_loss: 6.4244e-04\n",
      "Epoch 1142/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.3851e-04 - val_loss: 6.0834e-04\n",
      "Epoch 1143/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.3678e-04 - val_loss: 6.7014e-04\n",
      "Epoch 1144/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.4261e-04 - val_loss: 6.2741e-04\n",
      "Epoch 1145/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 2.5833e-04 - val_loss: 8.4826e-04\n",
      "Epoch 1146/2000\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 2.8109e-04 - val_loss: 7.4821e-04\n",
      "Epoch 1147/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.9026e-04 - val_loss: 5.3753e-04\n",
      "Epoch 1148/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 2.5693e-04 - val_loss: 7.1218e-04\n",
      "Epoch 1149/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 2.3783e-04 - val_loss: 6.4927e-04\n",
      "Epoch 1150/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.3981e-04 - val_loss: 6.2843e-04\n",
      "Epoch 1151/2000\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 2.4547e-04 - val_loss: 6.3125e-04\n",
      "Epoch 1152/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.4825e-04 - val_loss: 8.3447e-04\n",
      "Epoch 1153/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.4761e-04 - val_loss: 5.9546e-04\n",
      "Epoch 1154/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 2.4731e-04 - val_loss: 7.3051e-04\n",
      "Epoch 1155/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.3883e-04 - val_loss: 7.2040e-04\n",
      "Epoch 1156/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.3535e-04 - val_loss: 6.8364e-04\n",
      "Epoch 1157/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.4393e-04 - val_loss: 7.6709e-04\n",
      "Epoch 1158/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.4194e-04 - val_loss: 6.4262e-04\n",
      "Epoch 1159/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.4427e-04 - val_loss: 7.4028e-04\n",
      "Epoch 1160/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.4723e-04 - val_loss: 6.2290e-04\n",
      "Epoch 1161/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.3765e-04 - val_loss: 7.1350e-04\n",
      "Epoch 1162/2000\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 2.3893e-04 - val_loss: 5.7752e-04\n",
      "Epoch 1163/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.2652e-04 - val_loss: 6.8270e-04\n",
      "Epoch 1164/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.2374e-04 - val_loss: 8.0960e-04\n",
      "Epoch 1165/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.2274e-04 - val_loss: 6.6629e-04\n",
      "Epoch 1166/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 2.2014e-04 - val_loss: 8.2108e-04\n",
      "Epoch 1167/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.2866e-04 - val_loss: 7.3293e-04\n",
      "Epoch 1168/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.4206e-04 - val_loss: 5.9974e-04\n",
      "Epoch 1169/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.4297e-04 - val_loss: 8.4204e-04\n",
      "Epoch 1170/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.3245e-04 - val_loss: 6.0711e-04\n",
      "Epoch 1171/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.4232e-04 - val_loss: 6.7112e-04\n",
      "Epoch 1172/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.2895e-04 - val_loss: 6.3923e-04\n",
      "Epoch 1173/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.3560e-04 - val_loss: 9.1997e-04\n",
      "Epoch 1174/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 2.3685e-04 - val_loss: 5.8081e-04\n",
      "Epoch 1175/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.3615e-04 - val_loss: 6.5386e-04\n",
      "Epoch 1176/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.3018e-04 - val_loss: 6.5849e-04\n",
      "Epoch 1177/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 2.4042e-04 - val_loss: 6.4589e-04\n",
      "Epoch 1178/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.3225e-04 - val_loss: 7.3725e-04\n",
      "Epoch 1179/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.2648e-04 - val_loss: 6.7753e-04\n",
      "Epoch 1180/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 2.2581e-04 - val_loss: 7.5084e-04\n",
      "Epoch 1181/2000\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 2.3866e-04 - val_loss: 7.3851e-04\n",
      "Epoch 1182/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.2765e-04 - val_loss: 7.8429e-04\n",
      "Epoch 1183/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.1864e-04 - val_loss: 8.1347e-04\n",
      "Epoch 1184/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.3120e-04 - val_loss: 8.0006e-04\n",
      "Epoch 1185/2000\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 2.2343e-04 - val_loss: 8.0016e-04\n",
      "Epoch 1186/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.2254e-04 - val_loss: 6.2644e-04\n",
      "Epoch 1187/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.2597e-04 - val_loss: 7.2516e-04\n",
      "Epoch 1188/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.3344e-04 - val_loss: 7.5173e-04\n",
      "Epoch 1189/2000\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 2.3640e-04 - val_loss: 8.5309e-04\n",
      "Epoch 1190/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.5097e-04 - val_loss: 5.9980e-04\n",
      "Epoch 1191/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.5630e-04 - val_loss: 7.1976e-04\n",
      "Epoch 1192/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.3792e-04 - val_loss: 7.0428e-04\n",
      "Epoch 1193/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.4877e-04 - val_loss: 7.6060e-04\n",
      "Epoch 1194/2000\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 2.7093e-04 - val_loss: 6.4101e-04\n",
      "Epoch 1195/2000\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 2.5223e-04 - val_loss: 6.3207e-04\n",
      "Epoch 1196/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.3149e-04 - val_loss: 7.7270e-04\n",
      "Epoch 1197/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.3526e-04 - val_loss: 5.7598e-04\n",
      "Epoch 1198/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.2895e-04 - val_loss: 7.4544e-04\n",
      "Epoch 1199/2000\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 2.2193e-04 - val_loss: 7.4126e-04\n",
      "Epoch 1200/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 2s 523us/step - loss: 2.3043e-04 - val_loss: 7.2080e-04\n",
      "Epoch 1201/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.2587e-04 - val_loss: 8.0240e-04\n",
      "Epoch 1202/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.2522e-04 - val_loss: 8.3696e-04\n",
      "Epoch 1203/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.2667e-04 - val_loss: 7.9175e-04\n",
      "Epoch 1204/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.3297e-04 - val_loss: 8.4019e-04\n",
      "Epoch 1205/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.2583e-04 - val_loss: 7.4142e-04\n",
      "Epoch 1206/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.1624e-04 - val_loss: 8.7246e-04\n",
      "Epoch 1207/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.2842e-04 - val_loss: 7.3974e-04\n",
      "Epoch 1208/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.4010e-04 - val_loss: 8.0666e-04\n",
      "Epoch 1209/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 2.3742e-04 - val_loss: 6.7961e-04\n",
      "Epoch 1210/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.4214e-04 - val_loss: 9.4898e-04\n",
      "Epoch 1211/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.4683e-04 - val_loss: 9.0002e-04\n",
      "Epoch 1212/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.2358e-04 - val_loss: 6.7949e-04\n",
      "Epoch 1213/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.2316e-04 - val_loss: 8.4921e-04\n",
      "Epoch 1214/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.1136e-04 - val_loss: 8.4173e-04\n",
      "Epoch 1215/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.2370e-04 - val_loss: 8.3928e-04\n",
      "Epoch 1216/2000\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 2.2032e-04 - val_loss: 8.3324e-04\n",
      "Epoch 1217/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.2306e-04 - val_loss: 8.9472e-04\n",
      "Epoch 1218/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.2427e-04 - val_loss: 6.3057e-04\n",
      "Epoch 1219/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.3008e-04 - val_loss: 8.9774e-04\n",
      "Epoch 1220/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.2561e-04 - val_loss: 8.1091e-04\n",
      "Epoch 1221/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.2533e-04 - val_loss: 7.4383e-04\n",
      "Epoch 1222/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.2413e-04 - val_loss: 7.1201e-04\n",
      "Epoch 1223/2000\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 2.2557e-04 - val_loss: 8.4195e-04\n",
      "Epoch 1224/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.2473e-04 - val_loss: 6.4805e-04\n",
      "Epoch 1225/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 2.3765e-04 - val_loss: 6.9995e-04\n",
      "Epoch 1226/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.2447e-04 - val_loss: 9.4234e-04\n",
      "Epoch 1227/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.1190e-04 - val_loss: 7.3318e-04\n",
      "Epoch 1228/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.1278e-04 - val_loss: 9.1662e-04\n",
      "Epoch 1229/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.1252e-04 - val_loss: 7.4980e-04\n",
      "Epoch 1230/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 2.2196e-04 - val_loss: 7.0695e-04\n",
      "Epoch 1231/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 2.1998e-04 - val_loss: 9.8662e-04\n",
      "Epoch 1232/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.3115e-04 - val_loss: 9.9927e-04\n",
      "Epoch 1233/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.3049e-04 - val_loss: 8.7158e-04\n",
      "Epoch 1234/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.2731e-04 - val_loss: 8.3647e-04\n",
      "Epoch 1235/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 2.1633e-04 - val_loss: 7.5593e-04\n",
      "Epoch 1236/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.1604e-04 - val_loss: 8.3712e-04\n",
      "Epoch 1237/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.3425e-04 - val_loss: 6.5211e-04\n",
      "Epoch 1238/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.1938e-04 - val_loss: 8.2932e-04\n",
      "Epoch 1239/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 2.3559e-04 - val_loss: 9.7640e-04\n",
      "Epoch 1240/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 3.0307e-04 - val_loss: 6.2393e-04\n",
      "Epoch 1241/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.4327e-04 - val_loss: 8.4979e-04\n",
      "Epoch 1242/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.2897e-04 - val_loss: 6.5589e-04\n",
      "Epoch 1243/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.1852e-04 - val_loss: 8.1120e-04\n",
      "Epoch 1244/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.0661e-04 - val_loss: 7.7353e-04\n",
      "Epoch 1245/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.0739e-04 - val_loss: 9.2217e-04\n",
      "Epoch 1246/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.2726e-04 - val_loss: 8.7388e-04\n",
      "Epoch 1247/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.4744e-04 - val_loss: 0.0014\n",
      "Epoch 1248/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 3.0574e-04 - val_loss: 8.0919e-04\n",
      "Epoch 1249/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.7362e-04 - val_loss: 6.6756e-04\n",
      "Epoch 1250/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.5404e-04 - val_loss: 6.6478e-04\n",
      "Epoch 1251/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.2911e-04 - val_loss: 7.5268e-04\n",
      "Epoch 1252/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.2092e-04 - val_loss: 9.2239e-04\n",
      "Epoch 1253/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.2385e-04 - val_loss: 7.8926e-04\n",
      "Epoch 1254/2000\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 2.2128e-04 - val_loss: 7.5019e-04\n",
      "Epoch 1255/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.2504e-04 - val_loss: 7.4531e-04\n",
      "Epoch 1256/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 2.2760e-04 - val_loss: 8.5772e-04\n",
      "Epoch 1257/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 2.1347e-04 - val_loss: 0.0010\n",
      "Epoch 1258/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 2.3344e-04 - val_loss: 7.6965e-04\n",
      "Epoch 1259/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.2107e-04 - val_loss: 7.9653e-04\n",
      "Epoch 1260/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 2.2307e-04 - val_loss: 8.3201e-04\n",
      "Epoch 1261/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.1699e-04 - val_loss: 7.0761e-04\n",
      "Epoch 1262/2000\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 2.0789e-04 - val_loss: 7.3581e-04\n",
      "Epoch 1263/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.1639e-04 - val_loss: 8.9211e-04\n",
      "Epoch 1264/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.0728e-04 - val_loss: 9.5585e-04\n",
      "Epoch 1265/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.1004e-04 - val_loss: 8.0679e-04\n",
      "Epoch 1266/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.1099e-04 - val_loss: 8.0548e-04\n",
      "Epoch 1267/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 2.1085e-04 - val_loss: 9.2238e-04\n",
      "Epoch 1268/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 2.1619e-04 - val_loss: 8.5732e-04\n",
      "Epoch 1269/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.1952e-04 - val_loss: 7.9542e-04\n",
      "Epoch 1270/2000\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 2.2002e-04 - val_loss: 7.7379e-04\n",
      "Epoch 1271/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.1970e-04 - val_loss: 7.7165e-04\n",
      "Epoch 1272/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.1665e-04 - val_loss: 0.0011\n",
      "Epoch 1273/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 2.0981e-04 - val_loss: 9.0267e-04\n",
      "Epoch 1274/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.0672e-04 - val_loss: 9.3631e-04\n",
      "Epoch 1275/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.1771e-04 - val_loss: 0.0010\n",
      "Epoch 1276/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.3742e-04 - val_loss: 9.0500e-04\n",
      "Epoch 1277/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 2.3442e-04 - val_loss: 0.0010\n",
      "Epoch 1278/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.2887e-04 - val_loss: 9.1624e-04\n",
      "Epoch 1279/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.1171e-04 - val_loss: 9.0590e-04\n",
      "Epoch 1280/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.1575e-04 - val_loss: 8.5522e-04\n",
      "Epoch 1281/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 2.2460e-04 - val_loss: 9.9532e-04\n",
      "Epoch 1282/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.1430e-04 - val_loss: 8.9628e-04\n",
      "Epoch 1283/2000\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 2.1472e-04 - val_loss: 9.1568e-04\n",
      "Epoch 1284/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.0213e-04 - val_loss: 9.1901e-04\n",
      "Epoch 1285/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 2.1752e-04 - val_loss: 0.0012\n",
      "Epoch 1286/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 2.0956e-04 - val_loss: 0.0011\n",
      "Epoch 1287/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.0868e-04 - val_loss: 0.0011\n",
      "Epoch 1288/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.9526e-04 - val_loss: 0.0010\n",
      "Epoch 1289/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.0043e-04 - val_loss: 9.0984e-04\n",
      "Epoch 1290/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 1.9767e-04 - val_loss: 9.4221e-04\n",
      "Epoch 1291/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.0307e-04 - val_loss: 0.0010\n",
      "Epoch 1292/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.1658e-04 - val_loss: 0.0011\n",
      "Epoch 1293/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 2.2700e-04 - val_loss: 9.3524e-04\n",
      "Epoch 1294/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.3952e-04 - val_loss: 0.0010\n",
      "Epoch 1295/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.5810e-04 - val_loss: 9.5113e-04\n",
      "Epoch 1296/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 2.2882e-04 - val_loss: 9.1929e-04\n",
      "Epoch 1297/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.2868e-04 - val_loss: 9.7153e-04\n",
      "Epoch 1298/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.0587e-04 - val_loss: 0.0010\n",
      "Epoch 1299/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 2.0911e-04 - val_loss: 9.9929e-04\n",
      "Epoch 1300/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 2.0379e-04 - val_loss: 7.7382e-04\n",
      "Epoch 1301/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 2.1041e-04 - val_loss: 9.0352e-04\n",
      "Epoch 1302/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.2464e-04 - val_loss: 0.0010\n",
      "Epoch 1303/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.2803e-04 - val_loss: 9.6800e-04\n",
      "Epoch 1304/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.0687e-04 - val_loss: 0.0010\n",
      "Epoch 1305/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.0168e-04 - val_loss: 8.7153e-04\n",
      "Epoch 1306/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.9392e-04 - val_loss: 0.0011\n",
      "Epoch 1307/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 1.8829e-04 - val_loss: 0.0012\n",
      "Epoch 1308/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 1.9833e-04 - val_loss: 0.0010\n",
      "Epoch 1309/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.1690e-04 - val_loss: 8.7190e-04\n",
      "Epoch 1310/2000\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 2.0248e-04 - val_loss: 0.0012\n",
      "Epoch 1311/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 1.9229e-04 - val_loss: 0.0011\n",
      "Epoch 1312/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.9862e-04 - val_loss: 0.0011\n",
      "Epoch 1313/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 2.1389e-04 - val_loss: 0.0011\n",
      "Epoch 1314/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.9397e-04 - val_loss: 9.6940e-04\n",
      "Epoch 1315/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 1.9526e-04 - val_loss: 0.0012\n",
      "Epoch 1316/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 1.9624e-04 - val_loss: 0.0012\n",
      "Epoch 1317/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.3652e-04 - val_loss: 0.0011\n",
      "Epoch 1318/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 2.8410e-04 - val_loss: 0.0012\n",
      "Epoch 1319/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.4140e-04 - val_loss: 9.5027e-04\n",
      "Epoch 1320/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.1120e-04 - val_loss: 0.0010\n",
      "Epoch 1321/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.0011e-04 - val_loss: 0.0012\n",
      "Epoch 1322/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.0682e-04 - val_loss: 0.0012\n",
      "Epoch 1323/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.9700e-04 - val_loss: 0.0013\n",
      "Epoch 1324/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 1.9553e-04 - val_loss: 0.0012\n",
      "Epoch 1325/2000\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 1.9404e-04 - val_loss: 0.0012\n",
      "Epoch 1326/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 1.9438e-04 - val_loss: 0.0013\n",
      "Epoch 1327/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.9669e-04 - val_loss: 0.0013\n",
      "Epoch 1328/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.9643e-04 - val_loss: 0.0012\n",
      "Epoch 1329/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.9168e-04 - val_loss: 0.0013\n",
      "Epoch 1330/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.0041e-04 - val_loss: 0.0013\n",
      "Epoch 1331/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.2256e-04 - val_loss: 0.0010\n",
      "Epoch 1332/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.1195e-04 - val_loss: 0.0013\n",
      "Epoch 1333/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 2.0587e-04 - val_loss: 0.0013\n",
      "Epoch 1334/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 1.9495e-04 - val_loss: 0.0011\n",
      "Epoch 1335/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.9347e-04 - val_loss: 0.0012\n",
      "Epoch 1336/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 1.8204e-04 - val_loss: 0.0012\n",
      "Epoch 1337/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.8475e-04 - val_loss: 0.0015\n",
      "Epoch 1338/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.8979e-04 - val_loss: 0.0013\n",
      "Epoch 1339/2000\n",
      "3977/3977 [==============================] - 2s 528us/step - loss: 1.8813e-04 - val_loss: 9.9850e-04\n",
      "Epoch 1340/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 1.9924e-04 - val_loss: 0.0011\n",
      "Epoch 1341/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.0123e-04 - val_loss: 0.0012\n",
      "Epoch 1342/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.9743e-04 - val_loss: 0.0012\n",
      "Epoch 1343/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 1.8356e-04 - val_loss: 0.0011\n",
      "Epoch 1344/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.8696e-04 - val_loss: 0.0012\n",
      "Epoch 1345/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.8744e-04 - val_loss: 0.0012\n",
      "Epoch 1346/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.8275e-04 - val_loss: 0.0014\n",
      "Epoch 1347/2000\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 1.8981e-04 - val_loss: 0.0013\n",
      "Epoch 1348/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.9402e-04 - val_loss: 0.0012\n",
      "Epoch 1349/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 1.9761e-04 - val_loss: 0.0011\n",
      "Epoch 1350/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.0509e-04 - val_loss: 0.0012\n",
      "Epoch 1351/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.1927e-04 - val_loss: 0.0012\n",
      "Epoch 1352/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 1.9586e-04 - val_loss: 0.0011\n",
      "Epoch 1353/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 1.9936e-04 - val_loss: 0.0013\n",
      "Epoch 1354/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 2.1360e-04 - val_loss: 0.0012\n",
      "Epoch 1355/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.0827e-04 - val_loss: 0.0011\n",
      "Epoch 1356/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.0234e-04 - val_loss: 0.0010\n",
      "Epoch 1357/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 1.8941e-04 - val_loss: 0.0012\n",
      "Epoch 1358/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.9492e-04 - val_loss: 0.0012\n",
      "Epoch 1359/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.0139e-04 - val_loss: 0.0012\n",
      "Epoch 1360/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 2.2820e-04 - val_loss: 0.0011\n",
      "Epoch 1361/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.0331e-04 - val_loss: 0.0012\n",
      "Epoch 1362/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 2.0210e-04 - val_loss: 0.0012\n",
      "Epoch 1363/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.0802e-04 - val_loss: 0.0013\n",
      "Epoch 1364/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.9755e-04 - val_loss: 0.0012\n",
      "Epoch 1365/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.9858e-04 - val_loss: 0.0013\n",
      "Epoch 1366/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 1.9436e-04 - val_loss: 0.0012\n",
      "Epoch 1367/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 1.8379e-04 - val_loss: 0.0012\n",
      "Epoch 1368/2000\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 1.8755e-04 - val_loss: 0.0012\n",
      "Epoch 1369/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.8379e-04 - val_loss: 0.0011\n",
      "Epoch 1370/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 1.8792e-04 - val_loss: 0.0015\n",
      "Epoch 1371/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.8034e-04 - val_loss: 0.0011\n",
      "Epoch 1372/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 1.7574e-04 - val_loss: 0.0010\n",
      "Epoch 1373/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 1.8457e-04 - val_loss: 0.0013\n",
      "Epoch 1374/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 1.8313e-04 - val_loss: 0.0013\n",
      "Epoch 1375/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 1.8294e-04 - val_loss: 0.0013\n",
      "Epoch 1376/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 1.8523e-04 - val_loss: 0.0012\n",
      "Epoch 1377/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 1.9065e-04 - val_loss: 0.0013\n",
      "Epoch 1378/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 1.9140e-04 - val_loss: 0.0012\n",
      "Epoch 1379/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 1.9671e-04 - val_loss: 0.0016\n",
      "Epoch 1380/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 2.1223e-04 - val_loss: 0.0014\n",
      "Epoch 1381/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 2.2504e-04 - val_loss: 0.0013\n",
      "Epoch 1382/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 1.9743e-04 - val_loss: 0.0011\n",
      "Epoch 1383/2000\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 1.8208e-04 - val_loss: 9.9572e-04\n",
      "Epoch 1384/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.8592e-04 - val_loss: 0.0012\n",
      "Epoch 1385/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 1.9210e-04 - val_loss: 0.0012\n",
      "Epoch 1386/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 1.8734e-04 - val_loss: 0.0012\n",
      "Epoch 1387/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.9457e-04 - val_loss: 0.0011\n",
      "Epoch 1388/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.8653e-04 - val_loss: 0.0012\n",
      "Epoch 1389/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.8400e-04 - val_loss: 0.0012\n",
      "Epoch 1390/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.8394e-04 - val_loss: 0.0012\n",
      "Epoch 1391/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 1.7997e-04 - val_loss: 0.0013\n",
      "Epoch 1392/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 1.6680e-04 - val_loss: 0.0012\n",
      "Epoch 1393/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 1.8121e-04 - val_loss: 0.0012\n",
      "Epoch 1394/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 1.7567e-04 - val_loss: 0.0012\n",
      "Epoch 1395/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 1.7110e-04 - val_loss: 0.0014\n",
      "Epoch 1396/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.7560e-04 - val_loss: 0.0012\n",
      "Epoch 1397/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 1.7624e-04 - val_loss: 0.0013\n",
      "Epoch 1398/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 1.7732e-04 - val_loss: 0.0011\n",
      "Epoch 1399/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.7999e-04 - val_loss: 0.0013\n",
      "Epoch 1400/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 1.7972e-04 - val_loss: 0.0013\n",
      "Epoch 1401/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 1.9867e-04 - val_loss: 0.0015\n",
      "Epoch 1402/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 2.0811e-04 - val_loss: 0.0013\n",
      "Epoch 1403/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.8999e-04 - val_loss: 0.0014\n",
      "Epoch 1404/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.7276e-04 - val_loss: 0.0014\n",
      "Epoch 1405/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.6784e-04 - val_loss: 0.0014\n",
      "Epoch 1406/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 1.7467e-04 - val_loss: 0.0015\n",
      "Epoch 1407/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.8078e-04 - val_loss: 0.0016\n",
      "Epoch 1408/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.8768e-04 - val_loss: 0.0013\n",
      "Epoch 1409/2000\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 1.7899e-04 - val_loss: 0.0012\n",
      "Epoch 1410/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.7174e-04 - val_loss: 0.0012\n",
      "Epoch 1411/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 1.7949e-04 - val_loss: 0.0012\n",
      "Epoch 1412/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 1.9300e-04 - val_loss: 0.0015\n",
      "Epoch 1413/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 1.7754e-04 - val_loss: 0.0013\n",
      "Epoch 1414/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.7771e-04 - val_loss: 0.0014\n",
      "Epoch 1415/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.8387e-04 - val_loss: 0.0014\n",
      "Epoch 1416/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 1.8296e-04 - val_loss: 0.0012\n",
      "Epoch 1417/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.7103e-04 - val_loss: 0.0014\n",
      "Epoch 1418/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.7427e-04 - val_loss: 0.0014\n",
      "Epoch 1419/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.7838e-04 - val_loss: 0.0013\n",
      "Epoch 1420/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.6469e-04 - val_loss: 0.0014\n",
      "Epoch 1421/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.6607e-04 - val_loss: 0.0014\n",
      "Epoch 1422/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.6087e-04 - val_loss: 0.0015\n",
      "Epoch 1423/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.5945e-04 - val_loss: 0.0013\n",
      "Epoch 1424/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 1.5911e-04 - val_loss: 0.0014\n",
      "Epoch 1425/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.6194e-04 - val_loss: 0.0015\n",
      "Epoch 1426/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.5763e-04 - val_loss: 0.0015\n",
      "Epoch 1427/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 1.6330e-04 - val_loss: 0.0014\n",
      "Epoch 1428/2000\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 1.6359e-04 - val_loss: 0.0014\n",
      "Epoch 1429/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.6904e-04 - val_loss: 0.0014\n",
      "Epoch 1430/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 1.6658e-04 - val_loss: 0.0015\n",
      "Epoch 1431/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.5379e-04 - val_loss: 0.0014\n",
      "Epoch 1432/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 1.5599e-04 - val_loss: 0.0013\n",
      "Epoch 1433/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.7414e-04 - val_loss: 0.0016\n",
      "Epoch 1434/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.6651e-04 - val_loss: 0.0014\n",
      "Epoch 1435/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.6475e-04 - val_loss: 0.0017\n",
      "Epoch 1436/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 1.7492e-04 - val_loss: 0.0014\n",
      "Epoch 1437/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 1.8232e-04 - val_loss: 0.0013\n",
      "Epoch 1438/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.6644e-04 - val_loss: 0.0016\n",
      "Epoch 1439/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 1.6350e-04 - val_loss: 0.0012\n",
      "Epoch 1440/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 1.8481e-04 - val_loss: 0.0016\n",
      "Epoch 1441/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 1.7610e-04 - val_loss: 0.0013\n",
      "Epoch 1442/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 1.6193e-04 - val_loss: 0.0013\n",
      "Epoch 1443/2000\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 1.6088e-04 - val_loss: 0.0014\n",
      "Epoch 1444/2000\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 1.5854e-04 - val_loss: 0.0016\n",
      "Epoch 1445/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.5845e-04 - val_loss: 0.0015\n",
      "Epoch 1446/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.5634e-04 - val_loss: 0.0015\n",
      "Epoch 1447/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 1.5895e-04 - val_loss: 0.0015\n",
      "Epoch 1448/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.6140e-04 - val_loss: 0.0017\n",
      "Epoch 1449/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 1.6233e-04 - val_loss: 0.0014\n",
      "Epoch 1450/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 1.6964e-04 - val_loss: 0.0015\n",
      "Epoch 1451/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.6885e-04 - val_loss: 0.0014\n",
      "Epoch 1452/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.6297e-04 - val_loss: 0.0014\n",
      "Epoch 1453/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 1.6352e-04 - val_loss: 0.0016\n",
      "Epoch 1454/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.6199e-04 - val_loss: 0.0018\n",
      "Epoch 1455/2000\n",
      "3977/3977 [==============================] - 2s 529us/step - loss: 1.5313e-04 - val_loss: 0.0015\n",
      "Epoch 1456/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.4810e-04 - val_loss: 0.0016\n",
      "Epoch 1457/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.5072e-04 - val_loss: 0.0015\n",
      "Epoch 1458/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.5182e-04 - val_loss: 0.0016\n",
      "Epoch 1459/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.5097e-04 - val_loss: 0.0016\n",
      "Epoch 1460/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 1.5086e-04 - val_loss: 0.0015\n",
      "Epoch 1461/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.4865e-04 - val_loss: 0.0018\n",
      "Epoch 1462/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 1.5511e-04 - val_loss: 0.0014\n",
      "Epoch 1463/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 1.5920e-04 - val_loss: 0.0016\n",
      "Epoch 1464/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.7123e-04 - val_loss: 0.0015\n",
      "Epoch 1465/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.6066e-04 - val_loss: 0.0014\n",
      "Epoch 1466/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.7884e-04 - val_loss: 0.0018\n",
      "Epoch 1467/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.7617e-04 - val_loss: 0.0015\n",
      "Epoch 1468/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 1.6401e-04 - val_loss: 0.0016\n",
      "Epoch 1469/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 1.5695e-04 - val_loss: 0.0014\n",
      "Epoch 1470/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 1.7759e-04 - val_loss: 0.0017\n",
      "Epoch 1471/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.7629e-04 - val_loss: 0.0016\n",
      "Epoch 1472/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 1.6344e-04 - val_loss: 0.0014\n",
      "Epoch 1473/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 1.6266e-04 - val_loss: 0.0016\n",
      "Epoch 1474/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.5072e-04 - val_loss: 0.0016\n",
      "Epoch 1475/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 1.4574e-04 - val_loss: 0.0016\n",
      "Epoch 1476/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 1.4638e-04 - val_loss: 0.0015\n",
      "Epoch 1477/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 1.6901e-04 - val_loss: 0.0015\n",
      "Epoch 1478/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 1.5740e-04 - val_loss: 0.0016\n",
      "Epoch 1479/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.6654e-04 - val_loss: 0.0015\n",
      "Epoch 1480/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 1.5142e-04 - val_loss: 0.0014\n",
      "Epoch 1481/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 1.5385e-04 - val_loss: 0.0015\n",
      "Epoch 1482/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.4807e-04 - val_loss: 0.0015\n",
      "Epoch 1483/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.4283e-04 - val_loss: 0.0015\n",
      "Epoch 1484/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 1.4771e-04 - val_loss: 0.0016\n",
      "Epoch 1485/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.4264e-04 - val_loss: 0.0017\n",
      "Epoch 1486/2000\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 1.4893e-04 - val_loss: 0.0017\n",
      "Epoch 1487/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 1.5061e-04 - val_loss: 0.0016\n",
      "Epoch 1488/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.5315e-04 - val_loss: 0.0016\n",
      "Epoch 1489/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.6136e-04 - val_loss: 0.0015\n",
      "Epoch 1490/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 1.7019e-04 - val_loss: 0.0017\n",
      "Epoch 1491/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.6602e-04 - val_loss: 0.0016\n",
      "Epoch 1492/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 1.4822e-04 - val_loss: 0.0014\n",
      "Epoch 1493/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 1.4695e-04 - val_loss: 0.0015\n",
      "Epoch 1494/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 1.4764e-04 - val_loss: 0.0016\n",
      "Epoch 1495/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 1.5154e-04 - val_loss: 0.0014\n",
      "Epoch 1496/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 1.4548e-04 - val_loss: 0.0017\n",
      "Epoch 1497/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.4633e-04 - val_loss: 0.0018\n",
      "Epoch 1498/2000\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 1.5722e-04 - val_loss: 0.0015\n",
      "Epoch 1499/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.4890e-04 - val_loss: 0.0018\n",
      "Epoch 1500/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 1.4771e-04 - val_loss: 0.0017\n",
      "Epoch 1501/2000\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 1.3928e-04 - val_loss: 0.0016\n",
      "Epoch 1502/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 1.4798e-04 - val_loss: 0.0016\n",
      "Epoch 1503/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 1.6516e-04 - val_loss: 0.0016\n",
      "Epoch 1504/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 1.6055e-04 - val_loss: 0.0016\n",
      "Epoch 1505/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.5652e-04 - val_loss: 0.0017\n",
      "Epoch 1506/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.5417e-04 - val_loss: 0.0016\n",
      "Epoch 1507/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 1.7260e-04 - val_loss: 0.0017\n",
      "Epoch 1508/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.7987e-04 - val_loss: 0.0014\n",
      "Epoch 1509/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.4891e-04 - val_loss: 0.0017\n",
      "Epoch 1510/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.4655e-04 - val_loss: 0.0015\n",
      "Epoch 1511/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 1.5258e-04 - val_loss: 0.0015\n",
      "Epoch 1512/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.4754e-04 - val_loss: 0.0017\n",
      "Epoch 1513/2000\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 1.5227e-04 - val_loss: 0.0017\n",
      "Epoch 1514/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 1.4408e-04 - val_loss: 0.0017\n",
      "Epoch 1515/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 1.4716e-04 - val_loss: 0.0016\n",
      "Epoch 1516/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.5074e-04 - val_loss: 0.0019\n",
      "Epoch 1517/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.5259e-04 - val_loss: 0.0018\n",
      "Epoch 1518/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 1.4506e-04 - val_loss: 0.0018\n",
      "Epoch 1519/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.3275e-04 - val_loss: 0.0018\n",
      "Epoch 1520/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 1.2896e-04 - val_loss: 0.0017\n",
      "Epoch 1521/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 1.3996e-04 - val_loss: 0.0019\n",
      "Epoch 1522/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 1.4198e-04 - val_loss: 0.0018\n",
      "Epoch 1523/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.5314e-04 - val_loss: 0.0019\n",
      "Epoch 1524/2000\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 1.4140e-04 - val_loss: 0.0017\n",
      "Epoch 1525/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.3416e-04 - val_loss: 0.0017\n",
      "Epoch 1526/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 1.3509e-04 - val_loss: 0.0018\n",
      "Epoch 1527/2000\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 1.4659e-04 - val_loss: 0.0019\n",
      "Epoch 1528/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.5543e-04 - val_loss: 0.0017\n",
      "Epoch 1529/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 1.5560e-04 - val_loss: 0.0017\n",
      "Epoch 1530/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 1.4979e-04 - val_loss: 0.0019\n",
      "Epoch 1531/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.5669e-04 - val_loss: 0.0016\n",
      "Epoch 1532/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 1.6927e-04 - val_loss: 0.0018\n",
      "Epoch 1533/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 1.5833e-04 - val_loss: 0.0016\n",
      "Epoch 1534/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 1.5465e-04 - val_loss: 0.0017\n",
      "Epoch 1535/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.4782e-04 - val_loss: 0.0017\n",
      "Epoch 1536/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 1.3805e-04 - val_loss: 0.0018\n",
      "Epoch 1537/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 1.3214e-04 - val_loss: 0.0018\n",
      "Epoch 1538/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.3699e-04 - val_loss: 0.0017\n",
      "Epoch 1539/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 1.3613e-04 - val_loss: 0.0018\n",
      "Epoch 1540/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 1.4209e-04 - val_loss: 0.0018\n",
      "Epoch 1541/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.3263e-04 - val_loss: 0.0017\n",
      "Epoch 1542/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 1.2756e-04 - val_loss: 0.0020\n",
      "Epoch 1543/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.3057e-04 - val_loss: 0.0018\n",
      "Epoch 1544/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 1.3498e-04 - val_loss: 0.0018\n",
      "Epoch 1545/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.2872e-04 - val_loss: 0.0018\n",
      "Epoch 1546/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.3694e-04 - val_loss: 0.0020\n",
      "Epoch 1547/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 1.3186e-04 - val_loss: 0.0020\n",
      "Epoch 1548/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 1.2418e-04 - val_loss: 0.0018\n",
      "Epoch 1549/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.3654e-04 - val_loss: 0.0019\n",
      "Epoch 1550/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.3644e-04 - val_loss: 0.0022\n",
      "Epoch 1551/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.4171e-04 - val_loss: 0.0019\n",
      "Epoch 1552/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 1.3652e-04 - val_loss: 0.0019\n",
      "Epoch 1553/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.3029e-04 - val_loss: 0.0023\n",
      "Epoch 1554/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.2923e-04 - val_loss: 0.0019\n",
      "Epoch 1555/2000\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 1.3607e-04 - val_loss: 0.0018\n",
      "Epoch 1556/2000\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 1.2761e-04 - val_loss: 0.0021\n",
      "Epoch 1557/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 1.2796e-04 - val_loss: 0.0019\n",
      "Epoch 1558/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 1.3044e-04 - val_loss: 0.0019\n",
      "Epoch 1559/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 1.2179e-04 - val_loss: 0.0019\n",
      "Epoch 1560/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 1.4496e-04 - val_loss: 0.0025\n",
      "Epoch 1561/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.5661e-04 - val_loss: 0.0020\n",
      "Epoch 1562/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 1.5151e-04 - val_loss: 0.0024\n",
      "Epoch 1563/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 1.6258e-04 - val_loss: 0.0020\n",
      "Epoch 1564/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.4800e-04 - val_loss: 0.0018\n",
      "Epoch 1565/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.4130e-04 - val_loss: 0.0017\n",
      "Epoch 1566/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.3121e-04 - val_loss: 0.0018\n",
      "Epoch 1567/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 1.2609e-04 - val_loss: 0.0017\n",
      "Epoch 1568/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 1.2186e-04 - val_loss: 0.0019\n",
      "Epoch 1569/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 1.2967e-04 - val_loss: 0.0021\n",
      "Epoch 1570/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 1.3486e-04 - val_loss: 0.0019\n",
      "Epoch 1571/2000\n",
      "3977/3977 [==============================] - 2s 529us/step - loss: 1.2221e-04 - val_loss: 0.0018\n",
      "Epoch 1572/2000\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 1.3251e-04 - val_loss: 0.0018\n",
      "Epoch 1573/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 1.3377e-04 - val_loss: 0.0019\n",
      "Epoch 1574/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 1.2376e-04 - val_loss: 0.0021\n",
      "Epoch 1575/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 1.2262e-04 - val_loss: 0.0020\n",
      "Epoch 1576/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.2666e-04 - val_loss: 0.0020\n",
      "Epoch 1577/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.3024e-04 - val_loss: 0.0020\n",
      "Epoch 1578/2000\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 1.3225e-04 - val_loss: 0.0020\n",
      "Epoch 1579/2000\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 1.2326e-04 - val_loss: 0.0018\n",
      "Epoch 1580/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.3343e-04 - val_loss: 0.0022\n",
      "Epoch 1581/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.3149e-04 - val_loss: 0.0019\n",
      "Epoch 1582/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 1.2949e-04 - val_loss: 0.0019\n",
      "Epoch 1583/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 1.3382e-04 - val_loss: 0.0018\n",
      "Epoch 1584/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 1.4345e-04 - val_loss: 0.0017\n",
      "Epoch 1585/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 1.4390e-04 - val_loss: 0.0020\n",
      "Epoch 1586/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 1.4292e-04 - val_loss: 0.0019\n",
      "Epoch 1587/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 1.2438e-04 - val_loss: 0.0018\n",
      "Epoch 1588/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.2235e-04 - val_loss: 0.0016\n",
      "Epoch 1589/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 1.2785e-04 - val_loss: 0.0018\n",
      "Epoch 1590/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.2246e-04 - val_loss: 0.0018\n",
      "Epoch 1591/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 1.2321e-04 - val_loss: 0.0020\n",
      "Epoch 1592/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 1.2057e-04 - val_loss: 0.0017\n",
      "Epoch 1593/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 1.1847e-04 - val_loss: 0.0020\n",
      "Epoch 1594/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 1.1622e-04 - val_loss: 0.0021\n",
      "Epoch 1595/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.1846e-04 - val_loss: 0.0018\n",
      "Epoch 1596/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.3300e-04 - val_loss: 0.0021\n",
      "Epoch 1597/2000\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 1.3180e-04 - val_loss: 0.0017\n",
      "Epoch 1598/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 1.2773e-04 - val_loss: 0.0022\n",
      "Epoch 1599/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.2526e-04 - val_loss: 0.0018\n",
      "Epoch 1600/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 1.2589e-04 - val_loss: 0.0019\n",
      "Epoch 1601/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.2968e-04 - val_loss: 0.0019\n",
      "Epoch 1602/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.3359e-04 - val_loss: 0.0021\n",
      "Epoch 1603/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 1.4125e-04 - val_loss: 0.0018\n",
      "Epoch 1604/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.4216e-04 - val_loss: 0.0020\n",
      "Epoch 1605/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.4241e-04 - val_loss: 0.0017\n",
      "Epoch 1606/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 1.4339e-04 - val_loss: 0.0019\n",
      "Epoch 1607/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 1.2391e-04 - val_loss: 0.0018\n",
      "Epoch 1608/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 1.2035e-04 - val_loss: 0.0018\n",
      "Epoch 1609/2000\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 1.1583e-04 - val_loss: 0.0020\n",
      "Epoch 1610/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 1.3876e-04 - val_loss: 0.0019\n",
      "Epoch 1611/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 1.3556e-04 - val_loss: 0.0019\n",
      "Epoch 1612/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.3430e-04 - val_loss: 0.0020\n",
      "Epoch 1613/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.2962e-04 - val_loss: 0.0019\n",
      "Epoch 1614/2000\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 1.1649e-04 - val_loss: 0.0020\n",
      "Epoch 1615/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 1.1330e-04 - val_loss: 0.0021\n",
      "Epoch 1616/2000\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 1.1593e-04 - val_loss: 0.0020\n",
      "Epoch 1617/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 1.2961e-04 - val_loss: 0.0021\n",
      "Epoch 1618/2000\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 1.2311e-04 - val_loss: 0.0020\n",
      "Epoch 1619/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.0759e-04 - val_loss: 0.0018\n",
      "Epoch 1620/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.1239e-04 - val_loss: 0.0021\n",
      "Epoch 1621/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.1709e-04 - val_loss: 0.0018\n",
      "Epoch 1622/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.2421e-04 - val_loss: 0.0019\n",
      "Epoch 1623/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.1343e-04 - val_loss: 0.0022\n",
      "Epoch 1624/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.1796e-04 - val_loss: 0.0021\n",
      "Epoch 1625/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 1.2105e-04 - val_loss: 0.0023\n",
      "Epoch 1626/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 1.2485e-04 - val_loss: 0.0022\n",
      "Epoch 1627/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 1.1402e-04 - val_loss: 0.0020\n",
      "Epoch 1628/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.1406e-04 - val_loss: 0.0020\n",
      "Epoch 1629/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.1906e-04 - val_loss: 0.0022\n",
      "Epoch 1630/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 1.1815e-04 - val_loss: 0.0020\n",
      "Epoch 1631/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 1.1435e-04 - val_loss: 0.0021\n",
      "Epoch 1632/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 1.2205e-04 - val_loss: 0.0021\n",
      "Epoch 1633/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.2236e-04 - val_loss: 0.0022\n",
      "Epoch 1634/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.2011e-04 - val_loss: 0.0018\n",
      "Epoch 1635/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.2111e-04 - val_loss: 0.0022\n",
      "Epoch 1636/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.1802e-04 - val_loss: 0.0023\n",
      "Epoch 1637/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.1458e-04 - val_loss: 0.0020\n",
      "Epoch 1638/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.0932e-04 - val_loss: 0.0021\n",
      "Epoch 1639/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.1312e-04 - val_loss: 0.0022\n",
      "Epoch 1640/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 1.1364e-04 - val_loss: 0.0020\n",
      "Epoch 1641/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 1.0896e-04 - val_loss: 0.0024\n",
      "Epoch 1642/2000\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 1.0353e-04 - val_loss: 0.0020\n",
      "Epoch 1643/2000\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 1.0760e-04 - val_loss: 0.0022\n",
      "Epoch 1644/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 1.1285e-04 - val_loss: 0.0022\n",
      "Epoch 1645/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 1.1721e-04 - val_loss: 0.0021\n",
      "Epoch 1646/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 1.1242e-04 - val_loss: 0.0023\n",
      "Epoch 1647/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.1641e-04 - val_loss: 0.0021\n",
      "Epoch 1648/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 1.2412e-04 - val_loss: 0.0020\n",
      "Epoch 1649/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.1537e-04 - val_loss: 0.0019\n",
      "Epoch 1650/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 1.1303e-04 - val_loss: 0.0023\n",
      "Epoch 1651/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 1.0618e-04 - val_loss: 0.0023\n",
      "Epoch 1652/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.0634e-04 - val_loss: 0.0019\n",
      "Epoch 1653/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.0275e-04 - val_loss: 0.0023\n",
      "Epoch 1654/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.1031e-04 - val_loss: 0.0024\n",
      "Epoch 1655/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 1.0408e-04 - val_loss: 0.0022\n",
      "Epoch 1656/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 1.1381e-04 - val_loss: 0.0021\n",
      "Epoch 1657/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 1.2196e-04 - val_loss: 0.0021\n",
      "Epoch 1658/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.1280e-04 - val_loss: 0.0022\n",
      "Epoch 1659/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.1792e-04 - val_loss: 0.0022\n",
      "Epoch 1660/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 1.2185e-04 - val_loss: 0.0019\n",
      "Epoch 1661/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.3023e-04 - val_loss: 0.0021\n",
      "Epoch 1662/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.2137e-04 - val_loss: 0.0022\n",
      "Epoch 1663/2000\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 1.1026e-04 - val_loss: 0.0021\n",
      "Epoch 1664/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.0397e-04 - val_loss: 0.0020\n",
      "Epoch 1665/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.0557e-04 - val_loss: 0.0022\n",
      "Epoch 1666/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 1.0615e-04 - val_loss: 0.0023\n",
      "Epoch 1667/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.0788e-04 - val_loss: 0.0022\n",
      "Epoch 1668/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 1.1476e-04 - val_loss: 0.0020\n",
      "Epoch 1669/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 1.0858e-04 - val_loss: 0.0022\n",
      "Epoch 1670/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 1.1383e-04 - val_loss: 0.0021\n",
      "Epoch 1671/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 1.1487e-04 - val_loss: 0.0021\n",
      "Epoch 1672/2000\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 1.0991e-04 - val_loss: 0.0023\n",
      "Epoch 1673/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 1.0091e-04 - val_loss: 0.0021\n",
      "Epoch 1674/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 1.0395e-04 - val_loss: 0.0024\n",
      "Epoch 1675/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.1348e-04 - val_loss: 0.0023\n",
      "Epoch 1676/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.0846e-04 - val_loss: 0.0022\n",
      "Epoch 1677/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 1.0334e-04 - val_loss: 0.0022\n",
      "Epoch 1678/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 1.0587e-04 - val_loss: 0.0024\n",
      "Epoch 1679/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.1033e-04 - val_loss: 0.0025\n",
      "Epoch 1680/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.2574e-04 - val_loss: 0.0023\n",
      "Epoch 1681/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 1.1356e-04 - val_loss: 0.0022\n",
      "Epoch 1682/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.1121e-04 - val_loss: 0.0023\n",
      "Epoch 1683/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 1.1314e-04 - val_loss: 0.0020\n",
      "Epoch 1684/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 1.1735e-04 - val_loss: 0.0023\n",
      "Epoch 1685/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.1470e-04 - val_loss: 0.0019\n",
      "Epoch 1686/2000\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 1.0670e-04 - val_loss: 0.0021\n",
      "Epoch 1687/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 9.7899e-05 - val_loss: 0.0022\n",
      "Epoch 1688/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 1.0459e-04 - val_loss: 0.0021\n",
      "Epoch 1689/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.0248e-04 - val_loss: 0.0022\n",
      "Epoch 1690/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.0113e-04 - val_loss: 0.0021\n",
      "Epoch 1691/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 9.9283e-05 - val_loss: 0.0023\n",
      "Epoch 1692/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 9.6980e-05 - val_loss: 0.0023\n",
      "Epoch 1693/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 1.0161e-04 - val_loss: 0.0021\n",
      "Epoch 1694/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 1.0006e-04 - val_loss: 0.0023\n",
      "Epoch 1695/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.0265e-04 - val_loss: 0.0023\n",
      "Epoch 1696/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 9.3868e-05 - val_loss: 0.0023\n",
      "Epoch 1697/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 8.9650e-05 - val_loss: 0.0020\n",
      "Epoch 1698/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 9.3840e-05 - val_loss: 0.0024\n",
      "Epoch 1699/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.0083e-04 - val_loss: 0.0023\n",
      "Epoch 1700/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 9.4798e-05 - val_loss: 0.0021\n",
      "Epoch 1701/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 9.4530e-05 - val_loss: 0.0026\n",
      "Epoch 1702/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 9.1969e-05 - val_loss: 0.0023\n",
      "Epoch 1703/2000\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 9.3945e-05 - val_loss: 0.0022\n",
      "Epoch 1704/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 9.3068e-05 - val_loss: 0.0023\n",
      "Epoch 1705/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 8.9711e-05 - val_loss: 0.0023\n",
      "Epoch 1706/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 9.1688e-05 - val_loss: 0.0021\n",
      "Epoch 1707/2000\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 9.4831e-05 - val_loss: 0.0023\n",
      "Epoch 1708/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.0525e-04 - val_loss: 0.0022\n",
      "Epoch 1709/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 1.0653e-04 - val_loss: 0.0025\n",
      "Epoch 1710/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 1.0340e-04 - val_loss: 0.0021\n",
      "Epoch 1711/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 9.5054e-05 - val_loss: 0.0022\n",
      "Epoch 1712/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 1.0080e-04 - val_loss: 0.0024\n",
      "Epoch 1713/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 1.0130e-04 - val_loss: 0.0021\n",
      "Epoch 1714/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.0140e-04 - val_loss: 0.0022\n",
      "Epoch 1715/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 9.9585e-05 - val_loss: 0.0027\n",
      "Epoch 1716/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.0728e-04 - val_loss: 0.0021\n",
      "Epoch 1717/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 9.7103e-05 - val_loss: 0.0022\n",
      "Epoch 1718/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 1.0444e-04 - val_loss: 0.0022\n",
      "Epoch 1719/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 1.1237e-04 - val_loss: 0.0023\n",
      "Epoch 1720/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.2333e-04 - val_loss: 0.0022\n",
      "Epoch 1721/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.1168e-04 - val_loss: 0.0022\n",
      "Epoch 1722/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 1.1153e-04 - val_loss: 0.0021\n",
      "Epoch 1723/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 1.0928e-04 - val_loss: 0.0023\n",
      "Epoch 1724/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 9.4389e-05 - val_loss: 0.0021\n",
      "Epoch 1725/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 8.8691e-05 - val_loss: 0.0020\n",
      "Epoch 1726/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 8.9665e-05 - val_loss: 0.0024\n",
      "Epoch 1727/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 9.7765e-05 - val_loss: 0.0024\n",
      "Epoch 1728/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 9.8997e-05 - val_loss: 0.0022\n",
      "Epoch 1729/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 9.7784e-05 - val_loss: 0.0023\n",
      "Epoch 1730/2000\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 1.0596e-04 - val_loss: 0.0025\n",
      "Epoch 1731/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.1550e-04 - val_loss: 0.0022\n",
      "Epoch 1732/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 1.0860e-04 - val_loss: 0.0021\n",
      "Epoch 1733/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 1.0005e-04 - val_loss: 0.0021\n",
      "Epoch 1734/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 9.9876e-05 - val_loss: 0.0023\n",
      "Epoch 1735/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.0271e-04 - val_loss: 0.0022\n",
      "Epoch 1736/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.0570e-04 - val_loss: 0.0022\n",
      "Epoch 1737/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 9.6986e-05 - val_loss: 0.0023\n",
      "Epoch 1738/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 9.2305e-05 - val_loss: 0.0019\n",
      "Epoch 1739/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 9.0074e-05 - val_loss: 0.0021\n",
      "Epoch 1740/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 9.1234e-05 - val_loss: 0.0021\n",
      "Epoch 1741/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 8.4467e-05 - val_loss: 0.0021\n",
      "Epoch 1742/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 9.8360e-05 - val_loss: 0.0021\n",
      "Epoch 1743/2000\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 9.3752e-05 - val_loss: 0.0023\n",
      "Epoch 1744/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 9.3351e-05 - val_loss: 0.0022\n",
      "Epoch 1745/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 9.2361e-05 - val_loss: 0.0021\n",
      "Epoch 1746/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 8.9562e-05 - val_loss: 0.0022\n",
      "Epoch 1747/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 8.5422e-05 - val_loss: 0.0023\n",
      "Epoch 1748/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 8.0186e-05 - val_loss: 0.0024\n",
      "Epoch 1749/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 8.5117e-05 - val_loss: 0.0023\n",
      "Epoch 1750/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 8.7868e-05 - val_loss: 0.0023\n",
      "Epoch 1751/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 8.9307e-05 - val_loss: 0.0022\n",
      "Epoch 1752/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 8.8852e-05 - val_loss: 0.0022\n",
      "Epoch 1753/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 9.5212e-05 - val_loss: 0.0022\n",
      "Epoch 1754/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 9.0808e-05 - val_loss: 0.0020\n",
      "Epoch 1755/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 8.4726e-05 - val_loss: 0.0021\n",
      "Epoch 1756/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 8.8874e-05 - val_loss: 0.0020\n",
      "Epoch 1757/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 8.6660e-05 - val_loss: 0.0022\n",
      "Epoch 1758/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 8.4257e-05 - val_loss: 0.0023\n",
      "Epoch 1759/2000\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 8.5968e-05 - val_loss: 0.0023\n",
      "Epoch 1760/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 8.8861e-05 - val_loss: 0.0021\n",
      "Epoch 1761/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 8.2980e-05 - val_loss: 0.0023\n",
      "Epoch 1762/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 7.8917e-05 - val_loss: 0.0022\n",
      "Epoch 1763/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 8.2221e-05 - val_loss: 0.0021\n",
      "Epoch 1764/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 8.1721e-05 - val_loss: 0.0020\n",
      "Epoch 1765/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 9.0242e-05 - val_loss: 0.0021\n",
      "Epoch 1766/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 8.9653e-05 - val_loss: 0.0022\n",
      "Epoch 1767/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 8.2313e-05 - val_loss: 0.0022\n",
      "Epoch 1768/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 8.0638e-05 - val_loss: 0.0023\n",
      "Epoch 1769/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 7.7221e-05 - val_loss: 0.0021\n",
      "Epoch 1770/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 7.8556e-05 - val_loss: 0.0022\n",
      "Epoch 1771/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 7.8286e-05 - val_loss: 0.0024\n",
      "Epoch 1772/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 7.6663e-05 - val_loss: 0.0024\n",
      "Epoch 1773/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 2s 522us/step - loss: 7.7025e-05 - val_loss: 0.0025\n",
      "Epoch 1774/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 8.0582e-05 - val_loss: 0.0023\n",
      "Epoch 1775/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 8.2474e-05 - val_loss: 0.0022\n",
      "Epoch 1776/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 8.2741e-05 - val_loss: 0.0022\n",
      "Epoch 1777/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 9.3299e-05 - val_loss: 0.0022\n",
      "Epoch 1778/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 8.6115e-05 - val_loss: 0.0019\n",
      "Epoch 1779/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 8.6846e-05 - val_loss: 0.0022\n",
      "Epoch 1780/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 9.5571e-05 - val_loss: 0.0020\n",
      "Epoch 1781/2000\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 1.0172e-04 - val_loss: 0.0019\n",
      "Epoch 1782/2000\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 9.5102e-05 - val_loss: 0.0022\n",
      "Epoch 1783/2000\n",
      "3977/3977 [==============================] - 2s 539us/step - loss: 9.0020e-05 - val_loss: 0.0025\n",
      "Epoch 1784/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 8.9227e-05 - val_loss: 0.0021\n",
      "Epoch 1785/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 8.1517e-05 - val_loss: 0.0023\n",
      "Epoch 1786/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 8.4015e-05 - val_loss: 0.0021\n",
      "Epoch 1787/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 8.0276e-05 - val_loss: 0.0023\n",
      "Epoch 1788/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 8.7976e-05 - val_loss: 0.0023\n",
      "Epoch 1789/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 9.1652e-05 - val_loss: 0.0022\n",
      "Epoch 1790/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 9.8580e-05 - val_loss: 0.0021\n",
      "Epoch 1791/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 9.1798e-05 - val_loss: 0.0022\n",
      "Epoch 1792/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 8.7432e-05 - val_loss: 0.0024\n",
      "Epoch 1793/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 7.4556e-05 - val_loss: 0.0021\n",
      "Epoch 1794/2000\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 7.5466e-05 - val_loss: 0.0022\n",
      "Epoch 1795/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 7.5072e-05 - val_loss: 0.0022\n",
      "Epoch 1796/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 7.6330e-05 - val_loss: 0.0021\n",
      "Epoch 1797/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 7.7424e-05 - val_loss: 0.0022\n",
      "Epoch 1798/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 7.5412e-05 - val_loss: 0.0021\n",
      "Epoch 1799/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 7.6359e-05 - val_loss: 0.0021\n",
      "Epoch 1800/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 7.7574e-05 - val_loss: 0.0022\n",
      "Epoch 1801/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 8.4337e-05 - val_loss: 0.0023\n",
      "Epoch 1802/2000\n",
      "3977/3977 [==============================] - 2s 528us/step - loss: 8.6664e-05 - val_loss: 0.0020\n",
      "Epoch 1803/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.0023e-04 - val_loss: 0.0025\n",
      "Epoch 1804/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 1.1427e-04 - val_loss: 0.0019\n",
      "Epoch 1805/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 1.0667e-04 - val_loss: 0.0020\n",
      "Epoch 1806/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 1.1604e-04 - val_loss: 0.0022\n",
      "Epoch 1807/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 9.9401e-05 - val_loss: 0.0022\n",
      "Epoch 1808/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 8.5550e-05 - val_loss: 0.0020\n",
      "Epoch 1809/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 8.8765e-05 - val_loss: 0.0022\n",
      "Epoch 1810/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 8.6548e-05 - val_loss: 0.0020\n",
      "Epoch 1811/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 8.4887e-05 - val_loss: 0.0021\n",
      "Epoch 1812/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 8.7981e-05 - val_loss: 0.0023\n",
      "Epoch 1813/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 7.9127e-05 - val_loss: 0.0022\n",
      "Epoch 1814/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 7.6682e-05 - val_loss: 0.0021\n",
      "Epoch 1815/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 7.4951e-05 - val_loss: 0.0020\n",
      "Epoch 1816/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 7.0386e-05 - val_loss: 0.0020\n",
      "Epoch 1817/2000\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 7.1448e-05 - val_loss: 0.0021\n",
      "Epoch 1818/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 7.7671e-05 - val_loss: 0.0021\n",
      "Epoch 1819/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 7.5304e-05 - val_loss: 0.0021\n",
      "Epoch 1820/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 7.8900e-05 - val_loss: 0.0021\n",
      "Epoch 1821/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 7.4032e-05 - val_loss: 0.0023\n",
      "Epoch 1822/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 8.0699e-05 - val_loss: 0.0019\n",
      "Epoch 1823/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 7.8919e-05 - val_loss: 0.0020\n",
      "Epoch 1824/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 8.0502e-05 - val_loss: 0.0020\n",
      "Epoch 1825/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 8.0277e-05 - val_loss: 0.0020\n",
      "Epoch 1826/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 8.4499e-05 - val_loss: 0.0022\n",
      "Epoch 1827/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 7.8605e-05 - val_loss: 0.0019\n",
      "Epoch 1828/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 7.9807e-05 - val_loss: 0.0022\n",
      "Epoch 1829/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 8.3514e-05 - val_loss: 0.0022\n",
      "Epoch 1830/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 7.5949e-05 - val_loss: 0.0022\n",
      "Epoch 1831/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 8.2349e-05 - val_loss: 0.0022\n",
      "Epoch 1832/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 8.1596e-05 - val_loss: 0.0023\n",
      "Epoch 1833/2000\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 8.5006e-05 - val_loss: 0.0021\n",
      "Epoch 1834/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 9.1467e-05 - val_loss: 0.0019\n",
      "Epoch 1835/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 8.4548e-05 - val_loss: 0.0020\n",
      "Epoch 1836/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 8.4286e-05 - val_loss: 0.0021\n",
      "Epoch 1837/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 8.1195e-05 - val_loss: 0.0019\n",
      "Epoch 1838/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 7.7491e-05 - val_loss: 0.0020\n",
      "Epoch 1839/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 8.1953e-05 - val_loss: 0.0020\n",
      "Epoch 1840/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 9.6577e-05 - val_loss: 0.0020\n",
      "Epoch 1841/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 1.0178e-04 - val_loss: 0.0020\n",
      "Epoch 1842/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 8.7382e-05 - val_loss: 0.0019\n",
      "Epoch 1843/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 8.5805e-05 - val_loss: 0.0022\n",
      "Epoch 1844/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 9.0512e-05 - val_loss: 0.0022\n",
      "Epoch 1845/2000\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 8.0606e-05 - val_loss: 0.0021\n",
      "Epoch 1846/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 7.9738e-05 - val_loss: 0.0021\n",
      "Epoch 1847/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 8.6030e-05 - val_loss: 0.0019\n",
      "Epoch 1848/2000\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 8.0821e-05 - val_loss: 0.0019\n",
      "Epoch 1849/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 7.6818e-05 - val_loss: 0.0018\n",
      "Epoch 1850/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 7.7619e-05 - val_loss: 0.0019\n",
      "Epoch 1851/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 7.9406e-05 - val_loss: 0.0019\n",
      "Epoch 1852/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 8.1617e-05 - val_loss: 0.0019\n",
      "Epoch 1853/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 7.9610e-05 - val_loss: 0.0021\n",
      "Epoch 1854/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 8.5043e-05 - val_loss: 0.0019\n",
      "Epoch 1855/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 7.1468e-05 - val_loss: 0.0019\n",
      "Epoch 1856/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 6.7560e-05 - val_loss: 0.0021\n",
      "Epoch 1857/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 6.6732e-05 - val_loss: 0.0021\n",
      "Epoch 1858/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 6.6515e-05 - val_loss: 0.0021\n",
      "Epoch 1859/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 6.9581e-05 - val_loss: 0.0021\n",
      "Epoch 1860/2000\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 7.3220e-05 - val_loss: 0.0020\n",
      "Epoch 1861/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 7.9118e-05 - val_loss: 0.0019\n",
      "Epoch 1862/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 8.2239e-05 - val_loss: 0.0021\n",
      "Epoch 1863/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 8.0480e-05 - val_loss: 0.0021\n",
      "Epoch 1864/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 7.2210e-05 - val_loss: 0.0021\n",
      "Epoch 1865/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 6.6710e-05 - val_loss: 0.0020\n",
      "Epoch 1866/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 7.0534e-05 - val_loss: 0.0021\n",
      "Epoch 1867/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 7.1451e-05 - val_loss: 0.0022\n",
      "Epoch 1868/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 7.0129e-05 - val_loss: 0.0021\n",
      "Epoch 1869/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 7.3193e-05 - val_loss: 0.0020\n",
      "Epoch 1870/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 7.1106e-05 - val_loss: 0.0021\n",
      "Epoch 1871/2000\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 7.6157e-05 - val_loss: 0.0020\n",
      "Epoch 1872/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 7.6630e-05 - val_loss: 0.0021\n",
      "Epoch 1873/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 7.3518e-05 - val_loss: 0.0020\n",
      "Epoch 1874/2000\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 7.6234e-05 - val_loss: 0.0021\n",
      "Epoch 1875/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 7.8390e-05 - val_loss: 0.0023\n",
      "Epoch 1876/2000\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 7.6632e-05 - val_loss: 0.0023\n",
      "Epoch 1877/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 7.1722e-05 - val_loss: 0.0020\n",
      "Epoch 1878/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 7.6700e-05 - val_loss: 0.0021\n",
      "Epoch 1879/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 7.8126e-05 - val_loss: 0.0021\n",
      "Epoch 1880/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 7.4317e-05 - val_loss: 0.0020\n",
      "Epoch 1881/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 7.1779e-05 - val_loss: 0.0020\n",
      "Epoch 1882/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 7.1960e-05 - val_loss: 0.0019\n",
      "Epoch 1883/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 6.8709e-05 - val_loss: 0.0020\n",
      "Epoch 1884/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 6.9545e-05 - val_loss: 0.0022\n",
      "Epoch 1885/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 6.6401e-05 - val_loss: 0.0022\n",
      "Epoch 1886/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 6.5374e-05 - val_loss: 0.0021\n",
      "Epoch 1887/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 7.2416e-05 - val_loss: 0.0022\n",
      "Epoch 1888/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 7.9082e-05 - val_loss: 0.0023\n",
      "Epoch 1889/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 7.8139e-05 - val_loss: 0.0023\n",
      "Epoch 1890/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 7.9141e-05 - val_loss: 0.0020\n",
      "Epoch 1891/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 7.1427e-05 - val_loss: 0.0020\n",
      "Epoch 1892/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 7.9128e-05 - val_loss: 0.0018\n",
      "Epoch 1893/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 8.2685e-05 - val_loss: 0.0022\n",
      "Epoch 1894/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 7.4881e-05 - val_loss: 0.0021\n",
      "Epoch 1895/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 7.9776e-05 - val_loss: 0.0020\n",
      "Epoch 1896/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 6.8470e-05 - val_loss: 0.0018\n",
      "Epoch 1897/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 6.2785e-05 - val_loss: 0.0019\n",
      "Epoch 1898/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 6.2377e-05 - val_loss: 0.0020\n",
      "Epoch 1899/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 6.8058e-05 - val_loss: 0.0020\n",
      "Epoch 1900/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 6.3220e-05 - val_loss: 0.0018\n",
      "Epoch 1901/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 6.2819e-05 - val_loss: 0.0019\n",
      "Epoch 1902/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 6.0633e-05 - val_loss: 0.0020\n",
      "Epoch 1903/2000\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 6.1363e-05 - val_loss: 0.0021\n",
      "Epoch 1904/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 6.3847e-05 - val_loss: 0.0020\n",
      "Epoch 1905/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 6.1865e-05 - val_loss: 0.0020\n",
      "Epoch 1906/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 6.9632e-05 - val_loss: 0.0023\n",
      "Epoch 1907/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 7.3656e-05 - val_loss: 0.0018\n",
      "Epoch 1908/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 7.2518e-05 - val_loss: 0.0019\n",
      "Epoch 1909/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 6.6983e-05 - val_loss: 0.0019\n",
      "Epoch 1910/2000\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 6.9241e-05 - val_loss: 0.0020\n",
      "Epoch 1911/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 6.5796e-05 - val_loss: 0.0019\n",
      "Epoch 1912/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 7.2033e-05 - val_loss: 0.0019\n",
      "Epoch 1913/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 7.6766e-05 - val_loss: 0.0021\n",
      "Epoch 1914/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 7.6562e-05 - val_loss: 0.0020\n",
      "Epoch 1915/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 8.4471e-05 - val_loss: 0.0021\n",
      "Epoch 1916/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 8.0664e-05 - val_loss: 0.0021\n",
      "Epoch 1917/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 2s 523us/step - loss: 7.4664e-05 - val_loss: 0.0017\n",
      "Epoch 1918/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 7.0435e-05 - val_loss: 0.0018\n",
      "Epoch 1919/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 6.5215e-05 - val_loss: 0.0020\n",
      "Epoch 1920/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 6.6755e-05 - val_loss: 0.0022\n",
      "Epoch 1921/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 6.3318e-05 - val_loss: 0.0020\n",
      "Epoch 1922/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 6.8180e-05 - val_loss: 0.0021\n",
      "Epoch 1923/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 6.6571e-05 - val_loss: 0.0021\n",
      "Epoch 1924/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 6.7975e-05 - val_loss: 0.0019\n",
      "Epoch 1925/2000\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 6.6824e-05 - val_loss: 0.0019\n",
      "Epoch 1926/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 6.4943e-05 - val_loss: 0.0022\n",
      "Epoch 1927/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 6.6648e-05 - val_loss: 0.0019\n",
      "Epoch 1928/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 7.5777e-05 - val_loss: 0.0019\n",
      "Epoch 1929/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 7.5506e-05 - val_loss: 0.0021\n",
      "Epoch 1930/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 7.0763e-05 - val_loss: 0.0019\n",
      "Epoch 1931/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 7.4775e-05 - val_loss: 0.0019\n",
      "Epoch 1932/2000\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 7.2056e-05 - val_loss: 0.0020\n",
      "Epoch 1933/2000\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 6.6919e-05 - val_loss: 0.0019\n",
      "Epoch 1934/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 7.2556e-05 - val_loss: 0.0022\n",
      "Epoch 1935/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 6.9467e-05 - val_loss: 0.0018\n",
      "Epoch 1936/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 7.2024e-05 - val_loss: 0.0020\n",
      "Epoch 1937/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 7.0610e-05 - val_loss: 0.0019\n",
      "Epoch 1938/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 7.0577e-05 - val_loss: 0.0022\n",
      "Epoch 1939/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 7.4844e-05 - val_loss: 0.0020\n",
      "Epoch 1940/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 8.2777e-05 - val_loss: 0.0018\n",
      "Epoch 1941/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 7.6950e-05 - val_loss: 0.0018\n",
      "Epoch 1942/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 6.9444e-05 - val_loss: 0.0020\n",
      "Epoch 1943/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 6.2492e-05 - val_loss: 0.0018\n",
      "Epoch 1944/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 5.8141e-05 - val_loss: 0.0018\n",
      "Epoch 1945/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 5.7835e-05 - val_loss: 0.0019\n",
      "Epoch 1946/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 5.8193e-05 - val_loss: 0.0019\n",
      "Epoch 1947/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 5.4673e-05 - val_loss: 0.0018\n",
      "Epoch 1948/2000\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 5.5685e-05 - val_loss: 0.0020\n",
      "Epoch 1949/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 5.5465e-05 - val_loss: 0.0018\n",
      "Epoch 1950/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 5.3678e-05 - val_loss: 0.0018\n",
      "Epoch 1951/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 5.7413e-05 - val_loss: 0.0018\n",
      "Epoch 1952/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 5.7199e-05 - val_loss: 0.0017\n",
      "Epoch 1953/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 6.0030e-05 - val_loss: 0.0019\n",
      "Epoch 1954/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 5.6924e-05 - val_loss: 0.0018\n",
      "Epoch 1955/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 5.6800e-05 - val_loss: 0.0019\n",
      "Epoch 1956/2000\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 5.4851e-05 - val_loss: 0.0018\n",
      "Epoch 1957/2000\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 5.4552e-05 - val_loss: 0.0019\n",
      "Epoch 1958/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 5.8237e-05 - val_loss: 0.0019\n",
      "Epoch 1959/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 6.1678e-05 - val_loss: 0.0017\n",
      "Epoch 1960/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 6.2787e-05 - val_loss: 0.0019\n",
      "Epoch 1961/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 6.0535e-05 - val_loss: 0.0019\n",
      "Epoch 1962/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 5.9304e-05 - val_loss: 0.0019\n",
      "Epoch 1963/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 5.8549e-05 - val_loss: 0.0019\n",
      "Epoch 1964/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 5.6069e-05 - val_loss: 0.0018\n",
      "Epoch 1965/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 5.2130e-05 - val_loss: 0.0018\n",
      "Epoch 1966/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 5.2561e-05 - val_loss: 0.0019\n",
      "Epoch 1967/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 5.2995e-05 - val_loss: 0.0018\n",
      "Epoch 1968/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 5.8974e-05 - val_loss: 0.0019\n",
      "Epoch 1969/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 5.9927e-05 - val_loss: 0.0019\n",
      "Epoch 1970/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 5.6300e-05 - val_loss: 0.0020\n",
      "Epoch 1971/2000\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 5.6330e-05 - val_loss: 0.0019\n",
      "Epoch 1972/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 5.8529e-05 - val_loss: 0.0019\n",
      "Epoch 1973/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 5.6226e-05 - val_loss: 0.0018\n",
      "Epoch 1974/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 5.7103e-05 - val_loss: 0.0019\n",
      "Epoch 1975/2000\n",
      "3977/3977 [==============================] - 2s 529us/step - loss: 5.7420e-05 - val_loss: 0.0020\n",
      "Epoch 1976/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 5.6644e-05 - val_loss: 0.0020\n",
      "Epoch 1977/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 5.9931e-05 - val_loss: 0.0018\n",
      "Epoch 1978/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 6.7308e-05 - val_loss: 0.0019\n",
      "Epoch 1979/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 6.7881e-05 - val_loss: 0.0017\n",
      "Epoch 1980/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 6.2626e-05 - val_loss: 0.0020\n",
      "Epoch 1981/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 5.9319e-05 - val_loss: 0.0017\n",
      "Epoch 1982/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 6.2717e-05 - val_loss: 0.0018\n",
      "Epoch 1983/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 6.7172e-05 - val_loss: 0.0018\n",
      "Epoch 1984/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 6.1050e-05 - val_loss: 0.0019\n",
      "Epoch 1985/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 5.3636e-05 - val_loss: 0.0019\n",
      "Epoch 1986/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 5.2567e-05 - val_loss: 0.0020\n",
      "Epoch 1987/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 5.0731e-05 - val_loss: 0.0018\n",
      "Epoch 1988/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 4.9679e-05 - val_loss: 0.0019\n",
      "Epoch 1989/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 5.2371e-05 - val_loss: 0.0019\n",
      "Epoch 1990/2000\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 5.4770e-05 - val_loss: 0.0021\n",
      "Epoch 1991/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 5.2424e-05 - val_loss: 0.0019\n",
      "Epoch 1992/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 4.8558e-05 - val_loss: 0.0018\n",
      "Epoch 1993/2000\n",
      "3977/3977 [==============================] - 2s 519us/step - loss: 4.9350e-05 - val_loss: 0.0018\n",
      "Epoch 1994/2000\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 5.1778e-05 - val_loss: 0.0022\n",
      "Epoch 1995/2000\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 5.7197e-05 - val_loss: 0.0018\n",
      "Epoch 1996/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 5.6950e-05 - val_loss: 0.0019\n",
      "Epoch 1997/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 5.6705e-05 - val_loss: 0.0019\n",
      "Epoch 1998/2000\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 5.4715e-05 - val_loss: 0.0022\n",
      "Epoch 1999/2000\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 5.6300e-05 - val_loss: 0.0019\n",
      "Epoch 2000/2000\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 5.3236e-05 - val_loss: 0.0019\n"
     ]
    }
   ],
   "source": [
    "final_model = build_lstm(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'density': 186,\n",
       " 'activation': 'softsign',\n",
       " 'twice': True,\n",
       " 'full_density': True,\n",
       " 'lstmsize': 158,\n",
       " 'shuffle': True,\n",
       " 'optimizer': 'adam',\n",
       " 'callbacks': [<keras.callbacks.callbacks.ModelCheckpoint at 0x1d4311bfd48>]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_182\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_363 (LSTM)              (None, 92, 158)           103648    \n",
      "_________________________________________________________________\n",
      "lstm_364 (LSTM)              (None, 158)               200344    \n",
      "_________________________________________________________________\n",
      "dense_913 (Dense)            (None, 186)               29574     \n",
      "_________________________________________________________________\n",
      "dense_914 (Dense)            (None, 93)                17391     \n",
      "_________________________________________________________________\n",
      "dense_915 (Dense)            (None, 46)                4324      \n",
      "_________________________________________________________________\n",
      "dense_916 (Dense)            (None, 23)                1081      \n",
      "_________________________________________________________________\n",
      "dense_917 (Dense)            (None, 1)                 24        \n",
      "=================================================================\n",
      "Total params: 356,386\n",
      "Trainable params: 356,386\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model[0].load_weights('./checkpoints/IBM_3days/IBM.(best).hdf5')\n",
    "y_predicted = final_model[0].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y_test = y_normaliser.inverse_transform(y_predicted)\n",
    "true_y_test = y_normaliser.inverse_transform(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE is 19.38\n",
      "Medium error is 3.13\n"
     ]
    }
   ],
   "source": [
    "loss = np.mean((true_y_test - predicted_y_test)**2)\n",
    "medium_error = np.mean(abs(true_y_test - predicted_y_test))\n",
    "print(f'MSE is {loss:.2f}\\nMedium error is {medium_error:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_down_test = []\n",
    "up_down_predicted = []\n",
    "\n",
    "for y,x in zip(Y_test,X_test):\n",
    "    if y[0] > x[-1][0]: up_down_test.append(1)\n",
    "    elif y[0] < x[-1][0]: up_down_test.append(-1)\n",
    "    else: up_down_test.append(0)\n",
    "        \n",
    "for y,x in zip(y_predicted,X_test):\n",
    "    if y[0] > x[-1][0]: up_down_predicted.append(1)\n",
    "    elif y[0] < x[-1][0]: up_down_predicted.append(-1)\n",
    "    else: up_down_predicted.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trend accuracy is: 69.14%\n"
     ]
    }
   ],
   "source": [
    "print(f'Trend accuracy is: {(sum(1 for r,p in zip(up_down_test,up_down_predicted) if r == p)/len(up_down_test))*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for upward trend is: 67.21%\n",
      "Accuracy for downward trend is: 71.67%\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy for upward trend is: {(sum(1 for r,p in zip(up_down_test,up_down_predicted) if r == 1 and p == 1)/sum(1 for v in up_down_test if v == 1))*100:.2f}%')\n",
    "print(f'Accuracy for downward trend is: {(sum(1 for r,p in zip(up_down_test,up_down_predicted) if r == -1 and p == -1)/sum(1 for v in up_down_test if v == -1))*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predictions over the last 92 days in test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 3200x2400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "figure(num=None, figsize=(40, 30), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "plt.plot(range(92), true_y_test[-92:])\n",
    "plt.plot(range(92), predicted_y_test[-92:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Last 12 days + prediction of last 6 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 3200x2400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure(num=None, figsize=(40, 30), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "plt.plot(range(12), true_y_test[-12:])\n",
    "plt.plot(range(12), np.append(true_y_test[-12:-6], predicted_y_test[-6:]))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
