{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from joblib import load\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./datasets/IBM_daily.csv').sort_values(by='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>1. open</th>\n",
       "      <th>2. high</th>\n",
       "      <th>3. low</th>\n",
       "      <th>4. close</th>\n",
       "      <th>5. volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5217</th>\n",
       "      <td>1999-11-01</td>\n",
       "      <td>98.50</td>\n",
       "      <td>98.8100</td>\n",
       "      <td>96.37</td>\n",
       "      <td>96.75</td>\n",
       "      <td>9551800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5216</th>\n",
       "      <td>1999-11-02</td>\n",
       "      <td>96.75</td>\n",
       "      <td>96.8100</td>\n",
       "      <td>93.69</td>\n",
       "      <td>94.81</td>\n",
       "      <td>11105400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5215</th>\n",
       "      <td>1999-11-03</td>\n",
       "      <td>95.87</td>\n",
       "      <td>95.9400</td>\n",
       "      <td>93.50</td>\n",
       "      <td>94.37</td>\n",
       "      <td>10369100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5214</th>\n",
       "      <td>1999-11-04</td>\n",
       "      <td>94.44</td>\n",
       "      <td>94.4400</td>\n",
       "      <td>90.00</td>\n",
       "      <td>91.56</td>\n",
       "      <td>16697600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5213</th>\n",
       "      <td>1999-11-05</td>\n",
       "      <td>92.75</td>\n",
       "      <td>92.9400</td>\n",
       "      <td>90.19</td>\n",
       "      <td>90.25</td>\n",
       "      <td>13737600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-07-22</td>\n",
       "      <td>125.90</td>\n",
       "      <td>129.4700</td>\n",
       "      <td>125.80</td>\n",
       "      <td>128.67</td>\n",
       "      <td>8195366.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-07-23</td>\n",
       "      <td>129.10</td>\n",
       "      <td>129.3700</td>\n",
       "      <td>127.15</td>\n",
       "      <td>127.33</td>\n",
       "      <td>4220136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-07-24</td>\n",
       "      <td>126.48</td>\n",
       "      <td>127.6459</td>\n",
       "      <td>125.50</td>\n",
       "      <td>125.79</td>\n",
       "      <td>3531076.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-07-27</td>\n",
       "      <td>124.86</td>\n",
       "      <td>126.3200</td>\n",
       "      <td>124.71</td>\n",
       "      <td>126.21</td>\n",
       "      <td>3733547.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-28</td>\n",
       "      <td>125.82</td>\n",
       "      <td>126.3400</td>\n",
       "      <td>124.15</td>\n",
       "      <td>124.47</td>\n",
       "      <td>4157538.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5218 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  1. open   2. high  3. low  4. close   5. volume\n",
       "5217  1999-11-01    98.50   98.8100   96.37     96.75   9551800.0\n",
       "5216  1999-11-02    96.75   96.8100   93.69     94.81  11105400.0\n",
       "5215  1999-11-03    95.87   95.9400   93.50     94.37  10369100.0\n",
       "5214  1999-11-04    94.44   94.4400   90.00     91.56  16697600.0\n",
       "5213  1999-11-05    92.75   92.9400   90.19     90.25  13737600.0\n",
       "...          ...      ...       ...     ...       ...         ...\n",
       "4     2020-07-22   125.90  129.4700  125.80    128.67   8195366.0\n",
       "3     2020-07-23   129.10  129.3700  127.15    127.33   4220136.0\n",
       "2     2020-07-24   126.48  127.6459  125.50    125.79   3531076.0\n",
       "1     2020-07-27   124.86  126.3200  124.71    126.21   3733547.0\n",
       "0     2020-07-28   125.82  126.3400  124.15    124.47   4157538.0\n",
       "\n",
       "[5218 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1. open</th>\n",
       "      <th>2. high</th>\n",
       "      <th>3. low</th>\n",
       "      <th>4. close</th>\n",
       "      <th>5. volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5217</th>\n",
       "      <td>98.50</td>\n",
       "      <td>98.8100</td>\n",
       "      <td>96.37</td>\n",
       "      <td>96.75</td>\n",
       "      <td>9551800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5216</th>\n",
       "      <td>96.75</td>\n",
       "      <td>96.8100</td>\n",
       "      <td>93.69</td>\n",
       "      <td>94.81</td>\n",
       "      <td>11105400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5215</th>\n",
       "      <td>95.87</td>\n",
       "      <td>95.9400</td>\n",
       "      <td>93.50</td>\n",
       "      <td>94.37</td>\n",
       "      <td>10369100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5214</th>\n",
       "      <td>94.44</td>\n",
       "      <td>94.4400</td>\n",
       "      <td>90.00</td>\n",
       "      <td>91.56</td>\n",
       "      <td>16697600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5213</th>\n",
       "      <td>92.75</td>\n",
       "      <td>92.9400</td>\n",
       "      <td>90.19</td>\n",
       "      <td>90.25</td>\n",
       "      <td>13737600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>125.90</td>\n",
       "      <td>129.4700</td>\n",
       "      <td>125.80</td>\n",
       "      <td>128.67</td>\n",
       "      <td>8195366.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>129.10</td>\n",
       "      <td>129.3700</td>\n",
       "      <td>127.15</td>\n",
       "      <td>127.33</td>\n",
       "      <td>4220136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>126.48</td>\n",
       "      <td>127.6459</td>\n",
       "      <td>125.50</td>\n",
       "      <td>125.79</td>\n",
       "      <td>3531076.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>124.86</td>\n",
       "      <td>126.3200</td>\n",
       "      <td>124.71</td>\n",
       "      <td>126.21</td>\n",
       "      <td>3733547.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>125.82</td>\n",
       "      <td>126.3400</td>\n",
       "      <td>124.15</td>\n",
       "      <td>124.47</td>\n",
       "      <td>4157538.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5218 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      1. open   2. high  3. low  4. close   5. volume\n",
       "5217    98.50   98.8100   96.37     96.75   9551800.0\n",
       "5216    96.75   96.8100   93.69     94.81  11105400.0\n",
       "5215    95.87   95.9400   93.50     94.37  10369100.0\n",
       "5214    94.44   94.4400   90.00     91.56  16697600.0\n",
       "5213    92.75   92.9400   90.19     90.25  13737600.0\n",
       "...       ...       ...     ...       ...         ...\n",
       "4      125.90  129.4700  125.80    128.67   8195366.0\n",
       "3      129.10  129.3700  127.15    127.33   4220136.0\n",
       "2      126.48  127.6459  125.50    125.79   3531076.0\n",
       "1      124.86  126.3200  124.71    126.21   3733547.0\n",
       "0      125.82  126.3400  124.15    124.47   4157538.0\n",
       "\n",
       "[5218 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(columns='date')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequence for the LSTM network\n",
    "backlook = 92\n",
    "\n",
    "# Days to predict\n",
    "days = 3\n",
    "\n",
    "# Size of data split for testing\n",
    "train_size = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test split\n",
    "split = int(len(data) * train_size)\n",
    "\n",
    "train = data.to_numpy()[:split]\n",
    "test = data.to_numpy()[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load normalisers\n",
    "normaliser = load('./normalisers/x_normaliser.joblib')\n",
    "y_normaliser = load('./normalisers/y_normaliser.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise data\n",
    "train_norm = normaliser.transform(train)\n",
    "test_norm = normaliser.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now I get indexes for chunks from 3 in 3 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = []\n",
    "\n",
    "for i in range(days):\n",
    "    index.append(np.arange(i,len(train),days))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_index = []\n",
    "\n",
    "for i in range(len(index[0]) - backlook):\n",
    "    for e in range(days):\n",
    "        try: ordered_index.append(index[e][i:i+backlook])\n",
    "        except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalised train chunks\n",
    "X_train = np.array([train_norm[ix].copy() for ix in ordered_index])\n",
    "Y_train = np.array([train_norm[ordered_index[i+days][-1],3].copy() for i in range(len(ordered_index) - days)])\n",
    "Y_train = np.expand_dims(Y_train, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete those sequences that doesn't have a -th day in the results\n",
    "X_train = X_train[:Y_train.shape[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Same for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = []\n",
    "\n",
    "for i in range(days):\n",
    "    index.append(np.arange(i,len(test),days))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_index = []\n",
    "\n",
    "for i in range(len(index[0]) - backlook):\n",
    "    for e in range(days):\n",
    "        try: ordered_index.append(index[e][i:i+backlook])\n",
    "        except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalised test chunks\n",
    "X_test = np.array([test_norm[ix].copy() for ix in ordered_index])\n",
    "Y_test = np.array([test_norm[ordered_index[i+days][-1],3].copy() for i in range(len(ordered_index) - days)])\n",
    "Y_test = np.expand_dims(Y_test, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete those sequences that doesn't have a -th day in the results\n",
    "X_test = X_test[:Y_test.shape[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm(x, y, batch_size=512, epochs=24, **params):\n",
    "    \n",
    "    # List of parameters\n",
    "    if 'lstmsize' not in params: params['lstmsize'] = x.shape[1]\n",
    "    if 'density' not in params: params['density'] = int((params['lstmsize']//1.5)*2)\n",
    "    if 'activation' not in params: params['activation'] = 'relu'\n",
    "    if 'twice' not in params: params['twice'] = False\n",
    "    if 'optimizer' not in params: params['optimizer'] = 'adam'\n",
    "    if 'shuffle' not in params: params['shuffle'] = False\n",
    "    \n",
    "    # Model definition\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(params['lstmsize'], input_shape=x.shape[1:], return_sequences=params['twice']))\n",
    "    \n",
    "    if 'dropout' in params:\n",
    "        model.add(Dropout(params['dropout']))\n",
    "    \n",
    "    if params['twice']:\n",
    "        model.add(LSTM(params['lstmsize']))\n",
    "        \n",
    "        if 'dropout' in params:\n",
    "            model.add(Dropout(params['dropout']))\n",
    "            \n",
    "    model.add(Dense(params['density'], activation=params['activation']))\n",
    "    \n",
    "    if 'full_density' in params and params['full_density']:\n",
    "        density = params['density']//2\n",
    "        while density >= 12:\n",
    "            model.add(Dense(density, activation=params['activation']))\n",
    "            density //= 2\n",
    "            \n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    \n",
    "    model.compile(loss='mse', optimizer=params['optimizer'])\n",
    "    \n",
    "    if 'callbacks' in params:\n",
    "        callback = model.fit(x=x, y=y, validation_split=0.1, batch_size=batch_size, epochs=epochs, shuffle=params['shuffle'],\n",
    "                            callbacks=params['callbacks'])\n",
    "    else:\n",
    "        callback = model.fit(x=x, y=y, validation_split=0.1, batch_size=batch_size, epochs=epochs, shuffle=params['shuffle'])\n",
    "    \n",
    "    return [model, callback, params]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evolutive algorith to search for the most optimal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_genes(x, y, population_size, population=[]):\n",
    "    if population_size-len(population) < 0:\n",
    "        print('population size must be greater or equal than actual population')\n",
    "        return\n",
    "    \n",
    "    if len(population) > 0:\n",
    "        if len(population) < 3:\n",
    "            print('population should be empty or 3 at least')\n",
    "            return\n",
    "        \n",
    "        population[2] = breed_genes(x, y, population[0][2].copy())\n",
    "        population[1] = breed_genes(x, y, combine=(population[0][2], population[1][2]))\n",
    "        population = population[:3]\n",
    "    \n",
    "    for _ in range(population_size-len(population)):\n",
    "        subject = breed_genes(x, y)\n",
    "        population.append(subject)\n",
    "        \n",
    "    return population\n",
    "\n",
    "def breed_genes(x, y, genes={}, combine=None):\n",
    "    genes['x'] = x\n",
    "    genes['y'] = y\n",
    "    \n",
    "    if type(combine) is list or type(combine) is tuple:\n",
    "        genes['lstmsize'] = combine[np.random.randint(0,2)]['lstmsize']\n",
    "        genes['density'] = combine[np.random.randint(0,2)]['density']\n",
    "        genes['activation'] = combine[np.random.randint(0,2)]['activation']\n",
    "        genes['twice'] = combine[np.random.randint(0,2)]['twice']\n",
    "        genes['optimizer'] = combine[np.random.randint(0,2)]['optimizer']\n",
    "        genes['shuffle'] = combine[np.random.randint(0,2)]['shuffle']\n",
    "        \n",
    "        genes['dropout'] = combine[np.random.randint(0,2)].get('dropout')\n",
    "        if genes['dropout'] is None: del genes['dropout']\n",
    "        genes['full_density'] = combine[np.random.randint(0,2)].get('full_density')\n",
    "        if genes['full_density'] is None: del genes['full_density']\n",
    "            \n",
    "    else:\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['lstmsize'] = int((np.random.randint(x.shape[1],x.shape[1]*2)//2)*2)\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['density'] = int((np.random.randint(x.shape[1]//2,x.shape[1]*2.66)//2)*2)\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            activation = [\n",
    "                'relu',\n",
    "                'sigmoid',\n",
    "                'softplus',\n",
    "                'softsign',\n",
    "                'tanh',\n",
    "                'selu',\n",
    "                'elu',\n",
    "                'exponential'\n",
    "            ]\n",
    "            genes['activation'] = activation[np.random.randint(0,8)]\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['twice'] = True\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            optimizer = [\n",
    "                'sgd',\n",
    "                'rmsprop',\n",
    "                'adam',\n",
    "                'adadelta',\n",
    "                'adagrad',\n",
    "                'adamax',\n",
    "                'nadam'\n",
    "            ]\n",
    "            genes['optimizer'] = optimizer[np.random.randint(0,7)]\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['shuffle'] = True\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['dropout'] = np.random.randint(1,4)/10\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['full_density'] = True\n",
    "            \n",
    "    new_model = build_lstm(**genes)\n",
    "        \n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def breed_population(x, y, generations, population_size, population=[]):\n",
    "    \n",
    "    if generations > 1 and population_size < 3:\n",
    "        print('population size should be of a minimum of 3 for more than one generation')\n",
    "        return\n",
    "    \n",
    "    for g in range(generations):\n",
    "        print(f'\\nGENERATION {g}\\n')\n",
    "        population = set_genes(x, y, population_size, population)\n",
    "        population = sorted(population, key=lambda x: x[1].history['val_loss'][-1]+x[1].history['loss'][-1])\n",
    "        \n",
    "    return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GENERATION 0\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 1s 370us/step - loss: 0.2071 - val_loss: 0.0021\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 150us/step - loss: 0.0193 - val_loss: 0.0018\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 150us/step - loss: 0.0087 - val_loss: 0.0060\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 148us/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 155us/step - loss: 0.0028 - val_loss: 0.0015\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 149us/step - loss: 0.0022 - val_loss: 9.5417e-04\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 150us/step - loss: 0.0020 - val_loss: 8.3788e-04\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 151us/step - loss: 0.0017 - val_loss: 7.7666e-04\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 152us/step - loss: 0.0016 - val_loss: 7.7899e-04\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 149us/step - loss: 0.0017 - val_loss: 7.7119e-04\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 149us/step - loss: 0.0015 - val_loss: 7.6819e-04\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 153us/step - loss: 0.0015 - val_loss: 7.5148e-04\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 148us/step - loss: 0.0015 - val_loss: 7.8984e-04\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 150us/step - loss: 0.0015 - val_loss: 7.3985e-04\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 149us/step - loss: 0.0015 - val_loss: 7.5853e-04\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 148us/step - loss: 0.0014 - val_loss: 7.8818e-04\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 148us/step - loss: 0.0014 - val_loss: 7.5503e-04\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 150us/step - loss: 0.0013 - val_loss: 7.3388e-04\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 153us/step - loss: 0.0013 - val_loss: 7.2589e-04\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 151us/step - loss: 0.0013 - val_loss: 7.6997e-04\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 149us/step - loss: 0.0012 - val_loss: 7.2024e-04\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 149us/step - loss: 0.0012 - val_loss: 7.1225e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 148us/step - loss: 0.0012 - val_loss: 6.9652e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 147us/step - loss: 0.0012 - val_loss: 7.5287e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 3s 663us/step - loss: 0.0585 - val_loss: 0.0231\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 0.0120 - val_loss: 0.0017\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 529us/step - loss: 0.0067 - val_loss: 0.0032\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 0.0046 - val_loss: 0.0016\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 497us/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 505us/step - loss: 0.0033 - val_loss: 0.0014\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 493us/step - loss: 0.0031 - val_loss: 0.0015\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 507us/step - loss: 0.0029 - val_loss: 0.0019\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 501us/step - loss: 0.0027 - val_loss: 0.0021\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 494us/step - loss: 0.0028 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 506us/step - loss: 0.0027 - val_loss: 0.0016\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 0.0026 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 506us/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 507us/step - loss: 0.0025 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 491us/step - loss: 0.0024 - val_loss: 0.0013\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 493us/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 496us/step - loss: 0.0023 - val_loss: 0.0013\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 495us/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 493us/step - loss: 0.0023 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 493us/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 494us/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 495us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 496us/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 3s 761us/step - loss: 0.0565 - val_loss: 0.0091\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 546us/step - loss: 0.0093 - val_loss: 0.0175\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 545us/step - loss: 0.0063 - val_loss: 0.0055\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 544us/step - loss: 0.0046 - val_loss: 0.0068\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 548us/step - loss: 0.0034 - val_loss: 0.0049\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 548us/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 546us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 547us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 546us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 545us/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 551us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 547us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 545us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 544us/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 546us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 546us/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 548us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 547us/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 545us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 547us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 549us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 552us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 23/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 2s 546us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 547us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 3s 705us/step - loss: 0.8947 - val_loss: 0.2401\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 465us/step - loss: 0.1061 - val_loss: 0.0600\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 462us/step - loss: 0.0306 - val_loss: 0.0278\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 465us/step - loss: 0.0121 - val_loss: 0.0208\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 464us/step - loss: 0.0080 - val_loss: 0.0041\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 467us/step - loss: 0.0056 - val_loss: 0.0075\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 466us/step - loss: 0.0045 - val_loss: 0.0015\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 464us/step - loss: 0.0040 - val_loss: 0.0031\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 472us/step - loss: 0.0038 - val_loss: 0.0013\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 468us/step - loss: 0.0034 - val_loss: 0.0019\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 465us/step - loss: 0.0033 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 463us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 463us/step - loss: 0.0032 - val_loss: 0.0014\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 465us/step - loss: 0.0030 - val_loss: 0.0015\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 466us/step - loss: 0.0031 - val_loss: 0.0015\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 464us/step - loss: 0.0029 - val_loss: 0.0014\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 462us/step - loss: 0.0029 - val_loss: 0.0013\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 466us/step - loss: 0.0028 - val_loss: 0.0013\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 465us/step - loss: 0.0028 - val_loss: 0.0013\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 466us/step - loss: 0.0027 - val_loss: 0.0014\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 464us/step - loss: 0.0027 - val_loss: 0.0013\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 463us/step - loss: 0.0027 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 468us/step - loss: 0.0026 - val_loss: 0.0012\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 466us/step - loss: 0.0026 - val_loss: 0.0012\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 2s 616us/step - loss: 0.4936 - val_loss: 0.0198\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 378us/step - loss: 0.0374 - val_loss: 0.0136\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 379us/step - loss: 0.0139 - val_loss: 0.0162\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 377us/step - loss: 0.0112 - val_loss: 0.0026\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 377us/step - loss: 0.0071 - val_loss: 0.0057\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 376us/step - loss: 0.0058 - val_loss: 0.0017\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 377us/step - loss: 0.0057 - val_loss: 0.0017\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 382us/step - loss: 0.0053 - val_loss: 0.0027\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 377us/step - loss: 0.0050 - val_loss: 0.0020\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 377us/step - loss: 0.0049 - val_loss: 0.0018\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 375us/step - loss: 0.0047 - val_loss: 0.0021\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 377us/step - loss: 0.0047 - val_loss: 0.0020\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 375us/step - loss: 0.0046 - val_loss: 0.0018\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 376us/step - loss: 0.0043 - val_loss: 0.0019\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 378us/step - loss: 0.0044 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 376us/step - loss: 0.0041 - val_loss: 0.0017\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 379us/step - loss: 0.0043 - val_loss: 0.0018\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 378us/step - loss: 0.0042 - val_loss: 0.0018\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 381us/step - loss: 0.0038 - val_loss: 0.0017\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 377us/step - loss: 0.0041 - val_loss: 0.0018\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 376us/step - loss: 0.0040 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 378us/step - loss: 0.0038 - val_loss: 0.0017\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 376us/step - loss: 0.0039 - val_loss: 0.0017\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 378us/step - loss: 0.0038 - val_loss: 0.0017\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 3s 784us/step - loss: 15.1589 - val_loss: 0.1064\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 537us/step - loss: 0.0903 - val_loss: 0.0052\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0315 - val_loss: 0.0023\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0266 - val_loss: 0.0025\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0229 - val_loss: 0.0027\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0196 - val_loss: 0.0022\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 0.0175 - val_loss: 0.0042\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0155 - val_loss: 0.0030\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0144 - val_loss: 0.0025\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 536us/step - loss: 0.0147 - val_loss: 0.0053\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0132 - val_loss: 0.0037\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0127 - val_loss: 0.0046\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0122 - val_loss: 0.0043\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0112 - val_loss: 0.0031\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0107 - val_loss: 0.0044\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0102 - val_loss: 0.0033\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 535us/step - loss: 0.0101 - val_loss: 0.0044\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 536us/step - loss: 0.0097 - val_loss: 0.0059\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0096 - val_loss: 0.0065\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0091 - val_loss: 0.0032\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 535us/step - loss: 0.0090 - val_loss: 0.0052\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0088 - val_loss: 0.0044\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0086 - val_loss: 0.0043\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.0087 - val_loss: 0.0058\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 3s 841us/step - loss: 0.8776 - val_loss: 0.1049\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 536us/step - loss: 0.0453 - val_loss: 0.0295\n",
      "Epoch 3/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 2s 539us/step - loss: 0.0226 - val_loss: 0.0097\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0116 - val_loss: 0.0036\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.0069 - val_loss: 0.0031\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0056 - val_loss: 0.0028\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0044 - val_loss: 0.0011\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0041 - val_loss: 0.0016\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 535us/step - loss: 0.0036 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0035 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0033 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0033 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0032 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 536us/step - loss: 0.0030 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 535us/step - loss: 0.0029 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 535us/step - loss: 0.0028 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0028 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 536us/step - loss: 0.0028 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 535us/step - loss: 0.0027 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0027 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0024 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 540us/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0026 - val_loss: 0.0013\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0025 - val_loss: 0.0011\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 3s 853us/step - loss: 0.5290 - val_loss: 0.0058\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0600 - val_loss: 0.0054\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 535us/step - loss: 0.0180 - val_loss: 0.0181\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0082 - val_loss: 0.0021\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 535us/step - loss: 0.0057 - val_loss: 0.0015\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0044 - val_loss: 0.0025\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0035 - val_loss: 0.0020\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0031 - val_loss: 0.0019\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0030 - val_loss: 0.0017\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.0029 - val_loss: 0.0019\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0028 - val_loss: 0.0021\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0026 - val_loss: 0.0020\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0027 - val_loss: 0.0019\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 535us/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0026 - val_loss: 0.0013\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0026 - val_loss: 0.0015\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 536us/step - loss: 0.0025 - val_loss: 0.0015\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0024 - val_loss: 0.0015\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0024 - val_loss: 0.0015\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 535us/step - loss: 0.0024 - val_loss: 0.0015\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 3s 832us/step - loss: 0.0645 - val_loss: 0.0183\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0116 - val_loss: 0.0020\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 492us/step - loss: 0.0074 - val_loss: 0.0025\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 493us/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0031 - val_loss: 0.0050\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 492us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 494us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 491us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 3s 807us/step - loss: 0.0574 - val_loss: 0.0091\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 472us/step - loss: 0.0082 - val_loss: 0.0024\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 473us/step - loss: 0.0063 - val_loss: 0.0040\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 472us/step - loss: 0.0039 - val_loss: 0.0058\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 470us/step - loss: 0.0033 - val_loss: 0.0019\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 471us/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 474us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 8/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 2s 470us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 470us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 470us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 468us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 471us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 469us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 470us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 471us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 472us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 471us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 469us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 469us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 470us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 469us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 469us/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 468us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 475us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "\n",
      "GENERATION 1\n",
      "\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 2s 392us/step - loss: 0.1300 - val_loss: 0.0981\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 148us/step - loss: 0.0462 - val_loss: 0.0320\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 150us/step - loss: 0.0253 - val_loss: 0.0129\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 151us/step - loss: 0.0197 - val_loss: 0.0071\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 150us/step - loss: 0.0168 - val_loss: 0.0050\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 150us/step - loss: 0.0154 - val_loss: 0.0039\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 148us/step - loss: 0.0149 - val_loss: 0.0031\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 149us/step - loss: 0.0135 - val_loss: 0.0027\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 150us/step - loss: 0.0120 - val_loss: 0.0025\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 150us/step - loss: 0.0114 - val_loss: 0.0022\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 150us/step - loss: 0.0102 - val_loss: 0.0020\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 150us/step - loss: 0.0095 - val_loss: 0.0019\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 149us/step - loss: 0.0091 - val_loss: 0.0016\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 149us/step - loss: 0.0086 - val_loss: 0.0015\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 149us/step - loss: 0.0080 - val_loss: 0.0014\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 149us/step - loss: 0.0073 - val_loss: 0.0013\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 149us/step - loss: 0.0070 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 150us/step - loss: 0.0068 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 150us/step - loss: 0.0063 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 150us/step - loss: 0.0062 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 149us/step - loss: 0.0058 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 155us/step - loss: 0.0055 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 152us/step - loss: 0.0054 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 150us/step - loss: 0.0052 - val_loss: 0.0010\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 2s 442us/step - loss: 0.0634 - val_loss: 0.0035\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 153us/step - loss: 0.0148 - val_loss: 0.0043\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 151us/step - loss: 0.0059 - val_loss: 0.0019\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 152us/step - loss: 0.0046 - val_loss: 0.0062\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 153us/step - loss: 0.0037 - val_loss: 0.0013\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 152us/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 151us/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 151us/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 152us/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 152us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 152us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 152us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 151us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 154us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 152us/step - loss: 0.0013 - val_loss: 9.5907e-04\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 153us/step - loss: 0.0013 - val_loss: 8.6888e-04\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 152us/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 154us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 157us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 150us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 152us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 151us/step - loss: 0.0011 - val_loss: 8.4360e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 151us/step - loss: 0.0011 - val_loss: 9.4655e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 152us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 3s 683us/step - loss: 0.0527 - val_loss: 0.0193\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 316us/step - loss: 0.0103 - val_loss: 0.0031\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 319us/step - loss: 0.0057 - val_loss: 0.0125\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 316us/step - loss: 0.0045 - val_loss: 0.0018\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 317us/step - loss: 0.0036 - val_loss: 0.0023\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 316us/step - loss: 0.0030 - val_loss: 0.0041\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 319us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 316us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 314us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 315us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 316us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 315us/step - loss: 0.0018 - val_loss: 0.0016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 314us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 315us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 317us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 314us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 314us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 316us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 316us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 319us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 315us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 316us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 316us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 315us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 3s 684us/step - loss: 0.0577 - val_loss: 0.0187\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 313us/step - loss: 0.0095 - val_loss: 0.0087\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 313us/step - loss: 0.0050 - val_loss: 0.0028\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 314us/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 316us/step - loss: 0.0029 - val_loss: 0.0017\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 315us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 315us/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 314us/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 314us/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 314us/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 315us/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 313us/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 314us/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 313us/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 314us/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 315us/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 315us/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 328us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 313us/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 313us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 313us/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 316us/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 314us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 321us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 3s 697us/step - loss: 161036.9471 - val_loss: 13.6218\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 314us/step - loss: 13.5059 - val_loss: 24.7410\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 320us/step - loss: 18.8585 - val_loss: 25.7734\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 314us/step - loss: 18.1989 - val_loss: 22.7806\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 312us/step - loss: 15.8153 - val_loss: 19.1083\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 313us/step - loss: 13.1582 - val_loss: 15.8636\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 322us/step - loss: 10.8893 - val_loss: 13.1769\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 332us/step - loss: 9.0287 - val_loss: 10.9008\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 335us/step - loss: 7.4403 - val_loss: 8.8238\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 334us/step - loss: 5.9200 - val_loss: 6.7039\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 336us/step - loss: 4.2374 - val_loss: 4.3161\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 323us/step - loss: 2.4385 - val_loss: 1.5724\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 328us/step - loss: 0.5144 - val_loss: 0.0604\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 315us/step - loss: 0.3192 - val_loss: 0.3024\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 316us/step - loss: 0.1231 - val_loss: 0.0338\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 318us/step - loss: 0.1083 - val_loss: 0.0751\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 314us/step - loss: 0.0815 - val_loss: 0.0032\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 314us/step - loss: 0.0560 - val_loss: 0.0161\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 316us/step - loss: 0.0614 - val_loss: 0.0039\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 316us/step - loss: 0.0530 - val_loss: 0.0033\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 314us/step - loss: 0.0504 - val_loss: 0.0029\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 315us/step - loss: 0.0517 - val_loss: 0.0030\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 315us/step - loss: 0.0503 - val_loss: 0.0031\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 316us/step - loss: 0.0528 - val_loss: 0.0028\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 4s 976us/step - loss: 20408.7513 - val_loss: 2.7851\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 536us/step - loss: 6.4265 - val_loss: 1.8853\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 544us/step - loss: 2.7146 - val_loss: 1.0506\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 539us/step - loss: 1.4041 - val_loss: 0.5826\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 537us/step - loss: 0.9777 - val_loss: 0.3639\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 541us/step - loss: 0.6429 - val_loss: 0.2713\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 539us/step - loss: 0.5557 - val_loss: 0.2029\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 541us/step - loss: 0.4342 - val_loss: 0.1480\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.4307 - val_loss: 0.1302\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 540us/step - loss: 0.3464 - val_loss: 0.1068\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 539us/step - loss: 0.3036 - val_loss: 0.0839\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.2965 - val_loss: 0.0723\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.2741 - val_loss: 0.0644\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 537us/step - loss: 0.2452 - val_loss: 0.0524\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 544us/step - loss: 0.2509 - val_loss: 0.0509\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 539us/step - loss: 0.2276 - val_loss: 0.0388\n",
      "Epoch 17/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 2s 539us/step - loss: 0.2162 - val_loss: 0.0486\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 540us/step - loss: 0.2063 - val_loss: 0.0513\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.1907 - val_loss: 0.0391\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 539us/step - loss: 0.2044 - val_loss: 0.0558\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 537us/step - loss: 0.1792 - val_loss: 0.0381\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 537us/step - loss: 0.1813 - val_loss: 0.0372\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 540us/step - loss: 0.1707 - val_loss: 0.0380\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.1648 - val_loss: 0.0304\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 4s 880us/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 413us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 411us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 410us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 414us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 412us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 412us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 411us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 412us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 412us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 410us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 412us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 412us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 412us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 416us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 411us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 412us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 411us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 411us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 411us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 412us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 412us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 411us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 415us/step - loss: nan - val_loss: nan\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 3s 853us/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 411us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 410us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 413us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 410us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 413us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 413us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 412us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 412us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 411us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 413us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 410us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 411us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 409us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 412us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 416us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 414us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 411us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 408us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 411us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 409us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 411us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 408us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 412us/step - loss: nan - val_loss: nan\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 4s 897us/step - loss: 0.3930 - val_loss: 0.0017\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 411us/step - loss: 0.0055 - val_loss: 0.0017\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 410us/step - loss: 0.0080 - val_loss: 0.0354\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 411us/step - loss: 0.0120 - val_loss: 0.0056\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 411us/step - loss: 0.0171 - val_loss: 0.0166\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 411us/step - loss: 0.0152 - val_loss: 0.0137\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 412us/step - loss: 0.0180 - val_loss: 0.0272\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 413us/step - loss: 0.0161 - val_loss: 0.0348\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 412us/step - loss: 0.0250 - val_loss: 0.0071\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 412us/step - loss: 0.0065 - val_loss: 0.0223\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 410us/step - loss: 0.0158 - val_loss: 0.0213\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 409us/step - loss: 0.0220 - val_loss: 0.0020\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 410us/step - loss: 0.0047 - val_loss: 0.0213\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 409us/step - loss: 0.0127 - val_loss: 0.0177\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 412us/step - loss: 0.0171 - val_loss: 0.0046\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 411us/step - loss: 0.0054 - val_loss: 0.0139\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 411us/step - loss: 0.0120 - val_loss: 0.0149\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 411us/step - loss: 0.0084 - val_loss: 0.0035\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 410us/step - loss: 0.0094 - val_loss: 0.0200\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 410us/step - loss: 0.0098 - val_loss: 0.0015\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 411us/step - loss: 0.0058 - val_loss: 0.0176\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 411us/step - loss: 0.0118 - val_loss: 0.0056\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 410us/step - loss: 0.0047 - val_loss: 0.0096\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 408us/step - loss: 0.0093 - val_loss: 0.0151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GENERATION 2\n",
      "\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 3s 640us/step - loss: 0.0545 - val_loss: 0.0138\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 233us/step - loss: 0.0078 - val_loss: 0.0089\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 233us/step - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 235us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 232us/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 232us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 235us/step - loss: 0.0015 - val_loss: 8.8187e-04\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 234us/step - loss: 0.0015 - val_loss: 8.6565e-04\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 232us/step - loss: 0.0014 - val_loss: 8.9501e-04\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 232us/step - loss: 0.0014 - val_loss: 8.4131e-04\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 234us/step - loss: 0.0013 - val_loss: 8.2766e-04\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 234us/step - loss: 0.0013 - val_loss: 8.2529e-04\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 233us/step - loss: 0.0013 - val_loss: 8.5187e-04\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 233us/step - loss: 0.0013 - val_loss: 7.6049e-04\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 232us/step - loss: 0.0012 - val_loss: 7.7515e-04\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 232us/step - loss: 0.0012 - val_loss: 7.8605e-04\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 232us/step - loss: 0.0012 - val_loss: 7.4574e-04\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 233us/step - loss: 0.0011 - val_loss: 7.0960e-04\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 233us/step - loss: 0.0011 - val_loss: 6.9750e-04\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 233us/step - loss: 0.0011 - val_loss: 6.6373e-04\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 238us/step - loss: 0.0011 - val_loss: 7.8316e-04\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 231us/step - loss: 0.0010 - val_loss: 7.4552e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 233us/step - loss: 0.0010 - val_loss: 6.2485e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 233us/step - loss: 9.5644e-04 - val_loss: 6.1842e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 2s 600us/step - loss: 0.0782 - val_loss: 0.0089\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 162us/step - loss: 0.0084 - val_loss: 0.0019\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 162us/step - loss: 0.0041 - val_loss: 0.0013\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 164us/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 164us/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 155us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 154us/step - loss: 0.0017 - val_loss: 9.8079e-04\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 155us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 161us/step - loss: 0.0017 - val_loss: 9.5832e-04\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 160us/step - loss: 0.0016 - val_loss: 9.3456e-04\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 155us/step - loss: 0.0015 - val_loss: 9.7920e-04\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 157us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 162us/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 157us/step - loss: 0.0014 - val_loss: 9.4918e-04\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 162us/step - loss: 0.0012 - val_loss: 9.1025e-04\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 156us/step - loss: 0.0012 - val_loss: 8.8487e-04\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 157us/step - loss: 0.0012 - val_loss: 9.1691e-04\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 159us/step - loss: 0.0012 - val_loss: 9.8417e-04\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 158us/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 157us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 161us/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 159us/step - loss: 9.4922e-04 - val_loss: 0.0020\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 159us/step - loss: 9.5758e-04 - val_loss: 0.0013\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 154us/step - loss: 9.3971e-04 - val_loss: 0.0018\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 4s 1ms/step - loss: 0.1705 - val_loss: 0.0023\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 501us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 499us/step - loss: 0.0081 - val_loss: 0.0031\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 501us/step - loss: 0.0074 - val_loss: 0.0135\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 506us/step - loss: 0.0088 - val_loss: 0.0133\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 506us/step - loss: 0.0108 - val_loss: 0.0176\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 501us/step - loss: 0.0105 - val_loss: 0.0137\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 502us/step - loss: 0.0101 - val_loss: 0.0114\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 499us/step - loss: 0.0092 - val_loss: 0.0114\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 505us/step - loss: 0.0087 - val_loss: 0.0149\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 503us/step - loss: 0.0092 - val_loss: 0.0103\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 503us/step - loss: 0.0078 - val_loss: 0.0052\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 504us/step - loss: 0.0070 - val_loss: 0.0147\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 505us/step - loss: 0.0082 - val_loss: 0.0041\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 502us/step - loss: 0.0067 - val_loss: 0.0103\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 500us/step - loss: 0.0060 - val_loss: 0.0070\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 501us/step - loss: 0.0070 - val_loss: 0.0048\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 504us/step - loss: 0.0051 - val_loss: 0.0089\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 502us/step - loss: 0.0073 - val_loss: 0.0030\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 503us/step - loss: 0.0044 - val_loss: 0.0105\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 500us/step - loss: 0.0060 - val_loss: 0.0037\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 501us/step - loss: 0.0050 - val_loss: 0.0091\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 502us/step - loss: 0.0055 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 504us/step - loss: 0.0047 - val_loss: 0.0070\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 4s 1ms/step - loss: 0.0747 - val_loss: 0.0112\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 492us/step - loss: 0.0213 - val_loss: 0.0048\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0119 - val_loss: 0.0030\n",
      "Epoch 4/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 2s 494us/step - loss: 0.0074 - val_loss: 0.0022\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0052 - val_loss: 0.0021\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0043 - val_loss: 0.0023\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0039 - val_loss: 0.0024\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0037 - val_loss: 0.0024\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0037 - val_loss: 0.0024\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0037 - val_loss: 0.0026\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 492us/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 491us/step - loss: 0.0035 - val_loss: 0.0026\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 494us/step - loss: 0.0034 - val_loss: 0.0028\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 491us/step - loss: 0.0034 - val_loss: 0.0025\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0033 - val_loss: 0.0025\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0035 - val_loss: 0.0027\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0034 - val_loss: 0.0026\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0032 - val_loss: 0.0026\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0033 - val_loss: 0.0026\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 493us/step - loss: 0.0032 - val_loss: 0.0025\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 4s 1ms/step - loss: 0.0536 - val_loss: 0.0072\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0088 - val_loss: 0.0030\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 491us/step - loss: 0.0040 - val_loss: 0.0015\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0034 - val_loss: 0.0047\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 491us/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 491us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 493us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 495us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 493us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 492us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 492us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0014 - val_loss: 9.9986e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 491us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0013 - val_loss: 9.7989e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 4s 1ms/step - loss: 0.0570 - val_loss: 0.0129\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 502us/step - loss: 0.0089 - val_loss: 0.0036\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 499us/step - loss: 0.0057 - val_loss: 0.0094\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 497us/step - loss: 0.0034 - val_loss: 0.0056\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 498us/step - loss: 0.0028 - val_loss: 0.0015\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 499us/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 497us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 500us/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 497us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 502us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 500us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 497us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 499us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 499us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 500us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 499us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 498us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 503us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 501us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 502us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 501us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 498us/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 499us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 499us/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 5s 1ms/step - loss: 0.0795 - val_loss: 0.0154\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 500us/step - loss: 0.0123 - val_loss: 0.0036\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 501us/step - loss: 0.0068 - val_loss: 0.0168\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 501us/step - loss: 0.0048 - val_loss: 0.0018\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 499us/step - loss: 0.0034 - val_loss: 0.0016\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 504us/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 499us/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 500us/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 9/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 2s 501us/step - loss: 0.0025 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 497us/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 500us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 498us/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 498us/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 500us/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 499us/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 498us/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 502us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 501us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 500us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 499us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 499us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 503us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 500us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 497us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 5s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 501us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 501us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 500us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 501us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 500us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 501us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 500us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 502us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 501us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 501us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 499us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 500us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 500us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 499us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 500us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 510us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 500us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 501us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 497us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 504us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 497us/step - loss: nan - val_loss: nan\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 4s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 392us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 391us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 393us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 393us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 392us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 392us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 394us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 393us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 393us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 393us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 391us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 394us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 392us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 395us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 392us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 393us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 394us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 395us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 393us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 392us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 391us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 392us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 392us/step - loss: nan - val_loss: nan\n",
      "\n",
      "GENERATION 3\n",
      "\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 3s 855us/step - loss: 0.0744 - val_loss: 0.0043\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 234us/step - loss: 0.0088 - val_loss: 0.0025\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 233us/step - loss: 0.0041 - val_loss: 0.0015\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 234us/step - loss: 0.0025 - val_loss: 0.0012\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 232us/step - loss: 0.0018 - val_loss: 7.1692e-04\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 234us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 235us/step - loss: 0.0014 - val_loss: 7.0445e-04\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 233us/step - loss: 0.0013 - val_loss: 8.0477e-04\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 233us/step - loss: 0.0013 - val_loss: 6.9124e-04\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 233us/step - loss: 0.0012 - val_loss: 6.9070e-04\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 234us/step - loss: 0.0013 - val_loss: 6.9274e-04\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 231us/step - loss: 0.0012 - val_loss: 6.6797e-04\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 233us/step - loss: 0.0011 - val_loss: 6.6132e-04\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 232us/step - loss: 0.0011 - val_loss: 6.5659e-04\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 233us/step - loss: 0.0011 - val_loss: 6.5241e-04\n",
      "Epoch 16/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 1s 235us/step - loss: 0.0011 - val_loss: 7.1104e-04\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 233us/step - loss: 0.0011 - val_loss: 7.1045e-04\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 234us/step - loss: 0.0010 - val_loss: 6.8170e-04\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 234us/step - loss: 9.9947e-04 - val_loss: 6.2826e-04\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 233us/step - loss: 0.0010 - val_loss: 6.2032e-04\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 233us/step - loss: 9.9175e-04 - val_loss: 6.2001e-04\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 233us/step - loss: 9.9234e-04 - val_loss: 6.0169e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 233us/step - loss: 9.9208e-04 - val_loss: 5.9948e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 233us/step - loss: 9.5513e-04 - val_loss: 6.5638e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 3s 844us/step - loss: 0.0694 - val_loss: 0.0081\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 233us/step - loss: 0.0099 - val_loss: 0.0025\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 231us/step - loss: 0.0041 - val_loss: 0.0012\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 232us/step - loss: 0.0027 - val_loss: 0.0011\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 235us/step - loss: 0.0020 - val_loss: 0.0010\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 231us/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 231us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 231us/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 233us/step - loss: 0.0016 - val_loss: 9.1919e-04\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 232us/step - loss: 0.0015 - val_loss: 9.6065e-04\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 231us/step - loss: 0.0015 - val_loss: 9.1398e-04\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 233us/step - loss: 0.0014 - val_loss: 8.6357e-04\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 233us/step - loss: 0.0014 - val_loss: 8.4546e-04\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 232us/step - loss: 0.0013 - val_loss: 7.9766e-04\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 232us/step - loss: 0.0013 - val_loss: 7.4981e-04\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 231us/step - loss: 0.0012 - val_loss: 7.3622e-04\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 232us/step - loss: 0.0012 - val_loss: 7.4989e-04\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 232us/step - loss: 0.0012 - val_loss: 6.9743e-04\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 232us/step - loss: 0.0011 - val_loss: 6.7990e-04\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 232us/step - loss: 0.0011 - val_loss: 6.6384e-04\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 232us/step - loss: 0.0010 - val_loss: 6.4658e-04\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 235us/step - loss: 0.0011 - val_loss: 6.2332e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 232us/step - loss: 0.0010 - val_loss: 7.2791e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 231us/step - loss: 0.0010 - val_loss: 6.9438e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 4s 916us/step - loss: 0.0690 - val_loss: 0.0161\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 245us/step - loss: 0.0105 - val_loss: 0.0098\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 246us/step - loss: 0.0050 - val_loss: 0.0040\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 245us/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 244us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 244us/step - loss: 0.0015 - val_loss: 8.7575e-04\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 249us/step - loss: 0.0014 - val_loss: 8.5401e-04\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 247us/step - loss: 0.0013 - val_loss: 7.8164e-04\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 245us/step - loss: 0.0012 - val_loss: 7.6248e-04\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 246us/step - loss: 0.0011 - val_loss: 7.2965e-04\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 246us/step - loss: 0.0011 - val_loss: 6.8169e-04\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 246us/step - loss: 0.0011 - val_loss: 6.5023e-04\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 245us/step - loss: 9.8781e-04 - val_loss: 7.5225e-04\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 246us/step - loss: 9.6607e-04 - val_loss: 7.3231e-04\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 244us/step - loss: 8.8836e-04 - val_loss: 6.4377e-04\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 245us/step - loss: 8.6348e-04 - val_loss: 9.1092e-04\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 246us/step - loss: 8.6964e-04 - val_loss: 8.1502e-04\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 245us/step - loss: 8.0943e-04 - val_loss: 6.8056e-04\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 244us/step - loss: 8.1318e-04 - val_loss: 8.7995e-04\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 244us/step - loss: 8.0089e-04 - val_loss: 8.6680e-04\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 246us/step - loss: 7.7263e-04 - val_loss: 9.5597e-04\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 244us/step - loss: 7.4269e-04 - val_loss: 8.3386e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 246us/step - loss: 7.5428e-04 - val_loss: 9.8180e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 248us/step - loss: 7.5300e-04 - val_loss: 9.4276e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 4s 936us/step - loss: 0.0931 - val_loss: 0.0060\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 245us/step - loss: 0.0144 - val_loss: 0.0012\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 246us/step - loss: 0.0062 - val_loss: 0.0034\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 245us/step - loss: 0.0039 - val_loss: 0.0025\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 245us/step - loss: 0.0023 - val_loss: 0.0013\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 245us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 245us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 247us/step - loss: 0.0015 - val_loss: 9.1647e-04\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 248us/step - loss: 0.0014 - val_loss: 8.9924e-04\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 243us/step - loss: 0.0013 - val_loss: 8.6747e-04\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 245us/step - loss: 0.0013 - val_loss: 8.4568e-04\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 245us/step - loss: 0.0012 - val_loss: 7.9861e-04\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 245us/step - loss: 0.0011 - val_loss: 7.6974e-04\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 245us/step - loss: 0.0011 - val_loss: 7.3031e-04\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 245us/step - loss: 0.0010 - val_loss: 9.1467e-04\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 246us/step - loss: 0.0010 - val_loss: 7.2114e-04\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 246us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 18/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 1s 245us/step - loss: 9.9373e-04 - val_loss: 7.2133e-04\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 246us/step - loss: 0.0010 - val_loss: 6.7694e-04\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 243us/step - loss: 9.2497e-04 - val_loss: 9.5211e-04\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 246us/step - loss: 8.4436e-04 - val_loss: 0.0010\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 247us/step - loss: 8.6682e-04 - val_loss: 7.5983e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 245us/step - loss: 8.4045e-04 - val_loss: 0.0014\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 246us/step - loss: 8.1262e-04 - val_loss: 0.0011\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 4s 976us/step - loss: 0.1241 - val_loss: 0.0034\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 241us/step - loss: 0.0183 - val_loss: 0.0035\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 240us/step - loss: 0.0116 - val_loss: 0.0102\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 240us/step - loss: 0.0067 - val_loss: 0.0023\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 241us/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 241us/step - loss: 0.0039 - val_loss: 9.7334e-04\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 240us/step - loss: 0.0033 - val_loss: 0.0028\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 241us/step - loss: 0.0029 - val_loss: 8.6153e-04\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 243us/step - loss: 0.0029 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 243us/step - loss: 0.0025 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 241us/step - loss: 0.0023 - val_loss: 8.2377e-04\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 243us/step - loss: 0.0023 - val_loss: 9.8547e-04\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 241us/step - loss: 0.0021 - val_loss: 9.0033e-04\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 240us/step - loss: 0.0020 - val_loss: 7.8285e-04\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 240us/step - loss: 0.0019 - val_loss: 8.6732e-04\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 241us/step - loss: 0.0019 - val_loss: 8.1948e-04\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 240us/step - loss: 0.0017 - val_loss: 7.8244e-04\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 240us/step - loss: 0.0016 - val_loss: 7.0376e-04\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 240us/step - loss: 0.0016 - val_loss: 7.0425e-04\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 241us/step - loss: 0.0016 - val_loss: 6.8896e-04\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 241us/step - loss: 0.0015 - val_loss: 6.8783e-04\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 240us/step - loss: 0.0015 - val_loss: 6.8129e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 240us/step - loss: 0.0014 - val_loss: 6.7267e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 240us/step - loss: 0.0013 - val_loss: 6.7838e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 4s 959us/step - loss: 0.1904 - val_loss: 0.0928\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 242us/step - loss: 0.0312 - val_loss: 0.0434\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 241us/step - loss: 0.0130 - val_loss: 0.0107\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 242us/step - loss: 0.0077 - val_loss: 0.0107\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 241us/step - loss: 0.0053 - val_loss: 0.0011\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 241us/step - loss: 0.0039 - val_loss: 0.0029\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 240us/step - loss: 0.0032 - val_loss: 0.0016\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 242us/step - loss: 0.0029 - val_loss: 0.0018\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 241us/step - loss: 0.0028 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 241us/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 247us/step - loss: 0.0024 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 241us/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 240us/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 241us/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 241us/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 241us/step - loss: 0.0020 - val_loss: 0.0010\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 241us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 241us/step - loss: 0.0019 - val_loss: 9.4255e-04\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 242us/step - loss: 0.0018 - val_loss: 8.4287e-04\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 241us/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 242us/step - loss: 0.0017 - val_loss: 8.2761e-04\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 240us/step - loss: 0.0016 - val_loss: 8.4199e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 241us/step - loss: 0.0016 - val_loss: 8.0220e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 242us/step - loss: 0.0016 - val_loss: 7.8602e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 4s 988us/step - loss: 0.8807 - val_loss: 0.1879\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 242us/step - loss: 0.0697 - val_loss: 0.0533\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 241us/step - loss: 0.0188 - val_loss: 0.0318\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 242us/step - loss: 0.0155 - val_loss: 0.0011\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 241us/step - loss: 0.0059 - val_loss: 0.0094\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 241us/step - loss: 0.0039 - val_loss: 8.7653e-04\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 243us/step - loss: 0.0034 - val_loss: 7.9388e-04\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 243us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 241us/step - loss: 0.0025 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 241us/step - loss: 0.0024 - val_loss: 8.8834e-04\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 241us/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 246us/step - loss: 0.0023 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 241us/step - loss: 0.0021 - val_loss: 9.9370e-04\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 242us/step - loss: 0.0022 - val_loss: 0.0010\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 241us/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 240us/step - loss: 0.0021 - val_loss: 0.0010\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 244us/step - loss: 0.0021 - val_loss: 9.5884e-04\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 243us/step - loss: 0.0020 - val_loss: 9.5015e-04\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 242us/step - loss: 0.0020 - val_loss: 9.2730e-04\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 241us/step - loss: 0.0021 - val_loss: 9.2903e-04\n",
      "Epoch 21/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 1s 242us/step - loss: 0.0019 - val_loss: 8.9495e-04\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 240us/step - loss: 0.0019 - val_loss: 8.8176e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 241us/step - loss: 0.0018 - val_loss: 8.4842e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 240us/step - loss: 0.0019 - val_loss: 8.7623e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 5s 1ms/step - loss: 0.6423 - val_loss: 0.0100\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 537us/step - loss: 0.0274 - val_loss: 0.0020\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 540us/step - loss: 0.0117 - val_loss: 0.0015\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 540us/step - loss: 0.0056 - val_loss: 0.0080\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 545us/step - loss: 0.0040 - val_loss: 0.0014\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.0037 - val_loss: 0.0027\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 541us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 541us/step - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 537us/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 544us/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 554us/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 536us/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 540us/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 539us/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 540us/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 540us/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 540us/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 539us/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 539us/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 542us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 539us/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 540us/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 6s 1ms/step - loss: 0.1245 - val_loss: 0.0018\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 544us/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 540us/step - loss: 0.0048 - val_loss: 0.0086\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 540us/step - loss: 0.0031 - val_loss: 0.0018\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 541us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 539us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 539us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 540us/step - loss: 0.0019 - val_loss: 0.0031\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 539us/step - loss: 0.0076 - val_loss: 0.0058\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 541us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 541us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 540us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 540us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 540us/step - loss: 0.0020 - val_loss: 0.0050\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 540us/step - loss: 0.0051 - val_loss: 0.0074\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 541us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 540us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 541us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 542us/step - loss: 0.0023 - val_loss: 0.0049\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 542us/step - loss: 0.0027 - val_loss: 0.0044\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 540us/step - loss: 0.0038 - val_loss: 0.0067\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.0036 - val_loss: 0.0042\n",
      "\n",
      "GENERATION 4\n",
      "\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 4s 949us/step - loss: 0.5236 - val_loss: 0.0878\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 155us/step - loss: 0.0910 - val_loss: 0.0020\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 157us/step - loss: 0.0252 - val_loss: 0.0358\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 156us/step - loss: 0.0269 - val_loss: 0.0087\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 156us/step - loss: 0.0178 - val_loss: 0.0014\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 155us/step - loss: 0.0103 - val_loss: 0.0017\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 155us/step - loss: 0.0028 - val_loss: 0.0018\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 155us/step - loss: 0.0028 - val_loss: 0.0018\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 155us/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 155us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 155us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 155us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 154us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 155us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 155us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 156us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 155us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 157us/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 156us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 156us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 155us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 156us/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 154us/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 155us/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 4s 1ms/step - loss: 0.0477 - val_loss: 0.0135\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 234us/step - loss: 0.0070 - val_loss: 0.0068\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 233us/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 234us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 233us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 235us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 234us/step - loss: 0.0014 - val_loss: 8.7018e-04\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 233us/step - loss: 0.0014 - val_loss: 8.6553e-04\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 234us/step - loss: 0.0014 - val_loss: 8.3919e-04\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 233us/step - loss: 0.0013 - val_loss: 8.3900e-04\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 232us/step - loss: 0.0013 - val_loss: 8.0654e-04\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 238us/step - loss: 0.0013 - val_loss: 7.9567e-04\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 234us/step - loss: 0.0012 - val_loss: 8.1970e-04\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 234us/step - loss: 0.0012 - val_loss: 7.9644e-04\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 233us/step - loss: 0.0012 - val_loss: 7.9075e-04\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 233us/step - loss: 0.0012 - val_loss: 7.5297e-04\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 234us/step - loss: 0.0011 - val_loss: 7.3605e-04\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 234us/step - loss: 0.0011 - val_loss: 7.2958e-04\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 233us/step - loss: 0.0011 - val_loss: 7.5860e-04\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 234us/step - loss: 0.0011 - val_loss: 7.5819e-04\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 233us/step - loss: 0.0010 - val_loss: 8.0803e-04\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 232us/step - loss: 0.0010 - val_loss: 7.7318e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 234us/step - loss: 0.0010 - val_loss: 7.5638e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 233us/step - loss: 9.8761e-04 - val_loss: 7.4087e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 4s 1ms/step - loss: 0.0704 - val_loss: 0.0099\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 193us/step - loss: 0.0090 - val_loss: 0.0016\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 193us/step - loss: 0.0043 - val_loss: 0.0020\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 193us/step - loss: 0.0027 - val_loss: 0.0016\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 193us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 193us/step - loss: 0.0018 - val_loss: 8.8386e-04\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 194us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 194us/step - loss: 0.0016 - val_loss: 9.4174e-04\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 193us/step - loss: 0.0015 - val_loss: 8.5504e-04\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 192us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 193us/step - loss: 0.0014 - val_loss: 8.2544e-04\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 193us/step - loss: 0.0014 - val_loss: 8.0184e-04\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 194us/step - loss: 0.0013 - val_loss: 7.8441e-04\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 193us/step - loss: 0.0012 - val_loss: 7.6780e-04\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 195us/step - loss: 0.0012 - val_loss: 7.5476e-04\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 196us/step - loss: 0.0012 - val_loss: 7.4791e-04\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 193us/step - loss: 0.0012 - val_loss: 7.2016e-04\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 193us/step - loss: 0.0012 - val_loss: 7.1199e-04\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 193us/step - loss: 0.0011 - val_loss: 6.8949e-04\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 192us/step - loss: 0.0010 - val_loss: 6.5748e-04\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 193us/step - loss: 0.0011 - val_loss: 6.4691e-04\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 193us/step - loss: 0.0010 - val_loss: 6.7131e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 194us/step - loss: 9.8075e-04 - val_loss: 7.0711e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 195us/step - loss: 9.3594e-04 - val_loss: 7.3938e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 4s 1ms/step - loss: 0.1531 - val_loss: 0.0348\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 194us/step - loss: 0.0199 - val_loss: 0.0206\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 195us/step - loss: 0.0093 - val_loss: 0.0065\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 195us/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 194us/step - loss: 0.0034 - val_loss: 0.0019\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 195us/step - loss: 0.0026 - val_loss: 0.0015\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 193us/step - loss: 0.0024 - val_loss: 9.9272e-04\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 195us/step - loss: 0.0022 - val_loss: 9.9313e-04\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 194us/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 194us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 194us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 194us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 195us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 195us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 194us/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 195us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 194us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 195us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 193us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 195us/step - loss: 0.0013 - val_loss: 0.0025\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 196us/step - loss: 0.0013 - val_loss: 0.0026\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 195us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 195us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 193us/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 6s 1ms/step - loss: 0.1158 - val_loss: 0.0026\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 416us/step - loss: 0.0184 - val_loss: 0.0073\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 414us/step - loss: 0.0097 - val_loss: 0.0090\n",
      "Epoch 4/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 2s 413us/step - loss: 0.0067 - val_loss: 0.0037\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 416us/step - loss: 0.0043 - val_loss: 0.0020\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 416us/step - loss: 0.0038 - val_loss: 0.0027\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 415us/step - loss: 0.0034 - val_loss: 0.0021\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 415us/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 414us/step - loss: 0.0030 - val_loss: 0.0019\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 413us/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 412us/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 415us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 413us/step - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 414us/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 412us/step - loss: 0.0025 - val_loss: 0.0043\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 416us/step - loss: 0.0023 - val_loss: 0.0041\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 416us/step - loss: 0.0023 - val_loss: 0.0041\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 412us/step - loss: 0.0022 - val_loss: 0.0047\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 415us/step - loss: 0.0022 - val_loss: 0.0065\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 415us/step - loss: 0.0022 - val_loss: 0.0087\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 416us/step - loss: 0.0022 - val_loss: 0.0047\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 417us/step - loss: 0.0021 - val_loss: 0.0065\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 415us/step - loss: 0.0020 - val_loss: 0.0073\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 417us/step - loss: 0.0020 - val_loss: 0.0080\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 6s 1ms/step - loss: 0.0777 - val_loss: 0.0385\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 416us/step - loss: 0.0157 - val_loss: 0.0052\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 415us/step - loss: 0.0069 - val_loss: 0.0041\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 411us/step - loss: 0.0051 - val_loss: 0.0019\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 412us/step - loss: 0.0045 - val_loss: 0.0057\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 411us/step - loss: 0.0036 - val_loss: 0.0014\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 413us/step - loss: 0.0032 - val_loss: 0.0017\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 413us/step - loss: 0.0030 - val_loss: 0.0026\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 414us/step - loss: 0.0031 - val_loss: 0.0020\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 411us/step - loss: 0.0030 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 415us/step - loss: 0.0028 - val_loss: 0.0017\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 414us/step - loss: 0.0028 - val_loss: 0.0019\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 411us/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 411us/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 413us/step - loss: 0.0026 - val_loss: 0.0015\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 413us/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 412us/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 413us/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 417us/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 414us/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 414us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 413us/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 412us/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 414us/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 6s 1ms/step - loss: 0.0584 - val_loss: 0.0159\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 415us/step - loss: 0.0102 - val_loss: 0.0021\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 415us/step - loss: 0.0063 - val_loss: 0.0092\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 412us/step - loss: 0.0044 - val_loss: 0.0015\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 415us/step - loss: 0.0033 - val_loss: 0.0027\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 413us/step - loss: 0.0029 - val_loss: 0.0026\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 413us/step - loss: 0.0028 - val_loss: 0.0015\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 412us/step - loss: 0.0027 - val_loss: 0.0019\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 416us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 414us/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 413us/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 412us/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 413us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 411us/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 411us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 411us/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 414us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 412us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 416us/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 411us/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 411us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 414us/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 411us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 412us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 6s 1ms/step - loss: 0.0523 - val_loss: 0.0152\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 328us/step - loss: 0.0098 - val_loss: 0.0017\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 326us/step - loss: 0.0057 - val_loss: 0.0094\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 326us/step - loss: 0.0041 - val_loss: 0.0017\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 327us/step - loss: 0.0031 - val_loss: 0.0041\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 326us/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 325us/step - loss: 0.0024 - val_loss: 0.0015\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 326us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 9/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 1s 330us/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 329us/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 327us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 327us/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 327us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 328us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 325us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 326us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 326us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 326us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 327us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 326us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 325us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 327us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 325us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 325us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 6s 2ms/step - loss: 0.1134 - val_loss: 0.0165\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 413us/step - loss: 0.0113 - val_loss: 0.0041\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 415us/step - loss: 0.0061 - val_loss: 0.0045\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 415us/step - loss: 0.0037 - val_loss: 0.0052\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 414us/step - loss: 0.0030 - val_loss: 0.0014\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 412us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 412us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 410us/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 411us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 413us/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 413us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 413us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 412us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 412us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 410us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 411us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 413us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 412us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 411us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 413us/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 415us/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 412us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 413us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 412us/step - loss: 0.0020 - val_loss: 0.0016\n",
      "\n",
      "GENERATION 5\n",
      "\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 5s 1ms/step - loss: 0.0224 - val_loss: 0.0174\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 233us/step - loss: 0.0064 - val_loss: 0.0041\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 233us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 235us/step - loss: 0.0027 - val_loss: 0.0012\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 234us/step - loss: 0.0023 - val_loss: 8.7084e-04\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 233us/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 235us/step - loss: 0.0020 - val_loss: 8.1715e-04\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 234us/step - loss: 0.0018 - val_loss: 9.9388e-04\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 233us/step - loss: 0.0017 - val_loss: 9.3106e-04\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 234us/step - loss: 0.0017 - val_loss: 8.6501e-04\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 234us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 235us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 234us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 234us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 234us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 232us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 236us/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 234us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 234us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 233us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 235us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 235us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 234us/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 234us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 5s 1ms/step - loss: 0.0788 - val_loss: 0.0097\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 194us/step - loss: 0.0091 - val_loss: 0.0089\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 195us/step - loss: 0.0047 - val_loss: 0.0066\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 194us/step - loss: 0.0031 - val_loss: 0.0020\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 196us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 195us/step - loss: 0.0020 - val_loss: 8.7630e-04\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 195us/step - loss: 0.0018 - val_loss: 9.3549e-04\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 195us/step - loss: 0.0016 - val_loss: 8.9332e-04\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 195us/step - loss: 0.0016 - val_loss: 8.8908e-04\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 196us/step - loss: 0.0015 - val_loss: 8.5503e-04\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 194us/step - loss: 0.0014 - val_loss: 8.4702e-04\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 194us/step - loss: 0.0014 - val_loss: 8.2152e-04\n",
      "Epoch 13/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 1s 195us/step - loss: 0.0013 - val_loss: 8.5178e-04\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 196us/step - loss: 0.0014 - val_loss: 7.7135e-04\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 195us/step - loss: 0.0013 - val_loss: 7.4908e-04\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 195us/step - loss: 0.0013 - val_loss: 7.9965e-04\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 193us/step - loss: 0.0012 - val_loss: 8.0058e-04\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 197us/step - loss: 0.0012 - val_loss: 7.4712e-04\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 194us/step - loss: 0.0012 - val_loss: 7.3392e-04\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 196us/step - loss: 0.0011 - val_loss: 7.3274e-04\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 196us/step - loss: 0.0011 - val_loss: 7.4416e-04\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 197us/step - loss: 0.0011 - val_loss: 7.0755e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 195us/step - loss: 0.0011 - val_loss: 8.4159e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 194us/step - loss: 0.0010 - val_loss: 8.1836e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 6s 2ms/step - loss: 0.1909 - val_loss: 0.0039\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 414us/step - loss: 0.0419 - val_loss: 0.0369\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 415us/step - loss: 0.0177 - val_loss: 0.0122\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 415us/step - loss: 0.0070 - val_loss: 0.0027\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 413us/step - loss: 0.0049 - val_loss: 0.0033\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 416us/step - loss: 0.0042 - val_loss: 0.0020\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 414us/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 416us/step - loss: 0.0034 - val_loss: 0.0019\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 416us/step - loss: 0.0032 - val_loss: 0.0020\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 413us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 414us/step - loss: 0.0032 - val_loss: 0.0019\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 414us/step - loss: 0.0031 - val_loss: 0.0018\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 416us/step - loss: 0.0030 - val_loss: 0.0017\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 417us/step - loss: 0.0029 - val_loss: 0.0017\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 415us/step - loss: 0.0029 - val_loss: 0.0019\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 415us/step - loss: 0.0028 - val_loss: 0.0018\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 416us/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 413us/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 419us/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 417us/step - loss: 0.0027 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 416us/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 420us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 416us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 416us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 7s 2ms/step - loss: 0.0692 - val_loss: 0.0471\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 570us/step - loss: 0.0156 - val_loss: 0.0053\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 568us/step - loss: 0.0060 - val_loss: 0.0020\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 567us/step - loss: 0.0037 - val_loss: 0.0017\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 569us/step - loss: 0.0029 - val_loss: 0.0043\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 570us/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 565us/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 569us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 568us/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 569us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 567us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 572us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 568us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 569us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 573us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 566us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 570us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 567us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 571us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 568us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 567us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 568us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 567us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 576us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 7s 2ms/step - loss: 0.0544 - val_loss: 0.0132\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 567us/step - loss: 0.0078 - val_loss: 0.0084\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 567us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 569us/step - loss: 0.0031 - val_loss: 0.0024\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 568us/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 567us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 567us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 566us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 566us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 570us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 571us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 568us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 566us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 568us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 569us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 569us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 17/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 2s 570us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 571us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 572us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 569us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 570us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 571us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 570us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 572us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 8s 2ms/step - loss: 0.1034 - val_loss: 0.0506\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 570us/step - loss: 0.0253 - val_loss: 0.0288\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 569us/step - loss: 0.0110 - val_loss: 0.0022\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 570us/step - loss: 0.0055 - val_loss: 0.0037\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 569us/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 567us/step - loss: 0.0041 - val_loss: 0.0023\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 569us/step - loss: 0.0038 - val_loss: 0.0024\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 571us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 568us/step - loss: 0.0034 - val_loss: 0.0021\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 570us/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 570us/step - loss: 0.0031 - val_loss: 0.0017\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 569us/step - loss: 0.0030 - val_loss: 0.0018\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 574us/step - loss: 0.0028 - val_loss: 0.0016\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 572us/step - loss: 0.0028 - val_loss: 0.0015\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 569us/step - loss: 0.0028 - val_loss: 0.0015\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 573us/step - loss: 0.0026 - val_loss: 0.0015\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 570us/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 570us/step - loss: 0.0027 - val_loss: 0.0016\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 569us/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 570us/step - loss: 0.0026 - val_loss: 0.0013\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 567us/step - loss: 0.0025 - val_loss: 0.0014\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 568us/step - loss: 0.0024 - val_loss: 0.0014\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 569us/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 568us/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 7s 2ms/step - loss: 0.1113 - val_loss: 0.0094\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 570us/step - loss: 0.0167 - val_loss: 0.0148\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 569us/step - loss: 0.0088 - val_loss: 0.0053\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 572us/step - loss: 0.0054 - val_loss: 0.0029\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 569us/step - loss: 0.0040 - val_loss: 0.0025\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 569us/step - loss: 0.0037 - val_loss: 0.0016\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 569us/step - loss: 0.0035 - val_loss: 0.0020\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 568us/step - loss: 0.0032 - val_loss: 0.0019\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 569us/step - loss: 0.0031 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 571us/step - loss: 0.0031 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 566us/step - loss: 0.0030 - val_loss: 0.0016\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 570us/step - loss: 0.0030 - val_loss: 0.0016\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 569us/step - loss: 0.0028 - val_loss: 0.0016\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 568us/step - loss: 0.0027 - val_loss: 0.0015\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 566us/step - loss: 0.0027 - val_loss: 0.0016\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 567us/step - loss: 0.0026 - val_loss: 0.0014\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 569us/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 568us/step - loss: 0.0024 - val_loss: 0.0013\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 568us/step - loss: 0.0024 - val_loss: 0.0013\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 568us/step - loss: 0.0024 - val_loss: 0.0013\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 570us/step - loss: 0.0024 - val_loss: 0.0013\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 568us/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 565us/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 570us/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 8s 2ms/step - loss: 0.0791 - val_loss: 0.0474\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 576us/step - loss: 0.0170 - val_loss: 0.0084\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 573us/step - loss: 0.0081 - val_loss: 0.0024\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 577us/step - loss: 0.0055 - val_loss: 0.0028\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 575us/step - loss: 0.0044 - val_loss: 0.0016\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 576us/step - loss: 0.0037 - val_loss: 0.0018\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 576us/step - loss: 0.0035 - val_loss: 0.0015\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 576us/step - loss: 0.0032 - val_loss: 0.0015\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 574us/step - loss: 0.0031 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 573us/step - loss: 0.0030 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 576us/step - loss: 0.0030 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 576us/step - loss: 0.0027 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 575us/step - loss: 0.0028 - val_loss: 0.0016\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 573us/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 576us/step - loss: 0.0028 - val_loss: 0.0015\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 576us/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 575us/step - loss: 0.0024 - val_loss: 0.0013\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 576us/step - loss: 0.0023 - val_loss: 0.0013\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 577us/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 574us/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 578us/step - loss: 0.0024 - val_loss: 0.0015\n",
      "Epoch 22/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 2s 576us/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 580us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 578us/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 8s 2ms/step - loss: 0.1920 - val_loss: 0.1944\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 570us/step - loss: 0.1069 - val_loss: 0.1044\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 577us/step - loss: 0.0689 - val_loss: 0.0605\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 573us/step - loss: 0.0539 - val_loss: 0.0391\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 570us/step - loss: 0.0466 - val_loss: 0.0282\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 568us/step - loss: 0.0433 - val_loss: 0.0225\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 569us/step - loss: 0.0413 - val_loss: 0.0190\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 569us/step - loss: 0.0394 - val_loss: 0.0169\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 569us/step - loss: 0.0378 - val_loss: 0.0152\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 570us/step - loss: 0.0362 - val_loss: 0.0140\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 567us/step - loss: 0.0344 - val_loss: 0.0130\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 568us/step - loss: 0.0329 - val_loss: 0.0121\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 566us/step - loss: 0.0312 - val_loss: 0.0109\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 569us/step - loss: 0.0297 - val_loss: 0.0100\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 571us/step - loss: 0.0280 - val_loss: 0.0092\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 568us/step - loss: 0.0266 - val_loss: 0.0082\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 570us/step - loss: 0.0249 - val_loss: 0.0075\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 574us/step - loss: 0.0233 - val_loss: 0.0069\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 574us/step - loss: 0.0217 - val_loss: 0.0062\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 570us/step - loss: 0.0204 - val_loss: 0.0056\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 570us/step - loss: 0.0187 - val_loss: 0.0049\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 573us/step - loss: 0.0178 - val_loss: 0.0045\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 574us/step - loss: 0.0158 - val_loss: 0.0041\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 571us/step - loss: 0.0148 - val_loss: 0.0036\n",
      "\n",
      "GENERATION 6\n",
      "\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 6s 1ms/step - loss: 0.0497 - val_loss: 0.0012\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 173us/step - loss: 0.0105 - val_loss: 0.0033\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 172us/step - loss: 0.0049 - val_loss: 0.0032\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 175us/step - loss: 0.0030 - val_loss: 0.0025\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 174us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 173us/step - loss: 0.0022 - val_loss: 8.3281e-04\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 172us/step - loss: 0.0020 - val_loss: 9.1566e-04\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 173us/step - loss: 0.0019 - val_loss: 8.4071e-04\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 173us/step - loss: 0.0017 - val_loss: 8.1332e-04\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 172us/step - loss: 0.0017 - val_loss: 8.3291e-04\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 172us/step - loss: 0.0018 - val_loss: 8.0916e-04\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 173us/step - loss: 0.0017 - val_loss: 8.4091e-04\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 172us/step - loss: 0.0016 - val_loss: 7.8240e-04\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 171us/step - loss: 0.0017 - val_loss: 8.2193e-04\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 172us/step - loss: 0.0016 - val_loss: 7.7328e-04\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 172us/step - loss: 0.0016 - val_loss: 7.6236e-04\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 172us/step - loss: 0.0015 - val_loss: 7.7959e-04\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 171us/step - loss: 0.0015 - val_loss: 7.3252e-04\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 172us/step - loss: 0.0014 - val_loss: 7.5184e-04\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 171us/step - loss: 0.0015 - val_loss: 7.6118e-04\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 173us/step - loss: 0.0014 - val_loss: 7.8939e-04\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 171us/step - loss: 0.0014 - val_loss: 7.4908e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 173us/step - loss: 0.0014 - val_loss: 7.0020e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 173us/step - loss: 0.0014 - val_loss: 6.9885e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 6s 2ms/step - loss: 0.1577 - val_loss: 0.0432\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 235us/step - loss: 0.0131 - val_loss: 0.0161\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 236us/step - loss: 0.0060 - val_loss: 0.0072\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 235us/step - loss: 0.0038 - val_loss: 0.0024\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 238us/step - loss: 0.0026 - val_loss: 0.0012\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 238us/step - loss: 0.0019 - val_loss: 9.1514e-04\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 237us/step - loss: 0.0016 - val_loss: 9.4670e-04\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 235us/step - loss: 0.0015 - val_loss: 8.9413e-04\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 234us/step - loss: 0.0015 - val_loss: 9.0550e-04\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 234us/step - loss: 0.0014 - val_loss: 8.6875e-04\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 235us/step - loss: 0.0014 - val_loss: 8.9952e-04\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 234us/step - loss: 0.0014 - val_loss: 8.5371e-04\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 237us/step - loss: 0.0014 - val_loss: 8.4769e-04\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 235us/step - loss: 0.0013 - val_loss: 8.2066e-04\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 235us/step - loss: 0.0013 - val_loss: 8.0907e-04\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 235us/step - loss: 0.0013 - val_loss: 7.8647e-04\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 235us/step - loss: 0.0012 - val_loss: 7.7329e-04\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 235us/step - loss: 0.0012 - val_loss: 7.5360e-04\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 234us/step - loss: 0.0011 - val_loss: 7.3512e-04\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 234us/step - loss: 0.0011 - val_loss: 7.2891e-04\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 235us/step - loss: 0.0011 - val_loss: 7.3111e-04\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 235us/step - loss: 0.0011 - val_loss: 7.5172e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 237us/step - loss: 0.0010 - val_loss: 7.0220e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 235us/step - loss: 0.0010 - val_loss: 6.7043e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 8s 2ms/step - loss: 0.0632 - val_loss: 0.0289\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 0.0100 - val_loss: 0.0041\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 529us/step - loss: 0.0056 - val_loss: 0.0082\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0028 - val_loss: 0.0016\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 528us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 8s 2ms/step - loss: 0.1850 - val_loss: 0.1016\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0406 - val_loss: 0.0065\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0104 - val_loss: 0.0070\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 485us/step - loss: 0.0060 - val_loss: 0.0051\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 0.0045 - val_loss: 0.0027\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0033 - val_loss: 0.0020\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 485us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 485us/step - loss: 0.0027 - val_loss: 0.0021\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 484us/step - loss: 0.0025 - val_loss: 0.0046\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 485us/step - loss: 0.0023 - val_loss: 0.0063\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 485us/step - loss: 0.0023 - val_loss: 0.0047\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 484us/step - loss: 0.0022 - val_loss: 0.0067\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0022 - val_loss: 0.0054\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 0.0021 - val_loss: 0.0064\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0020 - val_loss: 0.0085\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0020 - val_loss: 0.0081\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 491us/step - loss: 0.0020 - val_loss: 0.0083\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 8s 2ms/step - loss: 0.1309 - val_loss: 0.0887\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0254 - val_loss: 0.0233\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0202 - val_loss: 0.0125\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0136 - val_loss: 0.0135\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0134 - val_loss: 0.0105\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0103 - val_loss: 0.0097\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0075 - val_loss: 0.0089\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0094 - val_loss: 0.0155\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 0.0089 - val_loss: 0.0060\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0051 - val_loss: 0.0048\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0065 - val_loss: 0.0074\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 0.0066 - val_loss: 0.0073\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0058 - val_loss: 0.0050\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0063 - val_loss: 0.0074\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 491us/step - loss: 0.0069 - val_loss: 0.0070\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0063 - val_loss: 0.0055\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0054 - val_loss: 0.0045\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0060 - val_loss: 0.0060\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0051 - val_loss: 0.0086\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0054 - val_loss: 0.0058\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0050 - val_loss: 0.0055\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0053 - val_loss: 0.0052\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 492us/step - loss: 0.0060 - val_loss: 0.0052\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 494us/step - loss: 0.0053 - val_loss: 0.0056\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 8s 2ms/step - loss: 0.0508 - val_loss: 0.0190\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0141 - val_loss: 0.0075\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 0.0100 - val_loss: 0.0042\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0073 - val_loss: 0.0041\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 491us/step - loss: 0.0074 - val_loss: 0.0061\n",
      "Epoch 6/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0079 - val_loss: 0.0051\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 485us/step - loss: 0.0079 - val_loss: 0.0068\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0078 - val_loss: 0.0048\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 494us/step - loss: 0.0070 - val_loss: 0.0050\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0061 - val_loss: 0.0082\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 0.0091 - val_loss: 0.0060\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 0.0073 - val_loss: 0.0056\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 0.0071 - val_loss: 0.0053\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0064 - val_loss: 0.0072\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0083 - val_loss: 0.0056\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0052 - val_loss: 0.0066\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0073 - val_loss: 0.0089\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0076 - val_loss: 0.0068\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0064 - val_loss: 0.0057\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0066 - val_loss: 0.0060\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0065 - val_loss: 0.0034\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 484us/step - loss: 0.0045 - val_loss: 0.0027\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: 0.0042 - val_loss: 0.0023\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 0.0064 - val_loss: 0.0058\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 8s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 485us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 495us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 485us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 485us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 485us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 487us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 485us/step - loss: nan - val_loss: nan\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 9s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: nan - val_loss: nan\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 9s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 471us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 469us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 469us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 469us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 471us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 472us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 470us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 470us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 471us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 469us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 469us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 469us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 2s 469us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 469us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 471us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 470us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 469us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 469us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 469us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 471us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 469us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 471us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 471us/step - loss: nan - val_loss: nan\n",
      "\n",
      "GENERATION 7\n",
      "\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 9s 2ms/step - loss: 0.1029 - val_loss: 0.0080\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 0.0138 - val_loss: 0.0056\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 529us/step - loss: 0.0119 - val_loss: 0.0071\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 0.0088 - val_loss: 0.0174\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 0.0097 - val_loss: 0.0047\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 528us/step - loss: 0.0068 - val_loss: 0.0119\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0076 - val_loss: 0.0047\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 528us/step - loss: 0.0070 - val_loss: 0.0043\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 528us/step - loss: 0.0054 - val_loss: 0.0033\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 529us/step - loss: 0.0065 - val_loss: 0.0062\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 0.0064 - val_loss: 0.0050\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 0.0057 - val_loss: 0.0042\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 0.0046 - val_loss: 0.0026\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 0.0054 - val_loss: 0.0018\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0032 - val_loss: 0.0043\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 0.0054 - val_loss: 0.0018\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 528us/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 0.0037 - val_loss: 0.0018\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 528us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 0.0057 - val_loss: 0.0031\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 0.0032 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 528us/step - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 0.0049 - val_loss: 0.0022\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 8s 2ms/step - loss: 0.0788 - val_loss: 0.0022\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 239us/step - loss: 0.0088 - val_loss: 0.0016\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 239us/step - loss: 0.0035 - val_loss: 9.2112e-04\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 239us/step - loss: 0.0025 - val_loss: 9.2076e-04\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 237us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 238us/step - loss: 0.0016 - val_loss: 8.3380e-04\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 239us/step - loss: 0.0015 - val_loss: 9.3480e-04\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 238us/step - loss: 0.0015 - val_loss: 7.9792e-04\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 238us/step - loss: 0.0014 - val_loss: 7.8002e-04\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 239us/step - loss: 0.0014 - val_loss: 8.0736e-04\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 242us/step - loss: 0.0013 - val_loss: 7.5075e-04\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 239us/step - loss: 0.0013 - val_loss: 7.3918e-04\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 239us/step - loss: 0.0013 - val_loss: 7.2671e-04\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 240us/step - loss: 0.0012 - val_loss: 7.1284e-04\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 238us/step - loss: 0.0012 - val_loss: 6.9971e-04\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 238us/step - loss: 0.0011 - val_loss: 6.8419e-04\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 240us/step - loss: 0.0011 - val_loss: 6.8214e-04\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 240us/step - loss: 0.0011 - val_loss: 6.5873e-04\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 237us/step - loss: 0.0011 - val_loss: 6.9905e-04\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 238us/step - loss: 0.0010 - val_loss: 6.7879e-04\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 238us/step - loss: 9.6547e-04 - val_loss: 6.3366e-04\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 238us/step - loss: 9.3562e-04 - val_loss: 6.4956e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 238us/step - loss: 9.2183e-04 - val_loss: 7.4586e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 239us/step - loss: 9.0408e-04 - val_loss: 7.0391e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 9s 2ms/step - loss: 0.0583 - val_loss: 0.0265\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 413us/step - loss: 0.0111 - val_loss: 0.0107\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 415us/step - loss: 0.0052 - val_loss: 0.0020\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 413us/step - loss: 0.0033 - val_loss: 0.0018\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 415us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 413us/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 413us/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 410us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 413us/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 415us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 414us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 414us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 410us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 418us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 411us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 412us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 413us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 18/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 2s 411us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 417us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 412us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 412us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 413us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 413us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 413us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 9s 2ms/step - loss: 0.0567 - val_loss: 0.0313\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 411us/step - loss: 0.0116 - val_loss: 0.0018\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 412us/step - loss: 0.0050 - val_loss: 0.0039\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 414us/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 412us/step - loss: 0.0028 - val_loss: 0.0020\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 412us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 411us/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 412us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 411us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 413us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 415us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 415us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 414us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 417us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 412us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 414us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 410us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 412us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 412us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 412us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 413us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 415us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 415us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 415us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 9s 2ms/step - loss: 0.0701 - val_loss: 0.0334\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 415us/step - loss: 0.0134 - val_loss: 0.0094\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 414us/step - loss: 0.0057 - val_loss: 0.0024\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 413us/step - loss: 0.0035 - val_loss: 0.0016\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 413us/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 414us/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 416us/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 416us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 413us/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 416us/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 413us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 416us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 412us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 413us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 412us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 413us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 415us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 414us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 413us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 415us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 413us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 411us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 414us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 414us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 9s 2ms/step - loss: 0.1004 - val_loss: 0.0154\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 414us/step - loss: 0.0190 - val_loss: 0.0123\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 415us/step - loss: 0.0079 - val_loss: 0.0039\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 419us/step - loss: 0.0042 - val_loss: 0.0018\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 417us/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 414us/step - loss: 0.0028 - val_loss: 0.0019\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 413us/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 414us/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 415us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 416us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 416us/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 413us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 414us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 417us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 414us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 413us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 415us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 415us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 416us/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 418us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 415us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 416us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 23/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 2s 416us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 412us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 10s 2ms/step - loss: 0.0872 - val_loss: 0.0328\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 411us/step - loss: 0.0179 - val_loss: 0.0140\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 414us/step - loss: 0.0081 - val_loss: 0.0054\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 414us/step - loss: 0.0051 - val_loss: 0.0055\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 411us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 412us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 412us/step - loss: 0.0027 - val_loss: 0.0020\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 413us/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 412us/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 413us/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 413us/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 411us/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 416us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 411us/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 412us/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 411us/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 413us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 411us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 411us/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 412us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 410us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 416us/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 417us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 414us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 10s 3ms/step - loss: 0.0841 - val_loss: 0.0031\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 558us/step - loss: 0.0082 - val_loss: 0.0057\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 559us/step - loss: 0.0042 - val_loss: 0.0021\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 560us/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 557us/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 560us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 561us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 558us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 560us/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 560us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 563us/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 559us/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 559us/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 557us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 558us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 559us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 561us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 563us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 561us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 559us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 562us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 558us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 560us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 559us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 10s 3ms/step - loss: 0.0978 - val_loss: 0.0311\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 474us/step - loss: 0.0138 - val_loss: 0.0057\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 475us/step - loss: 0.0055 - val_loss: 0.0028\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 475us/step - loss: 0.0036 - val_loss: 0.0025\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 475us/step - loss: 0.0030 - val_loss: 0.0051\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 477us/step - loss: 0.0027 - val_loss: 0.0019\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 474us/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 483us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 474us/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 477us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 477us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 474us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 474us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 471us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 474us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 476us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 473us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 475us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 472us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 474us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 477us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 473us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 472us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 473us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "\n",
      "GENERATION 8\n",
      "\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 11s 3ms/step - loss: 0.0592 - val_loss: 0.0029\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 0.0079 - val_loss: 0.0064\n",
      "Epoch 3/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 2s 529us/step - loss: 0.0051 - val_loss: 0.0030\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 529us/step - loss: 0.0033 - val_loss: 0.0059\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 0.0029 - val_loss: 0.0013\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 529us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 528us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 535us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 529us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 528us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 528us/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 529us/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 551us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 528us/step - loss: 0.0014 - val_loss: 9.9999e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 9s 2ms/step - loss: 0.0730 - val_loss: 0.0016\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 238us/step - loss: 0.0085 - val_loss: 9.3739e-04\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 242us/step - loss: 0.0040 - val_loss: 8.7109e-04\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 237us/step - loss: 0.0026 - val_loss: 8.7045e-04\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 238us/step - loss: 0.0018 - val_loss: 9.2728e-04\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 239us/step - loss: 0.0015 - val_loss: 7.9432e-04\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 237us/step - loss: 0.0014 - val_loss: 8.0094e-04\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 238us/step - loss: 0.0013 - val_loss: 8.1559e-04\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 239us/step - loss: 0.0014 - val_loss: 7.8935e-04\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 237us/step - loss: 0.0013 - val_loss: 8.1803e-04\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 238us/step - loss: 0.0013 - val_loss: 7.6852e-04\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 237us/step - loss: 0.0013 - val_loss: 7.5354e-04\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 238us/step - loss: 0.0012 - val_loss: 7.3584e-04\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 238us/step - loss: 0.0011 - val_loss: 7.3776e-04\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 238us/step - loss: 0.0012 - val_loss: 7.1322e-04\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 238us/step - loss: 0.0011 - val_loss: 7.1754e-04\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 239us/step - loss: 0.0012 - val_loss: 6.9054e-04\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 238us/step - loss: 0.0011 - val_loss: 6.7921e-04\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 239us/step - loss: 0.0011 - val_loss: 7.0895e-04\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 240us/step - loss: 0.0011 - val_loss: 6.5746e-04\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 237us/step - loss: 0.0011 - val_loss: 6.3373e-04\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 238us/step - loss: 0.0010 - val_loss: 6.7066e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 238us/step - loss: 0.0010 - val_loss: 6.2252e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 238us/step - loss: 9.8097e-04 - val_loss: 5.9717e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 11s 3ms/step - loss: 0.0637 - val_loss: 0.0433\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 529us/step - loss: 0.0135 - val_loss: 0.0061\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 0.0053 - val_loss: 0.0019\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 0.0030 - val_loss: 0.0038\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 521us/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 528us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 529us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 11s 3ms/step - loss: 0.0534 - val_loss: 0.0224\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 0.0088 - val_loss: 0.0054\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 0.0049 - val_loss: 0.0061\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 0.0031 - val_loss: 0.0016\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 7/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 2s 524us/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 528us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 529us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 11s 3ms/step - loss: 0.1108 - val_loss: 0.0321\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 367us/step - loss: 0.0187 - val_loss: 0.0047\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 366us/step - loss: 0.0097 - val_loss: 0.0026\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 363us/step - loss: 0.0064 - val_loss: 0.0022\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 363us/step - loss: 0.0049 - val_loss: 0.0021\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 363us/step - loss: 0.0043 - val_loss: 0.0021\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 364us/step - loss: 0.0039 - val_loss: 0.0024\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 365us/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 364us/step - loss: 0.0036 - val_loss: 0.0023\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 365us/step - loss: 0.0033 - val_loss: 0.0020\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 365us/step - loss: 0.0032 - val_loss: 0.0024\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 365us/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 364us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 365us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 365us/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 364us/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 365us/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 365us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 364us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 364us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 365us/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 364us/step - loss: 0.0024 - val_loss: 0.0051\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 365us/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 369us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 11s 3ms/step - loss: 0.9596 - val_loss: 0.7840\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 326us/step - loss: 0.3837 - val_loss: 0.3083\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 327us/step - loss: 0.1423 - val_loss: 0.1058\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 327us/step - loss: 0.0745 - val_loss: 0.0356\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 326us/step - loss: 0.0684 - val_loss: 0.0174\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 326us/step - loss: 0.0722 - val_loss: 0.0162\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 333us/step - loss: 0.0710 - val_loss: 0.0218\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 328us/step - loss: 0.0684 - val_loss: 0.0307\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 326us/step - loss: 0.0670 - val_loss: 0.0376\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 329us/step - loss: 0.0670 - val_loss: 0.0408\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 327us/step - loss: 0.0672 - val_loss: 0.0402\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 327us/step - loss: 0.0670 - val_loss: 0.0385\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 327us/step - loss: 0.0669 - val_loss: 0.0367\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 327us/step - loss: 0.0671 - val_loss: 0.0357\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 328us/step - loss: 0.0670 - val_loss: 0.0360\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 326us/step - loss: 0.0671 - val_loss: 0.0369\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 326us/step - loss: 0.0670 - val_loss: 0.0368\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 327us/step - loss: 0.0670 - val_loss: 0.0366\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 331us/step - loss: 0.0670 - val_loss: 0.0370\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 329us/step - loss: 0.0670 - val_loss: 0.0367\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 326us/step - loss: 0.0670 - val_loss: 0.0370\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 327us/step - loss: 0.0670 - val_loss: 0.0371\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 326us/step - loss: 0.0671 - val_loss: 0.0367\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 327us/step - loss: 0.0671 - val_loss: 0.0365\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 11s 3ms/step - loss: 0.0667 - val_loss: 0.0199\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 326us/step - loss: 0.0174 - val_loss: 0.0154\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 326us/step - loss: 0.0078 - val_loss: 0.0028\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 326us/step - loss: 0.0057 - val_loss: 0.0030\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 327us/step - loss: 0.0045 - val_loss: 0.0054\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 326us/step - loss: 0.0039 - val_loss: 0.0029\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 325us/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 326us/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 326us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 325us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 326us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 12/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 1s 325us/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 327us/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 328us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 325us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 326us/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 326us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 326us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 326us/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 325us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 327us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 327us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 326us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 328us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 11s 3ms/step - loss: 0.0803 - val_loss: 0.0137\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 327us/step - loss: 0.0169 - val_loss: 0.0203\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 327us/step - loss: 0.0082 - val_loss: 0.0051\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 326us/step - loss: 0.0056 - val_loss: 0.0019\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 326us/step - loss: 0.0047 - val_loss: 0.0069\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 328us/step - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 330us/step - loss: 0.0034 - val_loss: 0.0025\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 328us/step - loss: 0.0031 - val_loss: 0.0040\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 327us/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 327us/step - loss: 0.0027 - val_loss: 0.0021\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 327us/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 325us/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 325us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 327us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 326us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 326us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 326us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 326us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 329us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 327us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 328us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 326us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 328us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 326us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 12s 3ms/step - loss: 0.0647 - val_loss: 0.0151\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 478us/step - loss: 0.0153 - val_loss: 0.0075\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 476us/step - loss: 0.0075 - val_loss: 0.0077\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 480us/step - loss: 0.0045 - val_loss: 0.0070\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 478us/step - loss: 0.0028 - val_loss: 0.0048\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 476us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 476us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 475us/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 476us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 476us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 476us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 475us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 477us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 475us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 474us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 476us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 476us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 477us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 477us/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 475us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 476us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 475us/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 476us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 476us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "\n",
      "GENERATION 9\n",
      "\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 13s 3ms/step - loss: 0.0740 - val_loss: 0.0535\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 528us/step - loss: 0.0181 - val_loss: 0.0067\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 0.0077 - val_loss: 0.0015\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 529us/step - loss: 0.0052 - val_loss: 0.0018\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 0.0041 - val_loss: 0.0028\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 528us/step - loss: 0.0032 - val_loss: 0.0016\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 0.0031 - val_loss: 0.0014\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 0.0028 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 0.0030 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0028 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0027 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 528us/step - loss: 0.0025 - val_loss: 0.0014\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 0.0026 - val_loss: 0.0014\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 0.0024 - val_loss: 0.0014\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 0.0024 - val_loss: 0.0013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 528us/step - loss: 0.0024 - val_loss: 0.0013\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 0.0024 - val_loss: 0.0014\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 528us/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 529us/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 11s 3ms/step - loss: 0.0732 - val_loss: 0.0061\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 243us/step - loss: 0.0111 - val_loss: 0.0014\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 242us/step - loss: 0.0044 - val_loss: 8.3703e-04\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 243us/step - loss: 0.0027 - val_loss: 7.3308e-04\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 242us/step - loss: 0.0020 - val_loss: 9.8739e-04\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 242us/step - loss: 0.0017 - val_loss: 7.6532e-04\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 241us/step - loss: 0.0016 - val_loss: 8.8596e-04\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 243us/step - loss: 0.0015 - val_loss: 7.3339e-04\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 242us/step - loss: 0.0015 - val_loss: 7.9006e-04\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 241us/step - loss: 0.0015 - val_loss: 7.0563e-04\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 241us/step - loss: 0.0014 - val_loss: 7.1479e-04\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 241us/step - loss: 0.0013 - val_loss: 7.1078e-04\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 244us/step - loss: 0.0013 - val_loss: 6.8910e-04\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 243us/step - loss: 0.0013 - val_loss: 6.8215e-04\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 240us/step - loss: 0.0012 - val_loss: 6.6299e-04\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 241us/step - loss: 0.0012 - val_loss: 6.5689e-04\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 243us/step - loss: 0.0012 - val_loss: 6.7581e-04\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 242us/step - loss: 0.0012 - val_loss: 6.3341e-04\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 242us/step - loss: 0.0012 - val_loss: 6.1250e-04\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 241us/step - loss: 0.0011 - val_loss: 6.0274e-04\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 243us/step - loss: 0.0011 - val_loss: 5.9635e-04\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 241us/step - loss: 0.0010 - val_loss: 6.7143e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 241us/step - loss: 9.9765e-04 - val_loss: 5.7349e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 241us/step - loss: 0.0010 - val_loss: 5.6885e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 11s 3ms/step - loss: 0.1127 - val_loss: 0.0026\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 219us/step - loss: 0.0108 - val_loss: 0.0029\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 221us/step - loss: 0.0048 - val_loss: 0.0031\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 219us/step - loss: 0.0030 - val_loss: 0.0026\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 221us/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 220us/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 220us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 220us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 221us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 221us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 221us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 219us/step - loss: 0.0016 - val_loss: 9.9979e-04\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 221us/step - loss: 0.0016 - val_loss: 9.9534e-04\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 220us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 223us/step - loss: 0.0016 - val_loss: 9.8998e-04\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 219us/step - loss: 0.0016 - val_loss: 9.8702e-04\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 220us/step - loss: 0.0016 - val_loss: 9.7666e-04\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 221us/step - loss: 0.0016 - val_loss: 9.7645e-04\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 221us/step - loss: 0.0015 - val_loss: 9.7513e-04\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 220us/step - loss: 0.0016 - val_loss: 9.7714e-04\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 221us/step - loss: 0.0015 - val_loss: 9.6522e-04\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 220us/step - loss: 0.0016 - val_loss: 9.6045e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 219us/step - loss: 0.0015 - val_loss: 9.6857e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 219us/step - loss: 0.0015 - val_loss: 9.5134e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 11s 3ms/step - loss: 0.0598 - val_loss: 0.0129\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 222us/step - loss: 0.0069 - val_loss: 0.0049\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 221us/step - loss: 0.0036 - val_loss: 0.0014\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 221us/step - loss: 0.0027 - val_loss: 9.1230e-04\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 221us/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 222us/step - loss: 0.0019 - val_loss: 9.6262e-04\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 220us/step - loss: 0.0018 - val_loss: 9.9844e-04\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 221us/step - loss: 0.0018 - val_loss: 8.7234e-04\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 220us/step - loss: 0.0017 - val_loss: 9.1813e-04\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 221us/step - loss: 0.0016 - val_loss: 8.8050e-04\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 221us/step - loss: 0.0016 - val_loss: 8.8125e-04\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 221us/step - loss: 0.0016 - val_loss: 8.6197e-04\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 222us/step - loss: 0.0015 - val_loss: 8.5556e-04\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 220us/step - loss: 0.0015 - val_loss: 8.3754e-04\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 222us/step - loss: 0.0014 - val_loss: 8.2320e-04\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 223us/step - loss: 0.0015 - val_loss: 8.1246e-04\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 221us/step - loss: 0.0014 - val_loss: 8.0469e-04\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 222us/step - loss: 0.0014 - val_loss: 7.8851e-04\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 222us/step - loss: 0.0013 - val_loss: 8.0548e-04\n",
      "Epoch 20/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 1s 220us/step - loss: 0.0013 - val_loss: 7.9149e-04\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 220us/step - loss: 0.0012 - val_loss: 7.3807e-04\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 220us/step - loss: 0.0012 - val_loss: 7.5386e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 220us/step - loss: 0.0013 - val_loss: 7.8091e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 221us/step - loss: 0.0012 - val_loss: 7.0705e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 11s 3ms/step - loss: 0.1038 - val_loss: 0.0368\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 219us/step - loss: 0.0131 - val_loss: 0.0055\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 220us/step - loss: 0.0063 - val_loss: 0.0015\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 220us/step - loss: 0.0030 - val_loss: 0.0018\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 220us/step - loss: 0.0025 - val_loss: 0.0012\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 219us/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 221us/step - loss: 0.0019 - val_loss: 8.6701e-04\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 220us/step - loss: 0.0019 - val_loss: 9.6195e-04\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 220us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 220us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 219us/step - loss: 0.0018 - val_loss: 9.3629e-04\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 220us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 220us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 219us/step - loss: 0.0017 - val_loss: 9.7642e-04\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 221us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 220us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 221us/step - loss: 0.0016 - val_loss: 9.4926e-04\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 222us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 222us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 220us/step - loss: 0.0016 - val_loss: 9.6760e-04\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 220us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 220us/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 220us/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 219us/step - loss: 0.0016 - val_loss: 9.2215e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 12s 3ms/step - loss: 0.0502 - val_loss: 0.0148\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 221us/step - loss: 0.0081 - val_loss: 0.0085\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 221us/step - loss: 0.0045 - val_loss: 0.0018\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 221us/step - loss: 0.0034 - val_loss: 0.0028\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 221us/step - loss: 0.0031 - val_loss: 0.0018\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 222us/step - loss: 0.0027 - val_loss: 0.0011\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 222us/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 221us/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 222us/step - loss: 0.0024 - val_loss: 0.0013\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 221us/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 222us/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 222us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 221us/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 221us/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 222us/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 225us/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 223us/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 226us/step - loss: 0.0021 - val_loss: 0.0010\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 221us/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 222us/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 221us/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 221us/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 222us/step - loss: 0.0018 - val_loss: 9.7507e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 222us/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 12s 3ms/step - loss: 0.0581 - val_loss: 0.0252\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 221us/step - loss: 0.0096 - val_loss: 0.0116\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 221us/step - loss: 0.0056 - val_loss: 9.7664e-04\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 221us/step - loss: 0.0040 - val_loss: 8.8626e-04\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 220us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 221us/step - loss: 0.0029 - val_loss: 0.0013\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 220us/step - loss: 0.0027 - val_loss: 0.0013\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 221us/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 221us/step - loss: 0.0024 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 221us/step - loss: 0.0025 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 221us/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 222us/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 220us/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 221us/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 222us/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 220us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 221us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 225us/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 223us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 222us/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 222us/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 220us/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 220us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 24/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 1s 220us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 12s 3ms/step - loss: 0.0635 - val_loss: 0.0178\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 223us/step - loss: 0.0089 - val_loss: 0.0101\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 221us/step - loss: 0.0050 - val_loss: 0.0021\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 220us/step - loss: 0.0041 - val_loss: 0.0023\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 221us/step - loss: 0.0032 - val_loss: 0.0017\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 221us/step - loss: 0.0030 - val_loss: 8.9480e-04\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 219us/step - loss: 0.0028 - val_loss: 0.0018\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 221us/step - loss: 0.0026 - val_loss: 0.0011\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 219us/step - loss: 0.0026 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 220us/step - loss: 0.0025 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 220us/step - loss: 0.0025 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 219us/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 221us/step - loss: 0.0024 - val_loss: 0.0010\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 226us/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 220us/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 220us/step - loss: 0.0023 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 220us/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 223us/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 223us/step - loss: 0.0022 - val_loss: 0.0010\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 221us/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 221us/step - loss: 0.0021 - val_loss: 0.0010\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 221us/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 222us/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 219us/step - loss: 0.0021 - val_loss: 0.0010\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 13s 3ms/step - loss: 2.4646 - val_loss: 0.0038\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 484us/step - loss: 0.0088 - val_loss: 0.0037\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 482us/step - loss: 0.0076 - val_loss: 0.0035\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 482us/step - loss: 0.0069 - val_loss: 0.0035\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 480us/step - loss: 0.0060 - val_loss: 0.0034\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 483us/step - loss: 0.0059 - val_loss: 0.0033\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 483us/step - loss: 0.0058 - val_loss: 0.0035\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 483us/step - loss: 0.0053 - val_loss: 0.0032\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 482us/step - loss: 0.0055 - val_loss: 0.0032\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 482us/step - loss: 0.0051 - val_loss: 0.0031\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 482us/step - loss: 0.0050 - val_loss: 0.0030\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 0.0051 - val_loss: 0.0029\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 481us/step - loss: 0.0048 - val_loss: 0.0030\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 481us/step - loss: 0.0047 - val_loss: 0.0028\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 482us/step - loss: 0.0047 - val_loss: 0.0031\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 486us/step - loss: 0.0046 - val_loss: 0.0027\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 485us/step - loss: 0.0046 - val_loss: 0.0030\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 482us/step - loss: 0.0044 - val_loss: 0.0026\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 482us/step - loss: 0.0044 - val_loss: 0.0026\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 482us/step - loss: 0.0043 - val_loss: 0.0030\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 484us/step - loss: 0.0043 - val_loss: 0.0026\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 483us/step - loss: 0.0040 - val_loss: 0.0025\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 483us/step - loss: 0.0040 - val_loss: 0.0028\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 485us/step - loss: 0.0040 - val_loss: 0.0025\n",
      "\n",
      "GENERATION 10\n",
      "\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 14s 3ms/step - loss: 0.1016 - val_loss: 0.0647\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0244 - val_loss: 0.0120\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 529us/step - loss: 0.0107 - val_loss: 0.0028\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 535us/step - loss: 0.0058 - val_loss: 0.0059\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0051 - val_loss: 0.0029\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 0.0040 - val_loss: 0.0017\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0028 - val_loss: 0.0019\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0027 - val_loss: 0.0020\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 535us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 528us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 529us/step - loss: 0.0023 - val_loss: 0.0036\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 537us/step - loss: 0.0021 - val_loss: 0.0036\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 0.0020 - val_loss: 0.0032\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 0.0021 - val_loss: 0.0036\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 12s 3ms/step - loss: 0.0936 - val_loss: 9.9821e-04\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 244us/step - loss: 0.0084 - val_loss: 0.0019\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 243us/step - loss: 0.0040 - val_loss: 9.6314e-04\n",
      "Epoch 4/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 1s 242us/step - loss: 0.0026 - val_loss: 8.1044e-04\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 244us/step - loss: 0.0018 - val_loss: 9.3189e-04\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 244us/step - loss: 0.0017 - val_loss: 7.9233e-04\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 242us/step - loss: 0.0015 - val_loss: 9.3114e-04\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 243us/step - loss: 0.0014 - val_loss: 7.6047e-04\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 242us/step - loss: 0.0013 - val_loss: 7.9772e-04\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 242us/step - loss: 0.0013 - val_loss: 7.5020e-04\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 242us/step - loss: 0.0013 - val_loss: 7.2819e-04\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 243us/step - loss: 0.0013 - val_loss: 7.3462e-04\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 243us/step - loss: 0.0013 - val_loss: 7.1560e-04\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 242us/step - loss: 0.0012 - val_loss: 6.9865e-04\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 241us/step - loss: 0.0012 - val_loss: 6.8523e-04\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 241us/step - loss: 0.0011 - val_loss: 6.9781e-04\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 242us/step - loss: 0.0011 - val_loss: 6.8779e-04\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 244us/step - loss: 0.0011 - val_loss: 6.3534e-04\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 245us/step - loss: 0.0011 - val_loss: 6.3290e-04\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 244us/step - loss: 0.0010 - val_loss: 6.0315e-04\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 243us/step - loss: 9.9527e-04 - val_loss: 6.8391e-04\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 246us/step - loss: 9.6697e-04 - val_loss: 8.0451e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 244us/step - loss: 9.9681e-04 - val_loss: 8.2419e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 243us/step - loss: 9.5228e-04 - val_loss: 8.4245e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 12s 3ms/step - loss: 0.0520 - val_loss: 0.0153\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 245us/step - loss: 0.0071 - val_loss: 0.0041\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 243us/step - loss: 0.0036 - val_loss: 0.0012\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 242us/step - loss: 0.0023 - val_loss: 9.6986e-04\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 243us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 242us/step - loss: 0.0017 - val_loss: 9.2454e-04\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 243us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 241us/step - loss: 0.0015 - val_loss: 9.0507e-04\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 244us/step - loss: 0.0015 - val_loss: 9.2258e-04\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 242us/step - loss: 0.0014 - val_loss: 8.6770e-04\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 243us/step - loss: 0.0014 - val_loss: 8.6285e-04\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 242us/step - loss: 0.0014 - val_loss: 8.6455e-04\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 244us/step - loss: 0.0014 - val_loss: 8.5621e-04\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 243us/step - loss: 0.0013 - val_loss: 8.2310e-04\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 242us/step - loss: 0.0013 - val_loss: 8.2238e-04\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 242us/step - loss: 0.0013 - val_loss: 7.8070e-04\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 244us/step - loss: 0.0013 - val_loss: 7.6301e-04\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 243us/step - loss: 0.0012 - val_loss: 7.5245e-04\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 245us/step - loss: 0.0013 - val_loss: 7.4076e-04\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 244us/step - loss: 0.0012 - val_loss: 7.3405e-04\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 242us/step - loss: 0.0012 - val_loss: 7.2804e-04\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 244us/step - loss: 0.0012 - val_loss: 7.4201e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 242us/step - loss: 0.0012 - val_loss: 7.6812e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 243us/step - loss: 0.0011 - val_loss: 7.0989e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 13s 3ms/step - loss: 0.3461 - val_loss: 0.1150\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 244us/step - loss: 0.0296 - val_loss: 0.0436\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 245us/step - loss: 0.0089 - val_loss: 0.0088\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 244us/step - loss: 0.0077 - val_loss: 8.7621e-04\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 246us/step - loss: 0.0025 - val_loss: 0.0057\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 247us/step - loss: 0.0027 - val_loss: 9.7318e-04\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 245us/step - loss: 0.0019 - val_loss: 7.6474e-04\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 246us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 243us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 243us/step - loss: 0.0016 - val_loss: 9.7348e-04\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 246us/step - loss: 0.0016 - val_loss: 9.9972e-04\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 245us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 244us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 246us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 245us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 245us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 243us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 244us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 245us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 245us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 246us/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 246us/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 246us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 245us/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 13s 3ms/step - loss: 0.0741 - val_loss: 0.0133\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 247us/step - loss: 0.0070 - val_loss: 0.0055\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 246us/step - loss: 0.0032 - val_loss: 0.0013\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 246us/step - loss: 0.0022 - val_loss: 0.0044\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 246us/step - loss: 0.0020 - val_loss: 7.7778e-04\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 246us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 7/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 1s 248us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 246us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 245us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 244us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 250us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 248us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 245us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 245us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 243us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 243us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 246us/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 243us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 246us/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 242us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 243us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 246us/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 243us/step - loss: 0.0013 - val_loss: 9.7338e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 248us/step - loss: 0.0013 - val_loss: 9.6139e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 14s 4ms/step - loss: 0.0658 - val_loss: 0.0046\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 0.0082 - val_loss: 0.0046\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 0.0051 - val_loss: 0.0061\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 529us/step - loss: 0.0034 - val_loss: 0.0019\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 536us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 528us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 15s 4ms/step - loss: 0.0675 - val_loss: 0.0173\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0158 - val_loss: 0.0130\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0115 - val_loss: 0.0113\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 535us/step - loss: 0.0084 - val_loss: 0.0097\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0084 - val_loss: 0.0121\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 536us/step - loss: 0.0098 - val_loss: 0.0080\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 536us/step - loss: 0.0062 - val_loss: 0.0170\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0091 - val_loss: 0.0113\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0063 - val_loss: 0.0058\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 536us/step - loss: 0.0042 - val_loss: 0.0063\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 536us/step - loss: 0.0058 - val_loss: 0.0076\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 536us/step - loss: 0.0059 - val_loss: 0.0106\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 536us/step - loss: 0.0082 - val_loss: 0.0067\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 535us/step - loss: 0.0056 - val_loss: 0.0092\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0056 - val_loss: 0.0065\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0058 - val_loss: 0.0061\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0055 - val_loss: 0.0056\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0044 - val_loss: 0.0084\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0066 - val_loss: 0.0114\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0073 - val_loss: 0.0058\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0065 - val_loss: 0.0062\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 536us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0055 - val_loss: 0.0072\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0047 - val_loss: 0.0056\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 15s 4ms/step - loss: 0.1732 - val_loss: 0.1397\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0761 - val_loss: 0.0585\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 529us/step - loss: 0.0482 - val_loss: 0.0306\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0399 - val_loss: 0.0203\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 0.0361 - val_loss: 0.0156\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 536us/step - loss: 0.0336 - val_loss: 0.0132\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0311 - val_loss: 0.0115\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0287 - val_loss: 0.0101\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0266 - val_loss: 0.0090\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0245 - val_loss: 0.0082\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0222 - val_loss: 0.0074\n",
      "Epoch 12/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 2s 529us/step - loss: 0.0205 - val_loss: 0.0065\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0184 - val_loss: 0.0057\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 0.0164 - val_loss: 0.0048\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0144 - val_loss: 0.0041\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 528us/step - loss: 0.0127 - val_loss: 0.0035\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0110 - val_loss: 0.0031\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0095 - val_loss: 0.0027\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 0.0085 - val_loss: 0.0025\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0073 - val_loss: 0.0023\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 0.0065 - val_loss: 0.0021\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0057 - val_loss: 0.0021\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 529us/step - loss: 0.0051 - val_loss: 0.0021\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0047 - val_loss: 0.0021\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 15s 4ms/step - loss: 0.2085 - val_loss: 0.1307\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0287 - val_loss: 0.0251\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0173 - val_loss: 0.0294\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.0076 - val_loss: 0.0071\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 535us/step - loss: 0.0055 - val_loss: 0.0038\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0044 - val_loss: 0.0025\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0032 - val_loss: 0.0016\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 537us/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 535us/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0023 - val_loss: 0.0013\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 537us/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0032 - val_loss: 0.0014\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 535us/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 536us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 535us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 536us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 535us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 536us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "\n",
      "GENERATION 11\n",
      "\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 15s 4ms/step - loss: 0.1100 - val_loss: 0.0136\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0202 - val_loss: 0.0119\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 536us/step - loss: 0.0089 - val_loss: 0.0070\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0052 - val_loss: 0.0085\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0033 - val_loss: 0.0018\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 537us/step - loss: 0.0027 - val_loss: 0.0019\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 535us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 539us/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 546us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 541us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 537us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 14s 4ms/step - loss: 0.0550 - val_loss: 0.0063\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 245us/step - loss: 0.0070 - val_loss: 0.0055\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 245us/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 248us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 246us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 246us/step - loss: 0.0016 - val_loss: 9.6442e-04\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 244us/step - loss: 0.0014 - val_loss: 7.7653e-04\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 246us/step - loss: 0.0014 - val_loss: 7.6997e-04\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 245us/step - loss: 0.0013 - val_loss: 7.6473e-04\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 246us/step - loss: 0.0013 - val_loss: 7.5977e-04\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 247us/step - loss: 0.0013 - val_loss: 7.6025e-04\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 247us/step - loss: 0.0013 - val_loss: 7.5838e-04\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 246us/step - loss: 0.0012 - val_loss: 7.6304e-04\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 247us/step - loss: 0.0012 - val_loss: 7.7658e-04\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 247us/step - loss: 0.0012 - val_loss: 7.6612e-04\n",
      "Epoch 16/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 1s 246us/step - loss: 0.0012 - val_loss: 7.6319e-04\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 246us/step - loss: 0.0012 - val_loss: 7.9085e-04\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 249us/step - loss: 0.0011 - val_loss: 7.6970e-04\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 247us/step - loss: 0.0011 - val_loss: 7.1332e-04\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 245us/step - loss: 0.0011 - val_loss: 6.7945e-04\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 249us/step - loss: 0.0011 - val_loss: 6.9532e-04\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 248us/step - loss: 0.0011 - val_loss: 6.6414e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 245us/step - loss: 0.0010 - val_loss: 6.6596e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 246us/step - loss: 0.0010 - val_loss: 6.5073e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 14s 4ms/step - loss: 0.0827 - val_loss: 0.0460\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 219us/step - loss: 0.0194 - val_loss: 0.0178\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 219us/step - loss: 0.0086 - val_loss: 0.0040\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 219us/step - loss: 0.0051 - val_loss: 0.0026\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 231us/step - loss: 0.0033 - val_loss: 9.3137e-04\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 221us/step - loss: 0.0026 - val_loss: 9.7762e-04\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 217us/step - loss: 0.0024 - val_loss: 0.0011\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 218us/step - loss: 0.0022 - val_loss: 9.1058e-04\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 219us/step - loss: 0.0021 - val_loss: 9.4350e-04\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 222us/step - loss: 0.0020 - val_loss: 9.1457e-04\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 222us/step - loss: 0.0019 - val_loss: 9.1750e-04\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 218us/step - loss: 0.0019 - val_loss: 8.3750e-04\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 219us/step - loss: 0.0017 - val_loss: 9.4246e-04\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 218us/step - loss: 0.0017 - val_loss: 8.5887e-04\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 218us/step - loss: 0.0017 - val_loss: 7.8580e-04\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 218us/step - loss: 0.0017 - val_loss: 9.2444e-04\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 219us/step - loss: 0.0016 - val_loss: 7.4408e-04\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 217us/step - loss: 0.0015 - val_loss: 8.1956e-04\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 221us/step - loss: 0.0015 - val_loss: 7.5793e-04\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 219us/step - loss: 0.0015 - val_loss: 7.5306e-04\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 218us/step - loss: 0.0014 - val_loss: 7.3160e-04\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 218us/step - loss: 0.0014 - val_loss: 7.5748e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 219us/step - loss: 0.0014 - val_loss: 7.0168e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 218us/step - loss: 0.0013 - val_loss: 6.8889e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 15s 4ms/step - loss: 0.2705 - val_loss: 0.0672\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 257us/step - loss: 0.0705 - val_loss: 0.0051\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 0.0126 - val_loss: 0.0034\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 0.0067 - val_loss: 0.0015\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 257us/step - loss: 0.0036 - val_loss: 0.0016\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 0.0030 - val_loss: 0.0014\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 258us/step - loss: 0.0027 - val_loss: 0.0013\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 0.0026 - val_loss: 0.0012\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 258us/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 257us/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 258us/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 258us/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 257us/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 258us/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 257us/step - loss: 0.0019 - val_loss: 0.0010\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 258us/step - loss: 0.0019 - val_loss: 9.9063e-04\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 260us/step - loss: 0.0018 - val_loss: 9.6008e-04\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 0.0018 - val_loss: 9.3235e-04\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 260us/step - loss: 0.0017 - val_loss: 9.2053e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 260us/step - loss: 0.0017 - val_loss: 8.8353e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 257us/step - loss: 0.0017 - val_loss: 8.6326e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 17s 4ms/step - loss: 0.8589 - val_loss: 0.0332\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 566us/step - loss: 0.0733 - val_loss: 0.0229\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 565us/step - loss: 0.0261 - val_loss: 0.0055\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 569us/step - loss: 0.0086 - val_loss: 0.0118\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 564us/step - loss: 0.0192 - val_loss: 0.0104\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 566us/step - loss: 0.0055 - val_loss: 0.0075\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 570us/step - loss: 0.0046 - val_loss: 0.0079\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 563us/step - loss: 0.0045 - val_loss: 0.0104\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 565us/step - loss: 0.0049 - val_loss: 0.0129\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 563us/step - loss: 0.0050 - val_loss: 0.0095\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 568us/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 565us/step - loss: 0.0034 - val_loss: 0.0040\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 562us/step - loss: 0.0037 - val_loss: 0.0120\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 569us/step - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 562us/step - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 565us/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 565us/step - loss: 0.0034 - val_loss: 0.0079\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 568us/step - loss: 0.0049 - val_loss: 0.0099\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 565us/step - loss: 0.0037 - val_loss: 0.0039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 563us/step - loss: 0.0032 - val_loss: 0.0050\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 564us/step - loss: 0.0028 - val_loss: 0.0023\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 564us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 564us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 565us/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 17s 4ms/step - loss: 0.2239 - val_loss: 0.0190\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 565us/step - loss: 0.0425 - val_loss: 0.2757\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 565us/step - loss: 0.0387 - val_loss: 0.0066\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 565us/step - loss: 0.0493 - val_loss: 0.0031\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 566us/step - loss: 0.0272 - val_loss: 0.1318\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 567us/step - loss: 0.0232 - val_loss: 0.0076\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 567us/step - loss: 0.0377 - val_loss: 0.0031\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 566us/step - loss: 0.0230 - val_loss: 0.0406\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 564us/step - loss: 0.0188 - val_loss: 0.0244\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 565us/step - loss: 0.0266 - val_loss: 0.0068\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 568us/step - loss: 0.0208 - val_loss: 0.0083\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 567us/step - loss: 0.0151 - val_loss: 0.0256\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 569us/step - loss: 0.0183 - val_loss: 0.0133\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 570us/step - loss: 0.0205 - val_loss: 0.0034\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 565us/step - loss: 0.0161 - val_loss: 0.0199\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 565us/step - loss: 0.0127 - val_loss: 0.0052\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 566us/step - loss: 0.0168 - val_loss: 0.0061\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 565us/step - loss: 0.0128 - val_loss: 0.0116\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 563us/step - loss: 0.0137 - val_loss: 0.0079\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 568us/step - loss: 0.0113 - val_loss: 0.0079\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 574us/step - loss: 0.0134 - val_loss: 0.0090\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 569us/step - loss: 0.0112 - val_loss: 0.0064\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 568us/step - loss: 0.0118 - val_loss: 0.0065\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 567us/step - loss: 0.0097 - val_loss: 0.0062\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 17s 4ms/step - loss: 1.2988 - val_loss: 0.0026\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 569us/step - loss: 0.0067 - val_loss: 0.0024\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 565us/step - loss: 0.0129 - val_loss: 0.1312\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 571us/step - loss: 0.0969 - val_loss: 0.0420\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 569us/step - loss: 0.0891 - val_loss: 0.1161\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 568us/step - loss: 0.0541 - val_loss: 0.1287\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 569us/step - loss: 0.0797 - val_loss: 0.0568\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 568us/step - loss: 0.0685 - val_loss: 0.0920\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 568us/step - loss: 0.0554 - val_loss: 0.0759\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 567us/step - loss: 0.0625 - val_loss: 0.0582\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 565us/step - loss: 0.0540 - val_loss: 0.0658\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 565us/step - loss: 0.0476 - val_loss: 0.0461\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 567us/step - loss: 0.0478 - val_loss: 0.0499\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 569us/step - loss: 0.0382 - val_loss: 0.0370\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 568us/step - loss: 0.0404 - val_loss: 0.0346\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 570us/step - loss: 0.0352 - val_loss: 0.0383\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 567us/step - loss: 0.0346 - val_loss: 0.0295\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 566us/step - loss: 0.0327 - val_loss: 0.0139\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 568us/step - loss: 0.0299 - val_loss: 0.0228\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 564us/step - loss: 0.0264 - val_loss: 0.0366\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 565us/step - loss: 0.0254 - val_loss: 0.0167\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 567us/step - loss: 0.0304 - val_loss: 0.0160\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 568us/step - loss: 0.0215 - val_loss: 0.0270\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 568us/step - loss: 0.0263 - val_loss: 0.0179\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 17s 4ms/step - loss: 0.1050 - val_loss: 0.0817\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 566us/step - loss: 0.0450 - val_loss: 0.0047\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 566us/step - loss: 0.0137 - val_loss: 0.0301\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 569us/step - loss: 0.0073 - val_loss: 0.0214\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 565us/step - loss: 0.0053 - val_loss: 0.0036\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 564us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 564us/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 565us/step - loss: 0.0031 - val_loss: 0.0027\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 564us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 568us/step - loss: 0.0029 - val_loss: 0.0023\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 565us/step - loss: 0.0028 - val_loss: 0.0021\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 565us/step - loss: 0.0026 - val_loss: 0.0021\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 566us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 569us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 564us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 566us/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 567us/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 568us/step - loss: 0.0024 - val_loss: 0.0015\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 569us/step - loss: 0.0024 - val_loss: 0.0015\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 569us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 569us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 567us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 568us/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 565us/step - loss: 0.0023 - val_loss: 0.0018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 18s 4ms/step - loss: 0.5986 - val_loss: 0.0081\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 567us/step - loss: 0.0762 - val_loss: 0.1080\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 567us/step - loss: 0.0719 - val_loss: 0.0284\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 567us/step - loss: 0.0642 - val_loss: 0.0145\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 568us/step - loss: 0.0557 - val_loss: 0.0210\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 570us/step - loss: 0.0350 - val_loss: 0.0050\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 569us/step - loss: 0.0111 - val_loss: 0.0078\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 567us/step - loss: 0.0086 - val_loss: 0.0088\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 570us/step - loss: 0.0054 - val_loss: 0.0044\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 567us/step - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 568us/step - loss: 0.0040 - val_loss: 0.0030\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 563us/step - loss: 0.0038 - val_loss: 0.0024\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 572us/step - loss: 0.0038 - val_loss: 0.0023\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 564us/step - loss: 0.0035 - val_loss: 0.0028\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 565us/step - loss: 0.0034 - val_loss: 0.0029\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 564us/step - loss: 0.0033 - val_loss: 0.0029\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 564us/step - loss: 0.0032 - val_loss: 0.0024\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 566us/step - loss: 0.0031 - val_loss: 0.0023\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 567us/step - loss: 0.0031 - val_loss: 0.0020\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 569us/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 565us/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 567us/step - loss: 0.0029 - val_loss: 0.0019\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 566us/step - loss: 0.0030 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 567us/step - loss: 0.0029 - val_loss: 0.0019\n",
      "\n",
      "GENERATION 12\n",
      "\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 16s 4ms/step - loss: 0.0405 - val_loss: 0.0013\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 196us/step - loss: 0.0039 - val_loss: 0.0012\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 200us/step - loss: 0.0033 - val_loss: 0.0015\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 197us/step - loss: 0.0032 - val_loss: 0.0012\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 196us/step - loss: 0.0031 - val_loss: 0.0019\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 197us/step - loss: 0.0033 - val_loss: 0.0047\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 195us/step - loss: 0.0053 - val_loss: 0.0073\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 197us/step - loss: 0.0050 - val_loss: 0.0029\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 196us/step - loss: 0.0031 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 197us/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 196us/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 198us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 197us/step - loss: 0.0038 - val_loss: 0.0060\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 196us/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 197us/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 197us/step - loss: 0.0032 - val_loss: 0.0040\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 197us/step - loss: 0.0026 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 196us/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 197us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 198us/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 197us/step - loss: 0.0032 - val_loss: 0.0039\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 197us/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 200us/step - loss: 0.0018 - val_loss: 9.8621e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 198us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 16s 4ms/step - loss: 0.0945 - val_loss: 0.0018\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 252us/step - loss: 0.0091 - val_loss: 0.0011\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 249us/step - loss: 0.0044 - val_loss: 9.3666e-04\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 244us/step - loss: 0.0029 - val_loss: 0.0012\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 246us/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 246us/step - loss: 0.0017 - val_loss: 8.7730e-04\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 247us/step - loss: 0.0015 - val_loss: 9.0161e-04\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 249us/step - loss: 0.0014 - val_loss: 8.3501e-04\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 245us/step - loss: 0.0014 - val_loss: 8.2327e-04\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 247us/step - loss: 0.0013 - val_loss: 8.3187e-04\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 250us/step - loss: 0.0013 - val_loss: 8.0575e-04\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 247us/step - loss: 0.0012 - val_loss: 7.8613e-04\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 247us/step - loss: 0.0012 - val_loss: 7.6740e-04\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 249us/step - loss: 0.0012 - val_loss: 7.5322e-04\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 247us/step - loss: 0.0011 - val_loss: 7.9532e-04\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 247us/step - loss: 0.0012 - val_loss: 7.1289e-04\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 245us/step - loss: 0.0011 - val_loss: 6.9953e-04\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 245us/step - loss: 0.0011 - val_loss: 6.8269e-04\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 247us/step - loss: 0.0011 - val_loss: 7.0786e-04\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 248us/step - loss: 0.0010 - val_loss: 6.7472e-04\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 248us/step - loss: 9.7383e-04 - val_loss: 6.3808e-04\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 248us/step - loss: 9.8701e-04 - val_loss: 6.4347e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 247us/step - loss: 9.4821e-04 - val_loss: 7.4350e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 247us/step - loss: 9.4802e-04 - val_loss: 7.8625e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 18s 4ms/step - loss: 0.2200 - val_loss: 0.1556\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0827 - val_loss: 0.0599\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0459 - val_loss: 0.0270\n",
      "Epoch 4/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0340 - val_loss: 0.0147\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0286 - val_loss: 0.0100\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0255 - val_loss: 0.0076\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0229 - val_loss: 0.0063\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0206 - val_loss: 0.0054\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0187 - val_loss: 0.0047\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0169 - val_loss: 0.0042\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0152 - val_loss: 0.0038\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0136 - val_loss: 0.0034\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0123 - val_loss: 0.0031\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0111 - val_loss: 0.0027\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 0.0098 - val_loss: 0.0025\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0089 - val_loss: 0.0024\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0081 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 529us/step - loss: 0.0074 - val_loss: 0.0021\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0065 - val_loss: 0.0021\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0059 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0054 - val_loss: 0.0020\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0049 - val_loss: 0.0020\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 0.0046 - val_loss: 0.0021\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0043 - val_loss: 0.0021\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 18s 5ms/step - loss: 0.2172 - val_loss: 0.1655\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0894 - val_loss: 0.0633\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0483 - val_loss: 0.0266\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0356 - val_loss: 0.0138\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 528us/step - loss: 0.0306 - val_loss: 0.0090\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 529us/step - loss: 0.0272 - val_loss: 0.0069\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 0.0253 - val_loss: 0.0058\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 0.0230 - val_loss: 0.0051\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0213 - val_loss: 0.0045\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0193 - val_loss: 0.0041\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 0.0179 - val_loss: 0.0036\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0161 - val_loss: 0.0033\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 528us/step - loss: 0.0148 - val_loss: 0.0030\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0133 - val_loss: 0.0028\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 535us/step - loss: 0.0124 - val_loss: 0.0026\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 0.0110 - val_loss: 0.0025\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0101 - val_loss: 0.0024\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 0.0092 - val_loss: 0.0023\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 0.0084 - val_loss: 0.0023\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 529us/step - loss: 0.0077 - val_loss: 0.0023\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0072 - val_loss: 0.0023\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 0.0070 - val_loss: 0.0023\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0062 - val_loss: 0.0024\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0059 - val_loss: 0.0024\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 18s 4ms/step - loss: 0.0625 - val_loss: 0.0077\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 340us/step - loss: 0.0185 - val_loss: 0.0042\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 340us/step - loss: 0.0118 - val_loss: 0.0023\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 338us/step - loss: 0.0087 - val_loss: 0.0020\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 341us/step - loss: 0.0070 - val_loss: 0.0019\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 341us/step - loss: 0.0062 - val_loss: 0.0021\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 342us/step - loss: 0.0056 - val_loss: 0.0023\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 340us/step - loss: 0.0055 - val_loss: 0.0024\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 339us/step - loss: 0.0052 - val_loss: 0.0024\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 339us/step - loss: 0.0055 - val_loss: 0.0027\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 340us/step - loss: 0.0050 - val_loss: 0.0026\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 340us/step - loss: 0.0052 - val_loss: 0.0028\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 340us/step - loss: 0.0051 - val_loss: 0.0026\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 342us/step - loss: 0.0049 - val_loss: 0.0025\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 338us/step - loss: 0.0046 - val_loss: 0.0028\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 338us/step - loss: 0.0047 - val_loss: 0.0025\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 340us/step - loss: 0.0049 - val_loss: 0.0027\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 341us/step - loss: 0.0047 - val_loss: 0.0024\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 342us/step - loss: 0.0044 - val_loss: 0.0028\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 338us/step - loss: 0.0048 - val_loss: 0.0024\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 339us/step - loss: 0.0046 - val_loss: 0.0024\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 341us/step - loss: 0.0044 - val_loss: 0.0026\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 342us/step - loss: 0.0045 - val_loss: 0.0025\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 340us/step - loss: 0.0045 - val_loss: 0.0027\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 18s 5ms/step - loss: 0.1466 - val_loss: 0.0565\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 336us/step - loss: 0.0628 - val_loss: 0.0294\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 337us/step - loss: 0.0550 - val_loss: 0.0227\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 337us/step - loss: 0.0480 - val_loss: 0.0197\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 337us/step - loss: 0.0432 - val_loss: 0.0166\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 337us/step - loss: 0.0382 - val_loss: 0.0147\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 338us/step - loss: 0.0331 - val_loss: 0.0128\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 339us/step - loss: 0.0288 - val_loss: 0.0104\n",
      "Epoch 9/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 1s 338us/step - loss: 0.0251 - val_loss: 0.0087\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 342us/step - loss: 0.0212 - val_loss: 0.0066\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 340us/step - loss: 0.0181 - val_loss: 0.0053\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 343us/step - loss: 0.0159 - val_loss: 0.0041\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 341us/step - loss: 0.0136 - val_loss: 0.0033\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 337us/step - loss: 0.0117 - val_loss: 0.0029\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 335us/step - loss: 0.0102 - val_loss: 0.0025\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 337us/step - loss: 0.0092 - val_loss: 0.0023\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 338us/step - loss: 0.0083 - val_loss: 0.0023\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 339us/step - loss: 0.0074 - val_loss: 0.0024\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 338us/step - loss: 0.0071 - val_loss: 0.0025\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 338us/step - loss: 0.0064 - val_loss: 0.0027\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 337us/step - loss: 0.0060 - val_loss: 0.0030\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 338us/step - loss: 0.0059 - val_loss: 0.0033\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 338us/step - loss: 0.0055 - val_loss: 0.0034\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 339us/step - loss: 0.0053 - val_loss: 0.0036\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 19s 5ms/step - loss: 0.1407 - val_loss: 0.0103\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 0.0146 - val_loss: 0.0025\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 529us/step - loss: 0.0119 - val_loss: 0.0031\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0103 - val_loss: 0.0024\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 0.0102 - val_loss: 0.0027\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 0.0089 - val_loss: 0.0024\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 0.0084 - val_loss: 0.0026\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 0.0083 - val_loss: 0.0031\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 0.0083 - val_loss: 0.0023\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 0.0078 - val_loss: 0.0022\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 0.0074 - val_loss: 0.0025\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 0.0072 - val_loss: 0.0035\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 0.0070 - val_loss: 0.0021\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 0.0067 - val_loss: 0.0022\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0064 - val_loss: 0.0024\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 0.0060 - val_loss: 0.0021\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 528us/step - loss: 0.0062 - val_loss: 0.0021\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 0.0059 - val_loss: 0.0021\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 529us/step - loss: 0.0062 - val_loss: 0.0022\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 0.0055 - val_loss: 0.0021\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 0.0057 - val_loss: 0.0020\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 0.0056 - val_loss: 0.0020\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 0.0054 - val_loss: 0.0020\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 0.0053 - val_loss: 0.0020\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 19s 5ms/step - loss: 0.0655 - val_loss: 0.0029\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 0.0122 - val_loss: 0.0024\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 0.0094 - val_loss: 0.0025\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0088 - val_loss: 0.0028\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0081 - val_loss: 0.0038\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 0.0076 - val_loss: 0.0038\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0076 - val_loss: 0.0030\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0070 - val_loss: 0.0031\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 0.0069 - val_loss: 0.0031\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0064 - val_loss: 0.0027\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0061 - val_loss: 0.0024\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0063 - val_loss: 0.0026\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 0.0058 - val_loss: 0.0030\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0059 - val_loss: 0.0027\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0057 - val_loss: 0.0026\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 0.0057 - val_loss: 0.0030\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 526us/step - loss: 0.0057 - val_loss: 0.0027\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0055 - val_loss: 0.0027\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0053 - val_loss: 0.0024\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0051 - val_loss: 0.0025\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: 0.0050 - val_loss: 0.0027\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: 0.0053 - val_loss: 0.0026\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: 0.0049 - val_loss: 0.0025\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: 0.0047 - val_loss: 0.0024\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 19s 5ms/step - loss: 0.2237 - val_loss: 0.0016\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 332us/step - loss: 0.0063 - val_loss: 0.0016\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 332us/step - loss: 0.0091 - val_loss: 0.0042\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 334us/step - loss: 0.0056 - val_loss: 0.0027\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 333us/step - loss: 0.0041 - val_loss: 0.0029\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 335us/step - loss: 0.0042 - val_loss: 0.0086\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 332us/step - loss: 0.0064 - val_loss: 0.0027\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 333us/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 336us/step - loss: 0.0030 - val_loss: 0.0013\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 333us/step - loss: 0.0028 - val_loss: 0.0013\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 338us/step - loss: 0.0040 - val_loss: 0.0111\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 332us/step - loss: 0.0088 - val_loss: 0.0017\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 333us/step - loss: 0.0030 - val_loss: 0.0014\n",
      "Epoch 14/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 1s 334us/step - loss: 0.0025 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 332us/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 333us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 333us/step - loss: 0.0031 - val_loss: 0.0024\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 334us/step - loss: 0.0028 - val_loss: 0.0016\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 333us/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 332us/step - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 331us/step - loss: 0.0043 - val_loss: 0.0029\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 337us/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 350us/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 333us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "\n",
      "GENERATION 13\n",
      "\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 18s 5ms/step - loss: 0.2286 - val_loss: 0.1917\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 190us/step - loss: 0.0548 - val_loss: 0.0064\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 189us/step - loss: 0.0134 - val_loss: 0.0110\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 189us/step - loss: 0.0069 - val_loss: 0.0054\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 191us/step - loss: 0.0040 - val_loss: 0.0032\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 192us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 188us/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 189us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 188us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 189us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 188us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 188us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 189us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 187us/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 189us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 188us/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 189us/step - loss: 0.0014 - val_loss: 9.8168e-04\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 189us/step - loss: 0.0014 - val_loss: 9.8281e-04\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 189us/step - loss: 0.0013 - val_loss: 9.9796e-04\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 189us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 194us/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 188us/step - loss: 0.0012 - val_loss: 9.3930e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 189us/step - loss: 0.0011 - val_loss: 8.5172e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 188us/step - loss: 0.0011 - val_loss: 8.4491e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 18s 5ms/step - loss: 0.0484 - val_loss: 0.0130\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 248us/step - loss: 0.0072 - val_loss: 0.0066\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 249us/step - loss: 0.0036 - val_loss: 0.0032\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 248us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 248us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 247us/step - loss: 0.0015 - val_loss: 9.9105e-04\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 247us/step - loss: 0.0014 - val_loss: 7.9700e-04\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 248us/step - loss: 0.0013 - val_loss: 7.9922e-04\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 250us/step - loss: 0.0013 - val_loss: 7.9059e-04\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 249us/step - loss: 0.0013 - val_loss: 7.4767e-04\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 248us/step - loss: 0.0012 - val_loss: 7.1923e-04\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 248us/step - loss: 0.0012 - val_loss: 8.3376e-04\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 247us/step - loss: 0.0011 - val_loss: 9.0156e-04\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 248us/step - loss: 0.0011 - val_loss: 9.6026e-04\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 246us/step - loss: 0.0010 - val_loss: 8.7172e-04\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 253us/step - loss: 0.0010 - val_loss: 8.5337e-04\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 250us/step - loss: 9.8421e-04 - val_loss: 8.0280e-04\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 248us/step - loss: 9.6812e-04 - val_loss: 7.7554e-04\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 247us/step - loss: 9.6340e-04 - val_loss: 7.6860e-04\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 248us/step - loss: 8.7265e-04 - val_loss: 0.0010\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 247us/step - loss: 8.6968e-04 - val_loss: 8.8421e-04\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 247us/step - loss: 9.0164e-04 - val_loss: 6.8838e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 249us/step - loss: 8.9756e-04 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 248us/step - loss: 8.6102e-04 - val_loss: 9.5555e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 19s 5ms/step - loss: 0.0306 - val_loss: 0.0012\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 246us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 250us/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 249us/step - loss: 0.0025 - val_loss: 8.9310e-04\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 248us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 248us/step - loss: 0.0031 - val_loss: 0.0025\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 250us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 248us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 246us/step - loss: 0.0026 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 253us/step - loss: 0.0015 - val_loss: 8.8962e-04\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 248us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 246us/step - loss: 0.0019 - val_loss: 9.0701e-04\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 246us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 247us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 246us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 247us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 17/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 1s 248us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 246us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 247us/step - loss: 0.0013 - val_loss: 9.9462e-04\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 247us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 246us/step - loss: 0.0014 - val_loss: 8.0840e-04\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 246us/step - loss: 0.0014 - val_loss: 8.0211e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 251us/step - loss: 0.0012 - val_loss: 6.5977e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 248us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 21s 5ms/step - loss: 0.1014 - val_loss: 0.0026\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 537us/step - loss: 0.0079 - val_loss: 0.0053\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 535us/step - loss: 0.0048 - val_loss: 0.0121\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.0062 - val_loss: 0.0052\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 537us/step - loss: 0.0033 - val_loss: 0.0045\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 536us/step - loss: 0.0034 - val_loss: 0.0056\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 536us/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 536us/step - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 537us/step - loss: 0.0022 - val_loss: 0.0055\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 536us/step - loss: 0.0052 - val_loss: 0.0058\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 536us/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 536us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 541us/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 537us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 536us/step - loss: 0.0034 - val_loss: 0.0041\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.0031 - val_loss: 0.0025\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 539us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 539us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 535us/step - loss: 0.0024 - val_loss: 0.0015\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 20s 5ms/step - loss: 0.0989 - val_loss: 0.0035\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0181 - val_loss: 0.0084\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 399us/step - loss: 0.0115 - val_loss: 0.0574\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 401us/step - loss: 0.0115 - val_loss: 0.0078\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 398us/step - loss: 0.0107 - val_loss: 0.0121\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 399us/step - loss: 0.0072 - val_loss: 0.0075\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 399us/step - loss: 0.0094 - val_loss: 0.0152\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 399us/step - loss: 0.0091 - val_loss: 0.0039\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 401us/step - loss: 0.0062 - val_loss: 0.0036\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0050 - val_loss: 0.0032\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0072 - val_loss: 0.0086\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 401us/step - loss: 0.0102 - val_loss: 0.0093\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0071 - val_loss: 0.0053\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0075 - val_loss: 0.0083\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 406us/step - loss: 0.0083 - val_loss: 0.0059\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 403us/step - loss: 0.0066 - val_loss: 0.0051\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0075 - val_loss: 0.0094\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0108 - val_loss: 0.0040\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 399us/step - loss: 0.0052 - val_loss: 0.0065\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 399us/step - loss: 0.0071 - val_loss: 0.0046\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 401us/step - loss: 0.0089 - val_loss: 0.0102\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 399us/step - loss: 0.0077 - val_loss: 0.0038\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 398us/step - loss: 0.0052 - val_loss: 0.0036\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0062 - val_loss: 0.0061\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 21s 5ms/step - loss: 0.7384 - val_loss: 0.0072\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 402us/step - loss: 0.0445 - val_loss: 0.0017\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 401us/step - loss: 0.0074 - val_loss: 0.0025\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 403us/step - loss: 0.0058 - val_loss: 0.0045\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 402us/step - loss: 0.0063 - val_loss: 0.0161\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 405us/step - loss: 0.0207 - val_loss: 0.0156\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 402us/step - loss: 0.0061 - val_loss: 0.0029\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 407us/step - loss: 0.0034 - val_loss: 0.0023\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0032 - val_loss: 0.0016\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 402us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 403us/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 402us/step - loss: 0.0102 - val_loss: 0.0088\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 405us/step - loss: 0.0062 - val_loss: 0.0017\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 404us/step - loss: 0.0039 - val_loss: 0.0015\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 404us/step - loss: 0.0040 - val_loss: 0.0025\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 406us/step - loss: 0.0043 - val_loss: 0.0020\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 405us/step - loss: 0.0040 - val_loss: 0.0018\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 408us/step - loss: 0.0051 - val_loss: 0.0054\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 408us/step - loss: 0.0062 - val_loss: 0.0049\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 403us/step - loss: 0.0052 - val_loss: 0.0021\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0035 - val_loss: 0.0013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 403us/step - loss: 0.0029 - val_loss: 0.0020\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 402us/step - loss: 0.0035 - val_loss: 0.0020\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0045 - val_loss: 0.0039\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 20s 5ms/step - loss: 0.2197 - val_loss: 0.0015\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 402us/step - loss: 0.0067 - val_loss: 0.0088\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 405us/step - loss: 0.0104 - val_loss: 0.0079\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 403us/step - loss: 0.0042 - val_loss: 0.0027\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 408us/step - loss: 0.0037 - val_loss: 0.0014\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 405us/step - loss: 0.0042 - val_loss: 0.0015\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 403us/step - loss: 0.0049 - val_loss: 0.0016\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 405us/step - loss: 0.0043 - val_loss: 0.0012\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 402us/step - loss: 0.0033 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 402us/step - loss: 0.0040 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 404us/step - loss: 0.0040 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 399us/step - loss: 0.0036 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 401us/step - loss: 0.0031 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 402us/step - loss: 0.0026 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 407us/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 402us/step - loss: 0.0068 - val_loss: 0.0034\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 401us/step - loss: 0.0032 - val_loss: 0.0013\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 402us/step - loss: 0.0026 - val_loss: 0.0013\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 402us/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 402us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 405us/step - loss: 0.0076 - val_loss: 0.0100\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 401us/step - loss: 0.0037 - val_loss: 0.0023\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 402us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 22s 5ms/step - loss: 0.0664 - val_loss: 0.0016\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0049 - val_loss: 0.0016\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 402us/step - loss: 0.0071 - val_loss: 0.0176\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 399us/step - loss: 0.0083 - val_loss: 0.0017\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0034 - val_loss: 0.0013\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 404us/step - loss: 0.0043 - val_loss: 0.0066\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 399us/step - loss: 0.0098 - val_loss: 0.0029\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 401us/step - loss: 0.0039 - val_loss: 0.0016\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 401us/step - loss: 0.0032 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 404us/step - loss: 0.0051 - val_loss: 0.0027\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0060 - val_loss: 0.0039\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 401us/step - loss: 0.0038 - val_loss: 0.0016\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 401us/step - loss: 0.0036 - val_loss: 0.0022\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0032 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 402us/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0071 - val_loss: 0.0048\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 401us/step - loss: 0.0042 - val_loss: 0.0013\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 401us/step - loss: 0.0032 - val_loss: 0.0015\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 401us/step - loss: 0.0033 - val_loss: 0.0012\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 405us/step - loss: 0.0025 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0055 - val_loss: 0.0032\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 404us/step - loss: 0.0038 - val_loss: 0.0014\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 21s 5ms/step - loss: 0.6610 - val_loss: 0.0084\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 401us/step - loss: 0.0197 - val_loss: 0.0018\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0059 - val_loss: 0.0039\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 403us/step - loss: 0.0036 - val_loss: 0.0043\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 401us/step - loss: 0.0033 - val_loss: 0.0060\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 406us/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 402us/step - loss: 0.0032 - val_loss: 0.0048\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 412us/step - loss: 0.0031 - val_loss: 0.0044\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 406us/step - loss: 0.0029 - val_loss: 0.0027\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 401us/step - loss: 0.0029 - val_loss: 0.0015\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 401us/step - loss: 0.0030 - val_loss: 0.0024\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0027 - val_loss: 0.0042\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0029 - val_loss: 0.0054\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 404us/step - loss: 0.0027 - val_loss: 0.0021\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 403us/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 403us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 401us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 402us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 404us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 401us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 401us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "\n",
      "GENERATION 14\n",
      "\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 21s 5ms/step - loss: 0.1437 - val_loss: 0.1030\n",
      "Epoch 2/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 1s 222us/step - loss: 0.0158 - val_loss: 0.0029\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 222us/step - loss: 0.0042 - val_loss: 0.0060\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 222us/step - loss: 0.0037 - val_loss: 0.0040\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 224us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 225us/step - loss: 0.0027 - val_loss: 0.0052\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 225us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 222us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 223us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 224us/step - loss: 0.0028 - val_loss: 0.0056\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 223us/step - loss: 0.0037 - val_loss: 0.0022\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 223us/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 222us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 223us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 223us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 222us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 222us/step - loss: 0.0034 - val_loss: 0.0025\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 223us/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 224us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 227us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 222us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 223us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 223us/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 226us/step - loss: 0.0012 - val_loss: 8.7698e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 21s 5ms/step - loss: 0.0614 - val_loss: 0.0052\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 250us/step - loss: 0.0085 - val_loss: 0.0018\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 251us/step - loss: 0.0041 - val_loss: 0.0017\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 252us/step - loss: 0.0026 - val_loss: 0.0012\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 250us/step - loss: 0.0018 - val_loss: 8.9927e-04\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 249us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 248us/step - loss: 0.0014 - val_loss: 8.5642e-04\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 252us/step - loss: 0.0014 - val_loss: 8.6524e-04\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 253us/step - loss: 0.0013 - val_loss: 8.1069e-04\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 250us/step - loss: 0.0013 - val_loss: 8.3973e-04\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 249us/step - loss: 0.0012 - val_loss: 8.1105e-04\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 250us/step - loss: 0.0013 - val_loss: 7.7848e-04\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 250us/step - loss: 0.0012 - val_loss: 8.1375e-04\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 249us/step - loss: 0.0012 - val_loss: 7.8177e-04\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 250us/step - loss: 0.0011 - val_loss: 7.6865e-04\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 251us/step - loss: 0.0011 - val_loss: 8.0431e-04\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 253us/step - loss: 0.0011 - val_loss: 7.5703e-04\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 249us/step - loss: 0.0011 - val_loss: 7.4645e-04\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 251us/step - loss: 0.0011 - val_loss: 7.0429e-04\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 251us/step - loss: 0.0010 - val_loss: 6.8760e-04\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 250us/step - loss: 0.0010 - val_loss: 7.1727e-04\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 252us/step - loss: 9.9565e-04 - val_loss: 7.5008e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 251us/step - loss: 0.0010 - val_loss: 7.1902e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 248us/step - loss: 9.8583e-04 - val_loss: 9.2843e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 22s 6ms/step - loss: 0.0900 - val_loss: 0.0050\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 383us/step - loss: 0.0141 - val_loss: 0.0076\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 383us/step - loss: 0.0069 - val_loss: 0.0060\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 384us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 388us/step - loss: 0.0031 - val_loss: 0.0018\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 384us/step - loss: 0.0028 - val_loss: 0.0015\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 385us/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 384us/step - loss: 0.0024 - val_loss: 0.0015\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 383us/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 385us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 383us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 384us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 385us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 384us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 389us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 388us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 384us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 384us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 383us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 383us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 386us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 384us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 387us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 385us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 23s 6ms/step - loss: 0.1147 - val_loss: 0.0026\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 430us/step - loss: 0.0129 - val_loss: 0.0117\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 429us/step - loss: 0.0076 - val_loss: 0.0047\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 427us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 431us/step - loss: 0.0032 - val_loss: 0.0046\n",
      "Epoch 6/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 2s 428us/step - loss: 0.0028 - val_loss: 0.0020\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 427us/step - loss: 0.0026 - val_loss: 0.0020\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 428us/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 429us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 431us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 429us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 428us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 429us/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 430us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 431us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 435us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 430us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 434us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 428us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 429us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 431us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 429us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 429us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 430us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 23s 6ms/step - loss: 0.0770 - val_loss: 0.0042\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 429us/step - loss: 0.0094 - val_loss: 0.0038\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 430us/step - loss: 0.0062 - val_loss: 0.0117\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 430us/step - loss: 0.0043 - val_loss: 0.0015\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 429us/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 430us/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 429us/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 431us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 429us/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 434us/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 429us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 430us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 431us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 431us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 432us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 431us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 432us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 435us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 431us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 432us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 431us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 428us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 428us/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 428us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 24s 6ms/step - loss: 0.0603 - val_loss: 0.0240\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 493us/step - loss: 0.0106 - val_loss: 0.0019\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 492us/step - loss: 0.0059 - val_loss: 0.0121\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0046 - val_loss: 0.0014\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 491us/step - loss: 0.0032 - val_loss: 0.0014\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 492us/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 494us/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 492us/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 498us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 491us/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 492us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 493us/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 491us/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 492us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 494us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 492us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 491us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 493us/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 491us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 492us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 494us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 24s 6ms/step - loss: 0.0649 - val_loss: 0.0175\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 493us/step - loss: 0.0104 - val_loss: 0.0157\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 494us/step - loss: 0.0088 - val_loss: 0.0162\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 494us/step - loss: 0.0086 - val_loss: 0.0157\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 492us/step - loss: 0.0068 - val_loss: 0.0110\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 491us/step - loss: 0.0071 - val_loss: 0.0104\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 493us/step - loss: 0.0071 - val_loss: 0.0176\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 492us/step - loss: 0.0098 - val_loss: 0.0106\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0065 - val_loss: 0.0104\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 491us/step - loss: 0.0067 - val_loss: 0.0097\n",
      "Epoch 11/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0061 - val_loss: 0.0144\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0068 - val_loss: 0.0100\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0068 - val_loss: 0.0083\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0066 - val_loss: 0.0089\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0058 - val_loss: 0.0115\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 492us/step - loss: 0.0076 - val_loss: 0.0112\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 491us/step - loss: 0.0067 - val_loss: 0.0104\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 491us/step - loss: 0.0061 - val_loss: 0.0098\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 495us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0040 - val_loss: 0.0087\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0054 - val_loss: 0.0108\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 491us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0073 - val_loss: 0.0151\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 493us/step - loss: 0.0066 - val_loss: 0.0087\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 25s 6ms/step - loss: 0.0641 - val_loss: 0.0018\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0063 - val_loss: 0.0017\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 491us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 492us/step - loss: 0.0052 - val_loss: 0.0086\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 494us/step - loss: 0.0093 - val_loss: 0.0168\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 492us/step - loss: 0.0111 - val_loss: 0.0154\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0079 - val_loss: 0.0148\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0104 - val_loss: 0.0089\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 491us/step - loss: 0.0077 - val_loss: 0.0116\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0088 - val_loss: 0.0145\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 491us/step - loss: 0.0090 - val_loss: 0.0078\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 493us/step - loss: 0.0079 - val_loss: 0.0172\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 497us/step - loss: 0.0092 - val_loss: 0.0089\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 493us/step - loss: 0.0067 - val_loss: 0.0147\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0087 - val_loss: 0.0090\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0058 - val_loss: 0.0126\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0071 - val_loss: 0.0053\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0052 - val_loss: 0.0116\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0080 - val_loss: 0.0177\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0075 - val_loss: 0.0149\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 492us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 489us/step - loss: 0.0063 - val_loss: 0.0096\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 488us/step - loss: 0.0055 - val_loss: 0.0084\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 491us/step - loss: 0.0058 - val_loss: 0.0089\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 25s 6ms/step - loss: 0.0458 - val_loss: 0.0025\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 492us/step - loss: 0.0058 - val_loss: 0.0018\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 491us/step - loss: 0.0050 - val_loss: 0.0021\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 492us/step - loss: 0.0087 - val_loss: 0.0142\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 491us/step - loss: 0.0129 - val_loss: 0.0043\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 494us/step - loss: 0.0069 - val_loss: 0.0054\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 497us/step - loss: 0.0071 - val_loss: 0.0051\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0069 - val_loss: 0.0075\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 493us/step - loss: 0.0112 - val_loss: 0.0091\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 492us/step - loss: 0.0074 - val_loss: 0.0052\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 493us/step - loss: 0.0065 - val_loss: 0.0036\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 491us/step - loss: 0.0060 - val_loss: 0.0056\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0072 - val_loss: 0.0051\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 493us/step - loss: 0.0088 - val_loss: 0.0082\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0073 - val_loss: 0.0028\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 492us/step - loss: 0.0060 - val_loss: 0.0098\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 494us/step - loss: 0.0086 - val_loss: 0.0029\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 495us/step - loss: 0.0062 - val_loss: 0.0094\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0068 - val_loss: 0.0022\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 496us/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 493us/step - loss: 0.0051 - val_loss: 0.0029\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 497us/step - loss: 0.0052 - val_loss: 0.0019\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 492us/step - loss: 0.0032 - val_loss: 0.0012\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 490us/step - loss: 0.0029 - val_loss: 0.0014\n",
      "\n",
      "GENERATION 15\n",
      "\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 23s 6ms/step - loss: 0.0400 - val_loss: 0.0248\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 255us/step - loss: 0.0111 - val_loss: 0.0093\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 250us/step - loss: 0.0056 - val_loss: 0.0035\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 250us/step - loss: 0.0039 - val_loss: 0.0029\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 249us/step - loss: 0.0034 - val_loss: 0.0012\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 250us/step - loss: 0.0029 - val_loss: 0.0013\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 250us/step - loss: 0.0027 - val_loss: 7.5296e-04\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 250us/step - loss: 0.0024 - val_loss: 8.9452e-04\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 250us/step - loss: 0.0023 - val_loss: 7.8477e-04\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 250us/step - loss: 0.0022 - val_loss: 7.8059e-04\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 250us/step - loss: 0.0021 - val_loss: 7.0415e-04\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 253us/step - loss: 0.0020 - val_loss: 7.4391e-04\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 249us/step - loss: 0.0019 - val_loss: 8.0463e-04\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 249us/step - loss: 0.0019 - val_loss: 7.0233e-04\n",
      "Epoch 15/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 1s 250us/step - loss: 0.0018 - val_loss: 6.9971e-04\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 250us/step - loss: 0.0019 - val_loss: 7.5407e-04\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 250us/step - loss: 0.0017 - val_loss: 6.8124e-04\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 250us/step - loss: 0.0016 - val_loss: 6.5361e-04\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 251us/step - loss: 0.0016 - val_loss: 6.5732e-04\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 250us/step - loss: 0.0017 - val_loss: 6.4052e-04\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 251us/step - loss: 0.0016 - val_loss: 6.6585e-04\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 250us/step - loss: 0.0015 - val_loss: 8.1114e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 250us/step - loss: 0.0016 - val_loss: 6.8909e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 251us/step - loss: 0.0016 - val_loss: 6.5110e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 24s 6ms/step - loss: 0.0904 - val_loss: 0.0019\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 251us/step - loss: 0.0089 - val_loss: 0.0017\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 252us/step - loss: 0.0045 - val_loss: 0.0013\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 252us/step - loss: 0.0026 - val_loss: 0.0011\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 252us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 253us/step - loss: 0.0018 - val_loss: 8.3434e-04\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 251us/step - loss: 0.0016 - val_loss: 8.4990e-04\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 252us/step - loss: 0.0016 - val_loss: 8.6740e-04\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 251us/step - loss: 0.0015 - val_loss: 8.0306e-04\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 252us/step - loss: 0.0015 - val_loss: 8.0404e-04\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 253us/step - loss: 0.0014 - val_loss: 7.7591e-04\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 253us/step - loss: 0.0013 - val_loss: 7.6632e-04\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 0.0013 - val_loss: 7.4198e-04\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 253us/step - loss: 0.0013 - val_loss: 7.8770e-04\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 251us/step - loss: 0.0013 - val_loss: 7.4181e-04\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 252us/step - loss: 0.0012 - val_loss: 7.1952e-04\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 252us/step - loss: 0.0012 - val_loss: 7.3066e-04\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 253us/step - loss: 0.0011 - val_loss: 7.0075e-04\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 252us/step - loss: 0.0011 - val_loss: 6.7115e-04\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 252us/step - loss: 0.0010 - val_loss: 7.9694e-04\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 253us/step - loss: 0.0011 - val_loss: 7.8882e-04\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 252us/step - loss: 0.0011 - val_loss: 7.2709e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 252us/step - loss: 9.5261e-04 - val_loss: 6.3801e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 251us/step - loss: 9.8146e-04 - val_loss: 6.0661e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 24s 6ms/step - loss: 0.0260 - val_loss: 0.0145\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 253us/step - loss: 0.0068 - val_loss: 0.0011\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 254us/step - loss: 0.0041 - val_loss: 8.2365e-04\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 253us/step - loss: 0.0029 - val_loss: 8.1859e-04\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 252us/step - loss: 0.0026 - val_loss: 0.0013\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 252us/step - loss: 0.0022 - val_loss: 7.6001e-04\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 251us/step - loss: 0.0020 - val_loss: 8.5904e-04\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 253us/step - loss: 0.0019 - val_loss: 6.8285e-04\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 253us/step - loss: 0.0018 - val_loss: 6.8297e-04\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 253us/step - loss: 0.0016 - val_loss: 7.4343e-04\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 252us/step - loss: 0.0016 - val_loss: 7.5609e-04\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 251us/step - loss: 0.0015 - val_loss: 7.7746e-04\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 256us/step - loss: 0.0014 - val_loss: 6.4679e-04\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 252us/step - loss: 0.0014 - val_loss: 6.6087e-04\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 253us/step - loss: 0.0014 - val_loss: 6.2661e-04\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 252us/step - loss: 0.0013 - val_loss: 6.2338e-04\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 251us/step - loss: 0.0014 - val_loss: 6.3521e-04\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 255us/step - loss: 0.0013 - val_loss: 6.4440e-04\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 253us/step - loss: 0.0012 - val_loss: 6.1234e-04\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 254us/step - loss: 0.0013 - val_loss: 6.0865e-04\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 252us/step - loss: 0.0012 - val_loss: 6.2109e-04\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 254us/step - loss: 0.0012 - val_loss: 6.7577e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 257us/step - loss: 0.0012 - val_loss: 6.0105e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 253us/step - loss: 0.0012 - val_loss: 5.7782e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 26s 7ms/step - loss: 0.1105 - val_loss: 0.0026\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 537us/step - loss: 0.0263 - val_loss: 0.0018\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 535us/step - loss: 0.0237 - val_loss: 0.0017\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 541us/step - loss: 0.0051 - val_loss: 0.0181\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.0211 - val_loss: 0.0076\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 540us/step - loss: 0.0171 - val_loss: 0.0181\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 539us/step - loss: 0.0132 - val_loss: 0.0138\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 536us/step - loss: 0.0194 - val_loss: 0.0104\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 537us/step - loss: 0.0095 - val_loss: 0.0218\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 539us/step - loss: 0.0134 - val_loss: 0.0147\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0140 - val_loss: 0.0134\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0105 - val_loss: 0.0126\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 539us/step - loss: 0.0125 - val_loss: 0.0149\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.0088 - val_loss: 0.0174\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 539us/step - loss: 0.0120 - val_loss: 0.0119\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 537us/step - loss: 0.0091 - val_loss: 0.0157\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.0118 - val_loss: 0.0138\n",
      "Epoch 18/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 2s 536us/step - loss: 0.0073 - val_loss: 0.0141\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 536us/step - loss: 0.0119 - val_loss: 0.0084\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 539us/step - loss: 0.0068 - val_loss: 0.0165\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 543us/step - loss: 0.0108 - val_loss: 0.0130\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 537us/step - loss: 0.0075 - val_loss: 0.0110\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 536us/step - loss: 0.0109 - val_loss: 0.0079\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.0058 - val_loss: 0.0152\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 27s 7ms/step - loss: 0.3682 - val_loss: 0.0180\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 586us/step - loss: 0.0646 - val_loss: 0.0178\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 586us/step - loss: 0.0813 - val_loss: 0.0183\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 588us/step - loss: 0.0268 - val_loss: 0.0119\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 589us/step - loss: 0.0224 - val_loss: 0.0071\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 590us/step - loss: 0.0040 - val_loss: 0.0034\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 588us/step - loss: 0.0036 - val_loss: 0.0076\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 588us/step - loss: 0.0152 - val_loss: 0.0019\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 596us/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 588us/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 588us/step - loss: 0.0079 - val_loss: 0.0178\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 587us/step - loss: 0.0097 - val_loss: 0.0017\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 588us/step - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 585us/step - loss: 0.0033 - val_loss: 0.0043\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 586us/step - loss: 0.0088 - val_loss: 0.0041\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 583us/step - loss: 0.0039 - val_loss: 0.0017\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 585us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 589us/step - loss: 0.0060 - val_loss: 0.0038\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 586us/step - loss: 0.0045 - val_loss: 0.0023\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 588us/step - loss: 0.0044 - val_loss: 0.0038\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 589us/step - loss: 0.0066 - val_loss: 0.0029\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 585us/step - loss: 0.0038 - val_loss: 0.0014\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 586us/step - loss: 0.0031 - val_loss: 0.0026\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 583us/step - loss: 0.0045 - val_loss: 0.0031\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 28s 7ms/step - loss: 0.0500 - val_loss: 0.0086\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 437us/step - loss: 0.0144 - val_loss: 0.0028\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 437us/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 439us/step - loss: 0.0046 - val_loss: 0.0188\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 437us/step - loss: 0.0097 - val_loss: 0.0056\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 444us/step - loss: 0.0032 - val_loss: 0.0037\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 461us/step - loss: 0.0028 - val_loss: 0.0054\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 444us/step - loss: 0.0074 - val_loss: 0.0115\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 448us/step - loss: 0.0042 - val_loss: 0.0067\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 437us/step - loss: 0.0034 - val_loss: 0.0099\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 447us/step - loss: 0.0045 - val_loss: 0.0125\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 447us/step - loss: 0.0048 - val_loss: 0.0065\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 467us/step - loss: 0.0033 - val_loss: 0.0051\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 458us/step - loss: 0.0025 - val_loss: 0.0106\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 478us/step - loss: 0.0045 - val_loss: 0.0099\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 464us/step - loss: 0.0034 - val_loss: 0.0088\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 465us/step - loss: 0.0029 - val_loss: 0.0068\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 473us/step - loss: 0.0033 - val_loss: 0.0072\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 460us/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 467us/step - loss: 0.0022 - val_loss: 0.0093\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 468us/step - loss: 0.0043 - val_loss: 0.0128\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 464us/step - loss: 0.0033 - val_loss: 0.0072\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 466us/step - loss: 0.0035 - val_loss: 0.0068\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 463us/step - loss: 0.0023 - val_loss: 0.0050\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 30s 7ms/step - loss: 0.0602 - val_loss: 0.0102\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 604us/step - loss: 0.0099 - val_loss: 0.0140\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 604us/step - loss: 0.0064 - val_loss: 0.0148\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 611us/step - loss: 0.0069 - val_loss: 0.0101\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 606us/step - loss: 0.0042 - val_loss: 0.0134\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 607us/step - loss: 0.0076 - val_loss: 0.0091\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 608us/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 609us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 609us/step - loss: 0.0028 - val_loss: 0.0167\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 612us/step - loss: 0.0139 - val_loss: 0.0297\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 610us/step - loss: 0.0073 - val_loss: 0.0038\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 608us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 604us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 607us/step - loss: 0.0021 - val_loss: 0.0064\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 606us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 607us/step - loss: 0.0019 - val_loss: 0.0037\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 609us/step - loss: 0.0021 - val_loss: 0.0061\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 607us/step - loss: 0.0023 - val_loss: 0.0069\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 607us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 608us/step - loss: 0.0018 - val_loss: 0.0035\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 608us/step - loss: 0.0026 - val_loss: 0.0115\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 611us/step - loss: 0.0049 - val_loss: 0.0055\n",
      "Epoch 23/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 2s 608us/step - loss: 0.0019 - val_loss: 0.0031\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 609us/step - loss: 0.0015 - val_loss: 0.0050\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 30s 8ms/step - loss: 0.0451 - val_loss: 0.0119\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 536us/step - loss: 0.0130 - val_loss: 0.0044\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0037 - val_loss: 0.0040\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 535us/step - loss: 0.0222 - val_loss: 0.0051\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 535us/step - loss: 0.0067 - val_loss: 0.0253\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 537us/step - loss: 0.0062 - val_loss: 0.0033\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0052 - val_loss: 0.0031\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 539us/step - loss: 0.0031 - val_loss: 0.0020\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 535us/step - loss: 0.0055 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 538us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 536us/step - loss: 0.0019 - val_loss: 0.0065\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0048 - val_loss: 0.0179\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 535us/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 535us/step - loss: 0.0019 - val_loss: 0.0033\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0018 - val_loss: 0.0068\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0026 - val_loss: 0.0076\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 537us/step - loss: 0.0039 - val_loss: 0.0083\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 537us/step - loss: 0.0028 - val_loss: 0.0051\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 539us/step - loss: 0.0020 - val_loss: 0.0041\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 31s 8ms/step - loss: 0.0594 - val_loss: 0.0410\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 536us/step - loss: 0.0143 - val_loss: 0.0025\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 537us/step - loss: 0.0101 - val_loss: 0.0076\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0081 - val_loss: 0.0022\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 536us/step - loss: 0.0029 - val_loss: 0.0017\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0042 - val_loss: 0.0060\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 536us/step - loss: 0.0068 - val_loss: 0.0049\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 537us/step - loss: 0.0046 - val_loss: 0.0015\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 539us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 535us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 537us/step - loss: 0.0061 - val_loss: 0.0042\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 536us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0038 - val_loss: 0.0015\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 536us/step - loss: 0.0033 - val_loss: 0.0013\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 535us/step - loss: 0.0031 - val_loss: 0.0013\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 539us/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 536us/step - loss: 0.0027 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 535us/step - loss: 0.0041 - val_loss: 0.0012\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 540us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0042 - val_loss: 0.0020\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 539us/step - loss: 0.0024 - val_loss: 0.0012\n",
      "\n",
      "GENERATION 16\n",
      "\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 31s 8ms/step - loss: 0.1060 - val_loss: 0.0210\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 570us/step - loss: 0.0151 - val_loss: 0.0102\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 571us/step - loss: 0.0077 - val_loss: 0.0121\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 569us/step - loss: 0.0078 - val_loss: 0.0140\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 570us/step - loss: 0.0074 - val_loss: 0.0114\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 569us/step - loss: 0.0062 - val_loss: 0.0099\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 571us/step - loss: 0.0062 - val_loss: 0.0090\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 569us/step - loss: 0.0053 - val_loss: 0.0069\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 568us/step - loss: 0.0040 - val_loss: 0.0070\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 568us/step - loss: 0.0054 - val_loss: 0.0081\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 568us/step - loss: 0.0054 - val_loss: 0.0138\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 570us/step - loss: 0.0067 - val_loss: 0.0066\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 571us/step - loss: 0.0050 - val_loss: 0.0091\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 568us/step - loss: 0.0057 - val_loss: 0.0090\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 565us/step - loss: 0.0046 - val_loss: 0.0064\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 566us/step - loss: 0.0042 - val_loss: 0.0075\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 568us/step - loss: 0.0040 - val_loss: 0.0065\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 567us/step - loss: 0.0051 - val_loss: 0.0059\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 568us/step - loss: 0.0050 - val_loss: 0.0074\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 568us/step - loss: 0.0043 - val_loss: 0.0079\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 574us/step - loss: 0.0037 - val_loss: 0.0071\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 570us/step - loss: 0.0048 - val_loss: 0.0059\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 567us/step - loss: 0.0044 - val_loss: 0.0056\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 565us/step - loss: 0.0040 - val_loss: 0.0062\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 29s 7ms/step - loss: 0.0652 - val_loss: 0.0030\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 0.0084 - val_loss: 0.0021\n",
      "Epoch 3/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 1s 264us/step - loss: 0.0039 - val_loss: 0.0013\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 0.0026 - val_loss: 9.6906e-04\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 0.0019 - val_loss: 8.4496e-04\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 0.0017 - val_loss: 9.5013e-04\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 0.0015 - val_loss: 8.2500e-04\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 0.0014 - val_loss: 8.6840e-04\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 0.0014 - val_loss: 7.9743e-04\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 0.0013 - val_loss: 7.9437e-04\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 0.0013 - val_loss: 7.8829e-04\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 0.0013 - val_loss: 7.7716e-04\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 0.0013 - val_loss: 7.6336e-04\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 269us/step - loss: 0.0012 - val_loss: 7.3743e-04\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 0.0012 - val_loss: 7.1963e-04\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 0.0012 - val_loss: 7.2517e-04\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 0.0011 - val_loss: 7.5955e-04\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 0.0012 - val_loss: 7.4816e-04\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 0.0011 - val_loss: 6.9056e-04\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 0.0011 - val_loss: 6.7466e-04\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 0.0011 - val_loss: 6.9969e-04\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 268us/step - loss: 0.0010 - val_loss: 7.3825e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 0.0011 - val_loss: 9.5158e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 0.0010 - val_loss: 9.2039e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 30s 8ms/step - loss: 0.5600 - val_loss: 0.0274\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 0.0486 - val_loss: 0.0172\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 0.0261 - val_loss: 0.0021\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 269us/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 30s 8ms/step - loss: 3.7947 - val_loss: 0.0380\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 269us/step - loss: 0.0508 - val_loss: 0.0518\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 268us/step - loss: 0.0437 - val_loss: 0.0247\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 270us/step - loss: 0.0206 - val_loss: 0.0023\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 271us/step - loss: 0.0032 - val_loss: 0.0014\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 273us/step - loss: 0.0028 - val_loss: 0.0017\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 268us/step - loss: 0.0027 - val_loss: 0.0011\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 0.0035 - val_loss: 0.0031\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 0.0028 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 0.0024 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 0.0026 - val_loss: 0.0020\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 269us/step - loss: 0.0030 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 269us/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 269us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - ETA: 0s - loss: 0.002 - 1s 266us/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 0.0021 - val_loss: 0.0010\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 269us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 270us/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 269us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 0.0020 - val_loss: 9.5698e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 269us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 31s 8ms/step - loss: 0.0913 - val_loss: 0.0033\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 0.0113 - val_loss: 0.0012\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 270us/step - loss: 0.0062 - val_loss: 0.0038\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 0.0039 - val_loss: 0.0020\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 268us/step - loss: 0.0027 - val_loss: 0.0020\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 7/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 1s 277us/step - loss: 0.0021 - val_loss: 9.2204e-04\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 280us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 275us/step - loss: 0.0019 - val_loss: 9.1269e-04\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 272us/step - loss: 0.0017 - val_loss: 8.7553e-04\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 274us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 272us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 268us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 271us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 269us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 268us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 268us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 270us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 268us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 271us/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 270us/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 32s 8ms/step - loss: 0.2487 - val_loss: 0.0410\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 0.0359 - val_loss: 0.0252\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 0.0129 - val_loss: 0.0166\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 0.0067 - val_loss: 0.0050\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 517us/step - loss: 0.0046 - val_loss: 0.0017\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 0.0041 - val_loss: 0.0048\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 0.0034 - val_loss: 0.0016\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 0.0030 - val_loss: 0.0017\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 0.0025 - val_loss: 0.0015\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0024 - val_loss: 0.0013\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 520us/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 0.0025 - val_loss: 0.0014\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 513us/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 516us/step - loss: 0.0023 - val_loss: 0.0013\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 515us/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 514us/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 518us/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 512us/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 33s 8ms/step - loss: 0.4575 - val_loss: 0.0937\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 432us/step - loss: 0.0908 - val_loss: 0.1023\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 428us/step - loss: 0.0776 - val_loss: 0.0405\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 425us/step - loss: 0.0601 - val_loss: 0.0086\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 426us/step - loss: 0.0477 - val_loss: 0.0153\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 428us/step - loss: 0.0188 - val_loss: 0.0031\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 429us/step - loss: 0.0073 - val_loss: 0.0037\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 426us/step - loss: 0.0047 - val_loss: 0.0029\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 433us/step - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 425us/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 428us/step - loss: 0.0031 - val_loss: 0.0024\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 426us/step - loss: 0.0028 - val_loss: 0.0021\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 428us/step - loss: 0.0028 - val_loss: 0.0023\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 428us/step - loss: 0.0027 - val_loss: 0.0022\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 428us/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 428us/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 430us/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 427us/step - loss: 0.0025 - val_loss: 0.0015\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 426us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 428us/step - loss: 0.0026 - val_loss: 0.0015\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 429us/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 427us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 426us/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 428us/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 32s 8ms/step - loss: 0.0651 - val_loss: 0.0407\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 426us/step - loss: 0.0135 - val_loss: 0.0138\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 429us/step - loss: 0.0055 - val_loss: 0.0022\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 424us/step - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 424us/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 427us/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 426us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 426us/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 425us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 428us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 425us/step - loss: 0.0020 - val_loss: 0.0015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 429us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 424us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 427us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 425us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 428us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 426us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 424us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 427us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 425us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 423us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 424us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 425us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 428us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 34s 8ms/step - loss: 0.2230 - val_loss: 0.0020\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 430us/step - loss: 0.0200 - val_loss: 0.0280\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 424us/step - loss: 0.0139 - val_loss: 0.0140\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 425us/step - loss: 0.0063 - val_loss: 0.0016\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 425us/step - loss: 0.0038 - val_loss: 0.0017\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 429us/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 428us/step - loss: 0.0028 - val_loss: 0.0014\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 428us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 427us/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 426us/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 425us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 427us/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 428us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 429us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 426us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 428us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 427us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 426us/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 423us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 428us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 425us/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 429us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 425us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 441us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "\n",
      "GENERATION 17\n",
      "\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 34s 8ms/step - loss: 0.0857 - val_loss: 0.0331\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0167 - val_loss: 0.0150\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0072 - val_loss: 0.0052\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 401us/step - loss: 0.0041 - val_loss: 0.0071\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0031 - val_loss: 0.0015\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 398us/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 397us/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 397us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 398us/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 398us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 398us/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 397us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 403us/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 404us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 399us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 398us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 399us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 398us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 398us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 398us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 399us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 401us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 30s 8ms/step - loss: 0.0502 - val_loss: 0.0068\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 255us/step - loss: 0.0074 - val_loss: 0.0033\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 255us/step - loss: 0.0037 - val_loss: 0.0024\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 253us/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 254us/step - loss: 0.0019 - val_loss: 9.9487e-04\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 254us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 258us/step - loss: 0.0015 - val_loss: 8.8651e-04\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 260us/step - loss: 0.0014 - val_loss: 8.6572e-04\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 253us/step - loss: 0.0013 - val_loss: 7.8967e-04\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 255us/step - loss: 0.0013 - val_loss: 7.8456e-04\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 253us/step - loss: 0.0012 - val_loss: 7.4620e-04\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 254us/step - loss: 0.0012 - val_loss: 7.3178e-04\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 253us/step - loss: 0.0012 - val_loss: 7.1110e-04\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 261us/step - loss: 0.0011 - val_loss: 7.3376e-04\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 277us/step - loss: 0.0011 - val_loss: 8.3118e-04\n",
      "Epoch 16/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 1s 272us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 271us/step - loss: 9.8764e-04 - val_loss: 7.8841e-04\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 278us/step - loss: 9.9067e-04 - val_loss: 7.8617e-04\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 9.8489e-04 - val_loss: 6.8358e-04\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 9.4480e-04 - val_loss: 6.6368e-04\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 9.2790e-04 - val_loss: 8.6154e-04\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 268us/step - loss: 8.8952e-04 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 274us/step - loss: 8.7103e-04 - val_loss: 7.2848e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 256us/step - loss: 8.8505e-04 - val_loss: 8.2778e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 30s 8ms/step - loss: 0.0808 - val_loss: 0.0011\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 256us/step - loss: 0.0091 - val_loss: 0.0012\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 261us/step - loss: 0.0041 - val_loss: 0.0012\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 257us/step - loss: 0.0026 - val_loss: 0.0012\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 256us/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 256us/step - loss: 0.0019 - val_loss: 8.1336e-04\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 257us/step - loss: 0.0016 - val_loss: 8.2798e-04\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 256us/step - loss: 0.0015 - val_loss: 8.2957e-04\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 0.0015 - val_loss: 7.5815e-04\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 256us/step - loss: 0.0014 - val_loss: 7.4610e-04\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 261us/step - loss: 0.0014 - val_loss: 7.4881e-04\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 257us/step - loss: 0.0013 - val_loss: 7.2452e-04\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 255us/step - loss: 0.0013 - val_loss: 7.0109e-04\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 257us/step - loss: 0.0012 - val_loss: 6.9897e-04\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 256us/step - loss: 0.0012 - val_loss: 6.8067e-04\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 256us/step - loss: 0.0011 - val_loss: 6.7728e-04\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 257us/step - loss: 0.0011 - val_loss: 6.3659e-04\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 256us/step - loss: 0.0011 - val_loss: 6.2615e-04\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 256us/step - loss: 0.0011 - val_loss: 6.3047e-04\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 257us/step - loss: 0.0011 - val_loss: 6.2152e-04\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 257us/step - loss: 0.0010 - val_loss: 6.2672e-04\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 9.8537e-04 - val_loss: 6.3566e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 256us/step - loss: 9.8256e-04 - val_loss: 5.7276e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 257us/step - loss: 9.5739e-04 - val_loss: 5.7776e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 33s 8ms/step - loss: 0.0743 - val_loss: 0.0327\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 547us/step - loss: 0.0107 - val_loss: 0.0072\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 546us/step - loss: 0.0055 - val_loss: 0.0037\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 547us/step - loss: 0.0031 - val_loss: 0.0045\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 552us/step - loss: 0.0027 - val_loss: 0.0016\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 545us/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 545us/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 546us/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 550us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 544us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 550us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 555us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 546us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 546us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 548us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 548us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 546us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 545us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 549us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 550us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 546us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 549us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 547us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 546us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 33s 8ms/step - loss: 0.0862 - val_loss: 0.0962\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 548us/step - loss: 0.0355 - val_loss: 0.0212\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 546us/step - loss: 0.0136 - val_loss: 0.0025\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 545us/step - loss: 0.0079 - val_loss: 0.0086\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 545us/step - loss: 0.0052 - val_loss: 0.0102\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 547us/step - loss: 0.0041 - val_loss: 0.0057\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 545us/step - loss: 0.0034 - val_loss: 0.0027\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 546us/step - loss: 0.0031 - val_loss: 0.0024\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 550us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 548us/step - loss: 0.0029 - val_loss: 0.0026\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 548us/step - loss: 0.0027 - val_loss: 0.0020\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 545us/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 551us/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 544us/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 548us/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 543us/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 547us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 544us/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 19/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 2s 545us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 549us/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 543us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 546us/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 548us/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 543us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 33s 8ms/step - loss: 1.1677 - val_loss: 0.0323\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 545us/step - loss: 0.0467 - val_loss: 0.0544\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 547us/step - loss: 0.0744 - val_loss: 0.0045\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 548us/step - loss: 0.0154 - val_loss: 0.0147\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 546us/step - loss: 0.0084 - val_loss: 0.0119\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 553us/step - loss: 0.0207 - val_loss: 0.0101\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 545us/step - loss: 0.0065 - val_loss: 0.0073\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 547us/step - loss: 0.0053 - val_loss: 0.0061\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 546us/step - loss: 0.0052 - val_loss: 0.0106\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 547us/step - loss: 0.0048 - val_loss: 0.0058\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 545us/step - loss: 0.0045 - val_loss: 0.0067\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 545us/step - loss: 0.0062 - val_loss: 0.0158\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 544us/step - loss: 0.0049 - val_loss: 0.0064\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 548us/step - loss: 0.0050 - val_loss: 0.0116\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 547us/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 549us/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 546us/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 545us/step - loss: 0.0041 - val_loss: 0.0026\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 545us/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 550us/step - loss: 0.0037 - val_loss: 0.0025\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 549us/step - loss: 0.0036 - val_loss: 0.0022\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 551us/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 544us/step - loss: 0.0037 - val_loss: 0.0024\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 546us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 34s 9ms/step - loss: 0.8584 - val_loss: 0.0073\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 546us/step - loss: 0.0616 - val_loss: 0.0340\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 548us/step - loss: 0.0363 - val_loss: 0.0044\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 548us/step - loss: 0.0132 - val_loss: 0.0410\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 546us/step - loss: 0.0194 - val_loss: 0.0056\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 545us/step - loss: 0.0065 - val_loss: 0.0192\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 548us/step - loss: 0.0068 - val_loss: 0.0094\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 544us/step - loss: 0.0055 - val_loss: 0.0117\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 545us/step - loss: 0.0071 - val_loss: 0.0156\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 545us/step - loss: 0.0057 - val_loss: 0.0052\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 545us/step - loss: 0.0043 - val_loss: 0.0053\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 546us/step - loss: 0.0050 - val_loss: 0.0090\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 544us/step - loss: 0.0053 - val_loss: 0.0053\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 548us/step - loss: 0.0046 - val_loss: 0.0062\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 545us/step - loss: 0.0046 - val_loss: 0.0073\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 547us/step - loss: 0.0041 - val_loss: 0.0049\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 548us/step - loss: 0.0040 - val_loss: 0.0030\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 546us/step - loss: 0.0041 - val_loss: 0.0051\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 545us/step - loss: 0.0038 - val_loss: 0.0053\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 547us/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 546us/step - loss: 0.0036 - val_loss: 0.0021\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 547us/step - loss: 0.0035 - val_loss: 0.0026\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 544us/step - loss: 0.0044 - val_loss: 0.0022\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 544us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 34s 9ms/step - loss: 3.8824 - val_loss: 0.0235\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 544us/step - loss: 0.0665 - val_loss: 0.0133\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 544us/step - loss: 0.0183 - val_loss: 0.0030\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 547us/step - loss: 0.0152 - val_loss: 0.0641\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 543us/step - loss: 0.0176 - val_loss: 0.0102\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 547us/step - loss: 0.0049 - val_loss: 0.0057\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 546us/step - loss: 0.0041 - val_loss: 0.0031\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 544us/step - loss: 0.0041 - val_loss: 0.0088\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 545us/step - loss: 0.0051 - val_loss: 0.0082\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 545us/step - loss: 0.0047 - val_loss: 0.0120\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 542us/step - loss: 0.0049 - val_loss: 0.0058\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 543us/step - loss: 0.0040 - val_loss: 0.0031\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 548us/step - loss: 0.0035 - val_loss: 0.0041\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 547us/step - loss: 0.0038 - val_loss: 0.0054\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 543us/step - loss: 0.0041 - val_loss: 0.0067\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 552us/step - loss: 0.0038 - val_loss: 0.0047\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 545us/step - loss: 0.0036 - val_loss: 0.0032\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 547us/step - loss: 0.0036 - val_loss: 0.0063\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 543us/step - loss: 0.0038 - val_loss: 0.0041\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 545us/step - loss: 0.0034 - val_loss: 0.0047\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 546us/step - loss: 0.0042 - val_loss: 0.0095\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 544us/step - loss: 0.0053 - val_loss: 0.0084\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 543us/step - loss: 0.0052 - val_loss: 0.0078\n",
      "Epoch 24/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 2s 543us/step - loss: 0.0043 - val_loss: 0.0052\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 34s 9ms/step - loss: 4.0446 - val_loss: 0.0279\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 401us/step - loss: 0.0450 - val_loss: 0.0880\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 402us/step - loss: 0.0254 - val_loss: 0.0050\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0081 - val_loss: 0.0079\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 401us/step - loss: 0.0069 - val_loss: 0.0144\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0074 - val_loss: 0.0179\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 403us/step - loss: 0.0079 - val_loss: 0.0105\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0057 - val_loss: 0.0075\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0053 - val_loss: 0.0036\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 399us/step - loss: 0.0070 - val_loss: 0.0065\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 407us/step - loss: 0.0091 - val_loss: 0.0028\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 397us/step - loss: 0.0049 - val_loss: 0.0078\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 401us/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 402us/step - loss: 0.0053 - val_loss: 0.0107\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0053 - val_loss: 0.0038\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 404us/step - loss: 0.0046 - val_loss: 0.0025\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0045 - val_loss: 0.0031\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0041 - val_loss: 0.0053\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 399us/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 401us/step - loss: 0.0039 - val_loss: 0.0030\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 401us/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 399us/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 401us/step - loss: 0.0037 - val_loss: 0.0023\n",
      "\n",
      "GENERATION 18\n",
      "\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 34s 9ms/step - loss: 0.0542 - val_loss: 0.0271\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 432us/step - loss: 0.0100 - val_loss: 0.0019\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 433us/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 434us/step - loss: 0.0037 - val_loss: 0.0026\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 432us/step - loss: 0.0031 - val_loss: 0.0025\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 431us/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 432us/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 431us/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 433us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 432us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 434us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 439us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 436us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 431us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 435us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 433us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 433us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 434us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 433us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 431us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 432us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 435us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 438us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 434us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 34s 9ms/step - loss: 0.0647 - val_loss: 0.0016\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 258us/step - loss: 0.0075 - val_loss: 0.0014\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 258us/step - loss: 0.0039 - val_loss: 0.0012\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 257us/step - loss: 0.0027 - val_loss: 8.9332e-04\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 256us/step - loss: 0.0019 - val_loss: 7.7232e-04\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 257us/step - loss: 0.0017 - val_loss: 8.2403e-04\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 258us/step - loss: 0.0016 - val_loss: 7.6655e-04\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 258us/step - loss: 0.0015 - val_loss: 8.0071e-04\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 256us/step - loss: 0.0015 - val_loss: 7.5810e-04\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 258us/step - loss: 0.0014 - val_loss: 7.5355e-04\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 258us/step - loss: 0.0013 - val_loss: 7.6170e-04\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 257us/step - loss: 0.0013 - val_loss: 7.5158e-04\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 258us/step - loss: 0.0012 - val_loss: 7.4395e-04\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 261us/step - loss: 0.0013 - val_loss: 7.0565e-04\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 0.0012 - val_loss: 6.9777e-04\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 257us/step - loss: 0.0011 - val_loss: 7.5941e-04\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 0.0011 - val_loss: 7.3324e-04\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 258us/step - loss: 0.0011 - val_loss: 6.5619e-04\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 257us/step - loss: 0.0011 - val_loss: 6.3218e-04\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 258us/step - loss: 0.0011 - val_loss: 6.2714e-04\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 260us/step - loss: 0.0011 - val_loss: 6.1902e-04\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 257us/step - loss: 0.0010 - val_loss: 6.0065e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 0.0010 - val_loss: 5.9358e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 257us/step - loss: 9.8819e-04 - val_loss: 6.2408e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 36s 9ms/step - loss: 0.0691 - val_loss: 0.0138\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 0.0174 - val_loss: 0.0179\n",
      "Epoch 3/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 2s 536us/step - loss: 0.0129 - val_loss: 0.0136\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 528us/step - loss: 0.0103 - val_loss: 0.0075\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0086 - val_loss: 0.0114\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 0.0080 - val_loss: 0.0052\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 528us/step - loss: 0.0056 - val_loss: 0.0103\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 0.0060 - val_loss: 0.0061\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 0.0057 - val_loss: 0.0078\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 529us/step - loss: 0.0075 - val_loss: 0.0075\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0056 - val_loss: 0.0073\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 529us/step - loss: 0.0052 - val_loss: 0.0114\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 529us/step - loss: 0.0067 - val_loss: 0.0048\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 529us/step - loss: 0.0056 - val_loss: 0.0080\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 529us/step - loss: 0.0065 - val_loss: 0.0063\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0060 - val_loss: 0.0065\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0050 - val_loss: 0.0023\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0042 - val_loss: 0.0073\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0067 - val_loss: 0.0087\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 0.0066 - val_loss: 0.0066\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0058 - val_loss: 0.0066\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 529us/step - loss: 0.0041 - val_loss: 0.0033\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0051 - val_loss: 0.0036\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 529us/step - loss: 0.0042 - val_loss: 0.0061\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 36s 9ms/step - loss: 0.0885 - val_loss: 0.0117\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 535us/step - loss: 0.0200 - val_loss: 0.0150\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0148 - val_loss: 0.0172\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0100 - val_loss: 0.0171\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 0.0091 - val_loss: 0.0175\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0091 - val_loss: 0.0134\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0072 - val_loss: 0.0123\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0057 - val_loss: 0.0106\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0073 - val_loss: 0.0097\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 535us/step - loss: 0.0060 - val_loss: 0.0090\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 536us/step - loss: 0.0055 - val_loss: 0.0094\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0068 - val_loss: 0.0088\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0059 - val_loss: 0.0081\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0051 - val_loss: 0.0038\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 535us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 535us/step - loss: 0.0049 - val_loss: 0.0090\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0065 - val_loss: 0.0100\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0067 - val_loss: 0.0066\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0056 - val_loss: 0.0053\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0052 - val_loss: 0.0040\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0043 - val_loss: 0.0030\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0043 - val_loss: 0.0079\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0051 - val_loss: 0.0046\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 36s 9ms/step - loss: 0.0815 - val_loss: 0.0226\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0100 - val_loss: 0.0033\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0044 - val_loss: 0.0052\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0029 - val_loss: 0.0019\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 534us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 529us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 535us/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 529us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 535us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 536us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 536us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 536us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 37s 9ms/step - loss: 0.1143 - val_loss: 0.0031\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 535us/step - loss: 0.0165 - val_loss: 0.0088\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 0.0084 - val_loss: 0.0042\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 536us/step - loss: 0.0041 - val_loss: 0.0015\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 532us/step - loss: 0.0027 - val_loss: 0.0020\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 8/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 529us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 533us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 528us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 529us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 530us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 528us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 38s 10ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 527us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 531us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 523us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 522us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 525us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 524us/step - loss: nan - val_loss: nan\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 38s 10ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 353us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 357us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 355us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 356us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 354us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 352us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 351us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 353us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 353us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 353us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 353us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 353us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 353us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 355us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 354us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 356us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 360us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 355us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 351us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 352us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 355us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 352us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 354us/step - loss: nan - val_loss: nan\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 38s 9ms/step - loss: 0.2690 - val_loss: 0.1328\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 357us/step - loss: 0.0791 - val_loss: 0.0548\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 355us/step - loss: 0.0676 - val_loss: 0.0408\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 354us/step - loss: 0.0670 - val_loss: 0.0392\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 355us/step - loss: 0.0670 - val_loss: 0.0388\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 355us/step - loss: 0.0669 - val_loss: 0.0383\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 354us/step - loss: 0.0669 - val_loss: 0.0374\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 355us/step - loss: 0.0669 - val_loss: 0.0390\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 356us/step - loss: 0.0669 - val_loss: 0.0393\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 356us/step - loss: 0.0668 - val_loss: 0.0395\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 360us/step - loss: 0.0668 - val_loss: 0.0369\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 353us/step - loss: 0.0669 - val_loss: 0.0371\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 355us/step - loss: 0.0668 - val_loss: 0.0448\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 357us/step - loss: 0.0669 - val_loss: 0.0401\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 359us/step - loss: 0.0670 - val_loss: 0.0427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 355us/step - loss: 0.0667 - val_loss: 0.0337\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 358us/step - loss: 0.0666 - val_loss: 0.0346\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 360us/step - loss: 0.0667 - val_loss: 0.0446\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 353us/step - loss: 0.0666 - val_loss: 0.0395\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 356us/step - loss: 0.0666 - val_loss: 0.0352\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 354us/step - loss: 0.0666 - val_loss: 0.0308\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 361us/step - loss: 0.0666 - val_loss: 0.0308\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 354us/step - loss: 0.0665 - val_loss: 0.0266\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 354us/step - loss: 0.0665 - val_loss: 0.0355\n",
      "\n",
      "GENERATION 19\n",
      "\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 38s 9ms/step - loss: 0.0508 - val_loss: 0.0146\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 0.0083 - val_loss: 0.0072\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 260us/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 261us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 261us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 0.0014 - val_loss: 8.2663e-04\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 0.0013 - val_loss: 7.5886e-04\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 261us/step - loss: 0.0013 - val_loss: 7.3492e-04\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 261us/step - loss: 0.0012 - val_loss: 7.5419e-04\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 0.0012 - val_loss: 7.0876e-04\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 260us/step - loss: 0.0012 - val_loss: 6.9292e-04\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 261us/step - loss: 0.0011 - val_loss: 6.8855e-04\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 0.0011 - val_loss: 6.6660e-04\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 261us/step - loss: 0.0010 - val_loss: 7.1552e-04\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 0.0010 - val_loss: 6.2780e-04\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 261us/step - loss: 9.8214e-04 - val_loss: 6.0541e-04\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 9.5508e-04 - val_loss: 7.9057e-04\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 8.8399e-04 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 9.0184e-04 - val_loss: 7.5164e-04\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 8.8826e-04 - val_loss: 6.1799e-04\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 8.3474e-04 - val_loss: 6.9524e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 8.5496e-04 - val_loss: 9.1296e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 268us/step - loss: 8.1755e-04 - val_loss: 7.3297e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 37s 9ms/step - loss: 0.0322 - val_loss: 0.0170\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 261us/step - loss: 0.0069 - val_loss: 0.0069\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 261us/step - loss: 0.0030 - val_loss: 0.0023\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 0.0017 - val_loss: 9.3143e-04\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 0.0014 - val_loss: 8.3214e-04\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 0.0013 - val_loss: 7.8244e-04\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 0.0012 - val_loss: 7.4030e-04\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 261us/step - loss: 0.0012 - val_loss: 7.2362e-04\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 0.0011 - val_loss: 7.1296e-04\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 261us/step - loss: 0.0011 - val_loss: 6.9212e-04\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 260us/step - loss: 0.0010 - val_loss: 6.6386e-04\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 261us/step - loss: 9.8386e-04 - val_loss: 6.9586e-04\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 9.5755e-04 - val_loss: 6.5565e-04\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 261us/step - loss: 9.7343e-04 - val_loss: 6.0291e-04\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 9.4511e-04 - val_loss: 7.5813e-04\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 261us/step - loss: 9.2360e-04 - val_loss: 9.0436e-04\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 261us/step - loss: 9.1946e-04 - val_loss: 0.0010\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 8.5298e-04 - val_loss: 5.7537e-04\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 8.3561e-04 - val_loss: 8.3549e-04\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 8.1522e-04 - val_loss: 8.6689e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 7.8668e-04 - val_loss: 6.3269e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 8.0913e-04 - val_loss: 7.2675e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 37s 9ms/step - loss: 0.1120 - val_loss: 0.0295\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 217us/step - loss: 0.0100 - val_loss: 0.0124\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 220us/step - loss: 0.0047 - val_loss: 0.0062\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 219us/step - loss: 0.0030 - val_loss: 0.0022\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 218us/step - loss: 0.0024 - val_loss: 0.0013\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 216us/step - loss: 0.0019 - val_loss: 8.5012e-04\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 216us/step - loss: 0.0016 - val_loss: 8.2589e-04\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 222us/step - loss: 0.0016 - val_loss: 8.7835e-04\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 216us/step - loss: 0.0015 - val_loss: 8.1648e-04\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 219us/step - loss: 0.0015 - val_loss: 8.1169e-04\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 216us/step - loss: 0.0014 - val_loss: 8.0684e-04\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 224us/step - loss: 0.0014 - val_loss: 7.9928e-04\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 215us/step - loss: 0.0014 - val_loss: 7.9117e-04\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 215us/step - loss: 0.0014 - val_loss: 7.8664e-04\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 217us/step - loss: 0.0013 - val_loss: 7.9273e-04\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 217us/step - loss: 0.0013 - val_loss: 8.5908e-04\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 216us/step - loss: 0.0013 - val_loss: 8.4652e-04\n",
      "Epoch 18/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 1s 216us/step - loss: 0.0012 - val_loss: 7.5809e-04\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 217us/step - loss: 0.0012 - val_loss: 7.5065e-04\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 216us/step - loss: 0.0012 - val_loss: 7.8262e-04\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 218us/step - loss: 0.0011 - val_loss: 8.0271e-04\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 216us/step - loss: 0.0011 - val_loss: 8.1495e-04\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 216us/step - loss: 0.0011 - val_loss: 7.2466e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 215us/step - loss: 0.0011 - val_loss: 7.3275e-04\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 37s 9ms/step - loss: 0.5336 - val_loss: 0.2537\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 217us/step - loss: 0.1727 - val_loss: 0.0347\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 218us/step - loss: 0.0829 - val_loss: 0.0242\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 216us/step - loss: 0.0414 - val_loss: 0.0026\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 217us/step - loss: 0.0114 - val_loss: 0.0060\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 217us/step - loss: 0.0063 - val_loss: 0.0018\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 217us/step - loss: 0.0045 - val_loss: 0.0067\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 216us/step - loss: 0.0038 - val_loss: 0.0031\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 216us/step - loss: 0.0032 - val_loss: 0.0023\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 215us/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 217us/step - loss: 0.0029 - val_loss: 0.0026\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 217us/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 219us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 218us/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 216us/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 215us/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 216us/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 217us/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 217us/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 217us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 216us/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 218us/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 216us/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 219us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 39s 10ms/step - loss: 0.7390 - val_loss: 0.7024\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 235us/step - loss: 0.3663 - val_loss: 0.3477\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 236us/step - loss: 0.1718 - val_loss: 0.1631\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 241us/step - loss: 0.0930 - val_loss: 0.0763\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 237us/step - loss: 0.0697 - val_loss: 0.0401\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 234us/step - loss: 0.0674 - val_loss: 0.0272\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 235us/step - loss: 0.0684 - val_loss: 0.0247\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 236us/step - loss: 0.0684 - val_loss: 0.0274\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 235us/step - loss: 0.0676 - val_loss: 0.0318\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 236us/step - loss: 0.0671 - val_loss: 0.0360\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 234us/step - loss: 0.0670 - val_loss: 0.0388\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 234us/step - loss: 0.0670 - val_loss: 0.0397\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 236us/step - loss: 0.0670 - val_loss: 0.0396\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 235us/step - loss: 0.0670 - val_loss: 0.0390\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 241us/step - loss: 0.0670 - val_loss: 0.0382\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 242us/step - loss: 0.0670 - val_loss: 0.0378\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 236us/step - loss: 0.0670 - val_loss: 0.0374\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 238us/step - loss: 0.0670 - val_loss: 0.0382\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 236us/step - loss: 0.0670 - val_loss: 0.0377\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 236us/step - loss: 0.0670 - val_loss: 0.0375\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 235us/step - loss: 0.0670 - val_loss: 0.0378\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 235us/step - loss: 0.0670 - val_loss: 0.0385\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 235us/step - loss: 0.0670 - val_loss: 0.0379\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 237us/step - loss: 0.0670 - val_loss: 0.0371\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 39s 10ms/step - loss: 0.1273 - val_loss: 0.0072\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 236us/step - loss: 0.0138 - val_loss: 0.0182\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 237us/step - loss: 0.0072 - val_loss: 0.0045\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 238us/step - loss: 0.0027 - val_loss: 0.0022\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 238us/step - loss: 0.0033 - val_loss: 0.0014\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 238us/step - loss: 0.0027 - val_loss: 0.0014\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 237us/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 238us/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 239us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 238us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 238us/step - loss: 0.0019 - val_loss: 0.0055\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 236us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 240us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 242us/step - loss: 0.0021 - val_loss: 0.0010\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 239us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 243us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 239us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 239us/step - loss: 0.0015 - val_loss: 9.8542e-04\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 236us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 238us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 238us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 238us/step - loss: 0.0016 - val_loss: 9.3410e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 240us/step - loss: 0.0017 - val_loss: 9.6995e-04\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 238us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 38s 10ms/step - loss: 0.1363 - val_loss: 0.0039\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 1s 180us/step - loss: 0.0102 - val_loss: 0.0020\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 1s 179us/step - loss: 0.0053 - val_loss: 0.0027\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 1s 180us/step - loss: 0.0043 - val_loss: 0.0054\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 1s 179us/step - loss: 0.0045 - val_loss: 0.0054\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 1s 179us/step - loss: 0.0038 - val_loss: 0.0074\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 1s 180us/step - loss: 0.0032 - val_loss: 0.0061\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 1s 181us/step - loss: 0.0029 - val_loss: 0.0058\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 1s 181us/step - loss: 0.0025 - val_loss: 0.0055\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 1s 180us/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 1s 182us/step - loss: 0.0027 - val_loss: 0.0075\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 1s 181us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 1s 181us/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 1s 180us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 1s 180us/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 1s 178us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 1s 180us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 1s 182us/step - loss: 0.0018 - val_loss: 9.7242e-04\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 1s 182us/step - loss: 0.0019 - val_loss: 9.6335e-04\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 1s 182us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 1s 187us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 1s 182us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 1s 180us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 1s 181us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 39s 10ms/step - loss: 0.2128 - val_loss: 0.0029\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 394us/step - loss: 0.0158 - val_loss: 0.0113\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0097 - val_loss: 0.0052\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 393us/step - loss: 0.0080 - val_loss: 0.0061\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 393us/step - loss: 0.0057 - val_loss: 0.0082\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 391us/step - loss: 0.0047 - val_loss: 0.0056\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 393us/step - loss: 0.0042 - val_loss: 0.0031\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 391us/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 393us/step - loss: 0.0034 - val_loss: 0.0021\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 392us/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 390us/step - loss: 0.0032 - val_loss: 0.0019\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 392us/step - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 393us/step - loss: 0.0031 - val_loss: 0.0019\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 395us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 392us/step - loss: 0.0034 - val_loss: 0.0016\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 393us/step - loss: 0.0029 - val_loss: 0.0018\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 392us/step - loss: 0.0030 - val_loss: 0.0017\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 392us/step - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 393us/step - loss: 0.0030 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 394us/step - loss: 0.0028 - val_loss: 0.0015\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 392us/step - loss: 0.0028 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 395us/step - loss: 0.0033 - val_loss: 0.0024\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 394us/step - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 394us/step - loss: 0.0027 - val_loss: 0.0021\n",
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/24\n",
      "3977/3977 [==============================] - 39s 10ms/step - loss: 0.0669 - val_loss: 0.0125\n",
      "Epoch 2/24\n",
      "3977/3977 [==============================] - 2s 396us/step - loss: 0.0263 - val_loss: 0.0078\n",
      "Epoch 3/24\n",
      "3977/3977 [==============================] - 2s 395us/step - loss: 0.0211 - val_loss: 0.0051\n",
      "Epoch 4/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0167 - val_loss: 0.0044\n",
      "Epoch 5/24\n",
      "3977/3977 [==============================] - 2s 394us/step - loss: 0.0135 - val_loss: 0.0034\n",
      "Epoch 6/24\n",
      "3977/3977 [==============================] - 2s 395us/step - loss: 0.0114 - val_loss: 0.0028\n",
      "Epoch 7/24\n",
      "3977/3977 [==============================] - 2s 396us/step - loss: 0.0090 - val_loss: 0.0022\n",
      "Epoch 8/24\n",
      "3977/3977 [==============================] - 2s 395us/step - loss: 0.0078 - val_loss: 0.0020\n",
      "Epoch 9/24\n",
      "3977/3977 [==============================] - 2s 396us/step - loss: 0.0069 - val_loss: 0.0018\n",
      "Epoch 10/24\n",
      "3977/3977 [==============================] - 2s 396us/step - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 11/24\n",
      "3977/3977 [==============================] - 2s 394us/step - loss: 0.0058 - val_loss: 0.0019\n",
      "Epoch 12/24\n",
      "3977/3977 [==============================] - 2s 395us/step - loss: 0.0053 - val_loss: 0.0019\n",
      "Epoch 13/24\n",
      "3977/3977 [==============================] - 2s 395us/step - loss: 0.0051 - val_loss: 0.0019\n",
      "Epoch 14/24\n",
      "3977/3977 [==============================] - 2s 402us/step - loss: 0.0050 - val_loss: 0.0021\n",
      "Epoch 15/24\n",
      "3977/3977 [==============================] - 2s 394us/step - loss: 0.0047 - val_loss: 0.0021\n",
      "Epoch 16/24\n",
      "3977/3977 [==============================] - 2s 396us/step - loss: 0.0048 - val_loss: 0.0022\n",
      "Epoch 17/24\n",
      "3977/3977 [==============================] - 2s 396us/step - loss: 0.0046 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "3977/3977 [==============================] - 2s 400us/step - loss: 0.0046 - val_loss: 0.0025\n",
      "Epoch 19/24\n",
      "3977/3977 [==============================] - 2s 393us/step - loss: 0.0046 - val_loss: 0.0024\n",
      "Epoch 20/24\n",
      "3977/3977 [==============================] - 2s 395us/step - loss: 0.0043 - val_loss: 0.0024\n",
      "Epoch 21/24\n",
      "3977/3977 [==============================] - 2s 398us/step - loss: 0.0044 - val_loss: 0.0024\n",
      "Epoch 22/24\n",
      "3977/3977 [==============================] - 2s 396us/step - loss: 0.0044 - val_loss: 0.0023\n",
      "Epoch 23/24\n",
      "3977/3977 [==============================] - 2s 396us/step - loss: 0.0044 - val_loss: 0.0024\n",
      "Epoch 24/24\n",
      "3977/3977 [==============================] - 2s 399us/step - loss: 0.0044 - val_loss: 0.0024\n"
     ]
    }
   ],
   "source": [
    "best_models = breed_population(X_train, Y_train, generations=20, population_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0011233040131628513,\n",
       " 0.001192111405543983,\n",
       " 0.0011712845880538225,\n",
       " 0.001224838080815971,\n",
       " 0.0015764005947858095,\n",
       " 0.0008133641676977277,\n",
       " 0.0008279757457785308,\n",
       " 0.0008295708103105426,\n",
       " 0.0007581485551781952,\n",
       " 0.0007461017230525613,\n",
       " 0.0007488075643777847,\n",
       " 0.0007245154702104628,\n",
       " 0.0007010929402895272,\n",
       " 0.0006989718531258404,\n",
       " 0.0006806745077483356,\n",
       " 0.0006772835040464997,\n",
       " 0.0006365852896124125,\n",
       " 0.0006261459784582257,\n",
       " 0.0006304666749201715,\n",
       " 0.0006215222529135644,\n",
       " 0.0006267229327932,\n",
       " 0.0006356551893986762,\n",
       " 0.0005727605312131345,\n",
       " 0.000577763479668647]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models[0][1].history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal parameters\n",
      "_______________________\n",
      "shuffle: True\n",
      "dropout: 0.1\n",
      "lstmsize: 160\n",
      "activation: relu\n",
      "twice: False\n",
      "optimizer: adam\n",
      "density: 122\n"
     ]
    }
   ],
   "source": [
    "print('optimal parameters')\n",
    "print('_______________________')\n",
    "for key,val in best_models[0][2].items():\n",
    "    if key != 'x' and key != 'y': print(f'{key}: {val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_157\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_262 (LSTM)              (None, 160)               106240    \n",
      "_________________________________________________________________\n",
      "dropout_262 (Dropout)        (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dense_633 (Dense)            (None, 122)               19642     \n",
      "_________________________________________________________________\n",
      "dense_634 (Dense)            (None, 1)                 123       \n",
      "=================================================================\n",
      "Total params: 126,005\n",
      "Trainable params: 126,005\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_models[0][0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibm_checkpoint = ModelCheckpoint(\n",
    "    filepath='./checkpoints/IBM.{epoch}-{val_loss}.hdf5',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = best_models[0][2]\n",
    "params['x'] = X_train\n",
    "params['y'] = Y_train\n",
    "params['epochs'] = 2000\n",
    "params['callbacks'] = [ibm_checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3977 samples, validate on 442 samples\n",
      "Epoch 1/2000\n",
      "3977/3977 [==============================] - 40s 10ms/step - loss: 0.1121 - val_loss: 0.0036\n",
      "Epoch 2/2000\n",
      "3977/3977 [==============================] - 1s 274us/step - loss: 0.0102 - val_loss: 0.0038\n",
      "Epoch 3/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 0.0047 - val_loss: 0.0015\n",
      "Epoch 4/2000\n",
      "3977/3977 [==============================] - 1s 274us/step - loss: 0.0030 - val_loss: 0.0019\n",
      "Epoch 5/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 6/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 7/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 8/2000\n",
      "3977/3977 [==============================] - 1s 269us/step - loss: 0.0015 - val_loss: 9.0037e-04\n",
      "Epoch 9/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 0.0015 - val_loss: 9.9881e-04\n",
      "Epoch 10/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 0.0014 - val_loss: 8.7132e-04\n",
      "Epoch 11/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 0.0014 - val_loss: 9.0614e-04\n",
      "Epoch 12/2000\n",
      "3977/3977 [==============================] - 1s 271us/step - loss: 0.0014 - val_loss: 8.4495e-04\n",
      "Epoch 13/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 0.0014 - val_loss: 8.1464e-04\n",
      "Epoch 14/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 0.0013 - val_loss: 8.0171e-04\n",
      "Epoch 15/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 0.0013 - val_loss: 7.8912e-04\n",
      "Epoch 16/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 0.0013 - val_loss: 7.8306e-04\n",
      "Epoch 17/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 0.0013 - val_loss: 7.8015e-04\n",
      "Epoch 18/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 0.0012 - val_loss: 7.9218e-04\n",
      "Epoch 19/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 0.0012 - val_loss: 7.4662e-04\n",
      "Epoch 20/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 0.0012 - val_loss: 7.5040e-04\n",
      "Epoch 21/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 0.0011 - val_loss: 7.6718e-04\n",
      "Epoch 22/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 0.0011 - val_loss: 7.9456e-04\n",
      "Epoch 23/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 0.0011 - val_loss: 7.2395e-04\n",
      "Epoch 24/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 0.0011 - val_loss: 7.3761e-04\n",
      "Epoch 25/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 0.0011 - val_loss: 7.0974e-04\n",
      "Epoch 26/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 0.0011 - val_loss: 7.3707e-04\n",
      "Epoch 27/2000\n",
      "3977/3977 [==============================] - 1s 269us/step - loss: 0.0010 - val_loss: 6.4251e-04\n",
      "Epoch 28/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 9.8402e-04 - val_loss: 7.4688e-04\n",
      "Epoch 29/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 0.0010 - val_loss: 7.7994e-04\n",
      "Epoch 30/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 9.4428e-04 - val_loss: 8.7130e-04\n",
      "Epoch 31/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 0.0010 - val_loss: 8.0180e-04\n",
      "Epoch 32/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 9.3787e-04 - val_loss: 7.1982e-04\n",
      "Epoch 33/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 9.2287e-04 - val_loss: 7.3602e-04\n",
      "Epoch 34/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 8.9625e-04 - val_loss: 7.3786e-04\n",
      "Epoch 35/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 9.0367e-04 - val_loss: 6.5757e-04\n",
      "Epoch 36/2000\n",
      "3977/3977 [==============================] - 1s 269us/step - loss: 8.5534e-04 - val_loss: 6.4752e-04\n",
      "Epoch 37/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 8.7080e-04 - val_loss: 7.4187e-04\n",
      "Epoch 38/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 8.5925e-04 - val_loss: 7.6204e-04\n",
      "Epoch 39/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 8.6599e-04 - val_loss: 6.0586e-04\n",
      "Epoch 40/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 8.1611e-04 - val_loss: 0.0010\n",
      "Epoch 41/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 8.5183e-04 - val_loss: 6.3726e-04\n",
      "Epoch 42/2000\n",
      "3977/3977 [==============================] - 1s 268us/step - loss: 8.2803e-04 - val_loss: 6.0418e-04\n",
      "Epoch 43/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 8.3285e-04 - val_loss: 9.4977e-04\n",
      "Epoch 44/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 8.3946e-04 - val_loss: 0.0011\n",
      "Epoch 45/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 7.9977e-04 - val_loss: 9.1355e-04\n",
      "Epoch 46/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 7.7901e-04 - val_loss: 6.0377e-04\n",
      "Epoch 47/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 8.1927e-04 - val_loss: 7.8425e-04\n",
      "Epoch 48/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 7.7920e-04 - val_loss: 6.4257e-04\n",
      "Epoch 49/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 7.8833e-04 - val_loss: 5.8599e-04\n",
      "Epoch 50/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 7.9401e-04 - val_loss: 9.9726e-04\n",
      "Epoch 51/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 7.4481e-04 - val_loss: 6.8044e-04\n",
      "Epoch 52/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 7.3806e-04 - val_loss: 5.6073e-04\n",
      "Epoch 53/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 7.6550e-04 - val_loss: 9.8814e-04\n",
      "Epoch 54/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 7.5630e-04 - val_loss: 5.6988e-04\n",
      "Epoch 55/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 7.3243e-04 - val_loss: 9.6604e-04\n",
      "Epoch 56/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 7.2608e-04 - val_loss: 6.0934e-04\n",
      "Epoch 57/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 7.1499e-04 - val_loss: 7.7532e-04\n",
      "Epoch 58/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 7.2716e-04 - val_loss: 8.5791e-04\n",
      "Epoch 59/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 7.1575e-04 - val_loss: 6.0083e-04\n",
      "Epoch 60/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 7.0206e-04 - val_loss: 0.0011\n",
      "Epoch 61/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 7.2427e-04 - val_loss: 5.4925e-04\n",
      "Epoch 62/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 7.1058e-04 - val_loss: 9.9578e-04\n",
      "Epoch 63/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 6.7572e-04 - val_loss: 5.4194e-04\n",
      "Epoch 64/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 6.9691e-04 - val_loss: 9.3630e-04\n",
      "Epoch 65/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 6.8771e-04 - val_loss: 9.1181e-04\n",
      "Epoch 66/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 6.9377e-04 - val_loss: 4.8470e-04\n",
      "Epoch 67/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 7.1299e-04 - val_loss: 0.0013\n",
      "Epoch 68/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 7.2361e-04 - val_loss: 5.8061e-04\n",
      "Epoch 69/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 7.1318e-04 - val_loss: 7.6934e-04\n",
      "Epoch 70/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 6.9303e-04 - val_loss: 0.0012\n",
      "Epoch 71/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 6.7052e-04 - val_loss: 6.8981e-04\n",
      "Epoch 72/2000\n",
      "3977/3977 [==============================] - 1s 268us/step - loss: 6.6266e-04 - val_loss: 7.9625e-04\n",
      "Epoch 73/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 1s 264us/step - loss: 6.2595e-04 - val_loss: 7.7878e-04\n",
      "Epoch 74/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 6.5583e-04 - val_loss: 7.8524e-04\n",
      "Epoch 75/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 6.6729e-04 - val_loss: 7.8796e-04\n",
      "Epoch 76/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 6.5132e-04 - val_loss: 8.8701e-04\n",
      "Epoch 77/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 6.3273e-04 - val_loss: 8.3979e-04\n",
      "Epoch 78/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 6.3714e-04 - val_loss: 8.5498e-04\n",
      "Epoch 79/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 6.1456e-04 - val_loss: 6.7282e-04\n",
      "Epoch 80/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 6.3112e-04 - val_loss: 8.4480e-04\n",
      "Epoch 81/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 6.2734e-04 - val_loss: 7.8591e-04\n",
      "Epoch 82/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 6.2490e-04 - val_loss: 9.4461e-04\n",
      "Epoch 83/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 6.1887e-04 - val_loss: 4.9913e-04\n",
      "Epoch 84/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 6.5353e-04 - val_loss: 9.6052e-04\n",
      "Epoch 85/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 6.4837e-04 - val_loss: 8.8685e-04\n",
      "Epoch 86/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 6.3490e-04 - val_loss: 6.4732e-04\n",
      "Epoch 87/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 6.0934e-04 - val_loss: 0.0013\n",
      "Epoch 88/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 6.3706e-04 - val_loss: 8.1732e-04\n",
      "Epoch 89/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 6.0978e-04 - val_loss: 7.2155e-04\n",
      "Epoch 90/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 5.8668e-04 - val_loss: 9.4377e-04\n",
      "Epoch 91/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 6.1266e-04 - val_loss: 7.2121e-04\n",
      "Epoch 92/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 6.1252e-04 - val_loss: 9.8294e-04\n",
      "Epoch 93/2000\n",
      "3977/3977 [==============================] - 1s 270us/step - loss: 5.8456e-04 - val_loss: 7.3676e-04\n",
      "Epoch 94/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 6.4034e-04 - val_loss: 7.6347e-04\n",
      "Epoch 95/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 5.8379e-04 - val_loss: 0.0011\n",
      "Epoch 96/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 5.8139e-04 - val_loss: 9.2149e-04\n",
      "Epoch 97/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 5.8217e-04 - val_loss: 7.2787e-04\n",
      "Epoch 98/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 5.8906e-04 - val_loss: 0.0010\n",
      "Epoch 99/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 5.9772e-04 - val_loss: 8.0968e-04\n",
      "Epoch 100/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 5.9594e-04 - val_loss: 5.6489e-04\n",
      "Epoch 101/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 5.9610e-04 - val_loss: 7.9680e-04\n",
      "Epoch 102/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 5.7791e-04 - val_loss: 7.4328e-04\n",
      "Epoch 103/2000\n",
      "3977/3977 [==============================] - 1s 268us/step - loss: 5.6089e-04 - val_loss: 8.1580e-04\n",
      "Epoch 104/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 5.7268e-04 - val_loss: 6.0597e-04\n",
      "Epoch 105/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 6.0712e-04 - val_loss: 6.7768e-04\n",
      "Epoch 106/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 6.0737e-04 - val_loss: 0.0010\n",
      "Epoch 107/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 5.7291e-04 - val_loss: 7.2473e-04\n",
      "Epoch 108/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 5.6353e-04 - val_loss: 0.0011\n",
      "Epoch 109/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 5.7209e-04 - val_loss: 8.3783e-04\n",
      "Epoch 110/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 5.8061e-04 - val_loss: 9.5741e-04\n",
      "Epoch 111/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 5.7376e-04 - val_loss: 7.0994e-04\n",
      "Epoch 112/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 5.9732e-04 - val_loss: 8.0973e-04\n",
      "Epoch 113/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 5.6635e-04 - val_loss: 0.0013\n",
      "Epoch 114/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 5.7608e-04 - val_loss: 9.3735e-04\n",
      "Epoch 115/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 5.7588e-04 - val_loss: 8.6649e-04\n",
      "Epoch 116/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 5.6077e-04 - val_loss: 6.6706e-04\n",
      "Epoch 117/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 5.5384e-04 - val_loss: 8.1282e-04\n",
      "Epoch 118/2000\n",
      "3977/3977 [==============================] - 1s 268us/step - loss: 5.4941e-04 - val_loss: 0.0011\n",
      "Epoch 119/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 5.8604e-04 - val_loss: 0.0011\n",
      "Epoch 120/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 5.6482e-04 - val_loss: 9.6938e-04\n",
      "Epoch 121/2000\n",
      "3977/3977 [==============================] - 1s 270us/step - loss: 5.7438e-04 - val_loss: 7.0763e-04\n",
      "Epoch 122/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 5.4205e-04 - val_loss: 5.5379e-04\n",
      "Epoch 123/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 5.6193e-04 - val_loss: 7.4106e-04\n",
      "Epoch 124/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 5.4154e-04 - val_loss: 6.9818e-04\n",
      "Epoch 125/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 5.5516e-04 - val_loss: 7.0812e-04\n",
      "Epoch 126/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 5.3726e-04 - val_loss: 6.7946e-04\n",
      "Epoch 127/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 5.5400e-04 - val_loss: 9.0477e-04\n",
      "Epoch 128/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 5.4007e-04 - val_loss: 0.0012\n",
      "Epoch 129/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 5.7636e-04 - val_loss: 8.5517e-04\n",
      "Epoch 130/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 5.4496e-04 - val_loss: 7.4047e-04\n",
      "Epoch 131/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 5.4999e-04 - val_loss: 7.6781e-04\n",
      "Epoch 132/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 5.5105e-04 - val_loss: 0.0011\n",
      "Epoch 133/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 5.5160e-04 - val_loss: 0.0014\n",
      "Epoch 134/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 5.3646e-04 - val_loss: 0.0012\n",
      "Epoch 135/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 5.5208e-04 - val_loss: 8.0445e-04\n",
      "Epoch 136/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 5.4406e-04 - val_loss: 8.6827e-04\n",
      "Epoch 137/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 5.3304e-04 - val_loss: 9.0132e-04\n",
      "Epoch 138/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 5.4794e-04 - val_loss: 4.7536e-04\n",
      "Epoch 139/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 5.7488e-04 - val_loss: 6.7970e-04\n",
      "Epoch 140/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 5.6271e-04 - val_loss: 0.0012\n",
      "Epoch 141/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 5.4506e-04 - val_loss: 0.0011\n",
      "Epoch 142/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 5.4546e-04 - val_loss: 0.0014\n",
      "Epoch 143/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 5.3802e-04 - val_loss: 9.7083e-04\n",
      "Epoch 144/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 1s 263us/step - loss: 5.3450e-04 - val_loss: 8.3965e-04\n",
      "Epoch 145/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 5.1683e-04 - val_loss: 8.6087e-04\n",
      "Epoch 146/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 5.3682e-04 - val_loss: 9.6316e-04\n",
      "Epoch 147/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 5.3483e-04 - val_loss: 8.8035e-04\n",
      "Epoch 148/2000\n",
      "3977/3977 [==============================] - 1s 269us/step - loss: 5.2342e-04 - val_loss: 6.3992e-04\n",
      "Epoch 149/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 5.3153e-04 - val_loss: 7.5407e-04\n",
      "Epoch 150/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 5.5081e-04 - val_loss: 6.1301e-04\n",
      "Epoch 151/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 5.4628e-04 - val_loss: 6.0646e-04\n",
      "Epoch 152/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 5.7010e-04 - val_loss: 6.6496e-04\n",
      "Epoch 153/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 5.5017e-04 - val_loss: 0.0013\n",
      "Epoch 154/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 5.4001e-04 - val_loss: 7.6589e-04\n",
      "Epoch 155/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 5.2961e-04 - val_loss: 9.3563e-04\n",
      "Epoch 156/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 5.0351e-04 - val_loss: 0.0010\n",
      "Epoch 157/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 5.2085e-04 - val_loss: 0.0014\n",
      "Epoch 158/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 5.3636e-04 - val_loss: 0.0012\n",
      "Epoch 159/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 5.2324e-04 - val_loss: 0.0013\n",
      "Epoch 160/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 5.3155e-04 - val_loss: 0.0010\n",
      "Epoch 161/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 5.4001e-04 - val_loss: 0.0010\n",
      "Epoch 162/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 5.2589e-04 - val_loss: 0.0014\n",
      "Epoch 163/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 5.4002e-04 - val_loss: 6.8562e-04\n",
      "Epoch 164/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 5.4504e-04 - val_loss: 6.2802e-04\n",
      "Epoch 165/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 5.4242e-04 - val_loss: 9.4601e-04\n",
      "Epoch 166/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 5.0618e-04 - val_loss: 0.0019\n",
      "Epoch 167/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 5.5153e-04 - val_loss: 0.0010\n",
      "Epoch 168/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 5.3549e-04 - val_loss: 6.9604e-04\n",
      "Epoch 169/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 5.2626e-04 - val_loss: 0.0013\n",
      "Epoch 170/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 5.0762e-04 - val_loss: 0.0015\n",
      "Epoch 171/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 5.2423e-04 - val_loss: 0.0013\n",
      "Epoch 172/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 5.2146e-04 - val_loss: 6.9224e-04\n",
      "Epoch 173/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 5.1905e-04 - val_loss: 0.0011\n",
      "Epoch 174/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 5.1134e-04 - val_loss: 0.0011\n",
      "Epoch 175/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 5.1226e-04 - val_loss: 8.8319e-04\n",
      "Epoch 176/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 5.0335e-04 - val_loss: 8.6380e-04\n",
      "Epoch 177/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 5.0775e-04 - val_loss: 0.0015\n",
      "Epoch 178/2000\n",
      "3977/3977 [==============================] - 1s 272us/step - loss: 5.3102e-04 - val_loss: 0.0011\n",
      "Epoch 179/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 4.9980e-04 - val_loss: 5.6141e-04\n",
      "Epoch 180/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 5.3566e-04 - val_loss: 6.8058e-04\n",
      "Epoch 181/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 5.2482e-04 - val_loss: 0.0012\n",
      "Epoch 182/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 5.0353e-04 - val_loss: 0.0014\n",
      "Epoch 183/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.9691e-04 - val_loss: 0.0012\n",
      "Epoch 184/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.9519e-04 - val_loss: 9.0726e-04\n",
      "Epoch 185/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 5.0429e-04 - val_loss: 9.6278e-04\n",
      "Epoch 186/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 5.0749e-04 - val_loss: 8.3709e-04\n",
      "Epoch 187/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 5.1200e-04 - val_loss: 0.0011\n",
      "Epoch 188/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.9922e-04 - val_loss: 0.0011\n",
      "Epoch 189/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.9464e-04 - val_loss: 0.0014\n",
      "Epoch 190/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 5.0978e-04 - val_loss: 0.0011\n",
      "Epoch 191/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.9980e-04 - val_loss: 9.5474e-04\n",
      "Epoch 192/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 5.0279e-04 - val_loss: 7.7805e-04\n",
      "Epoch 193/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 5.1336e-04 - val_loss: 6.6259e-04\n",
      "Epoch 194/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 5.2531e-04 - val_loss: 9.4466e-04\n",
      "Epoch 195/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 5.0031e-04 - val_loss: 0.0011\n",
      "Epoch 196/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 5.1236e-04 - val_loss: 0.0017\n",
      "Epoch 197/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 5.2300e-04 - val_loss: 0.0019\n",
      "Epoch 198/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.9473e-04 - val_loss: 0.0010\n",
      "Epoch 199/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.9624e-04 - val_loss: 7.1356e-04\n",
      "Epoch 200/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 5.1146e-04 - val_loss: 8.7744e-04\n",
      "Epoch 201/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.9214e-04 - val_loss: 0.0011\n",
      "Epoch 202/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.7927e-04 - val_loss: 0.0014\n",
      "Epoch 203/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.9529e-04 - val_loss: 0.0018\n",
      "Epoch 204/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.9664e-04 - val_loss: 8.9138e-04\n",
      "Epoch 205/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.8920e-04 - val_loss: 8.1814e-04\n",
      "Epoch 206/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 4.7961e-04 - val_loss: 0.0011\n",
      "Epoch 207/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 4.9725e-04 - val_loss: 7.8892e-04\n",
      "Epoch 208/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.7719e-04 - val_loss: 8.7909e-04\n",
      "Epoch 209/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 5.0304e-04 - val_loss: 8.5902e-04\n",
      "Epoch 210/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 4.8236e-04 - val_loss: 0.0013\n",
      "Epoch 211/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.7814e-04 - val_loss: 9.8327e-04\n",
      "Epoch 212/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.8286e-04 - val_loss: 8.9319e-04\n",
      "Epoch 213/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 5.0024e-04 - val_loss: 9.4861e-04\n",
      "Epoch 214/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.9122e-04 - val_loss: 9.3345e-04\n",
      "Epoch 215/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 5.1777e-04 - val_loss: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 216/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 5.0755e-04 - val_loss: 8.7977e-04\n",
      "Epoch 217/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.8715e-04 - val_loss: 0.0011\n",
      "Epoch 218/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 4.7820e-04 - val_loss: 0.0011\n",
      "Epoch 219/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.9153e-04 - val_loss: 0.0010\n",
      "Epoch 220/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.8653e-04 - val_loss: 0.0013\n",
      "Epoch 221/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.8924e-04 - val_loss: 0.0018\n",
      "Epoch 222/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 5.1712e-04 - val_loss: 0.0014\n",
      "Epoch 223/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 5.3368e-04 - val_loss: 9.0722e-04\n",
      "Epoch 224/2000\n",
      "3977/3977 [==============================] - 1s 269us/step - loss: 4.9672e-04 - val_loss: 9.5684e-04\n",
      "Epoch 225/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 5.0212e-04 - val_loss: 9.9908e-04\n",
      "Epoch 226/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 4.8379e-04 - val_loss: 0.0010\n",
      "Epoch 227/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.9040e-04 - val_loss: 0.0014\n",
      "Epoch 228/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 4.8309e-04 - val_loss: 0.0014\n",
      "Epoch 229/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.8640e-04 - val_loss: 8.9368e-04\n",
      "Epoch 230/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.8401e-04 - val_loss: 9.4356e-04\n",
      "Epoch 231/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.9124e-04 - val_loss: 0.0013\n",
      "Epoch 232/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.7861e-04 - val_loss: 0.0013\n",
      "Epoch 233/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.6940e-04 - val_loss: 0.0011\n",
      "Epoch 234/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.6928e-04 - val_loss: 0.0012\n",
      "Epoch 235/2000\n",
      "3977/3977 [==============================] - 1s 271us/step - loss: 4.7307e-04 - val_loss: 0.0018\n",
      "Epoch 236/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 4.8451e-04 - val_loss: 9.3869e-04\n",
      "Epoch 237/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.8769e-04 - val_loss: 9.7900e-04\n",
      "Epoch 238/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.9463e-04 - val_loss: 9.6912e-04\n",
      "Epoch 239/2000\n",
      "3977/3977 [==============================] - 1s 268us/step - loss: 4.8662e-04 - val_loss: 0.0012\n",
      "Epoch 240/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.7278e-04 - val_loss: 0.0012\n",
      "Epoch 241/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.6505e-04 - val_loss: 9.9144e-04\n",
      "Epoch 242/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.6033e-04 - val_loss: 0.0010\n",
      "Epoch 243/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.7435e-04 - val_loss: 0.0011\n",
      "Epoch 244/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.8916e-04 - val_loss: 0.0013\n",
      "Epoch 245/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.9310e-04 - val_loss: 0.0013\n",
      "Epoch 246/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.7301e-04 - val_loss: 0.0015\n",
      "Epoch 247/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 4.6234e-04 - val_loss: 0.0016\n",
      "Epoch 248/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.5961e-04 - val_loss: 0.0014\n",
      "Epoch 249/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.8345e-04 - val_loss: 0.0017\n",
      "Epoch 250/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.8114e-04 - val_loss: 0.0013\n",
      "Epoch 251/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.6842e-04 - val_loss: 7.7005e-04\n",
      "Epoch 252/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 5.1225e-04 - val_loss: 5.0355e-04\n",
      "Epoch 253/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 5.2215e-04 - val_loss: 9.4768e-04\n",
      "Epoch 254/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 4.7569e-04 - val_loss: 0.0015\n",
      "Epoch 255/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.7177e-04 - val_loss: 0.0013\n",
      "Epoch 256/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.6550e-04 - val_loss: 0.0016\n",
      "Epoch 257/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.6278e-04 - val_loss: 0.0013\n",
      "Epoch 258/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.8244e-04 - val_loss: 0.0014\n",
      "Epoch 259/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 4.9515e-04 - val_loss: 0.0011\n",
      "Epoch 260/2000\n",
      "3977/3977 [==============================] - 1s 268us/step - loss: 4.8053e-04 - val_loss: 0.0011\n",
      "Epoch 261/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.8409e-04 - val_loss: 9.3055e-04\n",
      "Epoch 262/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.6749e-04 - val_loss: 0.0011\n",
      "Epoch 263/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 4.6332e-04 - val_loss: 0.0012\n",
      "Epoch 264/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 4.6859e-04 - val_loss: 0.0016\n",
      "Epoch 265/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.7734e-04 - val_loss: 0.0013\n",
      "Epoch 266/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.6985e-04 - val_loss: 0.0018\n",
      "Epoch 267/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.9736e-04 - val_loss: 0.0011\n",
      "Epoch 268/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.9271e-04 - val_loss: 8.5014e-04\n",
      "Epoch 269/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 4.8114e-04 - val_loss: 0.0014\n",
      "Epoch 270/2000\n",
      "3977/3977 [==============================] - 1s 282us/step - loss: 4.7740e-04 - val_loss: 0.0012\n",
      "Epoch 271/2000\n",
      "3977/3977 [==============================] - 1s 268us/step - loss: 4.6066e-04 - val_loss: 0.0011\n",
      "Epoch 272/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.6226e-04 - val_loss: 0.0011\n",
      "Epoch 273/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.6322e-04 - val_loss: 0.0014\n",
      "Epoch 274/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 4.5305e-04 - val_loss: 0.0014\n",
      "Epoch 275/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.5133e-04 - val_loss: 0.0014\n",
      "Epoch 276/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 4.6086e-04 - val_loss: 0.0015\n",
      "Epoch 277/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.5640e-04 - val_loss: 0.0014\n",
      "Epoch 278/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.5348e-04 - val_loss: 0.0015\n",
      "Epoch 279/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.5465e-04 - val_loss: 0.0013\n",
      "Epoch 280/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.6277e-04 - val_loss: 0.0016\n",
      "Epoch 281/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.6143e-04 - val_loss: 0.0017\n",
      "Epoch 282/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.5604e-04 - val_loss: 0.0014\n",
      "Epoch 283/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.5796e-04 - val_loss: 0.0013\n",
      "Epoch 284/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 4.5710e-04 - val_loss: 9.2124e-04\n",
      "Epoch 285/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.5624e-04 - val_loss: 0.0015\n",
      "Epoch 286/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.6553e-04 - val_loss: 0.0012\n",
      "Epoch 287/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.6095e-04 - val_loss: 0.0014\n",
      "Epoch 288/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.7546e-04 - val_loss: 8.2756e-04\n",
      "Epoch 289/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 4.6354e-04 - val_loss: 0.0011\n",
      "Epoch 290/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.6474e-04 - val_loss: 0.0011\n",
      "Epoch 291/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 4.7154e-04 - val_loss: 9.7376e-04\n",
      "Epoch 292/2000\n",
      "3977/3977 [==============================] - 1s 269us/step - loss: 4.6362e-04 - val_loss: 0.0011\n",
      "Epoch 293/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.7617e-04 - val_loss: 0.0010\n",
      "Epoch 294/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 4.5574e-04 - val_loss: 0.0012\n",
      "Epoch 295/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 4.4767e-04 - val_loss: 0.0014\n",
      "Epoch 296/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.4815e-04 - val_loss: 0.0016\n",
      "Epoch 297/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.4967e-04 - val_loss: 0.0014\n",
      "Epoch 298/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 4.7146e-04 - val_loss: 0.0011\n",
      "Epoch 299/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.6504e-04 - val_loss: 0.0012\n",
      "Epoch 300/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 4.5090e-04 - val_loss: 0.0013\n",
      "Epoch 301/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 4.5588e-04 - val_loss: 0.0016\n",
      "Epoch 302/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.5758e-04 - val_loss: 0.0012\n",
      "Epoch 303/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.4538e-04 - val_loss: 0.0011\n",
      "Epoch 304/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.6192e-04 - val_loss: 8.5985e-04\n",
      "Epoch 305/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.8189e-04 - val_loss: 8.5440e-04\n",
      "Epoch 306/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.8177e-04 - val_loss: 0.0011\n",
      "Epoch 307/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.7698e-04 - val_loss: 0.0015\n",
      "Epoch 308/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 4.6463e-04 - val_loss: 0.0014\n",
      "Epoch 309/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.5504e-04 - val_loss: 8.4236e-04\n",
      "Epoch 310/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.8948e-04 - val_loss: 0.0013\n",
      "Epoch 311/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 4.5411e-04 - val_loss: 0.0012\n",
      "Epoch 312/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.7284e-04 - val_loss: 0.0017\n",
      "Epoch 313/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.6355e-04 - val_loss: 0.0016\n",
      "Epoch 314/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.5319e-04 - val_loss: 0.0011\n",
      "Epoch 315/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 4.4604e-04 - val_loss: 0.0015\n",
      "Epoch 316/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.4827e-04 - val_loss: 0.0013\n",
      "Epoch 317/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.6578e-04 - val_loss: 0.0020\n",
      "Epoch 318/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.8432e-04 - val_loss: 0.0021\n",
      "Epoch 319/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.8672e-04 - val_loss: 0.0012\n",
      "Epoch 320/2000\n",
      "3977/3977 [==============================] - 1s 269us/step - loss: 4.8020e-04 - val_loss: 0.0011\n",
      "Epoch 321/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.9917e-04 - val_loss: 0.0016\n",
      "Epoch 322/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.7853e-04 - val_loss: 0.0019\n",
      "Epoch 323/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.4872e-04 - val_loss: 0.0012\n",
      "Epoch 324/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.4099e-04 - val_loss: 0.0013\n",
      "Epoch 325/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.8334e-04 - val_loss: 0.0016\n",
      "Epoch 326/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.6566e-04 - val_loss: 0.0019\n",
      "Epoch 327/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.5053e-04 - val_loss: 0.0013\n",
      "Epoch 328/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.5130e-04 - val_loss: 0.0018\n",
      "Epoch 329/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.6020e-04 - val_loss: 0.0014\n",
      "Epoch 330/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 4.5185e-04 - val_loss: 0.0016\n",
      "Epoch 331/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 4.4308e-04 - val_loss: 0.0013\n",
      "Epoch 332/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.3630e-04 - val_loss: 0.0014\n",
      "Epoch 333/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.3160e-04 - val_loss: 0.0011\n",
      "Epoch 334/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.3363e-04 - val_loss: 0.0016\n",
      "Epoch 335/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.3948e-04 - val_loss: 0.0017\n",
      "Epoch 336/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.6658e-04 - val_loss: 8.9652e-04\n",
      "Epoch 337/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.7533e-04 - val_loss: 0.0010\n",
      "Epoch 338/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 4.5351e-04 - val_loss: 0.0013\n",
      "Epoch 339/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.4314e-04 - val_loss: 0.0015\n",
      "Epoch 340/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.4227e-04 - val_loss: 0.0018\n",
      "Epoch 341/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.4142e-04 - val_loss: 0.0011\n",
      "Epoch 342/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.5296e-04 - val_loss: 9.6525e-04\n",
      "Epoch 343/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.7209e-04 - val_loss: 0.0014\n",
      "Epoch 344/2000\n",
      "3977/3977 [==============================] - 1s 268us/step - loss: 4.3667e-04 - val_loss: 0.0023\n",
      "Epoch 345/2000\n",
      "3977/3977 [==============================] - 1s 272us/step - loss: 4.5852e-04 - val_loss: 0.0016\n",
      "Epoch 346/2000\n",
      "3977/3977 [==============================] - 1s 269us/step - loss: 4.4337e-04 - val_loss: 0.0016\n",
      "Epoch 347/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.5079e-04 - val_loss: 0.0012\n",
      "Epoch 348/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 4.5505e-04 - val_loss: 0.0013\n",
      "Epoch 349/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.5322e-04 - val_loss: 0.0017\n",
      "Epoch 350/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.6676e-04 - val_loss: 0.0019\n",
      "Epoch 351/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.5375e-04 - val_loss: 0.0014\n",
      "Epoch 352/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.5570e-04 - val_loss: 0.0014\n",
      "Epoch 353/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.4333e-04 - val_loss: 0.0013\n",
      "Epoch 354/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.3232e-04 - val_loss: 0.0015\n",
      "Epoch 355/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.4416e-04 - val_loss: 0.0013\n",
      "Epoch 356/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.4660e-04 - val_loss: 0.0011\n",
      "Epoch 357/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.3482e-04 - val_loss: 0.0014\n",
      "Epoch 358/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.4626e-04 - val_loss: 0.0018\n",
      "Epoch 359/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 4.4841e-04 - val_loss: 0.0022\n",
      "Epoch 360/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 4.6011e-04 - val_loss: 0.0015\n",
      "Epoch 361/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.3599e-04 - val_loss: 0.0016\n",
      "Epoch 362/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.2180e-04 - val_loss: 0.0013\n",
      "Epoch 363/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.2651e-04 - val_loss: 0.0013\n",
      "Epoch 364/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.3821e-04 - val_loss: 0.0012\n",
      "Epoch 365/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 4.5659e-04 - val_loss: 0.0011\n",
      "Epoch 366/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.3202e-04 - val_loss: 0.0016\n",
      "Epoch 367/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 4.3772e-04 - val_loss: 0.0019\n",
      "Epoch 368/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.3869e-04 - val_loss: 0.0013\n",
      "Epoch 369/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.4129e-04 - val_loss: 0.0015\n",
      "Epoch 370/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.4102e-04 - val_loss: 0.0014\n",
      "Epoch 371/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.3764e-04 - val_loss: 0.0013\n",
      "Epoch 372/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.3197e-04 - val_loss: 0.0020\n",
      "Epoch 373/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.4939e-04 - val_loss: 0.0014\n",
      "Epoch 374/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.3737e-04 - val_loss: 9.8648e-04\n",
      "Epoch 375/2000\n",
      "3977/3977 [==============================] - 1s 268us/step - loss: 4.8432e-04 - val_loss: 0.0017\n",
      "Epoch 376/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.5832e-04 - val_loss: 0.0018\n",
      "Epoch 377/2000\n",
      "3977/3977 [==============================] - 1s 268us/step - loss: 4.3290e-04 - val_loss: 0.0010\n",
      "Epoch 378/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.5397e-04 - val_loss: 0.0012\n",
      "Epoch 379/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.3789e-04 - val_loss: 0.0015\n",
      "Epoch 380/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.3663e-04 - val_loss: 0.0013\n",
      "Epoch 381/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.3414e-04 - val_loss: 0.0012\n",
      "Epoch 382/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.3340e-04 - val_loss: 0.0014\n",
      "Epoch 383/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 4.2873e-04 - val_loss: 0.0013\n",
      "Epoch 384/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.3739e-04 - val_loss: 0.0018\n",
      "Epoch 385/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.5159e-04 - val_loss: 0.0018\n",
      "Epoch 386/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.4320e-04 - val_loss: 0.0016\n",
      "Epoch 387/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 4.6341e-04 - val_loss: 0.0010\n",
      "Epoch 388/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.5182e-04 - val_loss: 0.0015\n",
      "Epoch 389/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.4949e-04 - val_loss: 0.0019\n",
      "Epoch 390/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 4.3442e-04 - val_loss: 0.0015\n",
      "Epoch 391/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 4.3122e-04 - val_loss: 0.0016\n",
      "Epoch 392/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.3211e-04 - val_loss: 0.0014\n",
      "Epoch 393/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 4.3176e-04 - val_loss: 0.0017\n",
      "Epoch 394/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.3202e-04 - val_loss: 0.0014\n",
      "Epoch 395/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.4226e-04 - val_loss: 0.0015\n",
      "Epoch 396/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 4.3225e-04 - val_loss: 0.0019\n",
      "Epoch 397/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.5022e-04 - val_loss: 0.0012\n",
      "Epoch 398/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.4936e-04 - val_loss: 0.0011\n",
      "Epoch 399/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.6145e-04 - val_loss: 0.0023\n",
      "Epoch 400/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 4.5863e-04 - val_loss: 0.0014\n",
      "Epoch 401/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.3349e-04 - val_loss: 0.0015\n",
      "Epoch 402/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.3270e-04 - val_loss: 0.0019\n",
      "Epoch 403/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.2989e-04 - val_loss: 0.0013\n",
      "Epoch 404/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.2911e-04 - val_loss: 9.1831e-04\n",
      "Epoch 405/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 4.3224e-04 - val_loss: 0.0015\n",
      "Epoch 406/2000\n",
      "3977/3977 [==============================] - 1s 269us/step - loss: 4.3001e-04 - val_loss: 0.0015\n",
      "Epoch 407/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.2800e-04 - val_loss: 0.0016\n",
      "Epoch 408/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.1891e-04 - val_loss: 0.0014\n",
      "Epoch 409/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 4.2548e-04 - val_loss: 0.0014\n",
      "Epoch 410/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.2895e-04 - val_loss: 0.0016\n",
      "Epoch 411/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.4668e-04 - val_loss: 0.0011\n",
      "Epoch 412/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.3843e-04 - val_loss: 0.0011\n",
      "Epoch 413/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 4.6166e-04 - val_loss: 0.0015\n",
      "Epoch 414/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 4.5446e-04 - val_loss: 0.0023\n",
      "Epoch 415/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.6219e-04 - val_loss: 0.0010\n",
      "Epoch 416/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.5589e-04 - val_loss: 0.0011\n",
      "Epoch 417/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.4460e-04 - val_loss: 0.0020\n",
      "Epoch 418/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.4062e-04 - val_loss: 0.0019\n",
      "Epoch 419/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.2602e-04 - val_loss: 0.0016\n",
      "Epoch 420/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 4.2201e-04 - val_loss: 0.0016\n",
      "Epoch 421/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 4.3802e-04 - val_loss: 0.0013\n",
      "Epoch 422/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.2626e-04 - val_loss: 0.0010\n",
      "Epoch 423/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.5511e-04 - val_loss: 0.0013\n",
      "Epoch 424/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 4.4036e-04 - val_loss: 0.0020\n",
      "Epoch 425/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.2285e-04 - val_loss: 0.0014\n",
      "Epoch 426/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.2481e-04 - val_loss: 0.0016\n",
      "Epoch 427/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.2449e-04 - val_loss: 0.0016\n",
      "Epoch 428/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 4.4542e-04 - val_loss: 0.0023\n",
      "Epoch 429/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.3744e-04 - val_loss: 0.0016\n",
      "Epoch 430/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.2948e-04 - val_loss: 0.0014\n",
      "Epoch 431/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.3396e-04 - val_loss: 0.0015\n",
      "Epoch 432/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.2293e-04 - val_loss: 0.0017\n",
      "Epoch 433/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.3137e-04 - val_loss: 0.0011\n",
      "Epoch 434/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 1s 269us/step - loss: 4.6207e-04 - val_loss: 0.0013\n",
      "Epoch 435/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 4.3008e-04 - val_loss: 0.0016\n",
      "Epoch 436/2000\n",
      "3977/3977 [==============================] - 1s 270us/step - loss: 4.3372e-04 - val_loss: 0.0022\n",
      "Epoch 437/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.3077e-04 - val_loss: 0.0013\n",
      "Epoch 438/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.2165e-04 - val_loss: 0.0017\n",
      "Epoch 439/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.2260e-04 - val_loss: 0.0018\n",
      "Epoch 440/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 4.2947e-04 - val_loss: 0.0019\n",
      "Epoch 441/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.3126e-04 - val_loss: 0.0014\n",
      "Epoch 442/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.2081e-04 - val_loss: 0.0015\n",
      "Epoch 443/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.4760e-04 - val_loss: 0.0024\n",
      "Epoch 444/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.7770e-04 - val_loss: 0.0012\n",
      "Epoch 445/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.5347e-04 - val_loss: 0.0012\n",
      "Epoch 446/2000\n",
      "3977/3977 [==============================] - 1s 269us/step - loss: 4.3969e-04 - val_loss: 0.0016\n",
      "Epoch 447/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.3035e-04 - val_loss: 0.0020\n",
      "Epoch 448/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.2978e-04 - val_loss: 0.0014\n",
      "Epoch 449/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 4.2408e-04 - val_loss: 0.0015\n",
      "Epoch 450/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 4.2221e-04 - val_loss: 0.0017\n",
      "Epoch 451/2000\n",
      "3977/3977 [==============================] - 1s 268us/step - loss: 4.1663e-04 - val_loss: 0.0018\n",
      "Epoch 452/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 4.2115e-04 - val_loss: 0.0015\n",
      "Epoch 453/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.2110e-04 - val_loss: 0.0012\n",
      "Epoch 454/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.2113e-04 - val_loss: 0.0019\n",
      "Epoch 455/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.2633e-04 - val_loss: 0.0017\n",
      "Epoch 456/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.3452e-04 - val_loss: 0.0017\n",
      "Epoch 457/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.3003e-04 - val_loss: 0.0015\n",
      "Epoch 458/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.3062e-04 - val_loss: 0.0016\n",
      "Epoch 459/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.1171e-04 - val_loss: 0.0019\n",
      "Epoch 460/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.3390e-04 - val_loss: 0.0017\n",
      "Epoch 461/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.2383e-04 - val_loss: 0.0013\n",
      "Epoch 462/2000\n",
      "3977/3977 [==============================] - 1s 272us/step - loss: 4.3402e-04 - val_loss: 0.0017\n",
      "Epoch 463/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.3550e-04 - val_loss: 0.0019\n",
      "Epoch 464/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.2062e-04 - val_loss: 0.0013\n",
      "Epoch 465/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.2372e-04 - val_loss: 0.0014\n",
      "Epoch 466/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 4.2224e-04 - val_loss: 0.0019\n",
      "Epoch 467/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.2478e-04 - val_loss: 0.0017\n",
      "Epoch 468/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.2493e-04 - val_loss: 0.0019\n",
      "Epoch 469/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.2968e-04 - val_loss: 0.0017\n",
      "Epoch 470/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.1889e-04 - val_loss: 0.0025\n",
      "Epoch 471/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.3930e-04 - val_loss: 0.0019\n",
      "Epoch 472/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.2375e-04 - val_loss: 0.0015\n",
      "Epoch 473/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.1702e-04 - val_loss: 0.0014\n",
      "Epoch 474/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.2300e-04 - val_loss: 0.0016\n",
      "Epoch 475/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.2014e-04 - val_loss: 0.0017\n",
      "Epoch 476/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.2905e-04 - val_loss: 0.0014\n",
      "Epoch 477/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.2400e-04 - val_loss: 0.0021\n",
      "Epoch 478/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 4.3413e-04 - val_loss: 0.0015\n",
      "Epoch 479/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.2426e-04 - val_loss: 0.0022\n",
      "Epoch 480/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 4.2373e-04 - val_loss: 0.0015\n",
      "Epoch 481/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 4.2432e-04 - val_loss: 0.0020\n",
      "Epoch 482/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 4.2017e-04 - val_loss: 0.0019\n",
      "Epoch 483/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.2816e-04 - val_loss: 0.0016\n",
      "Epoch 484/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.2247e-04 - val_loss: 0.0013\n",
      "Epoch 485/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.2530e-04 - val_loss: 0.0021\n",
      "Epoch 486/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 4.2632e-04 - val_loss: 0.0020\n",
      "Epoch 487/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 4.2781e-04 - val_loss: 0.0016\n",
      "Epoch 488/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.1302e-04 - val_loss: 0.0012\n",
      "Epoch 489/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.4085e-04 - val_loss: 0.0017\n",
      "Epoch 490/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 4.1393e-04 - val_loss: 0.0014\n",
      "Epoch 491/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 4.1992e-04 - val_loss: 0.0016\n",
      "Epoch 492/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.1225e-04 - val_loss: 0.0017\n",
      "Epoch 493/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.2114e-04 - val_loss: 0.0019\n",
      "Epoch 494/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.1927e-04 - val_loss: 0.0018\n",
      "Epoch 495/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.1763e-04 - val_loss: 0.0017\n",
      "Epoch 496/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.2132e-04 - val_loss: 0.0013\n",
      "Epoch 497/2000\n",
      "3977/3977 [==============================] - 1s 268us/step - loss: 4.3552e-04 - val_loss: 0.0016\n",
      "Epoch 498/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.2335e-04 - val_loss: 0.0020\n",
      "Epoch 499/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.1909e-04 - val_loss: 0.0015\n",
      "Epoch 500/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.1470e-04 - val_loss: 0.0020\n",
      "Epoch 501/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.2164e-04 - val_loss: 0.0020\n",
      "Epoch 502/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 4.1015e-04 - val_loss: 0.0017\n",
      "Epoch 503/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.1077e-04 - val_loss: 0.0018\n",
      "Epoch 504/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.2350e-04 - val_loss: 0.0012\n",
      "Epoch 505/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.2570e-04 - val_loss: 0.0014\n",
      "Epoch 506/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 4.3101e-04 - val_loss: 0.0022\n",
      "Epoch 507/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.3228e-04 - val_loss: 0.0015\n",
      "Epoch 508/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.2198e-04 - val_loss: 0.0014\n",
      "Epoch 509/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.1513e-04 - val_loss: 0.0021\n",
      "Epoch 510/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.3012e-04 - val_loss: 0.0021\n",
      "Epoch 511/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 4.0901e-04 - val_loss: 0.0012\n",
      "Epoch 512/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 4.3945e-04 - val_loss: 0.0019\n",
      "Epoch 513/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.2493e-04 - val_loss: 0.0023\n",
      "Epoch 514/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.2511e-04 - val_loss: 0.0015\n",
      "Epoch 515/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.4573e-04 - val_loss: 0.0016\n",
      "Epoch 516/2000\n",
      "3977/3977 [==============================] - 1s 261us/step - loss: 4.2027e-04 - val_loss: 0.0016\n",
      "Epoch 517/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.1774e-04 - val_loss: 0.0014\n",
      "Epoch 518/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.1515e-04 - val_loss: 0.0016\n",
      "Epoch 519/2000\n",
      "3977/3977 [==============================] - 1s 268us/step - loss: 4.0803e-04 - val_loss: 0.0021\n",
      "Epoch 520/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.1064e-04 - val_loss: 0.0020\n",
      "Epoch 521/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.1607e-04 - val_loss: 0.0014\n",
      "Epoch 522/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.1337e-04 - val_loss: 0.0015\n",
      "Epoch 523/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.1652e-04 - val_loss: 0.0022\n",
      "Epoch 524/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.1139e-04 - val_loss: 0.0015\n",
      "Epoch 525/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.1786e-04 - val_loss: 0.0017\n",
      "Epoch 526/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.2436e-04 - val_loss: 0.0015\n",
      "Epoch 527/2000\n",
      "3977/3977 [==============================] - 1s 270us/step - loss: 4.2739e-04 - val_loss: 0.0011\n",
      "Epoch 528/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.3184e-04 - val_loss: 0.0022\n",
      "Epoch 529/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.2695e-04 - val_loss: 0.0021\n",
      "Epoch 530/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.2143e-04 - val_loss: 0.0017\n",
      "Epoch 531/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.2642e-04 - val_loss: 0.0010\n",
      "Epoch 532/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.3637e-04 - val_loss: 0.0020\n",
      "Epoch 533/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.3518e-04 - val_loss: 0.0028\n",
      "Epoch 534/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.5034e-04 - val_loss: 0.0017\n",
      "Epoch 535/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.3365e-04 - val_loss: 0.0011\n",
      "Epoch 536/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.5506e-04 - val_loss: 0.0022\n",
      "Epoch 537/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.5353e-04 - val_loss: 0.0022\n",
      "Epoch 538/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.3278e-04 - val_loss: 0.0013\n",
      "Epoch 539/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.1968e-04 - val_loss: 0.0023\n",
      "Epoch 540/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.1794e-04 - val_loss: 0.0015\n",
      "Epoch 541/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.0999e-04 - val_loss: 0.0020\n",
      "Epoch 542/2000\n",
      "3977/3977 [==============================] - 1s 268us/step - loss: 4.0335e-04 - val_loss: 0.0014\n",
      "Epoch 543/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.2769e-04 - val_loss: 0.0014\n",
      "Epoch 544/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.3178e-04 - val_loss: 0.0014\n",
      "Epoch 545/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.2179e-04 - val_loss: 0.0021\n",
      "Epoch 546/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.0317e-04 - val_loss: 0.0017\n",
      "Epoch 547/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.2150e-04 - val_loss: 0.0017\n",
      "Epoch 548/2000\n",
      "3977/3977 [==============================] - 1s 269us/step - loss: 4.2415e-04 - val_loss: 0.0023\n",
      "Epoch 549/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.2957e-04 - val_loss: 0.0018\n",
      "Epoch 550/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.1940e-04 - val_loss: 0.0021\n",
      "Epoch 551/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.1683e-04 - val_loss: 0.0018\n",
      "Epoch 552/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.1475e-04 - val_loss: 0.0013\n",
      "Epoch 553/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.4163e-04 - val_loss: 0.0022\n",
      "Epoch 554/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.2759e-04 - val_loss: 0.0020\n",
      "Epoch 555/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.1348e-04 - val_loss: 0.0018\n",
      "Epoch 556/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 4.1334e-04 - val_loss: 0.0018\n",
      "Epoch 557/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.1512e-04 - val_loss: 0.0018\n",
      "Epoch 558/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 4.1049e-04 - val_loss: 0.0015\n",
      "Epoch 559/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 4.1887e-04 - val_loss: 0.0020\n",
      "Epoch 560/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.1077e-04 - val_loss: 0.0020\n",
      "Epoch 561/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.1044e-04 - val_loss: 0.0014\n",
      "Epoch 562/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.2014e-04 - val_loss: 0.0022\n",
      "Epoch 563/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.2623e-04 - val_loss: 0.0021\n",
      "Epoch 564/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.1086e-04 - val_loss: 0.0017\n",
      "Epoch 565/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.1195e-04 - val_loss: 0.0018\n",
      "Epoch 566/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.1511e-04 - val_loss: 0.0017\n",
      "Epoch 567/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.1277e-04 - val_loss: 0.0020\n",
      "Epoch 568/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 4.1522e-04 - val_loss: 0.0016\n",
      "Epoch 569/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.1878e-04 - val_loss: 0.0017\n",
      "Epoch 570/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.0800e-04 - val_loss: 0.0019\n",
      "Epoch 571/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 4.1232e-04 - val_loss: 0.0018\n",
      "Epoch 572/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 4.1321e-04 - val_loss: 0.0025\n",
      "Epoch 573/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 4.2580e-04 - val_loss: 0.0020\n",
      "Epoch 574/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.1173e-04 - val_loss: 0.0018\n",
      "Epoch 575/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.0311e-04 - val_loss: 0.0017\n",
      "Epoch 576/2000\n",
      "3977/3977 [==============================] - 1s 270us/step - loss: 4.0585e-04 - val_loss: 0.0017\n",
      "Epoch 577/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.1239e-04 - val_loss: 0.0016\n",
      "Epoch 578/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.0159e-04 - val_loss: 0.0021\n",
      "Epoch 579/2000\n",
      "3977/3977 [==============================] - 1s 269us/step - loss: 4.1223e-04 - val_loss: 0.0021\n",
      "Epoch 580/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 1s 266us/step - loss: 4.1155e-04 - val_loss: 0.0021\n",
      "Epoch 581/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 4.1327e-04 - val_loss: 0.0023\n",
      "Epoch 582/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.1855e-04 - val_loss: 0.0016\n",
      "Epoch 583/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.2747e-04 - val_loss: 0.0015\n",
      "Epoch 584/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.1838e-04 - val_loss: 0.0020\n",
      "Epoch 585/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.0543e-04 - val_loss: 0.0018\n",
      "Epoch 586/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.0768e-04 - val_loss: 0.0019\n",
      "Epoch 587/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.1086e-04 - val_loss: 0.0014\n",
      "Epoch 588/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 4.1303e-04 - val_loss: 0.0020\n",
      "Epoch 589/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.0805e-04 - val_loss: 0.0022\n",
      "Epoch 590/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.2656e-04 - val_loss: 0.0016\n",
      "Epoch 591/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.2374e-04 - val_loss: 0.0013\n",
      "Epoch 592/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.2443e-04 - val_loss: 0.0021\n",
      "Epoch 593/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.1370e-04 - val_loss: 0.0017\n",
      "Epoch 594/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.1783e-04 - val_loss: 0.0015\n",
      "Epoch 595/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 4.0483e-04 - val_loss: 0.0021\n",
      "Epoch 596/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.9904e-04 - val_loss: 0.0023\n",
      "Epoch 597/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.2744e-04 - val_loss: 0.0013\n",
      "Epoch 598/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.4769e-04 - val_loss: 0.0013\n",
      "Epoch 599/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.2919e-04 - val_loss: 0.0022\n",
      "Epoch 600/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.1882e-04 - val_loss: 0.0023\n",
      "Epoch 601/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 4.1975e-04 - val_loss: 0.0018\n",
      "Epoch 602/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.1327e-04 - val_loss: 0.0013\n",
      "Epoch 603/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 4.1221e-04 - val_loss: 0.0023\n",
      "Epoch 604/2000\n",
      "3977/3977 [==============================] - 1s 268us/step - loss: 4.0345e-04 - val_loss: 0.0015\n",
      "Epoch 605/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 4.2003e-04 - val_loss: 0.0018\n",
      "Epoch 606/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.0048e-04 - val_loss: 0.0022\n",
      "Epoch 607/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.1441e-04 - val_loss: 0.0014\n",
      "Epoch 608/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.2277e-04 - val_loss: 0.0017\n",
      "Epoch 609/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.0006e-04 - val_loss: 0.0020\n",
      "Epoch 610/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 4.0391e-04 - val_loss: 0.0016\n",
      "Epoch 611/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.2733e-04 - val_loss: 0.0019\n",
      "Epoch 612/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.1743e-04 - val_loss: 0.0021\n",
      "Epoch 613/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.0313e-04 - val_loss: 0.0016\n",
      "Epoch 614/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.1253e-04 - val_loss: 0.0020\n",
      "Epoch 615/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.9932e-04 - val_loss: 0.0021\n",
      "Epoch 616/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.9646e-04 - val_loss: 0.0018\n",
      "Epoch 617/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.9973e-04 - val_loss: 0.0017\n",
      "Epoch 618/2000\n",
      "3977/3977 [==============================] - 1s 268us/step - loss: 4.0777e-04 - val_loss: 0.0018\n",
      "Epoch 619/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.1849e-04 - val_loss: 0.0025\n",
      "Epoch 620/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.2487e-04 - val_loss: 0.0017\n",
      "Epoch 621/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.1065e-04 - val_loss: 0.0018\n",
      "Epoch 622/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 4.1756e-04 - val_loss: 0.0021\n",
      "Epoch 623/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.0783e-04 - val_loss: 0.0019\n",
      "Epoch 624/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.0674e-04 - val_loss: 0.0018\n",
      "Epoch 625/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.1776e-04 - val_loss: 0.0012\n",
      "Epoch 626/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.2365e-04 - val_loss: 0.0021\n",
      "Epoch 627/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.2449e-04 - val_loss: 0.0025\n",
      "Epoch 628/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.1978e-04 - val_loss: 0.0015\n",
      "Epoch 629/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.9819e-04 - val_loss: 0.0019\n",
      "Epoch 630/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.0105e-04 - val_loss: 0.0016\n",
      "Epoch 631/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.0722e-04 - val_loss: 0.0022\n",
      "Epoch 632/2000\n",
      "3977/3977 [==============================] - 1s 261us/step - loss: 4.0741e-04 - val_loss: 0.0017\n",
      "Epoch 633/2000\n",
      "3977/3977 [==============================] - 1s 276us/step - loss: 4.1205e-04 - val_loss: 0.0016\n",
      "Epoch 634/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.2572e-04 - val_loss: 0.0024\n",
      "Epoch 635/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.2576e-04 - val_loss: 0.0017\n",
      "Epoch 636/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.2423e-04 - val_loss: 0.0016\n",
      "Epoch 637/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.0914e-04 - val_loss: 0.0020\n",
      "Epoch 638/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.0973e-04 - val_loss: 0.0015\n",
      "Epoch 639/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.1264e-04 - val_loss: 0.0021\n",
      "Epoch 640/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.0925e-04 - val_loss: 0.0022\n",
      "Epoch 641/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.1229e-04 - val_loss: 0.0015\n",
      "Epoch 642/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.1519e-04 - val_loss: 0.0017\n",
      "Epoch 643/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.2277e-04 - val_loss: 0.0029\n",
      "Epoch 644/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.5708e-04 - val_loss: 0.0021\n",
      "Epoch 645/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.2571e-04 - val_loss: 0.0017\n",
      "Epoch 646/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.0315e-04 - val_loss: 0.0018\n",
      "Epoch 647/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.0085e-04 - val_loss: 0.0021\n",
      "Epoch 648/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.1526e-04 - val_loss: 0.0013\n",
      "Epoch 649/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.1372e-04 - val_loss: 0.0021\n",
      "Epoch 650/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.1071e-04 - val_loss: 0.0022\n",
      "Epoch 651/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 4.0129e-04 - val_loss: 0.0017\n",
      "Epoch 652/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 3.9864e-04 - val_loss: 0.0019\n",
      "Epoch 653/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.0610e-04 - val_loss: 0.0018\n",
      "Epoch 654/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.0364e-04 - val_loss: 0.0022\n",
      "Epoch 655/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.0227e-04 - val_loss: 0.0017\n",
      "Epoch 656/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 4.0455e-04 - val_loss: 0.0020\n",
      "Epoch 657/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.1091e-04 - val_loss: 0.0014\n",
      "Epoch 658/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.0692e-04 - val_loss: 0.0027\n",
      "Epoch 659/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.1640e-04 - val_loss: 0.0021\n",
      "Epoch 660/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 4.1119e-04 - val_loss: 0.0019\n",
      "Epoch 661/2000\n",
      "3977/3977 [==============================] - 1s 269us/step - loss: 4.0833e-04 - val_loss: 0.0024\n",
      "Epoch 662/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.0273e-04 - val_loss: 0.0016\n",
      "Epoch 663/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 4.0350e-04 - val_loss: 0.0020\n",
      "Epoch 664/2000\n",
      "3977/3977 [==============================] - 1s 268us/step - loss: 4.0261e-04 - val_loss: 0.0020\n",
      "Epoch 665/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.0654e-04 - val_loss: 0.0019\n",
      "Epoch 666/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.0191e-04 - val_loss: 0.0016\n",
      "Epoch 667/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.0424e-04 - val_loss: 0.0022\n",
      "Epoch 668/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.0486e-04 - val_loss: 0.0023\n",
      "Epoch 669/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.1839e-04 - val_loss: 0.0015\n",
      "Epoch 670/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.1410e-04 - val_loss: 0.0017\n",
      "Epoch 671/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.9619e-04 - val_loss: 0.0019\n",
      "Epoch 672/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 4.0211e-04 - val_loss: 0.0018\n",
      "Epoch 673/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.0702e-04 - val_loss: 0.0021\n",
      "Epoch 674/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.0634e-04 - val_loss: 0.0025\n",
      "Epoch 675/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.2924e-04 - val_loss: 0.0024\n",
      "Epoch 676/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.1144e-04 - val_loss: 0.0016\n",
      "Epoch 677/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 4.0436e-04 - val_loss: 0.0018\n",
      "Epoch 678/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.0270e-04 - val_loss: 0.0020\n",
      "Epoch 679/2000\n",
      "3977/3977 [==============================] - 1s 268us/step - loss: 3.9775e-04 - val_loss: 0.0021\n",
      "Epoch 680/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.0441e-04 - val_loss: 0.0024\n",
      "Epoch 681/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.0021e-04 - val_loss: 0.0016\n",
      "Epoch 682/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.0522e-04 - val_loss: 0.0026\n",
      "Epoch 683/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.0247e-04 - val_loss: 0.0013\n",
      "Epoch 684/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.4410e-04 - val_loss: 0.0020\n",
      "Epoch 685/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.4007e-04 - val_loss: 0.0025\n",
      "Epoch 686/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 4.0711e-04 - val_loss: 0.0014\n",
      "Epoch 687/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.2517e-04 - val_loss: 0.0021\n",
      "Epoch 688/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.9721e-04 - val_loss: 0.0021\n",
      "Epoch 689/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.0539e-04 - val_loss: 0.0016\n",
      "Epoch 690/2000\n",
      "3977/3977 [==============================] - 1s 269us/step - loss: 4.0054e-04 - val_loss: 0.0020\n",
      "Epoch 691/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 3.9837e-04 - val_loss: 0.0019\n",
      "Epoch 692/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.0177e-04 - val_loss: 0.0020\n",
      "Epoch 693/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.9637e-04 - val_loss: 0.0022\n",
      "Epoch 694/2000\n",
      "3977/3977 [==============================] - 1s 268us/step - loss: 4.0875e-04 - val_loss: 0.0011\n",
      "Epoch 695/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.3848e-04 - val_loss: 0.0026\n",
      "Epoch 696/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.0988e-04 - val_loss: 0.0020\n",
      "Epoch 697/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.0119e-04 - val_loss: 0.0021\n",
      "Epoch 698/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 3.9877e-04 - val_loss: 0.0020\n",
      "Epoch 699/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 3.9979e-04 - val_loss: 0.0022\n",
      "Epoch 700/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.0063e-04 - val_loss: 0.0019\n",
      "Epoch 701/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.9804e-04 - val_loss: 0.0015\n",
      "Epoch 702/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.2325e-04 - val_loss: 0.0020\n",
      "Epoch 703/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.9949e-04 - val_loss: 0.0020\n",
      "Epoch 704/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.0015e-04 - val_loss: 0.0018\n",
      "Epoch 705/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.0939e-04 - val_loss: 0.0021\n",
      "Epoch 706/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 4.1222e-04 - val_loss: 0.0022\n",
      "Epoch 707/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.9670e-04 - val_loss: 0.0018\n",
      "Epoch 708/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.0051e-04 - val_loss: 0.0021\n",
      "Epoch 709/2000\n",
      "3977/3977 [==============================] - 1s 270us/step - loss: 3.9387e-04 - val_loss: 0.0018\n",
      "Epoch 710/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.9778e-04 - val_loss: 0.0020\n",
      "Epoch 711/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.9941e-04 - val_loss: 0.0016\n",
      "Epoch 712/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.0936e-04 - val_loss: 0.0022\n",
      "Epoch 713/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.0362e-04 - val_loss: 0.0019\n",
      "Epoch 714/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 4.0405e-04 - val_loss: 0.0019\n",
      "Epoch 715/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 4.0120e-04 - val_loss: 0.0025\n",
      "Epoch 716/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 4.0512e-04 - val_loss: 0.0020\n",
      "Epoch 717/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.0014e-04 - val_loss: 0.0014\n",
      "Epoch 718/2000\n",
      "3977/3977 [==============================] - 1s 269us/step - loss: 4.2662e-04 - val_loss: 0.0020\n",
      "Epoch 719/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.2639e-04 - val_loss: 0.0027\n",
      "Epoch 720/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.0668e-04 - val_loss: 0.0014\n",
      "Epoch 721/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.0153e-04 - val_loss: 0.0023\n",
      "Epoch 722/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.0423e-04 - val_loss: 0.0017\n",
      "Epoch 723/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.0133e-04 - val_loss: 0.0023\n",
      "Epoch 724/2000\n",
      "3977/3977 [==============================] - 1s 268us/step - loss: 4.1450e-04 - val_loss: 0.0023\n",
      "Epoch 725/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.1343e-04 - val_loss: 0.0016\n",
      "Epoch 726/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.0996e-04 - val_loss: 0.0029\n",
      "Epoch 727/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.2194e-04 - val_loss: 0.0018\n",
      "Epoch 728/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.1988e-04 - val_loss: 0.0018\n",
      "Epoch 729/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 4.1418e-04 - val_loss: 0.0022\n",
      "Epoch 730/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.9852e-04 - val_loss: 0.0026\n",
      "Epoch 731/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.1546e-04 - val_loss: 0.0017\n",
      "Epoch 732/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.0729e-04 - val_loss: 0.0021\n",
      "Epoch 733/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.0459e-04 - val_loss: 0.0023\n",
      "Epoch 734/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.0555e-04 - val_loss: 0.0015\n",
      "Epoch 735/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 4.2622e-04 - val_loss: 0.0023\n",
      "Epoch 736/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 4.0947e-04 - val_loss: 0.0016\n",
      "Epoch 737/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.3870e-04 - val_loss: 0.0020\n",
      "Epoch 738/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.2042e-04 - val_loss: 0.0022\n",
      "Epoch 739/2000\n",
      "3977/3977 [==============================] - 1s 268us/step - loss: 3.9994e-04 - val_loss: 0.0015\n",
      "Epoch 740/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.1732e-04 - val_loss: 0.0024\n",
      "Epoch 741/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.9775e-04 - val_loss: 0.0015\n",
      "Epoch 742/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 4.1001e-04 - val_loss: 0.0025\n",
      "Epoch 743/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.9891e-04 - val_loss: 0.0016\n",
      "Epoch 744/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.9786e-04 - val_loss: 0.0019\n",
      "Epoch 745/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.9944e-04 - val_loss: 0.0020\n",
      "Epoch 746/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 3.9516e-04 - val_loss: 0.0021\n",
      "Epoch 747/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 4.1053e-04 - val_loss: 0.0023\n",
      "Epoch 748/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.0718e-04 - val_loss: 0.0021\n",
      "Epoch 749/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.0044e-04 - val_loss: 0.0026\n",
      "Epoch 750/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.0055e-04 - val_loss: 0.0020\n",
      "Epoch 751/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.9747e-04 - val_loss: 0.0021\n",
      "Epoch 752/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.0206e-04 - val_loss: 0.0018\n",
      "Epoch 753/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.0218e-04 - val_loss: 0.0021\n",
      "Epoch 754/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 3.9689e-04 - val_loss: 0.0020\n",
      "Epoch 755/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.8846e-04 - val_loss: 0.0021\n",
      "Epoch 756/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.9447e-04 - val_loss: 0.0021\n",
      "Epoch 757/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.9416e-04 - val_loss: 0.0018\n",
      "Epoch 758/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.9262e-04 - val_loss: 0.0019\n",
      "Epoch 759/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.0423e-04 - val_loss: 0.0025\n",
      "Epoch 760/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.0685e-04 - val_loss: 0.0016\n",
      "Epoch 761/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.0262e-04 - val_loss: 0.0017\n",
      "Epoch 762/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.9208e-04 - val_loss: 0.0021\n",
      "Epoch 763/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.0062e-04 - val_loss: 0.0019\n",
      "Epoch 764/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 3.9510e-04 - val_loss: 0.0019\n",
      "Epoch 765/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.9545e-04 - val_loss: 0.0026\n",
      "Epoch 766/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.0645e-04 - val_loss: 0.0022\n",
      "Epoch 767/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.9005e-04 - val_loss: 0.0018\n",
      "Epoch 768/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.9828e-04 - val_loss: 0.0021\n",
      "Epoch 769/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.9650e-04 - val_loss: 0.0019\n",
      "Epoch 770/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 3.9654e-04 - val_loss: 0.0015\n",
      "Epoch 771/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.0404e-04 - val_loss: 0.0023\n",
      "Epoch 772/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.1894e-04 - val_loss: 0.0021\n",
      "Epoch 773/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.0208e-04 - val_loss: 0.0018\n",
      "Epoch 774/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.9879e-04 - val_loss: 0.0023\n",
      "Epoch 775/2000\n",
      "3977/3977 [==============================] - 1s 277us/step - loss: 3.9510e-04 - val_loss: 0.0018\n",
      "Epoch 776/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.0333e-04 - val_loss: 0.0022\n",
      "Epoch 777/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.9700e-04 - val_loss: 0.0015\n",
      "Epoch 778/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.0197e-04 - val_loss: 0.0021\n",
      "Epoch 779/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 3.9620e-04 - val_loss: 0.0023\n",
      "Epoch 780/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.9584e-04 - val_loss: 0.0018\n",
      "Epoch 781/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.9872e-04 - val_loss: 0.0014\n",
      "Epoch 782/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 4.1325e-04 - val_loss: 0.0023\n",
      "Epoch 783/2000\n",
      "3977/3977 [==============================] - 1s 277us/step - loss: 4.1541e-04 - val_loss: 0.0020\n",
      "Epoch 784/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.1434e-04 - val_loss: 0.0017\n",
      "Epoch 785/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 4.0944e-04 - val_loss: 0.0021\n",
      "Epoch 786/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.9299e-04 - val_loss: 0.0017\n",
      "Epoch 787/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 3.9817e-04 - val_loss: 0.0020\n",
      "Epoch 788/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.0140e-04 - val_loss: 0.0023\n",
      "Epoch 789/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.9335e-04 - val_loss: 0.0016\n",
      "Epoch 790/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.9645e-04 - val_loss: 0.0023\n",
      "Epoch 791/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 3.9014e-04 - val_loss: 0.0018\n",
      "Epoch 792/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.9148e-04 - val_loss: 0.0025\n",
      "Epoch 793/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.0165e-04 - val_loss: 0.0018\n",
      "Epoch 794/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.9813e-04 - val_loss: 0.0019\n",
      "Epoch 795/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 3.8708e-04 - val_loss: 0.0024\n",
      "Epoch 796/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.9872e-04 - val_loss: 0.0023\n",
      "Epoch 797/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 3.9582e-04 - val_loss: 0.0026\n",
      "Epoch 798/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.0258e-04 - val_loss: 0.0018\n",
      "Epoch 799/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.9316e-04 - val_loss: 0.0024\n",
      "Epoch 800/2000\n",
      "3977/3977 [==============================] - 1s 268us/step - loss: 3.9188e-04 - val_loss: 0.0016\n",
      "Epoch 801/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.1108e-04 - val_loss: 0.0017\n",
      "Epoch 802/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.9099e-04 - val_loss: 0.0021\n",
      "Epoch 803/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.8288e-04 - val_loss: 0.0021\n",
      "Epoch 804/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 3.9737e-04 - val_loss: 0.0015\n",
      "Epoch 805/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 4.1121e-04 - val_loss: 0.0016\n",
      "Epoch 806/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.2081e-04 - val_loss: 0.0026\n",
      "Epoch 807/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 4.2782e-04 - val_loss: 0.0016\n",
      "Epoch 808/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 4.0497e-04 - val_loss: 0.0026\n",
      "Epoch 809/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.9535e-04 - val_loss: 0.0020\n",
      "Epoch 810/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.8900e-04 - val_loss: 0.0019\n",
      "Epoch 811/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.0566e-04 - val_loss: 0.0023\n",
      "Epoch 812/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.9732e-04 - val_loss: 0.0020\n",
      "Epoch 813/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.9802e-04 - val_loss: 0.0020\n",
      "Epoch 814/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.8817e-04 - val_loss: 0.0021\n",
      "Epoch 815/2000\n",
      "3977/3977 [==============================] - 1s 269us/step - loss: 3.9055e-04 - val_loss: 0.0020\n",
      "Epoch 816/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.9300e-04 - val_loss: 0.0023\n",
      "Epoch 817/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 3.9020e-04 - val_loss: 0.0018\n",
      "Epoch 818/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.9454e-04 - val_loss: 0.0018\n",
      "Epoch 819/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.9408e-04 - val_loss: 0.0022\n",
      "Epoch 820/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.0104e-04 - val_loss: 0.0019\n",
      "Epoch 821/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.9169e-04 - val_loss: 0.0027\n",
      "Epoch 822/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.9423e-04 - val_loss: 0.0021\n",
      "Epoch 823/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.8530e-04 - val_loss: 0.0021\n",
      "Epoch 824/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.9089e-04 - val_loss: 0.0015\n",
      "Epoch 825/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.9311e-04 - val_loss: 0.0023\n",
      "Epoch 826/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.9348e-04 - val_loss: 0.0018\n",
      "Epoch 827/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.8530e-04 - val_loss: 0.0019\n",
      "Epoch 828/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 3.9176e-04 - val_loss: 0.0018\n",
      "Epoch 829/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 3.9528e-04 - val_loss: 0.0023\n",
      "Epoch 830/2000\n",
      "3977/3977 [==============================] - 1s 269us/step - loss: 3.8925e-04 - val_loss: 0.0019\n",
      "Epoch 831/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.9025e-04 - val_loss: 0.0020\n",
      "Epoch 832/2000\n",
      "3977/3977 [==============================] - 1s 270us/step - loss: 3.8614e-04 - val_loss: 0.0028\n",
      "Epoch 833/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.9761e-04 - val_loss: 0.0013\n",
      "Epoch 834/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.0330e-04 - val_loss: 0.0027\n",
      "Epoch 835/2000\n",
      "3977/3977 [==============================] - 1s 261us/step - loss: 4.1066e-04 - val_loss: 0.0019\n",
      "Epoch 836/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.0142e-04 - val_loss: 0.0021\n",
      "Epoch 837/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.9050e-04 - val_loss: 0.0021\n",
      "Epoch 838/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.0022e-04 - val_loss: 0.0021\n",
      "Epoch 839/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.9259e-04 - val_loss: 0.0020\n",
      "Epoch 840/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.9486e-04 - val_loss: 0.0017\n",
      "Epoch 841/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.9270e-04 - val_loss: 0.0029\n",
      "Epoch 842/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.0346e-04 - val_loss: 0.0021\n",
      "Epoch 843/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 3.9242e-04 - val_loss: 0.0020\n",
      "Epoch 844/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.8827e-04 - val_loss: 0.0022\n",
      "Epoch 845/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 3.9374e-04 - val_loss: 0.0028\n",
      "Epoch 846/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.4076e-04 - val_loss: 0.0024\n",
      "Epoch 847/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.0670e-04 - val_loss: 0.0020\n",
      "Epoch 848/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.9290e-04 - val_loss: 0.0023\n",
      "Epoch 849/2000\n",
      "3977/3977 [==============================] - 1s 260us/step - loss: 3.9404e-04 - val_loss: 0.0020\n",
      "Epoch 850/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.0483e-04 - val_loss: 0.0019\n",
      "Epoch 851/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 3.9631e-04 - val_loss: 0.0026\n",
      "Epoch 852/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.9981e-04 - val_loss: 0.0015\n",
      "Epoch 853/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.9290e-04 - val_loss: 0.0027\n",
      "Epoch 854/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 3.9510e-04 - val_loss: 0.0017\n",
      "Epoch 855/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.8820e-04 - val_loss: 0.0023\n",
      "Epoch 856/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.9533e-04 - val_loss: 0.0019\n",
      "Epoch 857/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.9828e-04 - val_loss: 0.0019\n",
      "Epoch 858/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.9340e-04 - val_loss: 0.0024\n",
      "Epoch 859/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.9815e-04 - val_loss: 0.0018\n",
      "Epoch 860/2000\n",
      "3977/3977 [==============================] - 1s 271us/step - loss: 3.9072e-04 - val_loss: 0.0021\n",
      "Epoch 861/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 3.9761e-04 - val_loss: 0.0024\n",
      "Epoch 862/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.9382e-04 - val_loss: 0.0018\n",
      "Epoch 863/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.8051e-04 - val_loss: 0.0024\n",
      "Epoch 864/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.9489e-04 - val_loss: 0.0025\n",
      "Epoch 865/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.8845e-04 - val_loss: 0.0020\n",
      "Epoch 866/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.9063e-04 - val_loss: 0.0020\n",
      "Epoch 867/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.9239e-04 - val_loss: 0.0023\n",
      "Epoch 868/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.8530e-04 - val_loss: 0.0020\n",
      "Epoch 869/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 3.8302e-04 - val_loss: 0.0018\n",
      "Epoch 870/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.9217e-04 - val_loss: 0.0026\n",
      "Epoch 871/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 3.9065e-04 - val_loss: 0.0018\n",
      "Epoch 872/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.9614e-04 - val_loss: 0.0023\n",
      "Epoch 873/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.9856e-04 - val_loss: 0.0023\n",
      "Epoch 874/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 4.0912e-04 - val_loss: 0.0012\n",
      "Epoch 875/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 4.4414e-04 - val_loss: 0.0029\n",
      "Epoch 876/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 4.2591e-04 - val_loss: 0.0024\n",
      "Epoch 877/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.9898e-04 - val_loss: 0.0017\n",
      "Epoch 878/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.9458e-04 - val_loss: 0.0024\n",
      "Epoch 879/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.9169e-04 - val_loss: 0.0016\n",
      "Epoch 880/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 3.9212e-04 - val_loss: 0.0027\n",
      "Epoch 881/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.9468e-04 - val_loss: 0.0017\n",
      "Epoch 882/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 3.9101e-04 - val_loss: 0.0024\n",
      "Epoch 883/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.9128e-04 - val_loss: 0.0018\n",
      "Epoch 884/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.9967e-04 - val_loss: 0.0021\n",
      "Epoch 885/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.8551e-04 - val_loss: 0.0022\n",
      "Epoch 886/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.8569e-04 - val_loss: 0.0023\n",
      "Epoch 887/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.8968e-04 - val_loss: 0.0016\n",
      "Epoch 888/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 3.9680e-04 - val_loss: 0.0023\n",
      "Epoch 889/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 3.8811e-04 - val_loss: 0.0017\n",
      "Epoch 890/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 3.9277e-04 - val_loss: 0.0024\n",
      "Epoch 891/2000\n",
      "3977/3977 [==============================] - 1s 268us/step - loss: 3.9345e-04 - val_loss: 0.0028\n",
      "Epoch 892/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 4.0211e-04 - val_loss: 0.0016\n",
      "Epoch 893/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 3.9430e-04 - val_loss: 0.0020\n",
      "Epoch 894/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 3.8703e-04 - val_loss: 0.0024\n",
      "Epoch 895/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.8536e-04 - val_loss: 0.0022\n",
      "Epoch 896/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.9126e-04 - val_loss: 0.0020\n",
      "Epoch 897/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.9205e-04 - val_loss: 0.0024\n",
      "Epoch 898/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.8613e-04 - val_loss: 0.0020\n",
      "Epoch 899/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.9403e-04 - val_loss: 0.0027\n",
      "Epoch 900/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.9547e-04 - val_loss: 0.0017\n",
      "Epoch 901/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.9600e-04 - val_loss: 0.0023\n",
      "Epoch 902/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.9990e-04 - val_loss: 0.0017\n",
      "Epoch 903/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.0188e-04 - val_loss: 0.0034\n",
      "Epoch 904/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.2530e-04 - val_loss: 0.0014\n",
      "Epoch 905/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.2471e-04 - val_loss: 0.0029\n",
      "Epoch 906/2000\n",
      "3977/3977 [==============================] - 1s 268us/step - loss: 4.1830e-04 - val_loss: 0.0015\n",
      "Epoch 907/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.9295e-04 - val_loss: 0.0020\n",
      "Epoch 908/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.8468e-04 - val_loss: 0.0022\n",
      "Epoch 909/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.8741e-04 - val_loss: 0.0022\n",
      "Epoch 910/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.8635e-04 - val_loss: 0.0022\n",
      "Epoch 911/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.8543e-04 - val_loss: 0.0022\n",
      "Epoch 912/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.9112e-04 - val_loss: 0.0021\n",
      "Epoch 913/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.9018e-04 - val_loss: 0.0024\n",
      "Epoch 914/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.8407e-04 - val_loss: 0.0025\n",
      "Epoch 915/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.0366e-04 - val_loss: 0.0024\n",
      "Epoch 916/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.1136e-04 - val_loss: 0.0019\n",
      "Epoch 917/2000\n",
      "3977/3977 [==============================] - 1s 269us/step - loss: 3.8847e-04 - val_loss: 0.0021\n",
      "Epoch 918/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.0758e-04 - val_loss: 0.0026\n",
      "Epoch 919/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 4.1585e-04 - val_loss: 0.0021\n",
      "Epoch 920/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.8711e-04 - val_loss: 0.0017\n",
      "Epoch 921/2000\n",
      "3977/3977 [==============================] - 1s 270us/step - loss: 3.9596e-04 - val_loss: 0.0026\n",
      "Epoch 922/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.9779e-04 - val_loss: 0.0016\n",
      "Epoch 923/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.9225e-04 - val_loss: 0.0026\n",
      "Epoch 924/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.9325e-04 - val_loss: 0.0022\n",
      "Epoch 925/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 3.9213e-04 - val_loss: 0.0018\n",
      "Epoch 926/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 3.9173e-04 - val_loss: 0.0028\n",
      "Epoch 927/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.0320e-04 - val_loss: 0.0017\n",
      "Epoch 928/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 3.8248e-04 - val_loss: 0.0021\n",
      "Epoch 929/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.8563e-04 - val_loss: 0.0016\n",
      "Epoch 930/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.9032e-04 - val_loss: 0.0023\n",
      "Epoch 931/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.7955e-04 - val_loss: 0.0021\n",
      "Epoch 932/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.8359e-04 - val_loss: 0.0023\n",
      "Epoch 933/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.7992e-04 - val_loss: 0.0022\n",
      "Epoch 934/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.8666e-04 - val_loss: 0.0024\n",
      "Epoch 935/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 3.8893e-04 - val_loss: 0.0022\n",
      "Epoch 936/2000\n",
      "3977/3977 [==============================] - 1s 268us/step - loss: 3.8935e-04 - val_loss: 0.0017\n",
      "Epoch 937/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 3.9727e-04 - val_loss: 0.0026\n",
      "Epoch 938/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.9420e-04 - val_loss: 0.0017\n",
      "Epoch 939/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.9843e-04 - val_loss: 0.0025\n",
      "Epoch 940/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.9384e-04 - val_loss: 0.0023\n",
      "Epoch 941/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.9099e-04 - val_loss: 0.0023\n",
      "Epoch 942/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.8814e-04 - val_loss: 0.0022\n",
      "Epoch 943/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.8870e-04 - val_loss: 0.0019\n",
      "Epoch 944/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.9655e-04 - val_loss: 0.0024\n",
      "Epoch 945/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 1s 267us/step - loss: 3.8311e-04 - val_loss: 0.0018\n",
      "Epoch 946/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 3.9091e-04 - val_loss: 0.0018\n",
      "Epoch 947/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.1398e-04 - val_loss: 0.0025\n",
      "Epoch 948/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.2678e-04 - val_loss: 0.0019\n",
      "Epoch 949/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.2327e-04 - val_loss: 0.0021\n",
      "Epoch 950/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 4.1069e-04 - val_loss: 0.0024\n",
      "Epoch 951/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 3.9235e-04 - val_loss: 0.0020\n",
      "Epoch 952/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.8542e-04 - val_loss: 0.0022\n",
      "Epoch 953/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 3.8456e-04 - val_loss: 0.0027\n",
      "Epoch 954/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.8868e-04 - val_loss: 0.0013\n",
      "Epoch 955/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.1581e-04 - val_loss: 0.0028\n",
      "Epoch 956/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.9395e-04 - val_loss: 0.0015\n",
      "Epoch 957/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.9249e-04 - val_loss: 0.0026\n",
      "Epoch 958/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 3.8639e-04 - val_loss: 0.0022\n",
      "Epoch 959/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.8085e-04 - val_loss: 0.0026\n",
      "Epoch 960/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 3.8641e-04 - val_loss: 0.0018\n",
      "Epoch 961/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.8900e-04 - val_loss: 0.0028\n",
      "Epoch 962/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.9093e-04 - val_loss: 0.0021\n",
      "Epoch 963/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.8890e-04 - val_loss: 0.0018\n",
      "Epoch 964/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.9021e-04 - val_loss: 0.0024\n",
      "Epoch 965/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 3.8887e-04 - val_loss: 0.0021\n",
      "Epoch 966/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 3.8521e-04 - val_loss: 0.0021\n",
      "Epoch 967/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 3.8232e-04 - val_loss: 0.0022\n",
      "Epoch 968/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.8708e-04 - val_loss: 0.0019\n",
      "Epoch 969/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.7887e-04 - val_loss: 0.0023\n",
      "Epoch 970/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.9137e-04 - val_loss: 0.0019\n",
      "Epoch 971/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.8996e-04 - val_loss: 0.0023\n",
      "Epoch 972/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.8198e-04 - val_loss: 0.0024\n",
      "Epoch 973/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.8830e-04 - val_loss: 0.0015\n",
      "Epoch 974/2000\n",
      "3977/3977 [==============================] - 1s 272us/step - loss: 3.9574e-04 - val_loss: 0.0026\n",
      "Epoch 975/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.9194e-04 - val_loss: 0.0018\n",
      "Epoch 976/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.8938e-04 - val_loss: 0.0025\n",
      "Epoch 977/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 3.8517e-04 - val_loss: 0.0020\n",
      "Epoch 978/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.8391e-04 - val_loss: 0.0023\n",
      "Epoch 979/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.9082e-04 - val_loss: 0.0023\n",
      "Epoch 980/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.8196e-04 - val_loss: 0.0021\n",
      "Epoch 981/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 3.8630e-04 - val_loss: 0.0023\n",
      "Epoch 982/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.7818e-04 - val_loss: 0.0020\n",
      "Epoch 983/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.8046e-04 - val_loss: 0.0020\n",
      "Epoch 984/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.8960e-04 - val_loss: 0.0025\n",
      "Epoch 985/2000\n",
      "3977/3977 [==============================] - 1s 261us/step - loss: 4.0436e-04 - val_loss: 0.0021\n",
      "Epoch 986/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.0645e-04 - val_loss: 0.0022\n",
      "Epoch 987/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.8809e-04 - val_loss: 0.0023\n",
      "Epoch 988/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.8828e-04 - val_loss: 0.0023\n",
      "Epoch 989/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.9513e-04 - val_loss: 0.0025\n",
      "Epoch 990/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.9526e-04 - val_loss: 0.0021\n",
      "Epoch 991/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.8393e-04 - val_loss: 0.0023\n",
      "Epoch 992/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.8058e-04 - val_loss: 0.0021\n",
      "Epoch 993/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.0019e-04 - val_loss: 0.0031\n",
      "Epoch 994/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.0639e-04 - val_loss: 0.0015\n",
      "Epoch 995/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.0742e-04 - val_loss: 0.0032\n",
      "Epoch 996/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.1017e-04 - val_loss: 0.0018\n",
      "Epoch 997/2000\n",
      "3977/3977 [==============================] - 1s 268us/step - loss: 4.0480e-04 - val_loss: 0.0025\n",
      "Epoch 998/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 3.9672e-04 - val_loss: 0.0016\n",
      "Epoch 999/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 3.9134e-04 - val_loss: 0.0027\n",
      "Epoch 1000/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.0154e-04 - val_loss: 0.0017\n",
      "Epoch 1001/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.9326e-04 - val_loss: 0.0026\n",
      "Epoch 1002/2000\n",
      "3977/3977 [==============================] - 1s 268us/step - loss: 3.9440e-04 - val_loss: 0.0021\n",
      "Epoch 1003/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 3.8502e-04 - val_loss: 0.0022\n",
      "Epoch 1004/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.8188e-04 - val_loss: 0.0023\n",
      "Epoch 1005/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.7896e-04 - val_loss: 0.0020\n",
      "Epoch 1006/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.8436e-04 - val_loss: 0.0022\n",
      "Epoch 1007/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.8904e-04 - val_loss: 0.0020\n",
      "Epoch 1008/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.8542e-04 - val_loss: 0.0025\n",
      "Epoch 1009/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.8457e-04 - val_loss: 0.0024\n",
      "Epoch 1010/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.9026e-04 - val_loss: 0.0020\n",
      "Epoch 1011/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.8920e-04 - val_loss: 0.0024\n",
      "Epoch 1012/2000\n",
      "3977/3977 [==============================] - 1s 268us/step - loss: 3.8241e-04 - val_loss: 0.0023\n",
      "Epoch 1013/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.8381e-04 - val_loss: 0.0020\n",
      "Epoch 1014/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.9248e-04 - val_loss: 0.0020\n",
      "Epoch 1015/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.8760e-04 - val_loss: 0.0023\n",
      "Epoch 1016/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.8123e-04 - val_loss: 0.0024\n",
      "Epoch 1017/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.8389e-04 - val_loss: 0.0024\n",
      "Epoch 1018/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.8732e-04 - val_loss: 0.0025\n",
      "Epoch 1019/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.8986e-04 - val_loss: 0.0017\n",
      "Epoch 1020/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.9286e-04 - val_loss: 0.0025\n",
      "Epoch 1021/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.9046e-04 - val_loss: 0.0024\n",
      "Epoch 1022/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.0141e-04 - val_loss: 0.0018\n",
      "Epoch 1023/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 3.9043e-04 - val_loss: 0.0024\n",
      "Epoch 1024/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.8383e-04 - val_loss: 0.0020\n",
      "Epoch 1025/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.8385e-04 - val_loss: 0.0026\n",
      "Epoch 1026/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 3.8104e-04 - val_loss: 0.0019\n",
      "Epoch 1027/2000\n",
      "3977/3977 [==============================] - 1s 268us/step - loss: 4.0105e-04 - val_loss: 0.0026\n",
      "Epoch 1028/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.8497e-04 - val_loss: 0.0020\n",
      "Epoch 1029/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.8438e-04 - val_loss: 0.0022\n",
      "Epoch 1030/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.7835e-04 - val_loss: 0.0018\n",
      "Epoch 1031/2000\n",
      "3977/3977 [==============================] - 1s 269us/step - loss: 3.9337e-04 - val_loss: 0.0023\n",
      "Epoch 1032/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.8414e-04 - val_loss: 0.0014\n",
      "Epoch 1033/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.2490e-04 - val_loss: 0.0028\n",
      "Epoch 1034/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 4.0581e-04 - val_loss: 0.0023\n",
      "Epoch 1035/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.9392e-04 - val_loss: 0.0024\n",
      "Epoch 1036/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.8892e-04 - val_loss: 0.0022\n",
      "Epoch 1037/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.7895e-04 - val_loss: 0.0025\n",
      "Epoch 1038/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.8916e-04 - val_loss: 0.0021\n",
      "Epoch 1039/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.0493e-04 - val_loss: 0.0020\n",
      "Epoch 1040/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.9192e-04 - val_loss: 0.0022\n",
      "Epoch 1041/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.8367e-04 - val_loss: 0.0024\n",
      "Epoch 1042/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 3.7709e-04 - val_loss: 0.0020\n",
      "Epoch 1043/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.7942e-04 - val_loss: 0.0022\n",
      "Epoch 1044/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 3.7973e-04 - val_loss: 0.0024\n",
      "Epoch 1045/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.8794e-04 - val_loss: 0.0020\n",
      "Epoch 1046/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.8295e-04 - val_loss: 0.0024\n",
      "Epoch 1047/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.8439e-04 - val_loss: 0.0020\n",
      "Epoch 1048/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.8905e-04 - val_loss: 0.0026\n",
      "Epoch 1049/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.8297e-04 - val_loss: 0.0022\n",
      "Epoch 1050/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.7703e-04 - val_loss: 0.0018\n",
      "Epoch 1051/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.8613e-04 - val_loss: 0.0024\n",
      "Epoch 1052/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.8089e-04 - val_loss: 0.0024\n",
      "Epoch 1053/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.8410e-04 - val_loss: 0.0025\n",
      "Epoch 1054/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.8828e-04 - val_loss: 0.0019\n",
      "Epoch 1055/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.9084e-04 - val_loss: 0.0024\n",
      "Epoch 1056/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.8659e-04 - val_loss: 0.0021\n",
      "Epoch 1057/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 3.8421e-04 - val_loss: 0.0025\n",
      "Epoch 1058/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.9367e-04 - val_loss: 0.0018\n",
      "Epoch 1059/2000\n",
      "3977/3977 [==============================] - 1s 270us/step - loss: 3.9592e-04 - val_loss: 0.0024\n",
      "Epoch 1060/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.8365e-04 - val_loss: 0.0026\n",
      "Epoch 1061/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 4.0129e-04 - val_loss: 0.0016\n",
      "Epoch 1062/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.9736e-04 - val_loss: 0.0027\n",
      "Epoch 1063/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 3.9249e-04 - val_loss: 0.0019\n",
      "Epoch 1064/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.8255e-04 - val_loss: 0.0026\n",
      "Epoch 1065/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.8033e-04 - val_loss: 0.0019\n",
      "Epoch 1066/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 3.7901e-04 - val_loss: 0.0025\n",
      "Epoch 1067/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.7611e-04 - val_loss: 0.0022\n",
      "Epoch 1068/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.7963e-04 - val_loss: 0.0023\n",
      "Epoch 1069/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.8426e-04 - val_loss: 0.0019\n",
      "Epoch 1070/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.9488e-04 - val_loss: 0.0020\n",
      "Epoch 1071/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.8672e-04 - val_loss: 0.0028\n",
      "Epoch 1072/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 3.8278e-04 - val_loss: 0.0022\n",
      "Epoch 1073/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 3.8508e-04 - val_loss: 0.0024\n",
      "Epoch 1074/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 3.8379e-04 - val_loss: 0.0021\n",
      "Epoch 1075/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.7854e-04 - val_loss: 0.0021\n",
      "Epoch 1076/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.8162e-04 - val_loss: 0.0025\n",
      "Epoch 1077/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 3.7959e-04 - val_loss: 0.0023\n",
      "Epoch 1078/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.7678e-04 - val_loss: 0.0027\n",
      "Epoch 1079/2000\n",
      "3977/3977 [==============================] - 1s 269us/step - loss: 3.8227e-04 - val_loss: 0.0026\n",
      "Epoch 1080/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 3.7907e-04 - val_loss: 0.0024\n",
      "Epoch 1081/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.7671e-04 - val_loss: 0.0021\n",
      "Epoch 1082/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 3.8477e-04 - val_loss: 0.0023\n",
      "Epoch 1083/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 3.7981e-04 - val_loss: 0.0022\n",
      "Epoch 1084/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.9504e-04 - val_loss: 0.0028\n",
      "Epoch 1085/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.9341e-04 - val_loss: 0.0020\n",
      "Epoch 1086/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 3.7594e-04 - val_loss: 0.0023\n",
      "Epoch 1087/2000\n",
      "3977/3977 [==============================] - 1s 278us/step - loss: 3.8696e-04 - val_loss: 0.0022\n",
      "Epoch 1088/2000\n",
      "3977/3977 [==============================] - 1s 270us/step - loss: 3.8358e-04 - val_loss: 0.0025\n",
      "Epoch 1089/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.8045e-04 - val_loss: 0.0020\n",
      "Epoch 1090/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.8135e-04 - val_loss: 0.0019\n",
      "Epoch 1091/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.8570e-04 - val_loss: 0.0021\n",
      "Epoch 1092/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.8471e-04 - val_loss: 0.0022\n",
      "Epoch 1093/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.8272e-04 - val_loss: 0.0023\n",
      "Epoch 1094/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.7761e-04 - val_loss: 0.0018\n",
      "Epoch 1095/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 3.7938e-04 - val_loss: 0.0024\n",
      "Epoch 1096/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.7839e-04 - val_loss: 0.0024\n",
      "Epoch 1097/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.8343e-04 - val_loss: 0.0021\n",
      "Epoch 1098/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 3.7863e-04 - val_loss: 0.0024\n",
      "Epoch 1099/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 3.8151e-04 - val_loss: 0.0020\n",
      "Epoch 1100/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.8727e-04 - val_loss: 0.0026\n",
      "Epoch 1101/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.8647e-04 - val_loss: 0.0017\n",
      "Epoch 1102/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 3.9115e-04 - val_loss: 0.0026\n",
      "Epoch 1103/2000\n",
      "3977/3977 [==============================] - 1s 269us/step - loss: 3.8858e-04 - val_loss: 0.0020\n",
      "Epoch 1104/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.7717e-04 - val_loss: 0.0019\n",
      "Epoch 1105/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.9022e-04 - val_loss: 0.0028\n",
      "Epoch 1106/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.8776e-04 - val_loss: 0.0017\n",
      "Epoch 1107/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.8757e-04 - val_loss: 0.0024\n",
      "Epoch 1108/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.7646e-04 - val_loss: 0.0021\n",
      "Epoch 1109/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.8033e-04 - val_loss: 0.0025\n",
      "Epoch 1110/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.7528e-04 - val_loss: 0.0017\n",
      "Epoch 1111/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.8622e-04 - val_loss: 0.0033\n",
      "Epoch 1112/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.9802e-04 - val_loss: 0.0023\n",
      "Epoch 1113/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 3.7293e-04 - val_loss: 0.0024\n",
      "Epoch 1114/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.8111e-04 - val_loss: 0.0024\n",
      "Epoch 1115/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.8362e-04 - val_loss: 0.0018\n",
      "Epoch 1116/2000\n",
      "3977/3977 [==============================] - 1s 270us/step - loss: 3.9266e-04 - val_loss: 0.0028\n",
      "Epoch 1117/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.9919e-04 - val_loss: 0.0018\n",
      "Epoch 1118/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 3.8551e-04 - val_loss: 0.0028\n",
      "Epoch 1119/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.8828e-04 - val_loss: 0.0017\n",
      "Epoch 1120/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.8420e-04 - val_loss: 0.0025\n",
      "Epoch 1121/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.7982e-04 - val_loss: 0.0016\n",
      "Epoch 1122/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.9393e-04 - val_loss: 0.0029\n",
      "Epoch 1123/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.8507e-04 - val_loss: 0.0020\n",
      "Epoch 1124/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 3.8329e-04 - val_loss: 0.0022\n",
      "Epoch 1125/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.9248e-04 - val_loss: 0.0029\n",
      "Epoch 1126/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.8193e-04 - val_loss: 0.0018\n",
      "Epoch 1127/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.7765e-04 - val_loss: 0.0027\n",
      "Epoch 1128/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.7650e-04 - val_loss: 0.0020\n",
      "Epoch 1129/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.7810e-04 - val_loss: 0.0025\n",
      "Epoch 1130/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.8146e-04 - val_loss: 0.0022\n",
      "Epoch 1131/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.7787e-04 - val_loss: 0.0024\n",
      "Epoch 1132/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.7729e-04 - val_loss: 0.0021\n",
      "Epoch 1133/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.8149e-04 - val_loss: 0.0026\n",
      "Epoch 1134/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.7105e-04 - val_loss: 0.0021\n",
      "Epoch 1135/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.7713e-04 - val_loss: 0.0027\n",
      "Epoch 1136/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.8005e-04 - val_loss: 0.0025\n",
      "Epoch 1137/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 4.0813e-04 - val_loss: 0.0022\n",
      "Epoch 1138/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.8918e-04 - val_loss: 0.0017\n",
      "Epoch 1139/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.8129e-04 - val_loss: 0.0033\n",
      "Epoch 1140/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.0845e-04 - val_loss: 0.0023\n",
      "Epoch 1141/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.7780e-04 - val_loss: 0.0020\n",
      "Epoch 1142/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.7795e-04 - val_loss: 0.0022\n",
      "Epoch 1143/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.7861e-04 - val_loss: 0.0023\n",
      "Epoch 1144/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 3.7799e-04 - val_loss: 0.0025\n",
      "Epoch 1145/2000\n",
      "3977/3977 [==============================] - 1s 268us/step - loss: 3.8797e-04 - val_loss: 0.0020\n",
      "Epoch 1146/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.9468e-04 - val_loss: 0.0024\n",
      "Epoch 1147/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.9607e-04 - val_loss: 0.0017\n",
      "Epoch 1148/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 3.8732e-04 - val_loss: 0.0030\n",
      "Epoch 1149/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 3.8478e-04 - val_loss: 0.0018\n",
      "Epoch 1150/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.8194e-04 - val_loss: 0.0026\n",
      "Epoch 1151/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.8289e-04 - val_loss: 0.0021\n",
      "Epoch 1152/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.8158e-04 - val_loss: 0.0026\n",
      "Epoch 1153/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 3.7556e-04 - val_loss: 0.0020\n",
      "Epoch 1154/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 3.8003e-04 - val_loss: 0.0026\n",
      "Epoch 1155/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.7371e-04 - val_loss: 0.0021\n",
      "Epoch 1156/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.7927e-04 - val_loss: 0.0027\n",
      "Epoch 1157/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.9940e-04 - val_loss: 0.0015\n",
      "Epoch 1158/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.9205e-04 - val_loss: 0.0034\n",
      "Epoch 1159/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.0964e-04 - val_loss: 0.0017\n",
      "Epoch 1160/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.9255e-04 - val_loss: 0.0027\n",
      "Epoch 1161/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.8449e-04 - val_loss: 0.0019\n",
      "Epoch 1162/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.7616e-04 - val_loss: 0.0031\n",
      "Epoch 1163/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 3.9615e-04 - val_loss: 0.0019\n",
      "Epoch 1164/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 3.7436e-04 - val_loss: 0.0027\n",
      "Epoch 1165/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.8218e-04 - val_loss: 0.0022\n",
      "Epoch 1166/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.7907e-04 - val_loss: 0.0026\n",
      "Epoch 1167/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.8982e-04 - val_loss: 0.0023\n",
      "Epoch 1168/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.7770e-04 - val_loss: 0.0028\n",
      "Epoch 1169/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.8229e-04 - val_loss: 0.0018\n",
      "Epoch 1170/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.8306e-04 - val_loss: 0.0026\n",
      "Epoch 1171/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.8510e-04 - val_loss: 0.0019\n",
      "Epoch 1172/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.7752e-04 - val_loss: 0.0031\n",
      "Epoch 1173/2000\n",
      "3977/3977 [==============================] - 1s 268us/step - loss: 3.8369e-04 - val_loss: 0.0019\n",
      "Epoch 1174/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.8243e-04 - val_loss: 0.0027\n",
      "Epoch 1175/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.7935e-04 - val_loss: 0.0020\n",
      "Epoch 1176/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.7963e-04 - val_loss: 0.0024\n",
      "Epoch 1177/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.9178e-04 - val_loss: 0.0018\n",
      "Epoch 1178/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.9532e-04 - val_loss: 0.0028\n",
      "Epoch 1179/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 3.8953e-04 - val_loss: 0.0017\n",
      "Epoch 1180/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.8697e-04 - val_loss: 0.0031\n",
      "Epoch 1181/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 4.0626e-04 - val_loss: 0.0014\n",
      "Epoch 1182/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.9388e-04 - val_loss: 0.0026\n",
      "Epoch 1183/2000\n",
      "3977/3977 [==============================] - 1s 261us/step - loss: 3.8028e-04 - val_loss: 0.0019\n",
      "Epoch 1184/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 3.9091e-04 - val_loss: 0.0029\n",
      "Epoch 1185/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.7914e-04 - val_loss: 0.0022\n",
      "Epoch 1186/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 3.6682e-04 - val_loss: 0.0022\n",
      "Epoch 1187/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.7369e-04 - val_loss: 0.0022\n",
      "Epoch 1188/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.7461e-04 - val_loss: 0.0028\n",
      "Epoch 1189/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.7459e-04 - val_loss: 0.0023\n",
      "Epoch 1190/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.7425e-04 - val_loss: 0.0021\n",
      "Epoch 1191/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.7294e-04 - val_loss: 0.0024\n",
      "Epoch 1192/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 3.7131e-04 - val_loss: 0.0022\n",
      "Epoch 1193/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.8386e-04 - val_loss: 0.0023\n",
      "Epoch 1194/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 3.7302e-04 - val_loss: 0.0025\n",
      "Epoch 1195/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.7572e-04 - val_loss: 0.0020\n",
      "Epoch 1196/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.8412e-04 - val_loss: 0.0025\n",
      "Epoch 1197/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.6849e-04 - val_loss: 0.0023\n",
      "Epoch 1198/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.7203e-04 - val_loss: 0.0021\n",
      "Epoch 1199/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 3.7527e-04 - val_loss: 0.0025\n",
      "Epoch 1200/2000\n",
      "3977/3977 [==============================] - 1s 277us/step - loss: 3.7123e-04 - val_loss: 0.0016\n",
      "Epoch 1201/2000\n",
      "3977/3977 [==============================] - 1s 269us/step - loss: 4.3110e-04 - val_loss: 0.0031\n",
      "Epoch 1202/2000\n",
      "3977/3977 [==============================] - 1s 260us/step - loss: 3.9130e-04 - val_loss: 0.0020\n",
      "Epoch 1203/2000\n",
      "3977/3977 [==============================] - 1s 257us/step - loss: 3.7685e-04 - val_loss: 0.0026\n",
      "Epoch 1204/2000\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 3.9084e-04 - val_loss: 0.0022\n",
      "Epoch 1205/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 4.1360e-04 - val_loss: 0.0022\n",
      "Epoch 1206/2000\n",
      "3977/3977 [==============================] - 1s 260us/step - loss: 3.8100e-04 - val_loss: 0.0027\n",
      "Epoch 1207/2000\n",
      "3977/3977 [==============================] - 1s 258us/step - loss: 3.7705e-04 - val_loss: 0.0023\n",
      "Epoch 1208/2000\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 3.7271e-04 - val_loss: 0.0021\n",
      "Epoch 1209/2000\n",
      "3977/3977 [==============================] - 1s 261us/step - loss: 3.7269e-04 - val_loss: 0.0027\n",
      "Epoch 1210/2000\n",
      "3977/3977 [==============================] - 1s 260us/step - loss: 3.7200e-04 - val_loss: 0.0022\n",
      "Epoch 1211/2000\n",
      "3977/3977 [==============================] - 1s 261us/step - loss: 3.6728e-04 - val_loss: 0.0021\n",
      "Epoch 1212/2000\n",
      "3977/3977 [==============================] - 1s 260us/step - loss: 3.7272e-04 - val_loss: 0.0027\n",
      "Epoch 1213/2000\n",
      "3977/3977 [==============================] - 1s 261us/step - loss: 3.8265e-04 - val_loss: 0.0021\n",
      "Epoch 1214/2000\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 3.7774e-04 - val_loss: 0.0022\n",
      "Epoch 1215/2000\n",
      "3977/3977 [==============================] - 1s 260us/step - loss: 3.7750e-04 - val_loss: 0.0023\n",
      "Epoch 1216/2000\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 3.7569e-04 - val_loss: 0.0022\n",
      "Epoch 1217/2000\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 3.7451e-04 - val_loss: 0.0023\n",
      "Epoch 1218/2000\n",
      "3977/3977 [==============================] - 1s 260us/step - loss: 3.6996e-04 - val_loss: 0.0022\n",
      "Epoch 1219/2000\n",
      "3977/3977 [==============================] - 1s 261us/step - loss: 3.7212e-04 - val_loss: 0.0022\n",
      "Epoch 1220/2000\n",
      "3977/3977 [==============================] - 1s 261us/step - loss: 3.7013e-04 - val_loss: 0.0023\n",
      "Epoch 1221/2000\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 3.8252e-04 - val_loss: 0.0026\n",
      "Epoch 1222/2000\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 3.8230e-04 - val_loss: 0.0022\n",
      "Epoch 1223/2000\n",
      "3977/3977 [==============================] - 1s 260us/step - loss: 3.7915e-04 - val_loss: 0.0026\n",
      "Epoch 1224/2000\n",
      "3977/3977 [==============================] - 1s 260us/step - loss: 3.6952e-04 - val_loss: 0.0023\n",
      "Epoch 1225/2000\n",
      "3977/3977 [==============================] - 1s 261us/step - loss: 3.8044e-04 - val_loss: 0.0027\n",
      "Epoch 1226/2000\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 3.8006e-04 - val_loss: 0.0021\n",
      "Epoch 1227/2000\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 3.7991e-04 - val_loss: 0.0022\n",
      "Epoch 1228/2000\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 3.8628e-04 - val_loss: 0.0024\n",
      "Epoch 1229/2000\n",
      "3977/3977 [==============================] - 1s 260us/step - loss: 3.6573e-04 - val_loss: 0.0026\n",
      "Epoch 1230/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.7838e-04 - val_loss: 0.0020\n",
      "Epoch 1231/2000\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 3.6871e-04 - val_loss: 0.0025\n",
      "Epoch 1232/2000\n",
      "3977/3977 [==============================] - 1s 260us/step - loss: 3.6777e-04 - val_loss: 0.0019\n",
      "Epoch 1233/2000\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 3.6769e-04 - val_loss: 0.0025\n",
      "Epoch 1234/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 1s 259us/step - loss: 3.7008e-04 - val_loss: 0.0021\n",
      "Epoch 1235/2000\n",
      "3977/3977 [==============================] - 1s 261us/step - loss: 3.7854e-04 - val_loss: 0.0027\n",
      "Epoch 1236/2000\n",
      "3977/3977 [==============================] - 1s 261us/step - loss: 3.7302e-04 - val_loss: 0.0016\n",
      "Epoch 1237/2000\n",
      "3977/3977 [==============================] - 1s 261us/step - loss: 4.1836e-04 - val_loss: 0.0036\n",
      "Epoch 1238/2000\n",
      "3977/3977 [==============================] - 1s 260us/step - loss: 4.1256e-04 - val_loss: 0.0020\n",
      "Epoch 1239/2000\n",
      "3977/3977 [==============================] - 1s 260us/step - loss: 3.8263e-04 - val_loss: 0.0023\n",
      "Epoch 1240/2000\n",
      "3977/3977 [==============================] - 1s 260us/step - loss: 3.7529e-04 - val_loss: 0.0024\n",
      "Epoch 1241/2000\n",
      "3977/3977 [==============================] - 1s 258us/step - loss: 3.6860e-04 - val_loss: 0.0027\n",
      "Epoch 1242/2000\n",
      "3977/3977 [==============================] - 1s 258us/step - loss: 3.6875e-04 - val_loss: 0.0023\n",
      "Epoch 1243/2000\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 3.6640e-04 - val_loss: 0.0022\n",
      "Epoch 1244/2000\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 3.8116e-04 - val_loss: 0.0022\n",
      "Epoch 1245/2000\n",
      "3977/3977 [==============================] - 1s 260us/step - loss: 3.6976e-04 - val_loss: 0.0025\n",
      "Epoch 1246/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 3.6926e-04 - val_loss: 0.0018\n",
      "Epoch 1247/2000\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 3.7773e-04 - val_loss: 0.0026\n",
      "Epoch 1248/2000\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 3.7612e-04 - val_loss: 0.0021\n",
      "Epoch 1249/2000\n",
      "3977/3977 [==============================] - 1s 260us/step - loss: 3.7008e-04 - val_loss: 0.0025\n",
      "Epoch 1250/2000\n",
      "3977/3977 [==============================] - 1s 258us/step - loss: 3.6925e-04 - val_loss: 0.0028\n",
      "Epoch 1251/2000\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 3.7357e-04 - val_loss: 0.0020\n",
      "Epoch 1252/2000\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 3.8300e-04 - val_loss: 0.0026\n",
      "Epoch 1253/2000\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 3.8381e-04 - val_loss: 0.0017\n",
      "Epoch 1254/2000\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 3.6982e-04 - val_loss: 0.0025\n",
      "Epoch 1255/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.7169e-04 - val_loss: 0.0022\n",
      "Epoch 1256/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.7571e-04 - val_loss: 0.0027\n",
      "Epoch 1257/2000\n",
      "3977/3977 [==============================] - 1s 261us/step - loss: 3.6799e-04 - val_loss: 0.0022\n",
      "Epoch 1258/2000\n",
      "3977/3977 [==============================] - 1s 258us/step - loss: 3.7828e-04 - val_loss: 0.0025\n",
      "Epoch 1259/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 3.8228e-04 - val_loss: 0.0022\n",
      "Epoch 1260/2000\n",
      "3977/3977 [==============================] - 1s 258us/step - loss: 3.7487e-04 - val_loss: 0.0023\n",
      "Epoch 1261/2000\n",
      "3977/3977 [==============================] - 1s 260us/step - loss: 3.6888e-04 - val_loss: 0.0025\n",
      "Epoch 1262/2000\n",
      "3977/3977 [==============================] - 1s 260us/step - loss: 3.7165e-04 - val_loss: 0.0025\n",
      "Epoch 1263/2000\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 3.7108e-04 - val_loss: 0.0023\n",
      "Epoch 1264/2000\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 3.7658e-04 - val_loss: 0.0024\n",
      "Epoch 1265/2000\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 3.6747e-04 - val_loss: 0.0024\n",
      "Epoch 1266/2000\n",
      "3977/3977 [==============================] - 1s 261us/step - loss: 3.7107e-04 - val_loss: 0.0024\n",
      "Epoch 1267/2000\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 3.8049e-04 - val_loss: 0.0025\n",
      "Epoch 1268/2000\n",
      "3977/3977 [==============================] - 1s 260us/step - loss: 3.8150e-04 - val_loss: 0.0024\n",
      "Epoch 1269/2000\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 3.7551e-04 - val_loss: 0.0020\n",
      "Epoch 1270/2000\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 3.6810e-04 - val_loss: 0.0021\n",
      "Epoch 1271/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.7074e-04 - val_loss: 0.0024\n",
      "Epoch 1272/2000\n",
      "3977/3977 [==============================] - 1s 260us/step - loss: 3.7162e-04 - val_loss: 0.0025\n",
      "Epoch 1273/2000\n",
      "3977/3977 [==============================] - 1s 261us/step - loss: 3.7141e-04 - val_loss: 0.0020\n",
      "Epoch 1274/2000\n",
      "3977/3977 [==============================] - 1s 260us/step - loss: 3.7022e-04 - val_loss: 0.0028\n",
      "Epoch 1275/2000\n",
      "3977/3977 [==============================] - 1s 260us/step - loss: 3.9003e-04 - val_loss: 0.0017\n",
      "Epoch 1276/2000\n",
      "3977/3977 [==============================] - 1s 258us/step - loss: 3.7425e-04 - val_loss: 0.0025\n",
      "Epoch 1277/2000\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 3.7063e-04 - val_loss: 0.0022\n",
      "Epoch 1278/2000\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 3.6581e-04 - val_loss: 0.0028\n",
      "Epoch 1279/2000\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 3.7829e-04 - val_loss: 0.0019\n",
      "Epoch 1280/2000\n",
      "3977/3977 [==============================] - 1s 260us/step - loss: 3.7220e-04 - val_loss: 0.0029\n",
      "Epoch 1281/2000\n",
      "3977/3977 [==============================] - 1s 260us/step - loss: 3.8117e-04 - val_loss: 0.0028\n",
      "Epoch 1282/2000\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 3.8161e-04 - val_loss: 0.0021\n",
      "Epoch 1283/2000\n",
      "3977/3977 [==============================] - 1s 258us/step - loss: 3.7548e-04 - val_loss: 0.0029\n",
      "Epoch 1284/2000\n",
      "3977/3977 [==============================] - 1s 261us/step - loss: 3.7905e-04 - val_loss: 0.0018\n",
      "Epoch 1285/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 3.8590e-04 - val_loss: 0.0028\n",
      "Epoch 1286/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 3.7588e-04 - val_loss: 0.0019\n",
      "Epoch 1287/2000\n",
      "3977/3977 [==============================] - 1s 260us/step - loss: 3.6511e-04 - val_loss: 0.0027\n",
      "Epoch 1288/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 3.7824e-04 - val_loss: 0.0023\n",
      "Epoch 1289/2000\n",
      "3977/3977 [==============================] - 1s 260us/step - loss: 3.6659e-04 - val_loss: 0.0026\n",
      "Epoch 1290/2000\n",
      "3977/3977 [==============================] - 1s 260us/step - loss: 3.6376e-04 - val_loss: 0.0024\n",
      "Epoch 1291/2000\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 3.7689e-04 - val_loss: 0.0025\n",
      "Epoch 1292/2000\n",
      "3977/3977 [==============================] - 1s 260us/step - loss: 3.6979e-04 - val_loss: 0.0022\n",
      "Epoch 1293/2000\n",
      "3977/3977 [==============================] - 1s 261us/step - loss: 3.7294e-04 - val_loss: 0.0022\n",
      "Epoch 1294/2000\n",
      "3977/3977 [==============================] - 1s 261us/step - loss: 3.8302e-04 - val_loss: 0.0027\n",
      "Epoch 1295/2000\n",
      "3977/3977 [==============================] - 1s 260us/step - loss: 3.9681e-04 - val_loss: 0.0022\n",
      "Epoch 1296/2000\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 3.7678e-04 - val_loss: 0.0024\n",
      "Epoch 1297/2000\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 3.7612e-04 - val_loss: 0.0021\n",
      "Epoch 1298/2000\n",
      "3977/3977 [==============================] - 1s 260us/step - loss: 3.6575e-04 - val_loss: 0.0025\n",
      "Epoch 1299/2000\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 3.5897e-04 - val_loss: 0.0028\n",
      "Epoch 1300/2000\n",
      "3977/3977 [==============================] - 1s 260us/step - loss: 3.7706e-04 - val_loss: 0.0015\n",
      "Epoch 1301/2000\n",
      "3977/3977 [==============================] - 1s 260us/step - loss: 4.0403e-04 - val_loss: 0.0032\n",
      "Epoch 1302/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.8411e-04 - val_loss: 0.0018\n",
      "Epoch 1303/2000\n",
      "3977/3977 [==============================] - 1s 258us/step - loss: 3.7619e-04 - val_loss: 0.0028\n",
      "Epoch 1304/2000\n",
      "3977/3977 [==============================] - 1s 260us/step - loss: 3.6173e-04 - val_loss: 0.0019\n",
      "Epoch 1305/2000\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 3.7075e-04 - val_loss: 0.0027\n",
      "Epoch 1306/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 1s 259us/step - loss: 3.6312e-04 - val_loss: 0.0026\n",
      "Epoch 1307/2000\n",
      "3977/3977 [==============================] - 1s 258us/step - loss: 3.7554e-04 - val_loss: 0.0019\n",
      "Epoch 1308/2000\n",
      "3977/3977 [==============================] - 1s 261us/step - loss: 3.7509e-04 - val_loss: 0.0030\n",
      "Epoch 1309/2000\n",
      "3977/3977 [==============================] - 1s 258us/step - loss: 3.7208e-04 - val_loss: 0.0021\n",
      "Epoch 1310/2000\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 3.6598e-04 - val_loss: 0.0028\n",
      "Epoch 1311/2000\n",
      "3977/3977 [==============================] - 1s 260us/step - loss: 3.7256e-04 - val_loss: 0.0020\n",
      "Epoch 1312/2000\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 3.6599e-04 - val_loss: 0.0024\n",
      "Epoch 1313/2000\n",
      "3977/3977 [==============================] - 1s 260us/step - loss: 3.5981e-04 - val_loss: 0.0024\n",
      "Epoch 1314/2000\n",
      "3977/3977 [==============================] - 1s 258us/step - loss: 3.6714e-04 - val_loss: 0.0025\n",
      "Epoch 1315/2000\n",
      "3977/3977 [==============================] - 1s 260us/step - loss: 3.6602e-04 - val_loss: 0.0024\n",
      "Epoch 1316/2000\n",
      "3977/3977 [==============================] - 1s 260us/step - loss: 3.5910e-04 - val_loss: 0.0021\n",
      "Epoch 1317/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 3.6110e-04 - val_loss: 0.0022\n",
      "Epoch 1318/2000\n",
      "3977/3977 [==============================] - 1s 260us/step - loss: 3.6583e-04 - val_loss: 0.0025\n",
      "Epoch 1319/2000\n",
      "3977/3977 [==============================] - 1s 260us/step - loss: 3.6695e-04 - val_loss: 0.0024\n",
      "Epoch 1320/2000\n",
      "3977/3977 [==============================] - 1s 258us/step - loss: 3.8087e-04 - val_loss: 0.0022\n",
      "Epoch 1321/2000\n",
      "3977/3977 [==============================] - 1s 261us/step - loss: 3.7440e-04 - val_loss: 0.0026\n",
      "Epoch 1322/2000\n",
      "3977/3977 [==============================] - 1s 261us/step - loss: 3.5978e-04 - val_loss: 0.0023\n",
      "Epoch 1323/2000\n",
      "3977/3977 [==============================] - 1s 260us/step - loss: 3.5297e-04 - val_loss: 0.0021\n",
      "Epoch 1324/2000\n",
      "3977/3977 [==============================] - 1s 260us/step - loss: 3.6429e-04 - val_loss: 0.0025\n",
      "Epoch 1325/2000\n",
      "3977/3977 [==============================] - 1s 258us/step - loss: 3.7284e-04 - val_loss: 0.0026\n",
      "Epoch 1326/2000\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 3.7267e-04 - val_loss: 0.0026\n",
      "Epoch 1327/2000\n",
      "3977/3977 [==============================] - 1s 261us/step - loss: 3.6859e-04 - val_loss: 0.0020\n",
      "Epoch 1328/2000\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 3.6893e-04 - val_loss: 0.0024\n",
      "Epoch 1329/2000\n",
      "3977/3977 [==============================] - 1s 258us/step - loss: 3.5959e-04 - val_loss: 0.0024\n",
      "Epoch 1330/2000\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 3.7079e-04 - val_loss: 0.0027\n",
      "Epoch 1331/2000\n",
      "3977/3977 [==============================] - 1s 260us/step - loss: 3.5951e-04 - val_loss: 0.0024\n",
      "Epoch 1332/2000\n",
      "3977/3977 [==============================] - 1s 261us/step - loss: 3.6174e-04 - val_loss: 0.0025\n",
      "Epoch 1333/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 3.5903e-04 - val_loss: 0.0026\n",
      "Epoch 1334/2000\n",
      "3977/3977 [==============================] - 1s 258us/step - loss: 3.5641e-04 - val_loss: 0.0024\n",
      "Epoch 1335/2000\n",
      "3977/3977 [==============================] - 1s 260us/step - loss: 3.6960e-04 - val_loss: 0.0026\n",
      "Epoch 1336/2000\n",
      "3977/3977 [==============================] - 1s 258us/step - loss: 3.6333e-04 - val_loss: 0.0024\n",
      "Epoch 1337/2000\n",
      "3977/3977 [==============================] - 1s 258us/step - loss: 3.6553e-04 - val_loss: 0.0025\n",
      "Epoch 1338/2000\n",
      "3977/3977 [==============================] - 1s 260us/step - loss: 3.6528e-04 - val_loss: 0.0024\n",
      "Epoch 1339/2000\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 3.6749e-04 - val_loss: 0.0023\n",
      "Epoch 1340/2000\n",
      "3977/3977 [==============================] - 1s 261us/step - loss: 3.5301e-04 - val_loss: 0.0030\n",
      "Epoch 1341/2000\n",
      "3977/3977 [==============================] - 1s 261us/step - loss: 3.6319e-04 - val_loss: 0.0020\n",
      "Epoch 1342/2000\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 3.6955e-04 - val_loss: 0.0032\n",
      "Epoch 1343/2000\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 3.7496e-04 - val_loss: 0.0016\n",
      "Epoch 1344/2000\n",
      "3977/3977 [==============================] - 1s 260us/step - loss: 3.6452e-04 - val_loss: 0.0027\n",
      "Epoch 1345/2000\n",
      "3977/3977 [==============================] - 1s 258us/step - loss: 3.6810e-04 - val_loss: 0.0021\n",
      "Epoch 1346/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.5931e-04 - val_loss: 0.0024\n",
      "Epoch 1347/2000\n",
      "3977/3977 [==============================] - 1s 260us/step - loss: 3.6821e-04 - val_loss: 0.0024\n",
      "Epoch 1348/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.5619e-04 - val_loss: 0.0026\n",
      "Epoch 1349/2000\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 3.5787e-04 - val_loss: 0.0022\n",
      "Epoch 1350/2000\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 3.5862e-04 - val_loss: 0.0028\n",
      "Epoch 1351/2000\n",
      "3977/3977 [==============================] - 1s 261us/step - loss: 3.6025e-04 - val_loss: 0.0023\n",
      "Epoch 1352/2000\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 3.5673e-04 - val_loss: 0.0025\n",
      "Epoch 1353/2000\n",
      "3977/3977 [==============================] - 1s 260us/step - loss: 3.5726e-04 - val_loss: 0.0022\n",
      "Epoch 1354/2000\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 3.5881e-04 - val_loss: 0.0026\n",
      "Epoch 1355/2000\n",
      "3977/3977 [==============================] - 1s 258us/step - loss: 3.5773e-04 - val_loss: 0.0025\n",
      "Epoch 1356/2000\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 3.5853e-04 - val_loss: 0.0025\n",
      "Epoch 1357/2000\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 3.5704e-04 - val_loss: 0.0025\n",
      "Epoch 1358/2000\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 3.5430e-04 - val_loss: 0.0022\n",
      "Epoch 1359/2000\n",
      "3977/3977 [==============================] - 1s 261us/step - loss: 3.5423e-04 - val_loss: 0.0020\n",
      "Epoch 1360/2000\n",
      "3977/3977 [==============================] - 1s 261us/step - loss: 3.6053e-04 - val_loss: 0.0031\n",
      "Epoch 1361/2000\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 3.6271e-04 - val_loss: 0.0019\n",
      "Epoch 1362/2000\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 3.6740e-04 - val_loss: 0.0025\n",
      "Epoch 1363/2000\n",
      "3977/3977 [==============================] - 1s 260us/step - loss: 3.6224e-04 - val_loss: 0.0020\n",
      "Epoch 1364/2000\n",
      "3977/3977 [==============================] - 1s 261us/step - loss: 3.5654e-04 - val_loss: 0.0028\n",
      "Epoch 1365/2000\n",
      "3977/3977 [==============================] - 1s 260us/step - loss: 3.6654e-04 - val_loss: 0.0020\n",
      "Epoch 1366/2000\n",
      "3977/3977 [==============================] - 1s 260us/step - loss: 3.7323e-04 - val_loss: 0.0027\n",
      "Epoch 1367/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 3.7230e-04 - val_loss: 0.0022\n",
      "Epoch 1368/2000\n",
      "3977/3977 [==============================] - 1s 260us/step - loss: 3.6643e-04 - val_loss: 0.0024\n",
      "Epoch 1369/2000\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 3.6667e-04 - val_loss: 0.0021\n",
      "Epoch 1370/2000\n",
      "3977/3977 [==============================] - 1s 260us/step - loss: 3.6500e-04 - val_loss: 0.0025\n",
      "Epoch 1371/2000\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 3.5548e-04 - val_loss: 0.0026\n",
      "Epoch 1372/2000\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 3.5935e-04 - val_loss: 0.0020\n",
      "Epoch 1373/2000\n",
      "3977/3977 [==============================] - 1s 260us/step - loss: 3.6745e-04 - val_loss: 0.0031\n",
      "Epoch 1374/2000\n",
      "3977/3977 [==============================] - 1s 258us/step - loss: 3.7344e-04 - val_loss: 0.0023\n",
      "Epoch 1375/2000\n",
      "3977/3977 [==============================] - 1s 268us/step - loss: 3.5700e-04 - val_loss: 0.0023\n",
      "Epoch 1376/2000\n",
      "3977/3977 [==============================] - 1s 261us/step - loss: 3.5870e-04 - val_loss: 0.0028\n",
      "Epoch 1377/2000\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 3.6292e-04 - val_loss: 0.0023\n",
      "Epoch 1378/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 1s 260us/step - loss: 3.6500e-04 - val_loss: 0.0026\n",
      "Epoch 1379/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.6189e-04 - val_loss: 0.0025\n",
      "Epoch 1380/2000\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 3.4888e-04 - val_loss: 0.0022\n",
      "Epoch 1381/2000\n",
      "3977/3977 [==============================] - 1s 260us/step - loss: 3.5524e-04 - val_loss: 0.0026\n",
      "Epoch 1382/2000\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 3.5543e-04 - val_loss: 0.0020\n",
      "Epoch 1383/2000\n",
      "3977/3977 [==============================] - 1s 258us/step - loss: 3.7004e-04 - val_loss: 0.0028\n",
      "Epoch 1384/2000\n",
      "3977/3977 [==============================] - 1s 258us/step - loss: 3.7557e-04 - val_loss: 0.0021\n",
      "Epoch 1385/2000\n",
      "3977/3977 [==============================] - 1s 260us/step - loss: 3.8358e-04 - val_loss: 0.0018\n",
      "Epoch 1386/2000\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 3.8537e-04 - val_loss: 0.0024\n",
      "Epoch 1387/2000\n",
      "3977/3977 [==============================] - 1s 260us/step - loss: 3.7270e-04 - val_loss: 0.0026\n",
      "Epoch 1388/2000\n",
      "3977/3977 [==============================] - 1s 260us/step - loss: 3.8056e-04 - val_loss: 0.0018\n",
      "Epoch 1389/2000\n",
      "3977/3977 [==============================] - 1s 260us/step - loss: 3.6315e-04 - val_loss: 0.0027\n",
      "Epoch 1390/2000\n",
      "3977/3977 [==============================] - 1s 260us/step - loss: 3.6050e-04 - val_loss: 0.0021\n",
      "Epoch 1391/2000\n",
      "3977/3977 [==============================] - 1s 261us/step - loss: 3.4888e-04 - val_loss: 0.0025\n",
      "Epoch 1392/2000\n",
      "3977/3977 [==============================] - 1s 260us/step - loss: 3.5567e-04 - val_loss: 0.0026\n",
      "Epoch 1393/2000\n",
      "3977/3977 [==============================] - 1s 259us/step - loss: 3.5809e-04 - val_loss: 0.0022\n",
      "Epoch 1394/2000\n",
      "3977/3977 [==============================] - 1s 348us/step - loss: 3.5610e-04 - val_loss: 0.0024\n",
      "Epoch 1395/2000\n",
      "3977/3977 [==============================] - 1s 271us/step - loss: 3.5040e-04 - val_loss: 0.0025\n",
      "Epoch 1396/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.5221e-04 - val_loss: 0.0022\n",
      "Epoch 1397/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.5236e-04 - val_loss: 0.0027\n",
      "Epoch 1398/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.5604e-04 - val_loss: 0.0024\n",
      "Epoch 1399/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 3.4758e-04 - val_loss: 0.0026\n",
      "Epoch 1400/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 3.4328e-04 - val_loss: 0.0025\n",
      "Epoch 1401/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.5749e-04 - val_loss: 0.0023\n",
      "Epoch 1402/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.5408e-04 - val_loss: 0.0023\n",
      "Epoch 1403/2000\n",
      "3977/3977 [==============================] - 1s 269us/step - loss: 3.4959e-04 - val_loss: 0.0026\n",
      "Epoch 1404/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.4953e-04 - val_loss: 0.0023\n",
      "Epoch 1405/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.5436e-04 - val_loss: 0.0027\n",
      "Epoch 1406/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.5394e-04 - val_loss: 0.0027\n",
      "Epoch 1407/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.5371e-04 - val_loss: 0.0021\n",
      "Epoch 1408/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.5892e-04 - val_loss: 0.0027\n",
      "Epoch 1409/2000\n",
      "3977/3977 [==============================] - 1s 268us/step - loss: 3.5826e-04 - val_loss: 0.0021\n",
      "Epoch 1410/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.5618e-04 - val_loss: 0.0025\n",
      "Epoch 1411/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.4809e-04 - val_loss: 0.0026\n",
      "Epoch 1412/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.4708e-04 - val_loss: 0.0018\n",
      "Epoch 1413/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.6559e-04 - val_loss: 0.0029\n",
      "Epoch 1414/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.6010e-04 - val_loss: 0.0022\n",
      "Epoch 1415/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 3.5174e-04 - val_loss: 0.0031\n",
      "Epoch 1416/2000\n",
      "3977/3977 [==============================] - 1s 268us/step - loss: 3.5789e-04 - val_loss: 0.0022\n",
      "Epoch 1417/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.5556e-04 - val_loss: 0.0024\n",
      "Epoch 1418/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.5750e-04 - val_loss: 0.0021\n",
      "Epoch 1419/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.4992e-04 - val_loss: 0.0029\n",
      "Epoch 1420/2000\n",
      "3977/3977 [==============================] - 1s 276us/step - loss: 3.5381e-04 - val_loss: 0.0019\n",
      "Epoch 1421/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.5527e-04 - val_loss: 0.0028\n",
      "Epoch 1422/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.5298e-04 - val_loss: 0.0020\n",
      "Epoch 1423/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.6053e-04 - val_loss: 0.0031\n",
      "Epoch 1424/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 3.5170e-04 - val_loss: 0.0022\n",
      "Epoch 1425/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.4400e-04 - val_loss: 0.0027\n",
      "Epoch 1426/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.5255e-04 - val_loss: 0.0030\n",
      "Epoch 1427/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 3.6015e-04 - val_loss: 0.0022\n",
      "Epoch 1428/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 3.4948e-04 - val_loss: 0.0027\n",
      "Epoch 1429/2000\n",
      "3977/3977 [==============================] - 1s 271us/step - loss: 3.5042e-04 - val_loss: 0.0027\n",
      "Epoch 1430/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.5404e-04 - val_loss: 0.0023\n",
      "Epoch 1431/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.4321e-04 - val_loss: 0.0021\n",
      "Epoch 1432/2000\n",
      "3977/3977 [==============================] - 1s 270us/step - loss: 3.4669e-04 - val_loss: 0.0027\n",
      "Epoch 1433/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.5105e-04 - val_loss: 0.0020\n",
      "Epoch 1434/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.4788e-04 - val_loss: 0.0024\n",
      "Epoch 1435/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.4034e-04 - val_loss: 0.0028\n",
      "Epoch 1436/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.4657e-04 - val_loss: 0.0026\n",
      "Epoch 1437/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.4921e-04 - val_loss: 0.0022\n",
      "Epoch 1438/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.3597e-04 - val_loss: 0.0028\n",
      "Epoch 1439/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.4270e-04 - val_loss: 0.0026\n",
      "Epoch 1440/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 3.4199e-04 - val_loss: 0.0024\n",
      "Epoch 1441/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.4324e-04 - val_loss: 0.0023\n",
      "Epoch 1442/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 3.4720e-04 - val_loss: 0.0034\n",
      "Epoch 1443/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.6359e-04 - val_loss: 0.0018\n",
      "Epoch 1444/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.6393e-04 - val_loss: 0.0030\n",
      "Epoch 1445/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.6898e-04 - val_loss: 0.0023\n",
      "Epoch 1446/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.4898e-04 - val_loss: 0.0026\n",
      "Epoch 1447/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.4724e-04 - val_loss: 0.0022\n",
      "Epoch 1448/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.4921e-04 - val_loss: 0.0028\n",
      "Epoch 1449/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.4698e-04 - val_loss: 0.0025\n",
      "Epoch 1450/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.3643e-04 - val_loss: 0.0021\n",
      "Epoch 1451/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.4498e-04 - val_loss: 0.0029\n",
      "Epoch 1452/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.4523e-04 - val_loss: 0.0025\n",
      "Epoch 1453/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.4842e-04 - val_loss: 0.0022\n",
      "Epoch 1454/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 3.4774e-04 - val_loss: 0.0028\n",
      "Epoch 1455/2000\n",
      "3977/3977 [==============================] - 1s 269us/step - loss: 3.5588e-04 - val_loss: 0.0027\n",
      "Epoch 1456/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.6539e-04 - val_loss: 0.0028\n",
      "Epoch 1457/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.6103e-04 - val_loss: 0.0019\n",
      "Epoch 1458/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.6131e-04 - val_loss: 0.0029\n",
      "Epoch 1459/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.4314e-04 - val_loss: 0.0021\n",
      "Epoch 1460/2000\n",
      "3977/3977 [==============================] - 1s 268us/step - loss: 3.3743e-04 - val_loss: 0.0030\n",
      "Epoch 1461/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.4647e-04 - val_loss: 0.0018\n",
      "Epoch 1462/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.4611e-04 - val_loss: 0.0027\n",
      "Epoch 1463/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 3.4169e-04 - val_loss: 0.0023\n",
      "Epoch 1464/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.4081e-04 - val_loss: 0.0024\n",
      "Epoch 1465/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.3624e-04 - val_loss: 0.0023\n",
      "Epoch 1466/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.4213e-04 - val_loss: 0.0025\n",
      "Epoch 1467/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.3421e-04 - val_loss: 0.0027\n",
      "Epoch 1468/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.2879e-04 - val_loss: 0.0020\n",
      "Epoch 1469/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.4522e-04 - val_loss: 0.0031\n",
      "Epoch 1470/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 3.4042e-04 - val_loss: 0.0028\n",
      "Epoch 1471/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.4446e-04 - val_loss: 0.0021\n",
      "Epoch 1472/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.4488e-04 - val_loss: 0.0032\n",
      "Epoch 1473/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.5454e-04 - val_loss: 0.0018\n",
      "Epoch 1474/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.5069e-04 - val_loss: 0.0025\n",
      "Epoch 1475/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 3.4998e-04 - val_loss: 0.0028\n",
      "Epoch 1476/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.4919e-04 - val_loss: 0.0021\n",
      "Epoch 1477/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 3.6050e-04 - val_loss: 0.0027\n",
      "Epoch 1478/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.4719e-04 - val_loss: 0.0025\n",
      "Epoch 1479/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.3573e-04 - val_loss: 0.0024\n",
      "Epoch 1480/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.3241e-04 - val_loss: 0.0027\n",
      "Epoch 1481/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.3455e-04 - val_loss: 0.0029\n",
      "Epoch 1482/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.3669e-04 - val_loss: 0.0021\n",
      "Epoch 1483/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.4752e-04 - val_loss: 0.0035\n",
      "Epoch 1484/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.5575e-04 - val_loss: 0.0019\n",
      "Epoch 1485/2000\n",
      "3977/3977 [==============================] - 1s 269us/step - loss: 3.4937e-04 - val_loss: 0.0032\n",
      "Epoch 1486/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.3642e-04 - val_loss: 0.0017\n",
      "Epoch 1487/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 3.4618e-04 - val_loss: 0.0025\n",
      "Epoch 1488/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 3.3078e-04 - val_loss: 0.0023\n",
      "Epoch 1489/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 3.3291e-04 - val_loss: 0.0025\n",
      "Epoch 1490/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.3051e-04 - val_loss: 0.0024\n",
      "Epoch 1491/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.2706e-04 - val_loss: 0.0023\n",
      "Epoch 1492/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.3777e-04 - val_loss: 0.0030\n",
      "Epoch 1493/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 3.4570e-04 - val_loss: 0.0018\n",
      "Epoch 1494/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.4437e-04 - val_loss: 0.0024\n",
      "Epoch 1495/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.2726e-04 - val_loss: 0.0026\n",
      "Epoch 1496/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 3.3554e-04 - val_loss: 0.0024\n",
      "Epoch 1497/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.3166e-04 - val_loss: 0.0022\n",
      "Epoch 1498/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.2703e-04 - val_loss: 0.0024\n",
      "Epoch 1499/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.3721e-04 - val_loss: 0.0031\n",
      "Epoch 1500/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 3.4334e-04 - val_loss: 0.0021\n",
      "Epoch 1501/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.3073e-04 - val_loss: 0.0030\n",
      "Epoch 1502/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.3090e-04 - val_loss: 0.0026\n",
      "Epoch 1503/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.4256e-04 - val_loss: 0.0019\n",
      "Epoch 1504/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.3135e-04 - val_loss: 0.0028\n",
      "Epoch 1505/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 3.2354e-04 - val_loss: 0.0025\n",
      "Epoch 1506/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.1795e-04 - val_loss: 0.0024\n",
      "Epoch 1507/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.2571e-04 - val_loss: 0.0023\n",
      "Epoch 1508/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.3563e-04 - val_loss: 0.0024\n",
      "Epoch 1509/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.4385e-04 - val_loss: 0.0029\n",
      "Epoch 1510/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.3403e-04 - val_loss: 0.0021\n",
      "Epoch 1511/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.3936e-04 - val_loss: 0.0031\n",
      "Epoch 1512/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.3789e-04 - val_loss: 0.0021\n",
      "Epoch 1513/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.3065e-04 - val_loss: 0.0024\n",
      "Epoch 1514/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.2154e-04 - val_loss: 0.0023\n",
      "Epoch 1515/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 3.2567e-04 - val_loss: 0.0031\n",
      "Epoch 1516/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 3.4726e-04 - val_loss: 0.0020\n",
      "Epoch 1517/2000\n",
      "3977/3977 [==============================] - 1s 269us/step - loss: 3.4375e-04 - val_loss: 0.0024\n",
      "Epoch 1518/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.2616e-04 - val_loss: 0.0028\n",
      "Epoch 1519/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.2427e-04 - val_loss: 0.0024\n",
      "Epoch 1520/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.1669e-04 - val_loss: 0.0028\n",
      "Epoch 1521/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.1872e-04 - val_loss: 0.0022\n",
      "Epoch 1522/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.1396e-04 - val_loss: 0.0024\n",
      "Epoch 1523/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 3.2157e-04 - val_loss: 0.0024\n",
      "Epoch 1524/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.2018e-04 - val_loss: 0.0024\n",
      "Epoch 1525/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.2510e-04 - val_loss: 0.0027\n",
      "Epoch 1526/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.3079e-04 - val_loss: 0.0023\n",
      "Epoch 1527/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.1668e-04 - val_loss: 0.0025\n",
      "Epoch 1528/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.2093e-04 - val_loss: 0.0024\n",
      "Epoch 1529/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.2152e-04 - val_loss: 0.0026\n",
      "Epoch 1530/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.2009e-04 - val_loss: 0.0020\n",
      "Epoch 1531/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 3.2314e-04 - val_loss: 0.0030\n",
      "Epoch 1532/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.2646e-04 - val_loss: 0.0020\n",
      "Epoch 1533/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.2715e-04 - val_loss: 0.0025\n",
      "Epoch 1534/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.1220e-04 - val_loss: 0.0025\n",
      "Epoch 1535/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 3.1334e-04 - val_loss: 0.0022\n",
      "Epoch 1536/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.1953e-04 - val_loss: 0.0028\n",
      "Epoch 1537/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.0739e-04 - val_loss: 0.0026\n",
      "Epoch 1538/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.1482e-04 - val_loss: 0.0025\n",
      "Epoch 1539/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 3.1661e-04 - val_loss: 0.0025\n",
      "Epoch 1540/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.1423e-04 - val_loss: 0.0027\n",
      "Epoch 1541/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.1942e-04 - val_loss: 0.0030\n",
      "Epoch 1542/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.2501e-04 - val_loss: 0.0026\n",
      "Epoch 1543/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.1661e-04 - val_loss: 0.0021\n",
      "Epoch 1544/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.1779e-04 - val_loss: 0.0025\n",
      "Epoch 1545/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 3.2325e-04 - val_loss: 0.0023\n",
      "Epoch 1546/2000\n",
      "3977/3977 [==============================] - 1s 272us/step - loss: 3.1774e-04 - val_loss: 0.0031\n",
      "Epoch 1547/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 3.1213e-04 - val_loss: 0.0022\n",
      "Epoch 1548/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.0931e-04 - val_loss: 0.0025\n",
      "Epoch 1549/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.0582e-04 - val_loss: 0.0024\n",
      "Epoch 1550/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.1751e-04 - val_loss: 0.0024\n",
      "Epoch 1551/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.1521e-04 - val_loss: 0.0023\n",
      "Epoch 1552/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.1366e-04 - val_loss: 0.0031\n",
      "Epoch 1553/2000\n",
      "3977/3977 [==============================] - 1s 261us/step - loss: 3.1519e-04 - val_loss: 0.0021\n",
      "Epoch 1554/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 3.0370e-04 - val_loss: 0.0031\n",
      "Epoch 1555/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.0803e-04 - val_loss: 0.0026\n",
      "Epoch 1556/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.0788e-04 - val_loss: 0.0028\n",
      "Epoch 1557/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.4403e-04 - val_loss: 0.0022\n",
      "Epoch 1558/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.1244e-04 - val_loss: 0.0029\n",
      "Epoch 1559/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.1488e-04 - val_loss: 0.0020\n",
      "Epoch 1560/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.1446e-04 - val_loss: 0.0030\n",
      "Epoch 1561/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 3.0659e-04 - val_loss: 0.0029\n",
      "Epoch 1562/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.1425e-04 - val_loss: 0.0021\n",
      "Epoch 1563/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.1993e-04 - val_loss: 0.0027\n",
      "Epoch 1564/2000\n",
      "3977/3977 [==============================] - 1s 261us/step - loss: 3.1507e-04 - val_loss: 0.0024\n",
      "Epoch 1565/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.0667e-04 - val_loss: 0.0027\n",
      "Epoch 1566/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.0931e-04 - val_loss: 0.0023\n",
      "Epoch 1567/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 3.1149e-04 - val_loss: 0.0025\n",
      "Epoch 1568/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.0985e-04 - val_loss: 0.0024\n",
      "Epoch 1569/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.0941e-04 - val_loss: 0.0020\n",
      "Epoch 1570/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.1154e-04 - val_loss: 0.0031\n",
      "Epoch 1571/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.1208e-04 - val_loss: 0.0024\n",
      "Epoch 1572/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.0890e-04 - val_loss: 0.0022\n",
      "Epoch 1573/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.1265e-04 - val_loss: 0.0035\n",
      "Epoch 1574/2000\n",
      "3977/3977 [==============================] - 1s 269us/step - loss: 3.2623e-04 - val_loss: 0.0021\n",
      "Epoch 1575/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.1186e-04 - val_loss: 0.0026\n",
      "Epoch 1576/2000\n",
      "3977/3977 [==============================] - 1s 268us/step - loss: 3.0959e-04 - val_loss: 0.0030\n",
      "Epoch 1577/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.0423e-04 - val_loss: 0.0021\n",
      "Epoch 1578/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.1775e-04 - val_loss: 0.0025\n",
      "Epoch 1579/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 3.3759e-04 - val_loss: 0.0033\n",
      "Epoch 1580/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.3010e-04 - val_loss: 0.0019\n",
      "Epoch 1581/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.0995e-04 - val_loss: 0.0030\n",
      "Epoch 1582/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.1747e-04 - val_loss: 0.0024\n",
      "Epoch 1583/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.0755e-04 - val_loss: 0.0022\n",
      "Epoch 1584/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.0346e-04 - val_loss: 0.0031\n",
      "Epoch 1585/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 3.1245e-04 - val_loss: 0.0019\n",
      "Epoch 1586/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.1511e-04 - val_loss: 0.0032\n",
      "Epoch 1587/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.0954e-04 - val_loss: 0.0022\n",
      "Epoch 1588/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 3.0346e-04 - val_loss: 0.0030\n",
      "Epoch 1589/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.1506e-04 - val_loss: 0.0021\n",
      "Epoch 1590/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.1526e-04 - val_loss: 0.0030\n",
      "Epoch 1591/2000\n",
      "3977/3977 [==============================] - 1s 269us/step - loss: 3.1533e-04 - val_loss: 0.0020\n",
      "Epoch 1592/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.1981e-04 - val_loss: 0.0029\n",
      "Epoch 1593/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 3.0787e-04 - val_loss: 0.0026\n",
      "Epoch 1594/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.9832e-04 - val_loss: 0.0025\n",
      "Epoch 1595/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.9960e-04 - val_loss: 0.0028\n",
      "Epoch 1596/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.9359e-04 - val_loss: 0.0025\n",
      "Epoch 1597/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.9485e-04 - val_loss: 0.0024\n",
      "Epoch 1598/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.9277e-04 - val_loss: 0.0028\n",
      "Epoch 1599/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.9443e-04 - val_loss: 0.0023\n",
      "Epoch 1600/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.0335e-04 - val_loss: 0.0029\n",
      "Epoch 1601/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.0844e-04 - val_loss: 0.0025\n",
      "Epoch 1602/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 2.9765e-04 - val_loss: 0.0025\n",
      "Epoch 1603/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.0653e-04 - val_loss: 0.0033\n",
      "Epoch 1604/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 3.3384e-04 - val_loss: 0.0022\n",
      "Epoch 1605/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.2408e-04 - val_loss: 0.0022\n",
      "Epoch 1606/2000\n",
      "3977/3977 [==============================] - 1s 268us/step - loss: 3.2013e-04 - val_loss: 0.0027\n",
      "Epoch 1607/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 3.1070e-04 - val_loss: 0.0021\n",
      "Epoch 1608/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.0474e-04 - val_loss: 0.0026\n",
      "Epoch 1609/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.9908e-04 - val_loss: 0.0026\n",
      "Epoch 1610/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.9240e-04 - val_loss: 0.0027\n",
      "Epoch 1611/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.9755e-04 - val_loss: 0.0027\n",
      "Epoch 1612/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.9416e-04 - val_loss: 0.0026\n",
      "Epoch 1613/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.9869e-04 - val_loss: 0.0024\n",
      "Epoch 1614/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.9890e-04 - val_loss: 0.0026\n",
      "Epoch 1615/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.8965e-04 - val_loss: 0.0027\n",
      "Epoch 1616/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.9133e-04 - val_loss: 0.0027\n",
      "Epoch 1617/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.9016e-04 - val_loss: 0.0025\n",
      "Epoch 1618/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.8958e-04 - val_loss: 0.0027\n",
      "Epoch 1619/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.9061e-04 - val_loss: 0.0020\n",
      "Epoch 1620/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.9317e-04 - val_loss: 0.0031\n",
      "Epoch 1621/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.8958e-04 - val_loss: 0.0026\n",
      "Epoch 1622/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 2.8738e-04 - val_loss: 0.0031\n",
      "Epoch 1623/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.9100e-04 - val_loss: 0.0022\n",
      "Epoch 1624/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.9512e-04 - val_loss: 0.0022\n",
      "Epoch 1625/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 3.1015e-04 - val_loss: 0.0027\n",
      "Epoch 1626/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.9944e-04 - val_loss: 0.0029\n",
      "Epoch 1627/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 3.0919e-04 - val_loss: 0.0019\n",
      "Epoch 1628/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 3.1052e-04 - val_loss: 0.0030\n",
      "Epoch 1629/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.9164e-04 - val_loss: 0.0026\n",
      "Epoch 1630/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.8576e-04 - val_loss: 0.0022\n",
      "Epoch 1631/2000\n",
      "3977/3977 [==============================] - 1s 271us/step - loss: 3.0596e-04 - val_loss: 0.0027\n",
      "Epoch 1632/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.9685e-04 - val_loss: 0.0027\n",
      "Epoch 1633/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.8670e-04 - val_loss: 0.0026\n",
      "Epoch 1634/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.9874e-04 - val_loss: 0.0021\n",
      "Epoch 1635/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.9737e-04 - val_loss: 0.0031\n",
      "Epoch 1636/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.9430e-04 - val_loss: 0.0026\n",
      "Epoch 1637/2000\n",
      "3977/3977 [==============================] - 1s 268us/step - loss: 2.9051e-04 - val_loss: 0.0027\n",
      "Epoch 1638/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 2.8489e-04 - val_loss: 0.0027\n",
      "Epoch 1639/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 2.7464e-04 - val_loss: 0.0022\n",
      "Epoch 1640/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.8463e-04 - val_loss: 0.0027\n",
      "Epoch 1641/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.8394e-04 - val_loss: 0.0029\n",
      "Epoch 1642/2000\n",
      "3977/3977 [==============================] - 1s 261us/step - loss: 2.8690e-04 - val_loss: 0.0024\n",
      "Epoch 1643/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.8541e-04 - val_loss: 0.0022\n",
      "Epoch 1644/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.9627e-04 - val_loss: 0.0033\n",
      "Epoch 1645/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.8319e-04 - val_loss: 0.0020\n",
      "Epoch 1646/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.0282e-04 - val_loss: 0.0027\n",
      "Epoch 1647/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.8290e-04 - val_loss: 0.0025\n",
      "Epoch 1648/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.8554e-04 - val_loss: 0.0024\n",
      "Epoch 1649/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 2.9915e-04 - val_loss: 0.0026\n",
      "Epoch 1650/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.0404e-04 - val_loss: 0.0028\n",
      "Epoch 1651/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.9417e-04 - val_loss: 0.0024\n",
      "Epoch 1652/2000\n",
      "3977/3977 [==============================] - 1s 269us/step - loss: 3.0530e-04 - val_loss: 0.0028\n",
      "Epoch 1653/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.8724e-04 - val_loss: 0.0026\n",
      "Epoch 1654/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.8409e-04 - val_loss: 0.0022\n",
      "Epoch 1655/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.8819e-04 - val_loss: 0.0028\n",
      "Epoch 1656/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.9047e-04 - val_loss: 0.0028\n",
      "Epoch 1657/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.9031e-04 - val_loss: 0.0021\n",
      "Epoch 1658/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.8763e-04 - val_loss: 0.0023\n",
      "Epoch 1659/2000\n",
      "3977/3977 [==============================] - 1s 269us/step - loss: 2.8925e-04 - val_loss: 0.0036\n",
      "Epoch 1660/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.9065e-04 - val_loss: 0.0021\n",
      "Epoch 1661/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.8389e-04 - val_loss: 0.0034\n",
      "Epoch 1662/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 3.0614e-04 - val_loss: 0.0025\n",
      "Epoch 1663/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.8704e-04 - val_loss: 0.0025\n",
      "Epoch 1664/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.7800e-04 - val_loss: 0.0027\n",
      "Epoch 1665/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.7561e-04 - val_loss: 0.0028\n",
      "Epoch 1666/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.7583e-04 - val_loss: 0.0023\n",
      "Epoch 1667/2000\n",
      "3977/3977 [==============================] - 1s 268us/step - loss: 2.6919e-04 - val_loss: 0.0029\n",
      "Epoch 1668/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.7300e-04 - val_loss: 0.0024\n",
      "Epoch 1669/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.7710e-04 - val_loss: 0.0023\n",
      "Epoch 1670/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.7565e-04 - val_loss: 0.0028\n",
      "Epoch 1671/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 2.7272e-04 - val_loss: 0.0023\n",
      "Epoch 1672/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.7062e-04 - val_loss: 0.0027\n",
      "Epoch 1673/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.7949e-04 - val_loss: 0.0025\n",
      "Epoch 1674/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.7214e-04 - val_loss: 0.0030\n",
      "Epoch 1675/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 2.7625e-04 - val_loss: 0.0019\n",
      "Epoch 1676/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.7816e-04 - val_loss: 0.0028\n",
      "Epoch 1677/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.8511e-04 - val_loss: 0.0033\n",
      "Epoch 1678/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.8822e-04 - val_loss: 0.0024\n",
      "Epoch 1679/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.8412e-04 - val_loss: 0.0021\n",
      "Epoch 1680/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.8831e-04 - val_loss: 0.0026\n",
      "Epoch 1681/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 2.8587e-04 - val_loss: 0.0026\n",
      "Epoch 1682/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 2.7755e-04 - val_loss: 0.0027\n",
      "Epoch 1683/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.7987e-04 - val_loss: 0.0025\n",
      "Epoch 1684/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.7384e-04 - val_loss: 0.0028\n",
      "Epoch 1685/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.6720e-04 - val_loss: 0.0025\n",
      "Epoch 1686/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 2.7173e-04 - val_loss: 0.0029\n",
      "Epoch 1687/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.6960e-04 - val_loss: 0.0029\n",
      "Epoch 1688/2000\n",
      "3977/3977 [==============================] - 1s 271us/step - loss: 2.6705e-04 - val_loss: 0.0023\n",
      "Epoch 1689/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.6965e-04 - val_loss: 0.0030\n",
      "Epoch 1690/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.7427e-04 - val_loss: 0.0026\n",
      "Epoch 1691/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.6614e-04 - val_loss: 0.0022\n",
      "Epoch 1692/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.6483e-04 - val_loss: 0.0031\n",
      "Epoch 1693/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.8052e-04 - val_loss: 0.0023\n",
      "Epoch 1694/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.8532e-04 - val_loss: 0.0021\n",
      "Epoch 1695/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.6886e-04 - val_loss: 0.0024\n",
      "Epoch 1696/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.7670e-04 - val_loss: 0.0025\n",
      "Epoch 1697/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.6689e-04 - val_loss: 0.0025\n",
      "Epoch 1698/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.7419e-04 - val_loss: 0.0027\n",
      "Epoch 1699/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.6693e-04 - val_loss: 0.0029\n",
      "Epoch 1700/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.6880e-04 - val_loss: 0.0021\n",
      "Epoch 1701/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.6116e-04 - val_loss: 0.0028\n",
      "Epoch 1702/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.6625e-04 - val_loss: 0.0023\n",
      "Epoch 1703/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.6824e-04 - val_loss: 0.0023\n",
      "Epoch 1704/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.6327e-04 - val_loss: 0.0019\n",
      "Epoch 1705/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.7327e-04 - val_loss: 0.0034\n",
      "Epoch 1706/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 2.7381e-04 - val_loss: 0.0026\n",
      "Epoch 1707/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.6542e-04 - val_loss: 0.0024\n",
      "Epoch 1708/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.6982e-04 - val_loss: 0.0035\n",
      "Epoch 1709/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 3.0165e-04 - val_loss: 0.0021\n",
      "Epoch 1710/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.9312e-04 - val_loss: 0.0031\n",
      "Epoch 1711/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.7792e-04 - val_loss: 0.0030\n",
      "Epoch 1712/2000\n",
      "3977/3977 [==============================] - 1s 268us/step - loss: 2.7075e-04 - val_loss: 0.0025\n",
      "Epoch 1713/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 2.6195e-04 - val_loss: 0.0028\n",
      "Epoch 1714/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.6380e-04 - val_loss: 0.0026\n",
      "Epoch 1715/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.6122e-04 - val_loss: 0.0023\n",
      "Epoch 1716/2000\n",
      "3977/3977 [==============================] - 1s 270us/step - loss: 2.6138e-04 - val_loss: 0.0032\n",
      "Epoch 1717/2000\n",
      "3977/3977 [==============================] - 1s 268us/step - loss: 2.6724e-04 - val_loss: 0.0027\n",
      "Epoch 1718/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 2.6143e-04 - val_loss: 0.0029\n",
      "Epoch 1719/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.7004e-04 - val_loss: 0.0021\n",
      "Epoch 1720/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.7080e-04 - val_loss: 0.0026\n",
      "Epoch 1721/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.5453e-04 - val_loss: 0.0024\n",
      "Epoch 1722/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.5997e-04 - val_loss: 0.0026\n",
      "Epoch 1723/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.6727e-04 - val_loss: 0.0027\n",
      "Epoch 1724/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.6750e-04 - val_loss: 0.0026\n",
      "Epoch 1725/2000\n",
      "3977/3977 [==============================] - 1s 275us/step - loss: 2.6009e-04 - val_loss: 0.0023\n",
      "Epoch 1726/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.6080e-04 - val_loss: 0.0028\n",
      "Epoch 1727/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 2.6393e-04 - val_loss: 0.0028\n",
      "Epoch 1728/2000\n",
      "3977/3977 [==============================] - 1s 269us/step - loss: 2.7097e-04 - val_loss: 0.0027\n",
      "Epoch 1729/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.6724e-04 - val_loss: 0.0028\n",
      "Epoch 1730/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.6435e-04 - val_loss: 0.0024\n",
      "Epoch 1731/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.5505e-04 - val_loss: 0.0029\n",
      "Epoch 1732/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.5758e-04 - val_loss: 0.0024\n",
      "Epoch 1733/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.5591e-04 - val_loss: 0.0024\n",
      "Epoch 1734/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.6508e-04 - val_loss: 0.0026\n",
      "Epoch 1735/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 2.5625e-04 - val_loss: 0.0034\n",
      "Epoch 1736/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 2.6426e-04 - val_loss: 0.0023\n",
      "Epoch 1737/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.5301e-04 - val_loss: 0.0027\n",
      "Epoch 1738/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.5857e-04 - val_loss: 0.0033\n",
      "Epoch 1739/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.6623e-04 - val_loss: 0.0020\n",
      "Epoch 1740/2000\n",
      "3977/3977 [==============================] - 1s 268us/step - loss: 2.7936e-04 - val_loss: 0.0034\n",
      "Epoch 1741/2000\n",
      "3977/3977 [==============================] - 1s 269us/step - loss: 2.8490e-04 - val_loss: 0.0026\n",
      "Epoch 1742/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 2.5797e-04 - val_loss: 0.0026\n",
      "Epoch 1743/2000\n",
      "3977/3977 [==============================] - 1s 268us/step - loss: 2.6212e-04 - val_loss: 0.0022\n",
      "Epoch 1744/2000\n",
      "3977/3977 [==============================] - 1s 268us/step - loss: 2.6410e-04 - val_loss: 0.0031\n",
      "Epoch 1745/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.8051e-04 - val_loss: 0.0017\n",
      "Epoch 1746/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.8019e-04 - val_loss: 0.0030\n",
      "Epoch 1747/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.5889e-04 - val_loss: 0.0029\n",
      "Epoch 1748/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.6373e-04 - val_loss: 0.0024\n",
      "Epoch 1749/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.5747e-04 - val_loss: 0.0029\n",
      "Epoch 1750/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.5155e-04 - val_loss: 0.0024\n",
      "Epoch 1751/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.5343e-04 - val_loss: 0.0024\n",
      "Epoch 1752/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.4907e-04 - val_loss: 0.0025\n",
      "Epoch 1753/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.5779e-04 - val_loss: 0.0023\n",
      "Epoch 1754/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 2.5609e-04 - val_loss: 0.0028\n",
      "Epoch 1755/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 2.5208e-04 - val_loss: 0.0026\n",
      "Epoch 1756/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.5559e-04 - val_loss: 0.0028\n",
      "Epoch 1757/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 2.5885e-04 - val_loss: 0.0024\n",
      "Epoch 1758/2000\n",
      "3977/3977 [==============================] - 1s 268us/step - loss: 2.5449e-04 - val_loss: 0.0028\n",
      "Epoch 1759/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.5180e-04 - val_loss: 0.0027\n",
      "Epoch 1760/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.5300e-04 - val_loss: 0.0028\n",
      "Epoch 1761/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.4525e-04 - val_loss: 0.0027\n",
      "Epoch 1762/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.6566e-04 - val_loss: 0.0031\n",
      "Epoch 1763/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.6417e-04 - val_loss: 0.0030\n",
      "Epoch 1764/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 2.5830e-04 - val_loss: 0.0022\n",
      "Epoch 1765/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.6031e-04 - val_loss: 0.0031\n",
      "Epoch 1766/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.3998e-04 - val_loss: 0.0027\n",
      "Epoch 1767/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.5352e-04 - val_loss: 0.0029\n",
      "Epoch 1768/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.5917e-04 - val_loss: 0.0027\n",
      "Epoch 1769/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.5141e-04 - val_loss: 0.0030\n",
      "Epoch 1770/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.4701e-04 - val_loss: 0.0026\n",
      "Epoch 1771/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 2.5632e-04 - val_loss: 0.0027\n",
      "Epoch 1772/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.4837e-04 - val_loss: 0.0024\n",
      "Epoch 1773/2000\n",
      "3977/3977 [==============================] - 1s 274us/step - loss: 2.5610e-04 - val_loss: 0.0029\n",
      "Epoch 1774/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.4411e-04 - val_loss: 0.0028\n",
      "Epoch 1775/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.5225e-04 - val_loss: 0.0028\n",
      "Epoch 1776/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.5657e-04 - val_loss: 0.0024\n",
      "Epoch 1777/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.5827e-04 - val_loss: 0.0028\n",
      "Epoch 1778/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.4748e-04 - val_loss: 0.0029\n",
      "Epoch 1779/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.4475e-04 - val_loss: 0.0030\n",
      "Epoch 1780/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.6845e-04 - val_loss: 0.0023\n",
      "Epoch 1781/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.5405e-04 - val_loss: 0.0026\n",
      "Epoch 1782/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.4576e-04 - val_loss: 0.0027\n",
      "Epoch 1783/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.4291e-04 - val_loss: 0.0026\n",
      "Epoch 1784/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.4475e-04 - val_loss: 0.0030\n",
      "Epoch 1785/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.4897e-04 - val_loss: 0.0024\n",
      "Epoch 1786/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.5065e-04 - val_loss: 0.0030\n",
      "Epoch 1787/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.5318e-04 - val_loss: 0.0032\n",
      "Epoch 1788/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 2.4871e-04 - val_loss: 0.0023\n",
      "Epoch 1789/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.3967e-04 - val_loss: 0.0027\n",
      "Epoch 1790/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.4442e-04 - val_loss: 0.0025\n",
      "Epoch 1791/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 2.3879e-04 - val_loss: 0.0025\n",
      "Epoch 1792/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.4380e-04 - val_loss: 0.0031\n",
      "Epoch 1793/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.3780e-04 - val_loss: 0.0026\n",
      "Epoch 1794/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 2.4733e-04 - val_loss: 0.0027\n",
      "Epoch 1795/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.4621e-04 - val_loss: 0.0030\n",
      "Epoch 1796/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.5334e-04 - val_loss: 0.0022\n",
      "Epoch 1797/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 2.5507e-04 - val_loss: 0.0030\n",
      "Epoch 1798/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.3810e-04 - val_loss: 0.0027\n",
      "Epoch 1799/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.3178e-04 - val_loss: 0.0027\n",
      "Epoch 1800/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.3672e-04 - val_loss: 0.0023\n",
      "Epoch 1801/2000\n",
      "3977/3977 [==============================] - 1s 268us/step - loss: 2.3751e-04 - val_loss: 0.0028\n",
      "Epoch 1802/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.4711e-04 - val_loss: 0.0021\n",
      "Epoch 1803/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.5589e-04 - val_loss: 0.0024\n",
      "Epoch 1804/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 2.4491e-04 - val_loss: 0.0028\n",
      "Epoch 1805/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.4219e-04 - val_loss: 0.0030\n",
      "Epoch 1806/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.3887e-04 - val_loss: 0.0021\n",
      "Epoch 1807/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.5600e-04 - val_loss: 0.0040\n",
      "Epoch 1808/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.5956e-04 - val_loss: 0.0027\n",
      "Epoch 1809/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.4034e-04 - val_loss: 0.0029\n",
      "Epoch 1810/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 1s 262us/step - loss: 2.4715e-04 - val_loss: 0.0024\n",
      "Epoch 1811/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 2.4026e-04 - val_loss: 0.0029\n",
      "Epoch 1812/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.4113e-04 - val_loss: 0.0033\n",
      "Epoch 1813/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.3593e-04 - val_loss: 0.0029\n",
      "Epoch 1814/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 2.4618e-04 - val_loss: 0.0029\n",
      "Epoch 1815/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.3866e-04 - val_loss: 0.0023\n",
      "Epoch 1816/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.5724e-04 - val_loss: 0.0032\n",
      "Epoch 1817/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.4882e-04 - val_loss: 0.0027\n",
      "Epoch 1818/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 2.4476e-04 - val_loss: 0.0028\n",
      "Epoch 1819/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 2.3917e-04 - val_loss: 0.0033\n",
      "Epoch 1820/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.4009e-04 - val_loss: 0.0030\n",
      "Epoch 1821/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 2.4229e-04 - val_loss: 0.0023\n",
      "Epoch 1822/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.3980e-04 - val_loss: 0.0033\n",
      "Epoch 1823/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.3538e-04 - val_loss: 0.0023\n",
      "Epoch 1824/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.3538e-04 - val_loss: 0.0031\n",
      "Epoch 1825/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.5130e-04 - val_loss: 0.0024\n",
      "Epoch 1826/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 2.3252e-04 - val_loss: 0.0031\n",
      "Epoch 1827/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.2813e-04 - val_loss: 0.0027\n",
      "Epoch 1828/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.2487e-04 - val_loss: 0.0027\n",
      "Epoch 1829/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.3349e-04 - val_loss: 0.0032\n",
      "Epoch 1830/2000\n",
      "3977/3977 [==============================] - 1s 269us/step - loss: 2.3775e-04 - val_loss: 0.0026\n",
      "Epoch 1831/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.2498e-04 - val_loss: 0.0030\n",
      "Epoch 1832/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.2268e-04 - val_loss: 0.0025\n",
      "Epoch 1833/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.2796e-04 - val_loss: 0.0026\n",
      "Epoch 1834/2000\n",
      "3977/3977 [==============================] - 1s 270us/step - loss: 2.3582e-04 - val_loss: 0.0031\n",
      "Epoch 1835/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.3663e-04 - val_loss: 0.0027\n",
      "Epoch 1836/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.3909e-04 - val_loss: 0.0029\n",
      "Epoch 1837/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.3085e-04 - val_loss: 0.0034\n",
      "Epoch 1838/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.3033e-04 - val_loss: 0.0027\n",
      "Epoch 1839/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.2460e-04 - val_loss: 0.0022\n",
      "Epoch 1840/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 2.2405e-04 - val_loss: 0.0031\n",
      "Epoch 1841/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.1301e-04 - val_loss: 0.0029\n",
      "Epoch 1842/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.1543e-04 - val_loss: 0.0024\n",
      "Epoch 1843/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.2499e-04 - val_loss: 0.0029\n",
      "Epoch 1844/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 2.2728e-04 - val_loss: 0.0030\n",
      "Epoch 1845/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.2857e-04 - val_loss: 0.0031\n",
      "Epoch 1846/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.3230e-04 - val_loss: 0.0026\n",
      "Epoch 1847/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.4003e-04 - val_loss: 0.0036\n",
      "Epoch 1848/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.3335e-04 - val_loss: 0.0024\n",
      "Epoch 1849/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 2.2944e-04 - val_loss: 0.0025\n",
      "Epoch 1850/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.1908e-04 - val_loss: 0.0029\n",
      "Epoch 1851/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.2754e-04 - val_loss: 0.0026\n",
      "Epoch 1852/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.2085e-04 - val_loss: 0.0029\n",
      "Epoch 1853/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.2463e-04 - val_loss: 0.0035\n",
      "Epoch 1854/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.2832e-04 - val_loss: 0.0028\n",
      "Epoch 1855/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 2.3329e-04 - val_loss: 0.0028\n",
      "Epoch 1856/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.1589e-04 - val_loss: 0.0025\n",
      "Epoch 1857/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.1940e-04 - val_loss: 0.0029\n",
      "Epoch 1858/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 2.2265e-04 - val_loss: 0.0026\n",
      "Epoch 1859/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 2.2210e-04 - val_loss: 0.0029\n",
      "Epoch 1860/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 2.2145e-04 - val_loss: 0.0027\n",
      "Epoch 1861/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.3601e-04 - val_loss: 0.0032\n",
      "Epoch 1862/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.2264e-04 - val_loss: 0.0025\n",
      "Epoch 1863/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.2119e-04 - val_loss: 0.0036\n",
      "Epoch 1864/2000\n",
      "3977/3977 [==============================] - 1s 268us/step - loss: 2.1841e-04 - val_loss: 0.0028\n",
      "Epoch 1865/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 2.1588e-04 - val_loss: 0.0029\n",
      "Epoch 1866/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.2024e-04 - val_loss: 0.0031\n",
      "Epoch 1867/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.2053e-04 - val_loss: 0.0027\n",
      "Epoch 1868/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.1117e-04 - val_loss: 0.0029\n",
      "Epoch 1869/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 2.1513e-04 - val_loss: 0.0033\n",
      "Epoch 1870/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.2774e-04 - val_loss: 0.0025\n",
      "Epoch 1871/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.3411e-04 - val_loss: 0.0033\n",
      "Epoch 1872/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.2550e-04 - val_loss: 0.0031\n",
      "Epoch 1873/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.1845e-04 - val_loss: 0.0027\n",
      "Epoch 1874/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.1643e-04 - val_loss: 0.0032\n",
      "Epoch 1875/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.1038e-04 - val_loss: 0.0029\n",
      "Epoch 1876/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.0994e-04 - val_loss: 0.0027\n",
      "Epoch 1877/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 2.0621e-04 - val_loss: 0.0029\n",
      "Epoch 1878/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.1676e-04 - val_loss: 0.0037\n",
      "Epoch 1879/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 2.0697e-04 - val_loss: 0.0029\n",
      "Epoch 1880/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.1525e-04 - val_loss: 0.0033\n",
      "Epoch 1881/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.1186e-04 - val_loss: 0.0033\n",
      "Epoch 1882/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.1458e-04 - val_loss: 0.0027\n",
      "Epoch 1883/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.1871e-04 - val_loss: 0.0032\n",
      "Epoch 1884/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.1765e-04 - val_loss: 0.0028\n",
      "Epoch 1885/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.2356e-04 - val_loss: 0.0034\n",
      "Epoch 1886/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.2640e-04 - val_loss: 0.0031\n",
      "Epoch 1887/2000\n",
      "3977/3977 [==============================] - 1s 268us/step - loss: 2.2434e-04 - val_loss: 0.0032\n",
      "Epoch 1888/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 2.2321e-04 - val_loss: 0.0028\n",
      "Epoch 1889/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.1848e-04 - val_loss: 0.0028\n",
      "Epoch 1890/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.1252e-04 - val_loss: 0.0029\n",
      "Epoch 1891/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.1185e-04 - val_loss: 0.0028\n",
      "Epoch 1892/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.0753e-04 - val_loss: 0.0031\n",
      "Epoch 1893/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.0557e-04 - val_loss: 0.0029\n",
      "Epoch 1894/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.0610e-04 - val_loss: 0.0027\n",
      "Epoch 1895/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.0279e-04 - val_loss: 0.0036\n",
      "Epoch 1896/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.0334e-04 - val_loss: 0.0030\n",
      "Epoch 1897/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 1.9900e-04 - val_loss: 0.0027\n",
      "Epoch 1898/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.0982e-04 - val_loss: 0.0031\n",
      "Epoch 1899/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 1.9929e-04 - val_loss: 0.0029\n",
      "Epoch 1900/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.0922e-04 - val_loss: 0.0031\n",
      "Epoch 1901/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.1511e-04 - val_loss: 0.0036\n",
      "Epoch 1902/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.1741e-04 - val_loss: 0.0028\n",
      "Epoch 1903/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 2.0924e-04 - val_loss: 0.0030\n",
      "Epoch 1904/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.0268e-04 - val_loss: 0.0034\n",
      "Epoch 1905/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 1.9634e-04 - val_loss: 0.0029\n",
      "Epoch 1906/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 1.9653e-04 - val_loss: 0.0037\n",
      "Epoch 1907/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.1539e-04 - val_loss: 0.0034\n",
      "Epoch 1908/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.1523e-04 - val_loss: 0.0027\n",
      "Epoch 1909/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 2.1017e-04 - val_loss: 0.0029\n",
      "Epoch 1910/2000\n",
      "3977/3977 [==============================] - 1s 269us/step - loss: 2.0531e-04 - val_loss: 0.0038\n",
      "Epoch 1911/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.0311e-04 - val_loss: 0.0035\n",
      "Epoch 1912/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 2.0744e-04 - val_loss: 0.0032\n",
      "Epoch 1913/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.1616e-04 - val_loss: 0.0037\n",
      "Epoch 1914/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.1715e-04 - val_loss: 0.0029\n",
      "Epoch 1915/2000\n",
      "3977/3977 [==============================] - 1s 269us/step - loss: 2.0506e-04 - val_loss: 0.0028\n",
      "Epoch 1916/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.0491e-04 - val_loss: 0.0036\n",
      "Epoch 1917/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 1.9562e-04 - val_loss: 0.0028\n",
      "Epoch 1918/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.0621e-04 - val_loss: 0.0031\n",
      "Epoch 1919/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.0848e-04 - val_loss: 0.0033\n",
      "Epoch 1920/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.0603e-04 - val_loss: 0.0037\n",
      "Epoch 1921/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.0652e-04 - val_loss: 0.0026\n",
      "Epoch 1922/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.1055e-04 - val_loss: 0.0038\n",
      "Epoch 1923/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 1.9419e-04 - val_loss: 0.0029\n",
      "Epoch 1924/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 2.0604e-04 - val_loss: 0.0032\n",
      "Epoch 1925/2000\n",
      "3977/3977 [==============================] - 1s 269us/step - loss: 1.9764e-04 - val_loss: 0.0037\n",
      "Epoch 1926/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 1.9777e-04 - val_loss: 0.0037\n",
      "Epoch 1927/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 1.9233e-04 - val_loss: 0.0032\n",
      "Epoch 1928/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 1.9862e-04 - val_loss: 0.0032\n",
      "Epoch 1929/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 1.9733e-04 - val_loss: 0.0032\n",
      "Epoch 1930/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 1.9926e-04 - val_loss: 0.0033\n",
      "Epoch 1931/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 1.9400e-04 - val_loss: 0.0034\n",
      "Epoch 1932/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.0189e-04 - val_loss: 0.0030\n",
      "Epoch 1933/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 1.9960e-04 - val_loss: 0.0032\n",
      "Epoch 1934/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 1.9352e-04 - val_loss: 0.0041\n",
      "Epoch 1935/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 1.9804e-04 - val_loss: 0.0033\n",
      "Epoch 1936/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 1.9289e-04 - val_loss: 0.0032\n",
      "Epoch 1937/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 1.9492e-04 - val_loss: 0.0030\n",
      "Epoch 1938/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 1.9736e-04 - val_loss: 0.0032\n",
      "Epoch 1939/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 1.9312e-04 - val_loss: 0.0032\n",
      "Epoch 1940/2000\n",
      "3977/3977 [==============================] - 1s 268us/step - loss: 2.0113e-04 - val_loss: 0.0031\n",
      "Epoch 1941/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 1.9249e-04 - val_loss: 0.0034\n",
      "Epoch 1942/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 1.9126e-04 - val_loss: 0.0031\n",
      "Epoch 1943/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 1.9231e-04 - val_loss: 0.0032\n",
      "Epoch 1944/2000\n",
      "3977/3977 [==============================] - 1s 269us/step - loss: 2.0238e-04 - val_loss: 0.0038\n",
      "Epoch 1945/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 1.9649e-04 - val_loss: 0.0029\n",
      "Epoch 1946/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 2.0995e-04 - val_loss: 0.0034\n",
      "Epoch 1947/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.0744e-04 - val_loss: 0.0033\n",
      "Epoch 1948/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 1.9232e-04 - val_loss: 0.0035\n",
      "Epoch 1949/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 1.9547e-04 - val_loss: 0.0033\n",
      "Epoch 1950/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 1.9817e-04 - val_loss: 0.0038\n",
      "Epoch 1951/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 1.8533e-04 - val_loss: 0.0034\n",
      "Epoch 1952/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 1.8232e-04 - val_loss: 0.0036\n",
      "Epoch 1953/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 1.8885e-04 - val_loss: 0.0033\n",
      "Epoch 1954/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3977/3977 [==============================] - 1s 265us/step - loss: 1.8725e-04 - val_loss: 0.0041\n",
      "Epoch 1955/2000\n",
      "3977/3977 [==============================] - 1s 268us/step - loss: 1.8653e-04 - val_loss: 0.0029\n",
      "Epoch 1956/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 1.9392e-04 - val_loss: 0.0035\n",
      "Epoch 1957/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 1.8681e-04 - val_loss: 0.0039\n",
      "Epoch 1958/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 1.9040e-04 - val_loss: 0.0041\n",
      "Epoch 1959/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.0074e-04 - val_loss: 0.0032\n",
      "Epoch 1960/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.0274e-04 - val_loss: 0.0026\n",
      "Epoch 1961/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 2.0760e-04 - val_loss: 0.0041\n",
      "Epoch 1962/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 1.9668e-04 - val_loss: 0.0036\n",
      "Epoch 1963/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 2.0007e-04 - val_loss: 0.0032\n",
      "Epoch 1964/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 1.9856e-04 - val_loss: 0.0028\n",
      "Epoch 1965/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 1.9316e-04 - val_loss: 0.0042\n",
      "Epoch 1966/2000\n",
      "3977/3977 [==============================] - 1s 262us/step - loss: 1.9902e-04 - val_loss: 0.0031\n",
      "Epoch 1967/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 1.9150e-04 - val_loss: 0.0032\n",
      "Epoch 1968/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 1.9986e-04 - val_loss: 0.0031\n",
      "Epoch 1969/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 1.9195e-04 - val_loss: 0.0038\n",
      "Epoch 1970/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 1.8321e-04 - val_loss: 0.0035\n",
      "Epoch 1971/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 1.8357e-04 - val_loss: 0.0035\n",
      "Epoch 1972/2000\n",
      "3977/3977 [==============================] - 1s 269us/step - loss: 1.8827e-04 - val_loss: 0.0029\n",
      "Epoch 1973/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 1.9423e-04 - val_loss: 0.0036\n",
      "Epoch 1974/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 1.8410e-04 - val_loss: 0.0030\n",
      "Epoch 1975/2000\n",
      "3977/3977 [==============================] - 1s 266us/step - loss: 1.8935e-04 - val_loss: 0.0034\n",
      "Epoch 1976/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 1.8697e-04 - val_loss: 0.0027\n",
      "Epoch 1977/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 1.9382e-04 - val_loss: 0.0035\n",
      "Epoch 1978/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 1.8748e-04 - val_loss: 0.0030\n",
      "Epoch 1979/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 2.0184e-04 - val_loss: 0.0029\n",
      "Epoch 1980/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 1.9760e-04 - val_loss: 0.0027\n",
      "Epoch 1981/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 1.8860e-04 - val_loss: 0.0040\n",
      "Epoch 1982/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 1.9835e-04 - val_loss: 0.0025\n",
      "Epoch 1983/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 2.0164e-04 - val_loss: 0.0030\n",
      "Epoch 1984/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 1.8556e-04 - val_loss: 0.0041\n",
      "Epoch 1985/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 2.0213e-04 - val_loss: 0.0031\n",
      "Epoch 1986/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 1.9185e-04 - val_loss: 0.0029\n",
      "Epoch 1987/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 1.8800e-04 - val_loss: 0.0028\n",
      "Epoch 1988/2000\n",
      "3977/3977 [==============================] - 1s 270us/step - loss: 2.1315e-04 - val_loss: 0.0044\n",
      "Epoch 1989/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 2.0906e-04 - val_loss: 0.0027\n",
      "Epoch 1990/2000\n",
      "3977/3977 [==============================] - 1s 265us/step - loss: 1.9525e-04 - val_loss: 0.0031\n",
      "Epoch 1991/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 1.9258e-04 - val_loss: 0.0034\n",
      "Epoch 1992/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 1.8496e-04 - val_loss: 0.0037\n",
      "Epoch 1993/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 1.6963e-04 - val_loss: 0.0033\n",
      "Epoch 1994/2000\n",
      "3977/3977 [==============================] - 1s 261us/step - loss: 1.7505e-04 - val_loss: 0.0034\n",
      "Epoch 1995/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 1.8196e-04 - val_loss: 0.0036\n",
      "Epoch 1996/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 1.8201e-04 - val_loss: 0.0027\n",
      "Epoch 1997/2000\n",
      "3977/3977 [==============================] - 1s 264us/step - loss: 1.8404e-04 - val_loss: 0.0043\n",
      "Epoch 1998/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 1.7857e-04 - val_loss: 0.0032\n",
      "Epoch 1999/2000\n",
      "3977/3977 [==============================] - 1s 263us/step - loss: 1.8507e-04 - val_loss: 0.0034\n",
      "Epoch 2000/2000\n",
      "3977/3977 [==============================] - 1s 267us/step - loss: 1.8464e-04 - val_loss: 0.0027\n"
     ]
    }
   ],
   "source": [
    "final_model = build_lstm(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'shuffle': True,\n",
       " 'dropout': 0.1,\n",
       " 'lstmsize': 160,\n",
       " 'activation': 'relu',\n",
       " 'twice': False,\n",
       " 'optimizer': 'adam',\n",
       " 'density': 122,\n",
       " 'callbacks': [<keras.callbacks.callbacks.ModelCheckpoint at 0x278d5e56948>]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_182\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_303 (LSTM)              (None, 160)               106240    \n",
      "_________________________________________________________________\n",
      "dropout_303 (Dropout)        (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dense_737 (Dense)            (None, 122)               19642     \n",
      "_________________________________________________________________\n",
      "dense_738 (Dense)            (None, 1)                 123       \n",
      "=================================================================\n",
      "Total params: 126,005\n",
      "Trainable params: 126,005\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model[0].load_weights('./checkpoints/IBM_3days/IBM.(best).hdf5')\n",
    "y_predicted = final_model[0].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y_test = y_normaliser.inverse_transform(y_predicted)\n",
    "true_y_test = y_normaliser.inverse_transform(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE is 27.94\n",
      "Medium error is 3.93\n"
     ]
    }
   ],
   "source": [
    "loss = np.mean((true_y_test - predicted_y_test)**2)\n",
    "medium_error = np.mean(abs(true_y_test - predicted_y_test))\n",
    "print(f'MSE is {loss:.2f}\\nMedium error is {medium_error:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_down_test = []\n",
    "up_down_predicted = []\n",
    "\n",
    "for y,x in zip(Y_test,X_test):\n",
    "    if y[0] > x[-1][0]: up_down_test.append(1)\n",
    "    elif y[0] < x[-1][0]: up_down_test.append(-1)\n",
    "    else: up_down_test.append(0)\n",
    "        \n",
    "for y,x in zip(y_predicted,X_test):\n",
    "    if y[0] > x[-1][0]: up_down_predicted.append(1)\n",
    "    elif y[0] < x[-1][0]: up_down_predicted.append(-1)\n",
    "    else: up_down_predicted.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trend accuracy is: 55.14%\n"
     ]
    }
   ],
   "source": [
    "print(f'Trend accuracy is: {(sum(1 for r,p in zip(up_down_test,up_down_predicted) if r == p)/len(up_down_test))*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for upward trend is: 22.94%\n",
      "Accuracy for downward trend is: 81.34%\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy for upward trend is: {(sum(1 for r,p in zip(up_down_test,up_down_predicted) if r == 1 and p == 1)/sum(1 for v in up_down_test if v == 1))*100:.2f}%')\n",
    "print(f'Accuracy for downward trend is: {(sum(1 for r,p in zip(up_down_test,up_down_predicted) if r == -1 and p == -1)/sum(1 for v in up_down_test if v == -1))*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predictions over the last 92 days in test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 3200x2400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "figure(num=None, figsize=(40, 30), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "plt.plot(range(92), true_y_test[-92:])\n",
    "plt.plot(range(92), predicted_y_test[-92:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Last 12 days + prediction of last 6 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 3200x2400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure(num=None, figsize=(40, 30), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "plt.plot(range(12), true_y_test[-12:])\n",
    "plt.plot(range(12), np.append(true_y_test[-12:-6], predicted_y_test[-6:]))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
