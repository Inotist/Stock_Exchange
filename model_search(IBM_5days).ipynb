{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./datasets/IBM_daily.csv').sort_values(by='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>1. open</th>\n",
       "      <th>2. high</th>\n",
       "      <th>3. low</th>\n",
       "      <th>4. close</th>\n",
       "      <th>5. volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5217</th>\n",
       "      <td>1999-11-01</td>\n",
       "      <td>98.50</td>\n",
       "      <td>98.8100</td>\n",
       "      <td>96.37</td>\n",
       "      <td>96.75</td>\n",
       "      <td>9551800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5216</th>\n",
       "      <td>1999-11-02</td>\n",
       "      <td>96.75</td>\n",
       "      <td>96.8100</td>\n",
       "      <td>93.69</td>\n",
       "      <td>94.81</td>\n",
       "      <td>11105400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5215</th>\n",
       "      <td>1999-11-03</td>\n",
       "      <td>95.87</td>\n",
       "      <td>95.9400</td>\n",
       "      <td>93.50</td>\n",
       "      <td>94.37</td>\n",
       "      <td>10369100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5214</th>\n",
       "      <td>1999-11-04</td>\n",
       "      <td>94.44</td>\n",
       "      <td>94.4400</td>\n",
       "      <td>90.00</td>\n",
       "      <td>91.56</td>\n",
       "      <td>16697600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5213</th>\n",
       "      <td>1999-11-05</td>\n",
       "      <td>92.75</td>\n",
       "      <td>92.9400</td>\n",
       "      <td>90.19</td>\n",
       "      <td>90.25</td>\n",
       "      <td>13737600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-07-22</td>\n",
       "      <td>125.90</td>\n",
       "      <td>129.4700</td>\n",
       "      <td>125.80</td>\n",
       "      <td>128.67</td>\n",
       "      <td>8195366.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-07-23</td>\n",
       "      <td>129.10</td>\n",
       "      <td>129.3700</td>\n",
       "      <td>127.15</td>\n",
       "      <td>127.33</td>\n",
       "      <td>4220136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-07-24</td>\n",
       "      <td>126.48</td>\n",
       "      <td>127.6459</td>\n",
       "      <td>125.50</td>\n",
       "      <td>125.79</td>\n",
       "      <td>3531076.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-07-27</td>\n",
       "      <td>124.86</td>\n",
       "      <td>126.3200</td>\n",
       "      <td>124.71</td>\n",
       "      <td>126.21</td>\n",
       "      <td>3733547.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-28</td>\n",
       "      <td>125.82</td>\n",
       "      <td>126.3400</td>\n",
       "      <td>124.15</td>\n",
       "      <td>124.47</td>\n",
       "      <td>4157538.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5218 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  1. open   2. high  3. low  4. close   5. volume\n",
       "5217  1999-11-01    98.50   98.8100   96.37     96.75   9551800.0\n",
       "5216  1999-11-02    96.75   96.8100   93.69     94.81  11105400.0\n",
       "5215  1999-11-03    95.87   95.9400   93.50     94.37  10369100.0\n",
       "5214  1999-11-04    94.44   94.4400   90.00     91.56  16697600.0\n",
       "5213  1999-11-05    92.75   92.9400   90.19     90.25  13737600.0\n",
       "...          ...      ...       ...     ...       ...         ...\n",
       "4     2020-07-22   125.90  129.4700  125.80    128.67   8195366.0\n",
       "3     2020-07-23   129.10  129.3700  127.15    127.33   4220136.0\n",
       "2     2020-07-24   126.48  127.6459  125.50    125.79   3531076.0\n",
       "1     2020-07-27   124.86  126.3200  124.71    126.21   3733547.0\n",
       "0     2020-07-28   125.82  126.3400  124.15    124.47   4157538.0\n",
       "\n",
       "[5218 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1. open</th>\n",
       "      <th>2. high</th>\n",
       "      <th>3. low</th>\n",
       "      <th>4. close</th>\n",
       "      <th>5. volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5217</th>\n",
       "      <td>98.50</td>\n",
       "      <td>98.8100</td>\n",
       "      <td>96.37</td>\n",
       "      <td>96.75</td>\n",
       "      <td>9551800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5216</th>\n",
       "      <td>96.75</td>\n",
       "      <td>96.8100</td>\n",
       "      <td>93.69</td>\n",
       "      <td>94.81</td>\n",
       "      <td>11105400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5215</th>\n",
       "      <td>95.87</td>\n",
       "      <td>95.9400</td>\n",
       "      <td>93.50</td>\n",
       "      <td>94.37</td>\n",
       "      <td>10369100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5214</th>\n",
       "      <td>94.44</td>\n",
       "      <td>94.4400</td>\n",
       "      <td>90.00</td>\n",
       "      <td>91.56</td>\n",
       "      <td>16697600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5213</th>\n",
       "      <td>92.75</td>\n",
       "      <td>92.9400</td>\n",
       "      <td>90.19</td>\n",
       "      <td>90.25</td>\n",
       "      <td>13737600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>125.90</td>\n",
       "      <td>129.4700</td>\n",
       "      <td>125.80</td>\n",
       "      <td>128.67</td>\n",
       "      <td>8195366.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>129.10</td>\n",
       "      <td>129.3700</td>\n",
       "      <td>127.15</td>\n",
       "      <td>127.33</td>\n",
       "      <td>4220136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>126.48</td>\n",
       "      <td>127.6459</td>\n",
       "      <td>125.50</td>\n",
       "      <td>125.79</td>\n",
       "      <td>3531076.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>124.86</td>\n",
       "      <td>126.3200</td>\n",
       "      <td>124.71</td>\n",
       "      <td>126.21</td>\n",
       "      <td>3733547.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>125.82</td>\n",
       "      <td>126.3400</td>\n",
       "      <td>124.15</td>\n",
       "      <td>124.47</td>\n",
       "      <td>4157538.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5218 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      1. open   2. high  3. low  4. close   5. volume\n",
       "5217    98.50   98.8100   96.37     96.75   9551800.0\n",
       "5216    96.75   96.8100   93.69     94.81  11105400.0\n",
       "5215    95.87   95.9400   93.50     94.37  10369100.0\n",
       "5214    94.44   94.4400   90.00     91.56  16697600.0\n",
       "5213    92.75   92.9400   90.19     90.25  13737600.0\n",
       "...       ...       ...     ...       ...         ...\n",
       "4      125.90  129.4700  125.80    128.67   8195366.0\n",
       "3      129.10  129.3700  127.15    127.33   4220136.0\n",
       "2      126.48  127.6459  125.50    125.79   3531076.0\n",
       "1      124.86  126.3200  124.71    126.21   3733547.0\n",
       "0      125.82  126.3400  124.15    124.47   4157538.0\n",
       "\n",
       "[5218 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(columns='date')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequence for the LSTM network\n",
    "backlook = 92\n",
    "\n",
    "# Days to predict\n",
    "days = 5\n",
    "\n",
    "# Size of data split for testing\n",
    "train_size = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = []\n",
    "\n",
    "for i in range(days):\n",
    "    index.append(np.arange(i,len(data),days))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_index = []\n",
    "\n",
    "for i in range(len(index[0]) - backlook):\n",
    "    for e in range(len(index)):\n",
    "        try: ordered_index.append(index[e][i:i+backlook])\n",
    "        except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise data\n",
    "normaliser = preprocessing.MinMaxScaler()\n",
    "data_norm = normaliser.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalised chunks\n",
    "historical_sequences_norm = np.array([data_norm[ix].copy() for ix in ordered_index])\n",
    "next_day_open_values_norm = np.array([data_norm[ordered_index[i+days][-1],0].copy() for i in range(len(ordered_index) - days)])\n",
    "next_day_open_values_norm = np.expand_dims(next_day_open_values_norm, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete those sequences that doesn't have a -th day in the results\n",
    "historical_sequences_norm = historical_sequences_norm[:next_day_open_values_norm.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4755, 92, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "historical_sequences_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4755, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_day_open_values_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.32507933],\n",
       "       [0.31792447],\n",
       "       [0.29925963],\n",
       "       ...,\n",
       "       [0.47601568],\n",
       "       [0.44328999],\n",
       "       [0.46319915]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Y raw data\n",
    "next_day_open_values = np.array([data.to_numpy()[ordered_index[i+days][-1],0] for i in range(len(ordered_index) - days)])\n",
    "next_day_open_values = np.expand_dims(next_day_open_values, -1)\n",
    "\n",
    "# Y normaliser\n",
    "y_normaliser = preprocessing.MinMaxScaler()\n",
    "y_normaliser.fit_transform(next_day_open_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test split\n",
    "split = int(historical_sequences_norm.shape[0] * train_size)\n",
    "\n",
    "X_train = historical_sequences_norm[:split]\n",
    "Y_train = next_day_open_values_norm[:split]\n",
    "\n",
    "X_test = historical_sequences_norm[split:]\n",
    "Y_test = next_day_open_values_norm[split:]\n",
    "unscaled_y_test = next_day_open_values[split:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm(x, y, batch_size=512, epochs=24, **params):\n",
    "    \n",
    "    # List of parameters\n",
    "    if 'lstmsize' not in params: params['lstmsize'] = x.shape[1]\n",
    "    if 'density' not in params: params['density'] = int((params['lstmsize']//1.5)*2)\n",
    "    if 'activation' not in params: params['activation'] = 'relu'\n",
    "    if 'twice' not in params: params['twice'] = False\n",
    "    if 'optimizer' not in params: params['optimizer'] = 'adam'\n",
    "    if 'shuffle' not in params: params['shuffle'] = False\n",
    "    \n",
    "    # Model definition\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(params['lstmsize'], input_shape=x.shape[1:], return_sequences=params['twice']))\n",
    "    \n",
    "    if 'dropout' in params:\n",
    "        model.add(Dropout(params['dropout']))\n",
    "    \n",
    "    if params['twice']:\n",
    "        model.add(LSTM(params['lstmsize']))\n",
    "        \n",
    "        if 'dropout' in params:\n",
    "            model.add(Dropout(params['dropout']))\n",
    "            \n",
    "    model.add(Dense(params['density'], activation=params['activation']))\n",
    "    \n",
    "    if 'full_density' in params and params['full_density']:\n",
    "        density = params['density']//2\n",
    "        while density >= 12:\n",
    "            model.add(Dense(density, activation=params['activation']))\n",
    "            density //= 2\n",
    "            \n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    \n",
    "    model.compile(loss='mse', optimizer=params['optimizer'])\n",
    "    \n",
    "    if 'callbacks' in params:\n",
    "        callback = model.fit(x=x, y=y, validation_split=0.1, batch_size=batch_size, epochs=epochs, shuffle=params['shuffle'],\n",
    "                            callbacks=params['callbacks'])\n",
    "    else:\n",
    "        callback = model.fit(x=x, y=y, validation_split=0.1, batch_size=batch_size, epochs=epochs, shuffle=params['shuffle'])\n",
    "    \n",
    "    return [model, callback, params]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evolutive algorith to search for the most optimal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_genes(x, y, population_size, population=[]):\n",
    "    if population_size-len(population) < 0:\n",
    "        print('population size must be greater or equal than actual population')\n",
    "        return\n",
    "    \n",
    "    if len(population) > 0:\n",
    "        if len(population) < 3:\n",
    "            print('population should be empty or 3 at least')\n",
    "            return\n",
    "        \n",
    "        population[2] = breed_genes(x, y, population[0][2].copy())\n",
    "        population[1] = breed_genes(x, y, combine=(population[0][2], population[1][2]))\n",
    "        population = population[:3]\n",
    "    \n",
    "    for _ in range(population_size-len(population)):\n",
    "        subject = breed_genes(x, y)\n",
    "        population.append(subject)\n",
    "        \n",
    "    return population\n",
    "\n",
    "def breed_genes(x, y, genes={}, combine=None):\n",
    "    genes['x'] = x\n",
    "    genes['y'] = y\n",
    "    \n",
    "    if type(combine) is list or type(combine) is tuple:\n",
    "        genes['lstmsize'] = combine[np.random.randint(0,2)]['lstmsize']\n",
    "        genes['density'] = combine[np.random.randint(0,2)]['density']\n",
    "        genes['activation'] = combine[np.random.randint(0,2)]['activation']\n",
    "        genes['twice'] = combine[np.random.randint(0,2)]['twice']\n",
    "        genes['optimizer'] = combine[np.random.randint(0,2)]['optimizer']\n",
    "        genes['shuffle'] = combine[np.random.randint(0,2)]['shuffle']\n",
    "        \n",
    "        genes['dropout'] = combine[np.random.randint(0,2)].get('dropout')\n",
    "        if genes['dropout'] is None: del genes['dropout']\n",
    "        genes['full_density'] = combine[np.random.randint(0,2)].get('full_density')\n",
    "        if genes['full_density'] is None: del genes['full_density']\n",
    "            \n",
    "    else:\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['lstmsize'] = int((np.random.randint(x.shape[1],x.shape[1]*2)//2)*2)\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['density'] = int((np.random.randint(x.shape[1]//2,x.shape[1]*2.66)//2)*2)\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            activation = [\n",
    "                'relu',\n",
    "                'sigmoid',\n",
    "                'softplus',\n",
    "                'softsign',\n",
    "                'tanh',\n",
    "                'selu',\n",
    "                'elu',\n",
    "                'exponential'\n",
    "            ]\n",
    "            genes['activation'] = activation[np.random.randint(0,8)]\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['twice'] = True\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            optimizer = [\n",
    "                'sgd',\n",
    "                'rmsprop',\n",
    "                'adam',\n",
    "                'adadelta',\n",
    "                'adagrad',\n",
    "                'adamax',\n",
    "                'nadam'\n",
    "            ]\n",
    "            genes['optimizer'] = optimizer[np.random.randint(0,7)]\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['shuffle'] = True\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['dropout'] = np.random.randint(1,4)/10\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['full_density'] = True\n",
    "            \n",
    "    new_model = build_lstm(**genes)\n",
    "        \n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def breed_population(x, y, generations, population_size, population=[]):\n",
    "    \n",
    "    if generations > 1 and population_size < 3:\n",
    "        print('population size should be of a minimum of 3 for more than one generation')\n",
    "        return\n",
    "    \n",
    "    for g in range(generations):\n",
    "        print(f'\\nGENERATION {g}\\n')\n",
    "        population = set_genes(x, y, population_size, population)\n",
    "        population = sorted(population, key=lambda x: x[1].history['val_loss'][-1]+x[1].history['loss'][-1])\n",
    "        \n",
    "    return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GENERATION 0\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 2s 628us/step - loss: 0.0766 - val_loss: 0.0120\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 308us/step - loss: 0.0099 - val_loss: 0.0031\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 300us/step - loss: 0.0050 - val_loss: 0.0034\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 302us/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 316us/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 318us/step - loss: 0.0024 - val_loss: 0.0045\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 310us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 317us/step - loss: 0.0022 - val_loss: 0.0034\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 303us/step - loss: 0.0021 - val_loss: 0.0034\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 303us/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 301us/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 304us/step - loss: 0.0019 - val_loss: 0.0032\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 302us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 302us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 313us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 327us/step - loss: 0.0017 - val_loss: 0.0027\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 302us/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 311us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 303us/step - loss: 0.0016 - val_loss: 0.0025\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 308us/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 319us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 299us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 304us/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 297us/step - loss: 0.0014 - val_loss: 0.0022\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 2s 638us/step - loss: 0.1442 - val_loss: 0.0682\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 432us/step - loss: 0.0247 - val_loss: 0.0047\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 430us/step - loss: 0.0095 - val_loss: 0.0048\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 429us/step - loss: 0.0061 - val_loss: 0.0076\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 430us/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 431us/step - loss: 0.0032 - val_loss: 0.0058\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 431us/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 433us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 434us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 432us/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 431us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 431us/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 431us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 430us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 431us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 432us/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 430us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 431us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 438us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 435us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 432us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 430us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 429us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 431us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: 0.1331 - val_loss: 0.0640\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 351us/step - loss: 0.0238 - val_loss: 0.0062\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 350us/step - loss: 0.0090 - val_loss: 0.0035\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 349us/step - loss: 0.0051 - val_loss: 0.0105\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 360us/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 353us/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 349us/step - loss: 0.0026 - val_loss: 0.0050\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 351us/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 350us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 350us/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 350us/step - loss: 0.0022 - val_loss: 0.0032\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 349us/step - loss: 0.0021 - val_loss: 0.0031\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 349us/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 349us/step - loss: 0.0019 - val_loss: 0.0034\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 350us/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 351us/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 351us/step - loss: 0.0016 - val_loss: 0.0025\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 352us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 354us/step - loss: 0.0015 - val_loss: 0.0029\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 351us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 349us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 349us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 348us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 24/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 1s 350us/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 2s 639us/step - loss: 0.4105 - val_loss: 0.0097\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 364us/step - loss: 0.1019 - val_loss: 0.1534\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 364us/step - loss: 0.0884 - val_loss: 0.0062\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 366us/step - loss: 0.0755 - val_loss: 0.0126\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 371us/step - loss: 0.0273 - val_loss: 0.0419\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 367us/step - loss: 0.0129 - val_loss: 0.0306\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 365us/step - loss: 0.0071 - val_loss: 0.0128\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 365us/step - loss: 0.0063 - val_loss: 0.0095\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 367us/step - loss: 0.0053 - val_loss: 0.0087\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 366us/step - loss: 0.0045 - val_loss: 0.0104\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 364us/step - loss: 0.0040 - val_loss: 0.0053\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 366us/step - loss: 0.0039 - val_loss: 0.0088\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 364us/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 365us/step - loss: 0.0036 - val_loss: 0.0075\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 369us/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 367us/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 366us/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 373us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 366us/step - loss: 0.0029 - val_loss: 0.0044\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 367us/step - loss: 0.0029 - val_loss: 0.0027\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 363us/step - loss: 0.0028 - val_loss: 0.0049\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 364us/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 365us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 370us/step - loss: 0.0028 - val_loss: 0.0040\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 2s 667us/step - loss: 0.1952 - val_loss: 0.0497\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 366us/step - loss: 0.0926 - val_loss: 0.0538\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 365us/step - loss: 0.0590 - val_loss: 0.0073\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 372us/step - loss: 0.0254 - val_loss: 0.0624\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 364us/step - loss: 0.0109 - val_loss: 0.0304\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 367us/step - loss: 0.0104 - val_loss: 0.0503\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 370us/step - loss: 0.0067 - val_loss: 0.0261\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 366us/step - loss: 0.0068 - val_loss: 0.0149\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 365us/step - loss: 0.0057 - val_loss: 0.0241\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 366us/step - loss: 0.0055 - val_loss: 0.0237\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 366us/step - loss: 0.0049 - val_loss: 0.0117\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 366us/step - loss: 0.0046 - val_loss: 0.0087\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 365us/step - loss: 0.0044 - val_loss: 0.0087\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 364us/step - loss: 0.0040 - val_loss: 0.0078\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 366us/step - loss: 0.0039 - val_loss: 0.0081\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 365us/step - loss: 0.0037 - val_loss: 0.0048\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 369us/step - loss: 0.0038 - val_loss: 0.0074\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 366us/step - loss: 0.0035 - val_loss: 0.0092\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 366us/step - loss: 0.0035 - val_loss: 0.0051\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 363us/step - loss: 0.0032 - val_loss: 0.0039\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 365us/step - loss: 0.0031 - val_loss: 0.0044\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 365us/step - loss: 0.0029 - val_loss: 0.0049\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 366us/step - loss: 0.0027 - val_loss: 0.0052\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 366us/step - loss: 0.0027 - val_loss: 0.0046\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 2s 670us/step - loss: 0.1492 - val_loss: 0.0691\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 366us/step - loss: 0.0729 - val_loss: 0.0081\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 373us/step - loss: 0.0370 - val_loss: 0.0219\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 367us/step - loss: 0.0132 - val_loss: 0.0578\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 367us/step - loss: 0.0086 - val_loss: 0.0312\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 366us/step - loss: 0.0063 - val_loss: 0.0070\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 366us/step - loss: 0.0056 - val_loss: 0.0130\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 367us/step - loss: 0.0051 - val_loss: 0.0127\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 369us/step - loss: 0.0047 - val_loss: 0.0075\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 369us/step - loss: 0.0043 - val_loss: 0.0084\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 367us/step - loss: 0.0040 - val_loss: 0.0084\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 369us/step - loss: 0.0039 - val_loss: 0.0061\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 368us/step - loss: 0.0037 - val_loss: 0.0058\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 367us/step - loss: 0.0034 - val_loss: 0.0049\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 367us/step - loss: 0.0034 - val_loss: 0.0051\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 374us/step - loss: 0.0032 - val_loss: 0.0044\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 369us/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 365us/step - loss: 0.0030 - val_loss: 0.0036\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 365us/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 367us/step - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 369us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 367us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 369us/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 366us/step - loss: 0.0025 - val_loss: 0.0049\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 2s 701us/step - loss: 0.0857 - val_loss: 0.0276\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 371us/step - loss: 0.0209 - val_loss: 0.0240\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 366us/step - loss: 0.0096 - val_loss: 0.0048\n",
      "Epoch 4/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 1s 365us/step - loss: 0.0065 - val_loss: 0.0145\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 366us/step - loss: 0.0052 - val_loss: 0.0027\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 366us/step - loss: 0.0045 - val_loss: 0.0061\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 365us/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 364us/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 367us/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 366us/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 368us/step - loss: 0.0033 - val_loss: 0.0043\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 366us/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 364us/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 372us/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 370us/step - loss: 0.0030 - val_loss: 0.0026\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 365us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 364us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 367us/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 366us/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 369us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 364us/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 366us/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 365us/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 365us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 2s 721us/step - loss: 0.0623 - val_loss: 0.0323\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 364us/step - loss: 0.0164 - val_loss: 0.0134\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 365us/step - loss: 0.0085 - val_loss: 0.0031\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 366us/step - loss: 0.0065 - val_loss: 0.0069\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 365us/step - loss: 0.0055 - val_loss: 0.0029\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 366us/step - loss: 0.0048 - val_loss: 0.0039\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 365us/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 365us/step - loss: 0.0040 - val_loss: 0.0035\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 364us/step - loss: 0.0038 - val_loss: 0.0033\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 364us/step - loss: 0.0036 - val_loss: 0.0032\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 364us/step - loss: 0.0036 - val_loss: 0.0033\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 366us/step - loss: 0.0034 - val_loss: 0.0028\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 369us/step - loss: 0.0033 - val_loss: 0.0029\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 364us/step - loss: 0.0033 - val_loss: 0.0026\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 366us/step - loss: 0.0033 - val_loss: 0.0026\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 365us/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 365us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 366us/step - loss: 0.0031 - val_loss: 0.0025\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 364us/step - loss: 0.0029 - val_loss: 0.0025\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 363us/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 365us/step - loss: 0.0029 - val_loss: 0.0023\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 365us/step - loss: 0.0028 - val_loss: 0.0023\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 367us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 364us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 3s 736us/step - loss: 0.0608 - val_loss: 0.0214\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 365us/step - loss: 0.0152 - val_loss: 0.0132\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 364us/step - loss: 0.0078 - val_loss: 0.0047\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 364us/step - loss: 0.0059 - val_loss: 0.0054\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 365us/step - loss: 0.0047 - val_loss: 0.0029\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 363us/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 364us/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 366us/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 365us/step - loss: 0.0034 - val_loss: 0.0027\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 363us/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 364us/step - loss: 0.0031 - val_loss: 0.0026\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 368us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 365us/step - loss: 0.0029 - val_loss: 0.0027\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 363us/step - loss: 0.0029 - val_loss: 0.0027\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 364us/step - loss: 0.0029 - val_loss: 0.0026\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 365us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 365us/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 365us/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 365us/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 364us/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 365us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 363us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 365us/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 369us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 3s 774us/step - loss: 0.0545 - val_loss: 0.0037\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 363us/step - loss: 0.0104 - val_loss: 0.0107\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 364us/step - loss: 0.0054 - val_loss: 0.0042\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 364us/step - loss: 0.0069 - val_loss: 0.0064\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 365us/step - loss: 0.0032 - val_loss: 0.0026\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 368us/step - loss: 0.0043 - val_loss: 0.0115\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 372us/step - loss: 0.0079 - val_loss: 0.0026\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 365us/step - loss: 0.0034 - val_loss: 0.0049\n",
      "Epoch 9/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 1s 367us/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 371us/step - loss: 0.0059 - val_loss: 0.0133\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 367us/step - loss: 0.0061 - val_loss: 0.0026\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 367us/step - loss: 0.0033 - val_loss: 0.0067\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 366us/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 367us/step - loss: 0.0038 - val_loss: 0.0085\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 365us/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 363us/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 367us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 364us/step - loss: 0.0022 - val_loss: 0.0059\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 364us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 366us/step - loss: 0.0046 - val_loss: 0.0056\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 365us/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 364us/step - loss: 0.0024 - val_loss: 0.0053\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 372us/step - loss: 0.0028 - val_loss: 0.0017\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 366us/step - loss: 0.0028 - val_loss: 0.0053\n",
      "\n",
      "GENERATION 1\n",
      "\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 3s 858us/step - loss: 0.1542 - val_loss: 0.0255\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 450us/step - loss: 0.0189 - val_loss: 0.0127\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 451us/step - loss: 0.0089 - val_loss: 0.0097\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 450us/step - loss: 0.0057 - val_loss: 0.0063\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 451us/step - loss: 0.0044 - val_loss: 0.0041\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 450us/step - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 455us/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 449us/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 452us/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 452us/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 449us/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 451us/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 449us/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 452us/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 450us/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 451us/step - loss: 0.0030 - val_loss: 0.0038\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 455us/step - loss: 0.0030 - val_loss: 0.0036\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 450us/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 453us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 450us/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 451us/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 451us/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 448us/step - loss: 0.0028 - val_loss: 0.0041\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 452us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 3s 779us/step - loss: 0.1084 - val_loss: 0.0128\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 352us/step - loss: 0.0243 - val_loss: 0.0092\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 355us/step - loss: 0.0120 - val_loss: 0.0040\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 352us/step - loss: 0.0071 - val_loss: 0.0040\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 351us/step - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 351us/step - loss: 0.0033 - val_loss: 0.0058\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 353us/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 352us/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 351us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 350us/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 351us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 350us/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 350us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 358us/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 351us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 350us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 352us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 351us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 349us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 350us/step - loss: 0.0016 - val_loss: 0.0025\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 350us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 351us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 350us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 350us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 3s 799us/step - loss: 0.1141 - val_loss: 0.0242\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 336us/step - loss: 0.0163 - val_loss: 0.0047\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 336us/step - loss: 0.0077 - val_loss: 0.0058\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 334us/step - loss: 0.0054 - val_loss: 0.0123\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 342us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 336us/step - loss: 0.0032 - val_loss: 0.0048\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 337us/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 334us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 335us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 337us/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 337us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 337us/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 338us/step - loss: 0.0021 - val_loss: 0.0032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 339us/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 336us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 336us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 336us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 335us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 335us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 337us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 335us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 336us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 335us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 336us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 3s 808us/step - loss: 0.2347 - val_loss: 0.1388\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 337us/step - loss: 0.0508 - val_loss: 0.0187\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 335us/step - loss: 0.0209 - val_loss: 0.0284\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 337us/step - loss: 0.0083 - val_loss: 0.0073\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 336us/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 335us/step - loss: 0.0036 - val_loss: 0.0057\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 337us/step - loss: 0.0030 - val_loss: 0.0038\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 337us/step - loss: 0.0028 - val_loss: 0.0041\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 336us/step - loss: 0.0025 - val_loss: 0.0042\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 336us/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 337us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 335us/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 344us/step - loss: 0.0021 - val_loss: 0.0031\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 336us/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 335us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 335us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 336us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 337us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 336us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 336us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 335us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 336us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 335us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 336us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 3s 852us/step - loss: 0.1769 - val_loss: 0.0227\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 355us/step - loss: 0.0300 - val_loss: 0.0320\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 356us/step - loss: 0.0158 - val_loss: 0.0227\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 356us/step - loss: 0.0075 - val_loss: 0.0048\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 354us/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 355us/step - loss: 0.0031 - val_loss: 0.0061\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 354us/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 353us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 355us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 354us/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 356us/step - loss: 0.0022 - val_loss: 0.0033\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 363us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 354us/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 355us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 355us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 356us/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 355us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 356us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 355us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 354us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 356us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 354us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 355us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 352us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 3s 863us/step - loss: 0.0753 - val_loss: 0.0072\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 374us/step - loss: 0.0116 - val_loss: 0.0149\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 374us/step - loss: 0.0056 - val_loss: 0.0034\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 375us/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 374us/step - loss: 0.0030 - val_loss: 0.0058\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 376us/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 375us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 375us/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 376us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 383us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 375us/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 374us/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 375us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 376us/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 376us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 374us/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 376us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 375us/step - loss: 0.0019 - val_loss: 0.0026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 374us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 375us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 374us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 381us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 375us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 375us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 3s 919us/step - loss: 0.0765 - val_loss: 0.0235\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 392us/step - loss: 0.0192 - val_loss: 0.0139\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 392us/step - loss: 0.0104 - val_loss: 0.0041\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 392us/step - loss: 0.0075 - val_loss: 0.0039\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 393us/step - loss: 0.0059 - val_loss: 0.0052\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 398us/step - loss: 0.0053 - val_loss: 0.0038\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 393us/step - loss: 0.0050 - val_loss: 0.0047\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 393us/step - loss: 0.0050 - val_loss: 0.0036\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 392us/step - loss: 0.0045 - val_loss: 0.0036\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 392us/step - loss: 0.0048 - val_loss: 0.0038\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 392us/step - loss: 0.0048 - val_loss: 0.0035\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 390us/step - loss: 0.0046 - val_loss: 0.0036\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 391us/step - loss: 0.0045 - val_loss: 0.0034\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 392us/step - loss: 0.0043 - val_loss: 0.0034\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 391us/step - loss: 0.0043 - val_loss: 0.0033\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 391us/step - loss: 0.0041 - val_loss: 0.0033\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 391us/step - loss: 0.0044 - val_loss: 0.0032\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 395us/step - loss: 0.0041 - val_loss: 0.0032\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 393us/step - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 392us/step - loss: 0.0037 - val_loss: 0.0032\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 390us/step - loss: 0.0039 - val_loss: 0.0031\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 393us/step - loss: 0.0038 - val_loss: 0.0031\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 391us/step - loss: 0.0040 - val_loss: 0.0031\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 393us/step - loss: 0.0037 - val_loss: 0.0030\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 3s 939us/step - loss: 0.2403 - val_loss: 0.0042\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 394us/step - loss: 0.0312 - val_loss: 0.0237\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 395us/step - loss: 0.0301 - val_loss: 0.0045\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 392us/step - loss: 0.0237 - val_loss: 0.0034\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 392us/step - loss: 0.0139 - val_loss: 0.0035\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 391us/step - loss: 0.0066 - val_loss: 0.0055\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 393us/step - loss: 0.0051 - val_loss: 0.0055\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 392us/step - loss: 0.0053 - val_loss: 0.0062\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 390us/step - loss: 0.0049 - val_loss: 0.0052\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 393us/step - loss: 0.0045 - val_loss: 0.0041\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 392us/step - loss: 0.0043 - val_loss: 0.0050\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 393us/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 391us/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 397us/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 395us/step - loss: 0.0039 - val_loss: 0.0044\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 391us/step - loss: 0.0038 - val_loss: 0.0041\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 392us/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 392us/step - loss: 0.0037 - val_loss: 0.0040\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 392us/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 393us/step - loss: 0.0036 - val_loss: 0.0043\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 392us/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 391us/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 392us/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 392us/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 3s 937us/step - loss: 0.2859 - val_loss: 0.0884\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 370us/step - loss: 0.0761 - val_loss: 0.0054\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 388us/step - loss: 0.0401 - val_loss: 0.0069\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 381us/step - loss: 0.0120 - val_loss: 0.0081\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 367us/step - loss: 0.0086 - val_loss: 0.0065\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 367us/step - loss: 0.0063 - val_loss: 0.0096\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 367us/step - loss: 0.0057 - val_loss: 0.0048\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 367us/step - loss: 0.0055 - val_loss: 0.0053\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 366us/step - loss: 0.0047 - val_loss: 0.0060\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 367us/step - loss: 0.0047 - val_loss: 0.0055\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 373us/step - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 367us/step - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 367us/step - loss: 0.0040 - val_loss: 0.0048\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 366us/step - loss: 0.0039 - val_loss: 0.0054\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 365us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 367us/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 366us/step - loss: 0.0038 - val_loss: 0.0047\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 367us/step - loss: 0.0038 - val_loss: 0.0053\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 364us/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 367us/step - loss: 0.0037 - val_loss: 0.0043\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 367us/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 366us/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 370us/step - loss: 0.0032 - val_loss: 0.0038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 370us/step - loss: 0.0034 - val_loss: 0.0043\n",
      "\n",
      "GENERATION 2\n",
      "\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 3s 1000us/step - loss: 2.0825 - val_loss: 0.0031\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 435us/step - loss: 0.0043 - val_loss: 0.0029\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 434us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 436us/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 434us/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 433us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 440us/step - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 433us/step - loss: 0.0033 - val_loss: 0.0040\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 434us/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 434us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 433us/step - loss: 0.0020 - val_loss: 0.0032\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 434us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 434us/step - loss: 0.0021 - val_loss: 0.0033\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 432us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 434us/step - loss: 0.0020 - val_loss: 0.0032\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 434us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 434us/step - loss: 0.0020 - val_loss: 0.0033\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 437us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 433us/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 433us/step - loss: 0.0018 - val_loss: 0.0033\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 433us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 434us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 436us/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 433us/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 3s 968us/step - loss: 0.1295 - val_loss: 0.0791\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 337us/step - loss: 0.0258 - val_loss: 0.0163\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 337us/step - loss: 0.0105 - val_loss: 0.0115\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 336us/step - loss: 0.0055 - val_loss: 0.0035\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 335us/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 336us/step - loss: 0.0030 - val_loss: 0.0049\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 337us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 337us/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 338us/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 336us/step - loss: 0.0021 - val_loss: 0.0031\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 337us/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 337us/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 336us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 345us/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 336us/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 337us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 338us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 341us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 335us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 336us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 337us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 335us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 338us/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 337us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 3s 975us/step - loss: 0.0813 - val_loss: 0.0253\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 337us/step - loss: 0.0175 - val_loss: 0.0181\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 336us/step - loss: 0.0087 - val_loss: 0.0048\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 337us/step - loss: 0.0057 - val_loss: 0.0062\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 336us/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 336us/step - loss: 0.0033 - val_loss: 0.0045\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 337us/step - loss: 0.0030 - val_loss: 0.0055\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 337us/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 337us/step - loss: 0.0027 - val_loss: 0.0046\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 336us/step - loss: 0.0027 - val_loss: 0.0041\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 337us/step - loss: 0.0026 - val_loss: 0.0041\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 340us/step - loss: 0.0026 - val_loss: 0.0039\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 342us/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 335us/step - loss: 0.0025 - val_loss: 0.0038\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 337us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 337us/step - loss: 0.0024 - val_loss: 0.0036\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 336us/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 336us/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 337us/step - loss: 0.0022 - val_loss: 0.0036\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 337us/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 337us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 337us/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 338us/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 337us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 3s 999us/step - loss: 0.0879 - val_loss: 0.0106\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 342us/step - loss: 0.0106 - val_loss: 0.0052\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 343us/step - loss: 0.0051 - val_loss: 0.0028\n",
      "Epoch 4/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 1s 342us/step - loss: 0.0035 - val_loss: 0.0069\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 342us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 344us/step - loss: 0.0025 - val_loss: 0.0056\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 341us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 342us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 343us/step - loss: 0.0022 - val_loss: 0.0033\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 344us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 349us/step - loss: 0.0021 - val_loss: 0.0035\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 343us/step - loss: 0.0021 - val_loss: 0.0034\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 342us/step - loss: 0.0021 - val_loss: 0.0033\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 343us/step - loss: 0.0020 - val_loss: 0.0033\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 344us/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 341us/step - loss: 0.0020 - val_loss: 0.0032\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 343us/step - loss: 0.0020 - val_loss: 0.0030\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 343us/step - loss: 0.0019 - val_loss: 0.0031\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 343us/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 342us/step - loss: 0.0019 - val_loss: 0.0030\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 343us/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 358us/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 353us/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 352us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 3s 999us/step - loss: 1.0040 - val_loss: 0.0249\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 342us/step - loss: 0.0298 - val_loss: 0.0053\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 343us/step - loss: 0.0149 - val_loss: 0.0039\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 343us/step - loss: 0.0060 - val_loss: 0.0047\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 342us/step - loss: 0.0035 - val_loss: 0.0049\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 343us/step - loss: 0.0032 - val_loss: 0.0048\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 356us/step - loss: 0.0032 - val_loss: 0.0050\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 349us/step - loss: 0.0031 - val_loss: 0.0059\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 346us/step - loss: 0.0031 - val_loss: 0.0050\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 343us/step - loss: 0.0031 - val_loss: 0.0041\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 342us/step - loss: 0.0031 - val_loss: 0.0055\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 343us/step - loss: 0.0030 - val_loss: 0.0043\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 342us/step - loss: 0.0030 - val_loss: 0.0047\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 344us/step - loss: 0.0029 - val_loss: 0.0045\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 342us/step - loss: 0.0029 - val_loss: 0.0048\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 341us/step - loss: 0.0029 - val_loss: 0.0051\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 344us/step - loss: 0.0028 - val_loss: 0.0044\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 344us/step - loss: 0.0028 - val_loss: 0.0045\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 342us/step - loss: 0.0028 - val_loss: 0.0044\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 343us/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 343us/step - loss: 0.0027 - val_loss: 0.0045\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 351us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 345us/step - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 343us/step - loss: 0.0026 - val_loss: 0.0039\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 4s 1ms/step - loss: 0.1274 - val_loss: 0.0111\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 346us/step - loss: 0.0079 - val_loss: 0.0083\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 344us/step - loss: 0.0112 - val_loss: 0.0096\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 344us/step - loss: 0.0062 - val_loss: 0.0076\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 344us/step - loss: 0.0071 - val_loss: 0.0107\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 348us/step - loss: 0.0065 - val_loss: 0.0096\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 344us/step - loss: 0.0066 - val_loss: 0.0083\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 343us/step - loss: 0.0048 - val_loss: 0.0074\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 343us/step - loss: 0.0047 - val_loss: 0.0091\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 344us/step - loss: 0.0047 - val_loss: 0.0031\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 345us/step - loss: 0.0031 - val_loss: 0.0095\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 343us/step - loss: 0.0052 - val_loss: 0.0051\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 344us/step - loss: 0.0039 - val_loss: 0.0103\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 343us/step - loss: 0.0054 - val_loss: 0.0040\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 350us/step - loss: 0.0032 - val_loss: 0.0067\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 345us/step - loss: 0.0040 - val_loss: 0.0035\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 345us/step - loss: 0.0032 - val_loss: 0.0065\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 346us/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 347us/step - loss: 0.0032 - val_loss: 0.0089\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 346us/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 343us/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 345us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 345us/step - loss: 0.0029 - val_loss: 0.0082\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 344us/step - loss: 0.0033 - val_loss: 0.0022\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 4s 1ms/step - loss: 0.0745 - val_loss: 0.0114\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 343us/step - loss: 0.0164 - val_loss: 0.0153\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 351us/step - loss: 0.0127 - val_loss: 0.0236\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 346us/step - loss: 0.0128 - val_loss: 0.0091\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 344us/step - loss: 0.0108 - val_loss: 0.0221\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 345us/step - loss: 0.0098 - val_loss: 0.0065\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 346us/step - loss: 0.0056 - val_loss: 0.0111\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 344us/step - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 9/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 1s 344us/step - loss: 0.0048 - val_loss: 0.0100\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 343us/step - loss: 0.0058 - val_loss: 0.0063\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 343us/step - loss: 0.0067 - val_loss: 0.0137\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 345us/step - loss: 0.0077 - val_loss: 0.0050\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 343us/step - loss: 0.0059 - val_loss: 0.0122\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 346us/step - loss: 0.0057 - val_loss: 0.0058\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 345us/step - loss: 0.0058 - val_loss: 0.0117\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 346us/step - loss: 0.0050 - val_loss: 0.0040\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 352us/step - loss: 0.0050 - val_loss: 0.0131\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 346us/step - loss: 0.0064 - val_loss: 0.0057\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 345us/step - loss: 0.0053 - val_loss: 0.0091\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 344us/step - loss: 0.0044 - val_loss: 0.0082\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 346us/step - loss: 0.0070 - val_loss: 0.0100\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 344us/step - loss: 0.0053 - val_loss: 0.0054\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 346us/step - loss: 0.0068 - val_loss: 0.0096\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 346us/step - loss: 0.0046 - val_loss: 0.0037\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 4s 1ms/step - loss: 0.0790 - val_loss: 0.0253\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 346us/step - loss: 0.0209 - val_loss: 0.0189\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 343us/step - loss: 0.0142 - val_loss: 0.0157\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 344us/step - loss: 0.0103 - val_loss: 0.0082\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 345us/step - loss: 0.0084 - val_loss: 0.0155\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 345us/step - loss: 0.0088 - val_loss: 0.0071\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 344us/step - loss: 0.0063 - val_loss: 0.0137\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 346us/step - loss: 0.0058 - val_loss: 0.0054\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 346us/step - loss: 0.0060 - val_loss: 0.0097\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 346us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 345us/step - loss: 0.0065 - val_loss: 0.0140\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 345us/step - loss: 0.0061 - val_loss: 0.0065\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 350us/step - loss: 0.0062 - val_loss: 0.0114\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 346us/step - loss: 0.0057 - val_loss: 0.0057\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 344us/step - loss: 0.0054 - val_loss: 0.0138\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 345us/step - loss: 0.0068 - val_loss: 0.0130\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 345us/step - loss: 0.0070 - val_loss: 0.0087\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 344us/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 342us/step - loss: 0.0040 - val_loss: 0.0101\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 344us/step - loss: 0.0065 - val_loss: 0.0099\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 345us/step - loss: 0.0060 - val_loss: 0.0067\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 346us/step - loss: 0.0042 - val_loss: 0.0081\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 345us/step - loss: 0.0063 - val_loss: 0.0079\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 344us/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 4s 1ms/step - loss: 0.0905 - val_loss: 0.0101\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 346us/step - loss: 0.0114 - val_loss: 0.0175\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 345us/step - loss: 0.0104 - val_loss: 0.0105\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 346us/step - loss: 0.0080 - val_loss: 0.0125\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 358us/step - loss: 0.0061 - val_loss: 0.0040\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 353us/step - loss: 0.0047 - val_loss: 0.0122\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 346us/step - loss: 0.0057 - val_loss: 0.0056\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 344us/step - loss: 0.0049 - val_loss: 0.0087\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 343us/step - loss: 0.0046 - val_loss: 0.0063\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 352us/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 344us/step - loss: 0.0050 - val_loss: 0.0047\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 345us/step - loss: 0.0042 - val_loss: 0.0107\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 345us/step - loss: 0.0055 - val_loss: 0.0046\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 343us/step - loss: 0.0045 - val_loss: 0.0084\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 345us/step - loss: 0.0055 - val_loss: 0.0079\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 344us/step - loss: 0.0047 - val_loss: 0.0107\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 346us/step - loss: 0.0062 - val_loss: 0.0065\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 346us/step - loss: 0.0065 - val_loss: 0.0154\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 345us/step - loss: 0.0095 - val_loss: 0.0035\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 344us/step - loss: 0.0031 - val_loss: 0.0049\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 348us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 343us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 348us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 347us/step - loss: 0.0044 - val_loss: 0.0100\n",
      "\n",
      "GENERATION 3\n",
      "\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 5s 1ms/step - loss: 0.1443 - val_loss: 0.1756\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 521us/step - loss: 0.0422 - val_loss: 0.0230\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 514us/step - loss: 0.0153 - val_loss: 0.0212\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 513us/step - loss: 0.0155 - val_loss: 0.0147\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 519us/step - loss: 0.0151 - val_loss: 0.0167\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 0.0121 - val_loss: 0.0260\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 512us/step - loss: 0.0111 - val_loss: 0.0253\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 513us/step - loss: 0.0139 - val_loss: 0.0196\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 512us/step - loss: 0.0100 - val_loss: 0.0241\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 513us/step - loss: 0.0106 - val_loss: 0.0212\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 512us/step - loss: 0.0126 - val_loss: 0.0091\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 511us/step - loss: 0.0082 - val_loss: 0.0215\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 513us/step - loss: 0.0073 - val_loss: 0.0066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 517us/step - loss: 0.0109 - val_loss: 0.0205\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 514us/step - loss: 0.0060 - val_loss: 0.0059\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 513us/step - loss: 0.0067 - val_loss: 0.0184\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 512us/step - loss: 0.0093 - val_loss: 0.0168\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 515us/step - loss: 0.0070 - val_loss: 0.0117\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 520us/step - loss: 0.0055 - val_loss: 0.0090\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 513us/step - loss: 0.0074 - val_loss: 0.0169\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 515us/step - loss: 0.0051 - val_loss: 0.0041\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 515us/step - loss: 0.0069 - val_loss: 0.0178\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 519us/step - loss: 0.0042 - val_loss: 0.0034\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 512us/step - loss: 0.0085 - val_loss: 0.0136\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 4s 1ms/step - loss: 0.1005 - val_loss: 0.0266\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 340us/step - loss: 0.0171 - val_loss: 0.0110\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 337us/step - loss: 0.0089 - val_loss: 0.0090\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 341us/step - loss: 0.0051 - val_loss: 0.0039\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 346us/step - loss: 0.0035 - val_loss: 0.0057\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 340us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 340us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 340us/step - loss: 0.0025 - val_loss: 0.0038\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 338us/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 337us/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 338us/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 336us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 339us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 338us/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 338us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 338us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 339us/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 341us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 344us/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 338us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 339us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 338us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 339us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 340us/step - loss: 0.0013 - val_loss: 0.0025\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 4s 1ms/step - loss: 0.1551 - val_loss: 0.0479\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 339us/step - loss: 0.0353 - val_loss: 0.0250\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 340us/step - loss: 0.0141 - val_loss: 0.0147\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 339us/step - loss: 0.0056 - val_loss: 0.0040\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 340us/step - loss: 0.0037 - val_loss: 0.0043\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 340us/step - loss: 0.0033 - val_loss: 0.0055\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 339us/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 338us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 338us/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 340us/step - loss: 0.0024 - val_loss: 0.0036\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 341us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 338us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 339us/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 337us/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 346us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 339us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 340us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 339us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 339us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 340us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 339us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 339us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 341us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 341us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 5s 1ms/step - loss: 0.1216 - val_loss: 0.0046\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 355us/step - loss: 0.0226 - val_loss: 0.0041\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 353us/step - loss: 0.0117 - val_loss: 0.0093\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 352us/step - loss: 0.0084 - val_loss: 0.0065\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 353us/step - loss: 0.0062 - val_loss: 0.0088\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 361us/step - loss: 0.0053 - val_loss: 0.0040\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 357us/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 353us/step - loss: 0.0040 - val_loss: 0.0053\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 354us/step - loss: 0.0039 - val_loss: 0.0042\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 361us/step - loss: 0.0035 - val_loss: 0.0050\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 355us/step - loss: 0.0034 - val_loss: 0.0053\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 352us/step - loss: 0.0033 - val_loss: 0.0065\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 354us/step - loss: 0.0033 - val_loss: 0.0062\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 354us/step - loss: 0.0032 - val_loss: 0.0068\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 353us/step - loss: 0.0030 - val_loss: 0.0071\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 354us/step - loss: 0.0029 - val_loss: 0.0065\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 355us/step - loss: 0.0028 - val_loss: 0.0078\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 354us/step - loss: 0.0028 - val_loss: 0.0084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 354us/step - loss: 0.0027 - val_loss: 0.0071\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 354us/step - loss: 0.0026 - val_loss: 0.0078\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 355us/step - loss: 0.0024 - val_loss: 0.0084\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 353us/step - loss: 0.0025 - val_loss: 0.0094\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 356us/step - loss: 0.0023 - val_loss: 0.0091\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 355us/step - loss: 0.0022 - val_loss: 0.0109\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 5s 1ms/step - loss: 0.0889 - val_loss: 0.0085\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 0.0117 - val_loss: 0.0168\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 0.0064 - val_loss: 0.0041\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 0.0036 - val_loss: 0.0047\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 5s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 483us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 483us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: nan - val_loss: nan\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 5s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 391us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 397us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 391us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 390us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 389us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 392us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 390us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 388us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 389us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 390us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 387us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 390us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 389us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 397us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 390us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 390us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 388us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 391us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 391us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 389us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 390us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 389us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 389us/step - loss: nan - val_loss: nan\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 6s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 527us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 525us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 530us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 528us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 532us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 527us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 529us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 526us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 527us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 527us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 526us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 529us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 527us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 531us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 525us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 527us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 527us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 527us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 526us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 528us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 526us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 527us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 532us/step - loss: nan - val_loss: nan\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 6s 2ms/step - loss: 567326982073612511816257110016.0000 - val_loss: 659344225789364142080.0000\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 529us/step - loss: 583772579387282833516003328.0000 - val_loss: 659344225789364142080.0000\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 531us/step - loss: 8035254801158064872928313344.0000 - val_loss: 659344225789364142080.0000\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 529us/step - loss: 1655280679386882546802972688384.0000 - val_loss: 659344225789364142080.0000\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 529us/step - loss: 801553911767703900145628150235136.0000 - val_loss: 659344225789364142080.0000\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 527us/step - loss: 192696870798701182539180015616.0000 - val_loss: 659344085051875786752.0000\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 524us/step - loss: 32121850609726130344605777920.0000 - val_loss: 659343099889457299456.0000\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 528us/step - loss: 41833970287068479644749529088.0000 - val_loss: 659326422497087193088.0000\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 529us/step - loss: 277093455929501975196908273008640.0000 - val_loss: 659318541197739294720.0000\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 527us/step - loss: 2629447301504447044115008323584.0000 - val_loss: 659317415297832452096.0000\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 529us/step - loss: 22101394125199236738976841728.0000 - val_loss: 659317274560344096768.0000\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 536us/step - loss: 13541975503399939804892233728.0000 - val_loss: 659317063454111563776.0000\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 527us/step - loss: 5485595437399713739130252820480.0000 - val_loss: 659316852347879030784.0000\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 529us/step - loss: 15362227255485151653420655968256.0000 - val_loss: 659316781979134853120.0000\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 526us/step - loss: 84565984556633060107396055040.0000 - val_loss: 659316781979134853120.0000\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 528us/step - loss: 498508038274675168107298816.0000 - val_loss: 659316781979134853120.0000\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 529us/step - loss: 38784175065014268739549396992.0000 - val_loss: 659316781979134853120.0000\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 527us/step - loss: 7348350391468865171914489856.0000 - val_loss: 659316781979134853120.0000\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 526us/step - loss: 1307750196529513784339681247232.0000 - val_loss: 659316781979134853120.0000\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 529us/step - loss: 45187902933488323656041889792.0000 - val_loss: 659316781979134853120.0000\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 533us/step - loss: 35813330602985529085744119808.0000 - val_loss: 659316781979134853120.0000\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 530us/step - loss: 1351307522016521356430016512.0000 - val_loss: 659316781979134853120.0000\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 526us/step - loss: 261159535326189688867266756608.0000 - val_loss: 659316570872902320128.0000\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 527us/step - loss: 3140351037920391914219110400.0000 - val_loss: 659316078291693076480.0000\n",
      "\n",
      "GENERATION 4\n",
      "\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 6s 2ms/step - loss: 0.7313 - val_loss: 0.2047\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 457us/step - loss: 0.2138 - val_loss: 0.0271\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 453us/step - loss: 0.0975 - val_loss: 0.1287\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 456us/step - loss: 0.0860 - val_loss: 0.0201\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 457us/step - loss: 0.0745 - val_loss: 0.0072\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 458us/step - loss: 0.0576 - val_loss: 0.0064\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 456us/step - loss: 0.0208 - val_loss: 0.0694\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 458us/step - loss: 0.0105 - val_loss: 0.0593\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 457us/step - loss: 0.0087 - val_loss: 0.0323\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 465us/step - loss: 0.0068 - val_loss: 0.0661\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 457us/step - loss: 0.0064 - val_loss: 0.0495\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 456us/step - loss: 0.0061 - val_loss: 0.0490\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 460us/step - loss: 0.0057 - val_loss: 0.0306\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 457us/step - loss: 0.0054 - val_loss: 0.0108\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0049 - val_loss: 0.0066\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 458us/step - loss: 0.0043 - val_loss: 0.0074\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 457us/step - loss: 0.0042 - val_loss: 0.0081\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 457us/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 460us/step - loss: 0.0036 - val_loss: 0.0076\n",
      "Epoch 21/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 457us/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 458us/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 458us/step - loss: 0.0032 - val_loss: 0.0046\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 457us/step - loss: 0.0030 - val_loss: 0.0041\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 6s 2ms/step - loss: 0.1232 - val_loss: 0.0065\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 440us/step - loss: 0.0148 - val_loss: 0.0168\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 438us/step - loss: 0.0063 - val_loss: 0.0041\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 440us/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 436us/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 439us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 437us/step - loss: 0.0024 - val_loss: 0.0041\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 439us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 439us/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 445us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 441us/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 436us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 439us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 439us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 439us/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 439us/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 438us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 439us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 440us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 443us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 439us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 439us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 440us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 439us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 6s 2ms/step - loss: 0.2197 - val_loss: 0.0993\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 439us/step - loss: 0.0869 - val_loss: 0.0069\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 441us/step - loss: 0.0596 - val_loss: 0.0099\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 440us/step - loss: 0.0206 - val_loss: 0.1472\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 440us/step - loss: 0.0101 - val_loss: 0.0358\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 437us/step - loss: 0.0063 - val_loss: 0.0356\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 439us/step - loss: 0.0051 - val_loss: 0.0245\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 439us/step - loss: 0.0044 - val_loss: 0.0112\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 439us/step - loss: 0.0039 - val_loss: 0.0095\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 447us/step - loss: 0.0032 - val_loss: 0.0052\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 440us/step - loss: 0.0029 - val_loss: 0.0067\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 439us/step - loss: 0.0026 - val_loss: 0.0040\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 441us/step - loss: 0.0024 - val_loss: 0.0055\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 439us/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 440us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 439us/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 439us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 438us/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 440us/step - loss: 0.0019 - val_loss: 0.0056\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 440us/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 446us/step - loss: 0.0018 - val_loss: 0.0035\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 440us/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 437us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 439us/step - loss: 0.0017 - val_loss: 0.0036\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 6s 2ms/step - loss: 0.1653 - val_loss: 0.0596\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 458us/step - loss: 0.0836 - val_loss: 0.0073\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 458us/step - loss: 0.0479 - val_loss: 0.0219\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 457us/step - loss: 0.0158 - val_loss: 0.0499\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 461us/step - loss: 0.0105 - val_loss: 0.0725\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0079 - val_loss: 0.0099\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0066 - val_loss: 0.0083\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 461us/step - loss: 0.0055 - val_loss: 0.0313\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0052 - val_loss: 0.0151\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 462us/step - loss: 0.0046 - val_loss: 0.0088\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0043 - val_loss: 0.0086\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 457us/step - loss: 0.0040 - val_loss: 0.0079\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0036 - val_loss: 0.0067\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 457us/step - loss: 0.0034 - val_loss: 0.0051\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 458us/step - loss: 0.0032 - val_loss: 0.0044\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0031 - val_loss: 0.0053\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 458us/step - loss: 0.0029 - val_loss: 0.0041\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 462us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 461us/step - loss: 0.0025 - val_loss: 0.0046\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 458us/step - loss: 0.0024 - val_loss: 0.0036\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 464us/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 6s 2ms/step - loss: 0.0858 - val_loss: 0.0390\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 379us/step - loss: 0.0182 - val_loss: 0.0103\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 379us/step - loss: 0.0095 - val_loss: 0.0029\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 378us/step - loss: 0.0066 - val_loss: 0.0047\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 379us/step - loss: 0.0055 - val_loss: 0.0036\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 380us/step - loss: 0.0047 - val_loss: 0.0030\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 379us/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 378us/step - loss: 0.0040 - val_loss: 0.0027\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 380us/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 383us/step - loss: 0.0036 - val_loss: 0.0031\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 381us/step - loss: 0.0036 - val_loss: 0.0031\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 379us/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 380us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 380us/step - loss: 0.0031 - val_loss: 0.0027\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 379us/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 380us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 381us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 382us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 380us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 378us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 379us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 384us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 380us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 381us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 6s 2ms/step - loss: 0.2735 - val_loss: 0.0434\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 382us/step - loss: 0.0404 - val_loss: 0.0061\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 379us/step - loss: 0.0191 - val_loss: 0.0123\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 379us/step - loss: 0.0123 - val_loss: 0.0030\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 380us/step - loss: 0.0091 - val_loss: 0.0131\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 380us/step - loss: 0.0076 - val_loss: 0.0029\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 383us/step - loss: 0.0067 - val_loss: 0.0069\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 379us/step - loss: 0.0060 - val_loss: 0.0032\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 382us/step - loss: 0.0054 - val_loss: 0.0044\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 380us/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 379us/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 380us/step - loss: 0.0046 - val_loss: 0.0041\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 385us/step - loss: 0.0043 - val_loss: 0.0040\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 381us/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 379us/step - loss: 0.0040 - val_loss: 0.0035\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 381us/step - loss: 0.0038 - val_loss: 0.0032\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 380us/step - loss: 0.0039 - val_loss: 0.0034\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 379us/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 380us/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 380us/step - loss: 0.0035 - val_loss: 0.0031\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 379us/step - loss: 0.0034 - val_loss: 0.0029\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 381us/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 380us/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 379us/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 6s 2ms/step - loss: 0.4381 - val_loss: 0.0712\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 378us/step - loss: 0.1076 - val_loss: 0.1822\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 380us/step - loss: 0.0987 - val_loss: 0.0088\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 387us/step - loss: 0.0738 - val_loss: 0.0088\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 379us/step - loss: 0.0419 - val_loss: 0.0051\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 379us/step - loss: 0.0116 - val_loss: 0.0054\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 381us/step - loss: 0.0094 - val_loss: 0.0159\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 381us/step - loss: 0.0056 - val_loss: 0.0179\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 379us/step - loss: 0.0052 - val_loss: 0.0057\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 381us/step - loss: 0.0042 - val_loss: 0.0071\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 379us/step - loss: 0.0040 - val_loss: 0.0086\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 380us/step - loss: 0.0038 - val_loss: 0.0059\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 378us/step - loss: 0.0036 - val_loss: 0.0053\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 381us/step - loss: 0.0036 - val_loss: 0.0055\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 380us/step - loss: 0.0035 - val_loss: 0.0055\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 385us/step - loss: 0.0033 - val_loss: 0.0062\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 386us/step - loss: 0.0033 - val_loss: 0.0058\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 378us/step - loss: 0.0032 - val_loss: 0.0048\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 382us/step - loss: 0.0031 - val_loss: 0.0044\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 387us/step - loss: 0.0030 - val_loss: 0.0046\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 379us/step - loss: 0.0029 - val_loss: 0.0048\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 380us/step - loss: 0.0029 - val_loss: 0.0045\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 381us/step - loss: 0.0029 - val_loss: 0.0044\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 381us/step - loss: 0.0029 - val_loss: 0.0041\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 6s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 378us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 378us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 379us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 380us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 1s 381us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 386us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 382us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 378us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 380us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 383us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 379us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 379us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 380us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 380us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 379us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 379us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 380us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 382us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 386us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 382us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 378us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 379us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 380us/step - loss: nan - val_loss: nan\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 7s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 503us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 502us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 501us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 501us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 502us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 500us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 504us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 500us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 500us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 501us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 502us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 501us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 502us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 501us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 501us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 507us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 503us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 504us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 501us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 503us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 501us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 502us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 502us/step - loss: nan - val_loss: nan\n",
      "\n",
      "GENERATION 5\n",
      "\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 7s 2ms/step - loss: 0.1087 - val_loss: 0.0048\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 441us/step - loss: 0.0165 - val_loss: 0.0087\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 439us/step - loss: 0.0073 - val_loss: 0.0069\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 441us/step - loss: 0.0044 - val_loss: 0.0041\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 443us/step - loss: 0.0029 - val_loss: 0.0056\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 439us/step - loss: 0.0026 - val_loss: 0.0039\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 438us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 439us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 438us/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 441us/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 438us/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 438us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 440us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 437us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 443us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 437us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 439us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 440us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 439us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 441us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 439us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 439us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 439us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 441us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 7s 2ms/step - loss: 0.1284 - val_loss: 0.0121\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 440us/step - loss: 0.0170 - val_loss: 0.0059\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 449us/step - loss: 0.0082 - val_loss: 0.0070\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 442us/step - loss: 0.0050 - val_loss: 0.0099\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 440us/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 441us/step - loss: 0.0030 - val_loss: 0.0035\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 439us/step - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 442us/step - loss: 0.0025 - val_loss: 0.0041\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 441us/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 441us/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 441us/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 443us/step - loss: 0.0020 - val_loss: 0.0030\n",
      "Epoch 13/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 446us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 442us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 444us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 439us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 441us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 439us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 442us/step - loss: 0.0014 - val_loss: 0.0022\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 440us/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 442us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 439us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 441us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 446us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 8s 2ms/step - loss: 0.1071 - val_loss: 0.0267\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 565us/step - loss: 0.0214 - val_loss: 0.0259\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0098 - val_loss: 0.0076\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 565us/step - loss: 0.0057 - val_loss: 0.0070\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 566us/step - loss: 0.0038 - val_loss: 0.0033\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 566us/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 564us/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 564us/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 565us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 565us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 566us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 564us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 567us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 568us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 565us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 580us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 568us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 565us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 567us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 568us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 565us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 568us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 563us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 8s 2ms/step - loss: 0.3277 - val_loss: 0.0065\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 568us/step - loss: 0.0810 - val_loss: 0.0957\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 568us/step - loss: 0.0999 - val_loss: 0.0999\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 566us/step - loss: 0.0846 - val_loss: 0.0412\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 566us/step - loss: 0.0746 - val_loss: 0.0174\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 566us/step - loss: 0.0764 - val_loss: 0.0203\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 567us/step - loss: 0.0742 - val_loss: 0.0326\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 566us/step - loss: 0.0737 - val_loss: 0.0387\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 567us/step - loss: 0.0738 - val_loss: 0.0336\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0735 - val_loss: 0.0293\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0735 - val_loss: 0.0300\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 566us/step - loss: 0.0735 - val_loss: 0.0322\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 566us/step - loss: 0.0735 - val_loss: 0.0319\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 567us/step - loss: 0.0735 - val_loss: 0.0320\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 568us/step - loss: 0.0734 - val_loss: 0.0318\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 567us/step - loss: 0.0734 - val_loss: 0.0319\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 567us/step - loss: 0.0733 - val_loss: 0.0307\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0731 - val_loss: 0.0317\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0731 - val_loss: 0.0315\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 567us/step - loss: 0.0733 - val_loss: 0.0324\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 566us/step - loss: 0.0730 - val_loss: 0.0302\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 567us/step - loss: 0.0722 - val_loss: 0.0298\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 567us/step - loss: 0.0708 - val_loss: 0.0287\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 566us/step - loss: 0.0681 - val_loss: 0.0276\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 8s 2ms/step - loss: 0.0752 - val_loss: 0.0150\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 464us/step - loss: 0.0619 - val_loss: 0.0157\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 462us/step - loss: 0.0326 - val_loss: 0.0215\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 466us/step - loss: 0.0149 - val_loss: 0.0545\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 462us/step - loss: 0.0100 - val_loss: 0.0640\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 467us/step - loss: 0.0062 - val_loss: 0.0456\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 462us/step - loss: 0.0048 - val_loss: 0.0509\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 466us/step - loss: 0.0041 - val_loss: 0.0557\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 462us/step - loss: 0.0038 - val_loss: 0.0612\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 462us/step - loss: 0.0036 - val_loss: 0.0569\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 466us/step - loss: 0.0035 - val_loss: 0.0570\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 469us/step - loss: 0.0033 - val_loss: 0.0553\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 464us/step - loss: 0.0032 - val_loss: 0.0577\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 468us/step - loss: 0.0032 - val_loss: 0.0508\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 464us/step - loss: 0.0032 - val_loss: 0.0484\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 464us/step - loss: 0.0031 - val_loss: 0.0453\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 466us/step - loss: 0.0030 - val_loss: 0.0325\n",
      "Epoch 18/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 465us/step - loss: 0.0029 - val_loss: 0.0138\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 464us/step - loss: 0.0032 - val_loss: 0.0112\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 463us/step - loss: 0.0027 - val_loss: 0.0101\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 464us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 465us/step - loss: 0.0020 - val_loss: 0.0049\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 464us/step - loss: 0.0019 - val_loss: 0.0060\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 466us/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 8s 2ms/step - loss: 1.2078 - val_loss: 0.7645\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 462us/step - loss: 0.3570 - val_loss: 0.1948\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 465us/step - loss: 0.1037 - val_loss: 0.0351\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 464us/step - loss: 0.0783 - val_loss: 0.0083\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 465us/step - loss: 0.0909 - val_loss: 0.0068\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 465us/step - loss: 0.0890 - val_loss: 0.0100\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 462us/step - loss: 0.0795 - val_loss: 0.0198\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 462us/step - loss: 0.0742 - val_loss: 0.0322\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 465us/step - loss: 0.0737 - val_loss: 0.0396\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 469us/step - loss: 0.0741 - val_loss: 0.0396\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 464us/step - loss: 0.0739 - val_loss: 0.0360\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 464us/step - loss: 0.0736 - val_loss: 0.0320\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 465us/step - loss: 0.0735 - val_loss: 0.0304\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 463us/step - loss: 0.0735 - val_loss: 0.0297\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 463us/step - loss: 0.0735 - val_loss: 0.0303\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 462us/step - loss: 0.0735 - val_loss: 0.0314\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 465us/step - loss: 0.0735 - val_loss: 0.0317\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 464us/step - loss: 0.0735 - val_loss: 0.0322\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 464us/step - loss: 0.0735 - val_loss: 0.0318\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 466us/step - loss: 0.0735 - val_loss: 0.0316\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 462us/step - loss: 0.0735 - val_loss: 0.0315\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 462us/step - loss: 0.0735 - val_loss: 0.0318\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 463us/step - loss: 0.0735 - val_loss: 0.0310\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 462us/step - loss: 0.0735 - val_loss: 0.0316\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 8s 2ms/step - loss: 0.1409 - val_loss: 0.0265\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 465us/step - loss: 0.0682 - val_loss: 0.0144\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 464us/step - loss: 0.0525 - val_loss: 0.0177\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 466us/step - loss: 0.0335 - val_loss: 0.0138\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 469us/step - loss: 0.0141 - val_loss: 0.0365\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 471us/step - loss: 0.0093 - val_loss: 0.0369\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 466us/step - loss: 0.0072 - val_loss: 0.0234\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 464us/step - loss: 0.0128 - val_loss: 0.0332\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 466us/step - loss: 0.0044 - val_loss: 0.0260\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 464us/step - loss: 0.0039 - val_loss: 0.0185\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 466us/step - loss: 0.0047 - val_loss: 0.0390\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 466us/step - loss: 0.0053 - val_loss: 0.0067\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 464us/step - loss: 0.0033 - val_loss: 0.0378\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 466us/step - loss: 0.0047 - val_loss: 0.0065\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 471us/step - loss: 0.0042 - val_loss: 0.0336\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 466us/step - loss: 0.0037 - val_loss: 0.0047\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 466us/step - loss: 0.0028 - val_loss: 0.0212\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 466us/step - loss: 0.0056 - val_loss: 0.0092\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 464us/step - loss: 0.0167 - val_loss: 0.0279\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 464us/step - loss: 0.0032 - val_loss: 0.0188\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 467us/step - loss: 0.0027 - val_loss: 0.0175\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 467us/step - loss: 0.0034 - val_loss: 0.0105\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 465us/step - loss: 0.0029 - val_loss: 0.0165\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 465us/step - loss: 0.0036 - val_loss: 0.0081\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 8s 2ms/step - loss: 0.0981 - val_loss: 0.0029\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 463us/step - loss: 0.0035 - val_loss: 0.0034\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 462us/step - loss: 0.0029 - val_loss: 0.0047\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 466us/step - loss: 0.0032 - val_loss: 0.0047\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 468us/step - loss: 0.0050 - val_loss: 0.0051\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 463us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 464us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 462us/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 462us/step - loss: 0.0064 - val_loss: 0.0077\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 462us/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 470us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 463us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 465us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 465us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 462us/step - loss: 0.0043 - val_loss: 0.0100\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 464us/step - loss: 0.0049 - val_loss: 0.0021\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 465us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 464us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 464us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 464us/step - loss: 0.0023 - val_loss: 0.0088\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 468us/step - loss: 0.0067 - val_loss: 0.0069\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 464us/step - loss: 0.0048 - val_loss: 0.0027\n",
      "Epoch 23/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 464us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 463us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 8s 2ms/step - loss: 0.1606 - val_loss: 0.0166\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 325us/step - loss: 0.0127 - val_loss: 0.0357\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 323us/step - loss: 0.0153 - val_loss: 0.0060\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 323us/step - loss: 0.0042 - val_loss: 0.0067\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 323us/step - loss: 0.0051 - val_loss: 0.0176\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 323us/step - loss: 0.0129 - val_loss: 0.0100\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 323us/step - loss: 0.0039 - val_loss: 0.0048\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 324us/step - loss: 0.0036 - val_loss: 0.0069\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 325us/step - loss: 0.0073 - val_loss: 0.0163\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 330us/step - loss: 0.0091 - val_loss: 0.0136\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 323us/step - loss: 0.0051 - val_loss: 0.0036\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 320us/step - loss: 0.0032 - val_loss: 0.0048\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 321us/step - loss: 0.0032 - val_loss: 0.0040\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 322us/step - loss: 0.0069 - val_loss: 0.0181\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 324us/step - loss: 0.0058 - val_loss: 0.0032\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 323us/step - loss: 0.0044 - val_loss: 0.0084\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 321us/step - loss: 0.0040 - val_loss: 0.0054\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 323us/step - loss: 0.0049 - val_loss: 0.0054\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 325us/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 327us/step - loss: 0.0038 - val_loss: 0.0063\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 324us/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 322us/step - loss: 0.0056 - val_loss: 0.0101\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 322us/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 331us/step - loss: 0.0026 - val_loss: 0.0059\n",
      "\n",
      "GENERATION 6\n",
      "\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 8s 2ms/step - loss: 0.1864 - val_loss: 0.0080\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 519us/step - loss: 0.0369 - val_loss: 0.0257\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 517us/step - loss: 0.0142 - val_loss: 0.0136\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 517us/step - loss: 0.0053 - val_loss: 0.0078\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 518us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 521us/step - loss: 0.0030 - val_loss: 0.0041\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 524us/step - loss: 0.0025 - val_loss: 0.0047\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 519us/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 523us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 517us/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 516us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 519us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 517us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 516us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 519us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 517us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 516us/step - loss: 0.0017 - val_loss: 0.0027\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 522us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 517us/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 516us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 516us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 516us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 518us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 518us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 8s 2ms/step - loss: 0.0701 - val_loss: 0.0153\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 446us/step - loss: 0.0098 - val_loss: 0.0036\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 441us/step - loss: 0.0041 - val_loss: 0.0091\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 444us/step - loss: 0.0033 - val_loss: 0.0039\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 440us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 442us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 443us/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 444us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 443us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 441us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 441us/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 445us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 446us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 441us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 442us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 443us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 443us/step - loss: 0.0014 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 444us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 441us/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 442us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 439us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 442us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 448us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 443us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 9s 3ms/step - loss: 0.0745 - val_loss: 0.0281\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 442us/step - loss: 0.0139 - val_loss: 0.0087\n",
      "Epoch 3/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 441us/step - loss: 0.0051 - val_loss: 0.0065\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 441us/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 444us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 443us/step - loss: 0.0026 - val_loss: 0.0050\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 442us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 448us/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 444us/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 443us/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 442us/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 441us/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 443us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 443us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 443us/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 442us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 441us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 442us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 448us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 446us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 443us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 443us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 443us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 445us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 8s 2ms/step - loss: 0.1226 - val_loss: 0.0098\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 327us/step - loss: 0.0220 - val_loss: 0.0110\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 328us/step - loss: 0.0106 - val_loss: 0.0113\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 333us/step - loss: 0.0061 - val_loss: 0.0051\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 354us/step - loss: 0.0045 - val_loss: 0.0088\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 345us/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 333us/step - loss: 0.0036 - val_loss: 0.0051\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 330us/step - loss: 0.0034 - val_loss: 0.0041\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 328us/step - loss: 0.0033 - val_loss: 0.0041\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 335us/step - loss: 0.0033 - val_loss: 0.0040\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 328us/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 327us/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 328us/step - loss: 0.0030 - val_loss: 0.0036\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 328us/step - loss: 0.0030 - val_loss: 0.0035\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 327us/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 327us/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 326us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 327us/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 334us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 328us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 330us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 327us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 326us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 327us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 9s 3ms/step - loss: 0.1118 - val_loss: 0.0049\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 403us/step - loss: 0.0086 - val_loss: 0.0055\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 404us/step - loss: 0.0085 - val_loss: 0.0093\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 410us/step - loss: 0.0054 - val_loss: 0.0043\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 417us/step - loss: 0.0044 - val_loss: 0.0103\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 406us/step - loss: 0.0072 - val_loss: 0.0034\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 404us/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 403us/step - loss: 0.0031 - val_loss: 0.0040\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 404us/step - loss: 0.0057 - val_loss: 0.0102\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 403us/step - loss: 0.0057 - val_loss: 0.0039\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 402us/step - loss: 0.0033 - val_loss: 0.0040\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 404us/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 401us/step - loss: 0.0041 - val_loss: 0.0084\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 403us/step - loss: 0.0055 - val_loss: 0.0042\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 403us/step - loss: 0.0040 - val_loss: 0.0068\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 406us/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 405us/step - loss: 0.0032 - val_loss: 0.0050\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 405us/step - loss: 0.0031 - val_loss: 0.0041\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 405us/step - loss: 0.0042 - val_loss: 0.0058\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 403us/step - loss: 0.0032 - val_loss: 0.0025\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 403us/step - loss: 0.0039 - val_loss: 0.0049\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 405us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 404us/step - loss: 0.0040 - val_loss: 0.0105\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 403us/step - loss: 0.0057 - val_loss: 0.0040\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 9s 3ms/step - loss: 0.1085 - val_loss: 0.0064\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 407us/step - loss: 0.0049 - val_loss: 0.0150\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 405us/step - loss: 0.0180 - val_loss: 0.0039\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 404us/step - loss: 0.0055 - val_loss: 0.0111\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 404us/step - loss: 0.0086 - val_loss: 0.0106\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 404us/step - loss: 0.0074 - val_loss: 0.0071\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 405us/step - loss: 0.0042 - val_loss: 0.0079\n",
      "Epoch 8/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 1s 404us/step - loss: 0.0087 - val_loss: 0.0090\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 404us/step - loss: 0.0050 - val_loss: 0.0043\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 404us/step - loss: 0.0035 - val_loss: 0.0063\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 404us/step - loss: 0.0078 - val_loss: 0.0103\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 403us/step - loss: 0.0058 - val_loss: 0.0065\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 410us/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 407us/step - loss: 0.0047 - val_loss: 0.0152\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 405us/step - loss: 0.0089 - val_loss: 0.0030\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 403us/step - loss: 0.0035 - val_loss: 0.0059\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 404us/step - loss: 0.0034 - val_loss: 0.0027\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 404us/step - loss: 0.0049 - val_loss: 0.0116\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 403us/step - loss: 0.0054 - val_loss: 0.0031\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 403us/step - loss: 0.0031 - val_loss: 0.0044\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 414us/step - loss: 0.0043 - val_loss: 0.0062\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 405us/step - loss: 0.0049 - val_loss: 0.0058\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 404us/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 410us/step - loss: 0.0029 - val_loss: 0.0074\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 9s 3ms/step - loss: 68519044.2950 - val_loss: 1286.9526\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 403us/step - loss: 7855.1975 - val_loss: 619.2753\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 405us/step - loss: 5471.5213 - val_loss: 60.8551\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 403us/step - loss: 4057.0270 - val_loss: 35.3696\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 404us/step - loss: 3351.0585 - val_loss: 42.8149\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 403us/step - loss: 2804.0224 - val_loss: 98.2052\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 404us/step - loss: 2448.1448 - val_loss: 130.1548\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 403us/step - loss: 1960.5342 - val_loss: 176.3911\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 408us/step - loss: 1427.4121 - val_loss: 117.6515\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 404us/step - loss: 1295.2850 - val_loss: 75.0985\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 404us/step - loss: 930.8070 - val_loss: 131.0614\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 404us/step - loss: 780.3135 - val_loss: 68.8287\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 404us/step - loss: 677.5583 - val_loss: 58.2621\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 404us/step - loss: 568.7509 - val_loss: 69.5049\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 404us/step - loss: 488.0476 - val_loss: 154.1082\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 402us/step - loss: 415.7134 - val_loss: 84.6065\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 403us/step - loss: 391.6178 - val_loss: 8.1557\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 402us/step - loss: 292.1657 - val_loss: 91.8195\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 403us/step - loss: 268.5253 - val_loss: 50.1822\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 405us/step - loss: 253.0366 - val_loss: 5.3830\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 405us/step - loss: 228.1460 - val_loss: 29.2366\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 404us/step - loss: 182.4687 - val_loss: 5.9892\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 403us/step - loss: 168.4195 - val_loss: 16.3712\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 403us/step - loss: 136.2116 - val_loss: 9.6593\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 10s 3ms/step - loss: 0.0690 - val_loss: 0.0044\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 404us/step - loss: 0.0060 - val_loss: 0.0053\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 405us/step - loss: 0.0079 - val_loss: 0.0088\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 403us/step - loss: 0.0064 - val_loss: 0.0079\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 409us/step - loss: 0.0050 - val_loss: 0.0034\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 404us/step - loss: 0.0060 - val_loss: 0.0113\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 404us/step - loss: 0.0063 - val_loss: 0.0055\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 404us/step - loss: 0.0059 - val_loss: 0.0076\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 404us/step - loss: 0.0045 - val_loss: 0.0023\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 403us/step - loss: 0.0042 - val_loss: 0.0102\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 406us/step - loss: 0.0064 - val_loss: 0.0030\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 404us/step - loss: 0.0047 - val_loss: 0.0108\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 407us/step - loss: 0.0053 - val_loss: 0.0023\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 404us/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 403us/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 412us/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 405us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 404us/step - loss: 0.0036 - val_loss: 0.0152\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 403us/step - loss: 0.0105 - val_loss: 0.0108\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 404us/step - loss: 0.0039 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 404us/step - loss: 0.0034 - val_loss: 0.0059\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 404us/step - loss: 0.0031 - val_loss: 0.0018\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 414us/step - loss: 0.0029 - val_loss: 0.0063\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 406us/step - loss: 0.0028 - val_loss: 0.0018\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 10s 3ms/step - loss: 3.7463 - val_loss: 0.0059\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 405us/step - loss: 0.0843 - val_loss: 0.0279\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 405us/step - loss: 0.0860 - val_loss: 0.0193\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 405us/step - loss: 0.0701 - val_loss: 0.0408\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 404us/step - loss: 0.0351 - val_loss: 0.0364\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 403us/step - loss: 0.0590 - val_loss: 0.0090\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 404us/step - loss: 0.0128 - val_loss: 0.0212\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 403us/step - loss: 0.0128 - val_loss: 0.0405\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 407us/step - loss: 0.0165 - val_loss: 0.0078\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 403us/step - loss: 0.0129 - val_loss: 0.0413\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 406us/step - loss: 0.0142 - val_loss: 0.0063\n",
      "Epoch 12/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 1s 408us/step - loss: 0.0107 - val_loss: 0.0360\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 405us/step - loss: 0.0188 - val_loss: 0.0070\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 409us/step - loss: 0.0115 - val_loss: 0.0376\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 405us/step - loss: 0.0142 - val_loss: 0.0083\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 404us/step - loss: 0.0102 - val_loss: 0.0253\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 403us/step - loss: 0.0121 - val_loss: 0.0269\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 404us/step - loss: 0.0199 - val_loss: 0.0294\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 404us/step - loss: 0.0088 - val_loss: 0.0079\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 405us/step - loss: 0.0082 - val_loss: 0.0230\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 405us/step - loss: 0.0138 - val_loss: 0.0170\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 404us/step - loss: 0.0120 - val_loss: 0.0201\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 408us/step - loss: 0.0077 - val_loss: 0.0063\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 404us/step - loss: 0.0066 - val_loss: 0.0150\n",
      "\n",
      "GENERATION 7\n",
      "\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 10s 3ms/step - loss: 0.0833 - val_loss: 0.0258\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 443us/step - loss: 0.0144 - val_loss: 0.0037\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 443us/step - loss: 0.0075 - val_loss: 0.0040\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 441us/step - loss: 0.0044 - val_loss: 0.0026\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 447us/step - loss: 0.0034 - val_loss: 0.0066\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 443us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 442us/step - loss: 0.0024 - val_loss: 0.0052\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 442us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 443us/step - loss: 0.0021 - val_loss: 0.0036\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 442us/step - loss: 0.0020 - val_loss: 0.0030\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 442us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 445us/step - loss: 0.0018 - val_loss: 0.0032\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 442us/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 443us/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 441us/step - loss: 0.0017 - val_loss: 0.0026\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 448us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 442us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 443us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 443us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 446us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 444us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 443us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 440us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 442us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 10s 3ms/step - loss: 0.2292 - val_loss: 0.0924\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 443us/step - loss: 0.0422 - val_loss: 0.0229\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 443us/step - loss: 0.0199 - val_loss: 0.0179\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 444us/step - loss: 0.0070 - val_loss: 0.0055\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 443us/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 444us/step - loss: 0.0033 - val_loss: 0.0051\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 444us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 444us/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 448us/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 444us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 443us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 448us/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 443us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 443us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 442us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 445us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 444us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 444us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 446us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 445us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 442us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 447us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 444us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 444us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 11s 3ms/step - loss: 0.1145 - val_loss: 0.0045\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 445us/step - loss: 0.0181 - val_loss: 0.0257\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 441us/step - loss: 0.0094 - val_loss: 0.0070\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 444us/step - loss: 0.0049 - val_loss: 0.0053\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 443us/step - loss: 0.0034 - val_loss: 0.0061\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 442us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 440us/step - loss: 0.0028 - val_loss: 0.0039\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 440us/step - loss: 0.0026 - val_loss: 0.0040\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 440us/step - loss: 0.0025 - val_loss: 0.0038\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 439us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 443us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 449us/step - loss: 0.0022 - val_loss: 0.0033\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 442us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 440us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 443us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 440us/step - loss: 0.0018 - val_loss: 0.0024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 441us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 442us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 441us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 440us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 440us/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 445us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 448us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 441us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 11s 3ms/step - loss: 0.1409 - val_loss: 0.0398\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 445us/step - loss: 0.0139 - val_loss: 0.0042\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 445us/step - loss: 0.0096 - val_loss: 0.0053\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 447us/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 446us/step - loss: 0.0056 - val_loss: 0.0127\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 446us/step - loss: 0.0062 - val_loss: 0.0037\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 444us/step - loss: 0.0047 - val_loss: 0.0096\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 445us/step - loss: 0.0048 - val_loss: 0.0034\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 444us/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 444us/step - loss: 0.0032 - val_loss: 0.0078\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 445us/step - loss: 0.0051 - val_loss: 0.0063\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 445us/step - loss: 0.0035 - val_loss: 0.0050\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 443us/step - loss: 0.0057 - val_loss: 0.0069\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 444us/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 450us/step - loss: 0.0023 - val_loss: 0.0064\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 446us/step - loss: 0.0042 - val_loss: 0.0053\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 445us/step - loss: 0.0048 - val_loss: 0.0045\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 447us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 455us/step - loss: 0.0031 - val_loss: 0.0049\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 464us/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 451us/step - loss: 0.0038 - val_loss: 0.0048\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 446us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 445us/step - loss: 0.0029 - val_loss: 0.0056\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 446us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 11s 3ms/step - loss: 0.1201 - val_loss: 0.0105\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 448us/step - loss: 0.0142 - val_loss: 0.0151\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 447us/step - loss: 0.0100 - val_loss: 0.0118\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 447us/step - loss: 0.0075 - val_loss: 0.0137\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 447us/step - loss: 0.0096 - val_loss: 0.0124\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 445us/step - loss: 0.0082 - val_loss: 0.0068\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 452us/step - loss: 0.0062 - val_loss: 0.0091\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 446us/step - loss: 0.0042 - val_loss: 0.0064\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 447us/step - loss: 0.0068 - val_loss: 0.0080\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 446us/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 446us/step - loss: 0.0057 - val_loss: 0.0108\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 445us/step - loss: 0.0052 - val_loss: 0.0042\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 447us/step - loss: 0.0048 - val_loss: 0.0080\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 445us/step - loss: 0.0037 - val_loss: 0.0058\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 445us/step - loss: 0.0052 - val_loss: 0.0074\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 445us/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 451us/step - loss: 0.0041 - val_loss: 0.0082\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 445us/step - loss: 0.0051 - val_loss: 0.0058\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 447us/step - loss: 0.0050 - val_loss: 0.0084\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 447us/step - loss: 0.0041 - val_loss: 0.0076\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 446us/step - loss: 0.0043 - val_loss: 0.0058\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 446us/step - loss: 0.0027 - val_loss: 0.0048\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 445us/step - loss: 0.0041 - val_loss: 0.0052\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 447us/step - loss: 0.0022 - val_loss: 0.0032\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 11s 3ms/step - loss: 0.1409 - val_loss: 0.0047\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 444us/step - loss: 0.0098 - val_loss: 0.0556\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 443us/step - loss: 0.0128 - val_loss: 0.0041\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 443us/step - loss: 0.0091 - val_loss: 0.0224\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 444us/step - loss: 0.0080 - val_loss: 0.0048\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 444us/step - loss: 0.0056 - val_loss: 0.0122\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 443us/step - loss: 0.0055 - val_loss: 0.0080\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 444us/step - loss: 0.0068 - val_loss: 0.0146\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 450us/step - loss: 0.0061 - val_loss: 0.0050\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 444us/step - loss: 0.0047 - val_loss: 0.0085\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 443us/step - loss: 0.0031 - val_loss: 0.0034\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 444us/step - loss: 0.0028 - val_loss: 0.0094\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 443us/step - loss: 0.0066 - val_loss: 0.0109\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 455us/step - loss: 0.0088 - val_loss: 0.0133\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 450us/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 445us/step - loss: 0.0026 - val_loss: 0.0082\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 442us/step - loss: 0.0043 - val_loss: 0.0149\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 444us/step - loss: 0.0082 - val_loss: 0.0178\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 451us/step - loss: 0.0051 - val_loss: 0.0027\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 442us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 444us/step - loss: 0.0019 - val_loss: 0.0049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 445us/step - loss: 0.0040 - val_loss: 0.0099\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 445us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 444us/step - loss: 0.0021 - val_loss: 0.0077\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 12s 3ms/step - loss: 0.1393 - val_loss: 0.0052\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 448us/step - loss: 0.0088 - val_loss: 0.0463\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 447us/step - loss: 0.0179 - val_loss: 0.0093\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 446us/step - loss: 0.0087 - val_loss: 0.0173\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 447us/step - loss: 0.0053 - val_loss: 0.0084\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 448us/step - loss: 0.0082 - val_loss: 0.0168\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 448us/step - loss: 0.0076 - val_loss: 0.0050\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 448us/step - loss: 0.0089 - val_loss: 0.0118\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 447us/step - loss: 0.0048 - val_loss: 0.0038\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 451us/step - loss: 0.0045 - val_loss: 0.0118\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 449us/step - loss: 0.0049 - val_loss: 0.0070\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 445us/step - loss: 0.0041 - val_loss: 0.0125\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 446us/step - loss: 0.0053 - val_loss: 0.0080\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 448us/step - loss: 0.0102 - val_loss: 0.0120\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 447us/step - loss: 0.0051 - val_loss: 0.0149\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 447us/step - loss: 0.0064 - val_loss: 0.0054\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 445us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 448us/step - loss: 0.0029 - val_loss: 0.0105\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 445us/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 446us/step - loss: 0.0038 - val_loss: 0.0119\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 453us/step - loss: 0.0037 - val_loss: 0.0033\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 447us/step - loss: 0.0033 - val_loss: 0.0086\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 447us/step - loss: 0.0042 - val_loss: 0.0030\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 448us/step - loss: 0.0037 - val_loss: 0.0133\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 12s 4ms/step - loss: 0.1430 - val_loss: 0.0031\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 0.0037 - val_loss: 0.0132\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 507us/step - loss: 0.0134 - val_loss: 0.0028\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 0.0032 - val_loss: 0.0057\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 507us/step - loss: 0.0029 - val_loss: 0.0026\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 503us/step - loss: 0.0059 - val_loss: 0.0193\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 505us/step - loss: 0.0081 - val_loss: 0.0042\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 511us/step - loss: 0.0051 - val_loss: 0.0074\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 504us/step - loss: 0.0035 - val_loss: 0.0023\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 0.0035 - val_loss: 0.0109\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 504us/step - loss: 0.0041 - val_loss: 0.0034\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 505us/step - loss: 0.0055 - val_loss: 0.0113\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 503us/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 504us/step - loss: 0.0042 - val_loss: 0.0087\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 505us/step - loss: 0.0045 - val_loss: 0.0041\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 505us/step - loss: 0.0053 - val_loss: 0.0143\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 506us/step - loss: 0.0055 - val_loss: 0.0045\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 507us/step - loss: 0.0038 - val_loss: 0.0074\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 506us/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 504us/step - loss: 0.0018 - val_loss: 0.0059\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 505us/step - loss: 0.0067 - val_loss: 0.0094\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 503us/step - loss: 0.0080 - val_loss: 0.0109\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 12s 4ms/step - loss: 0.1482 - val_loss: 0.0028\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 503us/step - loss: 0.0047 - val_loss: 0.0029\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 506us/step - loss: 0.0127 - val_loss: 0.0092\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 0.0040 - val_loss: 0.0032\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 505us/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 506us/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 507us/step - loss: 0.0046 - val_loss: 0.0161\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 511us/step - loss: 0.0081 - val_loss: 0.0027\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 507us/step - loss: 0.0036 - val_loss: 0.0063\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 505us/step - loss: 0.0039 - val_loss: 0.0031\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 505us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 0.0038 - val_loss: 0.0023\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 0.0026 - val_loss: 0.0040\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 505us/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 0.0078 - val_loss: 0.0134\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 507us/step - loss: 0.0052 - val_loss: 0.0024\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 506us/step - loss: 0.0038 - val_loss: 0.0078\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 0.0035 - val_loss: 0.0020\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 507us/step - loss: 0.0032 - val_loss: 0.0061\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 506us/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 506us/step - loss: 0.0025 - val_loss: 0.0059\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 0.0060 - val_loss: 0.0079\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 505us/step - loss: 0.0071 - val_loss: 0.0127\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 505us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "\n",
      "GENERATION 8\n",
      "\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 12s 4ms/step - loss: 0.0957 - val_loss: 0.0441\n",
      "Epoch 2/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 443us/step - loss: 0.0160 - val_loss: 0.0184\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 443us/step - loss: 0.0069 - val_loss: 0.0052\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 444us/step - loss: 0.0040 - val_loss: 0.0126\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 444us/step - loss: 0.0032 - val_loss: 0.0026\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 442us/step - loss: 0.0026 - val_loss: 0.0066\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 448us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 441us/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 442us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 443us/step - loss: 0.0019 - val_loss: 0.0034\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 443us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 443us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 441us/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 442us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 442us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 443us/step - loss: 0.0016 - val_loss: 0.0025\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 445us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 445us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 443us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 445us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 441us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 452us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 497us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 498us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 13s 4ms/step - loss: 0.0960 - val_loss: 0.0138\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 0.0200 - val_loss: 0.0117\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 0.0094 - val_loss: 0.0092\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 0.0062 - val_loss: 0.0112\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 489us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 0.0026 - val_loss: 0.0043\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 467us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 0.0022 - val_loss: 0.0032\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 464us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 460us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 464us/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 460us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 453us/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 453us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 450us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 452us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 452us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 451us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 450us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 451us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 12s 4ms/step - loss: 0.3217 - val_loss: 0.2607\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 450us/step - loss: 0.0639 - val_loss: 0.0042\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 451us/step - loss: 0.0112 - val_loss: 0.0109\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 452us/step - loss: 0.0063 - val_loss: 0.0074\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 454us/step - loss: 0.0035 - val_loss: 0.0031\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 450us/step - loss: 0.0027 - val_loss: 0.0041\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 452us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 448us/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 451us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 450us/step - loss: 0.0021 - val_loss: 0.0031\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 450us/step - loss: 0.0021 - val_loss: 0.0034\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 449us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 451us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 451us/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 451us/step - loss: 0.0020 - val_loss: 0.0030\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 456us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 452us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 455us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 452us/step - loss: 0.0021 - val_loss: 0.0033\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 452us/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 449us/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 450us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 450us/step - loss: 0.0026 - val_loss: 0.0044\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 452us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 13s 4ms/step - loss: 6.7637 - val_loss: 0.0292\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 451us/step - loss: 0.0691 - val_loss: 0.0187\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 450us/step - loss: 0.0369 - val_loss: 0.0086\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 451us/step - loss: 0.0097 - val_loss: 0.0699\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 455us/step - loss: 0.0087 - val_loss: 0.0218\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 450us/step - loss: 0.0064 - val_loss: 0.0367\n",
      "Epoch 7/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 451us/step - loss: 0.0057 - val_loss: 0.0521\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 449us/step - loss: 0.0057 - val_loss: 0.0379\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 449us/step - loss: 0.0055 - val_loss: 0.0417\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 450us/step - loss: 0.0054 - val_loss: 0.0375\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 448us/step - loss: 0.0054 - val_loss: 0.0237\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 451us/step - loss: 0.0054 - val_loss: 0.0355\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 452us/step - loss: 0.0052 - val_loss: 0.0324\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 450us/step - loss: 0.0051 - val_loss: 0.0238\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 467us/step - loss: 0.0051 - val_loss: 0.0303\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 456us/step - loss: 0.0050 - val_loss: 0.0225\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 449us/step - loss: 0.0049 - val_loss: 0.0288\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 449us/step - loss: 0.0049 - val_loss: 0.0209\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 448us/step - loss: 0.0048 - val_loss: 0.0235\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 452us/step - loss: 0.0048 - val_loss: 0.0314\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 448us/step - loss: 0.0053 - val_loss: 0.0146\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 449us/step - loss: 0.0048 - val_loss: 0.0202\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 451us/step - loss: 0.0045 - val_loss: 0.0162\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 448us/step - loss: 0.0045 - val_loss: 0.0209\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 13s 4ms/step - loss: 4.1300 - val_loss: 0.0298\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 469us/step - loss: 0.0692 - val_loss: 0.0279\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 467us/step - loss: 0.0379 - val_loss: 0.0536\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 0.0455 - val_loss: 0.0135\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 471us/step - loss: 0.0087 - val_loss: 0.0209\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 468us/step - loss: 0.0079 - val_loss: 0.0238\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 468us/step - loss: 0.0077 - val_loss: 0.0198\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 468us/step - loss: 0.0077 - val_loss: 0.0252\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 468us/step - loss: 0.0072 - val_loss: 0.0199\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 468us/step - loss: 0.0069 - val_loss: 0.0176\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 472us/step - loss: 0.0072 - val_loss: 0.0254\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 471us/step - loss: 0.0069 - val_loss: 0.0126\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 471us/step - loss: 0.0067 - val_loss: 0.0249\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 0.0064 - val_loss: 0.0154\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 469us/step - loss: 0.0062 - val_loss: 0.0165\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 470us/step - loss: 0.0064 - val_loss: 0.0221\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 468us/step - loss: 0.0062 - val_loss: 0.0173\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 471us/step - loss: 0.0060 - val_loss: 0.0161\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 469us/step - loss: 0.0060 - val_loss: 0.0091\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 468us/step - loss: 0.0060 - val_loss: 0.0145\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 469us/step - loss: 0.0056 - val_loss: 0.0129\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 469us/step - loss: 0.0057 - val_loss: 0.0094\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 469us/step - loss: 0.0054 - val_loss: 0.0151\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 0.0063 - val_loss: 0.0059\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 13s 4ms/step - loss: 1.6269 - val_loss: 0.0247\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 470us/step - loss: 0.0620 - val_loss: 0.0222\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 0.0310 - val_loss: 0.0264\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 469us/step - loss: 0.0080 - val_loss: 0.0276\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 468us/step - loss: 0.0077 - val_loss: 0.0584\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 470us/step - loss: 0.0083 - val_loss: 0.0158\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 470us/step - loss: 0.0081 - val_loss: 0.0522\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 467us/step - loss: 0.0071 - val_loss: 0.0231\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 469us/step - loss: 0.0068 - val_loss: 0.0435\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 468us/step - loss: 0.0060 - val_loss: 0.0340\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 469us/step - loss: 0.0057 - val_loss: 0.0253\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 469us/step - loss: 0.0055 - val_loss: 0.0243\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 0.0054 - val_loss: 0.0211\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 469us/step - loss: 0.0055 - val_loss: 0.0198\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 466us/step - loss: 0.0055 - val_loss: 0.0262\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 469us/step - loss: 0.0052 - val_loss: 0.0203\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 467us/step - loss: 0.0051 - val_loss: 0.0121\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 468us/step - loss: 0.0049 - val_loss: 0.0111\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 469us/step - loss: 0.0053 - val_loss: 0.0193\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 470us/step - loss: 0.0068 - val_loss: 0.0066\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 470us/step - loss: 0.0070 - val_loss: 0.0221\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 468us/step - loss: 0.0054 - val_loss: 0.0083\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 0.0047 - val_loss: 0.0129\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 467us/step - loss: 0.0046 - val_loss: 0.0082\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 13s 4ms/step - loss: 0.9974 - val_loss: 0.3063\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 390us/step - loss: 0.2065 - val_loss: 0.0185\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 394us/step - loss: 0.0444 - val_loss: 0.1834\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 391us/step - loss: 0.0395 - val_loss: 0.0187\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 392us/step - loss: 0.0070 - val_loss: 0.0246\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 390us/step - loss: 0.0064 - val_loss: 0.0354\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 397us/step - loss: 0.0058 - val_loss: 0.0258\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 390us/step - loss: 0.0054 - val_loss: 0.0264\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 391us/step - loss: 0.0052 - val_loss: 0.0143\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 392us/step - loss: 0.0048 - val_loss: 0.0204\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 392us/step - loss: 0.0053 - val_loss: 0.0074\n",
      "Epoch 12/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 1s 391us/step - loss: 0.0054 - val_loss: 0.0253\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 396us/step - loss: 0.0055 - val_loss: 0.0061\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 388us/step - loss: 0.0052 - val_loss: 0.0302\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 387us/step - loss: 0.0067 - val_loss: 0.0066\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 388us/step - loss: 0.0044 - val_loss: 0.0119\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 388us/step - loss: 0.0045 - val_loss: 0.0189\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 390us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 390us/step - loss: 0.0049 - val_loss: 0.0187\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 390us/step - loss: 0.0050 - val_loss: 0.0059\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 390us/step - loss: 0.0039 - val_loss: 0.0106\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 388us/step - loss: 0.0036 - val_loss: 0.0047\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 388us/step - loss: 0.0065 - val_loss: 0.0252\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 390us/step - loss: 0.0050 - val_loss: 0.0079\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 13s 4ms/step - loss: 0.7449 - val_loss: 0.0064\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 395us/step - loss: 0.0882 - val_loss: 0.0320\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 392us/step - loss: 0.0558 - val_loss: 0.0057\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 390us/step - loss: 0.0482 - val_loss: 0.0142\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 392us/step - loss: 0.0180 - val_loss: 0.0151\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 392us/step - loss: 0.0067 - val_loss: 0.0132\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 392us/step - loss: 0.0060 - val_loss: 0.0069\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 395us/step - loss: 0.0057 - val_loss: 0.0107\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 394us/step - loss: 0.0057 - val_loss: 0.0278\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 394us/step - loss: 0.0070 - val_loss: 0.0050\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 394us/step - loss: 0.0054 - val_loss: 0.0107\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 391us/step - loss: 0.0046 - val_loss: 0.0068\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 394us/step - loss: 0.0043 - val_loss: 0.0066\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 395us/step - loss: 0.0051 - val_loss: 0.0302\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 391us/step - loss: 0.0066 - val_loss: 0.0049\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 393us/step - loss: 0.0048 - val_loss: 0.0080\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 394us/step - loss: 0.0039 - val_loss: 0.0080\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 389us/step - loss: 0.0040 - val_loss: 0.0135\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 389us/step - loss: 0.0047 - val_loss: 0.0043\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 391us/step - loss: 0.0053 - val_loss: 0.0128\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 390us/step - loss: 0.0048 - val_loss: 0.0044\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 392us/step - loss: 0.0041 - val_loss: 0.0080\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 390us/step - loss: 0.0037 - val_loss: 0.0051\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 390us/step - loss: 0.0035 - val_loss: 0.0041\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 14s 4ms/step - loss: 1.1793 - val_loss: 0.0192\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 523us/step - loss: 0.0453 - val_loss: 0.0169\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 528us/step - loss: 0.0307 - val_loss: 0.0283\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 519us/step - loss: 0.0076 - val_loss: 0.0485\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 522us/step - loss: 0.0080 - val_loss: 0.0105\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 521us/step - loss: 0.0085 - val_loss: 0.0402\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 520us/step - loss: 0.0061 - val_loss: 0.0411\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 528us/step - loss: 0.0057 - val_loss: 0.0377\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 521us/step - loss: 0.0056 - val_loss: 0.0252\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 521us/step - loss: 0.0072 - val_loss: 0.0113\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 524us/step - loss: 0.0088 - val_loss: 0.0343\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 523us/step - loss: 0.0057 - val_loss: 0.0231\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 521us/step - loss: 0.0051 - val_loss: 0.0158\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 519us/step - loss: 0.0054 - val_loss: 0.0257\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 519us/step - loss: 0.0058 - val_loss: 0.0069\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 522us/step - loss: 0.0056 - val_loss: 0.0152\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 520us/step - loss: 0.0051 - val_loss: 0.0068\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 523us/step - loss: 0.0063 - val_loss: 0.0274\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 520us/step - loss: 0.0062 - val_loss: 0.0065\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 522us/step - loss: 0.0046 - val_loss: 0.0115\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 522us/step - loss: 0.0049 - val_loss: 0.0055\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 522us/step - loss: 0.0042 - val_loss: 0.0072\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 522us/step - loss: 0.0044 - val_loss: 0.0196\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 521us/step - loss: 0.0092 - val_loss: 0.0055\n",
      "\n",
      "GENERATION 9\n",
      "\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 14s 4ms/step - loss: 0.1442 - val_loss: 0.0039\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 375us/step - loss: 0.0048 - val_loss: 0.0116\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 376us/step - loss: 0.0103 - val_loss: 0.0151\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 375us/step - loss: 0.0096 - val_loss: 0.0192\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 375us/step - loss: 0.0121 - val_loss: 0.0126\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 375us/step - loss: 0.0081 - val_loss: 0.0266\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 376us/step - loss: 0.0101 - val_loss: 0.0086\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 376us/step - loss: 0.0093 - val_loss: 0.0247\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 379us/step - loss: 0.0096 - val_loss: 0.0070\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 379us/step - loss: 0.0069 - val_loss: 0.0270\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 375us/step - loss: 0.0070 - val_loss: 0.0070\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 375us/step - loss: 0.0076 - val_loss: 0.0185\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 373us/step - loss: 0.0065 - val_loss: 0.0032\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 376us/step - loss: 0.0070 - val_loss: 0.0246\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 374us/step - loss: 0.0070 - val_loss: 0.0033\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 377us/step - loss: 0.0049 - val_loss: 0.0265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 374us/step - loss: 0.0059 - val_loss: 0.0040\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 376us/step - loss: 0.0057 - val_loss: 0.0227\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 375us/step - loss: 0.0070 - val_loss: 0.0045\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 373us/step - loss: 0.0043 - val_loss: 0.0106\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 381us/step - loss: 0.0055 - val_loss: 0.0041\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 375us/step - loss: 0.0046 - val_loss: 0.0255\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 376us/step - loss: 0.0057 - val_loss: 0.0055\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 372us/step - loss: 0.0039 - val_loss: 0.0135\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 14s 4ms/step - loss: 0.0753 - val_loss: 0.0323\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 451us/step - loss: 0.0144 - val_loss: 0.0121\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 451us/step - loss: 0.0053 - val_loss: 0.0027\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 453us/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 452us/step - loss: 0.0028 - val_loss: 0.0050\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 452us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 452us/step - loss: 0.0023 - val_loss: 0.0047\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 457us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 458us/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 452us/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 450us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 452us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 452us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 454us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 451us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 453us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 451us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 451us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 458us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 452us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 453us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 452us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 453us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 452us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 15s 4ms/step - loss: 0.0795 - val_loss: 0.0330\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 451us/step - loss: 0.0160 - val_loss: 0.0172\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 452us/step - loss: 0.0071 - val_loss: 0.0064\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 452us/step - loss: 0.0050 - val_loss: 0.0034\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 458us/step - loss: 0.0043 - val_loss: 0.0067\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 451us/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 453us/step - loss: 0.0029 - val_loss: 0.0068\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 452us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 453us/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 452us/step - loss: 0.0021 - val_loss: 0.0034\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 452us/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 453us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 460us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0016 - val_loss: 0.0026\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 456us/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 453us/step - loss: 0.0015 - val_loss: 0.0024\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 452us/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 453us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 450us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 454us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 455us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 452us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 457us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 456us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 15s 4ms/step - loss: 0.0851 - val_loss: 0.0287\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 454us/step - loss: 0.0150 - val_loss: 0.0092\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 453us/step - loss: 0.0065 - val_loss: 0.0169\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 452us/step - loss: 0.0049 - val_loss: 0.0027\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 454us/step - loss: 0.0040 - val_loss: 0.0066\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 456us/step - loss: 0.0030 - val_loss: 0.0056\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 453us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 452us/step - loss: 0.0021 - val_loss: 0.0039\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 453us/step - loss: 0.0019 - val_loss: 0.0036\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 452us/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 455us/step - loss: 0.0017 - val_loss: 0.0026\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0016 - val_loss: 0.0025\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 452us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 451us/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 451us/step - loss: 0.0014 - val_loss: 0.0022\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 451us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 452us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 452us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 453us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 453us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 452us/step - loss: 0.0013 - val_loss: 0.0018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 458us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 454us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 451us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 15s 4ms/step - loss: 0.0448 - val_loss: 0.0031\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 454us/step - loss: 0.0068 - val_loss: 0.0045\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 453us/step - loss: 0.0057 - val_loss: 0.0143\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 450us/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 451us/step - loss: 0.0029 - val_loss: 0.0047\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 450us/step - loss: 0.0025 - val_loss: 0.0042\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 456us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 455us/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 452us/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 456us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 454us/step - loss: 0.0017 - val_loss: 0.0026\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 452us/step - loss: 0.0016 - val_loss: 0.0026\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 450us/step - loss: 0.0016 - val_loss: 0.0025\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 451us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 451us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 452us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 453us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 456us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 452us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 450us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 450us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 454us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 452us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 15s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 488us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 483us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 483us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 485us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 487us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 483us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 483us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 483us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 490us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 483us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 483us/step - loss: nan - val_loss: nan\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 16s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 532us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 514us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 506us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 507us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 511us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 512us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 515us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 512us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 507us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 506us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 506us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: nan - val_loss: nan\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 16s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 503us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 501us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 502us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 502us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 501us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 503us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 501us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 504us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 502us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 500us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 503us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 502us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 501us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 501us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 502us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 501us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 507us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 502us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 507us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 507us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 502us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 502us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 502us/step - loss: nan - val_loss: nan\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 16s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 506us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 503us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 503us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 502us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 504us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 507us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 506us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 513us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 514us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 519us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 511us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 513us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 501us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 501us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 502us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 503us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 503us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 502us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 506us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 503us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 502us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 502us/step - loss: nan - val_loss: nan\n",
      "\n",
      "GENERATION 10\n",
      "\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 16s 5ms/step - loss: 0.1130 - val_loss: 0.0535\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 530us/step - loss: 0.0190 - val_loss: 0.0241\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 526us/step - loss: 0.0079 - val_loss: 0.0056\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 530us/step - loss: 0.0048 - val_loss: 0.0142\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 524us/step - loss: 0.0036 - val_loss: 0.0025\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 526us/step - loss: 0.0029 - val_loss: 0.0067\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 524us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 526us/step - loss: 0.0023 - val_loss: 0.0045\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 526us/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 526us/step - loss: 0.0020 - val_loss: 0.0033\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 524us/step - loss: 0.0019 - val_loss: 0.0031\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 527us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 527us/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 526us/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 524us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 524us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 525us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 523us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 524us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 525us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 527us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 528us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 526us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 525us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 16s 5ms/step - loss: 0.0808 - val_loss: 0.0352\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 454us/step - loss: 0.0132 - val_loss: 0.0081\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 452us/step - loss: 0.0059 - val_loss: 0.0027\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0034 - val_loss: 0.0025\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 455us/step - loss: 0.0029 - val_loss: 0.0061\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 453us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 452us/step - loss: 0.0021 - val_loss: 0.0035\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 452us/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 453us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 454us/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 12/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 468us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 455us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 456us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 461us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 454us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 452us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 452us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 455us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 455us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 455us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 455us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 454us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 454us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 16s 5ms/step - loss: 0.1443 - val_loss: 0.0604\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 455us/step - loss: 0.0188 - val_loss: 0.0040\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 458us/step - loss: 0.0075 - val_loss: 0.0055\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 456us/step - loss: 0.0050 - val_loss: 0.0118\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 455us/step - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 455us/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 455us/step - loss: 0.0028 - val_loss: 0.0051\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 461us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 455us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 453us/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 454us/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 457us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 456us/step - loss: 0.0022 - val_loss: 0.0032\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 455us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 456us/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 456us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 454us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 454us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 454us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 453us/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 455us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 452us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 454us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 17s 5ms/step - loss: 0.0985 - val_loss: 0.0130\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 414us/step - loss: 0.0182 - val_loss: 0.0050\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 410us/step - loss: 0.0081 - val_loss: 0.0040\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 411us/step - loss: 0.0051 - val_loss: 0.0046\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 412us/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 409us/step - loss: 0.0031 - val_loss: 0.0056\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 412us/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 413us/step - loss: 0.0026 - val_loss: 0.0048\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 415us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 415us/step - loss: 0.0024 - val_loss: 0.0036\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 415us/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 415us/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 414us/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 413us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 411us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 413us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 412us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 412us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 411us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 412us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 410us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 411us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 410us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 418us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 17s 5ms/step - loss: 0.1241 - val_loss: 0.0196\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 412us/step - loss: 0.0177 - val_loss: 0.0102\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 414us/step - loss: 0.0082 - val_loss: 0.0079\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 414us/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 416us/step - loss: 0.0036 - val_loss: 0.0076\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 412us/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 420us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 413us/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 414us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 414us/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 415us/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 414us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 413us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 418us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 414us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 415us/step - loss: 0.0016 - val_loss: 0.0025\n",
      "Epoch 17/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 1s 413us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 420us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 413us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 414us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 414us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 411us/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 415us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 413us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 18s 5ms/step - loss: 0.6760 - val_loss: 0.3483\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 412us/step - loss: 0.1304 - val_loss: 0.0062\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 415us/step - loss: 0.0931 - val_loss: 0.0172\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 415us/step - loss: 0.0669 - val_loss: 0.0434\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 414us/step - loss: 0.0498 - val_loss: 0.0065\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 413us/step - loss: 0.0253 - val_loss: 0.0111\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 412us/step - loss: 0.0073 - val_loss: 0.0662\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 413us/step - loss: 0.0076 - val_loss: 0.0294\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 413us/step - loss: 0.0047 - val_loss: 0.0137\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 416us/step - loss: 0.0045 - val_loss: 0.0150\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 419us/step - loss: 0.0038 - val_loss: 0.0183\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 414us/step - loss: 0.0035 - val_loss: 0.0108\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 413us/step - loss: 0.0031 - val_loss: 0.0057\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 414us/step - loss: 0.0028 - val_loss: 0.0057\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 411us/step - loss: 0.0026 - val_loss: 0.0050\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 414us/step - loss: 0.0024 - val_loss: 0.0057\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 415us/step - loss: 0.0023 - val_loss: 0.0042\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 412us/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 415us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 415us/step - loss: 0.0020 - val_loss: 0.0036\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 411us/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 418us/step - loss: 0.0019 - val_loss: 0.0032\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 418us/step - loss: 0.0019 - val_loss: 0.0034\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 417us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 18s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 410us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 409us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 417us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 408us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 410us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 412us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 411us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 411us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 410us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 409us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 411us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 411us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 412us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 418us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 411us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 411us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 410us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 410us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 408us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 408us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 408us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 410us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 412us/step - loss: nan - val_loss: nan\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 18s 5ms/step - loss: 0.9814 - val_loss: 0.2200\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 432us/step - loss: 0.2059 - val_loss: 0.0254\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 435us/step - loss: 0.0958 - val_loss: 0.1277\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 432us/step - loss: 0.0855 - val_loss: 0.0177\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 431us/step - loss: 0.0776 - val_loss: 0.0094\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 433us/step - loss: 0.0629 - val_loss: 0.0240\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 435us/step - loss: 0.0380 - val_loss: 0.0089\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 436us/step - loss: 0.0112 - val_loss: 0.1226\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 435us/step - loss: 0.0092 - val_loss: 0.0195\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 432us/step - loss: 0.0067 - val_loss: 0.0145\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 431us/step - loss: 0.0056 - val_loss: 0.0100\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 434us/step - loss: 0.0049 - val_loss: 0.0126\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 432us/step - loss: 0.0045 - val_loss: 0.0123\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 430us/step - loss: 0.0041 - val_loss: 0.0104\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 433us/step - loss: 0.0039 - val_loss: 0.0065\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 433us/step - loss: 0.0037 - val_loss: 0.0050\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 433us/step - loss: 0.0035 - val_loss: 0.0094\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 438us/step - loss: 0.0035 - val_loss: 0.0049\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 433us/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 434us/step - loss: 0.0031 - val_loss: 0.0053\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 431us/step - loss: 0.0030 - val_loss: 0.0047\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 431us/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 23/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 1s 432us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 432us/step - loss: 0.0027 - val_loss: 0.0049\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 18s 5ms/step - loss: 2.2214 - val_loss: 0.7583\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 436us/step - loss: 0.2594 - val_loss: 0.0229\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 430us/step - loss: 0.1260 - val_loss: 0.0534\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 431us/step - loss: 0.0897 - val_loss: 0.0928\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 431us/step - loss: 0.0814 - val_loss: 0.0255\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 436us/step - loss: 0.0763 - val_loss: 0.0165\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 430us/step - loss: 0.0743 - val_loss: 0.0387\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 429us/step - loss: 0.0741 - val_loss: 0.0408\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 429us/step - loss: 0.0734 - val_loss: 0.0266\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 434us/step - loss: 0.0726 - val_loss: 0.0282\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 429us/step - loss: 0.0709 - val_loss: 0.0308\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 431us/step - loss: 0.0690 - val_loss: 0.0289\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 430us/step - loss: 0.0665 - val_loss: 0.0168\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 431us/step - loss: 0.0577 - val_loss: 0.0113\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 429us/step - loss: 0.0436 - val_loss: 0.0056\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 430us/step - loss: 0.0297 - val_loss: 0.0391\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 431us/step - loss: 0.0180 - val_loss: 0.0268\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 430us/step - loss: 0.0250 - val_loss: 0.0119\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 432us/step - loss: 0.0125 - val_loss: 0.0055\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 431us/step - loss: 0.0063 - val_loss: 0.0079\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 433us/step - loss: 0.0049 - val_loss: 0.0054\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 431us/step - loss: 0.0042 - val_loss: 0.0050\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 428us/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 430us/step - loss: 0.0036 - val_loss: 0.0046\n",
      "\n",
      "GENERATION 11\n",
      "\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 19s 6ms/step - loss: 0.0635 - val_loss: 0.0145\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 550us/step - loss: 0.0101 - val_loss: 0.0025\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 547us/step - loss: 0.0062 - val_loss: 0.0101\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 552us/step - loss: 0.0048 - val_loss: 0.0029\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 551us/step - loss: 0.0038 - val_loss: 0.0075\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 550us/step - loss: 0.0033 - val_loss: 0.0023\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 553us/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 552us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 549us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 551us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 551us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 550us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 549us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 551us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 550us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 552us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 552us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 551us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 550us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 553us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 20s 6ms/step - loss: 0.0704 - val_loss: 0.0367\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 456us/step - loss: 0.0142 - val_loss: 0.0116\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 460us/step - loss: 0.0064 - val_loss: 0.0036\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 464us/step - loss: 0.0042 - val_loss: 0.0034\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 458us/step - loss: 0.0033 - val_loss: 0.0057\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 456us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 458us/step - loss: 0.0025 - val_loss: 0.0052\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 461us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 458us/step - loss: 0.0020 - val_loss: 0.0032\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 458us/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 457us/step - loss: 0.0018 - val_loss: 0.0030\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 457us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 464us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 471us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 463us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 460us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 471us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 464us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 463us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 456us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 460us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 465us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 19s 6ms/step - loss: 0.0744 - val_loss: 0.0514\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 462us/step - loss: 0.0193 - val_loss: 0.0240\n",
      "Epoch 3/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 460us/step - loss: 0.0083 - val_loss: 0.0076\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 454us/step - loss: 0.0056 - val_loss: 0.0070\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 456us/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 457us/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 455us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 454us/step - loss: 0.0022 - val_loss: 0.0032\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 456us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 453us/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 455us/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 455us/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 460us/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 454us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 457us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 455us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 455us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 458us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 454us/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 456us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 453us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 452us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 462us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 455us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 20s 6ms/step - loss: 0.0867 - val_loss: 0.0134\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 420us/step - loss: 0.0143 - val_loss: 0.0062\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 417us/step - loss: 0.0082 - val_loss: 0.0174\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 418us/step - loss: 0.0053 - val_loss: 0.0025\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 418us/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 417us/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 417us/step - loss: 0.0031 - val_loss: 0.0027\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 417us/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 417us/step - loss: 0.0029 - val_loss: 0.0026\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 417us/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 415us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 418us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 418us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 416us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 418us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 417us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 415us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 417us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 418us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 420us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 418us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 417us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 418us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 425us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 20s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 421us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 416us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 413us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 415us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 415us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 414us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 414us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 414us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 415us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 414us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 413us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 420us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 415us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 428us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 416us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 417us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 415us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 415us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 421us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 421us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 414us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 415us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 416us/step - loss: nan - val_loss: nan\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 21s 6ms/step - loss: 0.1113 - val_loss: 0.0319\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 420us/step - loss: 0.0189 - val_loss: 0.0057\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 415us/step - loss: 0.0099 - val_loss: 0.0038\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 416us/step - loss: 0.0064 - val_loss: 0.0051\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 415us/step - loss: 0.0052 - val_loss: 0.0057\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 418us/step - loss: 0.0045 - val_loss: 0.0040\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 413us/step - loss: 0.0041 - val_loss: 0.0053\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 417us/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 9/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 1s 414us/step - loss: 0.0036 - val_loss: 0.0051\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 415us/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 416us/step - loss: 0.0033 - val_loss: 0.0043\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 414us/step - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 422us/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 419us/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 415us/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 417us/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 415us/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 421us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 418us/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 414us/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 418us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 418us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 417us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 423us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 21s 6ms/step - loss: 0.0778 - val_loss: 0.0049\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 503us/step - loss: 0.0108 - val_loss: 0.0059\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 499us/step - loss: 0.0076 - val_loss: 0.0096\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 500us/step - loss: 0.0050 - val_loss: 0.0070\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 499us/step - loss: 0.0043 - val_loss: 0.0030\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 500us/step - loss: 0.0037 - val_loss: 0.0069\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 502us/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 498us/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 500us/step - loss: 0.0030 - val_loss: 0.0036\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 505us/step - loss: 0.0030 - val_loss: 0.0038\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 497us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 503us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 502us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 501us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 502us/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 501us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 506us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 503us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 505us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 501us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 500us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 501us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 501us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 502us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 22s 6ms/step - loss: 0.0583 - val_loss: 0.0246\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 502us/step - loss: 0.0128 - val_loss: 0.0121\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 507us/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 506us/step - loss: 0.0046 - val_loss: 0.0028\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 504us/step - loss: 0.0039 - val_loss: 0.0077\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 504us/step - loss: 0.0034 - val_loss: 0.0028\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 501us/step - loss: 0.0030 - val_loss: 0.0044\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 501us/step - loss: 0.0028 - val_loss: 0.0039\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 503us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 501us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 501us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 502us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 505us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 505us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 502us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 501us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 501us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 501us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 502us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 500us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 506us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 503us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 503us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 22s 6ms/step - loss: 8.8684 - val_loss: 0.0065\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 502us/step - loss: 0.0165 - val_loss: 0.0044\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 505us/step - loss: 0.0102 - val_loss: 0.0042\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 504us/step - loss: 0.0074 - val_loss: 0.0042\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 502us/step - loss: 0.0065 - val_loss: 0.0042\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 503us/step - loss: 0.0065 - val_loss: 0.0041\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 504us/step - loss: 0.0060 - val_loss: 0.0041\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 0.0058 - val_loss: 0.0043\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 504us/step - loss: 0.0058 - val_loss: 0.0041\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 504us/step - loss: 0.0056 - val_loss: 0.0042\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 503us/step - loss: 0.0056 - val_loss: 0.0041\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 514us/step - loss: 0.0055 - val_loss: 0.0037\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 529us/step - loss: 0.0055 - val_loss: 0.0037\n",
      "Epoch 14/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 507us/step - loss: 0.0052 - val_loss: 0.0040\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 503us/step - loss: 0.0051 - val_loss: 0.0038\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 505us/step - loss: 0.0047 - val_loss: 0.0036\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 501us/step - loss: 0.0051 - val_loss: 0.0036\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 505us/step - loss: 0.0049 - val_loss: 0.0035\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 503us/step - loss: 0.0047 - val_loss: 0.0036\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 501us/step - loss: 0.0045 - val_loss: 0.0033\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 504us/step - loss: 0.0046 - val_loss: 0.0035\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 501us/step - loss: 0.0046 - val_loss: 0.0032\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 500us/step - loss: 0.0046 - val_loss: 0.0034\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 501us/step - loss: 0.0045 - val_loss: 0.0033\n",
      "\n",
      "GENERATION 12\n",
      "\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 23s 7ms/step - loss: 0.0768 - val_loss: 0.0347\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 485us/step - loss: 0.0164 - val_loss: 0.0123\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 0.0078 - val_loss: 0.0026\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 0.0052 - val_loss: 0.0042\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 0.0040 - val_loss: 0.0028\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 0.0035 - val_loss: 0.0047\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 0.0035 - val_loss: 0.0027\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 485us/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 483us/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 22s 7ms/step - loss: 0.0706 - val_loss: 0.0325\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0135 - val_loss: 0.0065\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 465us/step - loss: 0.0059 - val_loss: 0.0039\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 457us/step - loss: 0.0037 - val_loss: 0.0025\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 463us/step - loss: 0.0030 - val_loss: 0.0065\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 464us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 458us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 457us/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 457us/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 460us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 462us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 457us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 458us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 463us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 464us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 463us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 456us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 458us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 457us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 23s 7ms/step - loss: 0.3282 - val_loss: 0.1547\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 462us/step - loss: 0.0876 - val_loss: 0.0108\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0931 - val_loss: 0.0064\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 462us/step - loss: 0.0902 - val_loss: 0.0148\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 460us/step - loss: 0.0748 - val_loss: 0.0401\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 462us/step - loss: 0.0753 - val_loss: 0.0499\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 465us/step - loss: 0.0751 - val_loss: 0.0383\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 460us/step - loss: 0.0735 - val_loss: 0.0274\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 463us/step - loss: 0.0734 - val_loss: 0.0264\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 460us/step - loss: 0.0725 - val_loss: 0.0287\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0710 - val_loss: 0.0298\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 460us/step - loss: 0.0733 - val_loss: 0.0310\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 464us/step - loss: 0.0733 - val_loss: 0.0325\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 461us/step - loss: 0.0733 - val_loss: 0.0325\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0729 - val_loss: 0.0320\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 460us/step - loss: 0.0702 - val_loss: 0.0290\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 461us/step - loss: 0.0619 - val_loss: 0.0186\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 461us/step - loss: 0.0551 - val_loss: 0.0104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 460us/step - loss: 0.0704 - val_loss: 0.0131\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 462us/step - loss: 0.0752 - val_loss: 0.0388\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0750 - val_loss: 0.0465\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0741 - val_loss: 0.0297\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0736 - val_loss: 0.0255\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 461us/step - loss: 0.0735 - val_loss: 0.0317\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 23s 7ms/step - loss: 1.3472 - val_loss: 0.6257\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.2594 - val_loss: 0.1040\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 468us/step - loss: 0.0791 - val_loss: 0.0150\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 462us/step - loss: 0.0851 - val_loss: 0.0068\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0922 - val_loss: 0.0075\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 461us/step - loss: 0.0855 - val_loss: 0.0123\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 461us/step - loss: 0.0778 - val_loss: 0.0215\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 460us/step - loss: 0.0742 - val_loss: 0.0304\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0735 - val_loss: 0.0355\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0737 - val_loss: 0.0368\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 458us/step - loss: 0.0737 - val_loss: 0.0358\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 460us/step - loss: 0.0736 - val_loss: 0.0340\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 469us/step - loss: 0.0735 - val_loss: 0.0323\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 462us/step - loss: 0.0735 - val_loss: 0.0315\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 460us/step - loss: 0.0735 - val_loss: 0.0308\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 463us/step - loss: 0.0735 - val_loss: 0.0305\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0735 - val_loss: 0.0307\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0735 - val_loss: 0.0312\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 460us/step - loss: 0.0735 - val_loss: 0.0315\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0735 - val_loss: 0.0315\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 460us/step - loss: 0.0735 - val_loss: 0.0315\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 461us/step - loss: 0.0735 - val_loss: 0.0315\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 465us/step - loss: 0.0735 - val_loss: 0.0317\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 461us/step - loss: 0.0735 - val_loss: 0.0317\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 23s 7ms/step - loss: 0.5029 - val_loss: 0.0749\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 339us/step - loss: 0.0353 - val_loss: 0.0330\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 340us/step - loss: 0.0152 - val_loss: 0.0122\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 340us/step - loss: 0.0124 - val_loss: 0.0066\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 341us/step - loss: 0.0089 - val_loss: 0.0063\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 340us/step - loss: 0.0062 - val_loss: 0.0026\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 341us/step - loss: 0.0063 - val_loss: 0.0033\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 345us/step - loss: 0.0057 - val_loss: 0.0041\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 344us/step - loss: 0.0052 - val_loss: 0.0028\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 338us/step - loss: 0.0050 - val_loss: 0.0028\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 339us/step - loss: 0.0050 - val_loss: 0.0033\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 339us/step - loss: 0.0051 - val_loss: 0.0029\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 340us/step - loss: 0.0050 - val_loss: 0.0029\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 340us/step - loss: 0.0050 - val_loss: 0.0030\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 341us/step - loss: 0.0046 - val_loss: 0.0031\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 339us/step - loss: 0.0047 - val_loss: 0.0029\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 340us/step - loss: 0.0047 - val_loss: 0.0029\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 340us/step - loss: 0.0047 - val_loss: 0.0030\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 342us/step - loss: 0.0045 - val_loss: 0.0029\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 342us/step - loss: 0.0045 - val_loss: 0.0028\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 339us/step - loss: 0.0044 - val_loss: 0.0029\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 348us/step - loss: 0.0040 - val_loss: 0.0028\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 343us/step - loss: 0.0045 - val_loss: 0.0028\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 339us/step - loss: 0.0041 - val_loss: 0.0029\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 24s 7ms/step - loss: 0.4240 - val_loss: 0.0457\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 341us/step - loss: 0.0297 - val_loss: 0.0319\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 341us/step - loss: 0.0157 - val_loss: 0.0055\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 340us/step - loss: 0.0101 - val_loss: 0.0191\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 342us/step - loss: 0.0074 - val_loss: 0.0032\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 346us/step - loss: 0.0065 - val_loss: 0.0049\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 344us/step - loss: 0.0053 - val_loss: 0.0079\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 340us/step - loss: 0.0050 - val_loss: 0.0044\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 342us/step - loss: 0.0047 - val_loss: 0.0054\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 349us/step - loss: 0.0044 - val_loss: 0.0054\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 339us/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 342us/step - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 341us/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 341us/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 340us/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 340us/step - loss: 0.0039 - val_loss: 0.0044\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 342us/step - loss: 0.0039 - val_loss: 0.0048\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 342us/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 341us/step - loss: 0.0037 - val_loss: 0.0040\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 347us/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 342us/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 339us/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 342us/step - loss: 0.0037 - val_loss: 0.0044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 340us/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 24s 7ms/step - loss: 0.1561 - val_loss: 0.0150\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 342us/step - loss: 0.0199 - val_loss: 0.0030\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 342us/step - loss: 0.0113 - val_loss: 0.0045\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 349us/step - loss: 0.0068 - val_loss: 0.0038\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 341us/step - loss: 0.0047 - val_loss: 0.0028\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 342us/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 342us/step - loss: 0.0032 - val_loss: 0.0028\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 343us/step - loss: 0.0030 - val_loss: 0.0035\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 341us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 340us/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 342us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 342us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 340us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 343us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 341us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 342us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 346us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 343us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 341us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 342us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 342us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 343us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 342us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 342us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 26s 8ms/step - loss: 0.4078 - val_loss: 0.0580\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0249 - val_loss: 0.0040\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 563us/step - loss: 0.0104 - val_loss: 0.0256\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 563us/step - loss: 0.0076 - val_loss: 0.0032\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 562us/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0036 - val_loss: 0.0073\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0031 - val_loss: 0.0025\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 563us/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 561us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0022 - val_loss: 0.0034\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 561us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 26s 8ms/step - loss: 0.7406 - val_loss: 0.0126\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 426us/step - loss: 0.0434 - val_loss: 0.0596\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 428us/step - loss: 0.0314 - val_loss: 0.0426\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 427us/step - loss: 0.0149 - val_loss: 0.0032\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 432us/step - loss: 0.0077 - val_loss: 0.0037\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 425us/step - loss: 0.0054 - val_loss: 0.0054\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 425us/step - loss: 0.0042 - val_loss: 0.0027\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 425us/step - loss: 0.0037 - val_loss: 0.0062\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 427us/step - loss: 0.0031 - val_loss: 0.0025\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 427us/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 429us/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 424us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 426us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 426us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 426us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 430us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 431us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 427us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 426us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 427us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 425us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 427us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 427us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 425us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "\n",
      "GENERATION 13\n",
      "\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 26s 8ms/step - loss: 0.9492 - val_loss: 0.2688\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 452us/step - loss: 0.1784 - val_loss: 0.0382\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 453us/step - loss: 0.0839 - val_loss: 0.0910\n",
      "Epoch 4/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 452us/step - loss: 0.0733 - val_loss: 0.0144\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 452us/step - loss: 0.0691 - val_loss: 0.0109\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 452us/step - loss: 0.0539 - val_loss: 0.0167\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0298 - val_loss: 0.0133\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 451us/step - loss: 0.0086 - val_loss: 0.0827\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 452us/step - loss: 0.0072 - val_loss: 0.0174\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 457us/step - loss: 0.0059 - val_loss: 0.0159\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 453us/step - loss: 0.0042 - val_loss: 0.0089\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 455us/step - loss: 0.0041 - val_loss: 0.0058\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 453us/step - loss: 0.0036 - val_loss: 0.0054\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 452us/step - loss: 0.0033 - val_loss: 0.0063\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 452us/step - loss: 0.0032 - val_loss: 0.0047\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 452us/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0028 - val_loss: 0.0044\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 454us/step - loss: 0.0027 - val_loss: 0.0052\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 453us/step - loss: 0.0026 - val_loss: 0.0049\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 454us/step - loss: 0.0025 - val_loss: 0.0039\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 453us/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 453us/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 455us/step - loss: 0.0023 - val_loss: 0.0036\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 453us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 26s 8ms/step - loss: 0.0928 - val_loss: 0.0580\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 455us/step - loss: 0.0190 - val_loss: 0.0154\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 457us/step - loss: 0.0082 - val_loss: 0.0061\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 455us/step - loss: 0.0047 - val_loss: 0.0083\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 456us/step - loss: 0.0030 - val_loss: 0.0026\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 457us/step - loss: 0.0025 - val_loss: 0.0045\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 461us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 456us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0020 - val_loss: 0.0030\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 456us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 455us/step - loss: 0.0018 - val_loss: 0.0032\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 457us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 457us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 455us/step - loss: 0.0017 - val_loss: 0.0026\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 457us/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 458us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 461us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 457us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 458us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 456us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 457us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 455us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 453us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 26s 8ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 453us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 456us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 455us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 455us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 457us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 456us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 454us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 455us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 457us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 456us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 455us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 454us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 453us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 455us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 460us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 455us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 456us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 457us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 454us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 455us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 455us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 458us/step - loss: nan - val_loss: nan\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 27s 8ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 481us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: nan - val_loss: nan\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 27s 8ms/step - loss: 4369527650577831936.0000 - val_loss: 15877201.0000\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 1020765128297.7505 - val_loss: 15840358.0000\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 1071439673209.3813 - val_loss: 15784584.0000\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 964907562624.4861 - val_loss: 15710208.0000\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 991949725612.2372 - val_loss: 15605788.0000\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 1090206817880.3995 - val_loss: 15452047.0000\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 955153406130.8933 - val_loss: 15265770.0000\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 1059684773858.0848 - val_loss: 14996793.0000\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 1047397445702.6000 - val_loss: 14664997.0000\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 1009044824238.7052 - val_loss: 15037268.0000\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 971131680968.4324 - val_loss: 45577928.0000\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 914415225828.1788 - val_loss: 1024479552.0000\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 483931169545.7972 - val_loss: 16610404352.0000\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 192011168637.2702 - val_loss: 16370921472.0000\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 165643100451.9731 - val_loss: 12197567488.0000\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 161835586283.8820 - val_loss: 9557006336.0000\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 170492436980.1835 - val_loss: 9758265344.0000\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 177882808822.5767 - val_loss: 7635089408.0000\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 163258305862.3757 - val_loss: 7532373504.0000\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 154836541947.3631 - val_loss: 8639002624.0000\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 207579860055.0535 - val_loss: 5776592896.0000\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 144606124816.3786 - val_loss: 5481442304.0000\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 139903390948.8519 - val_loss: 3467950848.0000\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 149541773094.2168 - val_loss: 4669123072.0000\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 27s 8ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 430us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 430us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 431us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 430us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 430us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 432us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 430us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 430us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 428us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 431us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 433us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 431us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 431us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 432us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 429us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 429us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 430us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 431us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 430us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 431us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 430us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 434us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 430us/step - loss: nan - val_loss: nan\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 29s 8ms/step - loss: 2.5114 - val_loss: 0.0340\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 430us/step - loss: 0.0628 - val_loss: 0.0110\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 432us/step - loss: 0.0472 - val_loss: 0.0058\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 430us/step - loss: 0.0131 - val_loss: 0.0202\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 431us/step - loss: 0.0099 - val_loss: 0.0568\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 431us/step - loss: 0.0087 - val_loss: 0.0277\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 432us/step - loss: 0.0069 - val_loss: 0.0275\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 433us/step - loss: 0.0065 - val_loss: 0.0359\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 431us/step - loss: 0.0062 - val_loss: 0.0360\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 436us/step - loss: 0.0062 - val_loss: 0.0361\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 433us/step - loss: 0.0064 - val_loss: 0.0142\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 433us/step - loss: 0.0064 - val_loss: 0.0252\n",
      "Epoch 13/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 1s 435us/step - loss: 0.0058 - val_loss: 0.0250\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 432us/step - loss: 0.0057 - val_loss: 0.0208\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 432us/step - loss: 0.0056 - val_loss: 0.0210\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 432us/step - loss: 0.0055 - val_loss: 0.0156\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 430us/step - loss: 0.0056 - val_loss: 0.0335\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 430us/step - loss: 0.0074 - val_loss: 0.0070\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 430us/step - loss: 0.0066 - val_loss: 0.0227\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 430us/step - loss: 0.0053 - val_loss: 0.0143\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 436us/step - loss: 0.0053 - val_loss: 0.0240\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 431us/step - loss: 0.0058 - val_loss: 0.0075\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 432us/step - loss: 0.0049 - val_loss: 0.0155\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 433us/step - loss: 0.0049 - val_loss: 0.0059\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 28s 8ms/step - loss: 3.0835 - val_loss: 0.0110\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 430us/step - loss: 0.0408 - val_loss: 0.0047\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 431us/step - loss: 0.0121 - val_loss: 0.0046\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 430us/step - loss: 0.0062 - val_loss: 0.0049\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 429us/step - loss: 0.0055 - val_loss: 0.0044\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 429us/step - loss: 0.0051 - val_loss: 0.0063\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 431us/step - loss: 0.0047 - val_loss: 0.0058\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 429us/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 433us/step - loss: 0.0044 - val_loss: 0.0061\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 428us/step - loss: 0.0044 - val_loss: 0.0053\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 432us/step - loss: 0.0040 - val_loss: 0.0055\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 428us/step - loss: 0.0040 - val_loss: 0.0057\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 429us/step - loss: 0.0040 - val_loss: 0.0053\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 429us/step - loss: 0.0040 - val_loss: 0.0055\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 429us/step - loss: 0.0037 - val_loss: 0.0054\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 429us/step - loss: 0.0037 - val_loss: 0.0060\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 429us/step - loss: 0.0036 - val_loss: 0.0051\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 431us/step - loss: 0.0037 - val_loss: 0.0055\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 429us/step - loss: 0.0034 - val_loss: 0.0058\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 434us/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 428us/step - loss: 0.0036 - val_loss: 0.0050\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 429us/step - loss: 0.0034 - val_loss: 0.0052\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 430us/step - loss: 0.0035 - val_loss: 0.0051\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 428us/step - loss: 0.0033 - val_loss: 0.0048\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 28s 8ms/step - loss: 0.1188 - val_loss: 0.0246\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 491us/step - loss: 0.0723 - val_loss: 0.0233\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 488us/step - loss: 0.0718 - val_loss: 0.0440\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 491us/step - loss: 0.0727 - val_loss: 0.0303\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 494us/step - loss: 0.0708 - val_loss: 0.0280\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 491us/step - loss: 0.0705 - val_loss: 0.0333\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 494us/step - loss: 0.0702 - val_loss: 0.0282\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 492us/step - loss: 0.0698 - val_loss: 0.0368\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 490us/step - loss: 0.0695 - val_loss: 0.0313\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 491us/step - loss: 0.0691 - val_loss: 0.0236\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 492us/step - loss: 0.0704 - val_loss: 0.0239\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 489us/step - loss: 0.0683 - val_loss: 0.0260\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 491us/step - loss: 0.0687 - val_loss: 0.0256\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 491us/step - loss: 0.0688 - val_loss: 0.0234\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 494us/step - loss: 0.0691 - val_loss: 0.0332\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 489us/step - loss: 0.0669 - val_loss: 0.0311\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 491us/step - loss: 0.0664 - val_loss: 0.0171\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 490us/step - loss: 0.0669 - val_loss: 0.0331\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 489us/step - loss: 0.0658 - val_loss: 0.0234\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 492us/step - loss: 0.0652 - val_loss: 0.0219\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 488us/step - loss: 0.0647 - val_loss: 0.0256\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 490us/step - loss: 0.0641 - val_loss: 0.0318\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 490us/step - loss: 0.0636 - val_loss: 0.0325\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 494us/step - loss: 0.0633 - val_loss: 0.0135\n",
      "\n",
      "GENERATION 14\n",
      "\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 28s 8ms/step - loss: 0.1459 - val_loss: 0.0032\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 461us/step - loss: 0.0051 - val_loss: 0.0106\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0133 - val_loss: 0.0029\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 460us/step - loss: 0.0072 - val_loss: 0.0287\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0146 - val_loss: 0.0083\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0135 - val_loss: 0.0235\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 461us/step - loss: 0.0126 - val_loss: 0.0078\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 458us/step - loss: 0.0119 - val_loss: 0.0234\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 458us/step - loss: 0.0169 - val_loss: 0.0028\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 458us/step - loss: 0.0035 - val_loss: 0.0244\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 466us/step - loss: 0.0127 - val_loss: 0.0053\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0083 - val_loss: 0.0111\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0085 - val_loss: 0.0045\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0100 - val_loss: 0.0274\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0079 - val_loss: 0.0026\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0035 - val_loss: 0.0365\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 458us/step - loss: 0.0133 - val_loss: 0.0024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0038 - val_loss: 0.0253\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0067 - val_loss: 0.0040\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0075 - val_loss: 0.0249\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 464us/step - loss: 0.0058 - val_loss: 0.0020\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0048 - val_loss: 0.0235\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 460us/step - loss: 0.0091 - val_loss: 0.0025\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 29s 8ms/step - loss: 0.0754 - val_loss: 0.0426\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 461us/step - loss: 0.0170 - val_loss: 0.0160\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0069 - val_loss: 0.0040\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0039 - val_loss: 0.0064\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 464us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 463us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 458us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 462us/step - loss: 0.0020 - val_loss: 0.0036\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 460us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0017 - val_loss: 0.0027\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 460us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 461us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 466us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 460us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 460us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 461us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 461us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 461us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 460us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 29s 8ms/step - loss: 0.0811 - val_loss: 0.0037\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 462us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 460us/step - loss: 0.0109 - val_loss: 0.0047\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 461us/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 460us/step - loss: 0.0038 - val_loss: 0.0098\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0046 - val_loss: 0.0037\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 458us/step - loss: 0.0036 - val_loss: 0.0077\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0051 - val_loss: 0.0082\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 460us/step - loss: 0.0055 - val_loss: 0.0076\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 461us/step - loss: 0.0032 - val_loss: 0.0023\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 0.0030 - val_loss: 0.0080\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 0.0039 - val_loss: 0.0076\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 460us/step - loss: 0.0063 - val_loss: 0.0099\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 458us/step - loss: 0.0043 - val_loss: 0.0069\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0046 - val_loss: 0.0077\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 458us/step - loss: 0.0033 - val_loss: 0.0023\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0027 - val_loss: 0.0062\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 460us/step - loss: 0.0032 - val_loss: 0.0051\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 458us/step - loss: 0.0058 - val_loss: 0.0100\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0040 - val_loss: 0.0032\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 460us/step - loss: 0.0032 - val_loss: 0.0067\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 467us/step - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 462us/step - loss: 0.0027 - val_loss: 0.0057\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 461us/step - loss: 0.0027 - val_loss: 0.0020\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 30s 9ms/step - loss: 0.0692 - val_loss: 0.0030\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 462us/step - loss: 0.0032 - val_loss: 0.0114\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 458us/step - loss: 0.0065 - val_loss: 0.0027\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 465us/step - loss: 0.0022 - val_loss: 0.0066\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0050 - val_loss: 0.0070\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 458us/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 461us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 460us/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0020 - val_loss: 0.0034\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0072 - val_loss: 0.0111\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0049 - val_loss: 0.0024\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 457us/step - loss: 0.0021 - val_loss: 0.0031\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0016 - val_loss: 0.0025\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 464us/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 458us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 461us/step - loss: 0.0023 - val_loss: 0.0078\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0062 - val_loss: 0.0061\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0052 - val_loss: 0.0060\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 458us/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 458us/step - loss: 0.0015 - val_loss: 0.0021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 458us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 458us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 30s 9ms/step - loss: 13214.9172 - val_loss: 0.2789\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 540us/step - loss: 26.1102 - val_loss: 1.2533\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 537us/step - loss: 15.4155 - val_loss: 1.3181\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 540us/step - loss: 6.7537 - val_loss: 0.0679\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 536us/step - loss: 4.3794 - val_loss: 2.9477\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 537us/step - loss: 1.8783 - val_loss: 0.0440\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 535us/step - loss: 0.4089 - val_loss: 0.0140\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 534us/step - loss: 0.1553 - val_loss: 1.5587\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 540us/step - loss: 1.0417 - val_loss: 0.0089\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 536us/step - loss: 0.1096 - val_loss: 2.3844\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 538us/step - loss: 1.2160 - val_loss: 0.0100\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 538us/step - loss: 0.0473 - val_loss: 0.0085\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 539us/step - loss: 0.5410 - val_loss: 0.1435\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 537us/step - loss: 0.1024 - val_loss: 0.0081\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 536us/step - loss: 0.3696 - val_loss: 0.0176\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 535us/step - loss: 0.0576 - val_loss: 0.3693\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 542us/step - loss: 0.3662 - val_loss: 0.0093\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 541us/step - loss: 0.0114 - val_loss: 0.0817\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 536us/step - loss: 0.5470 - val_loss: 0.0063\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 537us/step - loss: 0.0152 - val_loss: 0.0646\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 536us/step - loss: 0.3083 - val_loss: 0.0129\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 537us/step - loss: 0.0162 - val_loss: 0.0095\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 537us/step - loss: 0.3758 - val_loss: 0.3199\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 538us/step - loss: 0.2051 - val_loss: 0.0080\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 31s 9ms/step - loss: 0.0780 - val_loss: 0.0199\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 0.0182 - val_loss: 0.0042\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 0.0121 - val_loss: 0.0317\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 0.0190 - val_loss: 0.0034\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 0.0040 - val_loss: 0.0123\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 0.0092 - val_loss: 0.0137\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 0.0124 - val_loss: 0.0238\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 0.0119 - val_loss: 0.0087\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 484us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 0.0121 - val_loss: 0.0149\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 0.0077 - val_loss: 0.0038\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 0.0046 - val_loss: 0.0314\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 0.0082 - val_loss: 0.0049\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 0.0049 - val_loss: 0.0410\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 0.0098 - val_loss: 0.0044\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 0.0041 - val_loss: 0.0104\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 0.0053 - val_loss: 0.0051\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 0.0054 - val_loss: 0.0109\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 485us/step - loss: 0.0043 - val_loss: 0.0109\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 0.0078 - val_loss: 0.0093\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 0.0021 - val_loss: 0.0174\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 0.0084 - val_loss: 0.0032\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 0.0031 - val_loss: 0.0073\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 0.0017 - val_loss: 0.0207\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 31s 9ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 503us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 501us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 499us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 501us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 501us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 501us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 500us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 501us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 499us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 507us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 501us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 501us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 500us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 501us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 501us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 500us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 502us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 500us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 504us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 502us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 504us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 501us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 501us/step - loss: nan - val_loss: nan\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 31s 9ms/step - loss: 0.1548 - val_loss: 0.0397\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 486us/step - loss: 0.0666 - val_loss: 0.0217\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 0.0576 - val_loss: 0.0173\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 0.0512 - val_loss: 0.0150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 0.0447 - val_loss: 0.0125\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 0.0392 - val_loss: 0.0108\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 0.0346 - val_loss: 0.0094\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 0.0298 - val_loss: 0.0082\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 0.0254 - val_loss: 0.0065\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 0.0216 - val_loss: 0.0055\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 0.0184 - val_loss: 0.0048\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 485us/step - loss: 0.0155 - val_loss: 0.0044\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 0.0142 - val_loss: 0.0043\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 0.0129 - val_loss: 0.0045\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 0.0113 - val_loss: 0.0049\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 0.0103 - val_loss: 0.0053\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 0.0099 - val_loss: 0.0058\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 0.0093 - val_loss: 0.0064\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 0.0088 - val_loss: 0.0070\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 0.0084 - val_loss: 0.0075\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 487us/step - loss: 0.0082 - val_loss: 0.0079\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 484us/step - loss: 0.0083 - val_loss: 0.0080\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 483us/step - loss: 0.0081 - val_loss: 0.0084\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 0.0079 - val_loss: 0.0089\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 31s 9ms/step - loss: 0.1274 - val_loss: 0.0513\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 0.0606 - val_loss: 0.0282\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 485us/step - loss: 0.0534 - val_loss: 0.0220\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 0.0495 - val_loss: 0.0191\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 0.0458 - val_loss: 0.0176\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 0.0422 - val_loss: 0.0163\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 0.0386 - val_loss: 0.0149\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 0.0355 - val_loss: 0.0141\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 0.0324 - val_loss: 0.0126\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 0.0294 - val_loss: 0.0114\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 0.0266 - val_loss: 0.0099\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 0.0236 - val_loss: 0.0090\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 484us/step - loss: 0.0214 - val_loss: 0.0080\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 483us/step - loss: 0.0189 - val_loss: 0.0068\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 0.0166 - val_loss: 0.0058\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 0.0147 - val_loss: 0.0053\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 483us/step - loss: 0.0130 - val_loss: 0.0045\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 0.0115 - val_loss: 0.0042\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 0.0103 - val_loss: 0.0038\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 0.0092 - val_loss: 0.0037\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 0.0084 - val_loss: 0.0036\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 0.0077 - val_loss: 0.0036\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 483us/step - loss: 0.0072 - val_loss: 0.0037\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 0.0066 - val_loss: 0.0039\n",
      "\n",
      "GENERATION 15\n",
      "\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 32s 9ms/step - loss: 0.0759 - val_loss: 0.0343\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 0.0153 - val_loss: 0.0148\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 0.0078 - val_loss: 0.0034\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 485us/step - loss: 0.0053 - val_loss: 0.0063\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 483us/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 486us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 487us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 32s 9ms/step - loss: 0.0730 - val_loss: 0.0483\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 458us/step - loss: 0.0177 - val_loss: 0.0194\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 458us/step - loss: 0.0072 - val_loss: 0.0050\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 464us/step - loss: 0.0044 - val_loss: 0.0068\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 460us/step - loss: 0.0031 - val_loss: 0.0026\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0021 - val_loss: 0.0033\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 460us/step - loss: 0.0019 - val_loss: 0.0036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 460us/step - loss: 0.0017 - val_loss: 0.0026\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 458us/step - loss: 0.0017 - val_loss: 0.0026\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 457us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 465us/step - loss: 0.0016 - val_loss: 0.0025\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 461us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 460us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 457us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 459us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 464us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 32s 9ms/step - loss: 0.0867 - val_loss: 0.0527\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 417us/step - loss: 0.0228 - val_loss: 0.0310\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 415us/step - loss: 0.0104 - val_loss: 0.0077\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 417us/step - loss: 0.0072 - val_loss: 0.0136\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 428us/step - loss: 0.0054 - val_loss: 0.0026\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 416us/step - loss: 0.0044 - val_loss: 0.0076\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 413us/step - loss: 0.0042 - val_loss: 0.0030\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 415us/step - loss: 0.0037 - val_loss: 0.0053\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 415us/step - loss: 0.0037 - val_loss: 0.0033\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 424us/step - loss: 0.0033 - val_loss: 0.0043\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 423us/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 416us/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 415us/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 417us/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 415us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 423us/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 412us/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 413us/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 415us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 414us/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 415us/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 414us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 412us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 413us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 34s 10ms/step - loss: 0.0708 - val_loss: 0.0297\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 512us/step - loss: 0.0145 - val_loss: 0.0070\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 511us/step - loss: 0.0072 - val_loss: 0.0026\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 511us/step - loss: 0.0050 - val_loss: 0.0037\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 517us/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 514us/step - loss: 0.0035 - val_loss: 0.0027\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 513us/step - loss: 0.0035 - val_loss: 0.0050\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 513us/step - loss: 0.0032 - val_loss: 0.0026\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 512us/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 511us/step - loss: 0.0029 - val_loss: 0.0027\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 513us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 512us/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 512us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 518us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 516us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 513us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 513us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 513us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 513us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 515us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 512us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 513us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 515us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 514us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 34s 10ms/step - loss: 0.0678 - val_loss: 0.0249\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 516us/step - loss: 0.0111 - val_loss: 0.0029\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 511us/step - loss: 0.0068 - val_loss: 0.0220\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 512us/step - loss: 0.0083 - val_loss: 0.0026\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 512us/step - loss: 0.0047 - val_loss: 0.0094\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 512us/step - loss: 0.0037 - val_loss: 0.0026\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 511us/step - loss: 0.0057 - val_loss: 0.0142\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 512us/step - loss: 0.0062 - val_loss: 0.0023\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 512us/step - loss: 0.0042 - val_loss: 0.0065\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 516us/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 514us/step - loss: 0.0046 - val_loss: 0.0133\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 0.0038 - val_loss: 0.0023\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 512us/step - loss: 0.0048 - val_loss: 0.0112\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 511us/step - loss: 0.0031 - val_loss: 0.0025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 0.0024 - val_loss: 0.0093\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 0.0042 - val_loss: 0.0021\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 513us/step - loss: 0.0031 - val_loss: 0.0062\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 512us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 517us/step - loss: 0.0018 - val_loss: 0.0050\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 515us/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 514us/step - loss: 0.0041 - val_loss: 0.0085\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 511us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 513us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 512us/step - loss: 0.0028 - val_loss: 0.0023\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 34s 10ms/step - loss: 0.1508 - val_loss: 0.0036\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 515us/step - loss: 0.0062 - val_loss: 0.0037\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 514us/step - loss: 0.0059 - val_loss: 0.0038\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 513us/step - loss: 0.0050 - val_loss: 0.0043\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 514us/step - loss: 0.0046 - val_loss: 0.0032\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 517us/step - loss: 0.0047 - val_loss: 0.0036\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 515us/step - loss: 0.0044 - val_loss: 0.0058\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 512us/step - loss: 0.0084 - val_loss: 0.0131\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 513us/step - loss: 0.0120 - val_loss: 0.0149\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 515us/step - loss: 0.0085 - val_loss: 0.0060\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 516us/step - loss: 0.0077 - val_loss: 0.0191\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 514us/step - loss: 0.0107 - val_loss: 0.0047\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 513us/step - loss: 0.0066 - val_loss: 0.0134\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 511us/step - loss: 0.0092 - val_loss: 0.0098\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 512us/step - loss: 0.0086 - val_loss: 0.0148\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 518us/step - loss: 0.0084 - val_loss: 0.0066\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 513us/step - loss: 0.0072 - val_loss: 0.0157\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 513us/step - loss: 0.0095 - val_loss: 0.0099\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 514us/step - loss: 0.0088 - val_loss: 0.0119\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 513us/step - loss: 0.0069 - val_loss: 0.0051\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 514us/step - loss: 0.0087 - val_loss: 0.0094\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 513us/step - loss: 0.0048 - val_loss: 0.0022\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 513us/step - loss: 0.0054 - val_loss: 0.0169\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 513us/step - loss: 0.0093 - val_loss: 0.0100\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 35s 10ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 515us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 511us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 511us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 515us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 512us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 515us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 512us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: nan - val_loss: nan\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 35s 10ms/step - loss: 0.0827 - val_loss: 0.0179\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0750 - val_loss: 0.0432\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0722 - val_loss: 0.0402\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 560us/step - loss: 0.0752 - val_loss: 0.0156\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0628 - val_loss: 0.0286\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 562us/step - loss: 0.0421 - val_loss: 0.0141\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0350 - val_loss: 0.0047\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 562us/step - loss: 0.0116 - val_loss: 0.0273\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 560us/step - loss: 0.0073 - val_loss: 0.0097\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 562us/step - loss: 0.0062 - val_loss: 0.0117\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0045 - val_loss: 0.0041\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0046 - val_loss: 0.0157\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0032 - val_loss: 0.0054\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 562us/step - loss: 0.0037 - val_loss: 0.0319\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 565us/step - loss: 0.0039 - val_loss: 0.0053\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 561us/step - loss: 0.0027 - val_loss: 0.0056\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 560us/step - loss: 0.0026 - val_loss: 0.0070\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 561us/step - loss: 0.0024 - val_loss: 0.0045\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 562us/step - loss: 0.0027 - val_loss: 0.0123\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 560us/step - loss: 0.0025 - val_loss: 0.0049\n",
      "Epoch 21/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0029 - val_loss: 0.0181\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 560us/step - loss: 0.0029 - val_loss: 0.0057\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0022 - val_loss: 0.0088\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 35s 10ms/step - loss: 0.2872 - val_loss: 0.0781\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0426 - val_loss: 0.0255\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 561us/step - loss: 0.0157 - val_loss: 0.0122\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0096 - val_loss: 0.0060\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0072 - val_loss: 0.0106\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0060 - val_loss: 0.0060\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 565us/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 563us/step - loss: 0.0042 - val_loss: 0.0049\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0042 - val_loss: 0.0035\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 563us/step - loss: 0.0042 - val_loss: 0.0034\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0040 - val_loss: 0.0034\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 561us/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 561us/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 562us/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 563us/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 561us/step - loss: 0.0039 - val_loss: 0.0033\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0037 - val_loss: 0.0030\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 560us/step - loss: 0.0041 - val_loss: 0.0030\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 563us/step - loss: 0.0039 - val_loss: 0.0029\n",
      "\n",
      "GENERATION 16\n",
      "\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 36s 10ms/step - loss: 0.1821 - val_loss: 0.0650\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 483us/step - loss: 0.0777 - val_loss: 0.0074\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 0.0860 - val_loss: 0.0112\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 483us/step - loss: 0.0753 - val_loss: 0.0323\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 0.0714 - val_loss: 0.0391\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 0.0674 - val_loss: 0.0287\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 0.0571 - val_loss: 0.0151\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 0.0433 - val_loss: 0.0078\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 484us/step - loss: 0.0282 - val_loss: 0.0073\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 0.0182 - val_loss: 0.0165\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 484us/step - loss: 0.0133 - val_loss: 0.0308\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 484us/step - loss: 0.0117 - val_loss: 0.0523\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 0.0078 - val_loss: 0.0565\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 487us/step - loss: 0.0057 - val_loss: 0.0466\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 483us/step - loss: 0.0047 - val_loss: 0.0402\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 0.0042 - val_loss: 0.0378\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 0.0038 - val_loss: 0.0392\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 0.0036 - val_loss: 0.0419\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 485us/step - loss: 0.0041 - val_loss: 0.0374\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 0.0035 - val_loss: 0.0361\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 0.0035 - val_loss: 0.0562\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 0.0034 - val_loss: 0.0531\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 0.0033 - val_loss: 0.0542\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 0.0032 - val_loss: 0.0542\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 36s 10ms/step - loss: 0.0429 - val_loss: 0.0032\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 464us/step - loss: 0.0072 - val_loss: 0.0072\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 0.0055 - val_loss: 0.0117\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 466us/step - loss: 0.0035 - val_loss: 0.0027\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 464us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 464us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 464us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 464us/step - loss: 0.0020 - val_loss: 0.0030\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 465us/step - loss: 0.0019 - val_loss: 0.0030\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 464us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 464us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 461us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 470us/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 468us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 466us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 464us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 465us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 463us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 465us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 464us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 464us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 471us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 464us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 36s 11ms/step - loss: 0.0862 - val_loss: 0.0317\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 467us/step - loss: 0.0164 - val_loss: 0.0193\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 464us/step - loss: 0.0063 - val_loss: 0.0029\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 464us/step - loss: 0.0038 - val_loss: 0.0048\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 466us/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 465us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 467us/step - loss: 0.0023 - val_loss: 0.0048\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 467us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 466us/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 465us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 463us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 467us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 464us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 464us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 466us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 465us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 466us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 466us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 466us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 463us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 465us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 466us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 466us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 465us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 38s 11ms/step - loss: 0.3224 - val_loss: 0.0689\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 0.0464 - val_loss: 0.0045\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 0.0247 - val_loss: 0.0031\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 0.0126 - val_loss: 0.0085\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 0.0079 - val_loss: 0.0032\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 0.0062 - val_loss: 0.0116\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 483us/step - loss: 0.0051 - val_loss: 0.0028\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 483us/step - loss: 0.0047 - val_loss: 0.0073\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 483us/step - loss: 0.0042 - val_loss: 0.0031\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 489us/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 483us/step - loss: 0.0037 - val_loss: 0.0040\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 483us/step - loss: 0.0034 - val_loss: 0.0040\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 485us/step - loss: 0.0032 - val_loss: 0.0037\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 483us/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 483us/step - loss: 0.0031 - val_loss: 0.0041\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 488us/step - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 483us/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 38s 11ms/step - loss: 0.4223 - val_loss: 0.0207\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 490us/step - loss: 0.0484 - val_loss: 0.0200\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 484us/step - loss: 0.0231 - val_loss: 0.0068\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 486us/step - loss: 0.0103 - val_loss: 0.0302\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 489us/step - loss: 0.0078 - val_loss: 0.0027\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 486us/step - loss: 0.0063 - val_loss: 0.0064\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 486us/step - loss: 0.0046 - val_loss: 0.0051\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 487us/step - loss: 0.0040 - val_loss: 0.0027\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 484us/step - loss: 0.0036 - val_loss: 0.0055\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 486us/step - loss: 0.0032 - val_loss: 0.0028\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 485us/step - loss: 0.0032 - val_loss: 0.0041\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 491us/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 484us/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 488us/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 485us/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 487us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 494us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 486us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 487us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 487us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 491us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 501us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 504us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 494us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 38s 11ms/step - loss: 1.3194 - val_loss: 0.1289\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 439us/step - loss: 0.0546 - val_loss: 0.0765\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 447us/step - loss: 0.0187 - val_loss: 0.0222\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 442us/step - loss: 0.0196 - val_loss: 0.0025\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 440us/step - loss: 0.0067 - val_loss: 0.0162\n",
      "Epoch 6/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 441us/step - loss: 0.0065 - val_loss: 0.0031\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 441us/step - loss: 0.0046 - val_loss: 0.0025\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 441us/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 440us/step - loss: 0.0037 - val_loss: 0.0053\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 443us/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 439us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 442us/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 442us/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 445us/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 440us/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 443us/step - loss: 0.0031 - val_loss: 0.0034\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 443us/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 441us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 440us/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 438us/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 440us/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 441us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 441us/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 447us/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 39s 11ms/step - loss: 1.0172 - val_loss: 0.0287\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 440us/step - loss: 0.0674 - val_loss: 0.0287\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 441us/step - loss: 0.0219 - val_loss: 0.0310\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 441us/step - loss: 0.0256 - val_loss: 0.0030\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 442us/step - loss: 0.0097 - val_loss: 0.0165\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 448us/step - loss: 0.0076 - val_loss: 0.0047\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 439us/step - loss: 0.0057 - val_loss: 0.0030\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 439us/step - loss: 0.0053 - val_loss: 0.0063\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 441us/step - loss: 0.0046 - val_loss: 0.0067\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 442us/step - loss: 0.0044 - val_loss: 0.0040\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 441us/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 441us/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 441us/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 439us/step - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 441us/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 441us/step - loss: 0.0039 - val_loss: 0.0041\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 446us/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 441us/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 441us/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 441us/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 439us/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 441us/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 442us/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 441us/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 39s 11ms/step - loss: 0.0730 - val_loss: 0.0240\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 361us/step - loss: 0.0632 - val_loss: 0.0209\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 362us/step - loss: 0.0474 - val_loss: 0.0074\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 362us/step - loss: 0.0381 - val_loss: 0.0066\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 363us/step - loss: 0.0427 - val_loss: 0.0093\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 362us/step - loss: 0.0667 - val_loss: 0.0079\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 361us/step - loss: 0.0638 - val_loss: 0.0185\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 362us/step - loss: 0.0390 - val_loss: 0.0076\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 362us/step - loss: 0.0281 - val_loss: 0.0184\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 372us/step - loss: 0.0197 - val_loss: 0.0170\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 361us/step - loss: 0.0232 - val_loss: 0.0250\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 364us/step - loss: 0.0394 - val_loss: 0.0104\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 362us/step - loss: 0.0334 - val_loss: 0.0093\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 362us/step - loss: 0.0376 - val_loss: 0.0074\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 363us/step - loss: 0.0291 - val_loss: 0.0090\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 365us/step - loss: 0.0204 - val_loss: 0.0173\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 363us/step - loss: 0.0130 - val_loss: 0.0279\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 363us/step - loss: 0.0100 - val_loss: 0.0375\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 362us/step - loss: 0.0079 - val_loss: 0.0464\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 362us/step - loss: 0.0072 - val_loss: 0.0555\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 362us/step - loss: 0.0068 - val_loss: 0.0582\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 365us/step - loss: 0.0061 - val_loss: 0.0528\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 368us/step - loss: 0.0057 - val_loss: 0.0512\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 363us/step - loss: 0.0053 - val_loss: 0.0496\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 39s 11ms/step - loss: 0.0602 - val_loss: 0.0059\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 362us/step - loss: 0.0078 - val_loss: 0.0162\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 360us/step - loss: 0.0053 - val_loss: 0.0027\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 371us/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 362us/step - loss: 0.0036 - val_loss: 0.0086\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 361us/step - loss: 0.0032 - val_loss: 0.0043\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 362us/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 362us/step - loss: 0.0027 - val_loss: 0.0046\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 363us/step - loss: 0.0026 - val_loss: 0.0044\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 364us/step - loss: 0.0024 - val_loss: 0.0038\n",
      "Epoch 11/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 1s 362us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 364us/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 362us/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 362us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 360us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 360us/step - loss: 0.0022 - val_loss: 0.0032\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 367us/step - loss: 0.0022 - val_loss: 0.0032\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 367us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 361us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 364us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 367us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 362us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 362us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 361us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "\n",
      "GENERATION 17\n",
      "\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 40s 12ms/step - loss: 0.0751 - val_loss: 0.0303\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 466us/step - loss: 0.0139 - val_loss: 0.0044\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 464us/step - loss: 0.0068 - val_loss: 0.0028\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 464us/step - loss: 0.0036 - val_loss: 0.0026\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 469us/step - loss: 0.0029 - val_loss: 0.0055\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 466us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 468us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 466us/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 467us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 464us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 467us/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 465us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 471us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 467us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 468us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 471us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 466us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 465us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 467us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 467us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 466us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 467us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 467us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 39s 12ms/step - loss: 0.0437 - val_loss: 0.0100\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 0.0081 - val_loss: 0.0037\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 469us/step - loss: 0.0049 - val_loss: 0.0118\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 467us/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 468us/step - loss: 0.0028 - val_loss: 0.0044\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 470us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 469us/step - loss: 0.0022 - val_loss: 0.0034\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 469us/step - loss: 0.0020 - val_loss: 0.0034\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 469us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 469us/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 468us/step - loss: 0.0017 - val_loss: 0.0026\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 470us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 469us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 472us/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 469us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 468us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 469us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 470us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 468us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 468us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 469us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 469us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 41s 12ms/step - loss: 0.0544 - val_loss: 0.0316\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 410us/step - loss: 0.0128 - val_loss: 0.0090\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 415us/step - loss: 0.0054 - val_loss: 0.0029\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 407us/step - loss: 0.0035 - val_loss: 0.0028\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 406us/step - loss: 0.0030 - val_loss: 0.0058\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 403us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 406us/step - loss: 0.0023 - val_loss: 0.0042\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 403us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 404us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 405us/step - loss: 0.0019 - val_loss: 0.0032\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 404us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 406us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 405us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 406us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 409us/step - loss: 0.0016 - val_loss: 0.0020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 404us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 404us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 405us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 406us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 405us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 404us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 404us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 406us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 405us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 41s 12ms/step - loss: 0.0766 - val_loss: 0.0094\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 494us/step - loss: 0.0100 - val_loss: 0.0052\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 497us/step - loss: 0.0062 - val_loss: 0.0159\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 495us/step - loss: 0.0042 - val_loss: 0.0031\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 492us/step - loss: 0.0031 - val_loss: 0.0046\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 493us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 492us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 494us/step - loss: 0.0020 - val_loss: 0.0034\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 494us/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 494us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 494us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 497us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 498us/step - loss: 0.0017 - val_loss: 0.0026\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 493us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 496us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 495us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 494us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 494us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 494us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 497us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 494us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 499us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 494us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 496us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 43s 12ms/step - loss: 0.0818 - val_loss: 0.0158\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0129 - val_loss: 0.0045\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 551us/step - loss: 0.0081 - val_loss: 0.0120\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 550us/step - loss: 0.0050 - val_loss: 0.0032\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 550us/step - loss: 0.0038 - val_loss: 0.0084\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 550us/step - loss: 0.0031 - val_loss: 0.0024\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 568us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 551us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 550us/step - loss: 0.0023 - val_loss: 0.0036\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 552us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 550us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 550us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 551us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 547us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 562us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 549us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 550us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 551us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 550us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 551us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 552us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 42s 12ms/step - loss: 0.0518 - val_loss: 0.0063\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0083 - val_loss: 0.0058\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0054 - val_loss: 0.0025\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0041 - val_loss: 0.0102\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 552us/step - loss: 0.0028 - val_loss: 0.0023\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0027 - val_loss: 0.0046\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 553us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 552us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 561us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0016 - val_loss: 0.0019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 552us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 44s 13ms/step - loss: 0.0840 - val_loss: 0.0499\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 529us/step - loss: 0.0210 - val_loss: 0.0147\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 532us/step - loss: 0.0098 - val_loss: 0.0038\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 525us/step - loss: 0.0058 - val_loss: 0.0054\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 528us/step - loss: 0.0045 - val_loss: 0.0033\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 528us/step - loss: 0.0039 - val_loss: 0.0028\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 529us/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 539us/step - loss: 0.0032 - val_loss: 0.0027\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 527us/step - loss: 0.0028 - val_loss: 0.0040\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 526us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 527us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 526us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 528us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 529us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 527us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 526us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 529us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 526us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 527us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 532us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 527us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 526us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 527us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 524us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 42s 12ms/step - loss: 0.0672 - val_loss: 0.0206\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 526us/step - loss: 0.0125 - val_loss: 0.0063\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 527us/step - loss: 0.0065 - val_loss: 0.0033\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 534us/step - loss: 0.0046 - val_loss: 0.0031\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 525us/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 526us/step - loss: 0.0033 - val_loss: 0.0027\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 528us/step - loss: 0.0031 - val_loss: 0.0046\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 528us/step - loss: 0.0030 - val_loss: 0.0025\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 525us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 528us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 534us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 529us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 534us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 528us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 529us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 528us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 527us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 526us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 529us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 527us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 529us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 530us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 525us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 526us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 44s 13ms/step - loss: 0.1567 - val_loss: 0.0030\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 546us/step - loss: 0.0051 - val_loss: 0.0040\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 545us/step - loss: 0.0071 - val_loss: 0.0088\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 551us/step - loss: 0.0039 - val_loss: 0.0028\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 544us/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 547us/step - loss: 0.0030 - val_loss: 0.0051\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 545us/step - loss: 0.0035 - val_loss: 0.0055\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 545us/step - loss: 0.0067 - val_loss: 0.0078\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 544us/step - loss: 0.0032 - val_loss: 0.0026\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 545us/step - loss: 0.0029 - val_loss: 0.0076\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 545us/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 546us/step - loss: 0.0036 - val_loss: 0.0066\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 549us/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 546us/step - loss: 0.0038 - val_loss: 0.0083\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 546us/step - loss: 0.0046 - val_loss: 0.0028\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 548us/step - loss: 0.0037 - val_loss: 0.0060\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 547us/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 548us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 545us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 547us/step - loss: 0.0054 - val_loss: 0.0117\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 550us/step - loss: 0.0045 - val_loss: 0.0019\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 547us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 544us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 553us/step - loss: 0.0023 - val_loss: 0.0060\n",
      "\n",
      "GENERATION 18\n",
      "\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 43s 13ms/step - loss: 0.0836 - val_loss: 0.0197\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 487us/step - loss: 0.0120 - val_loss: 0.0045\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 486us/step - loss: 0.0051 - val_loss: 0.0097\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 495us/step - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 487us/step - loss: 0.0032 - val_loss: 0.0057\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 487us/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 489us/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 489us/step - loss: 0.0026 - val_loss: 0.0041\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 487us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 487us/step - loss: 0.0025 - val_loss: 0.0038\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 488us/step - loss: 0.0024 - val_loss: 0.0036\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 489us/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 490us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 495us/step - loss: 0.0022 - val_loss: 0.0033\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 499us/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 494us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 489us/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 487us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 490us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 488us/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 488us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 491us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 494us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 488us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 45s 13ms/step - loss: 0.0399 - val_loss: 0.0034\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 507us/step - loss: 0.0063 - val_loss: 0.0056\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 0.0049 - val_loss: 0.0088\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 515us/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 506us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 506us/step - loss: 0.0023 - val_loss: 0.0049\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 504us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 506us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 506us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 502us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 0.0017 - val_loss: 0.0027\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 503us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 507us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 506us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 507us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 506us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 507us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 506us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 506us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 511us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 513us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 504us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 45s 13ms/step - loss: 0.0718 - val_loss: 0.0326\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 500us/step - loss: 0.0141 - val_loss: 0.0061\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 502us/step - loss: 0.0070 - val_loss: 0.0035\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 0.0042 - val_loss: 0.0026\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 504us/step - loss: 0.0034 - val_loss: 0.0071\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 504us/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 502us/step - loss: 0.0024 - val_loss: 0.0047\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 502us/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 505us/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 504us/step - loss: 0.0019 - val_loss: 0.0031\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 504us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 505us/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 506us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 505us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 503us/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 502us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 502us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 505us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 502us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 504us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 502us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 505us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 47s 14ms/step - loss: 0.0752 - val_loss: 0.0052\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 568us/step - loss: 0.0098 - val_loss: 0.0053\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 567us/step - loss: 0.0067 - val_loss: 0.0134\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 567us/step - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 568us/step - loss: 0.0032 - val_loss: 0.0079\n",
      "Epoch 6/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 564us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 566us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 568us/step - loss: 0.0021 - val_loss: 0.0035\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 567us/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0019 - val_loss: 0.0031\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0019 - val_loss: 0.0031\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 567us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 567us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 567us/step - loss: 0.0017 - val_loss: 0.0026\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0016 - val_loss: 0.0025\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 567us/step - loss: 0.0016 - val_loss: 0.0025\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 568us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 568us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 565us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 568us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 47s 14ms/step - loss: 0.0581 - val_loss: 0.0183\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 590us/step - loss: 0.0097 - val_loss: 0.0044\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 590us/step - loss: 0.0052 - val_loss: 0.0026\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 0.0037 - val_loss: 0.0031\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: 0.0033 - val_loss: 0.0040\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 590us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 590us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 589us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 590us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 48s 14ms/step - loss: 0.0575 - val_loss: 0.0098\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: 0.0102 - val_loss: 0.0063\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 0.0065 - val_loss: 0.0037\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 0.0046 - val_loss: 0.0085\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 0.0038 - val_loss: 0.0025\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 0.0036 - val_loss: 0.0032\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: 0.0033 - val_loss: 0.0049\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 0.0030 - val_loss: 0.0038\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 0.0022 - val_loss: 0.0033\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 48s 14ms/step - loss: 1.5130 - val_loss: 0.0311\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: 0.0124 - val_loss: 0.0070\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 0.0058 - val_loss: 0.0114\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 0.0053 - val_loss: 0.0087\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 589us/step - loss: 0.0046 - val_loss: 0.0099\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: 0.0046 - val_loss: 0.0119\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 0.0043 - val_loss: 0.0090\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 0.0042 - val_loss: 0.0099\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: 0.0044 - val_loss: 0.0098\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: 0.0042 - val_loss: 0.0065\n",
      "Epoch 11/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 592us/step - loss: 0.0040 - val_loss: 0.0094\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 589us/step - loss: 0.0039 - val_loss: 0.0079\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 0.0038 - val_loss: 0.0062\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: 0.0037 - val_loss: 0.0074\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 590us/step - loss: 0.0036 - val_loss: 0.0078\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 0.0036 - val_loss: 0.0074\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 0.0035 - val_loss: 0.0061\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 0.0035 - val_loss: 0.0081\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: 0.0034 - val_loss: 0.0052\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 0.0034 - val_loss: 0.0068\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 0.0035 - val_loss: 0.0062\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 590us/step - loss: 0.0032 - val_loss: 0.0062\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 0.0032 - val_loss: 0.0072\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 0.0032 - val_loss: 0.0054\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 48s 14ms/step - loss: 0.2309 - val_loss: 0.2259\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 0.1470 - val_loss: 0.1373\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 590us/step - loss: 0.1030 - val_loss: 0.0872\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 590us/step - loss: 0.0806 - val_loss: 0.0577\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 589us/step - loss: 0.0694 - val_loss: 0.0410\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 590us/step - loss: 0.0635 - val_loss: 0.0314\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 0.0595 - val_loss: 0.0258\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 589us/step - loss: 0.0567 - val_loss: 0.0223\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 0.0552 - val_loss: 0.0200\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: 0.0535 - val_loss: 0.0180\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 590us/step - loss: 0.0517 - val_loss: 0.0170\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: 0.0502 - val_loss: 0.0159\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 590us/step - loss: 0.0489 - val_loss: 0.0151\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 590us/step - loss: 0.0473 - val_loss: 0.0144\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 0.0456 - val_loss: 0.0136\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 0.0442 - val_loss: 0.0131\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 0.0422 - val_loss: 0.0123\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 0.0407 - val_loss: 0.0117\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 0.0388 - val_loss: 0.0110\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 0.0372 - val_loss: 0.0104\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 0.0349 - val_loss: 0.0096\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 610us/step - loss: 0.0334 - val_loss: 0.0089\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 0.0312 - val_loss: 0.0081\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 0.0293 - val_loss: 0.0074\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 49s 14ms/step - loss: 0.0643 - val_loss: 0.0095\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 0.0237 - val_loss: 0.0064\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 0.0159 - val_loss: 0.0052\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 0.0112 - val_loss: 0.0040\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 0.0078 - val_loss: 0.0039\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 0.0061 - val_loss: 0.0037\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 0.0052 - val_loss: 0.0036\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 0.0044 - val_loss: 0.0037\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 0.0042 - val_loss: 0.0038\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 0.0037 - val_loss: 0.0040\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 0.0038 - val_loss: 0.0041\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 602us/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 0.0037 - val_loss: 0.0042\n",
      "\n",
      "GENERATION 19\n",
      "\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 50s 15ms/step - loss: 0.0547 - val_loss: 0.0076\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 0.0092 - val_loss: 0.0037\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 472us/step - loss: 0.0057 - val_loss: 0.0125\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 0.0038 - val_loss: 0.0031\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 0.0031 - val_loss: 0.0060\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 0.0017 - val_loss: 0.0026\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 0.0016 - val_loss: 0.0024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 49s 14ms/step - loss: 0.0642 - val_loss: 0.0291\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 501us/step - loss: 0.0130 - val_loss: 0.0141\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 504us/step - loss: 0.0058 - val_loss: 0.0027\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 507us/step - loss: 0.0038 - val_loss: 0.0063\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 503us/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 502us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 502us/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 504us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 505us/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 503us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 502us/step - loss: 0.0018 - val_loss: 0.0030\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 503us/step - loss: 0.0017 - val_loss: 0.0026\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 504us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 503us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 505us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 506us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 503us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 503us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 504us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 507us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 50s 15ms/step - loss: 0.0859 - val_loss: 0.0093\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 491us/step - loss: 0.0117 - val_loss: 0.0066\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 492us/step - loss: 0.0069 - val_loss: 0.0177\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 492us/step - loss: 0.0043 - val_loss: 0.0026\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 494us/step - loss: 0.0030 - val_loss: 0.0050\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 491us/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 491us/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 496us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 492us/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 495us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 494us/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 494us/step - loss: 0.0017 - val_loss: 0.0026\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 492us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 490us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 491us/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 492us/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 493us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 497us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 492us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 490us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 491us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 491us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 494us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 493us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 51s 15ms/step - loss: 0.0743 - val_loss: 0.0328\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0141 - val_loss: 0.0169\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 567us/step - loss: 0.0060 - val_loss: 0.0049\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 568us/step - loss: 0.0043 - val_loss: 0.0088\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 568us/step - loss: 0.0031 - val_loss: 0.0024\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 568us/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 568us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 568us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 568us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 568us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 568us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 568us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 568us/step - loss: 0.0018 - val_loss: 0.0019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 566us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 53s 15ms/step - loss: 0.0814 - val_loss: 0.0205\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0151 - val_loss: 0.0151\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0062 - val_loss: 0.0030\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 567us/step - loss: 0.0052 - val_loss: 0.0099\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 568us/step - loss: 0.0042 - val_loss: 0.0029\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0038 - val_loss: 0.0041\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0032 - val_loss: 0.0040\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 52s 15ms/step - loss: 0.0724 - val_loss: 0.0036\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0057 - val_loss: 0.0113\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0091 - val_loss: 0.0033\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0043 - val_loss: 0.0084\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0082 - val_loss: 0.0061\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0036 - val_loss: 0.0026\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 568us/step - loss: 0.0040 - val_loss: 0.0068\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0059 - val_loss: 0.0098\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0041 - val_loss: 0.0026\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0040 - val_loss: 0.0072\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0047 - val_loss: 0.0027\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0031 - val_loss: 0.0063\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0034 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0055 - val_loss: 0.0077\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0032 - val_loss: 0.0017\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0029 - val_loss: 0.0068\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0040 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0031 - val_loss: 0.0059\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0028 - val_loss: 0.0039\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 53s 16ms/step - loss: 0.0673 - val_loss: 0.0045\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 568us/step - loss: 0.0048 - val_loss: 0.0037\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0128 - val_loss: 0.0076\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 568us/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 567us/step - loss: 0.0033 - val_loss: 0.0119\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 568us/step - loss: 0.0101 - val_loss: 0.0026\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0030 - val_loss: 0.0026\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 568us/step - loss: 0.0043 - val_loss: 0.0192\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 566us/step - loss: 0.0075 - val_loss: 0.0029\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0033 - val_loss: 0.0044\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0030 - val_loss: 0.0023\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0038 - val_loss: 0.0099\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0056 - val_loss: 0.0036\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0043 - val_loss: 0.0040\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0038 - val_loss: 0.0069\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0029 - val_loss: 0.0018\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0028 - val_loss: 0.0055\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0032 - val_loss: 0.0064\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 568us/step - loss: 0.0032 - val_loss: 0.0023\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 568us/step - loss: 0.0030 - val_loss: 0.0084\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0030 - val_loss: 0.0016\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 53s 16ms/step - loss: 0.6188 - val_loss: 0.0059\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 513us/step - loss: 0.0155 - val_loss: 0.0048\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 512us/step - loss: 0.0069 - val_loss: 0.0049\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 511us/step - loss: 0.0064 - val_loss: 0.0063\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 518us/step - loss: 0.0055 - val_loss: 0.0043\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 513us/step - loss: 0.0054 - val_loss: 0.0042\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 515us/step - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 513us/step - loss: 0.0054 - val_loss: 0.0055\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 513us/step - loss: 0.0051 - val_loss: 0.0046\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 512us/step - loss: 0.0046 - val_loss: 0.0064\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 513us/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 511us/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 512us/step - loss: 0.0046 - val_loss: 0.0059\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 518us/step - loss: 0.0049 - val_loss: 0.0038\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 513us/step - loss: 0.0043 - val_loss: 0.0041\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 512us/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 514us/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 512us/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 514us/step - loss: 0.0039 - val_loss: 0.0053\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 515us/step - loss: 0.0040 - val_loss: 0.0033\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 512us/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 523us/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 511us/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 53s 16ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 516us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 523us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 516us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 515us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 517us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 518us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 516us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 517us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 515us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 516us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 521us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 517us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 518us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 515us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 515us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 515us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 519us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 517us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 518us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 522us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 517us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 518us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 520us/step - loss: nan - val_loss: nan\n"
     ]
    }
   ],
   "source": [
    "best_models = breed_population(X_train, Y_train, generations=20, population_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.003136134473606944,\n",
       " 0.004474661312997341,\n",
       " 0.014259579591453075,\n",
       " 0.0026155197992920876,\n",
       " 0.004734313581138849,\n",
       " 0.004235910717397928,\n",
       " 0.00271443254314363,\n",
       " 0.0038245064206421375,\n",
       " 0.002922791289165616,\n",
       " 0.0024768321309238672,\n",
       " 0.0025739213451743126,\n",
       " 0.002595022087916732,\n",
       " 0.0025253870990127325,\n",
       " 0.002212777966633439,\n",
       " 0.002104748273268342,\n",
       " 0.0019132749876007438,\n",
       " 0.001775100827217102,\n",
       " 0.0017170206410810351,\n",
       " 0.0017738332971930504,\n",
       " 0.0016441865591332316,\n",
       " 0.0016519135097041726,\n",
       " 0.001608233549632132,\n",
       " 0.001631064573302865,\n",
       " 0.0015881020808592439]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models[0][1].history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal parameters\n",
      "_______________________\n",
      "twice: True\n",
      "shuffle: True\n",
      "lstmsize: 132\n",
      "full_density: True\n",
      "density: 148\n",
      "activation: elu\n",
      "optimizer: adam\n"
     ]
    }
   ],
   "source": [
    "print('optimal parameters')\n",
    "print('_______________________')\n",
    "for key,val in best_models[0][2].items():\n",
    "    if key != 'x' and key != 'y': print(f'{key}: {val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_87\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_173 (LSTM)              (None, 92, 132)           72864     \n",
      "_________________________________________________________________\n",
      "lstm_174 (LSTM)              (None, 132)               139920    \n",
      "_________________________________________________________________\n",
      "dense_432 (Dense)            (None, 148)               19684     \n",
      "_________________________________________________________________\n",
      "dense_433 (Dense)            (None, 74)                11026     \n",
      "_________________________________________________________________\n",
      "dense_434 (Dense)            (None, 37)                2775      \n",
      "_________________________________________________________________\n",
      "dense_435 (Dense)            (None, 18)                684       \n",
      "_________________________________________________________________\n",
      "dense_436 (Dense)            (None, 1)                 19        \n",
      "=================================================================\n",
      "Total params: 246,972\n",
      "Trainable params: 246,972\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_models[0][0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibm_checkpoint = ModelCheckpoint(\n",
    "    filepath='./checkpoints/IBM.{epoch}-{val_loss}.hdf5',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = best_models[0][2]\n",
    "params['x'] = X_train\n",
    "params['y'] = Y_train\n",
    "params['epochs'] = 2000\n",
    "params['callbacks'] = [ibm_checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/2000\n",
      "3423/3423 [==============================] - 54s 16ms/step - loss: 0.0800 - val_loss: 0.0470\n",
      "Epoch 2/2000\n",
      "3423/3423 [==============================] - 2s 492us/step - loss: 0.0185 - val_loss: 0.0190\n",
      "Epoch 3/2000\n",
      "3423/3423 [==============================] - 2s 485us/step - loss: 0.0073 - val_loss: 0.0037\n",
      "Epoch 4/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 0.0044 - val_loss: 0.0087\n",
      "Epoch 5/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 0.0033 - val_loss: 0.0028\n",
      "Epoch 6/2000\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 0.0026 - val_loss: 0.0041\n",
      "Epoch 7/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 8/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 9/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 10/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 11/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 12/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 13/2000\n",
      "3423/3423 [==============================] - 2s 487us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 14/2000\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 15/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 16/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 17/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 18/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 19/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 20/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 21/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 22/2000\n",
      "3423/3423 [==============================] - 2s 485us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 23/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 24/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 25/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 26/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 27/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 28/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 29/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 30/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 31/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 32/2000\n",
      "3423/3423 [==============================] - 2s 487us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 33/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 34/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 35/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 36/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 37/2000\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 38/2000\n",
      "3423/3423 [==============================] - 2s 484us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 39/2000\n",
      "3423/3423 [==============================] - 2s 483us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 40/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 41/2000\n",
      "3423/3423 [==============================] - 2s 487us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 42/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 43/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 44/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 45/2000\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 46/2000\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 47/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 48/2000\n",
      "3423/3423 [==============================] - 2s 483us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 49/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 50/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 51/2000\n",
      "3423/3423 [==============================] - 2s 488us/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 52/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 53/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 9.9428e-04 - val_loss: 0.0012\n",
      "Epoch 54/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 55/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 56/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 57/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 9.6568e-04 - val_loss: 0.0012\n",
      "Epoch 58/2000\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 9.6668e-04 - val_loss: 0.0012\n",
      "Epoch 59/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 9.6244e-04 - val_loss: 0.0013\n",
      "Epoch 60/2000\n",
      "3423/3423 [==============================] - 2s 490us/step - loss: 9.4233e-04 - val_loss: 0.0013\n",
      "Epoch 61/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 9.7723e-04 - val_loss: 0.0016\n",
      "Epoch 62/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 9.8500e-04 - val_loss: 0.0013\n",
      "Epoch 63/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 9.5269e-04 - val_loss: 0.0012\n",
      "Epoch 64/2000\n",
      "3423/3423 [==============================] - 2s 483us/step - loss: 9.8045e-04 - val_loss: 0.0013\n",
      "Epoch 65/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 66/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 67/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 68/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 9.2973e-04 - val_loss: 0.0012\n",
      "Epoch 69/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 9.1977e-04 - val_loss: 0.0012\n",
      "Epoch 70/2000\n",
      "3423/3423 [==============================] - 2s 489us/step - loss: 9.0828e-04 - val_loss: 0.0013\n",
      "Epoch 71/2000\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 9.5158e-04 - val_loss: 0.0011\n",
      "Epoch 72/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 9.2572e-04 - val_loss: 0.0013\n",
      "Epoch 73/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 9.0977e-04 - val_loss: 0.0012\n",
      "Epoch 74/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 8.9157e-04 - val_loss: 0.0011\n",
      "Epoch 75/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 8.6880e-04 - val_loss: 0.0010\n",
      "Epoch 76/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 478us/step - loss: 8.6822e-04 - val_loss: 0.0011\n",
      "Epoch 77/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 8.5507e-04 - val_loss: 0.0013\n",
      "Epoch 78/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 9.0552e-04 - val_loss: 0.0013\n",
      "Epoch 79/2000\n",
      "3423/3423 [==============================] - 2s 485us/step - loss: 8.9587e-04 - val_loss: 0.0012\n",
      "Epoch 80/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 8.6462e-04 - val_loss: 0.0010\n",
      "Epoch 81/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 8.6342e-04 - val_loss: 0.0010\n",
      "Epoch 82/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 8.3620e-04 - val_loss: 9.9235e-04\n",
      "Epoch 83/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 8.3726e-04 - val_loss: 0.0011\n",
      "Epoch 84/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 8.9179e-04 - val_loss: 0.0011\n",
      "Epoch 85/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 8.8851e-04 - val_loss: 9.9656e-04\n",
      "Epoch 86/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 8.5648e-04 - val_loss: 9.7337e-04\n",
      "Epoch 87/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 8.8580e-04 - val_loss: 9.9858e-04\n",
      "Epoch 88/2000\n",
      "3423/3423 [==============================] - 2s 487us/step - loss: 8.6576e-04 - val_loss: 0.0010\n",
      "Epoch 89/2000\n",
      "3423/3423 [==============================] - 2s 494us/step - loss: 8.0803e-04 - val_loss: 0.0011\n",
      "Epoch 90/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 8.2629e-04 - val_loss: 0.0011\n",
      "Epoch 91/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 8.4221e-04 - val_loss: 0.0011\n",
      "Epoch 92/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 7.9080e-04 - val_loss: 9.3076e-04\n",
      "Epoch 93/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 7.6829e-04 - val_loss: 9.4198e-04\n",
      "Epoch 94/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 7.7492e-04 - val_loss: 9.5508e-04\n",
      "Epoch 95/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 7.7529e-04 - val_loss: 8.9361e-04\n",
      "Epoch 96/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 7.5841e-04 - val_loss: 8.7979e-04\n",
      "Epoch 97/2000\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 7.5082e-04 - val_loss: 9.0855e-04\n",
      "Epoch 98/2000\n",
      "3423/3423 [==============================] - 2s 483us/step - loss: 8.1988e-04 - val_loss: 0.0011\n",
      "Epoch 99/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 8.2308e-04 - val_loss: 8.9804e-04\n",
      "Epoch 100/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 8.1061e-04 - val_loss: 9.8981e-04\n",
      "Epoch 101/2000\n",
      "3423/3423 [==============================] - 2s 499us/step - loss: 8.7522e-04 - val_loss: 8.6383e-04\n",
      "Epoch 102/2000\n",
      "3423/3423 [==============================] - 2s 495us/step - loss: 7.7694e-04 - val_loss: 9.0275e-04\n",
      "Epoch 103/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 7.5078e-04 - val_loss: 8.9233e-04\n",
      "Epoch 104/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 7.6394e-04 - val_loss: 0.0012\n",
      "Epoch 105/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 8.1526e-04 - val_loss: 9.7425e-04\n",
      "Epoch 106/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 7.4038e-04 - val_loss: 9.6320e-04\n",
      "Epoch 107/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 7.5185e-04 - val_loss: 9.0078e-04\n",
      "Epoch 108/2000\n",
      "3423/3423 [==============================] - 2s 487us/step - loss: 7.2229e-04 - val_loss: 8.3648e-04\n",
      "Epoch 109/2000\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 7.7569e-04 - val_loss: 8.0623e-04\n",
      "Epoch 110/2000\n",
      "3423/3423 [==============================] - 2s 486us/step - loss: 7.1912e-04 - val_loss: 8.0467e-04\n",
      "Epoch 111/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 7.2569e-04 - val_loss: 0.0010\n",
      "Epoch 112/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 7.4561e-04 - val_loss: 7.8308e-04\n",
      "Epoch 113/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 7.1657e-04 - val_loss: 8.3092e-04\n",
      "Epoch 114/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 6.9582e-04 - val_loss: 8.8209e-04\n",
      "Epoch 115/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 8.1505e-04 - val_loss: 9.3731e-04\n",
      "Epoch 116/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 8.4460e-04 - val_loss: 0.0015\n",
      "Epoch 117/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 9.1748e-04 - val_loss: 0.0014\n",
      "Epoch 118/2000\n",
      "3423/3423 [==============================] - 2s 487us/step - loss: 8.5086e-04 - val_loss: 0.0014\n",
      "Epoch 119/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 8.4144e-04 - val_loss: 9.3221e-04\n",
      "Epoch 120/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 7.8182e-04 - val_loss: 7.7447e-04\n",
      "Epoch 121/2000\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 7.2205e-04 - val_loss: 8.0991e-04\n",
      "Epoch 122/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 7.1588e-04 - val_loss: 7.8879e-04\n",
      "Epoch 123/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 7.0173e-04 - val_loss: 0.0010\n",
      "Epoch 124/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 7.4360e-04 - val_loss: 8.7768e-04\n",
      "Epoch 125/2000\n",
      "3423/3423 [==============================] - 2s 496us/step - loss: 7.0115e-04 - val_loss: 7.5569e-04\n",
      "Epoch 126/2000\n",
      "3423/3423 [==============================] - 2s 492us/step - loss: 6.7494e-04 - val_loss: 7.2360e-04\n",
      "Epoch 127/2000\n",
      "3423/3423 [==============================] - 2s 486us/step - loss: 6.8234e-04 - val_loss: 7.3509e-04\n",
      "Epoch 128/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 6.5537e-04 - val_loss: 7.4042e-04\n",
      "Epoch 129/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 6.4583e-04 - val_loss: 7.1219e-04\n",
      "Epoch 130/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 6.4653e-04 - val_loss: 7.9483e-04\n",
      "Epoch 131/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 6.5083e-04 - val_loss: 8.2833e-04\n",
      "Epoch 132/2000\n",
      "3423/3423 [==============================] - 2s 484us/step - loss: 6.6329e-04 - val_loss: 7.4818e-04\n",
      "Epoch 133/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 6.7234e-04 - val_loss: 6.8120e-04\n",
      "Epoch 134/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 7.4859e-04 - val_loss: 7.3073e-04\n",
      "Epoch 135/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 6.7539e-04 - val_loss: 6.9071e-04\n",
      "Epoch 136/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 6.6260e-04 - val_loss: 7.5146e-04\n",
      "Epoch 137/2000\n",
      "3423/3423 [==============================] - 2s 488us/step - loss: 6.6779e-04 - val_loss: 7.2990e-04\n",
      "Epoch 138/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 6.8589e-04 - val_loss: 6.9684e-04\n",
      "Epoch 139/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 6.7015e-04 - val_loss: 6.6833e-04\n",
      "Epoch 140/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 6.3380e-04 - val_loss: 7.7434e-04\n",
      "Epoch 141/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 6.1817e-04 - val_loss: 7.3448e-04\n",
      "Epoch 142/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 6.4416e-04 - val_loss: 9.0294e-04\n",
      "Epoch 143/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 6.7187e-04 - val_loss: 0.0010\n",
      "Epoch 144/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 7.1913e-04 - val_loss: 6.6674e-04\n",
      "Epoch 145/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 6.3940e-04 - val_loss: 6.6945e-04\n",
      "Epoch 146/2000\n",
      "3423/3423 [==============================] - 2s 485us/step - loss: 6.2294e-04 - val_loss: 7.4142e-04\n",
      "Epoch 147/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 484us/step - loss: 6.1713e-04 - val_loss: 7.0496e-04\n",
      "Epoch 148/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 6.0582e-04 - val_loss: 6.4354e-04\n",
      "Epoch 149/2000\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 5.8623e-04 - val_loss: 7.0859e-04\n",
      "Epoch 150/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.9630e-04 - val_loss: 6.3084e-04\n",
      "Epoch 151/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 5.7613e-04 - val_loss: 6.4428e-04\n",
      "Epoch 152/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 6.1204e-04 - val_loss: 6.3282e-04\n",
      "Epoch 153/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.6229e-04 - val_loss: 6.1867e-04\n",
      "Epoch 154/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 6.2171e-04 - val_loss: 6.9709e-04\n",
      "Epoch 155/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 6.5001e-04 - val_loss: 7.0020e-04\n",
      "Epoch 156/2000\n",
      "3423/3423 [==============================] - 2s 486us/step - loss: 5.6370e-04 - val_loss: 6.7298e-04\n",
      "Epoch 157/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 5.6021e-04 - val_loss: 6.2245e-04\n",
      "Epoch 158/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 5.6333e-04 - val_loss: 6.1506e-04\n",
      "Epoch 159/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.5147e-04 - val_loss: 6.1402e-04\n",
      "Epoch 160/2000\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 5.6883e-04 - val_loss: 6.3968e-04\n",
      "Epoch 161/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 6.0610e-04 - val_loss: 8.1969e-04\n",
      "Epoch 162/2000\n",
      "3423/3423 [==============================] - 2s 484us/step - loss: 5.9856e-04 - val_loss: 6.9677e-04\n",
      "Epoch 163/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 5.8774e-04 - val_loss: 6.0088e-04\n",
      "Epoch 164/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.6181e-04 - val_loss: 6.3388e-04\n",
      "Epoch 165/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 5.8996e-04 - val_loss: 8.1388e-04\n",
      "Epoch 166/2000\n",
      "3423/3423 [==============================] - 2s 484us/step - loss: 6.0016e-04 - val_loss: 6.4973e-04\n",
      "Epoch 167/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 5.8074e-04 - val_loss: 5.9617e-04\n",
      "Epoch 168/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.5029e-04 - val_loss: 7.8036e-04\n",
      "Epoch 169/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.5701e-04 - val_loss: 6.0455e-04\n",
      "Epoch 170/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 5.3593e-04 - val_loss: 6.9610e-04\n",
      "Epoch 171/2000\n",
      "3423/3423 [==============================] - 2s 485us/step - loss: 5.4536e-04 - val_loss: 6.0736e-04\n",
      "Epoch 172/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.3925e-04 - val_loss: 6.2256e-04\n",
      "Epoch 173/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 5.3846e-04 - val_loss: 6.1997e-04\n",
      "Epoch 174/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.6935e-04 - val_loss: 0.0010\n",
      "Epoch 175/2000\n",
      "3423/3423 [==============================] - 2s 488us/step - loss: 6.6320e-04 - val_loss: 5.9554e-04\n",
      "Epoch 176/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 6.0113e-04 - val_loss: 6.9867e-04\n",
      "Epoch 177/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.8546e-04 - val_loss: 6.0398e-04\n",
      "Epoch 178/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 6.0155e-04 - val_loss: 0.0012\n",
      "Epoch 179/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 7.8732e-04 - val_loss: 8.6173e-04\n",
      "Epoch 180/2000\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 8.7642e-04 - val_loss: 8.8889e-04\n",
      "Epoch 181/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 7.4348e-04 - val_loss: 0.0010\n",
      "Epoch 182/2000\n",
      "3423/3423 [==============================] - 2s 483us/step - loss: 6.3344e-04 - val_loss: 6.2771e-04\n",
      "Epoch 183/2000\n",
      "3423/3423 [==============================] - 2s 483us/step - loss: 5.9329e-04 - val_loss: 6.3291e-04\n",
      "Epoch 184/2000\n",
      "3423/3423 [==============================] - 2s 483us/step - loss: 5.7264e-04 - val_loss: 6.4096e-04\n",
      "Epoch 185/2000\n",
      "3423/3423 [==============================] - 2s 484us/step - loss: 5.4443e-04 - val_loss: 6.2799e-04\n",
      "Epoch 186/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 5.3915e-04 - val_loss: 6.1561e-04\n",
      "Epoch 187/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.5650e-04 - val_loss: 6.9179e-04\n",
      "Epoch 188/2000\n",
      "3423/3423 [==============================] - 2s 483us/step - loss: 6.0051e-04 - val_loss: 7.7687e-04\n",
      "Epoch 189/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 6.3973e-04 - val_loss: 6.0753e-04\n",
      "Epoch 190/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 5.5466e-04 - val_loss: 6.6592e-04\n",
      "Epoch 191/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 5.3664e-04 - val_loss: 6.6192e-04\n",
      "Epoch 192/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.2948e-04 - val_loss: 6.2986e-04\n",
      "Epoch 193/2000\n",
      "3423/3423 [==============================] - 2s 483us/step - loss: 5.5016e-04 - val_loss: 6.7334e-04\n",
      "Epoch 194/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.6133e-04 - val_loss: 5.9391e-04\n",
      "Epoch 195/2000\n",
      "3423/3423 [==============================] - 2s 483us/step - loss: 6.2480e-04 - val_loss: 7.1911e-04\n",
      "Epoch 196/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 6.3760e-04 - val_loss: 7.2169e-04\n",
      "Epoch 197/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.8759e-04 - val_loss: 6.0190e-04\n",
      "Epoch 198/2000\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 5.4704e-04 - val_loss: 7.0937e-04\n",
      "Epoch 199/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.3826e-04 - val_loss: 6.5517e-04\n",
      "Epoch 200/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.4065e-04 - val_loss: 6.9437e-04\n",
      "Epoch 201/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.3884e-04 - val_loss: 6.1534e-04\n",
      "Epoch 202/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.4508e-04 - val_loss: 5.8921e-04\n",
      "Epoch 203/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 5.2418e-04 - val_loss: 5.9077e-04\n",
      "Epoch 204/2000\n",
      "3423/3423 [==============================] - 2s 489us/step - loss: 5.5528e-04 - val_loss: 6.3570e-04\n",
      "Epoch 205/2000\n",
      "3423/3423 [==============================] - 2s 489us/step - loss: 5.5633e-04 - val_loss: 6.0690e-04\n",
      "Epoch 206/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 5.5692e-04 - val_loss: 6.0757e-04\n",
      "Epoch 207/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 5.5406e-04 - val_loss: 7.0358e-04\n",
      "Epoch 208/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 6.0346e-04 - val_loss: 9.9347e-04\n",
      "Epoch 209/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 6.0147e-04 - val_loss: 6.9646e-04\n",
      "Epoch 210/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 6.2564e-04 - val_loss: 5.8952e-04\n",
      "Epoch 211/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 5.6323e-04 - val_loss: 6.0520e-04\n",
      "Epoch 212/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.3498e-04 - val_loss: 5.9537e-04\n",
      "Epoch 213/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.1754e-04 - val_loss: 6.8737e-04\n",
      "Epoch 214/2000\n",
      "3423/3423 [==============================] - 2s 490us/step - loss: 5.4979e-04 - val_loss: 7.8253e-04\n",
      "Epoch 215/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 5.3465e-04 - val_loss: 5.9329e-04\n",
      "Epoch 216/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 5.3178e-04 - val_loss: 6.3442e-04\n",
      "Epoch 217/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.5124e-04 - val_loss: 6.1672e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 218/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 5.2308e-04 - val_loss: 6.5839e-04\n",
      "Epoch 219/2000\n",
      "3423/3423 [==============================] - 2s 497us/step - loss: 5.1928e-04 - val_loss: 5.8989e-04\n",
      "Epoch 220/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.1243e-04 - val_loss: 5.9099e-04\n",
      "Epoch 221/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 5.1704e-04 - val_loss: 6.9475e-04\n",
      "Epoch 222/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 5.2510e-04 - val_loss: 6.1828e-04\n",
      "Epoch 223/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 5.1559e-04 - val_loss: 5.9882e-04\n",
      "Epoch 224/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 5.1445e-04 - val_loss: 5.9449e-04\n",
      "Epoch 225/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 5.2291e-04 - val_loss: 6.7569e-04\n",
      "Epoch 226/2000\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 5.1958e-04 - val_loss: 7.0452e-04\n",
      "Epoch 227/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 5.4163e-04 - val_loss: 5.8310e-04\n",
      "Epoch 228/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.3813e-04 - val_loss: 5.9253e-04\n",
      "Epoch 229/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 5.3715e-04 - val_loss: 6.4068e-04\n",
      "Epoch 230/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.5395e-04 - val_loss: 6.3272e-04\n",
      "Epoch 231/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 5.1259e-04 - val_loss: 6.0691e-04\n",
      "Epoch 232/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.2539e-04 - val_loss: 6.3228e-04\n",
      "Epoch 233/2000\n",
      "3423/3423 [==============================] - 2s 487us/step - loss: 5.0593e-04 - val_loss: 5.9298e-04\n",
      "Epoch 234/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.1250e-04 - val_loss: 5.8839e-04\n",
      "Epoch 235/2000\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 5.0824e-04 - val_loss: 5.8965e-04\n",
      "Epoch 236/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.3215e-04 - val_loss: 6.0115e-04\n",
      "Epoch 237/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 5.4782e-04 - val_loss: 6.0310e-04\n",
      "Epoch 238/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 5.0781e-04 - val_loss: 6.0863e-04\n",
      "Epoch 239/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 5.4259e-04 - val_loss: 6.6050e-04\n",
      "Epoch 240/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 5.3275e-04 - val_loss: 5.9800e-04\n",
      "Epoch 241/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 5.2160e-04 - val_loss: 7.5108e-04\n",
      "Epoch 242/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.3899e-04 - val_loss: 8.2589e-04\n",
      "Epoch 243/2000\n",
      "3423/3423 [==============================] - 2s 488us/step - loss: 5.8022e-04 - val_loss: 8.7728e-04\n",
      "Epoch 244/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 6.0058e-04 - val_loss: 9.4712e-04\n",
      "Epoch 245/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.5557e-04 - val_loss: 6.2377e-04\n",
      "Epoch 246/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.1711e-04 - val_loss: 6.1826e-04\n",
      "Epoch 247/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 5.1863e-04 - val_loss: 6.4874e-04\n",
      "Epoch 248/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.1322e-04 - val_loss: 6.8445e-04\n",
      "Epoch 249/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 5.0875e-04 - val_loss: 5.9701e-04\n",
      "Epoch 250/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 5.1018e-04 - val_loss: 5.9274e-04\n",
      "Epoch 251/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.1231e-04 - val_loss: 5.9953e-04\n",
      "Epoch 252/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 5.1373e-04 - val_loss: 7.4011e-04\n",
      "Epoch 253/2000\n",
      "3423/3423 [==============================] - 2s 489us/step - loss: 5.5873e-04 - val_loss: 9.6562e-04\n",
      "Epoch 254/2000\n",
      "3423/3423 [==============================] - 2s 483us/step - loss: 6.0507e-04 - val_loss: 8.0626e-04\n",
      "Epoch 255/2000\n",
      "3423/3423 [==============================] - 2s 485us/step - loss: 5.6979e-04 - val_loss: 7.0620e-04\n",
      "Epoch 256/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 5.1460e-04 - val_loss: 7.6278e-04\n",
      "Epoch 257/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 5.1908e-04 - val_loss: 5.9879e-04\n",
      "Epoch 258/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 5.5117e-04 - val_loss: 6.0168e-04\n",
      "Epoch 259/2000\n",
      "3423/3423 [==============================] - 2s 484us/step - loss: 5.6453e-04 - val_loss: 5.9213e-04\n",
      "Epoch 260/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 5.4075e-04 - val_loss: 6.2845e-04\n",
      "Epoch 261/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 5.4607e-04 - val_loss: 5.9366e-04\n",
      "Epoch 262/2000\n",
      "3423/3423 [==============================] - 2s 486us/step - loss: 5.6469e-04 - val_loss: 8.8378e-04\n",
      "Epoch 263/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 6.6722e-04 - val_loss: 0.0011\n",
      "Epoch 264/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 5.9309e-04 - val_loss: 7.7641e-04\n",
      "Epoch 265/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 5.5722e-04 - val_loss: 5.9378e-04\n",
      "Epoch 266/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.4976e-04 - val_loss: 6.0900e-04\n",
      "Epoch 267/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.3634e-04 - val_loss: 6.7430e-04\n",
      "Epoch 268/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 5.3916e-04 - val_loss: 7.1988e-04\n",
      "Epoch 269/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 5.1003e-04 - val_loss: 7.6565e-04\n",
      "Epoch 270/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.2809e-04 - val_loss: 6.2252e-04\n",
      "Epoch 271/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 5.0266e-04 - val_loss: 6.1226e-04\n",
      "Epoch 272/2000\n",
      "3423/3423 [==============================] - 2s 486us/step - loss: 5.0191e-04 - val_loss: 6.1963e-04\n",
      "Epoch 273/2000\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 5.0084e-04 - val_loss: 6.2033e-04\n",
      "Epoch 274/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.1525e-04 - val_loss: 6.9727e-04\n",
      "Epoch 275/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.3311e-04 - val_loss: 7.2410e-04\n",
      "Epoch 276/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 5.2568e-04 - val_loss: 5.9238e-04\n",
      "Epoch 277/2000\n",
      "3423/3423 [==============================] - 2s 483us/step - loss: 5.4895e-04 - val_loss: 6.1401e-04\n",
      "Epoch 278/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 5.5031e-04 - val_loss: 6.3928e-04\n",
      "Epoch 279/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.3099e-04 - val_loss: 5.9181e-04\n",
      "Epoch 280/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 5.1780e-04 - val_loss: 6.0224e-04\n",
      "Epoch 281/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 5.1840e-04 - val_loss: 6.9276e-04\n",
      "Epoch 282/2000\n",
      "3423/3423 [==============================] - 2s 488us/step - loss: 5.2115e-04 - val_loss: 5.9091e-04\n",
      "Epoch 283/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 5.1298e-04 - val_loss: 6.1870e-04\n",
      "Epoch 284/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 5.2690e-04 - val_loss: 6.0275e-04\n",
      "Epoch 285/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.2025e-04 - val_loss: 6.8785e-04\n",
      "Epoch 286/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 5.1441e-04 - val_loss: 7.5808e-04\n",
      "Epoch 287/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 5.2108e-04 - val_loss: 5.9093e-04\n",
      "Epoch 288/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 481us/step - loss: 5.0966e-04 - val_loss: 5.8717e-04\n",
      "Epoch 289/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 5.2853e-04 - val_loss: 6.0480e-04\n",
      "Epoch 290/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 5.0269e-04 - val_loss: 7.4760e-04\n",
      "Epoch 291/2000\n",
      "3423/3423 [==============================] - 2s 483us/step - loss: 5.3969e-04 - val_loss: 6.7180e-04\n",
      "Epoch 292/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 5.1370e-04 - val_loss: 5.8680e-04\n",
      "Epoch 293/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.0891e-04 - val_loss: 5.8147e-04\n",
      "Epoch 294/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 5.0854e-04 - val_loss: 6.1287e-04\n",
      "Epoch 295/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 4.9991e-04 - val_loss: 5.9406e-04\n",
      "Epoch 296/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.5454e-04 - val_loss: 6.7065e-04\n",
      "Epoch 297/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 5.7730e-04 - val_loss: 6.3287e-04\n",
      "Epoch 298/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.7578e-04 - val_loss: 6.1766e-04\n",
      "Epoch 299/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 5.5110e-04 - val_loss: 8.6484e-04\n",
      "Epoch 300/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 5.6680e-04 - val_loss: 8.7595e-04\n",
      "Epoch 301/2000\n",
      "3423/3423 [==============================] - 2s 488us/step - loss: 5.6214e-04 - val_loss: 6.6639e-04\n",
      "Epoch 302/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 5.1091e-04 - val_loss: 6.0035e-04\n",
      "Epoch 303/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 5.0146e-04 - val_loss: 7.7264e-04\n",
      "Epoch 304/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.2687e-04 - val_loss: 6.7948e-04\n",
      "Epoch 305/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.1370e-04 - val_loss: 6.1933e-04\n",
      "Epoch 306/2000\n",
      "3423/3423 [==============================] - 2s 486us/step - loss: 5.6661e-04 - val_loss: 6.3807e-04\n",
      "Epoch 307/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.5257e-04 - val_loss: 5.9249e-04\n",
      "Epoch 308/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 5.6987e-04 - val_loss: 8.5107e-04\n",
      "Epoch 309/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 5.1634e-04 - val_loss: 5.9124e-04\n",
      "Epoch 310/2000\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 5.0992e-04 - val_loss: 6.0533e-04\n",
      "Epoch 311/2000\n",
      "3423/3423 [==============================] - 2s 489us/step - loss: 4.9818e-04 - val_loss: 6.1927e-04\n",
      "Epoch 312/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.0563e-04 - val_loss: 7.3510e-04\n",
      "Epoch 313/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 5.1032e-04 - val_loss: 5.8340e-04\n",
      "Epoch 314/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 5.2445e-04 - val_loss: 6.8959e-04\n",
      "Epoch 315/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.8321e-04 - val_loss: 6.4642e-04\n",
      "Epoch 316/2000\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 5.3396e-04 - val_loss: 5.9971e-04\n",
      "Epoch 317/2000\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 5.1577e-04 - val_loss: 6.2854e-04\n",
      "Epoch 318/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 5.2519e-04 - val_loss: 5.8783e-04\n",
      "Epoch 319/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 4.9945e-04 - val_loss: 6.4936e-04\n",
      "Epoch 320/2000\n",
      "3423/3423 [==============================] - 2s 485us/step - loss: 5.0600e-04 - val_loss: 6.5915e-04\n",
      "Epoch 321/2000\n",
      "3423/3423 [==============================] - 2s 487us/step - loss: 5.2788e-04 - val_loss: 7.1725e-04\n",
      "Epoch 322/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 5.0239e-04 - val_loss: 5.8970e-04\n",
      "Epoch 323/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 5.1951e-04 - val_loss: 6.2529e-04\n",
      "Epoch 324/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 5.1993e-04 - val_loss: 6.5752e-04\n",
      "Epoch 325/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 5.0757e-04 - val_loss: 5.9650e-04\n",
      "Epoch 326/2000\n",
      "3423/3423 [==============================] - 2s 483us/step - loss: 5.1514e-04 - val_loss: 5.8863e-04\n",
      "Epoch 327/2000\n",
      "3423/3423 [==============================] - 2s 485us/step - loss: 5.2272e-04 - val_loss: 5.8805e-04\n",
      "Epoch 328/2000\n",
      "3423/3423 [==============================] - 2s 484us/step - loss: 5.2428e-04 - val_loss: 7.3075e-04\n",
      "Epoch 329/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 5.4265e-04 - val_loss: 6.0585e-04\n",
      "Epoch 330/2000\n",
      "3423/3423 [==============================] - 2s 486us/step - loss: 5.3754e-04 - val_loss: 7.1058e-04\n",
      "Epoch 331/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.4697e-04 - val_loss: 5.9304e-04\n",
      "Epoch 332/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.0976e-04 - val_loss: 6.3043e-04\n",
      "Epoch 333/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 4.9650e-04 - val_loss: 6.2856e-04\n",
      "Epoch 334/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 4.9698e-04 - val_loss: 5.8880e-04\n",
      "Epoch 335/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.0776e-04 - val_loss: 5.8822e-04\n",
      "Epoch 336/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.2393e-04 - val_loss: 6.0069e-04\n",
      "Epoch 337/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 5.1628e-04 - val_loss: 5.9744e-04\n",
      "Epoch 338/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 4.9630e-04 - val_loss: 6.0365e-04\n",
      "Epoch 339/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.0418e-04 - val_loss: 6.4277e-04\n",
      "Epoch 340/2000\n",
      "3423/3423 [==============================] - 2s 488us/step - loss: 5.1105e-04 - val_loss: 6.3254e-04\n",
      "Epoch 341/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 5.4991e-04 - val_loss: 6.4914e-04\n",
      "Epoch 342/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 5.2121e-04 - val_loss: 5.8957e-04\n",
      "Epoch 343/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 5.0250e-04 - val_loss: 6.8208e-04\n",
      "Epoch 344/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 5.2912e-04 - val_loss: 8.1247e-04\n",
      "Epoch 345/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 5.1197e-04 - val_loss: 5.9896e-04\n",
      "Epoch 346/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 4.9710e-04 - val_loss: 6.9246e-04\n",
      "Epoch 347/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.1017e-04 - val_loss: 5.8701e-04\n",
      "Epoch 348/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 5.3685e-04 - val_loss: 5.8672e-04\n",
      "Epoch 349/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 5.4201e-04 - val_loss: 5.9955e-04\n",
      "Epoch 350/2000\n",
      "3423/3423 [==============================] - 2s 484us/step - loss: 5.1565e-04 - val_loss: 6.3560e-04\n",
      "Epoch 351/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 5.2105e-04 - val_loss: 8.1427e-04\n",
      "Epoch 352/2000\n",
      "3423/3423 [==============================] - 2s 483us/step - loss: 5.4028e-04 - val_loss: 6.8635e-04\n",
      "Epoch 353/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.2877e-04 - val_loss: 6.0012e-04\n",
      "Epoch 354/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.3107e-04 - val_loss: 6.0184e-04\n",
      "Epoch 355/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 5.4740e-04 - val_loss: 6.5882e-04\n",
      "Epoch 356/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 5.5052e-04 - val_loss: 5.8015e-04\n",
      "Epoch 357/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.0687e-04 - val_loss: 5.8579e-04\n",
      "Epoch 358/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 5.0521e-04 - val_loss: 5.9328e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 359/2000\n",
      "3423/3423 [==============================] - 2s 487us/step - loss: 5.0158e-04 - val_loss: 6.0202e-04\n",
      "Epoch 360/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 5.0108e-04 - val_loss: 6.9246e-04\n",
      "Epoch 361/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 5.1824e-04 - val_loss: 6.2456e-04\n",
      "Epoch 362/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 5.1019e-04 - val_loss: 5.9549e-04\n",
      "Epoch 363/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 5.0113e-04 - val_loss: 6.0021e-04\n",
      "Epoch 364/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.0839e-04 - val_loss: 6.1217e-04\n",
      "Epoch 365/2000\n",
      "3423/3423 [==============================] - 2s 501us/step - loss: 4.9243e-04 - val_loss: 5.8812e-04\n",
      "Epoch 366/2000\n",
      "3423/3423 [==============================] - 2s 487us/step - loss: 4.9813e-04 - val_loss: 6.0329e-04\n",
      "Epoch 367/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.0755e-04 - val_loss: 6.7909e-04\n",
      "Epoch 368/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 4.9911e-04 - val_loss: 6.1511e-04\n",
      "Epoch 369/2000\n",
      "3423/3423 [==============================] - 2s 485us/step - loss: 4.9203e-04 - val_loss: 5.9985e-04\n",
      "Epoch 370/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 5.0371e-04 - val_loss: 6.0571e-04\n",
      "Epoch 371/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.0857e-04 - val_loss: 6.5663e-04\n",
      "Epoch 372/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.1449e-04 - val_loss: 5.9715e-04\n",
      "Epoch 373/2000\n",
      "3423/3423 [==============================] - 2s 484us/step - loss: 4.9661e-04 - val_loss: 5.9477e-04\n",
      "Epoch 374/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.0494e-04 - val_loss: 5.8905e-04\n",
      "Epoch 375/2000\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 5.0360e-04 - val_loss: 6.0199e-04\n",
      "Epoch 376/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.1496e-04 - val_loss: 6.2476e-04\n",
      "Epoch 377/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 4.9514e-04 - val_loss: 5.9601e-04\n",
      "Epoch 378/2000\n",
      "3423/3423 [==============================] - 2s 483us/step - loss: 4.9790e-04 - val_loss: 5.9113e-04\n",
      "Epoch 379/2000\n",
      "3423/3423 [==============================] - 2s 486us/step - loss: 5.0366e-04 - val_loss: 5.9322e-04\n",
      "Epoch 380/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 5.1225e-04 - val_loss: 5.8865e-04\n",
      "Epoch 381/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.1456e-04 - val_loss: 6.0104e-04\n",
      "Epoch 382/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 4.9642e-04 - val_loss: 6.4375e-04\n",
      "Epoch 383/2000\n",
      "3423/3423 [==============================] - 2s 483us/step - loss: 5.2974e-04 - val_loss: 5.9718e-04\n",
      "Epoch 384/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 5.0691e-04 - val_loss: 7.3639e-04\n",
      "Epoch 385/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 5.1624e-04 - val_loss: 6.8485e-04\n",
      "Epoch 386/2000\n",
      "3423/3423 [==============================] - 2s 483us/step - loss: 4.9927e-04 - val_loss: 6.1905e-04\n",
      "Epoch 387/2000\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 5.0078e-04 - val_loss: 8.7702e-04\n",
      "Epoch 388/2000\n",
      "3423/3423 [==============================] - 2s 490us/step - loss: 5.8589e-04 - val_loss: 9.9929e-04\n",
      "Epoch 389/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 6.2919e-04 - val_loss: 9.4769e-04\n",
      "Epoch 390/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 6.0641e-04 - val_loss: 6.2308e-04\n",
      "Epoch 391/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 5.7960e-04 - val_loss: 6.0055e-04\n",
      "Epoch 392/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.7611e-04 - val_loss: 6.3535e-04\n",
      "Epoch 393/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 5.4463e-04 - val_loss: 6.1484e-04\n",
      "Epoch 394/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.1425e-04 - val_loss: 6.1546e-04\n",
      "Epoch 395/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.1572e-04 - val_loss: 6.6908e-04\n",
      "Epoch 396/2000\n",
      "3423/3423 [==============================] - 2s 483us/step - loss: 4.9648e-04 - val_loss: 6.0866e-04\n",
      "Epoch 397/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.1233e-04 - val_loss: 6.4536e-04\n",
      "Epoch 398/2000\n",
      "3423/3423 [==============================] - 2s 484us/step - loss: 5.0025e-04 - val_loss: 6.0478e-04\n",
      "Epoch 399/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 5.1778e-04 - val_loss: 6.3844e-04\n",
      "Epoch 400/2000\n",
      "3423/3423 [==============================] - 2s 485us/step - loss: 5.1841e-04 - val_loss: 7.0359e-04\n",
      "Epoch 401/2000\n",
      "3423/3423 [==============================] - 2s 485us/step - loss: 5.4421e-04 - val_loss: 8.7860e-04\n",
      "Epoch 402/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 5.3679e-04 - val_loss: 6.2840e-04\n",
      "Epoch 403/2000\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 4.9422e-04 - val_loss: 6.0582e-04\n",
      "Epoch 404/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 4.9603e-04 - val_loss: 6.5548e-04\n",
      "Epoch 405/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 4.9904e-04 - val_loss: 6.5182e-04\n",
      "Epoch 406/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 5.1677e-04 - val_loss: 5.8836e-04\n",
      "Epoch 407/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 5.1260e-04 - val_loss: 6.0029e-04\n",
      "Epoch 408/2000\n",
      "3423/3423 [==============================] - 2s 487us/step - loss: 5.1575e-04 - val_loss: 6.0463e-04\n",
      "Epoch 409/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.6598e-04 - val_loss: 7.7099e-04\n",
      "Epoch 410/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.7049e-04 - val_loss: 6.4883e-04\n",
      "Epoch 411/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.0367e-04 - val_loss: 6.8119e-04\n",
      "Epoch 412/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.2001e-04 - val_loss: 9.6736e-04\n",
      "Epoch 413/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 5.9141e-04 - val_loss: 8.1884e-04\n",
      "Epoch 414/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.8348e-04 - val_loss: 6.8166e-04\n",
      "Epoch 415/2000\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 6.1041e-04 - val_loss: 5.9614e-04\n",
      "Epoch 416/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.0062e-04 - val_loss: 6.8819e-04\n",
      "Epoch 417/2000\n",
      "3423/3423 [==============================] - 2s 485us/step - loss: 5.0658e-04 - val_loss: 7.5749e-04\n",
      "Epoch 418/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 5.2065e-04 - val_loss: 7.0835e-04\n",
      "Epoch 419/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.1722e-04 - val_loss: 6.0041e-04\n",
      "Epoch 420/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 5.1689e-04 - val_loss: 5.9860e-04\n",
      "Epoch 421/2000\n",
      "3423/3423 [==============================] - 2s 483us/step - loss: 5.0922e-04 - val_loss: 5.9565e-04\n",
      "Epoch 422/2000\n",
      "3423/3423 [==============================] - 2s 483us/step - loss: 5.1319e-04 - val_loss: 5.9285e-04\n",
      "Epoch 423/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 5.0988e-04 - val_loss: 5.8376e-04\n",
      "Epoch 424/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 5.0823e-04 - val_loss: 6.2909e-04\n",
      "Epoch 425/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 5.0738e-04 - val_loss: 6.0153e-04\n",
      "Epoch 426/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.2729e-04 - val_loss: 6.8169e-04\n",
      "Epoch 427/2000\n",
      "3423/3423 [==============================] - 2s 486us/step - loss: 5.6293e-04 - val_loss: 6.0154e-04\n",
      "Epoch 428/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 5.0283e-04 - val_loss: 6.8382e-04\n",
      "Epoch 429/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.0262e-04 - val_loss: 6.3282e-04\n",
      "Epoch 430/2000\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 5.2065e-04 - val_loss: 5.9555e-04\n",
      "Epoch 431/2000\n",
      "3423/3423 [==============================] - 2s 483us/step - loss: 5.0849e-04 - val_loss: 6.0370e-04\n",
      "Epoch 432/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 5.2381e-04 - val_loss: 6.1531e-04\n",
      "Epoch 433/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 5.1357e-04 - val_loss: 5.9803e-04\n",
      "Epoch 434/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.0936e-04 - val_loss: 5.9483e-04\n",
      "Epoch 435/2000\n",
      "3423/3423 [==============================] - 2s 486us/step - loss: 5.0769e-04 - val_loss: 5.9830e-04\n",
      "Epoch 436/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 5.0629e-04 - val_loss: 5.8384e-04\n",
      "Epoch 437/2000\n",
      "3423/3423 [==============================] - 2s 486us/step - loss: 5.2008e-04 - val_loss: 6.2883e-04\n",
      "Epoch 438/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 4.9715e-04 - val_loss: 6.1005e-04\n",
      "Epoch 439/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 4.9139e-04 - val_loss: 6.7685e-04\n",
      "Epoch 440/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 5.0283e-04 - val_loss: 7.0104e-04\n",
      "Epoch 441/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 4.9420e-04 - val_loss: 5.9446e-04\n",
      "Epoch 442/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 4.9587e-04 - val_loss: 6.5757e-04\n",
      "Epoch 443/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 4.9150e-04 - val_loss: 6.0419e-04\n",
      "Epoch 444/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 5.1295e-04 - val_loss: 5.8924e-04\n",
      "Epoch 445/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 4.9501e-04 - val_loss: 7.1035e-04\n",
      "Epoch 446/2000\n",
      "3423/3423 [==============================] - 2s 485us/step - loss: 5.0866e-04 - val_loss: 6.1736e-04\n",
      "Epoch 447/2000\n",
      "3423/3423 [==============================] - 2s 485us/step - loss: 5.1502e-04 - val_loss: 5.9090e-04\n",
      "Epoch 448/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 5.2270e-04 - val_loss: 5.9875e-04\n",
      "Epoch 449/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 4.9959e-04 - val_loss: 6.7685e-04\n",
      "Epoch 450/2000\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 5.0010e-04 - val_loss: 6.0454e-04\n",
      "Epoch 451/2000\n",
      "3423/3423 [==============================] - 2s 486us/step - loss: 5.1383e-04 - val_loss: 5.8666e-04\n",
      "Epoch 452/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 4.9836e-04 - val_loss: 6.1889e-04\n",
      "Epoch 453/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 5.2430e-04 - val_loss: 5.9336e-04\n",
      "Epoch 454/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.3849e-04 - val_loss: 7.2866e-04\n",
      "Epoch 455/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 5.5005e-04 - val_loss: 0.0011\n",
      "Epoch 456/2000\n",
      "3423/3423 [==============================] - 2s 486us/step - loss: 5.8044e-04 - val_loss: 8.5361e-04\n",
      "Epoch 457/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 5.5010e-04 - val_loss: 5.9702e-04\n",
      "Epoch 458/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.9072e-04 - val_loss: 5.8564e-04\n",
      "Epoch 459/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 5.0922e-04 - val_loss: 5.8997e-04\n",
      "Epoch 460/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 4.9487e-04 - val_loss: 6.5165e-04\n",
      "Epoch 461/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 4.8941e-04 - val_loss: 6.5238e-04\n",
      "Epoch 462/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 5.1494e-04 - val_loss: 8.1107e-04\n",
      "Epoch 463/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.4791e-04 - val_loss: 9.7726e-04\n",
      "Epoch 464/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.5466e-04 - val_loss: 5.9601e-04\n",
      "Epoch 465/2000\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 5.3284e-04 - val_loss: 6.0687e-04\n",
      "Epoch 466/2000\n",
      "3423/3423 [==============================] - 2s 489us/step - loss: 5.1812e-04 - val_loss: 5.9812e-04\n",
      "Epoch 467/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 5.0750e-04 - val_loss: 6.0139e-04\n",
      "Epoch 468/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 4.8931e-04 - val_loss: 5.9004e-04\n",
      "Epoch 469/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 4.8914e-04 - val_loss: 6.2122e-04\n",
      "Epoch 470/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 4.9278e-04 - val_loss: 5.9169e-04\n",
      "Epoch 471/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 4.9802e-04 - val_loss: 5.9070e-04\n",
      "Epoch 472/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.1983e-04 - val_loss: 6.0959e-04\n",
      "Epoch 473/2000\n",
      "3423/3423 [==============================] - 2s 483us/step - loss: 4.8997e-04 - val_loss: 6.0196e-04\n",
      "Epoch 474/2000\n",
      "3423/3423 [==============================] - 2s 484us/step - loss: 5.1286e-04 - val_loss: 6.0335e-04\n",
      "Epoch 475/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 5.0870e-04 - val_loss: 6.3252e-04\n",
      "Epoch 476/2000\n",
      "3423/3423 [==============================] - 2s 483us/step - loss: 5.2325e-04 - val_loss: 6.1445e-04\n",
      "Epoch 477/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 5.2859e-04 - val_loss: 5.9377e-04\n",
      "Epoch 478/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 5.2811e-04 - val_loss: 8.3615e-04\n",
      "Epoch 479/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 5.3465e-04 - val_loss: 7.8049e-04\n",
      "Epoch 480/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 5.3288e-04 - val_loss: 7.0782e-04\n",
      "Epoch 481/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 5.1031e-04 - val_loss: 5.9990e-04\n",
      "Epoch 482/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.1622e-04 - val_loss: 6.0286e-04\n",
      "Epoch 483/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.0194e-04 - val_loss: 5.9223e-04\n",
      "Epoch 484/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 5.0720e-04 - val_loss: 5.9655e-04\n",
      "Epoch 485/2000\n",
      "3423/3423 [==============================] - 2s 486us/step - loss: 4.9647e-04 - val_loss: 6.0551e-04\n",
      "Epoch 486/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 4.9469e-04 - val_loss: 5.9804e-04\n",
      "Epoch 487/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 4.9349e-04 - val_loss: 6.5388e-04\n",
      "Epoch 488/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 5.2935e-04 - val_loss: 6.9658e-04\n",
      "Epoch 489/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 5.1174e-04 - val_loss: 7.2616e-04\n",
      "Epoch 490/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 5.0683e-04 - val_loss: 6.4780e-04\n",
      "Epoch 491/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 4.9955e-04 - val_loss: 5.9516e-04\n",
      "Epoch 492/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 5.2368e-04 - val_loss: 6.1925e-04\n",
      "Epoch 493/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 5.5970e-04 - val_loss: 6.2038e-04\n",
      "Epoch 494/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 5.1824e-04 - val_loss: 6.2888e-04\n",
      "Epoch 495/2000\n",
      "3423/3423 [==============================] - 2s 488us/step - loss: 5.2317e-04 - val_loss: 6.3136e-04\n",
      "Epoch 496/2000\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 5.2087e-04 - val_loss: 5.9883e-04\n",
      "Epoch 497/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 4.9308e-04 - val_loss: 6.6524e-04\n",
      "Epoch 498/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 5.2257e-04 - val_loss: 5.9265e-04\n",
      "Epoch 499/2000\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 5.1283e-04 - val_loss: 6.3501e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 5.2291e-04 - val_loss: 6.6279e-04\n",
      "Epoch 501/2000\n",
      "3423/3423 [==============================] - 2s 484us/step - loss: 5.0469e-04 - val_loss: 6.6391e-04\n",
      "Epoch 502/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 4.8886e-04 - val_loss: 5.9843e-04\n",
      "Epoch 503/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 4.9698e-04 - val_loss: 5.9675e-04\n",
      "Epoch 504/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 4.8728e-04 - val_loss: 6.1326e-04\n",
      "Epoch 505/2000\n",
      "3423/3423 [==============================] - 2s 487us/step - loss: 4.9571e-04 - val_loss: 6.4198e-04\n",
      "Epoch 506/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 5.0701e-04 - val_loss: 6.8141e-04\n",
      "Epoch 507/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.4264e-04 - val_loss: 6.9551e-04\n",
      "Epoch 508/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.3075e-04 - val_loss: 6.0992e-04\n",
      "Epoch 509/2000\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 5.0392e-04 - val_loss: 6.7039e-04\n",
      "Epoch 510/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 5.0261e-04 - val_loss: 6.1289e-04\n",
      "Epoch 511/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 4.9589e-04 - val_loss: 6.5639e-04\n",
      "Epoch 512/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 4.9541e-04 - val_loss: 6.1657e-04\n",
      "Epoch 513/2000\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 4.9134e-04 - val_loss: 6.0373e-04\n",
      "Epoch 514/2000\n",
      "3423/3423 [==============================] - 2s 488us/step - loss: 4.8825e-04 - val_loss: 6.0486e-04\n",
      "Epoch 515/2000\n",
      "3423/3423 [==============================] - 2s 484us/step - loss: 4.9883e-04 - val_loss: 5.9957e-04\n",
      "Epoch 516/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 4.9532e-04 - val_loss: 6.4442e-04\n",
      "Epoch 517/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 4.9590e-04 - val_loss: 6.2708e-04\n",
      "Epoch 518/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 4.9509e-04 - val_loss: 6.0282e-04\n",
      "Epoch 519/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.3009e-04 - val_loss: 6.1320e-04\n",
      "Epoch 520/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.0221e-04 - val_loss: 7.0826e-04\n",
      "Epoch 521/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.3244e-04 - val_loss: 6.6048e-04\n",
      "Epoch 522/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 5.0112e-04 - val_loss: 6.6730e-04\n",
      "Epoch 523/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 4.9063e-04 - val_loss: 6.0247e-04\n",
      "Epoch 524/2000\n",
      "3423/3423 [==============================] - 2s 488us/step - loss: 5.1450e-04 - val_loss: 6.0178e-04\n",
      "Epoch 525/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 4.8968e-04 - val_loss: 6.0893e-04\n",
      "Epoch 526/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 4.8842e-04 - val_loss: 5.9227e-04\n",
      "Epoch 527/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 4.9747e-04 - val_loss: 5.8687e-04\n",
      "Epoch 528/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.0406e-04 - val_loss: 6.7189e-04\n",
      "Epoch 529/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 5.2555e-04 - val_loss: 9.3810e-04\n",
      "Epoch 530/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 5.8515e-04 - val_loss: 8.8960e-04\n",
      "Epoch 531/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 5.2040e-04 - val_loss: 6.0671e-04\n",
      "Epoch 532/2000\n",
      "3423/3423 [==============================] - 2s 487us/step - loss: 5.2371e-04 - val_loss: 6.2314e-04\n",
      "Epoch 533/2000\n",
      "3423/3423 [==============================] - 2s 488us/step - loss: 5.9092e-04 - val_loss: 6.8356e-04\n",
      "Epoch 534/2000\n",
      "3423/3423 [==============================] - 2s 515us/step - loss: 5.8920e-04 - val_loss: 6.5228e-04\n",
      "Epoch 535/2000\n",
      "3423/3423 [==============================] - 2s 500us/step - loss: 5.2368e-04 - val_loss: 6.2348e-04\n",
      "Epoch 536/2000\n",
      "3423/3423 [==============================] - 2s 489us/step - loss: 5.5178e-04 - val_loss: 7.8500e-04\n",
      "Epoch 537/2000\n",
      "3423/3423 [==============================] - 2s 496us/step - loss: 6.2409e-04 - val_loss: 6.0179e-04\n",
      "Epoch 538/2000\n",
      "3423/3423 [==============================] - 2s 523us/step - loss: 5.1575e-04 - val_loss: 7.7478e-04\n",
      "Epoch 539/2000\n",
      "3423/3423 [==============================] - 2s 494us/step - loss: 5.6292e-04 - val_loss: 9.4210e-04\n",
      "Epoch 540/2000\n",
      "3423/3423 [==============================] - 2s 492us/step - loss: 5.4728e-04 - val_loss: 6.2892e-04\n",
      "Epoch 541/2000\n",
      "3423/3423 [==============================] - 2s 499us/step - loss: 5.1880e-04 - val_loss: 9.2574e-04\n",
      "Epoch 542/2000\n",
      "3423/3423 [==============================] - 2s 490us/step - loss: 6.5424e-04 - val_loss: 6.6230e-04\n",
      "Epoch 543/2000\n",
      "3423/3423 [==============================] - 2s 496us/step - loss: 6.0805e-04 - val_loss: 6.1362e-04\n",
      "Epoch 544/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 5.7628e-04 - val_loss: 7.3723e-04\n",
      "Epoch 545/2000\n",
      "3423/3423 [==============================] - 2s 485us/step - loss: 5.2825e-04 - val_loss: 7.2306e-04\n",
      "Epoch 546/2000\n",
      "3423/3423 [==============================] - 2s 485us/step - loss: 5.2682e-04 - val_loss: 6.2493e-04\n",
      "Epoch 547/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 4.9481e-04 - val_loss: 6.0747e-04\n",
      "Epoch 548/2000\n",
      "3423/3423 [==============================] - 2s 500us/step - loss: 5.0768e-04 - val_loss: 6.2997e-04\n",
      "Epoch 549/2000\n",
      "3423/3423 [==============================] - 2s 517us/step - loss: 5.2854e-04 - val_loss: 5.8859e-04\n",
      "Epoch 550/2000\n",
      "3423/3423 [==============================] - 2s 529us/step - loss: 5.0118e-04 - val_loss: 6.0947e-04\n",
      "Epoch 551/2000\n",
      "3423/3423 [==============================] - 2s 535us/step - loss: 4.9393e-04 - val_loss: 5.9777e-04\n",
      "Epoch 552/2000\n",
      "3423/3423 [==============================] - 2s 527us/step - loss: 4.8159e-04 - val_loss: 5.9665e-04\n",
      "Epoch 553/2000\n",
      "3423/3423 [==============================] - 2s 506us/step - loss: 4.8392e-04 - val_loss: 6.0506e-04\n",
      "Epoch 554/2000\n",
      "3423/3423 [==============================] - 2s 517us/step - loss: 5.0671e-04 - val_loss: 6.3263e-04\n",
      "Epoch 555/2000\n",
      "3423/3423 [==============================] - 2s 507us/step - loss: 5.0741e-04 - val_loss: 6.5871e-04\n",
      "Epoch 556/2000\n",
      "3423/3423 [==============================] - 2s 487us/step - loss: 5.4154e-04 - val_loss: 6.3863e-04\n",
      "Epoch 557/2000\n",
      "3423/3423 [==============================] - 2s 507us/step - loss: 5.4529e-04 - val_loss: 6.8877e-04\n",
      "Epoch 558/2000\n",
      "3423/3423 [==============================] - 2s 496us/step - loss: 5.6162e-04 - val_loss: 5.9975e-04\n",
      "Epoch 559/2000\n",
      "3423/3423 [==============================] - 2s 506us/step - loss: 5.0165e-04 - val_loss: 7.0036e-04\n",
      "Epoch 560/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 5.1024e-04 - val_loss: 6.4476e-04\n",
      "Epoch 561/2000\n",
      "3423/3423 [==============================] - 2s 486us/step - loss: 5.1246e-04 - val_loss: 6.2323e-04\n",
      "Epoch 562/2000\n",
      "3423/3423 [==============================] - 2s 490us/step - loss: 4.9403e-04 - val_loss: 6.2875e-04\n",
      "Epoch 563/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 5.4060e-04 - val_loss: 6.0504e-04\n",
      "Epoch 564/2000\n",
      "3423/3423 [==============================] - 2s 540us/step - loss: 5.1093e-04 - val_loss: 5.8936e-04\n",
      "Epoch 565/2000\n",
      "3423/3423 [==============================] - 2s 518us/step - loss: 4.9068e-04 - val_loss: 7.8203e-04\n",
      "Epoch 566/2000\n",
      "3423/3423 [==============================] - 2s 484us/step - loss: 5.6397e-04 - val_loss: 8.4585e-04\n",
      "Epoch 567/2000\n",
      "3423/3423 [==============================] - 2s 491us/step - loss: 5.6895e-04 - val_loss: 6.1813e-04\n",
      "Epoch 568/2000\n",
      "3423/3423 [==============================] - 2s 501us/step - loss: 5.7642e-04 - val_loss: 7.2446e-04\n",
      "Epoch 569/2000\n",
      "3423/3423 [==============================] - 2s 498us/step - loss: 5.3803e-04 - val_loss: 5.9068e-04\n",
      "Epoch 570/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 495us/step - loss: 5.0979e-04 - val_loss: 6.4220e-04\n",
      "Epoch 571/2000\n",
      "3423/3423 [==============================] - 2s 516us/step - loss: 5.0164e-04 - val_loss: 6.8183e-04\n",
      "Epoch 572/2000\n",
      "3423/3423 [==============================] - 2s 492us/step - loss: 4.8983e-04 - val_loss: 6.3605e-04\n",
      "Epoch 573/2000\n",
      "3423/3423 [==============================] - 2s 497us/step - loss: 5.0058e-04 - val_loss: 5.9326e-04\n",
      "Epoch 574/2000\n",
      "3423/3423 [==============================] - 2s 496us/step - loss: 5.1246e-04 - val_loss: 5.9247e-04\n",
      "Epoch 575/2000\n",
      "3423/3423 [==============================] - 2s 498us/step - loss: 5.0807e-04 - val_loss: 6.7469e-04\n",
      "Epoch 576/2000\n",
      "3423/3423 [==============================] - 2s 490us/step - loss: 5.1740e-04 - val_loss: 6.6093e-04\n",
      "Epoch 577/2000\n",
      "3423/3423 [==============================] - 2s 494us/step - loss: 4.9403e-04 - val_loss: 6.5837e-04\n",
      "Epoch 578/2000\n",
      "3423/3423 [==============================] - 2s 501us/step - loss: 4.9479e-04 - val_loss: 6.1737e-04\n",
      "Epoch 579/2000\n",
      "3423/3423 [==============================] - 2s 486us/step - loss: 4.9049e-04 - val_loss: 5.8956e-04\n",
      "Epoch 580/2000\n",
      "3423/3423 [==============================] - 2s 497us/step - loss: 4.9520e-04 - val_loss: 5.9600e-04\n",
      "Epoch 581/2000\n",
      "3423/3423 [==============================] - 2s 502us/step - loss: 4.9286e-04 - val_loss: 6.5929e-04\n",
      "Epoch 582/2000\n",
      "3423/3423 [==============================] - 2s 499us/step - loss: 5.0081e-04 - val_loss: 7.7774e-04\n",
      "Epoch 583/2000\n",
      "3423/3423 [==============================] - 2s 494us/step - loss: 4.9887e-04 - val_loss: 5.8720e-04\n",
      "Epoch 584/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 4.9673e-04 - val_loss: 6.9065e-04\n",
      "Epoch 585/2000\n",
      "3423/3423 [==============================] - 2s 485us/step - loss: 5.8109e-04 - val_loss: 6.1923e-04\n",
      "Epoch 586/2000\n",
      "3423/3423 [==============================] - 2s 489us/step - loss: 5.3767e-04 - val_loss: 6.1151e-04\n",
      "Epoch 587/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 5.3471e-04 - val_loss: 6.0273e-04\n",
      "Epoch 588/2000\n",
      "3423/3423 [==============================] - 2s 496us/step - loss: 5.2081e-04 - val_loss: 6.1676e-04\n",
      "Epoch 589/2000\n",
      "3423/3423 [==============================] - 2s 491us/step - loss: 5.4230e-04 - val_loss: 0.0010\n",
      "Epoch 590/2000\n",
      "3423/3423 [==============================] - 2s 518us/step - loss: 6.2778e-04 - val_loss: 6.3479e-04\n",
      "Epoch 591/2000\n",
      "3423/3423 [==============================] - 2s 488us/step - loss: 5.8803e-04 - val_loss: 6.9717e-04\n",
      "Epoch 592/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 5.6087e-04 - val_loss: 6.4708e-04\n",
      "Epoch 593/2000\n",
      "3423/3423 [==============================] - 2s 495us/step - loss: 5.1742e-04 - val_loss: 6.5175e-04\n",
      "Epoch 594/2000\n",
      "3423/3423 [==============================] - 2s 488us/step - loss: 5.1298e-04 - val_loss: 6.3754e-04\n",
      "Epoch 595/2000\n",
      "3423/3423 [==============================] - 2s 485us/step - loss: 5.3881e-04 - val_loss: 6.1020e-04\n",
      "Epoch 596/2000\n",
      "3423/3423 [==============================] - 2s 489us/step - loss: 5.4594e-04 - val_loss: 6.2190e-04\n",
      "Epoch 597/2000\n",
      "3423/3423 [==============================] - 2s 498us/step - loss: 5.0964e-04 - val_loss: 7.0584e-04\n",
      "Epoch 598/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.2264e-04 - val_loss: 7.6427e-04\n",
      "Epoch 599/2000\n",
      "3423/3423 [==============================] - 2s 487us/step - loss: 5.1340e-04 - val_loss: 6.6617e-04\n",
      "Epoch 600/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 4.9113e-04 - val_loss: 6.1314e-04\n",
      "Epoch 601/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 4.8501e-04 - val_loss: 5.9486e-04\n",
      "Epoch 602/2000\n",
      "3423/3423 [==============================] - 2s 483us/step - loss: 4.9229e-04 - val_loss: 7.0871e-04\n",
      "Epoch 603/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 5.1105e-04 - val_loss: 5.9107e-04\n",
      "Epoch 604/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 5.0737e-04 - val_loss: 7.5940e-04\n",
      "Epoch 605/2000\n",
      "3423/3423 [==============================] - 2s 486us/step - loss: 5.3916e-04 - val_loss: 7.7308e-04\n",
      "Epoch 606/2000\n",
      "3423/3423 [==============================] - 2s 499us/step - loss: 5.0867e-04 - val_loss: 5.9620e-04\n",
      "Epoch 607/2000\n",
      "3423/3423 [==============================] - 2s 503us/step - loss: 4.8301e-04 - val_loss: 6.8538e-04\n",
      "Epoch 608/2000\n",
      "3423/3423 [==============================] - 2s 487us/step - loss: 5.1587e-04 - val_loss: 6.7276e-04\n",
      "Epoch 609/2000\n",
      "3423/3423 [==============================] - 2s 497us/step - loss: 5.0065e-04 - val_loss: 6.1323e-04\n",
      "Epoch 610/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 5.4161e-04 - val_loss: 6.0468e-04\n",
      "Epoch 611/2000\n",
      "3423/3423 [==============================] - 2s 494us/step - loss: 4.9384e-04 - val_loss: 7.1943e-04\n",
      "Epoch 612/2000\n",
      "3423/3423 [==============================] - 2s 496us/step - loss: 4.9939e-04 - val_loss: 6.3953e-04\n",
      "Epoch 613/2000\n",
      "3423/3423 [==============================] - 2s 499us/step - loss: 4.8078e-04 - val_loss: 6.1391e-04\n",
      "Epoch 614/2000\n",
      "3423/3423 [==============================] - 2s 498us/step - loss: 4.9318e-04 - val_loss: 7.0513e-04\n",
      "Epoch 615/2000\n",
      "3423/3423 [==============================] - 2s 498us/step - loss: 5.1217e-04 - val_loss: 6.6665e-04\n",
      "Epoch 616/2000\n",
      "3423/3423 [==============================] - 2s 491us/step - loss: 4.8830e-04 - val_loss: 6.0712e-04\n",
      "Epoch 617/2000\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 5.0977e-04 - val_loss: 5.9575e-04\n",
      "Epoch 618/2000\n",
      "3423/3423 [==============================] - 2s 515us/step - loss: 4.8827e-04 - val_loss: 5.9388e-04\n",
      "Epoch 619/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 4.9398e-04 - val_loss: 6.0677e-04\n",
      "Epoch 620/2000\n",
      "3423/3423 [==============================] - 2s 521us/step - loss: 5.0816e-04 - val_loss: 6.1682e-04\n",
      "Epoch 621/2000\n",
      "3423/3423 [==============================] - 2s 506us/step - loss: 4.9984e-04 - val_loss: 7.7094e-04\n",
      "Epoch 622/2000\n",
      "3423/3423 [==============================] - 2s 490us/step - loss: 5.1757e-04 - val_loss: 6.4104e-04\n",
      "Epoch 623/2000\n",
      "3423/3423 [==============================] - 2s 491us/step - loss: 4.8816e-04 - val_loss: 6.0035e-04\n",
      "Epoch 624/2000\n",
      "3423/3423 [==============================] - 2s 513us/step - loss: 4.7993e-04 - val_loss: 6.0021e-04\n",
      "Epoch 625/2000\n",
      "3423/3423 [==============================] - 2s 513us/step - loss: 4.8906e-04 - val_loss: 8.1898e-04\n",
      "Epoch 626/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 5.0956e-04 - val_loss: 6.8281e-04\n",
      "Epoch 627/2000\n",
      "3423/3423 [==============================] - 2s 503us/step - loss: 5.0202e-04 - val_loss: 6.0166e-04\n",
      "Epoch 628/2000\n",
      "3423/3423 [==============================] - 2s 493us/step - loss: 4.9947e-04 - val_loss: 6.7550e-04\n",
      "Epoch 629/2000\n",
      "3423/3423 [==============================] - 2s 494us/step - loss: 5.3592e-04 - val_loss: 6.0619e-04\n",
      "Epoch 630/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 4.9260e-04 - val_loss: 5.9707e-04\n",
      "Epoch 631/2000\n",
      "3423/3423 [==============================] - 2s 487us/step - loss: 4.8162e-04 - val_loss: 5.9700e-04\n",
      "Epoch 632/2000\n",
      "3423/3423 [==============================] - 2s 488us/step - loss: 4.8316e-04 - val_loss: 6.0385e-04\n",
      "Epoch 633/2000\n",
      "3423/3423 [==============================] - 2s 485us/step - loss: 5.3334e-04 - val_loss: 6.9428e-04\n",
      "Epoch 634/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 5.7698e-04 - val_loss: 6.7650e-04\n",
      "Epoch 635/2000\n",
      "3423/3423 [==============================] - 2s 512us/step - loss: 5.1857e-04 - val_loss: 5.9773e-04\n",
      "Epoch 636/2000\n",
      "3423/3423 [==============================] - 2s 488us/step - loss: 4.8196e-04 - val_loss: 6.4419e-04\n",
      "Epoch 637/2000\n",
      "3423/3423 [==============================] - 2s 495us/step - loss: 4.8861e-04 - val_loss: 6.2916e-04\n",
      "Epoch 638/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 4.9058e-04 - val_loss: 5.9742e-04\n",
      "Epoch 639/2000\n",
      "3423/3423 [==============================] - 2s 486us/step - loss: 4.8107e-04 - val_loss: 6.1561e-04\n",
      "Epoch 640/2000\n",
      "3423/3423 [==============================] - 2s 488us/step - loss: 4.7966e-04 - val_loss: 6.1170e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 641/2000\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 4.7685e-04 - val_loss: 6.2301e-04\n",
      "Epoch 642/2000\n",
      "3423/3423 [==============================] - 2s 498us/step - loss: 4.8010e-04 - val_loss: 6.3963e-04\n",
      "Epoch 643/2000\n",
      "3423/3423 [==============================] - 2s 512us/step - loss: 4.8146e-04 - val_loss: 5.9828e-04\n",
      "Epoch 644/2000\n",
      "3423/3423 [==============================] - 2s 517us/step - loss: 4.9684e-04 - val_loss: 7.1414e-04\n",
      "Epoch 645/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 5.2997e-04 - val_loss: 5.9198e-04\n",
      "Epoch 646/2000\n",
      "3423/3423 [==============================] - 2s 499us/step - loss: 4.9632e-04 - val_loss: 6.1033e-04\n",
      "Epoch 647/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 5.0463e-04 - val_loss: 6.0559e-04\n",
      "Epoch 648/2000\n",
      "3423/3423 [==============================] - 2s 497us/step - loss: 5.0524e-04 - val_loss: 6.9439e-04\n",
      "Epoch 649/2000\n",
      "3423/3423 [==============================] - 2s 504us/step - loss: 5.0941e-04 - val_loss: 7.9835e-04\n",
      "Epoch 650/2000\n",
      "3423/3423 [==============================] - 2s 503us/step - loss: 5.4273e-04 - val_loss: 6.3811e-04\n",
      "Epoch 651/2000\n",
      "3423/3423 [==============================] - 2s 497us/step - loss: 5.1883e-04 - val_loss: 6.0826e-04\n",
      "Epoch 652/2000\n",
      "3423/3423 [==============================] - 2s 495us/step - loss: 5.3504e-04 - val_loss: 6.7614e-04\n",
      "Epoch 653/2000\n",
      "3423/3423 [==============================] - 2s 500us/step - loss: 5.2939e-04 - val_loss: 6.0105e-04\n",
      "Epoch 654/2000\n",
      "3423/3423 [==============================] - 2s 501us/step - loss: 5.1893e-04 - val_loss: 9.0344e-04\n",
      "Epoch 655/2000\n",
      "3423/3423 [==============================] - 2s 502us/step - loss: 5.6342e-04 - val_loss: 7.4439e-04\n",
      "Epoch 656/2000\n",
      "3423/3423 [==============================] - 2s 513us/step - loss: 5.3367e-04 - val_loss: 6.0431e-04\n",
      "Epoch 657/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 5.3552e-04 - val_loss: 6.4067e-04\n",
      "Epoch 658/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 5.1269e-04 - val_loss: 6.1225e-04\n",
      "Epoch 659/2000\n",
      "3423/3423 [==============================] - 2s 516us/step - loss: 4.9915e-04 - val_loss: 6.2814e-04\n",
      "Epoch 660/2000\n",
      "3423/3423 [==============================] - 2s 524us/step - loss: 4.9664e-04 - val_loss: 5.9969e-04\n",
      "Epoch 661/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 5.0208e-04 - val_loss: 6.1074e-04\n",
      "Epoch 662/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 5.0618e-04 - val_loss: 6.1279e-04\n",
      "Epoch 663/2000\n",
      "3423/3423 [==============================] - 2s 507us/step - loss: 4.8886e-04 - val_loss: 6.0401e-04\n",
      "Epoch 664/2000\n",
      "3423/3423 [==============================] - 2s 531us/step - loss: 5.1662e-04 - val_loss: 6.0524e-04\n",
      "Epoch 665/2000\n",
      "3423/3423 [==============================] - 2s 495us/step - loss: 5.2774e-04 - val_loss: 7.5730e-04\n",
      "Epoch 666/2000\n",
      "3423/3423 [==============================] - 2s 487us/step - loss: 5.7904e-04 - val_loss: 8.5463e-04\n",
      "Epoch 667/2000\n",
      "3423/3423 [==============================] - 2s 489us/step - loss: 6.0682e-04 - val_loss: 6.1742e-04\n",
      "Epoch 668/2000\n",
      "3423/3423 [==============================] - 2s 498us/step - loss: 5.8283e-04 - val_loss: 0.0010\n",
      "Epoch 669/2000\n",
      "3423/3423 [==============================] - 2s 499us/step - loss: 5.6996e-04 - val_loss: 6.4437e-04\n",
      "Epoch 670/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 5.0426e-04 - val_loss: 6.0597e-04\n",
      "Epoch 671/2000\n",
      "3423/3423 [==============================] - 2s 485us/step - loss: 4.8322e-04 - val_loss: 6.1563e-04\n",
      "Epoch 672/2000\n",
      "3423/3423 [==============================] - 2s 492us/step - loss: 4.8584e-04 - val_loss: 6.2693e-04\n",
      "Epoch 673/2000\n",
      "3423/3423 [==============================] - 2s 503us/step - loss: 5.0556e-04 - val_loss: 6.1467e-04\n",
      "Epoch 674/2000\n",
      "3423/3423 [==============================] - 2s 492us/step - loss: 4.8044e-04 - val_loss: 6.0764e-04\n",
      "Epoch 675/2000\n",
      "3423/3423 [==============================] - 2s 497us/step - loss: 4.8620e-04 - val_loss: 6.0558e-04\n",
      "Epoch 676/2000\n",
      "3423/3423 [==============================] - 2s 496us/step - loss: 5.0649e-04 - val_loss: 6.7008e-04\n",
      "Epoch 677/2000\n",
      "3423/3423 [==============================] - 2s 507us/step - loss: 4.9070e-04 - val_loss: 6.2672e-04\n",
      "Epoch 678/2000\n",
      "3423/3423 [==============================] - 2s 496us/step - loss: 4.7957e-04 - val_loss: 6.0114e-04\n",
      "Epoch 679/2000\n",
      "3423/3423 [==============================] - 2s 496us/step - loss: 4.8786e-04 - val_loss: 5.9684e-04\n",
      "Epoch 680/2000\n",
      "3423/3423 [==============================] - 2s 496us/step - loss: 4.8725e-04 - val_loss: 6.8862e-04\n",
      "Epoch 681/2000\n",
      "3423/3423 [==============================] - 2s 484us/step - loss: 5.0943e-04 - val_loss: 7.2467e-04\n",
      "Epoch 682/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 4.9485e-04 - val_loss: 6.2243e-04\n",
      "Epoch 683/2000\n",
      "3423/3423 [==============================] - 2s 485us/step - loss: 4.7917e-04 - val_loss: 6.0472e-04\n",
      "Epoch 684/2000\n",
      "3423/3423 [==============================] - 2s 498us/step - loss: 4.8148e-04 - val_loss: 6.7115e-04\n",
      "Epoch 685/2000\n",
      "3423/3423 [==============================] - 2s 492us/step - loss: 5.0537e-04 - val_loss: 6.1089e-04\n",
      "Epoch 686/2000\n",
      "3423/3423 [==============================] - 2s 486us/step - loss: 5.0075e-04 - val_loss: 6.7118e-04\n",
      "Epoch 687/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 4.9787e-04 - val_loss: 6.0833e-04\n",
      "Epoch 688/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 4.8896e-04 - val_loss: 5.9971e-04\n",
      "Epoch 689/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 5.1513e-04 - val_loss: 7.0090e-04\n",
      "Epoch 690/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 4.9745e-04 - val_loss: 6.3686e-04\n",
      "Epoch 691/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 4.8682e-04 - val_loss: 6.6530e-04\n",
      "Epoch 692/2000\n",
      "3423/3423 [==============================] - 2s 504us/step - loss: 4.8969e-04 - val_loss: 6.1268e-04\n",
      "Epoch 693/2000\n",
      "3423/3423 [==============================] - 2s 484us/step - loss: 4.9755e-04 - val_loss: 6.1133e-04\n",
      "Epoch 694/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 5.0609e-04 - val_loss: 7.0384e-04\n",
      "Epoch 695/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 5.0969e-04 - val_loss: 6.0669e-04\n",
      "Epoch 696/2000\n",
      "3423/3423 [==============================] - 2s 505us/step - loss: 4.7826e-04 - val_loss: 6.0997e-04\n",
      "Epoch 697/2000\n",
      "3423/3423 [==============================] - 2s 501us/step - loss: 4.8305e-04 - val_loss: 6.2598e-04\n",
      "Epoch 698/2000\n",
      "3423/3423 [==============================] - 2s 503us/step - loss: 5.0240e-04 - val_loss: 6.5058e-04\n",
      "Epoch 699/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 4.8714e-04 - val_loss: 6.0752e-04\n",
      "Epoch 700/2000\n",
      "3423/3423 [==============================] - 2s 494us/step - loss: 4.8870e-04 - val_loss: 6.0759e-04\n",
      "Epoch 701/2000\n",
      "3423/3423 [==============================] - 2s 513us/step - loss: 5.0105e-04 - val_loss: 8.5666e-04\n",
      "Epoch 702/2000\n",
      "3423/3423 [==============================] - 2s 499us/step - loss: 5.0970e-04 - val_loss: 6.0960e-04\n",
      "Epoch 703/2000\n",
      "3423/3423 [==============================] - 2s 485us/step - loss: 4.7554e-04 - val_loss: 5.9582e-04\n",
      "Epoch 704/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 4.9446e-04 - val_loss: 6.0409e-04\n",
      "Epoch 705/2000\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 4.9692e-04 - val_loss: 5.9984e-04\n",
      "Epoch 706/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 5.3618e-04 - val_loss: 6.0979e-04\n",
      "Epoch 707/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 5.5432e-04 - val_loss: 6.2803e-04\n",
      "Epoch 708/2000\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 4.9463e-04 - val_loss: 6.5877e-04\n",
      "Epoch 709/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 5.0503e-04 - val_loss: 6.1156e-04\n",
      "Epoch 710/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 5.1943e-04 - val_loss: 8.3684e-04\n",
      "Epoch 711/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 474us/step - loss: 5.2344e-04 - val_loss: 6.6308e-04\n",
      "Epoch 712/2000\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 4.8546e-04 - val_loss: 7.0577e-04\n",
      "Epoch 713/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 4.9890e-04 - val_loss: 6.0397e-04\n",
      "Epoch 714/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.7908e-04 - val_loss: 6.3362e-04\n",
      "Epoch 715/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.7775e-04 - val_loss: 6.1333e-04\n",
      "Epoch 716/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.7373e-04 - val_loss: 6.1370e-04\n",
      "Epoch 717/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 4.8036e-04 - val_loss: 6.1062e-04\n",
      "Epoch 718/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.9300e-04 - val_loss: 6.0136e-04\n",
      "Epoch 719/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.7726e-04 - val_loss: 6.0304e-04\n",
      "Epoch 720/2000\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 5.0168e-04 - val_loss: 7.1930e-04\n",
      "Epoch 721/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 5.8376e-04 - val_loss: 6.0555e-04\n",
      "Epoch 722/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 4.9550e-04 - val_loss: 6.9594e-04\n",
      "Epoch 723/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.8597e-04 - val_loss: 6.1884e-04\n",
      "Epoch 724/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.8987e-04 - val_loss: 6.6434e-04\n",
      "Epoch 725/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 5.3460e-04 - val_loss: 6.0688e-04\n",
      "Epoch 726/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 5.0323e-04 - val_loss: 6.4073e-04\n",
      "Epoch 727/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 4.8378e-04 - val_loss: 6.0527e-04\n",
      "Epoch 728/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.7599e-04 - val_loss: 6.1490e-04\n",
      "Epoch 729/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.7415e-04 - val_loss: 6.0667e-04\n",
      "Epoch 730/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 4.7237e-04 - val_loss: 6.6904e-04\n",
      "Epoch 731/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 4.9201e-04 - val_loss: 6.9752e-04\n",
      "Epoch 732/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.4324e-04 - val_loss: 6.1053e-04\n",
      "Epoch 733/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 5.3751e-04 - val_loss: 6.2101e-04\n",
      "Epoch 734/2000\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 4.8943e-04 - val_loss: 6.7758e-04\n",
      "Epoch 735/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 5.0079e-04 - val_loss: 6.0121e-04\n",
      "Epoch 736/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 4.7364e-04 - val_loss: 6.4257e-04\n",
      "Epoch 737/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 4.8441e-04 - val_loss: 6.1488e-04\n",
      "Epoch 738/2000\n",
      "3423/3423 [==============================] - 2s 506us/step - loss: 4.8143e-04 - val_loss: 6.1198e-04\n",
      "Epoch 739/2000\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 4.8433e-04 - val_loss: 6.2739e-04\n",
      "Epoch 740/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.7730e-04 - val_loss: 6.5791e-04\n",
      "Epoch 741/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.0766e-04 - val_loss: 7.2820e-04\n",
      "Epoch 742/2000\n",
      "3423/3423 [==============================] - 2s 485us/step - loss: 5.2172e-04 - val_loss: 6.3403e-04\n",
      "Epoch 743/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 4.7775e-04 - val_loss: 6.2742e-04\n",
      "Epoch 744/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 4.8175e-04 - val_loss: 6.1118e-04\n",
      "Epoch 745/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 5.0705e-04 - val_loss: 7.3251e-04\n",
      "Epoch 746/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 5.3434e-04 - val_loss: 6.4033e-04\n",
      "Epoch 747/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 6.1372e-04 - val_loss: 0.0011\n",
      "Epoch 748/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 5.5738e-04 - val_loss: 5.9736e-04\n",
      "Epoch 749/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 5.6594e-04 - val_loss: 8.1432e-04\n",
      "Epoch 750/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 6.0818e-04 - val_loss: 7.3345e-04\n",
      "Epoch 751/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 5.5685e-04 - val_loss: 6.0869e-04\n",
      "Epoch 752/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 5.0181e-04 - val_loss: 6.1798e-04\n",
      "Epoch 753/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.8006e-04 - val_loss: 6.5802e-04\n",
      "Epoch 754/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.8670e-04 - val_loss: 6.7439e-04\n",
      "Epoch 755/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 4.8481e-04 - val_loss: 6.9798e-04\n",
      "Epoch 756/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.9199e-04 - val_loss: 5.9987e-04\n",
      "Epoch 757/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.8946e-04 - val_loss: 6.3162e-04\n",
      "Epoch 758/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 4.9769e-04 - val_loss: 6.1836e-04\n",
      "Epoch 759/2000\n",
      "3423/3423 [==============================] - 2s 472us/step - loss: 5.3358e-04 - val_loss: 7.3725e-04\n",
      "Epoch 760/2000\n",
      "3423/3423 [==============================] - 2s 483us/step - loss: 4.9739e-04 - val_loss: 6.0640e-04\n",
      "Epoch 761/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 4.8880e-04 - val_loss: 6.2679e-04\n",
      "Epoch 762/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 4.8074e-04 - val_loss: 7.3220e-04\n",
      "Epoch 763/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 5.0308e-04 - val_loss: 6.7506e-04\n",
      "Epoch 764/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.9113e-04 - val_loss: 6.6125e-04\n",
      "Epoch 765/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 4.9701e-04 - val_loss: 6.0284e-04\n",
      "Epoch 766/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.8036e-04 - val_loss: 6.5260e-04\n",
      "Epoch 767/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 5.1455e-04 - val_loss: 6.0613e-04\n",
      "Epoch 768/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 4.9267e-04 - val_loss: 5.9878e-04\n",
      "Epoch 769/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 4.9550e-04 - val_loss: 6.0466e-04\n",
      "Epoch 770/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.7809e-04 - val_loss: 6.0756e-04\n",
      "Epoch 771/2000\n",
      "3423/3423 [==============================] - 2s 483us/step - loss: 4.8374e-04 - val_loss: 5.9972e-04\n",
      "Epoch 772/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.8227e-04 - val_loss: 6.4531e-04\n",
      "Epoch 773/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.9133e-04 - val_loss: 6.8958e-04\n",
      "Epoch 774/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.9372e-04 - val_loss: 6.4868e-04\n",
      "Epoch 775/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 4.9419e-04 - val_loss: 6.7943e-04\n",
      "Epoch 776/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 5.2767e-04 - val_loss: 6.4016e-04\n",
      "Epoch 777/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 5.2654e-04 - val_loss: 6.7393e-04\n",
      "Epoch 778/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 5.0207e-04 - val_loss: 6.1782e-04\n",
      "Epoch 779/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.7473e-04 - val_loss: 6.1096e-04\n",
      "Epoch 780/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.9230e-04 - val_loss: 6.7242e-04\n",
      "Epoch 781/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 5.3639e-04 - val_loss: 8.0589e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 782/2000\n",
      "3423/3423 [==============================] - 2s 472us/step - loss: 5.5268e-04 - val_loss: 8.0015e-04\n",
      "Epoch 783/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 5.1366e-04 - val_loss: 6.0773e-04\n",
      "Epoch 784/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.7820e-04 - val_loss: 6.1093e-04\n",
      "Epoch 785/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.8010e-04 - val_loss: 6.4194e-04\n",
      "Epoch 786/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 4.8501e-04 - val_loss: 6.6596e-04\n",
      "Epoch 787/2000\n",
      "3423/3423 [==============================] - 2s 472us/step - loss: 5.3513e-04 - val_loss: 6.9065e-04\n",
      "Epoch 788/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 5.0914e-04 - val_loss: 6.4064e-04\n",
      "Epoch 789/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 4.9725e-04 - val_loss: 6.8191e-04\n",
      "Epoch 790/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 5.0625e-04 - val_loss: 6.6191e-04\n",
      "Epoch 791/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 4.9081e-04 - val_loss: 6.4430e-04\n",
      "Epoch 792/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.9044e-04 - val_loss: 6.2235e-04\n",
      "Epoch 793/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.8788e-04 - val_loss: 6.0645e-04\n",
      "Epoch 794/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.9003e-04 - val_loss: 6.4909e-04\n",
      "Epoch 795/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 5.0092e-04 - val_loss: 6.6338e-04\n",
      "Epoch 796/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 4.9398e-04 - val_loss: 6.0532e-04\n",
      "Epoch 797/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 4.7228e-04 - val_loss: 6.1618e-04\n",
      "Epoch 798/2000\n",
      "3423/3423 [==============================] - 2s 472us/step - loss: 4.8001e-04 - val_loss: 6.1848e-04\n",
      "Epoch 799/2000\n",
      "3423/3423 [==============================] - 2s 471us/step - loss: 4.8506e-04 - val_loss: 6.1208e-04\n",
      "Epoch 800/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.6988e-04 - val_loss: 6.0359e-04\n",
      "Epoch 801/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 4.7633e-04 - val_loss: 6.1812e-04\n",
      "Epoch 802/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.7200e-04 - val_loss: 6.3873e-04\n",
      "Epoch 803/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 5.1499e-04 - val_loss: 6.6987e-04\n",
      "Epoch 804/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 5.1892e-04 - val_loss: 6.0725e-04\n",
      "Epoch 805/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 5.0431e-04 - val_loss: 7.8661e-04\n",
      "Epoch 806/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 5.1586e-04 - val_loss: 7.3227e-04\n",
      "Epoch 807/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 4.8277e-04 - val_loss: 6.1543e-04\n",
      "Epoch 808/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 5.0861e-04 - val_loss: 6.1954e-04\n",
      "Epoch 809/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 5.1539e-04 - val_loss: 6.9236e-04\n",
      "Epoch 810/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 5.0490e-04 - val_loss: 6.1077e-04\n",
      "Epoch 811/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 4.7469e-04 - val_loss: 6.6199e-04\n",
      "Epoch 812/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 4.7392e-04 - val_loss: 6.1041e-04\n",
      "Epoch 813/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.6894e-04 - val_loss: 6.0181e-04\n",
      "Epoch 814/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.7364e-04 - val_loss: 6.1553e-04\n",
      "Epoch 815/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.9136e-04 - val_loss: 6.4675e-04\n",
      "Epoch 816/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 5.1534e-04 - val_loss: 7.5503e-04\n",
      "Epoch 817/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.9051e-04 - val_loss: 6.1404e-04\n",
      "Epoch 818/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.8787e-04 - val_loss: 6.0705e-04\n",
      "Epoch 819/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.7295e-04 - val_loss: 6.0211e-04\n",
      "Epoch 820/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 4.7393e-04 - val_loss: 6.3643e-04\n",
      "Epoch 821/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 4.8683e-04 - val_loss: 6.7537e-04\n",
      "Epoch 822/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 4.7902e-04 - val_loss: 6.2659e-04\n",
      "Epoch 823/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 5.0150e-04 - val_loss: 6.0583e-04\n",
      "Epoch 824/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 5.2200e-04 - val_loss: 6.0373e-04\n",
      "Epoch 825/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.8246e-04 - val_loss: 6.0351e-04\n",
      "Epoch 826/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.9714e-04 - val_loss: 6.2914e-04\n",
      "Epoch 827/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 5.1197e-04 - val_loss: 6.1311e-04\n",
      "Epoch 828/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 5.0593e-04 - val_loss: 6.5564e-04\n",
      "Epoch 829/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 5.1424e-04 - val_loss: 6.3029e-04\n",
      "Epoch 830/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 4.9924e-04 - val_loss: 6.8229e-04\n",
      "Epoch 831/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 5.1499e-04 - val_loss: 6.9482e-04\n",
      "Epoch 832/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 5.0931e-04 - val_loss: 6.0656e-04\n",
      "Epoch 833/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.6444e-04 - val_loss: 6.0255e-04\n",
      "Epoch 834/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 4.6435e-04 - val_loss: 6.0070e-04\n",
      "Epoch 835/2000\n",
      "3423/3423 [==============================] - 2s 472us/step - loss: 4.7917e-04 - val_loss: 6.0493e-04\n",
      "Epoch 836/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 4.8604e-04 - val_loss: 6.8013e-04\n",
      "Epoch 837/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 5.0189e-04 - val_loss: 7.1828e-04\n",
      "Epoch 838/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 5.0511e-04 - val_loss: 6.5982e-04\n",
      "Epoch 839/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 5.1413e-04 - val_loss: 6.8537e-04\n",
      "Epoch 840/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 5.5565e-04 - val_loss: 5.9697e-04\n",
      "Epoch 841/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 5.4817e-04 - val_loss: 7.3917e-04\n",
      "Epoch 842/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 5.4606e-04 - val_loss: 6.7853e-04\n",
      "Epoch 843/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 5.3749e-04 - val_loss: 5.9603e-04\n",
      "Epoch 844/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 5.4305e-04 - val_loss: 8.8980e-04\n",
      "Epoch 845/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 5.1941e-04 - val_loss: 6.3045e-04\n",
      "Epoch 846/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.7509e-04 - val_loss: 6.0215e-04\n",
      "Epoch 847/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 4.9882e-04 - val_loss: 6.5400e-04\n",
      "Epoch 848/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 4.8809e-04 - val_loss: 5.9536e-04\n",
      "Epoch 849/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.8977e-04 - val_loss: 6.0063e-04\n",
      "Epoch 850/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 4.8247e-04 - val_loss: 6.1276e-04\n",
      "Epoch 851/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.6534e-04 - val_loss: 6.0174e-04\n",
      "Epoch 852/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 473us/step - loss: 4.7848e-04 - val_loss: 6.0139e-04\n",
      "Epoch 853/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.9262e-04 - val_loss: 7.0093e-04\n",
      "Epoch 854/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 4.7643e-04 - val_loss: 5.9601e-04\n",
      "Epoch 855/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.6769e-04 - val_loss: 6.1084e-04\n",
      "Epoch 856/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.9945e-04 - val_loss: 6.3966e-04\n",
      "Epoch 857/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 4.9842e-04 - val_loss: 6.3124e-04\n",
      "Epoch 858/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.7671e-04 - val_loss: 6.4342e-04\n",
      "Epoch 859/2000\n",
      "3423/3423 [==============================] - 2s 472us/step - loss: 5.1353e-04 - val_loss: 6.6303e-04\n",
      "Epoch 860/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 5.1668e-04 - val_loss: 6.0277e-04\n",
      "Epoch 861/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.9528e-04 - val_loss: 6.4007e-04\n",
      "Epoch 862/2000\n",
      "3423/3423 [==============================] - 2s 472us/step - loss: 4.7620e-04 - val_loss: 7.9678e-04\n",
      "Epoch 863/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 4.9162e-04 - val_loss: 6.0639e-04\n",
      "Epoch 864/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.9103e-04 - val_loss: 6.8371e-04\n",
      "Epoch 865/2000\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 4.8626e-04 - val_loss: 6.4162e-04\n",
      "Epoch 866/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.7675e-04 - val_loss: 5.9743e-04\n",
      "Epoch 867/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.6626e-04 - val_loss: 6.0958e-04\n",
      "Epoch 868/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.6545e-04 - val_loss: 5.9982e-04\n",
      "Epoch 869/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 4.7305e-04 - val_loss: 5.9974e-04\n",
      "Epoch 870/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 4.7415e-04 - val_loss: 6.2843e-04\n",
      "Epoch 871/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.6877e-04 - val_loss: 5.9995e-04\n",
      "Epoch 872/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.7112e-04 - val_loss: 6.2688e-04\n",
      "Epoch 873/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.9863e-04 - val_loss: 6.5484e-04\n",
      "Epoch 874/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.9788e-04 - val_loss: 6.0489e-04\n",
      "Epoch 875/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.6808e-04 - val_loss: 5.9832e-04\n",
      "Epoch 876/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 4.6690e-04 - val_loss: 6.3516e-04\n",
      "Epoch 877/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.8192e-04 - val_loss: 6.3785e-04\n",
      "Epoch 878/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.6919e-04 - val_loss: 5.9704e-04\n",
      "Epoch 879/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 4.7526e-04 - val_loss: 6.3008e-04\n",
      "Epoch 880/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 5.0941e-04 - val_loss: 5.9872e-04\n",
      "Epoch 881/2000\n",
      "3423/3423 [==============================] - 2s 472us/step - loss: 4.9430e-04 - val_loss: 6.5513e-04\n",
      "Epoch 882/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.7894e-04 - val_loss: 6.6022e-04\n",
      "Epoch 883/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.6926e-04 - val_loss: 6.1056e-04\n",
      "Epoch 884/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 5.1052e-04 - val_loss: 7.7869e-04\n",
      "Epoch 885/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 5.5683e-04 - val_loss: 7.2617e-04\n",
      "Epoch 886/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 5.2620e-04 - val_loss: 7.7504e-04\n",
      "Epoch 887/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 5.6657e-04 - val_loss: 6.1665e-04\n",
      "Epoch 888/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 5.3453e-04 - val_loss: 6.0526e-04\n",
      "Epoch 889/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 4.9115e-04 - val_loss: 7.5211e-04\n",
      "Epoch 890/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.8249e-04 - val_loss: 6.0409e-04\n",
      "Epoch 891/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 4.9810e-04 - val_loss: 6.0986e-04\n",
      "Epoch 892/2000\n",
      "3423/3423 [==============================] - 2s 501us/step - loss: 4.6486e-04 - val_loss: 6.0352e-04\n",
      "Epoch 893/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 4.7224e-04 - val_loss: 6.0209e-04\n",
      "Epoch 894/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 4.8154e-04 - val_loss: 6.2500e-04\n",
      "Epoch 895/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.8001e-04 - val_loss: 6.1734e-04\n",
      "Epoch 896/2000\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 4.6977e-04 - val_loss: 6.2378e-04\n",
      "Epoch 897/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.6224e-04 - val_loss: 5.8841e-04\n",
      "Epoch 898/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 4.7638e-04 - val_loss: 6.4790e-04\n",
      "Epoch 899/2000\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 4.9968e-04 - val_loss: 6.1402e-04\n",
      "Epoch 900/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 5.1510e-04 - val_loss: 7.8253e-04\n",
      "Epoch 901/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 4.9280e-04 - val_loss: 6.3848e-04\n",
      "Epoch 902/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.8847e-04 - val_loss: 6.4859e-04\n",
      "Epoch 903/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.9212e-04 - val_loss: 5.9804e-04\n",
      "Epoch 904/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.6223e-04 - val_loss: 7.9666e-04\n",
      "Epoch 905/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 5.1546e-04 - val_loss: 0.0012\n",
      "Epoch 906/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 5.1310e-04 - val_loss: 6.6854e-04\n",
      "Epoch 907/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.5668e-04 - val_loss: 6.3900e-04\n",
      "Epoch 908/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.5144e-04 - val_loss: 7.7314e-04\n",
      "Epoch 909/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 5.2333e-04 - val_loss: 0.0014\n",
      "Epoch 910/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 6.2618e-04 - val_loss: 0.0010\n",
      "Epoch 911/2000\n",
      "3423/3423 [==============================] - 2s 472us/step - loss: 5.4212e-04 - val_loss: 6.1792e-04\n",
      "Epoch 912/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.9151e-04 - val_loss: 6.0970e-04\n",
      "Epoch 913/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.8231e-04 - val_loss: 6.7707e-04\n",
      "Epoch 914/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 4.7071e-04 - val_loss: 7.7799e-04\n",
      "Epoch 915/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 4.6910e-04 - val_loss: 5.9577e-04\n",
      "Epoch 916/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.5798e-04 - val_loss: 6.1488e-04\n",
      "Epoch 917/2000\n",
      "3423/3423 [==============================] - 2s 472us/step - loss: 4.7824e-04 - val_loss: 8.3199e-04\n",
      "Epoch 918/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 5.0194e-04 - val_loss: 8.8580e-04\n",
      "Epoch 919/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 4.7174e-04 - val_loss: 5.9896e-04\n",
      "Epoch 920/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.7211e-04 - val_loss: 6.1894e-04\n",
      "Epoch 921/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.5210e-04 - val_loss: 6.9264e-04\n",
      "Epoch 922/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 4.4318e-04 - val_loss: 6.0388e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 923/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.6765e-04 - val_loss: 6.8312e-04\n",
      "Epoch 924/2000\n",
      "3423/3423 [==============================] - 2s 488us/step - loss: 4.5140e-04 - val_loss: 7.3939e-04\n",
      "Epoch 925/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 4.6816e-04 - val_loss: 8.3123e-04\n",
      "Epoch 926/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.6511e-04 - val_loss: 7.2869e-04\n",
      "Epoch 927/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 4.3940e-04 - val_loss: 6.5963e-04\n",
      "Epoch 928/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 4.4256e-04 - val_loss: 8.5643e-04\n",
      "Epoch 929/2000\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 4.3833e-04 - val_loss: 7.7867e-04\n",
      "Epoch 930/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.5241e-04 - val_loss: 8.4873e-04\n",
      "Epoch 931/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.8407e-04 - val_loss: 8.8232e-04\n",
      "Epoch 932/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 4.7469e-04 - val_loss: 6.7027e-04\n",
      "Epoch 933/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.8208e-04 - val_loss: 6.0202e-04\n",
      "Epoch 934/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 4.7770e-04 - val_loss: 7.4507e-04\n",
      "Epoch 935/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.7211e-04 - val_loss: 8.3825e-04\n",
      "Epoch 936/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.4611e-04 - val_loss: 6.3244e-04\n",
      "Epoch 937/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.4681e-04 - val_loss: 6.4011e-04\n",
      "Epoch 938/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 4.7902e-04 - val_loss: 6.2959e-04\n",
      "Epoch 939/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.7669e-04 - val_loss: 7.0479e-04\n",
      "Epoch 940/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.5410e-04 - val_loss: 6.5600e-04\n",
      "Epoch 941/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.4695e-04 - val_loss: 8.9415e-04\n",
      "Epoch 942/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.4561e-04 - val_loss: 8.4878e-04\n",
      "Epoch 943/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 4.5094e-04 - val_loss: 7.1194e-04\n",
      "Epoch 944/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 4.5952e-04 - val_loss: 6.4443e-04\n",
      "Epoch 945/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 4.6911e-04 - val_loss: 8.2586e-04\n",
      "Epoch 946/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 4.7899e-04 - val_loss: 0.0010\n",
      "Epoch 947/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.7994e-04 - val_loss: 6.9823e-04\n",
      "Epoch 948/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 4.5657e-04 - val_loss: 6.9132e-04\n",
      "Epoch 949/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 4.5310e-04 - val_loss: 8.7210e-04\n",
      "Epoch 950/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.5410e-04 - val_loss: 0.0012\n",
      "Epoch 951/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.6171e-04 - val_loss: 8.0016e-04\n",
      "Epoch 952/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 4.6960e-04 - val_loss: 7.5664e-04\n",
      "Epoch 953/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.4800e-04 - val_loss: 6.6317e-04\n",
      "Epoch 954/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.5911e-04 - val_loss: 7.7306e-04\n",
      "Epoch 955/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 4.4688e-04 - val_loss: 6.2309e-04\n",
      "Epoch 956/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.4575e-04 - val_loss: 6.7678e-04\n",
      "Epoch 957/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.4933e-04 - val_loss: 7.2669e-04\n",
      "Epoch 958/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 4.9226e-04 - val_loss: 7.3902e-04\n",
      "Epoch 959/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 4.6708e-04 - val_loss: 9.2777e-04\n",
      "Epoch 960/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 4.3952e-04 - val_loss: 7.2956e-04\n",
      "Epoch 961/2000\n",
      "3423/3423 [==============================] - 2s 472us/step - loss: 4.4118e-04 - val_loss: 9.2133e-04\n",
      "Epoch 962/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 4.3659e-04 - val_loss: 8.9543e-04\n",
      "Epoch 963/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.6088e-04 - val_loss: 7.7047e-04\n",
      "Epoch 964/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 4.5424e-04 - val_loss: 7.1557e-04\n",
      "Epoch 965/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 4.3948e-04 - val_loss: 8.0768e-04\n",
      "Epoch 966/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.3974e-04 - val_loss: 0.0010\n",
      "Epoch 967/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 4.4754e-04 - val_loss: 7.7429e-04\n",
      "Epoch 968/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 4.2768e-04 - val_loss: 8.4306e-04\n",
      "Epoch 969/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.4281e-04 - val_loss: 9.9138e-04\n",
      "Epoch 970/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 4.2591e-04 - val_loss: 9.8233e-04\n",
      "Epoch 971/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.3884e-04 - val_loss: 9.6261e-04\n",
      "Epoch 972/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.2914e-04 - val_loss: 8.7947e-04\n",
      "Epoch 973/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.3590e-04 - val_loss: 9.6470e-04\n",
      "Epoch 974/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.6974e-04 - val_loss: 9.4225e-04\n",
      "Epoch 975/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.3609e-04 - val_loss: 9.1419e-04\n",
      "Epoch 976/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 4.3873e-04 - val_loss: 9.8682e-04\n",
      "Epoch 977/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 4.3258e-04 - val_loss: 8.9283e-04\n",
      "Epoch 978/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 4.2417e-04 - val_loss: 7.9902e-04\n",
      "Epoch 979/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.3117e-04 - val_loss: 0.0010\n",
      "Epoch 980/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.4870e-04 - val_loss: 0.0011\n",
      "Epoch 981/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 4.4199e-04 - val_loss: 7.1822e-04\n",
      "Epoch 982/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.6680e-04 - val_loss: 9.3978e-04\n",
      "Epoch 983/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 4.5486e-04 - val_loss: 7.0870e-04\n",
      "Epoch 984/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 4.7277e-04 - val_loss: 7.1476e-04\n",
      "Epoch 985/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.5122e-04 - val_loss: 0.0010\n",
      "Epoch 986/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.4089e-04 - val_loss: 9.3512e-04\n",
      "Epoch 987/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 4.2958e-04 - val_loss: 9.5314e-04\n",
      "Epoch 988/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 4.3063e-04 - val_loss: 8.6512e-04\n",
      "Epoch 989/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 4.5693e-04 - val_loss: 7.5442e-04\n",
      "Epoch 990/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.4427e-04 - val_loss: 9.0022e-04\n",
      "Epoch 991/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.3171e-04 - val_loss: 8.6215e-04\n",
      "Epoch 992/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.2220e-04 - val_loss: 9.3347e-04\n",
      "Epoch 993/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 4.2230e-04 - val_loss: 8.8285e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 994/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 4.1476e-04 - val_loss: 8.3682e-04\n",
      "Epoch 995/2000\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 4.1846e-04 - val_loss: 0.0013\n",
      "Epoch 996/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.3923e-04 - val_loss: 8.3237e-04\n",
      "Epoch 997/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 4.3267e-04 - val_loss: 8.7146e-04\n",
      "Epoch 998/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.1265e-04 - val_loss: 0.0010\n",
      "Epoch 999/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.1993e-04 - val_loss: 7.5144e-04\n",
      "Epoch 1000/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.4025e-04 - val_loss: 9.6198e-04\n",
      "Epoch 1001/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 4.2956e-04 - val_loss: 7.2392e-04\n",
      "Epoch 1002/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.3389e-04 - val_loss: 8.3883e-04\n",
      "Epoch 1003/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.2258e-04 - val_loss: 9.2920e-04\n",
      "Epoch 1004/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.1137e-04 - val_loss: 0.0011\n",
      "Epoch 1005/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 4.2474e-04 - val_loss: 7.5023e-04\n",
      "Epoch 1006/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 4.1505e-04 - val_loss: 0.0010\n",
      "Epoch 1007/2000\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 4.1927e-04 - val_loss: 7.6451e-04\n",
      "Epoch 1008/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 4.4314e-04 - val_loss: 8.4146e-04\n",
      "Epoch 1009/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 4.1870e-04 - val_loss: 9.8347e-04\n",
      "Epoch 1010/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 4.4328e-04 - val_loss: 0.0012\n",
      "Epoch 1011/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 4.4280e-04 - val_loss: 9.3242e-04\n",
      "Epoch 1012/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.7788e-04 - val_loss: 0.0011\n",
      "Epoch 1013/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 4.5896e-04 - val_loss: 0.0011\n",
      "Epoch 1014/2000\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 4.4411e-04 - val_loss: 9.3547e-04\n",
      "Epoch 1015/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.1278e-04 - val_loss: 9.4137e-04\n",
      "Epoch 1016/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 4.1523e-04 - val_loss: 0.0011\n",
      "Epoch 1017/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 4.3211e-04 - val_loss: 0.0015\n",
      "Epoch 1018/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.3431e-04 - val_loss: 8.4902e-04\n",
      "Epoch 1019/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 4.1170e-04 - val_loss: 9.3199e-04\n",
      "Epoch 1020/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 4.2073e-04 - val_loss: 0.0012\n",
      "Epoch 1021/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.2941e-04 - val_loss: 0.0016\n",
      "Epoch 1022/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 4.3785e-04 - val_loss: 0.0012\n",
      "Epoch 1023/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.1648e-04 - val_loss: 0.0011\n",
      "Epoch 1024/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.3836e-04 - val_loss: 0.0013\n",
      "Epoch 1025/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 4.0424e-04 - val_loss: 7.7072e-04\n",
      "Epoch 1026/2000\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 4.1911e-04 - val_loss: 9.0956e-04\n",
      "Epoch 1027/2000\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 4.1575e-04 - val_loss: 8.1719e-04\n",
      "Epoch 1028/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 4.0577e-04 - val_loss: 0.0011\n",
      "Epoch 1029/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.1864e-04 - val_loss: 0.0015\n",
      "Epoch 1030/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 4.2694e-04 - val_loss: 9.4635e-04\n",
      "Epoch 1031/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.2839e-04 - val_loss: 9.5017e-04\n",
      "Epoch 1032/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.2286e-04 - val_loss: 8.4607e-04\n",
      "Epoch 1033/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 4.1686e-04 - val_loss: 7.6101e-04\n",
      "Epoch 1034/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.4523e-04 - val_loss: 9.7420e-04\n",
      "Epoch 1035/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.3731e-04 - val_loss: 0.0013\n",
      "Epoch 1036/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 4.4101e-04 - val_loss: 0.0012\n",
      "Epoch 1037/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.1370e-04 - val_loss: 0.0012\n",
      "Epoch 1038/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.1268e-04 - val_loss: 8.2394e-04\n",
      "Epoch 1039/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 4.3730e-04 - val_loss: 8.9264e-04\n",
      "Epoch 1040/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.2180e-04 - val_loss: 0.0011\n",
      "Epoch 1041/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.2015e-04 - val_loss: 9.7694e-04\n",
      "Epoch 1042/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 4.1112e-04 - val_loss: 0.0011\n",
      "Epoch 1043/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 4.0678e-04 - val_loss: 0.0012\n",
      "Epoch 1044/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 3.9152e-04 - val_loss: 0.0013\n",
      "Epoch 1045/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.0310e-04 - val_loss: 7.9545e-04\n",
      "Epoch 1046/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 4.1879e-04 - val_loss: 7.4134e-04\n",
      "Epoch 1047/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.4657e-04 - val_loss: 0.0014\n",
      "Epoch 1048/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.2892e-04 - val_loss: 0.0014\n",
      "Epoch 1049/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 4.0116e-04 - val_loss: 9.5493e-04\n",
      "Epoch 1050/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 3.9159e-04 - val_loss: 0.0012\n",
      "Epoch 1051/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 4.1487e-04 - val_loss: 0.0013\n",
      "Epoch 1052/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.1659e-04 - val_loss: 0.0014\n",
      "Epoch 1053/2000\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 4.0673e-04 - val_loss: 9.1482e-04\n",
      "Epoch 1054/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.0583e-04 - val_loss: 9.9783e-04\n",
      "Epoch 1055/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 4.0322e-04 - val_loss: 0.0011\n",
      "Epoch 1056/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 4.1279e-04 - val_loss: 0.0012\n",
      "Epoch 1057/2000\n",
      "3423/3423 [==============================] - 2s 472us/step - loss: 4.0290e-04 - val_loss: 0.0015\n",
      "Epoch 1058/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 3.9550e-04 - val_loss: 9.7993e-04\n",
      "Epoch 1059/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 4.0099e-04 - val_loss: 7.2061e-04\n",
      "Epoch 1060/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 4.0988e-04 - val_loss: 9.7563e-04\n",
      "Epoch 1061/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 3.8964e-04 - val_loss: 8.4492e-04\n",
      "Epoch 1062/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.0869e-04 - val_loss: 0.0013\n",
      "Epoch 1063/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.0909e-04 - val_loss: 8.6485e-04\n",
      "Epoch 1064/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.1231e-04 - val_loss: 9.2305e-04\n",
      "Epoch 1065/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 485us/step - loss: 3.9859e-04 - val_loss: 0.0011\n",
      "Epoch 1066/2000\n",
      "3423/3423 [==============================] - 2s 483us/step - loss: 3.9925e-04 - val_loss: 9.3379e-04\n",
      "Epoch 1067/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.0020e-04 - val_loss: 7.9224e-04\n",
      "Epoch 1068/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.1970e-04 - val_loss: 0.0010\n",
      "Epoch 1069/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.3070e-04 - val_loss: 0.0011\n",
      "Epoch 1070/2000\n",
      "3423/3423 [==============================] - 2s 489us/step - loss: 3.9862e-04 - val_loss: 0.0011\n",
      "Epoch 1071/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 3.8960e-04 - val_loss: 8.9425e-04\n",
      "Epoch 1072/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 3.9048e-04 - val_loss: 9.3235e-04\n",
      "Epoch 1073/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.0446e-04 - val_loss: 0.0012\n",
      "Epoch 1074/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 3.8481e-04 - val_loss: 0.0011\n",
      "Epoch 1075/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 3.8251e-04 - val_loss: 9.8546e-04\n",
      "Epoch 1076/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 3.8558e-04 - val_loss: 0.0016\n",
      "Epoch 1077/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 3.9243e-04 - val_loss: 0.0012\n",
      "Epoch 1078/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 3.8069e-04 - val_loss: 8.7270e-04\n",
      "Epoch 1079/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 3.8268e-04 - val_loss: 0.0015\n",
      "Epoch 1080/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.0085e-04 - val_loss: 0.0011\n",
      "Epoch 1081/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 3.8928e-04 - val_loss: 8.8703e-04\n",
      "Epoch 1082/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.0568e-04 - val_loss: 0.0011\n",
      "Epoch 1083/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 3.8578e-04 - val_loss: 8.3992e-04\n",
      "Epoch 1084/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 4.1741e-04 - val_loss: 8.8521e-04\n",
      "Epoch 1085/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 4.2246e-04 - val_loss: 0.0010\n",
      "Epoch 1086/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.0202e-04 - val_loss: 0.0010\n",
      "Epoch 1087/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 3.9998e-04 - val_loss: 0.0012\n",
      "Epoch 1088/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 3.9340e-04 - val_loss: 0.0011\n",
      "Epoch 1089/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.2662e-04 - val_loss: 0.0012\n",
      "Epoch 1090/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 4.3380e-04 - val_loss: 0.0010\n",
      "Epoch 1091/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 4.0538e-04 - val_loss: 0.0010\n",
      "Epoch 1092/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 4.0856e-04 - val_loss: 7.8328e-04\n",
      "Epoch 1093/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 4.0155e-04 - val_loss: 0.0014\n",
      "Epoch 1094/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 3.8681e-04 - val_loss: 0.0011\n",
      "Epoch 1095/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 3.8659e-04 - val_loss: 8.8329e-04\n",
      "Epoch 1096/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 3.9577e-04 - val_loss: 8.9307e-04\n",
      "Epoch 1097/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 3.8639e-04 - val_loss: 0.0011\n",
      "Epoch 1098/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 3.8926e-04 - val_loss: 0.0015\n",
      "Epoch 1099/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 3.8850e-04 - val_loss: 8.7843e-04\n",
      "Epoch 1100/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 3.9673e-04 - val_loss: 9.3689e-04\n",
      "Epoch 1101/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.0233e-04 - val_loss: 0.0011\n",
      "Epoch 1102/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 3.9800e-04 - val_loss: 0.0015\n",
      "Epoch 1103/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 3.6847e-04 - val_loss: 0.0011\n",
      "Epoch 1104/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 3.6391e-04 - val_loss: 0.0011\n",
      "Epoch 1105/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 3.7366e-04 - val_loss: 0.0010\n",
      "Epoch 1106/2000\n",
      "3423/3423 [==============================] - 2s 484us/step - loss: 3.7711e-04 - val_loss: 0.0012\n",
      "Epoch 1107/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 3.7074e-04 - val_loss: 0.0011\n",
      "Epoch 1108/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 3.6735e-04 - val_loss: 0.0014\n",
      "Epoch 1109/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 3.7616e-04 - val_loss: 0.0020\n",
      "Epoch 1110/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 3.8558e-04 - val_loss: 0.0011\n",
      "Epoch 1111/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 3.6237e-04 - val_loss: 0.0010\n",
      "Epoch 1112/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 3.6518e-04 - val_loss: 0.0011\n",
      "Epoch 1113/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 3.9146e-04 - val_loss: 0.0011\n",
      "Epoch 1114/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 3.6489e-04 - val_loss: 0.0011\n",
      "Epoch 1115/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 3.6977e-04 - val_loss: 0.0011\n",
      "Epoch 1116/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 3.9959e-04 - val_loss: 0.0014\n",
      "Epoch 1117/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 4.0458e-04 - val_loss: 8.0171e-04\n",
      "Epoch 1118/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 3.9231e-04 - val_loss: 9.5113e-04\n",
      "Epoch 1119/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 3.9590e-04 - val_loss: 9.5874e-04\n",
      "Epoch 1120/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 3.8978e-04 - val_loss: 0.0011\n",
      "Epoch 1121/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 3.6483e-04 - val_loss: 0.0016\n",
      "Epoch 1122/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 3.9345e-04 - val_loss: 0.0015\n",
      "Epoch 1123/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 3.9044e-04 - val_loss: 8.5106e-04\n",
      "Epoch 1124/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 4.0884e-04 - val_loss: 0.0010\n",
      "Epoch 1125/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 4.0907e-04 - val_loss: 0.0012\n",
      "Epoch 1126/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 3.6168e-04 - val_loss: 0.0011\n",
      "Epoch 1127/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 3.5586e-04 - val_loss: 0.0010\n",
      "Epoch 1128/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 3.8097e-04 - val_loss: 0.0022\n",
      "Epoch 1129/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 3.8724e-04 - val_loss: 0.0013\n",
      "Epoch 1130/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 4.0173e-04 - val_loss: 9.1137e-04\n",
      "Epoch 1131/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 4.1011e-04 - val_loss: 9.5585e-04\n",
      "Epoch 1132/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 4.0888e-04 - val_loss: 0.0014\n",
      "Epoch 1133/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 3.9579e-04 - val_loss: 0.0015\n",
      "Epoch 1134/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 3.7577e-04 - val_loss: 8.6390e-04\n",
      "Epoch 1135/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 3.6439e-04 - val_loss: 0.0011\n",
      "Epoch 1136/2000\n",
      "3423/3423 [==============================] - 2s 471us/step - loss: 3.6922e-04 - val_loss: 0.0014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1137/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 3.5774e-04 - val_loss: 0.0010\n",
      "Epoch 1138/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 3.5089e-04 - val_loss: 0.0010\n",
      "Epoch 1139/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 3.5664e-04 - val_loss: 0.0012\n",
      "Epoch 1140/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 3.8794e-04 - val_loss: 0.0015\n",
      "Epoch 1141/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 3.9826e-04 - val_loss: 0.0011\n",
      "Epoch 1142/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 3.8838e-04 - val_loss: 0.0012\n",
      "Epoch 1143/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 4.0318e-04 - val_loss: 0.0011\n",
      "Epoch 1144/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 3.6704e-04 - val_loss: 0.0011\n",
      "Epoch 1145/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 3.7078e-04 - val_loss: 8.5562e-04\n",
      "Epoch 1146/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 3.7481e-04 - val_loss: 9.5108e-04\n",
      "Epoch 1147/2000\n",
      "3423/3423 [==============================] - 2s 472us/step - loss: 3.8721e-04 - val_loss: 0.0011\n",
      "Epoch 1148/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 3.8130e-04 - val_loss: 0.0011\n",
      "Epoch 1149/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 3.7030e-04 - val_loss: 0.0012\n",
      "Epoch 1150/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 3.6288e-04 - val_loss: 0.0013\n",
      "Epoch 1151/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 3.6491e-04 - val_loss: 0.0011\n",
      "Epoch 1152/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 3.5870e-04 - val_loss: 9.0303e-04\n",
      "Epoch 1153/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 3.8126e-04 - val_loss: 0.0011\n",
      "Epoch 1154/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 4.0092e-04 - val_loss: 0.0018\n",
      "Epoch 1155/2000\n",
      "3423/3423 [==============================] - 2s 472us/step - loss: 3.6682e-04 - val_loss: 0.0013\n",
      "Epoch 1156/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 3.5579e-04 - val_loss: 0.0013\n",
      "Epoch 1157/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 3.6135e-04 - val_loss: 8.7393e-04\n",
      "Epoch 1158/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 3.5869e-04 - val_loss: 0.0012\n",
      "Epoch 1159/2000\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 3.5235e-04 - val_loss: 0.0010\n",
      "Epoch 1160/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 3.4511e-04 - val_loss: 0.0012\n",
      "Epoch 1161/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 3.5220e-04 - val_loss: 0.0011\n",
      "Epoch 1162/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 3.4733e-04 - val_loss: 0.0010\n",
      "Epoch 1163/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 3.4868e-04 - val_loss: 0.0010\n",
      "Epoch 1164/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 3.3089e-04 - val_loss: 0.0017\n",
      "Epoch 1165/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 3.5821e-04 - val_loss: 0.0011\n",
      "Epoch 1166/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 3.6541e-04 - val_loss: 0.0011\n",
      "Epoch 1167/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 3.4548e-04 - val_loss: 0.0011\n",
      "Epoch 1168/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 3.3071e-04 - val_loss: 0.0013\n",
      "Epoch 1169/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 3.4854e-04 - val_loss: 0.0011\n",
      "Epoch 1170/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 3.3563e-04 - val_loss: 0.0011\n",
      "Epoch 1171/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 3.3617e-04 - val_loss: 0.0011\n",
      "Epoch 1172/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 3.4633e-04 - val_loss: 0.0012\n",
      "Epoch 1173/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 3.3784e-04 - val_loss: 0.0012\n",
      "Epoch 1174/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 3.4408e-04 - val_loss: 0.0012\n",
      "Epoch 1175/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 3.5139e-04 - val_loss: 0.0014\n",
      "Epoch 1176/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 3.4932e-04 - val_loss: 0.0013\n",
      "Epoch 1177/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 3.4244e-04 - val_loss: 0.0011\n",
      "Epoch 1178/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 3.4241e-04 - val_loss: 0.0013\n",
      "Epoch 1179/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 3.2609e-04 - val_loss: 0.0012\n",
      "Epoch 1180/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 3.4320e-04 - val_loss: 0.0013\n",
      "Epoch 1181/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 3.3144e-04 - val_loss: 0.0016\n",
      "Epoch 1182/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 3.3900e-04 - val_loss: 0.0012\n",
      "Epoch 1183/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 3.1157e-04 - val_loss: 0.0013\n",
      "Epoch 1184/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 3.1750e-04 - val_loss: 0.0014\n",
      "Epoch 1185/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 3.1565e-04 - val_loss: 0.0014\n",
      "Epoch 1186/2000\n",
      "3423/3423 [==============================] - 2s 485us/step - loss: 3.2591e-04 - val_loss: 0.0015\n",
      "Epoch 1187/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 3.5938e-04 - val_loss: 0.0015\n",
      "Epoch 1188/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 3.8265e-04 - val_loss: 0.0013\n",
      "Epoch 1189/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 3.6817e-04 - val_loss: 0.0013\n",
      "Epoch 1190/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 3.6093e-04 - val_loss: 9.5066e-04\n",
      "Epoch 1191/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 3.5307e-04 - val_loss: 0.0012\n",
      "Epoch 1192/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 3.2387e-04 - val_loss: 0.0013\n",
      "Epoch 1193/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 3.3862e-04 - val_loss: 0.0010\n",
      "Epoch 1194/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 3.4327e-04 - val_loss: 0.0012\n",
      "Epoch 1195/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 3.4905e-04 - val_loss: 0.0011\n",
      "Epoch 1196/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 3.3450e-04 - val_loss: 0.0012\n",
      "Epoch 1197/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 3.5273e-04 - val_loss: 0.0012\n",
      "Epoch 1198/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 3.3434e-04 - val_loss: 0.0011\n",
      "Epoch 1199/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 3.1778e-04 - val_loss: 0.0017\n",
      "Epoch 1200/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 3.3465e-04 - val_loss: 0.0012\n",
      "Epoch 1201/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 3.4387e-04 - val_loss: 0.0015\n",
      "Epoch 1202/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 3.2947e-04 - val_loss: 0.0013\n",
      "Epoch 1203/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 3.3862e-04 - val_loss: 0.0014\n",
      "Epoch 1204/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 3.3123e-04 - val_loss: 0.0015\n",
      "Epoch 1205/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 3.2563e-04 - val_loss: 0.0018\n",
      "Epoch 1206/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 3.2788e-04 - val_loss: 0.0020\n",
      "Epoch 1207/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 3.2935e-04 - val_loss: 0.0014\n",
      "Epoch 1208/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 3.3483e-04 - val_loss: 0.0012\n",
      "Epoch 1209/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 474us/step - loss: 3.2692e-04 - val_loss: 0.0015\n",
      "Epoch 1210/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 3.4323e-04 - val_loss: 0.0017\n",
      "Epoch 1211/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 3.3206e-04 - val_loss: 0.0015\n",
      "Epoch 1212/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 3.1954e-04 - val_loss: 0.0016\n",
      "Epoch 1213/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 3.3528e-04 - val_loss: 0.0021\n",
      "Epoch 1214/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 3.4207e-04 - val_loss: 0.0013\n",
      "Epoch 1215/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 3.3726e-04 - val_loss: 0.0015\n",
      "Epoch 1216/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 3.3372e-04 - val_loss: 0.0016\n",
      "Epoch 1217/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 3.2800e-04 - val_loss: 0.0013\n",
      "Epoch 1218/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 3.1273e-04 - val_loss: 0.0013\n",
      "Epoch 1219/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 3.1314e-04 - val_loss: 0.0019\n",
      "Epoch 1220/2000\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 3.1921e-04 - val_loss: 0.0016\n",
      "Epoch 1221/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 3.2938e-04 - val_loss: 0.0019\n",
      "Epoch 1222/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 3.3984e-04 - val_loss: 0.0014\n",
      "Epoch 1223/2000\n",
      "3423/3423 [==============================] - 2s 484us/step - loss: 3.2142e-04 - val_loss: 0.0015\n",
      "Epoch 1224/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 3.2173e-04 - val_loss: 0.0014\n",
      "Epoch 1225/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 3.2439e-04 - val_loss: 0.0021\n",
      "Epoch 1226/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 3.2062e-04 - val_loss: 0.0013\n",
      "Epoch 1227/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 3.1481e-04 - val_loss: 0.0017\n",
      "Epoch 1228/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 3.1725e-04 - val_loss: 0.0014\n",
      "Epoch 1229/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 3.1671e-04 - val_loss: 0.0017\n",
      "Epoch 1230/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 3.1658e-04 - val_loss: 0.0016\n",
      "Epoch 1231/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 3.0092e-04 - val_loss: 0.0018\n",
      "Epoch 1232/2000\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 2.9981e-04 - val_loss: 0.0020\n",
      "Epoch 1233/2000\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 2.9010e-04 - val_loss: 0.0020\n",
      "Epoch 1234/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 2.9597e-04 - val_loss: 0.0018\n",
      "Epoch 1235/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 3.1505e-04 - val_loss: 0.0019\n",
      "Epoch 1236/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 3.1488e-04 - val_loss: 0.0018\n",
      "Epoch 1237/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 3.1062e-04 - val_loss: 0.0019\n",
      "Epoch 1238/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 3.0336e-04 - val_loss: 0.0021\n",
      "Epoch 1239/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 3.1886e-04 - val_loss: 0.0018\n",
      "Epoch 1240/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 3.3918e-04 - val_loss: 0.0018\n",
      "Epoch 1241/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 3.1673e-04 - val_loss: 0.0018\n",
      "Epoch 1242/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 3.1961e-04 - val_loss: 0.0017\n",
      "Epoch 1243/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 3.1587e-04 - val_loss: 0.0020\n",
      "Epoch 1244/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 3.0540e-04 - val_loss: 0.0023\n",
      "Epoch 1245/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 3.0279e-04 - val_loss: 0.0022\n",
      "Epoch 1246/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 2.9499e-04 - val_loss: 0.0023\n",
      "Epoch 1247/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 3.2091e-04 - val_loss: 0.0022\n",
      "Epoch 1248/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 3.5607e-04 - val_loss: 0.0016\n",
      "Epoch 1249/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 3.4469e-04 - val_loss: 0.0018\n",
      "Epoch 1250/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 3.2180e-04 - val_loss: 0.0021\n",
      "Epoch 1251/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 2.9432e-04 - val_loss: 0.0024\n",
      "Epoch 1252/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 2.9602e-04 - val_loss: 0.0019\n",
      "Epoch 1253/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 3.0072e-04 - val_loss: 0.0022\n",
      "Epoch 1254/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 3.1961e-04 - val_loss: 0.0020\n",
      "Epoch 1255/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 2.9644e-04 - val_loss: 0.0021\n",
      "Epoch 1256/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 2.9838e-04 - val_loss: 0.0023\n",
      "Epoch 1257/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 2.8951e-04 - val_loss: 0.0022\n",
      "Epoch 1258/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 2.8003e-04 - val_loss: 0.0027\n",
      "Epoch 1259/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 3.0281e-04 - val_loss: 0.0022\n",
      "Epoch 1260/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 3.0035e-04 - val_loss: 0.0021\n",
      "Epoch 1261/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 3.2796e-04 - val_loss: 0.0025\n",
      "Epoch 1262/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 3.1495e-04 - val_loss: 0.0019\n",
      "Epoch 1263/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 3.0108e-04 - val_loss: 0.0022\n",
      "Epoch 1264/2000\n",
      "3423/3423 [==============================] - 2s 472us/step - loss: 3.0237e-04 - val_loss: 0.0020\n",
      "Epoch 1265/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 2.8065e-04 - val_loss: 0.0025\n",
      "Epoch 1266/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 2.8551e-04 - val_loss: 0.0026\n",
      "Epoch 1267/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 2.8341e-04 - val_loss: 0.0021\n",
      "Epoch 1268/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 2.8758e-04 - val_loss: 0.0023\n",
      "Epoch 1269/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 2.9946e-04 - val_loss: 0.0023\n",
      "Epoch 1270/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 2.9420e-04 - val_loss: 0.0025\n",
      "Epoch 1271/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 2.9772e-04 - val_loss: 0.0019\n",
      "Epoch 1272/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 3.0017e-04 - val_loss: 0.0022\n",
      "Epoch 1273/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 2.9936e-04 - val_loss: 0.0028\n",
      "Epoch 1274/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 3.2090e-04 - val_loss: 0.0025\n",
      "Epoch 1275/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 2.8779e-04 - val_loss: 0.0022\n",
      "Epoch 1276/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 2.8656e-04 - val_loss: 0.0023\n",
      "Epoch 1277/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 2.7634e-04 - val_loss: 0.0023\n",
      "Epoch 1278/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 2.7744e-04 - val_loss: 0.0029\n",
      "Epoch 1279/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 3.3230e-04 - val_loss: 0.0023\n",
      "Epoch 1280/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 3.2128e-04 - val_loss: 0.0028\n",
      "Epoch 1281/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 478us/step - loss: 3.0080e-04 - val_loss: 0.0022\n",
      "Epoch 1282/2000\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 2.9765e-04 - val_loss: 0.0021\n",
      "Epoch 1283/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 2.8159e-04 - val_loss: 0.0024\n",
      "Epoch 1284/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 2.8188e-04 - val_loss: 0.0025\n",
      "Epoch 1285/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 2.7069e-04 - val_loss: 0.0023\n",
      "Epoch 1286/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 2.9326e-04 - val_loss: 0.0023\n",
      "Epoch 1287/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 2.8797e-04 - val_loss: 0.0021\n",
      "Epoch 1288/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 2.8628e-04 - val_loss: 0.0021\n",
      "Epoch 1289/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 3.1204e-04 - val_loss: 0.0024\n",
      "Epoch 1290/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 2.9509e-04 - val_loss: 0.0024\n",
      "Epoch 1291/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 2.7673e-04 - val_loss: 0.0019\n",
      "Epoch 1292/2000\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 2.7036e-04 - val_loss: 0.0026\n",
      "Epoch 1293/2000\n",
      "3423/3423 [==============================] - 2s 486us/step - loss: 2.8019e-04 - val_loss: 0.0025\n",
      "Epoch 1294/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 2.7114e-04 - val_loss: 0.0024\n",
      "Epoch 1295/2000\n",
      "3423/3423 [==============================] - 2s 471us/step - loss: 2.7635e-04 - val_loss: 0.0023\n",
      "Epoch 1296/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 2.7186e-04 - val_loss: 0.0022\n",
      "Epoch 1297/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 2.8783e-04 - val_loss: 0.0022\n",
      "Epoch 1298/2000\n",
      "3423/3423 [==============================] - 2s 468us/step - loss: 2.7713e-04 - val_loss: 0.0027\n",
      "Epoch 1299/2000\n",
      "3423/3423 [==============================] - 2s 471us/step - loss: 2.9768e-04 - val_loss: 0.0022\n",
      "Epoch 1300/2000\n",
      "3423/3423 [==============================] - 2s 470us/step - loss: 3.2597e-04 - val_loss: 0.0018\n",
      "Epoch 1301/2000\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 3.1968e-04 - val_loss: 0.0021\n",
      "Epoch 1302/2000\n",
      "3423/3423 [==============================] - 2s 470us/step - loss: 3.0146e-04 - val_loss: 0.0020\n",
      "Epoch 1303/2000\n",
      "3423/3423 [==============================] - 2s 471us/step - loss: 3.0659e-04 - val_loss: 0.0019\n",
      "Epoch 1304/2000\n",
      "3423/3423 [==============================] - 2s 470us/step - loss: 2.9492e-04 - val_loss: 0.0021\n",
      "Epoch 1305/2000\n",
      "3423/3423 [==============================] - 2s 469us/step - loss: 2.7388e-04 - val_loss: 0.0023\n",
      "Epoch 1306/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 2.7383e-04 - val_loss: 0.0021\n",
      "Epoch 1307/2000\n",
      "3423/3423 [==============================] - 2s 467us/step - loss: 2.8613e-04 - val_loss: 0.0022\n",
      "Epoch 1308/2000\n",
      "3423/3423 [==============================] - 2s 470us/step - loss: 2.9572e-04 - val_loss: 0.0022\n",
      "Epoch 1309/2000\n",
      "3423/3423 [==============================] - 2s 468us/step - loss: 2.8127e-04 - val_loss: 0.0022\n",
      "Epoch 1310/2000\n",
      "3423/3423 [==============================] - 2s 471us/step - loss: 2.6860e-04 - val_loss: 0.0023\n",
      "Epoch 1311/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 2.7260e-04 - val_loss: 0.0024\n",
      "Epoch 1312/2000\n",
      "3423/3423 [==============================] - 2s 469us/step - loss: 2.6853e-04 - val_loss: 0.0022\n",
      "Epoch 1313/2000\n",
      "3423/3423 [==============================] - 2s 469us/step - loss: 2.8631e-04 - val_loss: 0.0024\n",
      "Epoch 1314/2000\n",
      "3423/3423 [==============================] - 2s 472us/step - loss: 3.1151e-04 - val_loss: 0.0022\n",
      "Epoch 1315/2000\n",
      "3423/3423 [==============================] - 2s 470us/step - loss: 3.0002e-04 - val_loss: 0.0022\n",
      "Epoch 1316/2000\n",
      "3423/3423 [==============================] - 2s 469us/step - loss: 2.8846e-04 - val_loss: 0.0025\n",
      "Epoch 1317/2000\n",
      "3423/3423 [==============================] - 2s 472us/step - loss: 2.6644e-04 - val_loss: 0.0022\n",
      "Epoch 1318/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 2.5876e-04 - val_loss: 0.0022\n",
      "Epoch 1319/2000\n",
      "3423/3423 [==============================] - 2s 471us/step - loss: 2.6278e-04 - val_loss: 0.0025\n",
      "Epoch 1320/2000\n",
      "3423/3423 [==============================] - 2s 470us/step - loss: 2.6785e-04 - val_loss: 0.0024\n",
      "Epoch 1321/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 2.5852e-04 - val_loss: 0.0022\n",
      "Epoch 1322/2000\n",
      "3423/3423 [==============================] - 2s 469us/step - loss: 2.7353e-04 - val_loss: 0.0025\n",
      "Epoch 1323/2000\n",
      "3423/3423 [==============================] - 2s 470us/step - loss: 2.7605e-04 - val_loss: 0.0026\n",
      "Epoch 1324/2000\n",
      "3423/3423 [==============================] - 2s 470us/step - loss: 2.6206e-04 - val_loss: 0.0024\n",
      "Epoch 1325/2000\n",
      "3423/3423 [==============================] - 2s 471us/step - loss: 2.7941e-04 - val_loss: 0.0023\n",
      "Epoch 1326/2000\n",
      "3423/3423 [==============================] - 2s 468us/step - loss: 2.6787e-04 - val_loss: 0.0020\n",
      "Epoch 1327/2000\n",
      "3423/3423 [==============================] - 2s 468us/step - loss: 2.8511e-04 - val_loss: 0.0024\n",
      "Epoch 1328/2000\n",
      "3423/3423 [==============================] - 2s 468us/step - loss: 2.8996e-04 - val_loss: 0.0029\n",
      "Epoch 1329/2000\n",
      "3423/3423 [==============================] - 2s 466us/step - loss: 2.6892e-04 - val_loss: 0.0021\n",
      "Epoch 1330/2000\n",
      "3423/3423 [==============================] - 2s 471us/step - loss: 2.6841e-04 - val_loss: 0.0026\n",
      "Epoch 1331/2000\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 2.7261e-04 - val_loss: 0.0025\n",
      "Epoch 1332/2000\n",
      "3423/3423 [==============================] - 2s 469us/step - loss: 2.8684e-04 - val_loss: 0.0025\n",
      "Epoch 1333/2000\n",
      "3423/3423 [==============================] - 2s 469us/step - loss: 2.6211e-04 - val_loss: 0.0023\n",
      "Epoch 1334/2000\n",
      "3423/3423 [==============================] - 2s 472us/step - loss: 2.6584e-04 - val_loss: 0.0025\n",
      "Epoch 1335/2000\n",
      "3423/3423 [==============================] - 2s 468us/step - loss: 2.6193e-04 - val_loss: 0.0026\n",
      "Epoch 1336/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 2.5584e-04 - val_loss: 0.0026\n",
      "Epoch 1337/2000\n",
      "3423/3423 [==============================] - 2s 470us/step - loss: 2.5945e-04 - val_loss: 0.0022\n",
      "Epoch 1338/2000\n",
      "3423/3423 [==============================] - 2s 471us/step - loss: 2.5523e-04 - val_loss: 0.0025\n",
      "Epoch 1339/2000\n",
      "3423/3423 [==============================] - 2s 469us/step - loss: 2.6964e-04 - val_loss: 0.0024\n",
      "Epoch 1340/2000\n",
      "3423/3423 [==============================] - 2s 467us/step - loss: 2.5848e-04 - val_loss: 0.0028\n",
      "Epoch 1341/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 2.5241e-04 - val_loss: 0.0024\n",
      "Epoch 1342/2000\n",
      "3423/3423 [==============================] - 2s 469us/step - loss: 2.6125e-04 - val_loss: 0.0024\n",
      "Epoch 1343/2000\n",
      "3423/3423 [==============================] - 2s 470us/step - loss: 2.4678e-04 - val_loss: 0.0024\n",
      "Epoch 1344/2000\n",
      "3423/3423 [==============================] - 2s 468us/step - loss: 2.5622e-04 - val_loss: 0.0026\n",
      "Epoch 1345/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 2.5897e-04 - val_loss: 0.0023\n",
      "Epoch 1346/2000\n",
      "3423/3423 [==============================] - 2s 469us/step - loss: 2.6627e-04 - val_loss: 0.0023\n",
      "Epoch 1347/2000\n",
      "3423/3423 [==============================] - 2s 471us/step - loss: 2.5919e-04 - val_loss: 0.0026\n",
      "Epoch 1348/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 2.6534e-04 - val_loss: 0.0026\n",
      "Epoch 1349/2000\n",
      "3423/3423 [==============================] - 2s 471us/step - loss: 2.8457e-04 - val_loss: 0.0025\n",
      "Epoch 1350/2000\n",
      "3423/3423 [==============================] - 2s 470us/step - loss: 2.7048e-04 - val_loss: 0.0021\n",
      "Epoch 1351/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 2.5873e-04 - val_loss: 0.0025\n",
      "Epoch 1352/2000\n",
      "3423/3423 [==============================] - 2s 471us/step - loss: 2.5424e-04 - val_loss: 0.0021\n",
      "Epoch 1353/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 470us/step - loss: 2.6127e-04 - val_loss: 0.0023\n",
      "Epoch 1354/2000\n",
      "3423/3423 [==============================] - 2s 470us/step - loss: 2.5895e-04 - val_loss: 0.0028\n",
      "Epoch 1355/2000\n",
      "3423/3423 [==============================] - 2s 469us/step - loss: 2.6465e-04 - val_loss: 0.0029\n",
      "Epoch 1356/2000\n",
      "3423/3423 [==============================] - 2s 471us/step - loss: 2.7107e-04 - val_loss: 0.0030\n",
      "Epoch 1357/2000\n",
      "3423/3423 [==============================] - 2s 471us/step - loss: 2.6732e-04 - val_loss: 0.0026\n",
      "Epoch 1358/2000\n",
      "3423/3423 [==============================] - 2s 470us/step - loss: 2.6568e-04 - val_loss: 0.0019\n",
      "Epoch 1359/2000\n",
      "3423/3423 [==============================] - 2s 465us/step - loss: 2.7173e-04 - val_loss: 0.0021\n",
      "Epoch 1360/2000\n",
      "3423/3423 [==============================] - 2s 470us/step - loss: 2.3836e-04 - val_loss: 0.0024\n",
      "Epoch 1361/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 2.3836e-04 - val_loss: 0.0026\n",
      "Epoch 1362/2000\n",
      "3423/3423 [==============================] - 2s 586us/step - loss: 2.4384e-04 - val_loss: 0.0026\n",
      "Epoch 1363/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 2.4696e-04 - val_loss: 0.0025\n",
      "Epoch 1364/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 2.4716e-04 - val_loss: 0.0024\n",
      "Epoch 1365/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 2.5392e-04 - val_loss: 0.0028\n",
      "Epoch 1366/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 2.6619e-04 - val_loss: 0.0027\n",
      "Epoch 1367/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 2.4031e-04 - val_loss: 0.0027\n",
      "Epoch 1368/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 2.3747e-04 - val_loss: 0.0027\n",
      "Epoch 1369/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 2.6000e-04 - val_loss: 0.0024\n",
      "Epoch 1370/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 2.4993e-04 - val_loss: 0.0028\n",
      "Epoch 1371/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 2.5289e-04 - val_loss: 0.0027\n",
      "Epoch 1372/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 2.5563e-04 - val_loss: 0.0027\n",
      "Epoch 1373/2000\n",
      "3423/3423 [==============================] - 2s 472us/step - loss: 2.4102e-04 - val_loss: 0.0027\n",
      "Epoch 1374/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 2.3443e-04 - val_loss: 0.0025\n",
      "Epoch 1375/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 2.4515e-04 - val_loss: 0.0028\n",
      "Epoch 1376/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 2.4493e-04 - val_loss: 0.0026\n",
      "Epoch 1377/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 2.4024e-04 - val_loss: 0.0031\n",
      "Epoch 1378/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 2.7489e-04 - val_loss: 0.0031\n",
      "Epoch 1379/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 2.6929e-04 - val_loss: 0.0029\n",
      "Epoch 1380/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 2.6728e-04 - val_loss: 0.0026\n",
      "Epoch 1381/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 2.6200e-04 - val_loss: 0.0026\n",
      "Epoch 1382/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 2.6393e-04 - val_loss: 0.0029\n",
      "Epoch 1383/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 2.6228e-04 - val_loss: 0.0026\n",
      "Epoch 1384/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 2.5096e-04 - val_loss: 0.0027\n",
      "Epoch 1385/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 2.3727e-04 - val_loss: 0.0025\n",
      "Epoch 1386/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 2.5425e-04 - val_loss: 0.0027\n",
      "Epoch 1387/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 2.4499e-04 - val_loss: 0.0024\n",
      "Epoch 1388/2000\n",
      "3423/3423 [==============================] - 2s 472us/step - loss: 2.5997e-04 - val_loss: 0.0029\n",
      "Epoch 1389/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 2.5156e-04 - val_loss: 0.0024\n",
      "Epoch 1390/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 2.6624e-04 - val_loss: 0.0023\n",
      "Epoch 1391/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 2.9087e-04 - val_loss: 0.0021\n",
      "Epoch 1392/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 2.6939e-04 - val_loss: 0.0023\n",
      "Epoch 1393/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 2.5741e-04 - val_loss: 0.0025\n",
      "Epoch 1394/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 2.5324e-04 - val_loss: 0.0024\n",
      "Epoch 1395/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 2.3801e-04 - val_loss: 0.0025\n",
      "Epoch 1396/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 2.4539e-04 - val_loss: 0.0025\n",
      "Epoch 1397/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 2.4188e-04 - val_loss: 0.0026\n",
      "Epoch 1398/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 2.3235e-04 - val_loss: 0.0025\n",
      "Epoch 1399/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 2.3858e-04 - val_loss: 0.0026\n",
      "Epoch 1400/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 2.4301e-04 - val_loss: 0.0035\n",
      "Epoch 1401/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 2.7242e-04 - val_loss: 0.0029\n",
      "Epoch 1402/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 2.6898e-04 - val_loss: 0.0027\n",
      "Epoch 1403/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 2.5041e-04 - val_loss: 0.0026\n",
      "Epoch 1404/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 2.4013e-04 - val_loss: 0.0025\n",
      "Epoch 1405/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 2.3908e-04 - val_loss: 0.0025\n",
      "Epoch 1406/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 2.3895e-04 - val_loss: 0.0025\n",
      "Epoch 1407/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 2.5094e-04 - val_loss: 0.0027\n",
      "Epoch 1408/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 2.4445e-04 - val_loss: 0.0031\n",
      "Epoch 1409/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 2.4361e-04 - val_loss: 0.0028\n",
      "Epoch 1410/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 2.5918e-04 - val_loss: 0.0027\n",
      "Epoch 1411/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 2.7628e-04 - val_loss: 0.0025\n",
      "Epoch 1412/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 2.6658e-04 - val_loss: 0.0021\n",
      "Epoch 1413/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 2.5181e-04 - val_loss: 0.0027\n",
      "Epoch 1414/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 2.4452e-04 - val_loss: 0.0028\n",
      "Epoch 1415/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 2.4769e-04 - val_loss: 0.0031\n",
      "Epoch 1416/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 2.4195e-04 - val_loss: 0.0025\n",
      "Epoch 1417/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 2.4094e-04 - val_loss: 0.0027\n",
      "Epoch 1418/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 2.2473e-04 - val_loss: 0.0026\n",
      "Epoch 1419/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 2.1535e-04 - val_loss: 0.0028\n",
      "Epoch 1420/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 2.1823e-04 - val_loss: 0.0027\n",
      "Epoch 1421/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 2.1847e-04 - val_loss: 0.0026\n",
      "Epoch 1422/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 2.0802e-04 - val_loss: 0.0027\n",
      "Epoch 1423/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 2.2203e-04 - val_loss: 0.0028\n",
      "Epoch 1424/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 2.3652e-04 - val_loss: 0.0029\n",
      "Epoch 1425/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 473us/step - loss: 2.4984e-04 - val_loss: 0.0033\n",
      "Epoch 1426/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 2.7334e-04 - val_loss: 0.0027\n",
      "Epoch 1427/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 2.5524e-04 - val_loss: 0.0027\n",
      "Epoch 1428/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 2.7857e-04 - val_loss: 0.0028\n",
      "Epoch 1429/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 2.7754e-04 - val_loss: 0.0033\n",
      "Epoch 1430/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 2.8567e-04 - val_loss: 0.0031\n",
      "Epoch 1431/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 2.7275e-04 - val_loss: 0.0022\n",
      "Epoch 1432/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 2.6152e-04 - val_loss: 0.0022\n",
      "Epoch 1433/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 2.6174e-04 - val_loss: 0.0028\n",
      "Epoch 1434/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 2.3773e-04 - val_loss: 0.0031\n",
      "Epoch 1435/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 2.3881e-04 - val_loss: 0.0027\n",
      "Epoch 1436/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 2.3311e-04 - val_loss: 0.0028\n",
      "Epoch 1437/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 2.2689e-04 - val_loss: 0.0029\n",
      "Epoch 1438/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 2.2062e-04 - val_loss: 0.0027\n",
      "Epoch 1439/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 2.2537e-04 - val_loss: 0.0028\n",
      "Epoch 1440/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 2.1975e-04 - val_loss: 0.0032\n",
      "Epoch 1441/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 2.1933e-04 - val_loss: 0.0030\n",
      "Epoch 1442/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 2.1641e-04 - val_loss: 0.0030\n",
      "Epoch 1443/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 2.1826e-04 - val_loss: 0.0035\n",
      "Epoch 1444/2000\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 2.2240e-04 - val_loss: 0.0032\n",
      "Epoch 1445/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 2.0997e-04 - val_loss: 0.0030\n",
      "Epoch 1446/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 2.0769e-04 - val_loss: 0.0027\n",
      "Epoch 1447/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 2.1968e-04 - val_loss: 0.0032\n",
      "Epoch 1448/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 2.2339e-04 - val_loss: 0.0030\n",
      "Epoch 1449/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 2.4863e-04 - val_loss: 0.0029\n",
      "Epoch 1450/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 2.3966e-04 - val_loss: 0.0025\n",
      "Epoch 1451/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 2.4720e-04 - val_loss: 0.0027\n",
      "Epoch 1452/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 2.3217e-04 - val_loss: 0.0032\n",
      "Epoch 1453/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 2.6223e-04 - val_loss: 0.0028\n",
      "Epoch 1454/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 2.5877e-04 - val_loss: 0.0031\n",
      "Epoch 1455/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 2.5842e-04 - val_loss: 0.0033\n",
      "Epoch 1456/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 2.3932e-04 - val_loss: 0.0026\n",
      "Epoch 1457/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 2.3254e-04 - val_loss: 0.0028\n",
      "Epoch 1458/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 2.3067e-04 - val_loss: 0.0028\n",
      "Epoch 1459/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 2.2567e-04 - val_loss: 0.0028\n",
      "Epoch 1460/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 2.2965e-04 - val_loss: 0.0029\n",
      "Epoch 1461/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 2.3098e-04 - val_loss: 0.0029\n",
      "Epoch 1462/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 2.2589e-04 - val_loss: 0.0029\n",
      "Epoch 1463/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 2.2830e-04 - val_loss: 0.0028\n",
      "Epoch 1464/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 2.2278e-04 - val_loss: 0.0026\n",
      "Epoch 1465/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 2.2026e-04 - val_loss: 0.0025\n",
      "Epoch 1466/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 2.1663e-04 - val_loss: 0.0032\n",
      "Epoch 1467/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 2.3030e-04 - val_loss: 0.0036\n",
      "Epoch 1468/2000\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 2.3958e-04 - val_loss: 0.0026\n",
      "Epoch 1469/2000\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 2.3434e-04 - val_loss: 0.0031\n",
      "Epoch 1470/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 2.3832e-04 - val_loss: 0.0033\n",
      "Epoch 1471/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 2.3744e-04 - val_loss: 0.0029\n",
      "Epoch 1472/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 2.2559e-04 - val_loss: 0.0026\n",
      "Epoch 1473/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 2.1854e-04 - val_loss: 0.0028\n",
      "Epoch 1474/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 2.2823e-04 - val_loss: 0.0035\n",
      "Epoch 1475/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 2.0967e-04 - val_loss: 0.0029\n",
      "Epoch 1476/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 2.0359e-04 - val_loss: 0.0027\n",
      "Epoch 1477/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 2.2047e-04 - val_loss: 0.0031\n",
      "Epoch 1478/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 2.1829e-04 - val_loss: 0.0031\n",
      "Epoch 1479/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 2.1023e-04 - val_loss: 0.0032\n",
      "Epoch 1480/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 2.2957e-04 - val_loss: 0.0027\n",
      "Epoch 1481/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 2.2527e-04 - val_loss: 0.0028\n",
      "Epoch 1482/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 2.1828e-04 - val_loss: 0.0031\n",
      "Epoch 1483/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 2.2179e-04 - val_loss: 0.0032\n",
      "Epoch 1484/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 2.2158e-04 - val_loss: 0.0033\n",
      "Epoch 1485/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 2.1059e-04 - val_loss: 0.0030\n",
      "Epoch 1486/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 2.0629e-04 - val_loss: 0.0028\n",
      "Epoch 1487/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 2.0968e-04 - val_loss: 0.0029\n",
      "Epoch 1488/2000\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 2.4042e-04 - val_loss: 0.0037\n",
      "Epoch 1489/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 2.3642e-04 - val_loss: 0.0034\n",
      "Epoch 1490/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 2.6374e-04 - val_loss: 0.0032\n",
      "Epoch 1491/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 2.5763e-04 - val_loss: 0.0027\n",
      "Epoch 1492/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 2.5651e-04 - val_loss: 0.0025\n",
      "Epoch 1493/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 2.6191e-04 - val_loss: 0.0037\n",
      "Epoch 1494/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 2.6687e-04 - val_loss: 0.0026\n",
      "Epoch 1495/2000\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 2.3166e-04 - val_loss: 0.0030\n",
      "Epoch 1496/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 2.2864e-04 - val_loss: 0.0033\n",
      "Epoch 1497/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 474us/step - loss: 2.1551e-04 - val_loss: 0.0030\n",
      "Epoch 1498/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 2.0459e-04 - val_loss: 0.0031\n",
      "Epoch 1499/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 2.2109e-04 - val_loss: 0.0035\n",
      "Epoch 1500/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 2.0262e-04 - val_loss: 0.0033\n",
      "Epoch 1501/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 1.9769e-04 - val_loss: 0.0034\n",
      "Epoch 1502/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 1.9755e-04 - val_loss: 0.0036\n",
      "Epoch 1503/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 1.9962e-04 - val_loss: 0.0037\n",
      "Epoch 1504/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 2.1344e-04 - val_loss: 0.0034\n",
      "Epoch 1505/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 2.3388e-04 - val_loss: 0.0032\n",
      "Epoch 1506/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 2.4713e-04 - val_loss: 0.0034\n",
      "Epoch 1507/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 2.4483e-04 - val_loss: 0.0035\n",
      "Epoch 1508/2000\n",
      "3423/3423 [==============================] - 2s 478us/step - loss: 2.2419e-04 - val_loss: 0.0033\n",
      "Epoch 1509/2000\n",
      "3423/3423 [==============================] - 2s 485us/step - loss: 2.1625e-04 - val_loss: 0.0026\n",
      "Epoch 1510/2000\n",
      "3423/3423 [==============================] - 2s 486us/step - loss: 2.3566e-04 - val_loss: 0.0031\n",
      "Epoch 1511/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 2.1147e-04 - val_loss: 0.0040\n",
      "Epoch 1512/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 2.1307e-04 - val_loss: 0.0035\n",
      "Epoch 1513/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 2.0404e-04 - val_loss: 0.0034\n",
      "Epoch 1514/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 2.0711e-04 - val_loss: 0.0033\n",
      "Epoch 1515/2000\n",
      "3423/3423 [==============================] - 2s 486us/step - loss: 2.0159e-04 - val_loss: 0.0034\n",
      "Epoch 1516/2000\n",
      "3423/3423 [==============================] - 2s 479us/step - loss: 2.0930e-04 - val_loss: 0.0034\n",
      "Epoch 1517/2000\n",
      "3423/3423 [==============================] - 2s 484us/step - loss: 1.9622e-04 - val_loss: 0.0035\n",
      "Epoch 1518/2000\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 2.0127e-04 - val_loss: 0.0035\n",
      "Epoch 1519/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 1.9739e-04 - val_loss: 0.0038\n",
      "Epoch 1520/2000\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 2.0086e-04 - val_loss: 0.0037\n",
      "Epoch 1521/2000\n",
      "3423/3423 [==============================] - 2s 472us/step - loss: 2.0015e-04 - val_loss: 0.0035\n",
      "Epoch 1522/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 2.2081e-04 - val_loss: 0.0039\n",
      "Epoch 1523/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 2.2273e-04 - val_loss: 0.0041\n",
      "Epoch 1524/2000\n",
      "3423/3423 [==============================] - 2s 472us/step - loss: 2.2624e-04 - val_loss: 0.0035\n",
      "Epoch 1525/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 2.4436e-04 - val_loss: 0.0035\n",
      "Epoch 1526/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 2.2761e-04 - val_loss: 0.0038\n",
      "Epoch 1527/2000\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 2.1712e-04 - val_loss: 0.0038\n",
      "Epoch 1528/2000\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 2.1191e-04 - val_loss: 0.0032\n",
      "Epoch 1529/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 2.0684e-04 - val_loss: 0.0035\n",
      "Epoch 1530/2000\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 2.0100e-04 - val_loss: 0.0037\n",
      "Epoch 1531/2000\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 1.9876e-04 - val_loss: 0.0038\n",
      "Epoch 1532/2000\n",
      "3423/3423 [==============================] - 2s 503us/step - loss: 1.9848e-04 - val_loss: 0.0040\n",
      "Epoch 1533/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 2.0460e-04 - val_loss: 0.0037\n",
      "Epoch 1534/2000\n",
      "3423/3423 [==============================] - 2s 512us/step - loss: 2.0483e-04 - val_loss: 0.0034\n",
      "Epoch 1535/2000\n",
      "3423/3423 [==============================] - 2s 513us/step - loss: 1.9242e-04 - val_loss: 0.0036\n",
      "Epoch 1536/2000\n",
      "3423/3423 [==============================] - 2s 512us/step - loss: 1.9082e-04 - val_loss: 0.0041\n",
      "Epoch 1537/2000\n",
      "3423/3423 [==============================] - 2s 521us/step - loss: 1.9606e-04 - val_loss: 0.0041\n",
      "Epoch 1538/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 2.0688e-04 - val_loss: 0.0034\n",
      "Epoch 1539/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 2.0633e-04 - val_loss: 0.0041\n",
      "Epoch 1540/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 2.2510e-04 - val_loss: 0.0041\n",
      "Epoch 1541/2000\n",
      "3423/3423 [==============================] - 2s 514us/step - loss: 2.1273e-04 - val_loss: 0.0034\n",
      "Epoch 1542/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 2.0603e-04 - val_loss: 0.0033\n",
      "Epoch 1543/2000\n",
      "3423/3423 [==============================] - 2s 514us/step - loss: 1.9502e-04 - val_loss: 0.0033\n",
      "Epoch 1544/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.9637e-04 - val_loss: 0.0035\n",
      "Epoch 1545/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 2.0618e-04 - val_loss: 0.0036\n",
      "Epoch 1546/2000\n",
      "3423/3423 [==============================] - 2s 514us/step - loss: 2.1829e-04 - val_loss: 0.0035\n",
      "Epoch 1547/2000\n",
      "3423/3423 [==============================] - 2s 521us/step - loss: 2.0644e-04 - val_loss: 0.0040\n",
      "Epoch 1548/2000\n",
      "3423/3423 [==============================] - 2s 521us/step - loss: 1.9289e-04 - val_loss: 0.0037\n",
      "Epoch 1549/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.9488e-04 - val_loss: 0.0035\n",
      "Epoch 1550/2000\n",
      "3423/3423 [==============================] - 2s 511us/step - loss: 2.1374e-04 - val_loss: 0.0034\n",
      "Epoch 1551/2000\n",
      "3423/3423 [==============================] - 2s 511us/step - loss: 2.1122e-04 - val_loss: 0.0033\n",
      "Epoch 1552/2000\n",
      "3423/3423 [==============================] - 2s 507us/step - loss: 2.0556e-04 - val_loss: 0.0034\n",
      "Epoch 1553/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 1.9576e-04 - val_loss: 0.0038\n",
      "Epoch 1554/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 2.0511e-04 - val_loss: 0.0031\n",
      "Epoch 1555/2000\n",
      "3423/3423 [==============================] - 2s 515us/step - loss: 2.0859e-04 - val_loss: 0.0033\n",
      "Epoch 1556/2000\n",
      "3423/3423 [==============================] - 2s 507us/step - loss: 1.9328e-04 - val_loss: 0.0039\n",
      "Epoch 1557/2000\n",
      "3423/3423 [==============================] - 2s 506us/step - loss: 1.8588e-04 - val_loss: 0.0033\n",
      "Epoch 1558/2000\n",
      "3423/3423 [==============================] - 2s 507us/step - loss: 1.9199e-04 - val_loss: 0.0034\n",
      "Epoch 1559/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 2.0111e-04 - val_loss: 0.0037\n",
      "Epoch 1560/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 2.1487e-04 - val_loss: 0.0034\n",
      "Epoch 1561/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 2.1889e-04 - val_loss: 0.0032\n",
      "Epoch 1562/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 2.0910e-04 - val_loss: 0.0034\n",
      "Epoch 1563/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.9473e-04 - val_loss: 0.0038\n",
      "Epoch 1564/2000\n",
      "3423/3423 [==============================] - 2s 517us/step - loss: 1.8852e-04 - val_loss: 0.0038\n",
      "Epoch 1565/2000\n",
      "3423/3423 [==============================] - 2s 506us/step - loss: 1.9301e-04 - val_loss: 0.0033\n",
      "Epoch 1566/2000\n",
      "3423/3423 [==============================] - 2s 512us/step - loss: 1.9230e-04 - val_loss: 0.0036\n",
      "Epoch 1567/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.8954e-04 - val_loss: 0.0038\n",
      "Epoch 1568/2000\n",
      "3423/3423 [==============================] - 2s 511us/step - loss: 1.8534e-04 - val_loss: 0.0032\n",
      "Epoch 1569/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 509us/step - loss: 1.8554e-04 - val_loss: 0.0032\n",
      "Epoch 1570/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.8593e-04 - val_loss: 0.0042\n",
      "Epoch 1571/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 1.9629e-04 - val_loss: 0.0035\n",
      "Epoch 1572/2000\n",
      "3423/3423 [==============================] - 2s 507us/step - loss: 1.9177e-04 - val_loss: 0.0033\n",
      "Epoch 1573/2000\n",
      "3423/3423 [==============================] - 2s 516us/step - loss: 1.8472e-04 - val_loss: 0.0033\n",
      "Epoch 1574/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.8921e-04 - val_loss: 0.0035\n",
      "Epoch 1575/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.7956e-04 - val_loss: 0.0040\n",
      "Epoch 1576/2000\n",
      "3423/3423 [==============================] - 2s 506us/step - loss: 1.8844e-04 - val_loss: 0.0038\n",
      "Epoch 1577/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.8184e-04 - val_loss: 0.0036\n",
      "Epoch 1578/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 1.7739e-04 - val_loss: 0.0037\n",
      "Epoch 1579/2000\n",
      "3423/3423 [==============================] - 2s 512us/step - loss: 1.7980e-04 - val_loss: 0.0039\n",
      "Epoch 1580/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.8831e-04 - val_loss: 0.0038\n",
      "Epoch 1581/2000\n",
      "3423/3423 [==============================] - 2s 511us/step - loss: 1.9805e-04 - val_loss: 0.0029\n",
      "Epoch 1582/2000\n",
      "3423/3423 [==============================] - 2s 513us/step - loss: 1.9770e-04 - val_loss: 0.0033\n",
      "Epoch 1583/2000\n",
      "3423/3423 [==============================] - 2s 512us/step - loss: 1.9016e-04 - val_loss: 0.0039\n",
      "Epoch 1584/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.8307e-04 - val_loss: 0.0037\n",
      "Epoch 1585/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.8059e-04 - val_loss: 0.0038\n",
      "Epoch 1586/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.7478e-04 - val_loss: 0.0036\n",
      "Epoch 1587/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.7494e-04 - val_loss: 0.0035\n",
      "Epoch 1588/2000\n",
      "3423/3423 [==============================] - 2s 511us/step - loss: 1.9163e-04 - val_loss: 0.0040\n",
      "Epoch 1589/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 1.8455e-04 - val_loss: 0.0030\n",
      "Epoch 1590/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.8720e-04 - val_loss: 0.0034\n",
      "Epoch 1591/2000\n",
      "3423/3423 [==============================] - 2s 514us/step - loss: 1.7235e-04 - val_loss: 0.0036\n",
      "Epoch 1592/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.8650e-04 - val_loss: 0.0040\n",
      "Epoch 1593/2000\n",
      "3423/3423 [==============================] - 2s 506us/step - loss: 1.7206e-04 - val_loss: 0.0037\n",
      "Epoch 1594/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 1.7310e-04 - val_loss: 0.0041\n",
      "Epoch 1595/2000\n",
      "3423/3423 [==============================] - 2s 511us/step - loss: 1.8279e-04 - val_loss: 0.0036\n",
      "Epoch 1596/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.7763e-04 - val_loss: 0.0036\n",
      "Epoch 1597/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 1.7450e-04 - val_loss: 0.0036\n",
      "Epoch 1598/2000\n",
      "3423/3423 [==============================] - 2s 511us/step - loss: 1.8146e-04 - val_loss: 0.0032\n",
      "Epoch 1599/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.9646e-04 - val_loss: 0.0033\n",
      "Epoch 1600/2000\n",
      "3423/3423 [==============================] - 2s 514us/step - loss: 1.8619e-04 - val_loss: 0.0038\n",
      "Epoch 1601/2000\n",
      "3423/3423 [==============================] - 2s 514us/step - loss: 1.7863e-04 - val_loss: 0.0035\n",
      "Epoch 1602/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.7546e-04 - val_loss: 0.0035\n",
      "Epoch 1603/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 1.7324e-04 - val_loss: 0.0038\n",
      "Epoch 1604/2000\n",
      "3423/3423 [==============================] - 2s 511us/step - loss: 1.7660e-04 - val_loss: 0.0035\n",
      "Epoch 1605/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.6632e-04 - val_loss: 0.0031\n",
      "Epoch 1606/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 1.6934e-04 - val_loss: 0.0038\n",
      "Epoch 1607/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.8389e-04 - val_loss: 0.0037\n",
      "Epoch 1608/2000\n",
      "3423/3423 [==============================] - 2s 511us/step - loss: 1.8652e-04 - val_loss: 0.0032\n",
      "Epoch 1609/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.8974e-04 - val_loss: 0.0032\n",
      "Epoch 1610/2000\n",
      "3423/3423 [==============================] - 2s 519us/step - loss: 1.8421e-04 - val_loss: 0.0035\n",
      "Epoch 1611/2000\n",
      "3423/3423 [==============================] - 2s 511us/step - loss: 1.8960e-04 - val_loss: 0.0038\n",
      "Epoch 1612/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.7992e-04 - val_loss: 0.0040\n",
      "Epoch 1613/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 1.9912e-04 - val_loss: 0.0038\n",
      "Epoch 1614/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 1.8854e-04 - val_loss: 0.0037\n",
      "Epoch 1615/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 1.8639e-04 - val_loss: 0.0035\n",
      "Epoch 1616/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.9177e-04 - val_loss: 0.0036\n",
      "Epoch 1617/2000\n",
      "3423/3423 [==============================] - 2s 507us/step - loss: 1.8285e-04 - val_loss: 0.0039\n",
      "Epoch 1618/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 1.7174e-04 - val_loss: 0.0036\n",
      "Epoch 1619/2000\n",
      "3423/3423 [==============================] - 2s 515us/step - loss: 1.6759e-04 - val_loss: 0.0036\n",
      "Epoch 1620/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.9243e-04 - val_loss: 0.0032\n",
      "Epoch 1621/2000\n",
      "3423/3423 [==============================] - 2s 512us/step - loss: 2.0041e-04 - val_loss: 0.0033\n",
      "Epoch 1622/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.7779e-04 - val_loss: 0.0039\n",
      "Epoch 1623/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.6701e-04 - val_loss: 0.0034\n",
      "Epoch 1624/2000\n",
      "3423/3423 [==============================] - 2s 507us/step - loss: 1.7164e-04 - val_loss: 0.0037\n",
      "Epoch 1625/2000\n",
      "3423/3423 [==============================] - 2s 512us/step - loss: 1.6462e-04 - val_loss: 0.0038\n",
      "Epoch 1626/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.7179e-04 - val_loss: 0.0042\n",
      "Epoch 1627/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.7620e-04 - val_loss: 0.0035\n",
      "Epoch 1628/2000\n",
      "3423/3423 [==============================] - 2s 517us/step - loss: 1.7686e-04 - val_loss: 0.0032\n",
      "Epoch 1629/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.7264e-04 - val_loss: 0.0038\n",
      "Epoch 1630/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.7243e-04 - val_loss: 0.0037\n",
      "Epoch 1631/2000\n",
      "3423/3423 [==============================] - 2s 512us/step - loss: 1.6660e-04 - val_loss: 0.0034\n",
      "Epoch 1632/2000\n",
      "3423/3423 [==============================] - 2s 507us/step - loss: 1.7067e-04 - val_loss: 0.0041\n",
      "Epoch 1633/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.9627e-04 - val_loss: 0.0033\n",
      "Epoch 1634/2000\n",
      "3423/3423 [==============================] - 2s 525us/step - loss: 1.9675e-04 - val_loss: 0.0031\n",
      "Epoch 1635/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 2.1268e-04 - val_loss: 0.0039\n",
      "Epoch 1636/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.9067e-04 - val_loss: 0.0038\n",
      "Epoch 1637/2000\n",
      "3423/3423 [==============================] - 2s 516us/step - loss: 1.7229e-04 - val_loss: 0.0037\n",
      "Epoch 1638/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.7336e-04 - val_loss: 0.0038\n",
      "Epoch 1639/2000\n",
      "3423/3423 [==============================] - 2s 519us/step - loss: 1.6806e-04 - val_loss: 0.0035\n",
      "Epoch 1640/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.8834e-04 - val_loss: 0.0035\n",
      "Epoch 1641/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 509us/step - loss: 1.9465e-04 - val_loss: 0.0038\n",
      "Epoch 1642/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.8144e-04 - val_loss: 0.0039\n",
      "Epoch 1643/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.7520e-04 - val_loss: 0.0038\n",
      "Epoch 1644/2000\n",
      "3423/3423 [==============================] - 2s 507us/step - loss: 1.6255e-04 - val_loss: 0.0035\n",
      "Epoch 1645/2000\n",
      "3423/3423 [==============================] - 2s 506us/step - loss: 1.5694e-04 - val_loss: 0.0039\n",
      "Epoch 1646/2000\n",
      "3423/3423 [==============================] - 2s 514us/step - loss: 1.6523e-04 - val_loss: 0.0040\n",
      "Epoch 1647/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 1.6641e-04 - val_loss: 0.0035\n",
      "Epoch 1648/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.5564e-04 - val_loss: 0.0039\n",
      "Epoch 1649/2000\n",
      "3423/3423 [==============================] - 2s 511us/step - loss: 1.5378e-04 - val_loss: 0.0038\n",
      "Epoch 1650/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 1.5820e-04 - val_loss: 0.0038\n",
      "Epoch 1651/2000\n",
      "3423/3423 [==============================] - 2s 511us/step - loss: 1.5601e-04 - val_loss: 0.0039\n",
      "Epoch 1652/2000\n",
      "3423/3423 [==============================] - 2s 511us/step - loss: 1.4687e-04 - val_loss: 0.0038\n",
      "Epoch 1653/2000\n",
      "3423/3423 [==============================] - 2s 507us/step - loss: 1.5788e-04 - val_loss: 0.0042\n",
      "Epoch 1654/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 1.6604e-04 - val_loss: 0.0037\n",
      "Epoch 1655/2000\n",
      "3423/3423 [==============================] - 2s 512us/step - loss: 1.6202e-04 - val_loss: 0.0038\n",
      "Epoch 1656/2000\n",
      "3423/3423 [==============================] - 2s 514us/step - loss: 1.6973e-04 - val_loss: 0.0039\n",
      "Epoch 1657/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.7594e-04 - val_loss: 0.0040\n",
      "Epoch 1658/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 1.7148e-04 - val_loss: 0.0035\n",
      "Epoch 1659/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.8535e-04 - val_loss: 0.0037\n",
      "Epoch 1660/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.6219e-04 - val_loss: 0.0036\n",
      "Epoch 1661/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.5840e-04 - val_loss: 0.0038\n",
      "Epoch 1662/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.6515e-04 - val_loss: 0.0040\n",
      "Epoch 1663/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.7693e-04 - val_loss: 0.0035\n",
      "Epoch 1664/2000\n",
      "3423/3423 [==============================] - 2s 512us/step - loss: 1.6505e-04 - val_loss: 0.0036\n",
      "Epoch 1665/2000\n",
      "3423/3423 [==============================] - 2s 518us/step - loss: 1.7738e-04 - val_loss: 0.0041\n",
      "Epoch 1666/2000\n",
      "3423/3423 [==============================] - 2s 511us/step - loss: 1.6912e-04 - val_loss: 0.0034\n",
      "Epoch 1667/2000\n",
      "3423/3423 [==============================] - 2s 512us/step - loss: 1.8802e-04 - val_loss: 0.0038\n",
      "Epoch 1668/2000\n",
      "3423/3423 [==============================] - 2s 511us/step - loss: 1.6381e-04 - val_loss: 0.0035\n",
      "Epoch 1669/2000\n",
      "3423/3423 [==============================] - 2s 516us/step - loss: 1.6327e-04 - val_loss: 0.0037\n",
      "Epoch 1670/2000\n",
      "3423/3423 [==============================] - 2s 532us/step - loss: 1.5869e-04 - val_loss: 0.0036\n",
      "Epoch 1671/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 1.4564e-04 - val_loss: 0.0037\n",
      "Epoch 1672/2000\n",
      "3423/3423 [==============================] - 2s 506us/step - loss: 1.4333e-04 - val_loss: 0.0040\n",
      "Epoch 1673/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.4531e-04 - val_loss: 0.0038\n",
      "Epoch 1674/2000\n",
      "3423/3423 [==============================] - 2s 515us/step - loss: 1.4846e-04 - val_loss: 0.0038\n",
      "Epoch 1675/2000\n",
      "3423/3423 [==============================] - 2s 511us/step - loss: 1.4943e-04 - val_loss: 0.0038\n",
      "Epoch 1676/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.4718e-04 - val_loss: 0.0040\n",
      "Epoch 1677/2000\n",
      "3423/3423 [==============================] - 2s 511us/step - loss: 1.4772e-04 - val_loss: 0.0039\n",
      "Epoch 1678/2000\n",
      "3423/3423 [==============================] - 2s 511us/step - loss: 1.5380e-04 - val_loss: 0.0041\n",
      "Epoch 1679/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.6022e-04 - val_loss: 0.0039\n",
      "Epoch 1680/2000\n",
      "3423/3423 [==============================] - 2s 511us/step - loss: 1.7051e-04 - val_loss: 0.0040\n",
      "Epoch 1681/2000\n",
      "3423/3423 [==============================] - 2s 507us/step - loss: 1.6539e-04 - val_loss: 0.0041\n",
      "Epoch 1682/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.5958e-04 - val_loss: 0.0042\n",
      "Epoch 1683/2000\n",
      "3423/3423 [==============================] - 2s 516us/step - loss: 1.5492e-04 - val_loss: 0.0041\n",
      "Epoch 1684/2000\n",
      "3423/3423 [==============================] - 2s 506us/step - loss: 1.4562e-04 - val_loss: 0.0043\n",
      "Epoch 1685/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.4894e-04 - val_loss: 0.0037\n",
      "Epoch 1686/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 1.5519e-04 - val_loss: 0.0036\n",
      "Epoch 1687/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 1.4721e-04 - val_loss: 0.0038\n",
      "Epoch 1688/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 1.4618e-04 - val_loss: 0.0042\n",
      "Epoch 1689/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 1.5044e-04 - val_loss: 0.0039\n",
      "Epoch 1690/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 1.5434e-04 - val_loss: 0.0040\n",
      "Epoch 1691/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.5129e-04 - val_loss: 0.0039\n",
      "Epoch 1692/2000\n",
      "3423/3423 [==============================] - 2s 514us/step - loss: 1.5144e-04 - val_loss: 0.0036\n",
      "Epoch 1693/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.5449e-04 - val_loss: 0.0036\n",
      "Epoch 1694/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.6554e-04 - val_loss: 0.0040\n",
      "Epoch 1695/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.5700e-04 - val_loss: 0.0043\n",
      "Epoch 1696/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 1.5785e-04 - val_loss: 0.0044\n",
      "Epoch 1697/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 1.5596e-04 - val_loss: 0.0037\n",
      "Epoch 1698/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.6413e-04 - val_loss: 0.0038\n",
      "Epoch 1699/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.6221e-04 - val_loss: 0.0044\n",
      "Epoch 1700/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.6747e-04 - val_loss: 0.0050\n",
      "Epoch 1701/2000\n",
      "3423/3423 [==============================] - 2s 517us/step - loss: 1.6533e-04 - val_loss: 0.0041\n",
      "Epoch 1702/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.5366e-04 - val_loss: 0.0037\n",
      "Epoch 1703/2000\n",
      "3423/3423 [==============================] - 2s 512us/step - loss: 1.4677e-04 - val_loss: 0.0040\n",
      "Epoch 1704/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.4474e-04 - val_loss: 0.0039\n",
      "Epoch 1705/2000\n",
      "3423/3423 [==============================] - 2s 507us/step - loss: 1.5385e-04 - val_loss: 0.0042\n",
      "Epoch 1706/2000\n",
      "3423/3423 [==============================] - 2s 511us/step - loss: 1.4702e-04 - val_loss: 0.0039\n",
      "Epoch 1707/2000\n",
      "3423/3423 [==============================] - 2s 512us/step - loss: 1.3979e-04 - val_loss: 0.0037\n",
      "Epoch 1708/2000\n",
      "3423/3423 [==============================] - 2s 506us/step - loss: 1.6735e-04 - val_loss: 0.0035\n",
      "Epoch 1709/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 1.8133e-04 - val_loss: 0.0033\n",
      "Epoch 1710/2000\n",
      "3423/3423 [==============================] - 2s 518us/step - loss: 1.9016e-04 - val_loss: 0.0038\n",
      "Epoch 1711/2000\n",
      "3423/3423 [==============================] - 2s 513us/step - loss: 1.6711e-04 - val_loss: 0.0040\n",
      "Epoch 1712/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.7158e-04 - val_loss: 0.0039\n",
      "Epoch 1713/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.7346e-04 - val_loss: 0.0036\n",
      "Epoch 1714/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.8310e-04 - val_loss: 0.0037\n",
      "Epoch 1715/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.7115e-04 - val_loss: 0.0038\n",
      "Epoch 1716/2000\n",
      "3423/3423 [==============================] - 2s 507us/step - loss: 1.6638e-04 - val_loss: 0.0041\n",
      "Epoch 1717/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.6746e-04 - val_loss: 0.0039\n",
      "Epoch 1718/2000\n",
      "3423/3423 [==============================] - 2s 517us/step - loss: 1.5387e-04 - val_loss: 0.0034\n",
      "Epoch 1719/2000\n",
      "3423/3423 [==============================] - 2s 533us/step - loss: 1.4944e-04 - val_loss: 0.0036\n",
      "Epoch 1720/2000\n",
      "3423/3423 [==============================] - 2s 529us/step - loss: 1.5822e-04 - val_loss: 0.0035\n",
      "Epoch 1721/2000\n",
      "3423/3423 [==============================] - 2s 525us/step - loss: 1.6429e-04 - val_loss: 0.0038\n",
      "Epoch 1722/2000\n",
      "3423/3423 [==============================] - 2s 526us/step - loss: 1.5527e-04 - val_loss: 0.0039\n",
      "Epoch 1723/2000\n",
      "3423/3423 [==============================] - 2s 519us/step - loss: 1.4404e-04 - val_loss: 0.0036\n",
      "Epoch 1724/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.4854e-04 - val_loss: 0.0039\n",
      "Epoch 1725/2000\n",
      "3423/3423 [==============================] - 2s 505us/step - loss: 1.4262e-04 - val_loss: 0.0037\n",
      "Epoch 1726/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.3994e-04 - val_loss: 0.0034\n",
      "Epoch 1727/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.4670e-04 - val_loss: 0.0042\n",
      "Epoch 1728/2000\n",
      "3423/3423 [==============================] - 2s 514us/step - loss: 1.4113e-04 - val_loss: 0.0044\n",
      "Epoch 1729/2000\n",
      "3423/3423 [==============================] - 2s 513us/step - loss: 1.3731e-04 - val_loss: 0.0037\n",
      "Epoch 1730/2000\n",
      "3423/3423 [==============================] - 2s 527us/step - loss: 1.4146e-04 - val_loss: 0.0044\n",
      "Epoch 1731/2000\n",
      "3423/3423 [==============================] - 2s 513us/step - loss: 1.4296e-04 - val_loss: 0.0041\n",
      "Epoch 1732/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.4719e-04 - val_loss: 0.0042\n",
      "Epoch 1733/2000\n",
      "3423/3423 [==============================] - 2s 513us/step - loss: 1.4643e-04 - val_loss: 0.0041\n",
      "Epoch 1734/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.3600e-04 - val_loss: 0.0039\n",
      "Epoch 1735/2000\n",
      "3423/3423 [==============================] - 2s 519us/step - loss: 1.3486e-04 - val_loss: 0.0037\n",
      "Epoch 1736/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.5717e-04 - val_loss: 0.0038\n",
      "Epoch 1737/2000\n",
      "3423/3423 [==============================] - 2s 521us/step - loss: 1.5092e-04 - val_loss: 0.0037\n",
      "Epoch 1738/2000\n",
      "3423/3423 [==============================] - 2s 513us/step - loss: 1.4612e-04 - val_loss: 0.0040\n",
      "Epoch 1739/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.4480e-04 - val_loss: 0.0039\n",
      "Epoch 1740/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.4628e-04 - val_loss: 0.0038\n",
      "Epoch 1741/2000\n",
      "3423/3423 [==============================] - 2s 511us/step - loss: 1.4162e-04 - val_loss: 0.0034\n",
      "Epoch 1742/2000\n",
      "3423/3423 [==============================] - 2s 512us/step - loss: 1.4663e-04 - val_loss: 0.0040\n",
      "Epoch 1743/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.4146e-04 - val_loss: 0.0036\n",
      "Epoch 1744/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.5018e-04 - val_loss: 0.0038\n",
      "Epoch 1745/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.4732e-04 - val_loss: 0.0041\n",
      "Epoch 1746/2000\n",
      "3423/3423 [==============================] - 2s 514us/step - loss: 1.3258e-04 - val_loss: 0.0038\n",
      "Epoch 1747/2000\n",
      "3423/3423 [==============================] - 2s 516us/step - loss: 1.3196e-04 - val_loss: 0.0040\n",
      "Epoch 1748/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 1.3402e-04 - val_loss: 0.0038\n",
      "Epoch 1749/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 1.2857e-04 - val_loss: 0.0043\n",
      "Epoch 1750/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.2750e-04 - val_loss: 0.0042\n",
      "Epoch 1751/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.3381e-04 - val_loss: 0.0042\n",
      "Epoch 1752/2000\n",
      "3423/3423 [==============================] - 2s 506us/step - loss: 1.4025e-04 - val_loss: 0.0041\n",
      "Epoch 1753/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.4002e-04 - val_loss: 0.0041\n",
      "Epoch 1754/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.3261e-04 - val_loss: 0.0040\n",
      "Epoch 1755/2000\n",
      "3423/3423 [==============================] - 2s 512us/step - loss: 1.4123e-04 - val_loss: 0.0038\n",
      "Epoch 1756/2000\n",
      "3423/3423 [==============================] - 2s 517us/step - loss: 1.3998e-04 - val_loss: 0.0039\n",
      "Epoch 1757/2000\n",
      "3423/3423 [==============================] - 2s 515us/step - loss: 1.4173e-04 - val_loss: 0.0042\n",
      "Epoch 1758/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.5142e-04 - val_loss: 0.0038\n",
      "Epoch 1759/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.5540e-04 - val_loss: 0.0036\n",
      "Epoch 1760/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.3789e-04 - val_loss: 0.0037\n",
      "Epoch 1761/2000\n",
      "3423/3423 [==============================] - 2s 507us/step - loss: 1.2720e-04 - val_loss: 0.0035\n",
      "Epoch 1762/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.3515e-04 - val_loss: 0.0038\n",
      "Epoch 1763/2000\n",
      "3423/3423 [==============================] - 2s 511us/step - loss: 1.3238e-04 - val_loss: 0.0037\n",
      "Epoch 1764/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.4126e-04 - val_loss: 0.0040\n",
      "Epoch 1765/2000\n",
      "3423/3423 [==============================] - 2s 517us/step - loss: 1.3170e-04 - val_loss: 0.0042\n",
      "Epoch 1766/2000\n",
      "3423/3423 [==============================] - 2s 511us/step - loss: 1.3012e-04 - val_loss: 0.0038\n",
      "Epoch 1767/2000\n",
      "3423/3423 [==============================] - 2s 511us/step - loss: 1.3746e-04 - val_loss: 0.0043\n",
      "Epoch 1768/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.3776e-04 - val_loss: 0.0042\n",
      "Epoch 1769/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.4484e-04 - val_loss: 0.0031\n",
      "Epoch 1770/2000\n",
      "3423/3423 [==============================] - 2s 517us/step - loss: 1.3961e-04 - val_loss: 0.0041\n",
      "Epoch 1771/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.4289e-04 - val_loss: 0.0038\n",
      "Epoch 1772/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 1.4459e-04 - val_loss: 0.0037\n",
      "Epoch 1773/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 1.5915e-04 - val_loss: 0.0034\n",
      "Epoch 1774/2000\n",
      "3423/3423 [==============================] - 2s 516us/step - loss: 1.3374e-04 - val_loss: 0.0035\n",
      "Epoch 1775/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 1.2795e-04 - val_loss: 0.0041\n",
      "Epoch 1776/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.3078e-04 - val_loss: 0.0040\n",
      "Epoch 1777/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.2754e-04 - val_loss: 0.0039\n",
      "Epoch 1778/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.2578e-04 - val_loss: 0.0039\n",
      "Epoch 1779/2000\n",
      "3423/3423 [==============================] - 2s 506us/step - loss: 1.2881e-04 - val_loss: 0.0038\n",
      "Epoch 1780/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.5105e-04 - val_loss: 0.0040\n",
      "Epoch 1781/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.4852e-04 - val_loss: 0.0046\n",
      "Epoch 1782/2000\n",
      "3423/3423 [==============================] - 2s 506us/step - loss: 1.4705e-04 - val_loss: 0.0038\n",
      "Epoch 1783/2000\n",
      "3423/3423 [==============================] - 2s 516us/step - loss: 1.4910e-04 - val_loss: 0.0041\n",
      "Epoch 1784/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.4476e-04 - val_loss: 0.0041\n",
      "Epoch 1785/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 512us/step - loss: 1.3133e-04 - val_loss: 0.0038\n",
      "Epoch 1786/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 1.3387e-04 - val_loss: 0.0036\n",
      "Epoch 1787/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 1.4766e-04 - val_loss: 0.0040\n",
      "Epoch 1788/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.4170e-04 - val_loss: 0.0043\n",
      "Epoch 1789/2000\n",
      "3423/3423 [==============================] - 2s 507us/step - loss: 1.3744e-04 - val_loss: 0.0043\n",
      "Epoch 1790/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.4244e-04 - val_loss: 0.0035\n",
      "Epoch 1791/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.4440e-04 - val_loss: 0.0041\n",
      "Epoch 1792/2000\n",
      "3423/3423 [==============================] - 2s 515us/step - loss: 1.4521e-04 - val_loss: 0.0039\n",
      "Epoch 1793/2000\n",
      "3423/3423 [==============================] - 2s 506us/step - loss: 1.4572e-04 - val_loss: 0.0039\n",
      "Epoch 1794/2000\n",
      "3423/3423 [==============================] - 2s 511us/step - loss: 1.4615e-04 - val_loss: 0.0041\n",
      "Epoch 1795/2000\n",
      "3423/3423 [==============================] - 2s 511us/step - loss: 1.2745e-04 - val_loss: 0.0041\n",
      "Epoch 1796/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.3125e-04 - val_loss: 0.0037\n",
      "Epoch 1797/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 1.3868e-04 - val_loss: 0.0040\n",
      "Epoch 1798/2000\n",
      "3423/3423 [==============================] - 2s 506us/step - loss: 1.3771e-04 - val_loss: 0.0039\n",
      "Epoch 1799/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.2278e-04 - val_loss: 0.0047\n",
      "Epoch 1800/2000\n",
      "3423/3423 [==============================] - 2s 511us/step - loss: 1.2222e-04 - val_loss: 0.0042\n",
      "Epoch 1801/2000\n",
      "3423/3423 [==============================] - 2s 513us/step - loss: 1.2285e-04 - val_loss: 0.0042\n",
      "Epoch 1802/2000\n",
      "3423/3423 [==============================] - 2s 515us/step - loss: 1.3188e-04 - val_loss: 0.0044\n",
      "Epoch 1803/2000\n",
      "3423/3423 [==============================] - 2s 507us/step - loss: 1.3149e-04 - val_loss: 0.0040\n",
      "Epoch 1804/2000\n",
      "3423/3423 [==============================] - 2s 512us/step - loss: 1.2900e-04 - val_loss: 0.0038\n",
      "Epoch 1805/2000\n",
      "3423/3423 [==============================] - 2s 506us/step - loss: 1.3340e-04 - val_loss: 0.0040\n",
      "Epoch 1806/2000\n",
      "3423/3423 [==============================] - 2s 511us/step - loss: 1.3750e-04 - val_loss: 0.0043\n",
      "Epoch 1807/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.3967e-04 - val_loss: 0.0042\n",
      "Epoch 1808/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.3860e-04 - val_loss: 0.0037\n",
      "Epoch 1809/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 1.3199e-04 - val_loss: 0.0046\n",
      "Epoch 1810/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.3944e-04 - val_loss: 0.0040\n",
      "Epoch 1811/2000\n",
      "3423/3423 [==============================] - 2s 517us/step - loss: 1.3130e-04 - val_loss: 0.0048\n",
      "Epoch 1812/2000\n",
      "3423/3423 [==============================] - 2s 506us/step - loss: 1.2755e-04 - val_loss: 0.0045\n",
      "Epoch 1813/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.2532e-04 - val_loss: 0.0043\n",
      "Epoch 1814/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.2151e-04 - val_loss: 0.0040\n",
      "Epoch 1815/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.2100e-04 - val_loss: 0.0046\n",
      "Epoch 1816/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.2428e-04 - val_loss: 0.0041\n",
      "Epoch 1817/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 1.2545e-04 - val_loss: 0.0046\n",
      "Epoch 1818/2000\n",
      "3423/3423 [==============================] - 2s 507us/step - loss: 1.2726e-04 - val_loss: 0.0043\n",
      "Epoch 1819/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 1.3622e-04 - val_loss: 0.0050\n",
      "Epoch 1820/2000\n",
      "3423/3423 [==============================] - 2s 518us/step - loss: 1.4238e-04 - val_loss: 0.0041\n",
      "Epoch 1821/2000\n",
      "3423/3423 [==============================] - 2s 507us/step - loss: 1.3852e-04 - val_loss: 0.0045\n",
      "Epoch 1822/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 1.3466e-04 - val_loss: 0.0042\n",
      "Epoch 1823/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 1.3403e-04 - val_loss: 0.0042\n",
      "Epoch 1824/2000\n",
      "3423/3423 [==============================] - 2s 513us/step - loss: 1.3294e-04 - val_loss: 0.0042\n",
      "Epoch 1825/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.2312e-04 - val_loss: 0.0043\n",
      "Epoch 1826/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.2635e-04 - val_loss: 0.0042\n",
      "Epoch 1827/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 1.2102e-04 - val_loss: 0.0040\n",
      "Epoch 1828/2000\n",
      "3423/3423 [==============================] - 2s 513us/step - loss: 1.3733e-04 - val_loss: 0.0045\n",
      "Epoch 1829/2000\n",
      "3423/3423 [==============================] - 2s 520us/step - loss: 1.3491e-04 - val_loss: 0.0044\n",
      "Epoch 1830/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.4040e-04 - val_loss: 0.0042\n",
      "Epoch 1831/2000\n",
      "3423/3423 [==============================] - 2s 514us/step - loss: 1.4438e-04 - val_loss: 0.0041\n",
      "Epoch 1832/2000\n",
      "3423/3423 [==============================] - 2s 506us/step - loss: 1.3078e-04 - val_loss: 0.0037\n",
      "Epoch 1833/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.3114e-04 - val_loss: 0.0044\n",
      "Epoch 1834/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.1524e-04 - val_loss: 0.0040\n",
      "Epoch 1835/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.1762e-04 - val_loss: 0.0050\n",
      "Epoch 1836/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.2002e-04 - val_loss: 0.0045\n",
      "Epoch 1837/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.1135e-04 - val_loss: 0.0047\n",
      "Epoch 1838/2000\n",
      "3423/3423 [==============================] - 2s 515us/step - loss: 1.2142e-04 - val_loss: 0.0046\n",
      "Epoch 1839/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.3248e-04 - val_loss: 0.0039\n",
      "Epoch 1840/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.3069e-04 - val_loss: 0.0042\n",
      "Epoch 1841/2000\n",
      "3423/3423 [==============================] - 2s 507us/step - loss: 1.2673e-04 - val_loss: 0.0045\n",
      "Epoch 1842/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.2183e-04 - val_loss: 0.0047\n",
      "Epoch 1843/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.2645e-04 - val_loss: 0.0040\n",
      "Epoch 1844/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.2125e-04 - val_loss: 0.0040\n",
      "Epoch 1845/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 1.3038e-04 - val_loss: 0.0047\n",
      "Epoch 1846/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.3113e-04 - val_loss: 0.0047\n",
      "Epoch 1847/2000\n",
      "3423/3423 [==============================] - 2s 517us/step - loss: 1.5313e-04 - val_loss: 0.0047\n",
      "Epoch 1848/2000\n",
      "3423/3423 [==============================] - 2s 507us/step - loss: 1.4235e-04 - val_loss: 0.0044\n",
      "Epoch 1849/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.3841e-04 - val_loss: 0.0043\n",
      "Epoch 1850/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.4437e-04 - val_loss: 0.0041\n",
      "Epoch 1851/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.3612e-04 - val_loss: 0.0043\n",
      "Epoch 1852/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.3567e-04 - val_loss: 0.0042\n",
      "Epoch 1853/2000\n",
      "3423/3423 [==============================] - 2s 506us/step - loss: 1.3148e-04 - val_loss: 0.0044\n",
      "Epoch 1854/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.2712e-04 - val_loss: 0.0045\n",
      "Epoch 1855/2000\n",
      "3423/3423 [==============================] - 2s 507us/step - loss: 1.1202e-04 - val_loss: 0.0038\n",
      "Epoch 1856/2000\n",
      "3423/3423 [==============================] - 2s 520us/step - loss: 1.2039e-04 - val_loss: 0.0039\n",
      "Epoch 1857/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 511us/step - loss: 1.3698e-04 - val_loss: 0.0045\n",
      "Epoch 1858/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.3078e-04 - val_loss: 0.0045\n",
      "Epoch 1859/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.3417e-04 - val_loss: 0.0040\n",
      "Epoch 1860/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.2982e-04 - val_loss: 0.0042\n",
      "Epoch 1861/2000\n",
      "3423/3423 [==============================] - 2s 511us/step - loss: 1.3677e-04 - val_loss: 0.0043\n",
      "Epoch 1862/2000\n",
      "3423/3423 [==============================] - 2s 511us/step - loss: 1.3283e-04 - val_loss: 0.0043\n",
      "Epoch 1863/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.2403e-04 - val_loss: 0.0041\n",
      "Epoch 1864/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.2225e-04 - val_loss: 0.0051\n",
      "Epoch 1865/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.2364e-04 - val_loss: 0.0043\n",
      "Epoch 1866/2000\n",
      "3423/3423 [==============================] - 2s 513us/step - loss: 1.1702e-04 - val_loss: 0.0045\n",
      "Epoch 1867/2000\n",
      "3423/3423 [==============================] - 2s 513us/step - loss: 1.2221e-04 - val_loss: 0.0042\n",
      "Epoch 1868/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.1630e-04 - val_loss: 0.0044\n",
      "Epoch 1869/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.0877e-04 - val_loss: 0.0047\n",
      "Epoch 1870/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.1015e-04 - val_loss: 0.0047\n",
      "Epoch 1871/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 1.0406e-04 - val_loss: 0.0050\n",
      "Epoch 1872/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.0768e-04 - val_loss: 0.0045\n",
      "Epoch 1873/2000\n",
      "3423/3423 [==============================] - 2s 507us/step - loss: 1.0270e-04 - val_loss: 0.0046\n",
      "Epoch 1874/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 1.0674e-04 - val_loss: 0.0043\n",
      "Epoch 1875/2000\n",
      "3423/3423 [==============================] - 2s 515us/step - loss: 1.1946e-04 - val_loss: 0.0041\n",
      "Epoch 1876/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.3280e-04 - val_loss: 0.0046\n",
      "Epoch 1877/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 1.2175e-04 - val_loss: 0.0047\n",
      "Epoch 1878/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.2904e-04 - val_loss: 0.0041\n",
      "Epoch 1879/2000\n",
      "3423/3423 [==============================] - 2s 507us/step - loss: 1.2927e-04 - val_loss: 0.0046\n",
      "Epoch 1880/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.4355e-04 - val_loss: 0.0048\n",
      "Epoch 1881/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.3717e-04 - val_loss: 0.0044\n",
      "Epoch 1882/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 1.2413e-04 - val_loss: 0.0041\n",
      "Epoch 1883/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.1461e-04 - val_loss: 0.0044\n",
      "Epoch 1884/2000\n",
      "3423/3423 [==============================] - 2s 517us/step - loss: 1.1985e-04 - val_loss: 0.0044\n",
      "Epoch 1885/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.1997e-04 - val_loss: 0.0047\n",
      "Epoch 1886/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 1.1971e-04 - val_loss: 0.0049\n",
      "Epoch 1887/2000\n",
      "3423/3423 [==============================] - 2s 521us/step - loss: 1.2289e-04 - val_loss: 0.0047\n",
      "Epoch 1888/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.1525e-04 - val_loss: 0.0044\n",
      "Epoch 1889/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 1.0698e-04 - val_loss: 0.0044\n",
      "Epoch 1890/2000\n",
      "3423/3423 [==============================] - 2s 507us/step - loss: 1.0978e-04 - val_loss: 0.0042\n",
      "Epoch 1891/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 1.1267e-04 - val_loss: 0.0043\n",
      "Epoch 1892/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 1.0630e-04 - val_loss: 0.0047\n",
      "Epoch 1893/2000\n",
      "3423/3423 [==============================] - 2s 516us/step - loss: 1.0929e-04 - val_loss: 0.0043\n",
      "Epoch 1894/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.1188e-04 - val_loss: 0.0043\n",
      "Epoch 1895/2000\n",
      "3423/3423 [==============================] - 2s 512us/step - loss: 1.2933e-04 - val_loss: 0.0051\n",
      "Epoch 1896/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.3607e-04 - val_loss: 0.0044\n",
      "Epoch 1897/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.3438e-04 - val_loss: 0.0043\n",
      "Epoch 1898/2000\n",
      "3423/3423 [==============================] - 2s 507us/step - loss: 1.1969e-04 - val_loss: 0.0049\n",
      "Epoch 1899/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.4220e-04 - val_loss: 0.0048\n",
      "Epoch 1900/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.3690e-04 - val_loss: 0.0047\n",
      "Epoch 1901/2000\n",
      "3423/3423 [==============================] - 2s 511us/step - loss: 1.2779e-04 - val_loss: 0.0045\n",
      "Epoch 1902/2000\n",
      "3423/3423 [==============================] - 2s 513us/step - loss: 1.2934e-04 - val_loss: 0.0049\n",
      "Epoch 1903/2000\n",
      "3423/3423 [==============================] - 2s 507us/step - loss: 1.2682e-04 - val_loss: 0.0044\n",
      "Epoch 1904/2000\n",
      "3423/3423 [==============================] - 2s 511us/step - loss: 1.1937e-04 - val_loss: 0.0044\n",
      "Epoch 1905/2000\n",
      "3423/3423 [==============================] - 2s 506us/step - loss: 1.1613e-04 - val_loss: 0.0044\n",
      "Epoch 1906/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 1.1782e-04 - val_loss: 0.0047\n",
      "Epoch 1907/2000\n",
      "3423/3423 [==============================] - 2s 506us/step - loss: 1.0809e-04 - val_loss: 0.0046\n",
      "Epoch 1908/2000\n",
      "3423/3423 [==============================] - 2s 513us/step - loss: 1.0891e-04 - val_loss: 0.0049\n",
      "Epoch 1909/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.1445e-04 - val_loss: 0.0051\n",
      "Epoch 1910/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 1.0949e-04 - val_loss: 0.0049\n",
      "Epoch 1911/2000\n",
      "3423/3423 [==============================] - 2s 517us/step - loss: 1.1198e-04 - val_loss: 0.0045\n",
      "Epoch 1912/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.1560e-04 - val_loss: 0.0050\n",
      "Epoch 1913/2000\n",
      "3423/3423 [==============================] - 2s 506us/step - loss: 1.2101e-04 - val_loss: 0.0045\n",
      "Epoch 1914/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 1.2090e-04 - val_loss: 0.0043\n",
      "Epoch 1915/2000\n",
      "3423/3423 [==============================] - 2s 511us/step - loss: 1.2036e-04 - val_loss: 0.0045\n",
      "Epoch 1916/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.1313e-04 - val_loss: 0.0047\n",
      "Epoch 1917/2000\n",
      "3423/3423 [==============================] - 2s 506us/step - loss: 1.1691e-04 - val_loss: 0.0050\n",
      "Epoch 1918/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.2611e-04 - val_loss: 0.0045\n",
      "Epoch 1919/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 1.3679e-04 - val_loss: 0.0047\n",
      "Epoch 1920/2000\n",
      "3423/3423 [==============================] - 2s 517us/step - loss: 1.3302e-04 - val_loss: 0.0044\n",
      "Epoch 1921/2000\n",
      "3423/3423 [==============================] - 2s 513us/step - loss: 1.2541e-04 - val_loss: 0.0041\n",
      "Epoch 1922/2000\n",
      "3423/3423 [==============================] - 2s 512us/step - loss: 1.1281e-04 - val_loss: 0.0045\n",
      "Epoch 1923/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.1811e-04 - val_loss: 0.0048\n",
      "Epoch 1924/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 1.2265e-04 - val_loss: 0.0043\n",
      "Epoch 1925/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.1828e-04 - val_loss: 0.0043\n",
      "Epoch 1926/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.1001e-04 - val_loss: 0.0050\n",
      "Epoch 1927/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.1059e-04 - val_loss: 0.0040\n",
      "Epoch 1928/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.0844e-04 - val_loss: 0.0046\n",
      "Epoch 1929/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 513us/step - loss: 1.0810e-04 - val_loss: 0.0046\n",
      "Epoch 1930/2000\n",
      "3423/3423 [==============================] - 2s 516us/step - loss: 1.1160e-04 - val_loss: 0.0052\n",
      "Epoch 1931/2000\n",
      "3423/3423 [==============================] - 2s 513us/step - loss: 1.1323e-04 - val_loss: 0.0044\n",
      "Epoch 1932/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 1.1819e-04 - val_loss: 0.0046\n",
      "Epoch 1933/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.1312e-04 - val_loss: 0.0046\n",
      "Epoch 1934/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.1174e-04 - val_loss: 0.0044\n",
      "Epoch 1935/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 1.0768e-04 - val_loss: 0.0050\n",
      "Epoch 1936/2000\n",
      "3423/3423 [==============================] - 2s 506us/step - loss: 1.1306e-04 - val_loss: 0.0045\n",
      "Epoch 1937/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.0148e-04 - val_loss: 0.0046\n",
      "Epoch 1938/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 1.1894e-04 - val_loss: 0.0049\n",
      "Epoch 1939/2000\n",
      "3423/3423 [==============================] - 2s 516us/step - loss: 1.1179e-04 - val_loss: 0.0046\n",
      "Epoch 1940/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 1.2619e-04 - val_loss: 0.0050\n",
      "Epoch 1941/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.2080e-04 - val_loss: 0.0050\n",
      "Epoch 1942/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 1.1266e-04 - val_loss: 0.0046\n",
      "Epoch 1943/2000\n",
      "3423/3423 [==============================] - 2s 511us/step - loss: 1.1480e-04 - val_loss: 0.0045\n",
      "Epoch 1944/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.1746e-04 - val_loss: 0.0043\n",
      "Epoch 1945/2000\n",
      "3423/3423 [==============================] - 2s 506us/step - loss: 1.4105e-04 - val_loss: 0.0045\n",
      "Epoch 1946/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.2057e-04 - val_loss: 0.0049\n",
      "Epoch 1947/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.2736e-04 - val_loss: 0.0054\n",
      "Epoch 1948/2000\n",
      "3423/3423 [==============================] - 2s 517us/step - loss: 1.3242e-04 - val_loss: 0.0051\n",
      "Epoch 1949/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 1.1566e-04 - val_loss: 0.0045\n",
      "Epoch 1950/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 1.1163e-04 - val_loss: 0.0044\n",
      "Epoch 1951/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 1.1238e-04 - val_loss: 0.0040\n",
      "Epoch 1952/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.1965e-04 - val_loss: 0.0046\n",
      "Epoch 1953/2000\n",
      "3423/3423 [==============================] - 2s 507us/step - loss: 1.0659e-04 - val_loss: 0.0044\n",
      "Epoch 1954/2000\n",
      "3423/3423 [==============================] - 2s 511us/step - loss: 1.0871e-04 - val_loss: 0.0046\n",
      "Epoch 1955/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 1.0927e-04 - val_loss: 0.0040\n",
      "Epoch 1956/2000\n",
      "3423/3423 [==============================] - 2s 511us/step - loss: 1.0779e-04 - val_loss: 0.0049\n",
      "Epoch 1957/2000\n",
      "3423/3423 [==============================] - 2s 517us/step - loss: 1.1138e-04 - val_loss: 0.0045\n",
      "Epoch 1958/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.0910e-04 - val_loss: 0.0048\n",
      "Epoch 1959/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.0465e-04 - val_loss: 0.0048\n",
      "Epoch 1960/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.0072e-04 - val_loss: 0.0041\n",
      "Epoch 1961/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 1.0701e-04 - val_loss: 0.0049\n",
      "Epoch 1962/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.0991e-04 - val_loss: 0.0045\n",
      "Epoch 1963/2000\n",
      "3423/3423 [==============================] - 2s 517us/step - loss: 9.9079e-05 - val_loss: 0.0050\n",
      "Epoch 1964/2000\n",
      "3423/3423 [==============================] - 2s 513us/step - loss: 9.5704e-05 - val_loss: 0.0046\n",
      "Epoch 1965/2000\n",
      "3423/3423 [==============================] - 2s 511us/step - loss: 9.4737e-05 - val_loss: 0.0049\n",
      "Epoch 1966/2000\n",
      "3423/3423 [==============================] - 2s 517us/step - loss: 1.0139e-04 - val_loss: 0.0050\n",
      "Epoch 1967/2000\n",
      "3423/3423 [==============================] - 2s 512us/step - loss: 1.0105e-04 - val_loss: 0.0046\n",
      "Epoch 1968/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.0669e-04 - val_loss: 0.0048\n",
      "Epoch 1969/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.1197e-04 - val_loss: 0.0053\n",
      "Epoch 1970/2000\n",
      "3423/3423 [==============================] - 2s 511us/step - loss: 1.0733e-04 - val_loss: 0.0048\n",
      "Epoch 1971/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 9.6907e-05 - val_loss: 0.0048\n",
      "Epoch 1972/2000\n",
      "3423/3423 [==============================] - 2s 507us/step - loss: 9.2946e-05 - val_loss: 0.0046\n",
      "Epoch 1973/2000\n",
      "3423/3423 [==============================] - 2s 506us/step - loss: 9.5864e-05 - val_loss: 0.0044\n",
      "Epoch 1974/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 9.8514e-05 - val_loss: 0.0048\n",
      "Epoch 1975/2000\n",
      "3423/3423 [==============================] - 2s 516us/step - loss: 9.3452e-05 - val_loss: 0.0049\n",
      "Epoch 1976/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.1117e-04 - val_loss: 0.0048\n",
      "Epoch 1977/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 1.2154e-04 - val_loss: 0.0049\n",
      "Epoch 1978/2000\n",
      "3423/3423 [==============================] - 2s 511us/step - loss: 1.0696e-04 - val_loss: 0.0047\n",
      "Epoch 1979/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.0996e-04 - val_loss: 0.0051\n",
      "Epoch 1980/2000\n",
      "3423/3423 [==============================] - 2s 515us/step - loss: 1.0169e-04 - val_loss: 0.0045\n",
      "Epoch 1981/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 9.9558e-05 - val_loss: 0.0047\n",
      "Epoch 1982/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.0826e-04 - val_loss: 0.0047\n",
      "Epoch 1983/2000\n",
      "3423/3423 [==============================] - 2s 507us/step - loss: 1.2678e-04 - val_loss: 0.0051\n",
      "Epoch 1984/2000\n",
      "3423/3423 [==============================] - 2s 512us/step - loss: 1.1934e-04 - val_loss: 0.0046\n",
      "Epoch 1985/2000\n",
      "3423/3423 [==============================] - 2s 513us/step - loss: 1.0990e-04 - val_loss: 0.0053\n",
      "Epoch 1986/2000\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 1.3611e-04 - val_loss: 0.0053\n",
      "Epoch 1987/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.3341e-04 - val_loss: 0.0050\n",
      "Epoch 1988/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.2211e-04 - val_loss: 0.0048\n",
      "Epoch 1989/2000\n",
      "3423/3423 [==============================] - 2s 506us/step - loss: 1.1006e-04 - val_loss: 0.0050\n",
      "Epoch 1990/2000\n",
      "3423/3423 [==============================] - 2s 506us/step - loss: 9.9228e-05 - val_loss: 0.0049\n",
      "Epoch 1991/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.0489e-04 - val_loss: 0.0044\n",
      "Epoch 1992/2000\n",
      "3423/3423 [==============================] - 2s 512us/step - loss: 1.0490e-04 - val_loss: 0.0046\n",
      "Epoch 1993/2000\n",
      "3423/3423 [==============================] - 2s 511us/step - loss: 1.0788e-04 - val_loss: 0.0049\n",
      "Epoch 1994/2000\n",
      "3423/3423 [==============================] - 2s 517us/step - loss: 1.2152e-04 - val_loss: 0.0048\n",
      "Epoch 1995/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1.1217e-04 - val_loss: 0.0051\n",
      "Epoch 1996/2000\n",
      "3423/3423 [==============================] - 2s 511us/step - loss: 1.0056e-04 - val_loss: 0.0046\n",
      "Epoch 1997/2000\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1.0151e-04 - val_loss: 0.0044\n",
      "Epoch 1998/2000\n",
      "3423/3423 [==============================] - 2s 511us/step - loss: 9.9106e-05 - val_loss: 0.0048\n",
      "Epoch 1999/2000\n",
      "3423/3423 [==============================] - 2s 507us/step - loss: 9.9516e-05 - val_loss: 0.0043\n",
      "Epoch 2000/2000\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 9.9824e-05 - val_loss: 0.0048\n"
     ]
    }
   ],
   "source": [
    "final_model = build_lstm(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'twice': True,\n",
       " 'shuffle': True,\n",
       " 'lstmsize': 132,\n",
       " 'full_density': True,\n",
       " 'density': 148,\n",
       " 'activation': 'elu',\n",
       " 'optimizer': 'adam',\n",
       " 'callbacks': [<keras.callbacks.callbacks.ModelCheckpoint at 0x211ae938c88>]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_182\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_363 (LSTM)              (None, 92, 132)           72864     \n",
      "_________________________________________________________________\n",
      "lstm_364 (LSTM)              (None, 132)               139920    \n",
      "_________________________________________________________________\n",
      "dense_908 (Dense)            (None, 148)               19684     \n",
      "_________________________________________________________________\n",
      "dense_909 (Dense)            (None, 74)                11026     \n",
      "_________________________________________________________________\n",
      "dense_910 (Dense)            (None, 37)                2775      \n",
      "_________________________________________________________________\n",
      "dense_911 (Dense)            (None, 18)                684       \n",
      "_________________________________________________________________\n",
      "dense_912 (Dense)            (None, 1)                 19        \n",
      "=================================================================\n",
      "Total params: 246,972\n",
      "Trainable params: 246,972\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model[0].load_weights('./checkpoints/IBM_5days/IBM.(actual_best).hdf5')\n",
    "y_predicted = final_model[0].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y_test = y_normaliser.inverse_transform(y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE is 21.64\n",
      "Medium error is 3.28\n"
     ]
    }
   ],
   "source": [
    "loss = np.mean((unscaled_y_test - predicted_y_test)**2)\n",
    "medium_error = np.mean(abs(unscaled_y_test - predicted_y_test))\n",
    "print(f'MSE is {loss:.2f}\\nMedium error is {medium_error:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_down_test = []\n",
    "up_down_predicted = []\n",
    "\n",
    "for y,x in zip(Y_test,X_test):\n",
    "    if y[0] > x[-1][0]: up_down_test.append(1)\n",
    "    elif y[0] < x[-1][0]: up_down_test.append(-1)\n",
    "    else: up_down_test.append(0)\n",
    "        \n",
    "for y,x in zip(y_predicted,X_test):\n",
    "    if y[0] > x[-1][0]: up_down_predicted.append(1)\n",
    "    elif y[0] < x[-1][0]: up_down_predicted.append(-1)\n",
    "    else: up_down_predicted.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trend accuracy is: 57.10%\n"
     ]
    }
   ],
   "source": [
    "print(f'Trend accuracy is: {(sum(1 for r,p in zip(up_down_test,up_down_predicted) if r == p)/len(up_down_test))*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for upward trend is: 54.05%\n",
      "Accuracy for downward trend is: 60.53%\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy for upward trend is: {(sum(1 for r,p in zip(up_down_test,up_down_predicted) if r == 1 and p == 1)/sum(1 for v in up_down_test if v == 1))*100:.2f}%')\n",
    "print(f'Accuracy for downward trend is: {(sum(1 for r,p in zip(up_down_test,up_down_predicted) if r == -1 and p == -1)/sum(1 for v in up_down_test if v == -1))*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predictions over the last 92 days in test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 3200x2400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "figure(num=None, figsize=(40, 30), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "plt.plot(range(92), unscaled_y_test[-92:])\n",
    "plt.plot(range(92), predicted_y_test[-92:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Actual week + prediction of next week (10 days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 3200x2400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure(num=None, figsize=(40, 30), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "plt.plot(range(10), unscaled_y_test[-10:])\n",
    "plt.plot(range(10), np.append(unscaled_y_test[-10:-5], predicted_y_test[-5:]))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
